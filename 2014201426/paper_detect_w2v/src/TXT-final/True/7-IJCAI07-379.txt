
we investigate search problems under risk in statespace graphs  with the aim of finding optimal paths for risk-averse agents. we consider problems where uncertainty is due to the existence of different scenarios of known probabilities  with different impacts on costs of solution-paths. we consider various non-linear decision criteria  eu  rdu  yaari  to express risk averse preferences; then we provide a general optimization procedure for such criteria  based on a path-ranking algorithm applied on a scalarized valuation of the graph. we also consider partial preference models like second order stochastic dominance  ssd  and propose a multiobjective search algorithm to determine ssdoptimal paths. finally  the numerical performance of our algorithms are presented and discussed.
1 introduction
various problems investigated in artificial intelligence can be formalized as shortest path problemsin an implicit state space graph  e.g. path-planning for mobile robots  vlsi layout  internet searching . starting from a given state  we want to determine an optimal sequence of admissible actions allowing transitions from state to state until a goal state is reached. here  optimality refers to the minimization of one or several cost functions attached to transitions  representing distances  times  energy consumptions...forsuch problems  constructive search algorithms like a  and a붼   hart et al.  1; pearl  1  for single objective problems or moa  for multiobjective problems  stewart and white iii  1  have been proposed  performingthe implicit enumeration of feasible solutions.
모an important source of complexity in path-planning problems is the uncertainty attached to some elements of the problem. in some situations  the consequences of actions are not certain and the transitions are only known in probabilities. in some other  the knowledge of the current state is imperfect  partial observability . finally  the costs of transitions might itself be uncertain. although many studies concentrate on the two first sources of uncertainty  see the important litterature on mdps and pomdps  e.g. puterman  1; kaebling et al.  1   some others focus on the uncertainty attached to transition-costs. for example  when costs are time dependent and representable by random variables  the sda  algorithm has been introduced to determine the preferred paths according to the stochastic dominance partial order  wellman et al.  1 . an extension of this algorithm specifically designed to cope with both uncertainty and multiple criteria has been proposed by wurman and wellman .
모we consider here another variation of the search problem under uncertainty  that concerns the search of  robust  solution-paths  as introduced by kouvelis and yu . under total uncertainty  it corresponds to situations where costs of paths might depend on different possible scenarios  states of the world   or different viewpoints  discordant sources of information . roughly speaking  the aim is to determine paths with  reasonnable  cost in all scenarios. under risk  i.e. when probabilities are known  this problem generalizes to the search of  low-cost/low-risk  paths. let us consider a simple example:
example 1 consider the network pictured on figure 1 where the initial state is 1 and the goal node is 1. assume that only two scenarios with known probabilities p1 and p1 are relevant concerning the traffic  yielding two different sets of costs on the network. hence  to each path pi is associated a vector
  one cost per scenario: with x1 =
 with
with  

x =  1 	  i = 1 ... 1  we want to determine solutions paths associated with low-risk cost-distributions.

figure 1: a 1-scenarios problem and its representation
모this simple problem might prove very hard to solve on larger instances due to the coexistence of two difficulties: the combinatorial nature of the solution space and the existence of several conflicting scenarios on costs. it is important to note that the vector-valued path problem introduced above cannot be reduced to a standard shortest path problem by linear scalarization of cost-vectors without loosing significant information. assume for example that the arcs of the graph plotted on the left part of figure 1 are valued accoding to their expected cost  so that each path pi receives a weight
. then algorithm a  used with such
scalars weights might output p1 or p1  depending on the relative value of p1 and p1  but neither path p1 nor p1 p1. this can easily be shown using the right part of figure 1 where the images of solution-paths are plotted in the valuation space; we can indeed see that p1  p1 and p1 do not belong to the boundary of the convex hull  grey triangle  of the images of paths  thus being excluded from the set of potential winners  as long as a linear criterion is used. this is not satisfactory because p1 presents a well-balanced profile and might be preferred to p1 or p1 by a risk-averse agent. similarly he might prefers p1 to p1 or p1 to p1  depending on probabilities.
모example 1 shows the limitations of linear aggregation functions in decision-making under risk on non-convex domains. to overcome the difficulty  we need to resort to more sophisticated decision criteria to compare cost distributions in term of risk  as those introduced in decision theory. these decision criteria escape linearity either by introducinga transformation of costs as in the expected utility model  eu  von neumann and morgenstern  1   or by introducing a probability-transformation as in yaari's model  yaari  1   or even both as in the rank-dependent utility model  rdu  quiggin  1  . alternatively  partial comparison models including an idea of risk might be used when the agent's utility function is not known  e.g. second-orderstochastic dominance  ssd . the aim of this paper is to incorporate such models in search algorithms to determine low-risk solution paths in implicit graphs.
모the paper is organized as follows: in section 1  we introduce preliminary formal material as well as decision criteria modelling risk-sensitive decision behaviours. in section 1  we propose a general optimization procedure to find the best paths with respect to such criteria. in section 1  we propose a multiobjective search algorithm for the determination of ssd-optimal paths. finally  numerical experiments of algorithms are given in section 1.
1 problem formulation
1 notations and definitions
we consider a state space graph g =  n a  where n is a finite set of nodes  possible states   and a is a set of arcs representingfeasible transitions between nodes. formally we have where s n    n is the set of all successors of node n  nodes that can be reached from n by a feasible elementary transition . then s 뫍 n denotes the source of the graph  the initial state   붞   n the subset of goal nodes  p s 붞  the set of all paths from s to a goal node 붺 뫍 붞  and the set of all paths linking n to n. we call solution-path a path from s to a goal node 붺 뫍 붞. throughoutthe paper  we assume that there exists at least one solution-path.
모following a classical scheme in robust optimization  kouvelis and yu  1   we consider a finite set s =
{s1 ... sm} of possible scenarios  each having possibly a different impact on the transition-costs  and a scenariodependent valuation v : a 뫄 s 뫸 n giving  for any arc a 뫍 a and any scenario s 뫍 s the cost v a s  of the transition represented by a. costs over a path are supposed to be additive  which allows valuation v to be extended from arcs to paths by setting  for any path p and any scenario s 
. in the sequel  we assume that the
cost of every solution path is  upper  bounded by a positive constant m.
모a cost-vector  is associated to each path p in the graph in such a way that component xi = v p si . let pi denote the probability of scenario si  with pi 뫟 1 for  then a path p with cost-vector x is represented by the distribution  x1 ... xm;p1 ... pm . let l be the set of probabilistic distributions having a finite support in  1 m . the cost of each path is a random variable x characterized by law px 뫍 l  defined for any b    1 m   by px b  = p {s 뫍 s : x s  뫍 b} . for any random variable x  the expected value of x is given by m   the cumulative function fx is given by fx z  = p {s 뫍 s : x s  뫞 z}  for all z 뫍  1 m  and the associated decumulative function is denoted gx z  = 1   fx z .
1 decision criteria for risk-averse agents
in the field of decision making under risk  the concept of riskaversion has been widely investigated  first in the framework of eu theory and then in more general frameworks. roughly speaking  risk-aversion amounts to preferring a solution with a guaranteed cost to any other risky solution with the same expected cost. this was formalized by pratt and arrow  pratt  1; arrow  1  that define weak risk-aversion for a weak preference relation  on l as follows:
definition 1 an agent is said to be weakly risk-averse if  for any distribution x in l  he considers that e x  is as least as good as.
모in eu theory  risk-aversion means that the agent's utility function u on payoffs is increasing and concave  the coefficient of risk-aversion of any agent being measured by
  arrow  1 . in our context  the counterpart of eu is given by the expected weight function:
		 1 
where w :  1 m  뫸 r is a strictly increasing function such that w xi  represents the subjective weight  disutility  attached to cost xi by the agent. criterion ew x  is to be minimized since it represents the disutility of any cost distribution x. in the ew model  risk aversion means choosing an increasing and convex w in equation  1   so as to get ew e x   뫞 ew x  for all x 뫍 l.
모despite its intuitive appeal  eu theory does not explain all rational decision making behaviors  e.g. the violation of savage's sure thing principle  ellsberg  1  . this has led researchers to sophisticate the definition of expected utility. among the most popular generalizations of eu  let us mention the rank dependent utility introduced by quiggin   which can be reformulated in our context as follows:

where  .  represents a permutation on {1 ... m} such that x 1  뫞 ... 뫞 x m     is a non-decreasing probability transformation function  proper to any agent  such that   1  = 1 and   1  = 1  and w is a weight function assigning subjective disutility to real costs. this criterion can be interpreted as follows: the weight of a path with cost-distribution x is at least w x 1   with probability 1. then the weight might increase from w x 1   to w x 1   with probability mass   gx x 1   ; the same applies from w x 1   to w x 1   with probabilitymass   gx x 1     and so on... when w z  = z for all z 
rdw is known as yaari's model  yaari  1 .
모weak risk-aversion can be obtained in yaari's model by choosing a probability transformation such that   p  뫟 p for all p 뫍  1 . this holds also for rdw provided function w is convex  quiggin  1 . on the other hand  when   is the identity function  then rdw boils down to ew. indeed  considering probabilities q 1  = 1 and
 for all i = 1 ... m   1  rdw criterion can be rewritten as follows:

from this last equation  observing that q i    q i+1  = p i   we can see that rdw reduces to ew when   z  = z for all z. hence  rdw generalizes both ew and yaari's model. for the sake of generality  we consider rdw in the sequel and investigate the following problem:
rdw search problem. we want to determine a rdwoptimal distribution in the set of all cost distributions of paths in p s 붞 .
this problem is np-hard. indeed  choosing w x  = x    1  = 1 and   x  = 1 for all x 뫍  1 m   we get rdw x  = x m  = maxi xi. hence rdw minimization in a vector valued graph reduces to the min-max shortest path problem  proved np-hard by murthy and her .
1 search with rdw
as many other non-linear criteria  rdw breaks the bellman principle and one cannot directly resort to dynamic programming to compute optimal paths. to overcome this difficulty  we propose an exact algorithm which proceeds in three steps: 1  linear scalarization: the cost of every arc is defined as the expected value of its cost distribution; 1  ranking: enumeration of paths by increasing order of expected costs; 1  stopping condition: stops enumeration when we can prove that a rdw-optimal distribution has been found. step 1 can be performed by ka   an extension of a  proposed by galand and perny  to enumerate the solution-paths of an implicit graph by increasing order of costs. before expliciting step 1  we need to establish the following result:
proposition 1 for all non-decreasing probability transformations   on  1  such that   q  뫟 q for all q 뫍  1   for all non-decreasing and convex weight functions w on  1 m   for all x 뫍 l we have: rdw x  뫟 w  e x  
proof. since x i+1  뫟 x i  for i = 1 ... m   1 and w is non-decreasing  we have: w x i+1     w x i   뫟 1 for all i = 1 ... m   1. hence  from equation  1     q  뫟 q for all q 뫍  1  implies that: rdw x 
m
= ew x  뫟 w e x   by convexity of w.	
now  let {p1 ... pr} denotes the set of elementary solution-paths in p s 붞   with cost distributions x1 ... xr  indexed in such a way that e x1  뫞 e x1  뫞
... 뫞 e xr . each distribution xj yields cost xji = v pj si  with probability pi for i = 1 ... m. the sequence of paths  pj j=1 ... r can be generated by implementing the ranking algorithm of step 1 on the initial graph
g =  n a   using a scalar valuation defined by m . indeed  the value of any path pj in this graph is by linearity of expectation.
모now  assume that  during the enumeration  we reach  at step k  a path pk such that: w e xk   뫟 rdw x붹 k   where 붹 k  is the index of a rdw-optimal path in
{p1 ... pk}  then enumeration can be stopped thanks to:
proposition 1 if w e xk   뫟 rdw x붹 k   for some k 뫍 {1 ... r}  where 붹 k  is the index of a rdw-minimal path in {p1 ... pk}  then p붹 k  is a rdw-minimal solutionpath in p s 붞 .
proof. we know that p붹 k  is rdw-minimal among the k-first detected paths. we only have to show that no other solution-path can have a lower weight according to rdw. for all j 뫍 {k + 1 ... r} we have: rdw xj  뫟 w e xj   thanks to proposition 1. moreover e xj  뫟 e xk  which implies w e xj   뫟 w e xk   뫟 rdw x붹 k  . hence rdw xj  뫟
rdw x붹 k   which shows that p붹 k  is rdw-minimal over p s 붞 .	
모propositions 1 and 1 show that the ranked enumeration of solution-paths performed at step 1 can be interrupted without loosing the rdw-optimal solution. this establishes the admissibility of our 1-steps algorithm. numerical tests performed on different instances and presented in section 1 indicate that the stopping condition is activated early in the enumeration  which shows the practical efficiency of the proposed algorithm.
1 dominance-based search
functions rdw and ew provide sharp evaluation criteria but require a precise knowledge of the agent's attitude towards risk  at least to assess the disutility function . in this section we consider less demanding models yet allowing well-founded discrimination between some distributions.
1 dominance relations
a primary dominance concept to compare cost distributions in l is the following:
definition 1 for all x  y 뫍 l  functional dominance is defined by: x fd y     s 뫍 s x s  뫞 y  s  
모for relation fd and any other dominance relation fined in the sequel  the set of distributions in l  
l is defined by:.
모when the probabilities of scenarios are known  functional dominance can be refined by first order stochastic dominance defined as follows:
definition 1 for all x y 뫍 l  the first order stochastic dominance relation is defined by:
x fsd y     z 뫍  1 m  gx z  뫞 gy  z  
actually  the usual definition of fsd involves cumulative distributions fx applied to payoffs instead of decumulative functions gx applied to costs. in definition 1  x fsd y means that x assigns no more probability than y to events of type:  the cost of the path will go beyond z . hence it is natural to consider that x is at least as good as y when
x fsd y .
모relation fsd is clearly related to the ew model since x fsd y if and only if ew x  뫞 ew y   for all increasing weight function w  quiggin  1 . this gives a nice interpretation to definition 1 within eu theory  with a useful consequence: if the agent is a ew-minimizer  with any increasing weight function w   then his preferred solutions necessarily belong to the set of fsd-optimal solutions. now  an even richer dominance relation can be considered:
definition 1 for all x y 뫍 l  the second order stochastic dominance relation is defined as follows:
     x ssd y     z 뫍  1 m  g1x z  뫞 g1y  z   where for all z 뫍  1 m .
stochastic dominance is acknowledged as a standard way of characterizing risk-averse behaviors independently of any utility model. for example  rotschild and stiglitz  and machina and pratt  provide axiomatic characterizations of ssd in terms of risk using  mean preserving spreads . as a consequence  an agent is said to be strongly risk-averse if he prefers x to y whenever x ssd y . moreover  ssd has a natural interpretation within eu theory: x ssd y if and only if ew x  뫞 ew y   for all increasing and convex weight function w  quiggin  1 . as a nice consequence we knowthat wheneveran agentis a risk-averse ew-minimizer  then his preferred solutions necessarily belong to the set of ssd-optimal solutions. the same applies to rdw provided 뷋 q  뫟 q for all q 뫍  1  and function w is convex  this directly follows from a result of quiggin  . this shows that  even outside eu theory  ssd appears as a natural preference relation for risk-averse agents. it can be used as a first efficient filtering of risky paths.
모interestingly enough  relations fsd and ssd dominance relations can equivalently be defined by:
x fsd y     p 뫍  1  g몭x p  뫞 g몭y  p   1 x ssd y     p 뫍  1  g몭1x p  뫞 g몭1y  p  
where g몭x and g몭1 are inverse functions defined by: 1 x
 
모since s is finite in our context  x is a discrete distribution; therefore gx and g몭x are step functions. moreover g1x and g몭1x are piecewise linear functions. function g몭1x z  is known as the lorenz function. it is commonly used for inequality ordering of positive random variables  muliere and scarsini  1 . as an illustration  consider example 1 with p1 = 1 and p1 = 1. we have: g몭1 p  = 1p for all p 뫍  1.1   g몭1 p  = 1 + 1p for all p 뫍  1 1   whereas g몭1 p  = 1p for all p 뫍  1.1   g몭1 p  = 1+1p for all p 뫍  1 1 ; hence g몭1 p  뫞 g몭1 p  for all p and therefore x1 ssd x1. this confirms the intuition that path p1 with cost  1  is less risky than path p1 with cost  1 
모the dominance relations introduced in this subsection being transitive  the sets of fd-optimal elements  fsd-optimal elements and ssd-optimal elements are not empty. moreover  these sets are nested thanks to the following implications: x fd y   x fsd y and x fsd y  
x ssd y   for all distributions x y 뫍 l. in example 1 we have l = {x1 x1 x1 x1 x1 x1} and p1 = 1 and p1 = 1. hence the set of fd-optimal elements is {x1 x1 x1 x1 x1}  the set of fsd-optimal elements is the same and the set of ssd-optimal elements is {x1 x1 x1}. the next section is devoted to the following:
ssd search problem. we want to determine all ssd-optimal distributions in the set of cost distributions of paths in p s 붞  and for each of them  at least one solution-path.
1 problem complexity
to assess complexity of the search  we first make explicit a link between ssd and generalized lorenz dominance  as defined by marshall and olkin . generalized lorenz dominance  denoted gld in the sequel  is based on the definition of lorenz vector l x  =  l1 x  ... lm x   for any vector x =  x1 ... xm  where lk x  is the sum of the k greatest components of x. then  relation gld is defined as follows: x gld y if l x  pareto dominates l y   i.e. lk x  뫞 lk y  for k = 1 ... m. now  if pi = 1/m for i = 1 ... m then ssd defined by equation  1  on distributions reduces to lorenz dominance on the corresponding cost vectors since lk x  = mg몭1x k/m . hence  in the particular case of equally probable scenarios  the ssd search problem reduces to the search of lorenz non-dominated paths  a nphard problem as shown by perny and spanjaard . this shows that the ssd search problem is also np-hard.
1 the ssda  algorithm
consider example 1 and assume that the two scenarios have equal probabilities  we can see that the preferred subpath from node 1 to node 1 is with cost xp =  1  which is preferred to path  with cost 
 1  since  1;1 1  ssd  1;1 1 . indeed  we are in the case of subsection 1  equally probable scenarios  with and obviously  1  pareto dominates  1 . now  appending path withrespectively yields path with cost x1 =  1  and path
. hence l x1  pareto dom-
inates l x1   therefore  1;1 1 ssd  1;1 1  which constitutes a preference reversal and illustrates a violation of bellman principle  thus invalidating a direct dynamic programming approach  optimal path p1 would be lost during the search if p is pruned at node 1 due to p .
모however  the problem can be overcome knowing that: i  ssd-optimal paths are also fd-optimal; ii  fd-optimality satisfies the bellman principle; iii  the set of scenarios being finite  fd-optimality on cost distributions is nothing else but pareto-optimality on cost-vectors. ssd-optimal distributions might indeed be obtained in two stages: 1  generate fd-optimal solution-paths using multiobjective a   moa   stewart and white iii  1; mandow and de la cruz  1 ; 1  eliminate ssd-dominated solutions within the output set. however  fd-optimal solutions being often numerous  it is more efficient to focus directly on ssd-optimal solutions during the search. for this reason we introduce now a refinement of moa  called ssda  for the direct determination of ssdoptimal solutions.
모as in moa   ssda  expands vector-valued labels  attached to subpaths  rather than nodes. note that  unlike the scalar case  there possibly exists several pareto nondominated paths with distinct cost-vectors to reach a given node; hence several labels can be associate to a same node n. at each step of the search  the set of generated labels is divided into two disjoint sets: a set open of not yet expanded labels and a set closed of already expanded labels. whenever the label selected for expansion is attached to a solution path  it is stored in a set sol. initially  open contains only the label attached to the empty subpath on node s  while closed and sol are empty. we describe below the essential features of the ssda  algorithm.
output: it determines the set of ssd-optimal solution-paths  i.e. solution-paths the distribution of which is ssd-optimal. if several paths have the same g1 distribution  only one path among them is stored using standard bookkeeping techniques.
heuristics: like in moa   a set h n  of heuristic costvectors is used at any node n since n may be on the path of more than one non-dominated solution. this set estimates the set h  n  of non-dominated costs of paths from n to 붞. priority: to direct the search we use a set-valued labelevaluation function f defined in such a way that    at any label   estimates the set of non-dominated costs of solution paths extending the subpath associated with .
this set is computed from all possible combinations
  where denotes the value of
the subpath associated with and the node to which  is attached. at each step of the search  ssda  expands a label  in open such that contains at least one ssd-optimal cost-vector inopen. such a label can be chosen  for instance  so as to minimize ew with a convex w function. at goal nodes  this priority rule guarantees to expand only labels attached to ssd-optimal paths.
pruning: the pruning of labels cannot be done directly with the ssd relation  as shown in the beginning of this subsection. the following pruning rules are used:
rule 1: at node n  a label  뫍 open is pruned if there exists another label  at the same node n such that.
this rule is essentially the same as in moa  and is justified by the fact that fd-optimality does satisfy the bellman principle and fd dominanceimplies ssd dominance. indeed  labels pruned like this necessarily lead to a fd-dominatedpaths and therefore cannot lead to ssd-optimal solution paths.
rule 1: a label  뫍 open is pruned if for all there existssol such that ssd f. this rule allows an early eliminationof uninteresting labels while keepingadmissibility of the algorithm provided heuristic h is admissible  i.e.  n 뫍 n   h  뫍 h  n    h 뫍 h n  s.t. h fd h . indeed  if h is admissible  then for all there exists  such that  which implies that f ssd f  and therefore ssd f  by transitivity of ssd.
모note that deciding whether x ssd y can be performed in constant time. indeed  since functions g몭1x p  and g몭1y  p  are piecewise linear as indicated in section 1  their comparison amounts to test for pareto dominance on the union set of break points of both functions  the cardinality of which is upper bounded by 1m.
termination: the process is kept running until the set open becomes empty  i.e. there is no remaining subpath able to reach a new ssd-optimal solution path. by construction  ssda  develops a subgraph of the one developped by moa  and the termination derives from the termination of moa .
1 numerical tests
various tests have been performed to evaluate the performance of algorithms on randomly generated graphs of different sizes. the number of nodes in these graphs varies from 1 to 1 and the number of arcs from 1  for 1 nodes  to 1 for 1 nodes . cost vectors are integers randomly drawn within interval  1  1 . algorithms were implemented in c++. the computational experiments were carried out with a pentium iv cpu 1ghz pc.
모table 1 presents the average performance of algorithms for different classes of instances  characterized by #nodes  the number of nodes in the graph   and m  the number of scenarios . in each class  we give the average performance computed over 1 different instances. for every class  we give #ssd the average number of ssd-optimal distributions and tssd the average time  in seconds  to solve the ssd search problem with ssda . results given in table 1 show that the average number of ssd-optimal distributions increases slowly with the size of the graph; moreover ssda  computation times show a good efficiency  less than 1 seconds in worst cases . the two rightmost columns of table 1 concern the performance in determining rdw-optimal paths with w z  = z1 and. we give #gen  the aver-
m#nodes#nssdtnssd#gentrdw1.1.1.1.11.1.1.1.11.1.1.1.11.1.1.1.11.1.1.1.11.1.1.1.11.1.1.1.11.1.1.1.11.1.1.1.1table 1: performance of the algorithms
age number of paths generated before reaching the stopping condition of proposition 1  and trdw the average time of the search in seconds. values obtained for #gen show that path enumeration is stopped after a very reasonable number of iterations and computation times are about one second in worst cases. the gain in efficiency when compared to ssda  is due to the preliminary scalarization of the graph valuation which avoids numerous pareto-dominance tests during the exploration  but also to the fact that we only seek one rdw-optimal path among nssd paths. we have performed other experiments which are not reported here to save space: when   p  = p  ew model  or w z  = z  yaari's model   the performance is even slightly better. moreover  when convexity of w and concavity of   are increased to enhance riskaversion  e.g. with w z  = z1 and  the performance is not significantly degraded.
1 conclusion
we have provided efficient exact algorithms to determine low-risk/low-cost solution paths. algorithm ssda  proposed in section 1 provides a subset of paths convenient for a risk-averse agent  without requiring the definition of a disutility function. moreover  when a disutility criterion is known  more or less risky paths can be efficiently determined with the algorithm proposed in section 1. in the future  it should be worth investigating optimization based on risk-sensitive models in other dynamic decision making problems  e.g. decision trees or markov decision processes. in that direction  the main problem to deal with is the existence of dynamic inconsistencies induced by such nonlinear models. to face this difficulty  adapting the approaches proposed here to bypass the violation of bellman principle might be of interest.
