 
we present a new paradigm for minimax search algorithms: mt  a memory-enhanced version of pearl's test procedure. by changing the way mt is called  a number of practical best-first search algorithms can be simply constructed. reformulating sss* as an instance of mt eliminates all its perceived implementation drawbacks. most assessments of minimax search performance are based on simulations that do not address two key ingredients of high performance game-playing programs: iterative deepening and memory usage. instead  we use experimental data gathered from tournament checkers  othello and chess programs. the use of iterative deepening and memory makes our results differ significantly from the literature. one new instance of our framework  mtd /   out-performs our best alpha-beta searcher on leaf nodes  total nodes and execution time. to our knowledge  these are the first reported results that compare both depth-first and bestfirst algorithms given the same amount of memory. 
1 	introduction 
for over 1 years  alpha-beta has been the algorithm of choice for searching game trees. using a simple left-toright depth-first traversal  it is able to efficiently search trees  knuth and moore  1; pearl  1 . several important enhancements were added to the basic alphabeta framework  including iterative deepening  transposition tables  the history heuristic  and minimal search windows  schaeffer  1 . the resulting algorithm is so efficient that other promising fixed-depth algorithms were largely ignored. in particular  although best-first search strategies seemed promising both analytically and in simulations  they are not used in practice. 
　this paper presents a number of contributions to our understanding of depth-first and best-first minimax search: 
  mt  a memory enhanced version of pearl's test pro-cedure  is introduced. mt yields a binary-valued decision. we present a simple framework of mt drivers  mtd  that make repeated calls to mt to home in on the minimax value. surprisingly  mtd can be used to construct a variety of best-first search algorithms  such as sss*  stockman  1   using depth-first search. 
  sss*  and its dual dual*  marsland et a/.  1   has not been used in practice because of several perceived drawbacks  campbell and marsland  1; kaindl et al  1; marsland et a/.  1; roizen and pearl  1 . when expressed in the mtd framework  these problems disappear. furthermore  sss* becomes easy to implement and integrate into a conventional alpha-beta game-playing program. 
  simulations of minimax search algorithms in the literature are misleading because they make simplifying assumptions  such as assuming no dependencies between leaf values  or excluding iterative deepening and transposition tables . our approach was to gather experimental data from three real game-playing programs  chess  othello and checkers   covering the range from high to low branching factors. our results contradict published simulation results on the relative merit of a variety of minimax search algorithms  kaindl et a/.  1; marsland et a/.  1; reinefeld and ridinger  1 . 
  in previous work  depth-first and best-first mini-max search algorithms were compared using different amounts of memory. these are the first experiments that compare them using identical storage requirements. 
  with dynamic move reordering  sss* is no longer guaranteed to expand fewer leaf nodes than alphabeta  stockman's proof  stockman  1  does not hold in practice . in our experiments  sss* performs as fast as any of our alpha-beta implementations  but visits too many interior nodes to be practical. 
  a new instance of our framework  mtd /   out per-forms our best alpha-beta searcher on leaf nodes  total nodes and execution time. 
1 	memory-enhanced test 
pearl introduced the concept of a proof procedure for game trees in his scout algorithm  pearl  1   also 
	plaat  etal 	1 


1 	automated reasoning 

provides two benefits:  1  preventing unnecessary node re-expansion  and  1  facilitating best-first node selection  see sections 1 and 1 . both are necessary for the efficiency of the algorithm. 
one could ask the question whether a simple one-pass 
alpha-beta search with a wide search window would not be as efficient. various papers point out that a tighter alpha-beta window causes more cutoffs than a wider window  all other things being equal  for example  
 campbell and marsland  1; marsland et a/.  1; plaat et a/.  1c  . since mt does not re-expand nodes from a previous pass  it cannot have fewer cutoffs than wide-windowed alpha-beta for new nodes.  nodes expanded in a previous pass are not re-expanded but looked-up in memory.  this implies that any sequence of mt calls will be more efficient  it will never evaluate more leaf nodes and usually significantly less  than a call to alpha-beta with window  -oo  +oo   for non-iterative deepening searches. 
1 	four misconceptions concerning sss* 
mtd +oo  causes mt to expand the same leaf nodes in the same order as sss*  see  plaat et al.  1c  for a substantiation of this claim . the surprising result that a depth-first search procedure can be used to examine nodes in a best-first manner can be explained as follows. the value of g - e  where g = f+  causes mt to explore only nodes that can lower the upper bound at the root; this is the best-first expansion order of sss*. only children that can influence the value of a node are traversed: the highest-valued child of a max node  and the lowest of a min node. expanding brothers of these so-called critical children gives a best-first expansion. it is instructive to mentally execute the mtd +oo  algorithm of figure 1 on an example tree such as the one in  stockman  1   as is done in  plaat et a/.  1b . 
　an important issue concerning the efficiency of mtbased algorithms is memory usage. sss* can be regarded as manipulating one max solution tree in place. a max solution tree has only one successor at each min node and all successors at max nodes  while the converse is true for min solution trees  pijls and de bruin  1; stockman  1 . whenever the upper bound is lowered  a new  better  subtree has been expanded. mtd +oo  has to keep only this best max solution tree in memory. given a branching factor of w and a tree of depth d  the space complexity of a driver causing mt to construct and refine one max solution tree is therefore of the order 1 w d/1   and a driver manipulating one min solution tree is of order 1 w d/1   as required for dual* . a simple calculation and empirical evidence show this to be realistic storage requirements.  due to lack of space we refer to  plaat et a/.  1c  for an in-depth treatment of these issues.  
　a transposition table provides a flexible way of storing solution trees. while at any time entries from old  inferior  solution trees may be resident  they will be overwritten by newer entries when their space is needed. there is no need for a time-consuming sss* purge operation. as long as the table is big enough to store the min and/or max solution trees that are essential for the efficient operation of the algorithm  it provides for fast access and efficient storage. 
the literature cites four issues concerning sss* 
 kaindl et a/.  1; roizen and pearl  1 . the first is the complicated algorithm. comparing the code for alpha-beta  knuth and moore  1  and sss*  stockman  1   one cannot help getting the feeling of being overwhelmed by its complexity. looking at the code in figure 1 we think this is solved. the second is sss*'s exponential storage demands. a counter-argument is that alpha-beta in game-playing programs also has exponential storage needs to achieve good performance; the transposition table must be large enough to store the move ordering information of the previous iteration. in other words  both alpha-beta and sss* perform best with a minimum of storage of the order of the size of min/max solution tree s . the third is that sss* uses expensive operations on the sorted open list. in our mt reformulation  no such operations are used. there is no explicit open list  only an implicit search tree stored in a transposition table. the store and retrieve operations are just as fast for alpha-beta as for sss*. in summary  the arguments against sss* are eliminated using an mt representation. sss* is no longer an impractical algorithm  plaat et al.  1c . 
　the fourth issue in the literature is that sss* will provably never expand more leaf nodes than alpha-beta  stockman  1 . however  our experiments used iterative deepening and move reordering  which violates the implied preconditions of the proof. in expanding more nodes than sss* in a previous iteration  alpha-beta reorders more nodes. consequently  in a subsequent iteration sss* may have to consider a node for which it has no move ordering information whereas alpha-beta does. thus  alpha-beta's inefficiency in a previous iteration can actually benefit it later in the search. with iterative deepening  it is now possible for alpha-beta to expand fewer leaf nodes than sss*  a short example proving this can be found in  plaat et a/.  1c  . 
　mtd + oo  shows up poorly if all nodes visited in the search is used as the performance metric. mtd -l-oo  retraverses internal nodes to find the best node to expand next  whereas alpha-beta does not. 
　we conclude that our reformulation together with the results of section 1 contradict the literature on all four points. 
1 	drivers for mt 
having seen one driver for mt  the ideas can be encompassed in a generalized driver routine. the driver can be regarded as providing a series of calls to mt to successively refine bounds on the minimax value. by parameterizing the driver code  a variety of algorithms can be constructed. the parameter needed is the first starting bound for mt. using this parameter  an algorithm using our mt driver  mtd  can be expressed as mtd  first   see figure 1 .  in  plaat et a/.  1b  a more general version of mtd is presented  facilitating the construction of more algorithms.  a number of interesting algorithms can easily be constructed using mtd. some interesting mtd formulations include: 
	plaat etal 	1 

sss*. sss* can be described as mtd 
　dual*. in the dual version of sss* minimization is replaced by maximization  the open list is kept in reverse order  and the starting value is -oo. this algorithm becomes mtd i. the advantage of dual* over sss* lies in the search of odd-depth search trees  marsland et a/.  1 . 
　mtd / . rather than using  as a first bound  we can start at a value which might be closer to /. given that iterative deepening is used in many application domains  the obvious approximation for the minimax value is the result of the previous iteration. in mtd terms this algorithm becomes mtd heuristic-guess . if the initial guess is below the minimax value  mtd /  can be viewed as a version of dual* that started closer to /  otherwise it becomes a version of sss* that started closer to /. 
　other mtd variations possible are: bisecting the interval in each pass  using larger step sizes  and searching for the best move  not the best value   plaat et a/.  1b . 
　formulating a seemingly diverse collection of algorithms into one unifying framework focuses attention on the fundamental differences. for example  the framework allows the reader to see just how similar sss* and dual* really are  and that these are just special cases of calling pearl's test  or rather mt . the drivers concisely capture the algorithm differences. mtd offers us a high-level paradigm that facilitates the reasoning about important issues like algorithm efficiency and memory usage  without the need for low-level details. 
　by using mt  all mtd algorithms benefit from the maximum number of cutoffs a single bound can generate. each mtd makes a different choice for this bound  which influences the number of cutoffs. tests show that on average  there is a relationship between the starting bound and the size of the search trees generated: a sequence of mt searches to find the game value benefits from a start value close to the game value. starting bounds such as  are in a sense the worst possible choices. 
　figure 1 validates the choice of a starting bound close to the game value. the figure shows the percentage of unique leaf evaluations of mtd /   for othello; similar results were obtained using chess and checkers. the data points are given as a percentage of the size of the search tree built by our best alpha-beta searcher  aspiration negascout .  since iterative deepening algorithms are used  the cumulative leaf count over all previous depths 
1 	automated reasoning 

is shown for depth 1 and 1.  given an initial guess of h and the minimax value of /  the graph plots the search effort expended for different values of h - f. for each depth the first guess is distorted by the same amount. to the left of the graph  mtd /  is closer to dual*  to the right it is closer to sss*. a first guess close to / makes mtd /  perform better than the 1% aspiration negascout baseline. the guess must be close to / for the effect to become significant  between -1 and 
+ 1 of / for othello  given that values lie in the range 
. thus  if mtd /  is to be effective  the / obtained from the previous iteration must be a good indicator of the next iteration's value. 
1 	experiments 
there are three ways to evaluate a new algorithm: analysis  simulation or empirical testing. the emphasis in the literature has been on analysis and simulation. this is surprising given the large number of game-playing programs in existence. 
　the mathematical analyses of minimax search algorithms do a good job of increasing our understanding of the algorithms  but fail to give reliable predictions of their performance. the problem is that the game trees are analyzed using simplifying assumptions; the trees differ from those generated by real game-playing programs. to overcome this deficiency  a number of authors have conducted simulations  for example   kaindl et a/.  1; marsland et a/.  1; muszycka and shinghal  1  . in our opinion  the simulations did not capture the behavior of realistic search algorithms as they are used in game-playing programs. instead  we decided to conduct experiments in a setting that was to be as realistic as possible. our experiments attempt to address the concerns we have with the parameters chosen in many of the simulations: 
  high degree of ordering: most simulations have the quality of their move ordering below what is seen in real game-playing programs. 
  dynamic move re-ordering: simulations use fixed-depth searching. game-playing programs use iterative deepening to seed memory  transposition table  

with best moves to improve the move ordering. this adds overhead to the search  which is more than offset by the improved move ordering. also  transpositions and the history heuristic dynamically re-order the game tree during the search. proofs that sss* does not expand more leaf nodes than alpha-beta do not hold for the iterative deepened versions of these algorithms. 
  memory: simulations assume either no storage of previously computed results  or unfairly bias their experiments by not giving all the algorithms the same storage. for iterative deepening to be effective  best move information from previous iterations must be saved in memory. in game-playing programs a transposition table is used. simulations often use an inconsistent standard for counting leaf nodes. in conventional simulations  for example   marsland et a/.  1   each visit to a leaf node is counted for depth-first algorithms like negascout  whereas the leaf is counted only once for best-first algorithms like sss*  because it was stored in memory  no re-expansion occurs . 
  value dependence: some simulations generate the value of a child independent of the value of the parent. however  there is usually a high correlation between the values of these two nodes in real games. 
the net result is that iterative deepening and memory improve the move ordering beyond what has been used in most simulations. besides move ordering the other three differences between artificial and real trees can cause problems in simulations. just increasing the move ordering to 1% is not sufficient to yield realistic simulations. as well  simulations are concerned with tree size  but practitioners are concerned with execution time. simulation results do not necessarily correlate well with execution time. for example  there are many papers showing sss* expands fewer leaf nodes than alphabeta. however  sss* implementations using stockman's original formulation have too much execution overhead to be competitive with alpha-beta  roizen and pearl  
1   
1 	experiment design 
to assess the feasibility of the proposed algorithms  a series of experiments was performed to compare alpha-beta  negascout  sss*  mtd +oo    dual* 
 mtd -oo    mtd /   and other variants  see  plaat et al.  1b  . 
　rather than use simulations  our data has been gathered from three game-playing programs: chinook  checkers   keyano  othello   and phoenix  chess . all three programs are well-known in their respective domain. for our experiments  we used the program author's search algorithm which  presumably  has been highly tuned to the application. the only change we made was to disable search extensions and forward pruning. all programs used iterative deepening. the mtd algorithms would be repeatedly called with successively deeper search depths. all three programs used a standard transposition table with 1 entries. for our experiments we used the program author's original transposition table data structures and table manipulation code. 
　conventional test sets in the literature proved to be poor predictors of performance. test set positions are selected  usually  to test a particular characteristic or property of the game and are not indicative of typical game conditions. by using a sequences of moves from real games as the test positions  we are attempting to create a test set that is representative of real game search properties. 
　all three programs were run on 1 balanced test positions  searching to a depth so that all searched roughly the same amount of time.  a number of test runs was performed on a bigger test set and to a higher search depth to check that the 1 positions did not cause anomalies.  in checkers  the average branching factor is approximately 1  1 moves in a capture position; 1 in a non-capture position   in othello it is 1 and in chess it is 1. the branching factor determined the maximum search depth for our experiments: 1 ply for chinook  1 ply for keyano  and 1 ply for phoenix. 
　many papers in the literature use alpha-beta as the base line for comparing the performance of other algorithms  for example   campbell and marsland  1  . the implication is that this is the standard data point which everyone is trying to beat. however  game-playing programs have evolved beyond simple alpha-beta algorithms. therefore  we have chosen to use the current algorithm of choice as our base line: aspiration window enhanced negascout  campbell and marsland  1 . the graphs in figure 1 show the cumulative number of nodes over all previous iterations for a certain depth  which is realistic since iterative deepening is used   relative to aspiration negascout. 
　to our knowledge this is the first comparison of algorithms like alpha-beta  negascout  sss* and dual* where all algorithms are given the exact same resources. 
1 	experiment results 
figure 1 shows the performance of phoenix for  unique  leaf evaluations  nbp or number of bottom positions   and figure 1 shows the total node count  leaf  interior  and transposition nodes . the total node count includes all revisits to previously searched nodes. although most simulations only report nbp  we find that the total node count has a higher correlation with execution time for some algorithms. detailed results for all the games can be found in  plaat et a/.  1b . 
　over all three games  the best results are from mtd / . its leaf node counts are consistently better than aspiration negascout  averaging at least a 1% improvement. more surprisingly is that mtd /  outperforms aspiration negascout on the total node measure as well. since each iteration requires repeated calls to mt  at least two and possibly many more   one might expect mtd /  to perform badly by this measure because of the repeated traversals of the tree. this suggests that mtd /   on average  is calling mt close to the minimum number of times. for all three programs  mt gets called between 1 and 1 times on average. in contrast  the sss* and dual* results are poor compared 
	plaat  et al 	1 

to negascout when all nodes in the search tree are considered. each of these algorithms performs dozens and sometimes even hundreds of mt searches  depending on how wide the range of leaf values is. 
　implementing sss* as an instance of mtd yields results that run counter to the literature. sss* is now as easy to implement as aspiration negascout  uses as much storage and has no additional execution overhead  but performs generally worse when viewed in the context of iterative deepening and transposition tables. dual* is more efficient than sss* but still comes out poorly in all the graphs measuring total node count. sometimes sss* expands more leaf nodes than alpha-beta  as discussed in section 1   contradicting both the analytic and simulation results for fixed-depth sss* and alpha-beta. 
an interesting observation is that the effectiveness of 
sss* appears to be a function of the branching factor; the larger the branching factor  the better it performs. 
　given these results  some of the algorithmic differences can be explained. if we know the value of the search tree is /  then two searches are required: 
which fails high establishing a lower bound on /  and 
  which fails low and establishes an upper bound on /. the closer the approximation to /  the less the work that has to be done  according to figure 1 . as that figure indicated  the performance of mtd /  is 
1 	automated reasoning 
dependent on the quality of the score that is used as the first-guess. for programs with a pronounced odd/even oscillation in their score  results are better if not the score of the previous iterative deepening pass is used  but the one from 1 passes ago. considering this  it is not a surprise that both dual* and sss* come out poorly. their initial bounds for the minimax value are poor  meaning that the many calls to mt result in significantly more interior as well as leaf nodes. negascout used a wide window for the principal variation  pv  and all re-searches. the wide-window search of the pv gives a good first approximation to the minimax value. that approximation is then used to search the rest of the tree with minimal window searches-which are equivalent to mt calls. if these refutation searches are successful  no re-search is needed   then negascout deviates from mtd /  only in the way it searches the pv for a value  the wider window causing less cutoffs. mtd /  uses mt for searching all nodes  including the pv. 
　the bottom line for practitioners is execution time. since we did not have the resources to run all our experiments on identical and otherwise idle machines  we only show execution time graphs for mtd /  in figure 1. comparing results for the same machines we found that mtd /  is on average consistently the fastest algorithm. in our experiments we found that for chinook and keyano mtd /  was about 1% faster in execution time than aspiration negascout  for phoenix we found mtd /  1% faster. for other programs and other machines these results will obviously differ  depending in part on the quality of the score of the previous iteration  and on the test positions used. also  since the tested algorithms perform relatively close together  the relative differences are quite sensitive to variations in input parameters. in generalizing these results  one should keep this sensitivity in mind. using these numbers as absolute predictors for other situations would not do justice to the complexities of real-life game trees. we refer to  plaat et al.  1b  for the remainder of our experimental data and explanations. 
　basing one's conclusions only on simulations can be hazardous. for example  the general view is that sss* is  1  difficult to understand   1  has unreasonable memory requirements   1  is slow   1  provably dominates alpha-beta in expanded leaves  and  1  that it expands 

significantly fewer leaf nodes than alpha-beta. a recent paper used simulations to show that point 1 and 1 could be wrong  reinefeld and ridinger  1   painting an altogether favorable picture for sss*. using real programs  we showed that all five points are wrong  making it clear that  although sss* is practical  in realistic programs it has no substantial advantage over alphabeta-variants like aspiration negascout. we think that only real programs provide a valid basis for conclusions. 
1 	conclusions 
over thirty years of research have been devoted to improving the efficiency of alpha-beta searching. the mt family of algorithms are comparatively new  without the benefit of intense investigations. yet  mtd /  is already out-performing our best alpha-beta based implementations in real game-playing programs. mt is a simple and elegant paradigm for high performance game-tree search algorithms. it eliminates all the perceived drawbacks of sss* in practice. 
　the purpose of a simulation is to reliably model an algorithm to gain insight into its performance. simulations are usually performed when it is too difficult or too expensive to construct the proper experimental environment. for game-tree searching  the case for simulations is weak. there is no need to do simulations when there are quality game-playing programs available for obtaining actual data. further  as this paper has demonstrated  simulation parameters can be incorrect  resulting in large errors in the results that lead to misleading conclusions. in particular  the failure to include iterative deepening  transposition tables  and almost perfectly ordered trees in many simulations are serious omissions. 
　although a 1% improvement for chess may not seem much  it comes at no extra algorithmic complexity: just a standard alpha-beta-based chess program plus one while loop. binary-valued searches enhanced with it-
erative deepening  transposition tables and the history heuristic is an efficient search method that uses no explicit knowledge of the application domain. it is remarkable that one can search almost perfectly without explicitly using application-dependent knowledge other than the evaluation function. 
acknowledgements 
this work has benefited from discussions with mark 
brockington  author of keyano   yngvi bjornsson and andreas junghanns. the financial support of the dutch organization for scientific research  nwo   the natural 
sciences and engineering research council of canada  grant ogp-1  and the university of alberta central research fund are gratefully acknowledged. 
