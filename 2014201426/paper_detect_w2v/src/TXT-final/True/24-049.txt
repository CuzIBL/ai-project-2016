 
an environment for the experimentation with parsing strategies is presented which consists of a parser which can process arbitrary parsing strategies  a functional language for the definition of strategies  and a statistical component which helps the user assess the effects of the different strategies. 
1. introduction 
1. 	motivation 
the past decade has witnessed the emergence and widespread acceptance of declarative grammar formalisms  some wellknown exemplars being definite clause grammar  pereira and warren 1   generalized phrase structure grammar fgazdar et al. 1   and head-driven phrase structure grammar  pollard and sag 1   
　in contradistinction to their more procedural predecessors like transformational grammar  chomsky 1  and augmented transition networks  woods 1   today's declarative grammar formalisms do not prescribe an order in which the possible operations on the grammar are to be carried out1. 
　what both today's declarative grammars and the procedural grammars have in common is that they give all the sentences generated by the grammar equal status  and do not account for degrees of acceptability. 
　consequently  many current natural language systems have parsers that enumerate all analyses of a given string  but have no way of preferring one analysis of ambiguous sentences. the choice of a path in the search space is generally accidental  and it is not possible to formulate a parsing strategy explicitely. 
this work was supported by ibm germany's lilog project. 
　definite clause grammars are an exception only if they are interpreted by the standard prolog proof procedure. for alternative processing regimes see  pereira and shieber 1  
　this situation is not very satisfactory both from the psycholinguistic and from the engineering point of view. 
　from the psycholinguistic perspective  one property which needs to be modeled and explained is that humans in general consider only one reading of an ambiguous sentence. another property is the robustness of human sentence processing when presented with ill-formed input. 
　from the engineering perspective  it would rather be desirable to integrate syntactic preferences and semantic processing into the parsing process for early disambiguation in order to avoid the cost of exploring the complete search space  and the knowledge processing needed for selecting one reading of an ambiguous sentence. 
1. what is a parsing strategy 
a parsing strategy determines the behaviour the parser in case of non-determinsm  kay 1 . such non-determinism may arise by the choice of a rule to apply  and the choice of linguistic objects to which the rule is applied1. the application of a rule to linguistic objects is a parsing task. 
　in the literature  the term  parsing strategy  is used in three different senses: 
a  avoiding useless parsing tasks 
　a parsing strategy is a rule-selection strategy that avoids any structure building which does not contribute to the final parse result. such strategies would be top-down parsing  which makes sure that the only rules are chosen which may produce a parse with category s  bottom-up parsing which ensures that only rules are chosen which are licensed by the words in the input string  the directed parsing methods  kay 1  wir1n 1  which combine the merits of top-down and bottom-up parsing. head-driven parsing also falls into this category. 
　　1 this is the case for rule-based grammars. for principle-based grammars like government-binding theory  chomsky 1  or hpsg  pollard and sag 1   a parsing strategy might specify which principle to apply first and to which linguistic object. 
	erbach 	1 

b  best-fim parsing  heurjsticaiiy guided search  
a parsing strategy is a heuristically guided search strategy  
 kay 1 . with such a strategy  more promising parsing tasks are preferred over less promising ones. a best-first parsing strategy prefers one of several parsing tasks  but gives the results of the successful parsing tasks equal status. 
c  ambiguity resolution  and degrees of acceptability  
　a parsing strategy provides a preference for one analysis for ambiguous  sub strings. it may well be that this preference follows from the execution of a best-first strategy defined without reference to preferences for alternative analyses. on the other hand  a best-first parsing strategy may rely on these preferences for its choice of the best parsing task. we return to this issue in sections 1 and 1. 
　a parsing strategy is defined by a function which assigns a priority to each parsing task. while the output of the function is a numerical priority value  little is known about the input arguments to the function. 
　haugeneder and gehrke  propose a model where the user can assign different weights to eight factors  initial priority of the rule  initial priority for different readings of the lexemes  complexity of the structure  scoring of word hypotheses for spoken input  priority of an active edge  span of active edge  span of inactive edge  number of words left for processing . we are not that committed to the input of the heuristic function  and allow considerable more flexibility. in our view  finding appropriate input arguments to the function is one central objective of reasearch on parsing strategies. 
1. development of parsing strategies as an experimental process 
like  haugeneder and gehrke 1   we view the discovery of parsing strategies as a largely experimental process of incremental optimization. each cycle in the development 
consists of the following steps: 
a  definition  or modification  of a parsing strategy 
b  parsing of example sentences 
c  analysis of the parser's behaviour 
　the third step should not only indicate whether the desired behaviour has been achieved  but also help to locate sources of inefficiency. these three steps must be supported by the following features of the parser: 
a  a language for the definition of parsing strategies 
b  the ability to process different strategies 
c  statistics and diagnostic tools for evaluation of its 
behaviour with respect to a particular parsing strategy 
1. implementation of parsing strategies 
the system presented here allows the user to define parsing strategies for declarative grammars in a declarative fashion by writing an priority assignment function which gives a priority to a given parsing task. 
1. the parser1 
　the parser is a bottom-up1 active chart parser. the essential data structure of the parser is the agenda  kay 1   a list of pairs of parsing tasks and associated priorities. 
　the parser can process grammars encoded in the unification grammar formalism stuf  bouma et al. 1 . because unification of feature structures is computationally expensive  parsing tasks correspond to unifications  namely the unification of an item with a rule to produce an active item  or a passive item in the case of unary rules   or the combination of an active and a passive item: 
- apply 	r u l e  rule-name item  
- a and p active-itern passive-item  
　the parser can also be run without producing active items; in this case  a rule is applied to as many items as the righthand side of the rule has elements  corresponding to the parsing task apply rule  rule-name  item}  . . .  itemn . 
　since both rules and linguistic objects  chart items  are involved in a parsing task  the two kinds of non-determinism mentioned in section 1 arc present in the choice of a parsing task1: the choice of a rule  and the choice of linguistic objects to apply the rule to. 
the top level of the parsing algorithm is very simple: 
	while agenda not empty  	and not success do 
1. remove the task w i t h the highest p r i o r i t y from the agenda 
1. execute that 	parsing task 
1. generate new parsing tasks 
1 . assign each new parsing task a p r i o r i t y and add it to the agenda 
end while 
　a parsing strategy is defined by writing a priorityassignment function which is used in step 1 of the parsing algorithm. 
　without any particular priority assignment function  the above is an algorithm schema  kay 1   because the choice of a parsing task from the agenda is undetermined. 
1. specification 	of parsing 	strategies 
　　1the parser is implemented in quintus prolog and integrated in lilog's linguistic development environment leu/1. 
1
   it is a bottom-up parser because some of the grammars have no context-free skeleton to guide top-down analysis. 
1
   there is another kind of non-determinism not accounted for here. it arises when the linguistic objects which are manipulated contain disjunctions. from a theoretical point of view  all disjunctions can be brought into disjunctive normal form  and 

1 	natural language 

each of the disjuncts can be treated as a linguistic object. 
　 if there are several tasks with the same priority  the one that was most recently generated will be used. 

1.1. 	a 	functional 	language 	for 	the 
specification 	of parsing strategies 
we provide a restricted language  in which parsing strategies arc specified  containing the following primitive functions: 
rule   task  : the grammar rule of a parsing task i tem { n task1   : the n-th item of a parsing task is  item  : the feature structure of an item path  path fs  : value of a path in a feature structure coreferent pathl path1 fs : returns 1 if pathl and path1 in the feature structure fs are coreferent  1 otherwise r e s u l t i n g - i t e m   t a s k 1   : 
the resulting item of a parsing task 
j h s   rule  : the left-hand side of a rule r h s   rule  : the right-hand side of a rule  a list  i n i t i a l - p r i o r i t y   r u l e   : the initial priority of a rule 
start. i n q - vert ex  item  : 
the starting vertex of an item 
e n d i n g - v e r t e x  item  : the ending vertex of an item 
remainder  item  : a list of feature structures  if the item is active  the empty list if the item is passive 
daughters  item  : a list of daughters  or 'lex' if the item is lexical 
a c c e p t a b i l i t y   i t e m   : the acceptability assigned to an item 
 see section 1  
	cpu-1 i mo    : 	a constantly increasing value 
　in addition  the usual functions for the arithmetic operations and comparisons  list manipulation  first  rest  eons  length   and truth functions  and  or  if  if-then-else  not  equal  are provided. 
　the user can define more complex functions from these primitive functions. some examples are given below 
 variables are designated by upper-case letters : 
span item  	= 
　　ending-vertex item  	- 	starting-vertex item  category item  	p a t h     s y n 	cat  	fs ltem   
-1 
   'an item is a object consisting of starting vertex  ending vertex  feature structure  local tree  rule name and list of daughter items   remainder of an active item  acceptability rating  and a unique identifier with which the item is referred to in the list of daughters and in the parsing task. if the identifier is given as input to a function  the function is applied to the corresponding item. 
1 
　　for resulting items  only information about starting and ending vertex  and the local tree is available. 
complexity item  	-
	i f   	equal 	 daughters item  	lex 	  
  
	complex daughters  item   	+ 1 	  
complex itemllst  	= 
	i f   equal  	itemlist 	   	  
1 
	f 	  c o m p l e x i t y   f i r s t  itemlist    
complex rest itemlist     
   in particular  the function p r i o r i t y  strategy task  can be defined  which will then be used as the priority assignment function for the parsing strategy given as the first argument. 
　note that the function acceptability  item  introduces almost unlimited power because of the syntactic  semantic and pragmatic factors enter into the determination of the degree of acceptability of a linguistic object 
1.1. some 	examples 
some priority assignment functions are given in the following. these simple parsing strategies merely serve to illustrate the flexibility of the mechanism. 
　depth-first  depth : every new parsing task gets higher priority than the other parsing tasks still on the agenda  i. e. the agenda behaves as a stack. in practice  this can be done by using some constandy increasing value as the priority of the task. 
	p r i o r i t y   d e p t h 	task  	= 	cpu-time   
right-to-leftfrightleft . use the starting vertex of the 
resulting item as the priority of the parsing task. p r i o r i t y   r i g h t l e f t task  = s t a r t i n g - v e r t e x   r e s u l t i n q - i t e m   t a s k     
prefer long items over short ones  longitem ; use the span 
of the resulting item as the priority. p r i o r i t y   1 o n g i t e m task  = span resulting-item task   
prefer long rules  longmie  p r i o r i t y  longrule task  = length rhs rule task      combine active and passive items before applying rules  ap  
	p r i o r i t y   a p task  	= 	equal task a and p a p   
　the priority is 1 if the task is the combination of an active and a passive item  and 1 otherwise. 
　sort new to front  new-to-front ; this general strategy  haugeneder and gehrke 1  ensures that all new tasks are added to the front of the agenda  i. e. that they have higher priority than any other tasks already on the agenda. however  an order may be imposed upon the new tasks. in order to achieve this behaviour one ensures that the priorities for the 
	erbach 	1 

new tasks lie in the interval between the current and the next item number. since item numbers are incremented by 1  the priority must be in the interval  itemcount itemcount+1 . the heuristic function  which is defined using the primitive functions listed above  has a range between 1 and 1. 
p r i o r i t y   n e w - t o - f r o n t task  = itemcount    + heuri s t i c - f unction  task  
1. reduction of the search space 
in the parsing process  many parsing tasks are generated. 
whenever a new passive item p is added  the following parsing tasks are generated: 
- for every rule r a task apply rule  r p  and 
- for every active item a whose ending vertex is the starting vertex of pa task a  and p   a   p   . 
whenever an active item a is added: 
- for every passive item p whose starting vertex is the ending vertex of the a a task a and p   a  p  . 
　however  not all parsing tasks do succeed - in fact  most of them fail. but  assigning a priority to a parsing task which is going to fail anyway is a waste of effort. 
　we have implemented a computationally inexpensive filter which eliminates most of the useless parsing tasks. the filter uses only a subset of the information present in the feature structures of the rules  and encodes this as a prolog term. if the unification of the prolog terms involved in the parsing task fails  the parsing task cannot succeed. the parsing tasks which pass the filter are assigned a priority and added to the agenda. 
　the use of a filter resulted in a reduction of the total parse time of 1 to 1 percent. 
1. statistical 	information 
we assume that the definition of parsing strategies is an experimental process of incremental optimization. in order to obtain information about the behavior of a parsing strategy  the following statistics are collected during the parsing process. 
a1: 	cpu-time until first result is found 
a1: 	cpu-time after complete exploration of the search space 
b: 	number of possible parsing tasks  i. e. the total search space  
c: number of parsing tasks on the agenda  i. e. the reduced search space  
d l : number of successful parsing tasks  i. e. number of chart items  after finding the first parse 
d1: number of successful parsing tasks  i. e. number of chart items  after complete exploration of the search space 
el: number of parsing tasks which contribute to the first result  i. e. number of nodes in the result tree s  including active items  
1 	natural language 
e1: number of parsing tasks which contribte to all results  i. c. number of distinct nodes in all result trees including active items  e1: number of parsing tasks which contribute to the correct reading  i. e. number of nodes in the chosen result tree . there must be feedback from further processing steps about which reading for an ambiguous sentence was the correct one. 　the values obtained by counting parsing tasks  b  c  d and e  are also available for each rule of the grammar. b  c  d1 and e1  which involve exhaustive search  are independent of a particular parsing strategy. they exhibit global properties of the grammar  and are useful in the determination of parsing strategies. 
　these figures are available after one parse  and may also be summed up over a number of parses. the ratio between these figures which is the basis for the development of parsing strategies. 
　time efficiency: the ratio a1/a1  cpu-time after first parse / cpu-time after exhaustive search  indicates the time efficiency of the chosen parsing strategy. a value of 1 would indicate that finding the first parse with that parsing strategy takes 1% of the time which is needed for finding all parses. a value that is greater than 1 indicates that the time needed for assigning priorities to parsing tasks is greater than the time saved by using the parsing strategy. 
　successful possible tasks: the ratio d1/b indicates which proportion of all parsing tasks is successful. 
　successful tasks on agenda: the ratio d1/c indicates which proportion of the parsing tasks on the agenda are ultimately successful. ideally  this ratio should be equal to 1. if this value is very low for a particular rule  means that it is a rule which passes the filter  cf. section 1   but is frequently unsuccessful. in this case  the filter should be improved. if this is not possible with reasonable effort  the rule should be assigned low priority. 
　space efficiency  for a strategy : the ratio d1/d1  chart items after first parse / chart items after exhaustive search  gives an indication of how much space for storing chart items is saved by the parsing strategy. this can be an very important issue if large structures are built for each item  as is the case with feature-value grammars. 
useless items  for a strategy ; the ratio e1/dl  used items 
/ built items  indicates how many of the successful tasks are used in the first final result with a particular parsing strategy. ideally  the value should be equal to 1. 
useless items  with exhaustive searctri:the ratio e1/d1 
 used items / built items after exhaustive search  indicates which proportion of successful tasks are used in any of the final results. if available  the ratio e1/d1 should be used. if this value is low for some rule  the rule is frequently successful  but rarely contributes to the final parse result s . 
　such rules are particularly disastrous  because their successful execution creates new items  which in turn lead to 

the generation of new parsing tasks. such rules should be assigned low priority. an example is the apposition rule  which combines any two adjacent nps  as in the following examples: 
noam chomsky  the well-known linguist  ... our teacher  a notorious drug addict  
1. towards a self-optimizing parser 
the results of the above statistics can be used to find a reasonable parsing strategy automatically. in this case  the priority assignment function would take as its only input the rule involved in the parsing task. 
a promising parsing strategy would delay rules that 
- arc frequently successful  but rarely contribute to the final result  ratio e1/d1 or e1/d1   or 
- are not filtered out  but frequently fail  ratio d1/c . 
　where c  d1 and e1 are the statistical figures for a 
　particular rule summed over a representative number of parses. 
1. criteria for priority assignment 
1 . 1 . 	surface 	properties 
our experiments have shown that parsing strategies based on surface properties of chart items  such as length  starting position  syntactic category do not have any significant advantages over depth-first search. 
　strategies based on the statistics described in section 1 were more successful  and reduced the time for finding the first parse of a sentence by about 1 percent. our experiments only adressed the issue of finding one parse result quickly  which is appropriate for unambiguous strings   but did not at all address the issue of finding the preferred reading first. 
1. 	degrees 	of acceptability 
psycholinguistic research strongly suggests that some analyses of an ambiguous sentence are more acceptable than others. while it is not clear how degrees of acceptability are determined  it is quite obvious how they can be used in the definition of parsing strategies: the priority of a parsing task should be high if the items involved in it have a high degree of acceptability. 
　in addition  rules should be given an initial priority  which may be determined by the function given in section 1. the same is true for different readings of lexical items  which can be given an initial probability. 
the priority of a parsing task is then a function of 
- the degree of acceptability of the constituents involved  or the initial probability of readings of lexical items  
- the initial priority of the rule involved 
　one possible such function for a task involving n items would be: 


　it would be mathematically more tempting to view the acceptability values for items and initial priorities for rules as probabilities  because the theory of probability is well understood. the priority assignment function could then be defined by multiplying all the probabilities: 
two objections may be raised against such an approach. 
first  multiplication will always make the probability of a new node equal to or less then the probabilities of its daughters. for this reason  the probability decreases as trees get larger. this effect must somehow be compensated. the second objection against probabiltics is that serious calculation with probabilities requires reliable statistical data  which may not be available. 
　in the following we discuss some factors which play a role in determining the acceptability of a constituent 
1.1. 	lp-rules 
in german  violation of a linear precedence rule does not make a string completely unaccaptable  but reduces its adaptability  uszkorcit 1 . each lp-rule may have a different weight  and violation of the lp-rule will decrease the acceptability of the constituent in which the rule is violated according to its weight. 
1.1. attachment 	preferences 
attachment preferences have been extensively studied in psycholinguistics  e. g.  fodor and frazier 1  . one main principle is right association  which means that a modifier is  attached into the phrase marker as a right sister to existing constituents and as low in the tree as possible . 
　this strategy can be modelled by a strategy  which prefers parsing tasks in which the modifier is the rightmost constituent  and which have a short span. semantic factors can override syntactic attachment p