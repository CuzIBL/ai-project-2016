 
for many applications  it is important that agents be not only correct  but also comprehensible to human users. typically  people have tried to make agents' behavior and reasoning understandable by adding post-hoc specialpurpose explanation systems  with often disappointing results. here  i instead take the comprehensibility of agent behavior as a central agent design consideration from the start. i describe an agent architecture  the expressivator  that supports comprehensibility on top of a behavior-based framework  using four technical innovations:  1  structuring the agent's behavior according to the signs and signifiers it is intended to communicate;  1  allowing the agent to keep track of its impression on the user with sign management   1  using behavioral transitions to explain the reasons for agent  behavior  and  1  expressing behavioral interrelationships directly using meta-level controls. 
1 	introduction 
no matter how powerful an ai system is  it may be useless if its actions and reasoning are incomprehensible to users. expert systems that suggest investing one's life savings in an obscure caribbean manufacturer or treating a patient with a little-used drug with potent sideeffects without making clear why will quickly be shelved in favor of old-fashioned  questionable human experts. tutoring systems will fail if students cannot figure out what the agent demonstrating the proper solution is doing or why. humans will have difficulty guiding teleautonomous robots whose behavior and reasoning is only understandable after time-consuming analysis of activity logs. believable agents are pointless if their personality  behavior  and thinking are unclear. 
　in all these cases  the usability and usefulness of the ai system depends heavily on its behavior being easy to understand by human users. but most techniques available for building such systems focus on problem-solving  with understandability as an afterthought. as a result  previous approaches to this problem have generally focused on taking already-built but inadequately understandable systems and adding explanation systems to make them more comprehensible  johnson  1   diederich and tickle  1 . in essence  with these approaches the system's behavior and reasoning remain as ineffable as always  but a special-purpose system is added to reconstruct and translate it for human users often with disappointing results. 
　in this paper  i instead explore the possibility of designing agents to be comprehensible from the start that is  agents can be structured so that their behavior and reasoning is comprehensible all along  eliminating the need for a special-purpose explanation system to improve the agent's comprehensibility after the fact. in order to do this  i first lay out the requirements for comprehensibility from a psychological perspective. i then describe an implemented agent architecture  the expressivator  which provides support for comprehensible behavior on top of a behavior-based framework. the expressivator works by designing agents in terms of communicated signs rather than internal problem-solving behaviors  and by using behavioral transitions to explain the connection between the agent's activities to users. 
1 	prerequisites for comprehensibility 
the groundwork for comprehensible systems has been laid out by believable agents research. because comprehensibility is so essential to believable agents  ba systems have often included user understandability as one central agent design consideration  loyall  1   neal reilly  1   blumberg  1   lester and stone  1   but one that is usually applied in an ad hoc manner. the expressivator is instead built on a systematic analysis of the requirements for comprehensibility from a psychological point of view. 
　basically  an agent is comprehensible if  based on the agents' observable actions  users can build an accurate interpretation of the agent's beliefs  reasoning  knowledge  and so on. this means that an agent will be particularly understandable if it gives off the kinds of behavioral cues from which people find it easy to construct meaning. in order to know what kind of cues these are  we need to understand how people go about interpreting 
sengers 	1 
agents. we can then tailor our agents to give the kind of behavioral cues that are easy for people to understand. 
　the way in which people go about interpreting the behavior of complex  autonomous systems is the subject of the field of narrative psychology  bruner  1 . narrative psychology argues that people construct meaning from observed actions by organizing them into narrative  or stories. narrative theory has uncovered numer-
ous properties of this kind of organization  bruner  1   including centrally the following two: 
  people try to discover not only what the agent does  but also why. the reasons or motivations behind actions are just as important as what is done. 
  events are not seen in isolation. users try to inter-pret events as they relate to each other. 
　narrative psychologists argue that people comprehend intentional activity by trying to interrelate observed actions and to find out the reasons for the agent's behavioral choices. if this is so  then an agent  to be maximally understandable  must have the following properties: 
  the agent must clearly express what it is doing. these individual actions must be clear to the user  since they form the building blocks for any future interpretation. 
  the agent must clearly express why it is doing what it does. 
  the relationships between the agents' activities must be made clear. the agent cannot simply jump between different activities  but should suggest to the user how the activities fit together into a logical whole. 
　in addition  for maximum comprehensibility  behavior cannot be arbitrarily complex. behavior in which an agent can take account of many perhaps barely noticeable environmental conditions and do complex reasoning instantaneously simply cannot be communicated adequately. at the same time  since users can infer a great deal about the agent's motivations and personality from simple actions  simple  well-chosen behaviors can be enough. 
　the properties which comprehensible agents must have lead to the following heuristic for comprehensible agent construction: 
behaviors should be as simple as possible. the agent's comprehensibility comes from thinking out the connections between behaviors and displaying them to the user. 
1 	building comprehensible agents 
this heuristic forms the basis of the expressivator  an agent architecture that focuses on the expression of agent actions and their interrelationships to users. the expressivator is built on top of hap  loyall and bates  1   a behavior-based language designed for believable agents. the expressivator provides systematic support for narrative comprehensibility through the following mechanisms: 
1 	software agents 
  expressing what the agent does: the agent's design is based not on internally-defined behaviors  but on signs and signifiers which are directly communicated to the user. the agent uses a signmanagement system to keep track of the signs and 
signifiers that have been communicated. 
  expressing why the agent does it: behavioral transitions communicate the reasons for agent activity. 
  expressing the relationships between activities: transitions use meta-level controls to know about and influence other behaviors  so that their relationships are expressly communicated to the user. 
each of these mechanisms is described in more detail below. examples come from the expressivator's use in the industrial graveyard. in this virtual environment the 
patient  a discarded lamp character implemented with the expressivator  attempts to eke out a miserable existence while being bullied about by the overseer  an agent implemented in hap. 
1 	signs  signifiers  and sign management 
the first prerequisite for behavior comprehensibility is that the user should be able to clearly tell what the agent is doing. clear communication of the basic actions and behaviors of the agent is essential if the user is to comprehend the agent's activity. signs and signifiers support the construction of clearly communicated behavior; sign management allows the agent itself to keep track of what has been communicated  so it can tailor subsequent behavioral communication to the user's current interpretation. 
signs and signifiers 
current behavior-based approaches are based on an internal  problem-solving approach  and generally divide an agent into activities in which the agent likes to or needs to engage. typical behavior-based systems divide an agent into three parts:  1  physical actions in which the agent engages   1  low-level behaviors  which are the agent's simple activities  and  1  high-level behaviors  which combine low-level behaviors into high-level activities using more complex reasoning. because these activities are implemented according to what makes sense from the agent's internal point of view  there is no necessary correlation between the agent's behaviors and the behaviors we would like the user to see in our agent. 
　but for comprehensible agent design  it may make more sense to design the agent according to the things we would like to communicate to the user  i.e. making the internal behaviors exactly those behaviors we want to communicate to the user. then  communicating what the agent does reduces to the problem of making sure that each of these behaviors is properly communicated. for this reason  the expressivator structures an agent not into physical actions and problem-solving behaviors  but into signs and signifiers  or units of action 

that are likely to be meaningful to the user. this structure involves three levels  roughly corresponding to those of generic behavior-based a i :  1  signs  which are small sets of physical actions that are likely to be interpreted in a particular way by the user;  1  low-level signijiers  which combine signs  physical actions  and mental actions to communicate particular immediate physical activities to the user; and  1  high-level signifiers  which combine low-level signifiers to communicate the agent's high-level activities. 
　there are several differences between these structural units and the default behavior-based ones. unlike physical actions and behaviors  signs and signifiers focus on what the user is likely to interpret  rather than what the agent is 'actually'  i.e. internally  doing. in addition  signs and signifiers are context-dependent; the same physical movements may lead to different signs or signifiers  depending on the context in which the actions are interpreted. most importantly  signs and signifiers carry an explicit commitment to communication; they require the agent designer to think about how the agent should be interpreted and to provide visual cues to support that interpretation. 
　signs and signifiers are not simply design constructs; they also have technical manifestations. formally  a sign is a token the system produces after having engaged in physical behavior that is likely to be interpreted in a particular way. this token consists of an arbitrary label and an optional set of arguments. the label  such as  noticed possible insult   is meaningful to the designer  and represents how the designer expects that physical behavior to be interpreted. the arguments  such as  would-be insulter is wilma   give more information about the sign. this token is stored by the sign-management system described below  so that the agent can use it to influence its subsequent behavioral decisions. a low-level signifier is a behavior that is annotated with the special form  with lowjeveljsignifying... ; a high-level signifier is similarly annotated   w i t h highjevel signifying.... . signifiers can also generate tokens for the sign-management system  as described below. 
sign management 
once a designer has structured an agent according to what it needs to communicate  agents can reason about what has been communicated in order to fine-tune presentation of subsequent signs and signifiers. that is  by noting which signifiers have been communicated  agents can reason about the user's likely current interpretation of their actions and use this as a basis for deciding how to communicate subsequent activity. 
　the most obvious way for the agent to keep track of what the user thinks is for it simply to notice which signs and signifiers are currently running. after all  signifiers represent what is being communicated to the user. but it turns out in practice that this is not correct because the user's interpretation of signs and signifiers lags behind the agent's engagement in them. for example  if the agent is currently running a  head-banging  signifier  the user will need to see the agent smack its head a few times before realizing that the agent is doing it. 
　the sign-management system deals with this problem by having the agent post signs and signifiers when it believes the user must have seen them. a behavior can post a sign each time it has engaged in some physical actions that express that sign  using the post -sign language mechanism. similarly  once signs have been posted that express a low-level signifier  behaviors use post jowjevel to post that that low-level signifier has been successfully expressed. once the right low-level signifiers have been posted to express a high-level signifier  post-high jevel is used to post that high-level signifier. each of these commands causes a token to be stored in the agent's memory listing the current sign  low-level signifier  or high-level signifier  respectively  along with a time stamp. once signs and signifiers have been posted  other behaviors can check to see what has been posted recently before they decide what to do. the result is that the signs and signifiers the agent has expressed can be used just like environmental stimuli and internal drives to affect subsequent behavioral presentation  tuning the agent's behavior to the user's interpretation. 
1 	transitions 
the second requirement of behavior comprehensibility is that the user should be able to tell why the agent is doing what it is doing. in behavior-based terms  every time an agent selects a particular behavior  it should express to the user the reason it is changing from the old behavior to the new one. this is difficult to do in most behaviorbased systems because behaviors are designed and run independently; when a behavior is chosen  it has no idea who it succeeds  let alone why. 
　in the expressivator  behavioral transitions are used to express the agent's reasoning. transitions are special behaviors which act to 'glue' two signifying behaviors together. when a transition notices that it is time to switch between two signifiers  it takes over from the old signifier. instead of switching abruptly to the new signifier  it takes a moment to express to the user the reason for the behavioral change. 
　transitions are implemented in two parts  each of which is a full-fledged behavior:  1  transition triggers  that determine when it is appropriate to switch to another behavior for a particular reason  and  1  transition demons  that implement the transition sequence that ex-
presses that reason to the user. transition triggers run in the background  generally checking which behaviors are running  e.g. exploring the world   and combining this information with sensory input about current conditions  e.g. the overseer is approaching . when its conditions are fulfilled  the transition trigger adds a special token to memory  rioting the behavior which should terminate  the behavior which should replace it  and a label which represents the reason for the replacement  e.g. afraid  of overseer . 
　transition demons monitor memory  waiting for a transition for a particular reason to be triggered. they 
	sengers 	1 

then choose an appropriate behavioral expression for the reason for change  according to the current likely user interpretation and conditions in the virtual environment. expressing the reasoning behind behavioral change often requires changes to subsequent behaviors; for example  if the patient starts doing some odious task because it is forced to by the overseer  it should include some annoyed glances at the overseer as part of the task-fulfilling behavior. transitions are able to express these kinds of interbehavioral influences using the meta-level controls described below. 
1 	meta-level controls 
the third requirement of narrative comprehensibility is that the relationships between the agent's activities are made clear. instead of jumping around between apparently independent actions  the agent's activities should express some common threads. but these relationships are difficult to express in most behavior-based systems because they treat individual behaviors as distinct entities which do not have access to each other. conflicts and influences between behaviors are not handled by behaviors themselves but by underlying mechanisms within the architecture. because the mechanisms that handle relationships between behaviors are part of the implicit architecture of the agent  they are not directly expressible to the user. 
　the expressivator deals with this problem by giving behaviors meta-level controls  special powers to sense and influence each other. because meta-level controls are explicitly intended for communication and coordination between behaviors  they are in some sense a violation of the behavior-based principle of minimal behavioral interaction. nevertheless  meta-level controls are so useful for coordinating behavior that several have already found a home in behavior-based architectures. an example is hamsterdam's meta-level commands  which allow nonactive behaviors to suggest actions for the currently dominant behavior to do on the side  blumberg  1 . in the expressivator  behaviors can  1  query which other behaviors have recently happened or are currently active;  1  delete other behaviors;  1  add new behaviors  not as subbehaviors  but at the top level of the agent;  1  add new sub-behaviors to other behaviors;  1  change the internal variables that affect the way in which other behaviors are processed;  1  turn off a behavior's ability to send motor commands  and  1  move running subbehaviors from one behavior to another. 
　the most important function for these meta-level controls in the expressivator is to allow for the implementation of transitions. transitions  at a minimum  need to be able to find out when an old behavior needs to be terminated  delete the old behavior  engage in some action  and then start a new behavior. this means that transition behaviors need to have all the abilities of a regular behavior  and a few more:  1  they need to be able to know what other behaviors are running;  1  they need to be able to delete an old behavior; and  1  they need to be able to begin a new behavior. ideally  they 
1 	software agents 
should also be able to alter the new behavior's processing to reflect how it relates to what the agent was doing before. in the expressivator  transitions can do all these things with meta-level controls. 
　more generally  meta-level controls make the relationships between behaviors explicit  as much a part of the agent design as behaviors themselves. they allow behaviors to affect one another directly when necessary  rather than making interbehavioral effects subtle side-effects of the agent design. meta-level controls give agent builders more power to expose the inner workings of agents by letting them access and then express aspects of behavior processing that other systems leave implicit. 
1 	putting it all together 
narrative psychology suggests that comprehensibility requires agents to clearly express what they do  why they do it  and the interrelationships between their activities. the expressivator supports comprehensibility by expressing the agent's actions through signs and signifiers  the reasons for agent activity through transitions  and the interrelationships between activities through metalevel controls. 
　these architectural mechanisms are described separately  but used together in the agent design process  changing the way in which agents are designed. in a typical behavior-based system  an agent is defined in 1 
　major steps:  1  deciding on the high-level behaviors in which the agent will engage;  1  implementing each highlevel behavior  generally in terms of a number of low-level behaviors and some miscellaneous behavior to knit them together;  1  using environmental triggers  conflicts  and other design strategies to know when each behavior is appropriate for the creature to engage in. with the expressivator  the choice and expression of these structural 'units' for the agent is not enough; in order to support the user's comprehension  the designer must also give careful consideration to expressing the reasons for and interrelationships between those units. these interrelationships are designed and implemented with transitions  which alter the signifiers they connect in order to make them clearer. in practice  transitions are the keystone of the architecture  combining signifiers in meaningful ways through the use of meta-level controls. 
1 	results 
the best way to see how the expressivator changes the quality of agent behavior is to look at how its transitions work in detail. here  i will go over one point where the agent switches behaviors  and explain how transitions make this switch more comprehensible. one example does not proof make  but it does take up a lot of space; the sceptical reader can find more in  sengers  1 . 
　as our excerpt begins  the patient notices the schedule of daily activities which is posted on the fence. it goes over to read the schedule. the overseer  noticing that the patient is at the schedule and that the user is watching the patient  goes over to the schedule  changes 


figure 1: response without transitions 
the time to 1  and forces the patient to engage in the activity for that hour: exercising. 
　the goal of this part of the plot is to communicate to the user the daily regime into which the patient is strapped. the patient does not have autonomy over its actions; it can be forced by the overseer to engage in activities completely independently of its desires. the specific behavioral change from reading the schedule to exercising  then  should show the user that the agent changes its activity because  1  it notices the overseer   1  the overseer enforces the scheduled activities;  1  the activity that is currently scheduled is exercising. 
without transitions  the patient's response to the 
overseer is basically stimulus-response  figure 1 . the 
patient starts out reading the schedule. as soon as the patient senses the overseer  it immediately starts exercising. this reaction is both correct and instantaneous; the patient is doing an excellent job of problem-solving and rapidly selecting optimal behavior. but this behavioral sequence is also perplexing; the chain of logic that connects the overseer's presence and the various environmental props to the patient's actions is not displayed to the user  being jumped over in the instantaneous change from one behavior to another. 
　with transitions  attempts are made to make the logic behind the behavioral change clearer  figure 1 . again  the behavior starts with the patient reading the schedule. this time  when the overseer approaches  the patient just glances at the overseer and returns to reading. since the patient normally has a strongly fearful reaction to the overseer  and by this time the overseer's enthusiasm for punishing the patient has already generally aroused sympathy in the user's mind   the user has a good chance of understanding that this simple glance without further reaction means that the patient has not really processed that the overseer is standing behind it. suddenly  the patient becomes startled and quickly looks back at the overseer again. now  the user can get the impression that the patient has registered the overseer's presence. wrhatever happens next must be a reaction to that presence. next  the patient checks the 

figure 1: response with transitions 
time and the schedule of activities to determine that it is time to exercise. then the patient whirls to face the overseer and frantically and energetically begins exercising  tapering off in enthusiasm as the overseer departs. this transition clearly communicates that the change in behavior is connected to several factors: the presence of the overseer  the clock  and the schedule. this is in contrast with the transition-less sequence  in which there is no clear connection between any of the environmental factors and the patient 's behavioral change. 
1 	evaluation 
how good is the expressivator  the kind of detailed transition analysis given here suggests that  with the expressivator  the user is given more information on which to judge both the agent's behavior and the reasons for the agent's behavioral changes. this is certainly a basis for improved user understanding  but does not necessarily imply actual improvement. in particular  the quality of the animation is not up to snuff  which means users sometimes have trouble interpreting the simple movements of the agent. all the innovations the expressivator introduces are wort hless if individual signs are not clearly animated; everything rests on the substantial animation problem of getting a sigh to look like a sigh and not like a cough or a snort. this problem is exacerbated when  
	sengers 	1 

as in hap  there is a mind-body split  with the mind generating actions that are implemented autonomously by the body. the resulting divide between command and execution makes accurate timing and therefore effective control of animation impossible. this problem of generating expressive animation  while not a straightforward   a i problem   must be addressed by any architecture that is going to implement graphically presented  comprehensible agents. 
　certainly  the difficulty of communicating agents' thinking could be lessened by allowing them to talk. then  the framework designed here could be applied simply by using natural language to express what the agent is doing and why. at the same time  constant explanatory commentary   now i am going to hide because the overseer is coming and i am afraid!   seems unnatural and distracting  leaving a role for physical action to back up and expand on the agent's utterances. 
　the industrial graveyard is an entertainment application  but the constructs of the expressivator are not limited to believable agents. the concept of a narrative structure for behavior can be just as important for teleautonomous robots  semi-autonomous avatars  or pedagogical agents. however  the expressivator's focus on behavior and concrete action probably does not adequately support systems like automatic theorem provers that engage in complex  abstract reasoning. 
　the greatest conceptual problem with the expressivator is the potential explosion of the number of transitions needed between signifiers; but this turned out not to be a problem in practice. for the patient's 1 high-level signifiers there were only 1 transitions  and for the patient's 1 low-level signifiers  there were only 1 transitions. this is for several reasons. first of all  transitions are only needed between high-level signifiers  and between low-level signifiers that share the same high-level signifier - not between low-level signifiers in different high-level signifiers.1 i also cut out many transitions by writing several generic transitions  that could go from any behavior to a particular behavior. most importantly  i found in practice that many of the possible transitions did not make practical sense because of the semantics of the behaviors involved. 
　the greatest advantage of the expressivator for the behavior programmer is that it makes it much easier to handle interbehavioral effects. the coordination of multiple high-level behaviors is one of the major stumbling blocks of behavior-based architectures  brooks  1 ; since interbehavioral factors are implicit in the architecture they are hard to control  leading to multiple behaviors battling it out over the agent's body  and hours of tweaking to get each behavior to happen when and only when it is supposed to. this is much easier to handle when behaviors can simply kill other behaviors that are not appropriate  and when the trigger conditions for each behavior can be explicitly set. 

   this would be implemented instead with a transition between the respective high-level signifiers. 
1 	software agents 
1 	conclusion 
for many applications  agents will be much more usefill if their behavior and reasoning are understandable to human users. the work done here is based on the idea that agents will be more comprehensible if they are tailored to support human  narrative interpretation from the start. this interpretation requires that agents should show what they are doing  why they are doing it  and the interrelationships between their activities. in practice  this means making behaviors maximally simple and expressive  and explicitly showing the connections between them. the expressivator supports this style of agent construction by using transitions to relate signifying behaviors  expressing their interrelationships through meta-level controls. 
