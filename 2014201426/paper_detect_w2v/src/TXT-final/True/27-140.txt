 
crucial to the transformation of computers into intelligent multimedia systems is the ability to access  manipulate and manage visual information. in particular  video data is becoming a prevalent source of such information. our multiple perspective interactive video  mpivideo   project integrates a variety of visual computing operations with modeling and interaction techniques  to extract  synthesize and manage dynamic representations of scenes observed from multiple perspectives. automatic and semi-automatic analysis of video data from multiple cameras is performed. this analysis is used to build a three-dimensional model of the environment monitored by the cameras. mpi- video has applications in a variety of areas including the development of immersive video for telepresence systems  traffic monitoring and control and the analysis of physical performances  e.g. sports and dance. this video presents an overview of mpi- video along with demonstrations of two mpi-video prototypes developed in the visual computing lab. further details on mpi- video are described by jain and wakimoto in  jain and wakimoto  1  and in our technical report  kelly et a/.  1  
first  we present an mpi-video system which automatically identifies and tracks objects moving in an environment recorded by four cameras. each camera  sees  the environment from a different perspective. moving object data is extracted from each camera image using image differencing techniques. this information is integrated by a centralized modeling and assimilation module to construct a three-dimensional model of object behavior and events in the environment. an interface is provided allowing users to interact with the threedimensional model and the video data. the interface presents both the raw video data  annotated to indicate moving objects in the scene  along with the three dimensional model. users can view the environment from a variety of perspectives which are not limited to the real camera views. 
using a cursor  viewers can select objects and areas in the scene. a marker indicating the selection as seen from each camera perspective  is placed in each camera window. this demonstration also introduces the notion of a  best view.  that is  a particular camera view for which some criteria  either specified by the system or a user  is optimal. for instance  the  best view  might be the vista in which a particular object of interest is largest. here  the  best view  is that for which the distance along the line of sight from camera to selected position is minimum. when a location in the model is selected the system determines the line of sight distance and chooses that view  from the four available  for which this distance is shortest. 
to perform the video analysis and modeling  our mpi-video system uses information about the  static  world. camera calibration maps related locations in the two-dimensional video to a fully three-dimensional representation of the world recorded by the cameras. the video demonstrates software developed to assist in this calibration. details on this mpi-video prototype can be found in our technical report  kelly et al.  1 . 
the use of mpi-video to support an immersive video application is also shown. in immersive video visual information from multiple live video images of a real-world event is obtained and integrated to provide a photo-realistic rendition of the dynamic environment  thus supporting a sense of total immersion in the environment. using the actual camera data  a view from a location anywhere in the environ-
	katkere etal 	1 

ment can be constructed. these views are created by mosaicing pixels from the video data. several such  virtual  views are shown and an animated walk through1 of the courtyard environment illustrates a sequence of such views. immersive video is described in greater detail in our technical report  moezzi et ai  1 . 
the second portion of the video highlights an early mpi- video prototype  named fumble. in this prototype  we analyze football data from three cameras covering a superbowl. the system tracks different players on the field. while our mpi-video system described above  provides fully automatic detection and tracking  this second system relies on manual analysis of the video data. here  objects in the video data were identified and this information stored in a database. this knowledge is used to track players in the video sequences and to support user queries of the data. an interface allows users to query about players in the system and a threedimensional cursor is used to select and locate players in the video data. for instance  a user can place the cursor on a particular player in the video frame and ask  who is this   the system will then identify the player. alternately  a specific player can be chosen from a list and the system will indicate  using the three-dimensional cursor  where the player is in the frame. as in the previous system  fumble also provides a  best view . in this case  the frame which keeps a selected player of interest most central to the frame. a  best view  sequence illustrates this capability of the fumble prototype. jain and wakimoto  jain and wakimoto  1  present more information on the fumble prototype. 
