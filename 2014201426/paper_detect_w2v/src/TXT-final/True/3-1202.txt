
reasoning with time1 needs more than just a list of temporal expressions. timeml-an emerging standard for temporal annotation as a language capturing properties and relationships among timedenoting expressions and events in text-is a good starting point for bridging the gap between temporal analysis of documents and reasoning with the information derived from them. hard as timemlcompliant analysis is  the small size of the only currently available annotated corpus makes it even harder. we address this problem with a hybrid timeml annotator  which uses cascaded finite-state grammars  for temporal expression analysis  shallow syntactic parsing  and feature generation  together with a machine learning component capable of effectively using large amounts of unannotated data.
1 temporal analysis of documents
many information extraction tasks limit analysis of time to identifying a narrow class of time expressions  which literally specify a temporal point or an interval. for instance  a recent  1  ace task is that of temporal expression recognition and normalisation  tern; see http:// timex1.mitre.org/tern.html . it targets absolute date/ time specifications  e.g.  june 1th  1    descriptions of intervals   three semesters    referential  relative  expressions   last week    and so forth. a fraction of such expressions may include a relational component   the two weeks since the conference    a month of delays following the disclosure    making them event-anchored; however  the majority refer only to what in a more syntactic framework would be considered as a 'temporal adjunct'. the tern task thus does not address the general question of associating a time stamp with an event.
　deeper document analysis requires awareness of temporal aspects of discourse. several applications have recently started addressing some issues of time. document summarisation tackles identification and normalisation of time expressions  mani & wilson  1   time stamping of event clauses  filatova and hovy  1   and temporal ordering of events in news  mani et al.  1 . operational question answering  qa  systems can now  under certain conditions  answer e.g. 'when' or 'how long' questions  prager et al.  1 .
　beyond manipulation of temporal expressions  advanced content analysis projects are beginning to define operational requirements for  in effect  temporal reasoning. more sophisticated qa  for instance  needs more than just informationderived from 'bare' temporal markers  pustejovsky et al.  1; schilder & habel  1 . intelligence analysis typically handles contradictory information  while looking for mutually corroborating facts; for this  temporal relations within such an information space are essential. multi-document summarisation crucially requires temporal ordering over events described across the collection.
　a temporal reasoner requires a framework capturing the ways in which relationships among entities are described in text  anchored in time  and related to each other. related are questions of defining a representation that can accommodate components of a temporal structure  and implementing a text analysis process for instantiating such a structure.
　this paper describes an effort towards an analytical framework for detailed time information extraction. we sketch the temporal reasoning component which is the ultimate 'client' of the analysis. we motivate our choice of timeml  an emerging standard for annotation of temporal information in text  as a representationalframework; in the process  we highlight timeml's main features  and characterise a mapping froma timeml-compliantrepresentationto an isomorphicset of time-points and intervals expected by the reasoner.
　we develop a strategy for time analysis of text  a synergistic approach deploying both finite-state  fs  grammars and machine learning techniques. the respective strengths of these technologies are well suited for the challenges of the task: complexity of analysis  and paucity of examples of timeml-style annotation. a complex cascade of fs grammars targets certain components of timeml  time expressions  in particular   identifies syntactic clues for marking other components  related to temporal links   and derives features for use by machine learning. the training is on a timeml annotated corpus; given the small-and thus problematic for training-size of the only  so far  available reference corpus  timebank   we incorporatea learning strategydeveloped to leverage large volumes of unlabeled data.
　to our knowledge  this is the first attempt to use the representational principles of timeml for practical analysis of time. this is also the first use of a timeml corpus as reference data for implementing temporal analysis.
1 motivation: reasoning with time
we are motivated by developing a useful  and reusable  temporal analysis framework  where 'downstream' applications are enabled to reason and draw inferences over time elements.
　a hybrid reasoner  fikes et al.  1   to be deployed in intelligence analysis  maintains a directed graph of time points  intervals defined via start and end points  and temporal relations such as before  after  and equal point. the graph is assumed generated via a mapping process  external to the reasoner  from a  temporal  text analysis. relations are operationalised  and temporal algebra evaluates instances  draws inference over goals  and broadens a base of inferred assertions on the basis of relational axioms. an example within the reasoner's inferential capability is:
 find instances of  int such that  during  int 1  .
　reasoning with relations such as during  associating an event with an interval   costarts  associating two events   instantiated for the example fragment:  on 1 august iran accuses the taliban of taking 1 diplomats and 1 truck drivers hostage in mazar-e-sharif. the crisis began with that accusation.  would infer  on the basis of predicates like:
 during iran-accuses-taliban-take-hostages august-1 
 costarts iran-accuses-taliban-take-hostages iran-taliban-crisis 
that the answer to the question  when did the iranian-taliban crisis begin   is  august 1  1 .
　details of this inferential process need not concern us here. we gloss over issues like enumerating the range of temporal relations and axioms  describing the reasoner's model of events  e.g. iran-accuses-taliban-take-hostages   and elaborating its notion of 'a point in time'  subsuming both literal expressions and event specifications . operationally  a separate component maps temporal analysis results to a suitably neutral  and expressive  ontological representation of time  daml-time  hobbs et al.  1  . this allows for a representation hospitable to first-order logic inference formalism-like the one assumed in hobbs et al.-to be kept separate from surface text analysis: much like the traditional separation along the syntax-semantics interface.
　we start from the belief that the representation for the reasoner is derivable from a timeml-compliant text analysis.1timeml is a proposal for annotating time information;e.g. the first example sentence above would be marked up as:
 signal sid= s1   on  /signal   timex1 tid= t1  type= date  value=  1-1   1 august  /timex1  iran  event eid=  e1  class=  i action   accuses  /event  the taliban of  event eid= e1  class= occurrence   taking  /event  1 diplomats and 1 truck drivers hostage in mazar-e-sharif. the  event eid= e1  class= occurrence   crisis  /event   event eid= e1  class=  aspectual   began  /event   signal sid= s1  type= date  mod= start   with  /signal  that  event eid= e1  class= i action   accusation  /event .
 mkinstance eiid= ei1  evid= e1 /   mkinstance eiid= ei1  evid= e1 / 
 mkinstance eiid= ei1  evid= e1 /   mkinstance eiid= ei1  evid= e1 / 
 tlink eiid= ei1  reltotime= t1  reltype= is included / 
 tlink eiid= ei1  reltoeiid= ei1  reltype= identity / 
 alink eiid= ei1  reltoeiid= ei1  reltype= initiates / 
timeml is described in section 1. essentially  it promotes explicit representation and typing of time expressions and events  and an equally explicit mechanism for linking these with temporal links  using a vocabulary of temporal relations.
　in addition to in-line mark-up  explicit links are marked. event instance identifiers  ei1  ei1  and ei1 refer to  respectively  the accusation in the first sentence  the crisis  and the reference to  that accusation  in the second sentence. the reltype attributes on the link descriptions define temporal relationships between event instances and time expressions; in this particular example  an identity link encodes the coreferentiality between the event instances  mentions  in the two sentences of the accusation event of the earlier example.
　it is the combination of event descriptors  their anchoring to time points  and the semantics of relational links  which enable the derivation of during and costarts associations that the reasoner understands.
1 timeml: a mark-up language for time
most content analysis applications to date do not explicitly incorporate temporal reasoning  and their needs can be met by analysis of simple time expressions  dates  intervals  etc . this is largely the motivation for tern's timex1 tag; at the same time it explains why timex1 is inadequate for supporting the representational requirements outlined earlier.1
　timeml aims at capturing the richness of time information in documents. it marks up more than just temporal expressions  and focuses on ways of systematically anchoring event predicates to a time denoting expressions  and on ordering such event expressions relative to each other.
　timeml derives higher expressiveness from explicitly separating representation of temporal expressions from that of events. time analysis is distributed across four component structures: timex1  signal  event  and link; all are rendered as tags  with attributes  saur＞  et al.  1 .1
　timex1 extends1 the timex1  ferro  1  attributes: it captures temporal expressions  commonly categorised as date  time  duration   both literal and intensionally specified. signal tags are  typically  function words indicative of relationships between temporal objects: temporal prepositions  for  during  etc.  or temporal connectives  before  while . event  in timeml nomenclature  is a cover term for situations that happen or occur; these can be punctual  or last for a period of time. timeml posits a refined typology of events  pustejovsky et al.  1 . all classes of event expressions-tensed verbs  stative adjectives and other modifiers  event nominals-are marked up with suitable attributes on the event tag. finally  the link tag is used to encode a variety of relations that exist between the temporal elements in a document  as well as to establish an explicit ordering of events. three subtypes to the link tag are used to represent strict temporal relationships between events or between an event and a time  tlink   subordination between two events or an event and a signal  slink   and aspectual relationship between an aspectual event and its argument  alink .
　timeml's richer component set  in-line mark-up of temporal primitives  and non-consuming tags for temporal relations across arbitrarily long text spans  make it highly compatible with the current paradigm of annotation-based encapsulation of document analysis.
1 timeml and temporal analysis
timeml's annotation-based representation facilitates integration of time analysis with the analysis of other syntactic and/ or discourse phenomena; it also naturally supports exploitation of larger contextual effects by the temporal parser proper  see 1  . this is a crucial observation  given that the prominently attractive characteristic of timeml-its intrinsic richness of expression-makes it challenging for analysis.
　there are two broad categories of problems for developing an automated timeml analyser: of substance and of infrastructure. substantive issues include normalising time expressions to a canonical representation  timex1's value attribute   identifying a broad range of events  e.g. event nominals and predicative adjectives acting as event specifiers   linking time-denoting expressions  typically a timex1 and an event   and typing of those links.
　the infrastructure problems-small size and less than consistent mark-up of the timebank corpus-are due to the fact that this  first  versionis largelya side productof a small number of annotators trying out timeml's expressive capabilities. timebank is thus intended as a reference  and not for training. our hybrid approach to temporal parsing  combining finitestate  fs  recognitionwith machine learning from sparse data  1   is largely motivated by this nature of timebank.
1 the timebank corpus
timebank has only 1 documents  1k words . if we held out 1% of the corpus as test data  we have barely over 1k words for training. below we show counts of  event-timex1  tlink1 and event types  saur＞  et al.  1 . tlink examples are particularly sparse; the data also shows highly uneven distribution of examples of different types.
　in comparison  the penn treebank corpus for part-ofspeech tagging contains  1m words    1 times larger than timebank ; the conll'1 named entity chunking training set  at http://cnts.uia.ac.be/conll1/ner/  has over 1k words with 1k examples  1 times more than tlink examples  over just 1 name classes  compared to the 1 tlink classes defined by timeml . tern's training set-almost 1 documents/1k words-is considered to be somewhat sparse  with over 1k timex examples. tlink type # occurrences event type # occurrences
is included1occurrence1during1state1ends1reporting1simultaneous1i action1ended by1i state1after1aspectual1begins1perception1before1includes1begun by1iafter1identity1ibefore1
1 analytical strategy
minimally  the reasoner would require that the analytical framework supports time stamping and temporal ordering of events; thus we target the analysis tasks of finding timex1's  assigning canonical values  marking and typing events  and associating  some of them  with timex1 tags.
　timex1 expressions are naturally amenable to fs description. fs devices can also encode some larger context for time analysis  temporal connectives for marking putative events  clause boundaries for scoping possible event-time pairs  etc; see 1 . to complement such analysis  a machine learning approach can cast the problem of marking events as chunking. recently   ando  1  has developed a framework for exploiting large amounts of unannotated corpora in supervised learning for chunking. in such a framework  mid-to-high-level syntactic parsing-typically derived by fs cascades-can produce rich features for classifiers.
　thus  we combine fs grammars for temporal expressions  embedded in a general purpose shallow parser  with machine learning trained with timebank and unannotated corpora.
1 fs-based parser for temporal expressions
viewing timex1 analysis as an information extraction task  a cascade of finite-state grammars with broad coverage  compiled down to a single timex1 automaton with 1 states and over 1 transitions  targets abstract temporal entities such as unit  point  period  relation  etc; these may be further decomposed and typed into e.g. month  day  year  for a unit ; or interval or duration  for a period .
　fine-grained analysis of temporal expressions  instantiating attributes like granularity  cardinality  refdirection  and so forth  is crucially required for normalising a timex1: representing the last five years  as illustrated below facilitates the derivation of a value for the timex1 value attribute.
	 timex :  relative	: true  
 ref direction : past  
 cardinality : 1  
 granularity : year    
　such analysis amounts to a parse tree under the timex1.  not shown above is additional information  anchoring the expression into the larger discourse and informing other normalisation processes which emit the full complement of timex1 attributes-type  temporalfunction  anchortimeid  etc . timebank does not contain such fine-grained mark-up: the grammars thus perform an additional 'discovery' task  for which no training data currently exists  but which is essential for discourse-levelpost-processing handlinge.g.ambiguous and/or underspecifiedtime expressions or the relationship between document-internal and document-external temporal properties  such as 'document creation time' .
1 shallow parsing for feature generation
in principle  substantial discourse analysis can be carried out from a shallow syntactic base  and derived by means of fs cascading  kennedy & boguraev  1 . our grammars interleave shallow parsing with named entity extraction. they specify temporal expressions in terms of linguistic units  as opposed to simply lexical cues  as many temporal taggers to date do . this point cannot be over-emphasised. one of the complex problems for timeml analysis is that of event identification. a temporal tagger  if narrowly focused on time expressions only  cf.  schilder & habel  1    offers no clues to what events are there in the text. in contrast  a temporal parser aware of the syntax of a time phrase like  during the long and ultimately unsuccessful war in afghanistan  is very close to knowing-from configurational properties of a prepositional phrase-that the nominal argument   war   of the temporal preposition   during   is an event nominal.
　ultimately  syntactic analysis beyond timeml components is used to derive features for the classifiers tasked with finding
events and links  section 1 .
　feature generation typically relies on a mix of lexical properties and some configurational syntactic information  depending on the complexity of the task . our scheme additionally needs some semantic typing  knowledge of boundaries of longer syntactic units  typically a variety of clauses   and some grammatical function. an example  simplified  of the fs cascade output is:
 snt  svoclause
 tadjunct in  np  timex1 the 1 period timex1  np  tadjunct  
 sub  np the company np  sub 
 vg  grmeventoccurrence earned grmeventoccurrence  vg 
 obj  np  money $1 million money  np  obj  svoclause  ... snt 
　most of the above is self-explanatory  but we emphasise a few key points. the analysis captures the mix of syntactic chunks  semantic categories  and timeml components used for feature generation. it maintains local timex1 analysis; the time expression is inside of a larger clause boundary  with internal grammatical function identification for some of the event predicates. the specifics of mapping configurational information into feature vectors is described in section 1.
1 machine learning for timeml components
timeml parsing is thus a bifurcated process of timeml components recognition: timex1's are marked by fs grammars; signals  events and links are identified by classification models derived from analysis of both timebank and large unannotated corpora. features for these models are derived from common strategies for exploiting local context  as well as from mining the results-both mark-up and configurational-from the fs grammar cascading  as illustrated in the previous section.  more details on feature generation follow in section 1 below. 
classifiers and feature vectors
the classification framework we adopt for this work is based on a principle of empirical risk minimization. in particular  we use a linear classifier  which makes classification decisions by thresholding inner products of feature vectors and weight vectors. it learns weight vectors by minimizing classification errors  empirical risk  on annotated training data.
　for our experiments  section 1   we use the robust risk minimization  rrm  classifier  zhang et al.  1   which has been shown useful for a number of text analysis tasks such as syntactic chunking  named entity chunking  and partof-speech tagging.
　in marked contrast to generative models  where assumptions about features are tightly coupled with algorithms  rrm-as is the case with discriminative analysis-enjoys clear separation of feature representation from the underlying algorithms for training and classification. this facilitates experimentation with different feature representations  since the separation between these and the algorithms which manipulate them does not require change in algorithms. we show how choice of features affects performance in section 1.
word profiling for exploitation of unannotated corpora
in general  classification learning requires substantial amount of labeled data for training-considerably more than what timebank offers  cf. 1 . this characteristic of size is potentially a limiting factor in supervised learning approaches. we  however  seek to improve performance by exploiting unannotated corpora  with their natural advantages of size and availability. we use a word profiling technique  developed specially for exploiting a large unannotated corpus for tagging/chunking tasks  ando  1 . word profiling identifies  and extracts  word-characteristic information from unannotated corpora; it does this  in essence  by collecting and compressing feature frequencies from the corpus.
　word profiling turns co-occurrence counts of words and features  e.g. 'next word'  'head of subject'  etc  into new feature vectors. for instance  observing that  extinction  and  explosion  are often used as syntactic subject to  occur   and that  earthquakes   happen   helps to predict that  explosion    extinction   and  earthquake  all function like event nominals. below  1  we demonstrate the effectiveness of word profiling  specifically for event recognition.
1 implementation
to use classifiers  one needs to design feature vector representation for the objects to be classified. this entails selection of some predictive attributes of the objects  in effect promoting these to the status of features  and definition of mappings between vector dimensions and those attributes  feature mapping . in this section we describe the essence of our feature design for event and tlink recognition.1
1 event recognition
similarly to named entity chunking  we cast the event recognition task as a problem of sequential labeling of tokens by encoding chunk information into token tags. for a given class  this generates three tags: e:class  the last  end  token of a chunk denoting a mention of class type   i:class  a token inside of a chunk   and o  any token outside of any target chunk . the example sequence below indicates that the two tokens  very bad  are spanned by an event-state annotation.
，，， another/o very/i:event-state bad/e:event-state week/o ，，，
　in this way  the event chunking task becomes a  1k+1 way classification of tokens where k is the number of event types; this is followed by a viterbi-style decoding.  we use the same scheme for signal recognition. 
　the feature representation used for event extraction experiments mimics the one developed for a comparative study of entity recognition with word profiling  ando  1 . the features we extract are:
  token  capitalization  part-of-speech  pos  in 1-token window;
  bi-grams of adjacent words in 1-token window;
  words in the same syntactic chunk;
  head words in 1-chunk window;
  word uni- and bi-grams based on subject-verb-objectand preposition-noun constructions;
  syntactic chunk types  noun or verb group chunks only ;   token tags in 1-token window to the left;
  tri-grams of pos  capitalization  and word ending;   tri-grams of pos  capitalization  and left tag.
1 tlink recognition
tlink is a relation between events and time expressions which can link two events  two timex1's  or an event and a timex1. presently  see 1  we focus on tlinks between events and time expressions.
　as a relational link  tlink does not naturally fit the tagging abstraction for a chunking problem  outlined above. instead  we formulate a classification task as follows. after posting event and timex1 annotations  by the event classifier and the fs temporal parser  respectively   for each pairing between an event and a timex1  we ask whether it is a certain type of tlink. this defines a -way classification problem  where  is the number of tlink types  before  after  etc; section 1 . the adjustment term '+1' is for the negative class  not-a-temporal-link .
the relation-extraction nature of the task of posting
tlinks requires a different feature representation  capable of encoding the syntactic function of the relation arguments  events and timex1's   and some of the larger context of their mentions. to that end  we consider the following five partitions  defined in terms of tokens : spans of arguments  p 1 or p 1 ; two tokens to the left/right of the left/right argument  p left/p right ; and the tokens between the arguments  p middle . from each partition  we extract tokens and partsof-speech as features.

we also consider segments  syntactic constructions derived by fs analysis: 'when-clause'  'subject'  etc  in certain relationship to partitions: contained in p 1  p 1  or p middle; covering p 1  or p 1  but not overlapping with p 1  or p 1 ; occurring to the left of p 1  or the right of p 1 ; or covering both p 1 and p 1. we use uni- and bi-grams of types of these segments as features.
　in this feature representation  segments play a crucial role by capturing the syntactic functions of events and timex1's  as well as the syntactic relations between them.
　thus in the example analysis on p. 1  svoclause is the smallest segment containing both an event and a timex1  indicative of a direct syntactic relation between the two. in the next example  the timex1 and event chunks are contained in different clauses  a thatclause and a svoclause  respectively   which structurally prohibits a tlink relation between the two.
 snt
analysts have complained
 thatclause that  timex1 third-quarter timex1  corporate earnings have n't been very good thatclause 
 svoclause   but the effect  event hit event  ... svoclause  snt 
thus our feature representation is capable of capturing this information via the types of the segments that contain each of event and timex1 without overlapping.
1 experiments
we present here performance results on event and tlink recognition only. this is largely because the primary focus of this paper is to report on how effective our analytical strategy is in leveraging the reference nature of the small timebank corpus for training classifiers for timeml. of these  signal was briefly mentioned earlier  see footnote 1   and timex1 recognition  driven by fs grammars  belongs to a different paper. since this is the first attempt to build a timemlcompliant analyser  cf. section 1   there are no comparable results in the literature.
　the results  micro-averaged f-measure  reflect experiments with different settings  against the timebank corpus  and produced by 1-fold cross validation.
1 event recognition
it should be clear  by looking at the example analysis  p. 1   how local information and syntactic environment both contribute to the feature generation process. figure 1 shows performance results with and without word profiling for exploiting an unannotated corpus. for word profiling  we extracted
	features	with typing	w/o typing
basic11	basic + word-profiling	1  +1 	1  +1 
figure 1: event extraction results  with/without typing. parentheses show contribution of word profiling  over using basic features only.
feature co-occurrence counts from 1m words of 1 wall street journal. the proposed event chunks are counted as correct only when both the chunk boundaries and event types are correct. while word profiling improves performance  1% f-measure is lower than typical performance of  for instance  named entity chunking. on the other hand  when we train the event classifiers without typing  we obtain 1% f-measure. this is indicative of the inherent complexity of the event typing task.
1 tlink recognition
in this experimental setting  we only consider the pairings of
event and timex1 which appear within a certain distance in the same sentences.1
　for comparison  we implement the following simple baseline method. considering the text sequence of events and timex1's  only 'close' pairs of potential arguments are coupled with tlinks; event e and timex1 t are close if and only if e is the closest event to t and t is the closest timex1 to e. for all other pairings  no temporal relation is posted. depending on the 'with-'/'without-typing' setting  the baseline method either types the tlink as the most populous class in timebank  is included  or simply marks it as 'it exists'. results are shown in figure 1. clearly  the detection of distance  # of tlinks  features with typing w/o typing
distance ＋ 1 tokens
 1 tlinks baseline11basic11basic+fs1  +1 1  +1 distance ＋ 1 tokens
 1 tlinks baseline11basic11basic+fs1  +1 1  +1 distance ＋ 1 tokens
 1 tlinks baseline11basic11basic+fs1  +1 1  +1 figure 1: tlink extraction results  with/without typing. parentheses show contribution of grammar-derived features  over using basic ones only. baseline posts tlinksover 'close' event/timex1pairs.
temporal relations between events and time expressions requires more than simply coupling the closest pairs within a sentence  as the baseline does . it is also clear that the baseline method performs poorly  especially for pairings over relatively long distances. for instance  it produces 1% when we consider the pairings within 1 tokens without typing. in the same setting  our method produces 1% in f-measure  significantly outperforming the baseline.
　we compare performance in two types of feature representation: 'basic' and 'basic+fs grammar'  which reflect the without- and with-segment-type information obtained by the grammar analysis  respectively. as the positive delta's show  configurationalsyntactic informationcan be exploited beneficially by our process. focusing on within-1-tokens pairings  we achieve 1% f-measure without typing of tlinks  and 1% with typing.  the task without typing is a binary classification to detect whether the pairing has a tlink relation or not  regardless of the type.  as the figure shows  the task becomes harder when we consider longer distance pairings. within a 1 token distance  we obtain figures of 1% and 1%  without and with typing respectively.
　while we are moderately successful in detecting the existence of temporal relations  the noticeable differences in performance between the task settings with and without typing indicate that we are not as successful in distinguishing one type from another. in particular  the relatively low performance of tlink typing highlights the difficulty in distinguishing between during and is included.
　the guidelines  and common sense analysis  suggest that is included type should be assigned if the time point or duration of event is included in the duration of the associated timex1. during  on the other hand  should be assigned as a type if some relation represented by the event holds during the duration of the timex1. we note that for this particular typing problem  the subtle distinctions are hard even for human annotators: the timebank corpus displays a number of occasions where inconsistent tagging is evident.
1 conclusion
timeml is a significant development in time analysis  as it captures detailed information  anchored in eventuality and linguistic structure  and shown to be crucial inferential and reasoning tasks. in additionto defining annotationguidelines  the timeml effort notably created the first reference corpus illustrative of expressiveness of the language.
　unfortunately  the small size of the timebank corpus prevents its straightforward use as a training resource  a problem further exacerbated by the inherent complexity of timemlcompliant analysis. and yet  for reasoning engines to function  timeml analysers need to be built.
　 mani et al.  1  discuss some pioneering work in linking events with times  and ordering events  indicative of productive strategies for posting  some  tlink information. however  the nature of these efforts is such that differences in premises  representation  and focus make a direct performance comparison impossible. furthermore  the work pre-dates timeml  and cannot be conveniently mapped to timebank data; this  in effect  precludes a quantitative comparison with our work.
in a first systematic attempt at timeml-compliantanalysis  and leveraging the timebank corpus  we have developed a strategy which synergisticallyblends finite-state analysis over linguistic annotations with a state-of-the-art machine learning technique. particularly effective are: aggressive analysis  by complex grammars  of both timeml components and syntactic structure; coupled with a learning algorithm capable of training over unannotated data  in addition to exploiting arbitrarily small amounts of labeled data. while work remains  notably refining the tlink recogniser  targeting other types of links  and enhancing event recognition with external lexical resources   this is a significant step in instantiating a deeper time analysis  capable of satisfying the needs of reasoning engines.
