
trust should be substantially based on evidence. further  a key challenge for multiagent systems is how to determine trust based on reports from multiple sources  who might themselves be trusted to varying degrees. hence an ability to combine evidence-based trust reports in a manner that discounts for imperfect trust in the reporting agents is crucial for multiagent systems. this paper understands trust in terms of belief and certainty: a's trust in b is reflected in the strength of a's belief that b is trustworthy. this paper formulates certainty in terms of evidence based on a statistical measure defined over a probability distribution of the probability of positive outcomes. this novel definition supports important mathematical properties  including  1  certainty increases as conflict increases provided the amount of evidence is unchanged  and  1  certainty increases as the amount of evidence increases provided conflict is unchanged. moreover  despite a more subtle definition than previous approaches  this paper  1  establishes a bijection between evidence and trust spaces  enabling robust combination of trust reports and  1  provides an efficient algorithm for computing this bijection.
1 introduction
in simple terms  an agent's trust in another can be understood as a belief that the latter's behavior will support the agent's plans. subtle relationships underlie trust in social and organizational settings  castelfranchi and falcone  1 . without detracting from such principles  this paper takes a narrower view of trust: here an agent seeks to establish a belief or disbelief that another agent's behavior is good  thus abstracting out details of the agent's own plans and the social and organizational relationships between the two agents . the model proposed here can  however  be used to capture as many dimensions of trust as needed  e.g.  timeliness  quality of service  and so on.
　for rational agents  trust in a party should be based substantially on evidence consisting of positive and negative experiences with it. this evidence can be collected by an agent locally or via a reputation agency or by following a referral protocol. in such cases  the evidence may be implicit in the trust reports obtained that somehow summarize the evidence. this paper develops a principled evidence-basedapproachfor trust that supportstwo crucial requirementsof multiagentsystems:
dynamism. practical agent systems face the challenge that trust evolves over time  both as additional information is obtained and as the parties being considered alter their behavior.
composition. it is clear that trust cannot be trivially propagated. for example  a may trust b who trusts c  but a may not trust c. however  we need to combine trust reports that cannot themselves be perfectly trusted  possibly because of their provenance or the way in which they are obtained.
traditionally  principled approaches to trust have been difficult to come by because of the above requirements. with few exceptions  current approaches for combining trust reports tend to involvead hoc formulas  which might be simple to implement but are extremely difficult to understand from a conceptual basis. the common idea underlying a solution that satisfies the above requirements is the notion of discounting. dynamism can be accommodated by discounting over time and composition by discounting over the space of sources  i.e.  agents . others have used discounting before  but without adequate mathematical justification. for instance  yu and singh  develop such a discounting approach layered on their  principled  dempster-shafer account.
　the best multiagent application of the present approach is in the work of wang and singh  1a   who develop an algebra for aggregating trust over graphs understood as webs of trust. wang and singh concentrate on their algebra and assume a separate  underlying trust model  which is the one developed here. by contrast  the present paper is neutral about the discounting and aggregation mechanisms  and instead develops a principled evidential trust model that would underlie any such agent system where trust reports are gathered from
multiple sources.
following j sang   we understand trust based on the probability of the probability of outcomes  and adopt his idea of a trust space of triples of belief  in a good outcome   disbelief  or belief in a bad outcome   and uncertainty. trust in this sense is neutral as to the outcome and is reflected in the certainty  i.e.  one minus the uncertainty . thus the following three situations are distinguished:
  trust in a party  i.e.  regarding its being good : belief is high  disbelief is low  and uncertainty is low.
  distrust in a party: belief is low  disbelief is high  and uncertainty is low.
  lack of trust in a party  pro or con : uncertainty is high.
　however  whereas j sang defines certainty in an ad hoc manner  we define certainty based on a well-known statistical measure. despite the increased subtlety of our definition  it preserves a bijection between trust and evidence spaces  enabling combination of trust reports  via mapping them to evidence . our definition captures the following key intuitions.
effect of evidence. certainty increases as evidence increases  for a fixed ratio of positive and negative observations .
effect of conflict. certainty decreases as the extent of conflict increases in the evidence.
　j sang's approach satisfies the intuition about evidence but fails the intuition about conflict. it falsely predicts that mounting conflicting evidence increases certainty-and equally as much as mounting confirmatory evidence. say alice deals with bob four times or obtains  fully trustworthy  reports about bob from four witnesses: in either case  her evidence would be between 1 and 1 positive experiences. it seems uncontroversial that alice's certainty is greatest when the evidence is all in favor or all against and least when the evidence is equally split. section 1 shows that j sang assigns the same certainty in each case.
　yu and singh  model positive  negative  or neutral evidence  and apply dempster-shafer theory to compute trust. neutral experiences yield uncertainty  but conflicting positive or negative evidence doesn't increase uncertainty. further  for conflicting evidence  dempster-shafertheory can yield unintuitive results  sentz and ferson  1 . say pete sees two physicians  dawn and ed  for a headache. dawn says pete has meningitis  a brain tumor  or neither with probabilities 1  1  and 1  respectively. ed says pete has a concussion  a brain tumor  or neither with probabilities 1  1  and 1  respectively. dempster-shafer theory yields that the probability of a brain tumor is 1  which is highly counterintuitive  because neither dawn nor ed thought that was likely.
　this paper contributes  1  a rigorous  probabilistic definition of certainty that satisfies the above key intuitions   1  the establishment of a bijection between trust reports and evidence  which enables the principled combination of trust reports  and  1  an efficient algorithm for computing this bijection.
1 modeling certainty
the proposed approach is based on the fundamental intuition that an agent can model the behavior of another agent in probabilistic terms. specifically  an agent can represent the probability of a positive experience with  i.e.  good behavior by  another agent. this probability must lie in the real interval  1 . the agent's trust corresponds to how strongly the agent believes that this probability is a specific value  whether large or small  we don't care . this strength of belief is also captured in probabilistic terms. to this end  we formulate a probability density function of the probability of a positive experience. following  j sang  1   we term this a probabilitycertainty density function  pcdf . in our approach  unlike
j sang's  certainty is a statistical measure defined on a pcdf.
1 certainty from a pcdf
because the cumulative probability of a probability lying within  1  must equal 1  all pcdfs must have the mean density of 1 over  1   and 1 elsewhere. lacking additional knowledge  a pcdf would be a uniform distribution over  1 . however  with additional knowledge  the pcdf would deviate from the uniform distribution. for example  knowing that the probability of good behavior is at least 1  we would obtain a distribution that is 1 over  1.1  and 1 over  1 1 . similarly  knowing that the probability of good behavior lies in  1 1   we would obtain a distribution that is 1 over  1.1  and  1 1   and 1 over  1 1 .
　in formal terms  let p （  1  represent the probability of a positive outcome. let the distribution of p be given as a function such that. the probability that the probability of a positive outcome lies in
 p1 p1  can be calculated by	p	. the mean value of
. when we know nothing else  f is a uniform distribution over probabilities p. that is  f p  = 1 for p （  1  and 1 elsewhere. this reflects the bayesian intuition of assuming an equiprobable prior. the uniform distribution has a certainty of 1. as more knowledge is acquired  the probability mass shifts so that f p  is above 1 for some values of p and below 1 for other values of p.
　our key intuition is that the agent's trust corresponds to increasing deviation from the uniform distribution. two of the most established measures for deviation are standard deviation and mean absolute deviation  mad . mad is more robust  because it does not involve squaring  which can increase standard deviation because of outliers or  heavy tail  distributions such as the notorious cauchy distribution . absolute values can sometimes complicate the mathematics. but  in the present setting  mad turns out to yield straightforward mathematics. in a discrete setting involving data points x1...xn with mean x   mad is given by. in the present case  instead of n we divide by the size of the domain  i.e.  1. because a pcdf has a mean value of 1  increase in some parts must match reduction elsewhere. both increase and reduction from 1 are counted by |f p    1|. definition 1 scales the mad for to remove this double counting. definition 1 the certainty based on f  cf  is given by cf =

　certainty captures the fraction of the knowledge that we do have. for motivation  consider randomly picking a ball from a bin that contains n balls colored white or black. suppose p is the probability that the ball randomly picked is white. if we have no knowledge about how many white balls there are in the bin  we can't estimate p with any confidence that is  certainty c = 1. if we know that exactly m balls are white  then we have perfect knowledge about the distribution. we can estimate with c = 1. however  if all we know is that at least m balls are white and at least n balls are black
 thus m + n ＋ n   then we have partial knowledge. here
. the probability of drawing a white ball ranges
from. we have

using definition 1  we can confirm that:

1 evidence and trust spaces conceptually
for simplicity  we model a  rating  agent's experience with a  rated  agent as a binary event: positive or negative. evidence is conceptualized in terms of the numbers of positive and negative experiences. in terms of direct observations  these numbers would obviously be whole numbers. however  our motivation is to combine evidence in the context of trust. as section 1 motivates  for reasons of dynamism or composition  the evidence may need to be discounted to reflect the aging of or the imperfect trust placed in the evidence source. intuitively  because of such discounting  the evidence is best understood as if there were real  i.e.  not necessarily natural  numbers of experiences. accordingly we model the evidence space as e = r 〜 r  a two-dimensional space of reals. the members of e are pairs  corresponding to the numbers of positive and negative experiences  respectively. combining evidence is trivial: simply perform vector sum.
definition 1 define evidence space e = { r s |r − 1 s − 1 t = r + s   1}
　let x be the probability of a positive outcome. the posterior probability of evidenceis the conditional probability of x given  casella and berger  1  p. 1 . definition 1 the conditional probability of x given is

where
　traditional probability theory models the event by  α 1 α   the expected probabilities of positive and negative outcomes  respectively  where . the traditional probability model ignores uncertainty.
　a trust space consists of trust reports modeled in a threedimensional space of reals in  1 . each point in this space is a triple   where b + d + u = 1  representing the weights assigned to belief  disbelief  and uncertainty  respectively. certainty c is simply 1   u. thus c = 1 and c = 1 indicate perfect knowledge and ignorance  respectively.
　combining trust reports is nontrivial. our proposed definition of certainty is key in accomplishing a bijection between evidence and trust reports. the problem of combining independent trust reports is reduced to the problem of combining the evidence underlying them.  definitions 1 and 1 are based on  j sang  1 . 
definition 1 define trust space as t = { b d u |b   1 d   1 u   1 b + d + u = 1}.
1 from evidence to trust reports
using definition 1  define certainty based on evidence:
definition 1 
　throughout  r  s  and t = r + s refer to positive  negative  and total evidence  respectively. importantly   the expected value of the probability of a positive outcome  also characterizes conflict in the evidence. clearly  α （  1 : α approaching 1 or 1 indicates unanimity  whereas α = 1 means r = s  i.e.  maximal conflict in the body of evidence. we can write c r s  as c  t + 1 α   1  t + 1  1   α    1 . when α is fixed  certainty is a function of t  written c t . when t is fixed  it is a function of α  written c α . and  and are the corresponding derivatives.
　the following is our transformation from evidence to trust spaces. this transformation relates positive and negative evidence to belief and disbelief  respectively  but discounted by the certainty. the idea of adding 1 each to r and s  and thus 1 to r + s  follows laplace's famous rule of succession for applying probability to inductive reasoning  sunrise  1 . this reduces the impact of sparse evidence  and is sometimes termed laplace smoothing. if you only made one observation and it was positive  you would not want to conclude that there would never be a negative observation. as the body of evidence increases  the increment of 1 becomes negligible. more sophisticated formulations of rules of succession exist  ristad  1   but laplace's rule is simple and reasonably effective for our present purposes. laplace's rule is insensitive to the number of outcomes in that 1 is always added. the effect of this statistical  correction   the added 1  decreases inversely as the numberof outcomes being considered increases. more sophisticated approaches may be thought of as decreasing the effects of their corrections more rapidly.
definition 1 let z r s  =  b d u  be a transformation from e to t	  where
 	  =	 	  	 	  =  1  	   	   and	 	  =
1   c r s .
　one can easily verify that c 1    1. in general  because t = r + s   1  c r s    1. moreover  c r s    1: thus  1   c r s    1. this coupled with the rule of succession ensures that b   1  d   1  and u   1. notice that.
j sang et al.  map evidence  to a trust triple
. two main differences with our approach are:  1  they ignore the rule of succession and  1  in essence  they define certainty as t+1t . they offer no mathematical justification for doing so. section 1 shows an unintuitive consequence of their definition.
1 important properties and computation
we now show that the above definition yields important formal properties and how to compute with it.
1 increasing experiences with fixed conflict
consider the scenario where the total number of experiences increases for fixed α = 1. for example  compare observing 1 good episodes out of 1 with observing 1 good episodes out of 1. the expected value  α  is the same in both cases  but the certainty is clearly greater in the second. in general  we would expect certainty to increase as the amount of evidence increases. definition 1 yields a certainty of 1 from
  but a certainty of 1..
　figure 1 plots how certainty varies with t when α = 1. theorem 1 captures this property in general.

figure 1: certainty increases with t when conflict  α = 1  is fixed; x-axis: t; y-axis: c t 
theorem 1 fix α. then c t  increases with t for t   1.
proof idea: show that.
　the full proofs of this and other theorems of this paper are included in a technical report  wang and singh  1b .
1 increasing conflict with fixed experience
another important scenario is when the total number of experiences is fixed  but the evidence varies to reflect different levels of conflict by using different values of α. clearly  certainty should increase as r or s dominates the other  i.e.  α approaches 1 or 1  but should reduce as r and s are balanced  i.e.  α approaches 1 . figure 1 plots certainty for fixed t and varying conflict.
　more specifically  consider alice's example from section 1. table 1 shows the effect of conflict where t = 1.
　theorem 1 captures the property that certainty increases with increasing unanimity.

figure 1: certainty is concave when t is fixed at 1; x-axis: r + 1; y-axis: c α ; minimum occurs at r = s = 1
table 1: certainty computed by different approaches for varying conflict

our approach11111j sang et al.11111yu & singh111theorem 1 c α  is decreasing when   increasing when   and minimum at.
 proof idea: show that when α （  1.1  and  when α （  1 1 .

figure 1: x-axis: r; y-axis: s; z-axis: certainty
　putting the above results together suggests that the relationship between certainty on the one hand and positive and negative evidence on the other is nontrivial. figure 1 confirms this intuition by plotting certainty against r and s as a surface.
1 bijection between evidence and trust reports
the ability to combine trust reports effectively relies on being able to map between the evidence and the trust spaces. with such a mapping in hand  to combine two trust reports  we would simply perform the following steps:  1  map trust reports to evidence;  1  combine the evidence;  1  transform the combined evidence to a trust report. the following theorem establishes that z has a unique inverse z 1. theorem 1 the transformation z is a bijection.
proof sketch: given  b d u  （ t  we need  r s  （ e such that z r s  =  b d u . as explained in section 1  α = b+bd. thus  we only need to find t such that c t  = 1 u. the
existence and uniqueness of t is proved by showing that
1. c t  is increasing when t   1  theorem 1 
1. limt★± c t  = 1
1. limt★1 c t  = 1
　briefly  yu and singh  base uncertainty not on conflict  but on intermediate  neither positive not negative  outcomes. let's revisit pete's example of section 1. in our approach  dawn and ed's diagnoses correspond to two b  d  u triples  where b means  tumor  and d means  not a tumor  :  1 1 1  and  1 1 1   respectively. combining these we obtain the b  d  u triple of  1 1 1 . that is  the weight assigned to a tumor is 1 as opposed to 1 by dempster-shafer theory  which is unintuitive  because a tumor is dawn and ed's least likely prediction.
1 algorithm and complexity
no closed form is known for z 1. algorithm 1 calculates
z 1  via binary search on c t   to any necessary precision  . here tmax   1 is the maximum evidence considered.
;
1 t1 = 1; 1 t1 = tmax;
1 while	do
1t = t1t1;
1if c t    c then t1 = t else t1 = t
1 return r =   t + 1 α   1   s = t   ralgorithm 1: calculating  r s  = z 1 b d u 
theorem 1 the complexity of algorithm 1 is .
proof: after the while loop iterates i times  t1   t1 = tmax1 i. eventually  t1   t1 falls below   thus terminating the while loop. assume it terminates in n iterations. then . this implies n    lgtmax   lg     1.
1 discussion
this paper is meant to offer a theoretical development of trust that would underlie a variety of situations where trust reports based on evidence are combined. in particular  it contributes to a mathematical understanding of trust  especially as it underlies a variety of multiagent applications. these include referral systems and webs of trust in particular  in studying which we identified the need for this research. such applications require a natural treatment of composition and discounting in an evidence-based framework.
　further  an evidence-based notion of trust must support important properties regardingthe effects of increasing evidence  for constant conflict  and of increasing conflict  for constant evidence . the theoretical validation provided here is highly valuable in a general-purpose conceptually driven mathematical approach. the main technical insight of this paper is how to manage the duality between trust and evidence spaces in a manner that provides a rigorous basis for combining trust reports.
　let's briefly revisit the topic of trust dynamics from section 1. the foregoing showed how trust evolves with respect to increasing outcomes under different conditions. the same properties apply to the evolution of trust over time  that is  as time passes and more evidence is obtained. a crucial observation is that because of the bijection we established  the historical evidence at any point can be summarized in a beliefdisbelief-uncertainty triple. new evidence can then be added as explained above. moreover  we can discount the value of evidence over time if necessary  e.g.  at every time step  chosen based on the domain: every hour or day  or after every transaction . thus new evidence would have a greater impact than older evidence.
　a payoff of this approach is that an agent who wishes to achieve a specific level of certainty can compute how much evidence would be needed at different levels of conflict. or  the agent can iteratively compute certainty to see if it has reached an acceptable level.
1 directions
this work has opened up some important directions for future work. an important technical challenge is to extend the above work from binary to multivalued events. such an extension will enable us to handle a larger variety of interactions among people and services. a current direction is to experimentally validate this work  doing which is made difficult by the lack of established datasets and testbeds  but the situation is improving in this regard  fullam et al.  1 .
1 literature on trust
a huge amount of research has been conducted on trust  even if we limit our attention to evidential approaches. abdulrahman and hailes  present an early model for computing trust. however  their approach is highly ad hoc and limited. specifically  various weights are simply added up without any mathematical justification. likewise  the term uncertainty is described but without any foundation.
　the regret system combines several aspects of trust  notably the social aspects  sabater and sierra  1 . it involves a numberof formulas  which are given intuitive  but not mathematical  justification. a lot of other work  e.g.   huynhet al.  1   involves heuristics that combine multiple information sources to judge trust. it would be an interesting direction to combine a rigorous approach such as ours with the above heuristic approaches to capture a rich variety of practical criteria well.
　teacy et al.  develop a probabilistic treatment of trust. they model trust in terms of confidence that the expected value lies within a specified error tolerance. an agent's confidenceincreases with the errortolerance. teacy et al. study combinations of probability distributions to which the evaluations given by different agents might correspond. they do not formally study certainty. and their approach doesn't yield a probabilistically valid method for combining trust reports.
1 literature on information theory
shannon entropy  is the best known informationtheoretic measure of uncertainty. it is based on a discrete probability distribution  over a finite set x of alternatives  elementary events . shannon's formula encodes the number of bits required to obtain certainty:
. here s p  can be viewed
as the weighted average of the conflict among the evidential claims expressed by p. more complex  but less wellestablished  definitions of entropy have been proposed for continuous distributions as well  e.g.   smith  1 .
　entropy  however  is not suitable for the present purposes of modeling evidential trust. entropy models bits of missing information which ranges from 1 to ±. at one level  this disagrees with our intuition that  for the purposes of trust  we need to model the confidence placed in a probability estimation. moreover  the above definitions cannot be used in measuring the uncertainty of the probability estimation based on past positive and negative experiences.
acknowledgments
we thank the anonymous reviewers for their helpful comments and chung-wei hang for useful discussions.
