 
in linguistics  the semantic relations between words in a sentence are accounted for  inter alia  as the assignment of thematic roles  e.g. agent  instrument  etc. as in predicate logic  simple linguistic expressions are decomposed into one predicate  often the verb  and its arguments. the predicate assigns thematic roles to the arguments  so that each sentence has a thematic grid  a structure with all thematic roles assigned by the predicate. in order to reveal the thematic grid of a sentence  a system called htrp  hybrid thematic role processor  is proposed  in which the connectionist architecture has  as input  a featural representation of the words of a sentence  and  as output  its thematic grid. both a 
random initial weight version  riw  and a biased initial weight version  biw  are proposed to account for systems without and with initial knowledge  respectively. in biw  initial connection weights reflect symbolic rules for thematic roles. for both versions  after supervised training  a set of final symbolic rules is extracted  which is consistently correlated to linguistic symbolic - knowledge. in the case of biw  this amounts to a revision of the initial rules. in riw  symbolic rules seem to be induced from the connectionist architecture and training. 
1 introduction 
in sentences such as 
      .1  the man broke the window with the stone  one can intuitively find an agent  the man   a patient  the window   and an instrument  the stone . linguistic theory  haegeman  1  refers to the roles words usually have in relation to a verb as thematic roles  so that one can say that break has a thematic structure with the following roles  agent  patient  instrument   in this sentence. but linguistic theory also assumes that this structure can change  depending on the sentence. so  for the sentence 
 1  the stone broke the vase  
1 	machine learning 
there is a different thematic structure  since stone is cause  the one that causes the action  and vase is patient. the difference between  1  and  1  is that although the same verb is employed  break   no agent or instrument is expressed in  1 ; thus  the thematic structure for  1  -  cause  patient  - is different from the thematic structure for  1 . 
   the theoretical approach to thematic roles in linguistics is symbolic. as in predicate logic  the linguistic expressions are decomposed into a central predicate  often the verb  and a number of arguments that complete its meaning  raposo  1 . the predicate assigns thematic roles to the arguments  and each sentence has a thematic grid  i. e.  a structure with all thematic roles assigned to the sentence arguments by the predicate. 
a natural language processing system  called htrp 
 which stands for hybrid thematic role processor   is proposed to identify the thematic grid of a semantically sound input sentence. two versions are deployed: the first  without initial knowledge  and the second  with initial knowledge. the first version specifies an ordinary connectionist architecture with initial random connection weights  henceforth called riw  random initial weight version . in the second version  henceforth called biw  biased initial weight version   a set of biased initial network connection weights is introduced to represent symbolic rules for ten thematic roles. in both versions  after supervised training  a set of final symbolic rules is extracted  which is consistently correlated to linguistic  symbolic  knowledge. in the case of biw  this amounts to a revision of the initial rules. in riw  symbolic rules seem to be induced from the connectionist architecture. 
1 thematic roles 
taking sentences  1  and  1  again  it seems that the distinction between agent and cause has something to do with the nouns that are assigned such roles. thus  since only an animate noun is supposed to be an agent  some kind of semantic analysis is necessary in order to distinguish between different thematic assignments. in other words  thematic roles must be elements with se-

mantic content  dowty  1 . one could then imagine that the words  which can fill each of the slots for a given thematic grid  share a common semantic core. assuming this is regular  one could try to capture such regularity  a  by describing each word in terms of its semantic features  and  b  by generalizing over all such descriptions for each thematic slot. 
   semantic feature generalization is the hallmark of mcclelland and kawamoto's  pioneering proposal  and of much subsequent work. in a system called cppro  rosa  1   a connectionist architecture based on an adaptation of mcclelland and kawamoto's  model is proposed. the words are represented by arrays of semantic microfeatures  formed by subsets accounting for aspects of word meaning  like human and non-human  where only one value in each subset is active. for the verb  these arrays are arranged on the basis of thematic relationships between the verb and the other words of a sentence  thus mapping thematic roles onto semantic features. the aim of cppro is to explore the idea of microfeature representation in order to build an architecture able to analyze and to learn the correct thematic relationship attributions of the words in a sentence. its output reflects judgements of semantic acceptability of a sentence. 
   in htrp  the output is constituted by the thematic grid of a sentence  composed of up to ten thematic roles: 
agent  experiencer  cause  patient  theme  source  goal  beneficiary  value  and instrument. for htrp  some intuitive thematic role definitions are adopted  as follows. agent is the argument having the control of the action expressed by the predicate. experiencer is a participant who does not have the control of an action expressing a psychological state. cause is the argument that initiates the action expressed by the predicate without controlling it. patient is the participant affected directly by the action of the predicate  usually changing state. theme is the participant affected indirectly by the action of the predicate  without changing state. the other role labels are self-explanatory. 
　in htrp  only sentences with up to three arguments are taken care of. thus  the argument structure  haegeman  1  of the sentences is as follows: verb; 	1 	1 	1 
             argl 	arg1 	arg1 where argl  argl and arg1 are the arguments of the verb  to which the predicate  the verb  assigns thematic roles. a limited set of verbs is chosen for the present implementation of htrp: break  buy  deliver  fear  frighten  give  hit  and love. 
1 verb representation 
the representation of the verb in htrp is strongly based on franchi and can′ado . they use a nonlexicalist representation; that is  the thematic role assignment compositionally depends on the whole sentence. for instance  taking the verb break   1  and  1  are the thematic grids for  1  and  1  respectively: 
 1  mary broke the vase with a hammer. 
 1  the stone broke the vase. 
 1   agent  patient  instrument   1   cause  patient . 
   to explain the difference  one can resort again to the notion that thematic roles are elements with semantic content. in this case  it seems that sometimes  e.g. in sentence  1   control of action is required by the verb break in relation to argl  while no such control is required in sentence  1 . thus  one could say that control of action is a feature to be associated with the verb. 
　the same is true for the verb frighten  regarding a different feature: direct process triggering. 
 1  mary frightened paul with a scream. 
 1  the tests frightened paul. 
in  1  control of action is part of the game  while in  1  direct process triggering assumes a central role. 
　thus  a small set of features can be associated with the verb  in the same manner that nouns are associated with a set of  different  features  waltz and pollack  1; mcclelland and kawamoto  1; rosa  1 . 
　the compositional features associated with the verb change according to the sentence in which the verb is used. so  it is inadequate to say that a specific verb has a single thematic grid  because this will depend on the whole sentence in which the verb occurs. in sum  a nonlexicalist approach is preferable. 
1 the connectionist architecture 
htrp system uses a connectionist architecture representing eleven independent artificial neural networks  one for each thematic role and one for the error output  lawrence et al  1 . the elementary processors are classical perceptron-like units  and each net has 1 input units  1 hidden units  and one output unit. the input units are responsible for the representation of two words of a sentence  the verb and one of the nouns. since each htrp sentence has  at most  three nouns beyond the verb  each sentence works with at most three neural networks  in order to activate a grid of up to three thematic roles. the first hidden unit  v  represents the conjunction of all the verb microfeatures  and the second  n   the conjunction of all the noun microfeatures. the output unit represents the conjunction of these two microfeature sets  see figure 1 . the error output  which has also two hidden units and one output unit  differs at the input layer  which in this case has 1 units  because it is unknown which nouns  in conjunction with the verb  activate the error output. 
1 the error output 
lawrence et al  propose a recurrent neural network to classify english sentences as grammatical or un~ 
	rosa and 	franc1 	1 

1 the hybrid approach 
　　　　　　　　　　　　　　　　　　　　　　　　　the symbolic knowledge generated by the net can be since its inception  artificial intelligence  ai  is torn extracted  in both versions of htrp  in a way comparabetween two opposing fields: the symbolic paradigm  ble to initial symbolic knowledge implementation in 
 based on logic  and the connectionist paradigm  based on biw  using the above structure. the propagation of the activity of elementary processors. artificial neural networks do not have the expressive 1 microfeatural representations power of general logical representations  since they are 
not adequate for manipulation of high level symbols 	word representation in htrp is adapted from the se-
  fodoi and pylyshyn  1 they are usually preferred mantic microfeature representations used by waltz and in a number of situations  such as pattern recognition  pollack  and mcclelland and kawamoto  1 because they are able to generalize over the inputs  they for the noun. for the verb  the representation is mainly 

are fault tolerant  and they exhibit the ability to learn 
from experience. 
   but neural networks have a disadvantage: often because of lack of transparency it is hard to understand how they build their inner representations. for instance  it is not easy to ascertain the meaning of the connections and 
their weights or the configuration of the hidden layers as 
regards a certain input-output pair. 
   but  the so-called knowledge-based neural networks  which bring the opposing ai paradigms into closer contact  allow for symbolic knowledge to be introduced in as well as to be extracted from neural networks - that is called hybrid approach. 
the extraction of symbolic knowledge from trained 
1 machine learning 
based on franchi and cangado   nouns and verbs 
are accounted for by twenty binary semantic microfeature units each. the following general schema represents the 
nouns: 
  human - non-human 
  soft - hard 
  small - medium - large 
  1-d/compact - 1-d - 1-d 
  pointed - rounded 
  fragile/breakable - unbreakable 
  value - furniture - food - toy - tool/utensil animate 

　for each thematic role there are two 'hidden' rales whose antecedents map the units belonging to the input 
layer and whose consequents map hidden units - one for 
the verb  and the otter for the noun  see figure 1 . bar 
instance  for the thematic role agent in biw  there is no initial rule for the noun  n   because any noun can in principle be an agent. the system  after learning  will decide which nouns could be agents. but for the verb 
  arg 1 has cmtrol of action - on control 	 v   the rule is: 
  direct process triggering - indirect triggering 	if for verb  1 control of action  +  1 direct 
process triggering  +  1 impacting process  +  1 
  direction to source  argl  - direction to goal  arg1  	objective  +  1 interest on process  
  impacting process for arg1 - no impacting process 	then v 
  change of state of arg1 - no change of state 
  psychological state - no psychological state 
  argl has objective - no objective 
  effective action - no effective action 
  high intensity of the process - tow intensity // 1 v  +  1 n  then thematic role = agent. 
1 the learning step 
the training sentences are generated by a sentence generator  alternating verbs and nouns. both semantically sound and ill-formed sentences are generated. for biw  learning begins after the introduction of initial symbolic   argl has interest on process - no interest on process rules as connection weights of the network. the algo-
　again  for each of these subsets  one feature is active  rithm used is the supervised backpropagation  rumelhart and the other is inactive. for instance  in the sense of et al.  1 . after 1 training cycles  the system is sentence  1  above  for break the following features are able to judge  with a high degree of certainty  if a senactive: control of action  direct process triggering  di- tence is meaningful or not  and  if it is  which its thematic rection to goal  impacting process  change of state  no grid is. psychological state  objective  effective action  high in- one interesting consequence of learning is that the tensity  and interest on process. in the sense of sentence system is able to categorize on the basis of the comple 1   the following features are active: no control of ac- mentarity of the verb microfeatures for most subsets. tion  indirect process triggering  direction to goal  im- consider the system without initial knowledge  riw ; in pacting process  change of state  no psychological state  this case  the initial connection weights for each subset of 

no objective  effective action  high intensity  and no interest on process. as one can see  two different readings for the same verb break. 
　but when the user enters the verb break into htrp  the system does not know which break is intended. and  the network input is the  average  of the two readings of break. again  some of the microfeatures will be undetermined. and again  the system will arrive at the missing values for the intended reading of break. 
1 initial symbolic rules 
the htrp  thematic rules  inspired by haegeman 
 1j and mcrae et al.  for 1 types of verbs  1 different verbs and 1 alternative readings  were also implemented. the rules are if-then rules  logical implications   and they are implemented as an and gate  i. e.  if an input is absent  the unit should not be activated. unlike classical logic  each element in the antecedent part of the rules is weighted in a fuzzy way  by the connection weight of the respective element in the network. then  for a unit to be active  all its inputs together should be microfeatures are random. since  during training the sentences exhibited mutually exclusive values within each subset of microfeatures  the final connection weights are found to be complementary in the sense that their respective values are of opposite signals. that is  the network incorporates the complementarity of microfeatures in virtue of its architecture and experience. 
1 final rules 
rule extraction consists in reversing the process of initial rule insertion  in biw. that is  the net weights are assessed and a weighted antecedent is obtained  corresponding to the connection weight. this rule is fuzzy because it allows for weighted antecedents in the production rule. the symbolic knowledge thus extracted from the present connectionist architecture corresponds to the network learning and generalization capacities. as a consequence  the network is able to  revise  the initial symbolic rules. the fuzzy rule extraction from the network  after training  for both versions of htrp is based on fu   setiono and liu   and towell and shavlik. 
rosa and francozo 1 

grammatical  exhibiting the same discriminatory power supplied by linguistic theory. the network is not divided into innate and learned knowledge. instead  positive and negative examples are used to discriminate between grammatically acceptable and unacceptable sentences. 

	verb microfeatures 	noun microfeatures 
figure 1. the connectionist architecture for one thematic role. 
   in htrp  an error output network is implemented  in order to account for this. for a semantically unacceptable input like: 
        1  the stone bought the man the system activates the error output. so  before generating the thematic grid for a sentence  htrp tests the semantic acceptability of such sentence  so that the system only reveals the thematic grid for semantically well formed sentences. 
1 the hybrid approach 
since its inception  artificial intelligence  ai  is torn between two opposing fields: the symbolic paradigm  based on logic  and the connectionist paradigm  based on the propagation of the activity of elementary processors. 
   artificial neural networks do not have the expressive power of general logical representations  since they are not adequate for manipulation of high level symbols  fodor and pylyshyn  1 . they are usually preferred in a number of situations  such as pattern recognition  because they are able to generalize over the inputs  they are fault tolerant  and they exhibit the ability to learn from experience. 
   but neural networks have a disadvantage: often because of lack of transparency it is hard to understand how they build their inner representations. for instance  it is not easy to ascertain the meaning of the connections and their weights or the configuration of the hidden layers as regards a certain input-output pair. 
   but  the so-called knowledge-based neural networks  which bring the opposing ai paradigms into closer contact  allow for symbolic knowledge to be introduced in as well as to be extracted from neural networks - that is called hybrid approach. 
the extraction of symbolic knowledge from trained 
1 	machine learning 
neural networks permits the exchange of information between connectionist and symbolic knowledge representations and has been of great interest to understand what the neural network actually does  shavlik  1 . additionally  a significant decrease in learning time can be obtained by training networks with initial knowledge  omlin and giles  1 . also  the symbolic knowledge can be input into neural networks and then refined after training. 
   in the hybrid approach adopted here  the symbolic knowledge is represented through connection weights between neural network processing units. for instance  a fuzzy logical rule  with weighted antecedents a and b  
and consequent c  
        1   can be represented by a connectionist schema  as shown in figure 1. the rule is fuzzy-like  because wac and wbc  connection weights  are not binary values but real numbers. also  it simulates an and unit  such that only the presence of both inputs a and b causes unit c to be activated. 

   the symbolic knowledge generated by the net can be extracted  in both versions of htrp  in a way comparable to initial symbolic knowledge implementation in biw  using the above structure. 
1 microfeatural representations 
word representation in htrp is adapted from the semantic microfeature representations used by waltz and pollack  and mcclelland and kawamoto   for the noun. for the verb  the representation is mainly based on franchi and cancado . nouns and verbs are accounted for by twenty binary semantic microfeature units each. the following general schema represents the nouns: 
  human - non-human 
  soft - hard 
  small - medium - large 
  1-d/compact - 1-d - 1-d 
  pointed - rounded 
  fragile/breakable - unbreakable 
  value - furniture - food - toy - tool/utensil animate 

   for each of these subsets  only one feature is active  and all the others are inactive. for instance  man is human  soft  large  1-d  rounded  unbreakable  and animate'  stone is non-human  hard  small  1-d  pointed  unbreakable  and tool/utensil. 
   the system also includes ambiguous nouns  so that some of its microfeatures are undetermined. in such cases  the system will arrive at the missing values for the intended reading  because it is fault tolerant. 
the following schema represents the verbs: 
  argl has control of action - no control 
  direct process triggering - indirect triggering 
  direction to source  argl  - direction to goal  arg1  
  impacting process for arg1 - no impacting process 
  change of state of arg1 - no change of state 
  psychological state - no psychological state 
  argl has objective - no objective 
  effective action - no effective action 
  high intensity of the process - low intensity 
  argl has interest on process - no interest on process 
   again  for each of these subsets  one feature is active  and the other is inactive. for instance  in the sense of sentence  1  above  for break the following features are active: control of action  direct process triggering  direction to goal  impacting process  change of state  no 
psychological state  objective  effective action  high intensity  and interest on process. in the sense of sentence  1   the following features are active: no control of action  indirect process triggering  direction to goal  im-
pacting process  change of state  no psychological state  no objective  effective action  high intensity  and no interest on process. as one can see  two different readings for the same verb break. 
   but when the user enters the verb break into htrp  the system does not know which break is intended. and  the network input is the  average  of the two readings of break. again  some of .the microfeatures will be undetermined. and again  the system will arrive at the missing values for the intended reading of break. 
1 initial symbolic rules 
the htrp  thematic rules  inspired by haegeman 
 and mcrae et al.  for 1 types of verbs  1 different verbs and 1 alternative readings  were also implemented. the rules are if-then rules  logical implications   and they are implemented as an and gate  i. e.  if an input is absent  the unit should not be activated. unlike classical logic  each element in the antecedent part of the rules is weighted in a fuzzy way  by the connection weight of the respective element in the network. then  for a unit to be active  all its inputs together should be such that their sum is enough to activate the unit  see figure 1 . 
   for each thematic role there are two 'hidden' rules whose antecedents map the units belonging to the input layer and whose consequents map hidden units - one for the verb  and the other for the noun  see figure 1 . for instance  for the thematic role agent in biw  there is no initial rule for the noun  n   because any noun can in principle be an agent. the system  after learning  will decide which nouns could be agents. but for the verb 
 v   the rule is: 
       if for verb  1 control of action  +  1 direct process triggering  +  1 impacting process  +  1 
objective  +  1 interest on process  then v 
// 1 v  +  1 n  then thematic role = agent. 
1 the learning step 
the training sentences are generated by a sentence generator  alternating verbs and nouns. both semantically sound and ill-formed sentences are generated. for biw  learning begins after the introduction of initial symbolic rules as connection weights of the network. the algorithm used is the supervised backpropagation  rumelhart et al.  1 . after 1 training cycles  the system is able to judge  with a high degree of certainty  if a sentence is meaningful or not  and  if it is  which its thematic grid is. 
   one interesting consequence of learning is that the system is able to categorize on the basis of the complementarity of the verb microfeatures for most subsets. consider the system without initial knowledge  riw ; in this case  the initial connection weights for each subset of microfeatures are random. since  during training the sentences exhibited mutually exclusive values within each subset of microfeatures  the final connection weights are found to be complementary in the sense that their respective values are of opposite signals. that is  the network incorporates the complementarity of microfeatures in virtue of its architecture and experience. 
1 final rules 
rule extraction consists in reversing the process of initial rule insertion  in biw. that is  the net weights are assessed and a weighted antecedent is obtained  corresponding to the connection weight. this rule is fuzzy because it allows for weighted antecedents in the production rule. the symbolic knowledge thus extracted from the present connectionist architecture corresponds to the network learning and generalization capacities. as a consequence  the network is able to  revise  the initial symbolic rules. the fuzzy rule extraction from the network  after training  for both versions of htrp is based on fu   setiono and liu   and towell and shavlik . 
	rosa and 	franc1 	1 

   for riw  the final rules for the thematic role agent are the following: 
'hidden* rules: 
       if for verb  -1 control of action  +  -1 direct process triggering  +  -1 direction to goal  +  -1 impacting process  +  -1 change of state  +  -1 no 
psychological state  +  -1 objective  +  -1 effective  
+  1 high intensity  +  -1 interest on process  thenv 
       if for noun  1 human  +  1 soft  +  1 mejiuro + i.1 large  +  1 1-d  +  1 rounded  +  1 unbreakable  +  1 animate  thenn 
'output' rule: 
if -1 v  +  1 n  then thematic role = agent. 
   notice that almost all antecedents of the 'hidden' rule are negative for the verb. but the antecedent of the 'output' rule  -1 v  is also negative for the verb  which means that the negative signals cancel each other out. 
   notice also that  for the verb  many microfeatures were highly biased by learning: control of action  direct 
process triggering  impacting process  change of state  objective  effective  and interest on process. in relation to the noun rule  the agent learned by the net is mainly medium and animate  and less prominently  human  large  and unbreakable. 
   for biw  that is  with the introduction of initial symbolic rules  for the thematic role agent there is the following final rule for the verb: 
'hidden' rule: 
       if for verb  1 control of action  +  1 direct process triggering  +  1 direction to goal  +  1 impacting process  +  1 change of state  +  1 no psy-
chological state  +  1 objective  +  -1 effective  + 
 1 high intensity  +  1 interest on process  thenv 
   as one can see  considering the initial rule antecedents  all features were highly strengthened by learning  with the exception of impacting process  which rose only from 1 to 1. that is  the system can be said to reinforce the initial features. 
there is a final rule for the noun too: 
'hidden' rule: 
       if for noun  -1 human  +  -1 soft  +  -1 medium + -1 large  +  -1 1-d  +  -1 rounded  + 
 -1 unbreakable  +  -1 animate  thenn 
'output' rule: 
if  1 v  +  -1 n  then thematic role = agent. 
   since the 'output' rule shows a negative antecedent for the noun  -1 n   all the negative weights of the 'hidden' rule antecedents become positive. so  the agent learned by the net is mainly human  medium and animate  
1 	machine learning 
and  with less prominence  soft  targe  1-d  rounded  and unbreakable. 
   notice that there are small differences between the final hidden rules for nouns in riw and biw  although one might expect them to be the same because both for biw and riw no initial rules for nouns are provided. such difference stems from  i  the connectionist architecture employed  which takes into account both verb and noun inputs to activate the thematic role output  see figure 1 ; and  ii  from the backpropagation algorithm  which causes vert  weights to influence noun weights during the error backpropagation step. 
to illustrate and compare the differences between 
ca dt dg im cs np ob ef hi ip i 1 1 1 -1 -1 fr 1 1 1 1 1 1 1 1 -1 1 fb 1 1 1 1 1 1 1 -1 1 1 riw and biw  a summary of the weights for the verb  concerning the thematic role agent  is presented in table 1. recall that these values are used to weigh the microfeatures in the antecedents of the symbolic rules. mf 
note: mf = semantic microfeature; ca = control of action; dt = direct triggering; dg = direction to goal; im = impacting process; cs = change of state; np = no psychological state; ob = objective; = effective; hi = high intensity; ip = interest on process; / = initial weights; fr = final weights for riw; fb = final weights for biw. table 1. a comparison between initial and final weights. 
   notice that  when initial knowledge is input to the system  biw   there is a tendency of strengthening the initial weights. when no initial knowledge is provided  riw   the final weights are quite close to those in biw. this can only be taken as evidence that the final weights reflect the available symbolic knowledge  about a thematic role  from the examples and from the architecture  since in this case the initial weights are arbitrary. 
1 conclusion 
in the realms of connectionist natural language processing  several systems use the notion of thematic role modeling  e.g.  mcclelland and kawamoto   mcclelland et al.   st. john and mcclelland 
  jain   and miikkulainen  . also  at least one recent paper  chan and franklin  1  implementing a hybrid system makes use of the notion of case roles  which is close to the concept of thematic relations. the present system departs from all these in that it relies on the role of semantic entailments in thematic relations  i.e.  in the way it makes use of theoretical knowledge from linguistics. 
   htrp implements a symbolic-connectionist hybrid approach to thematic role processing. in this approach  

the advantages of symbolic systems  ease of knowledge representation  understanding through logical inference  etc.  are combined with the advantages of connectionism  learning  generalization  fault tolerance  etc.  to yield a more discriminating thematic role processing  that is sensitive to the subtleties involved in such linguistic phenomenon. 
   the representation of semantic features adopted in this system would also easily allow for new words to be entered in order to increase its lexicon  once their semantic microfeature arrays are supplied. in htrp a single network accounts for each verb-noun pair; thus generalizing over both nouns and verbs. in fact  this is crucial in dealing with thematic roles  for they are but the generalization of semantic relationships between verbs and nouns. another interesting result that should be emphasized regards riw. even in a system without initial knowledge  the final rules extracted from the network fully correspond to the symbolic theory that explains them. that is  it seems that the htrp architecture together with training is enough for the system to arrive at the correct semantic grid of a sentence. 
acknowledgements 
we thank marcio l. de andrade netto  ester m. scarpa  and plinio a. barbosa  of unicamp  for their extensive comments and inspiration on drafts of this paper. we also thank ijcai1 reviewers  for their very useful suggestions. of course  remaining mistakes are our own. 
