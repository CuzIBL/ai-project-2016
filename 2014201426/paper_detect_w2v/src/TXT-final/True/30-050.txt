 
a model for the formation of situation concepts is described. a characteristic of this form of concept formation is that it does not require instructive feedback. this renders it suitable for concept formation by autonomous agents. it is experimentally demonstrated that situation concepts constructed independently by several agents can convey useful information between agents through a learned system of communication. a relation was found between the development of the learned system of communication and the duration of the situations. 
1 	introduction 
the ability to communicate with others is a manifestation of our intelligence. an understanding of communication therefore contributes to the goals of artificial intelligence. a requirement for higher forms of communication  such as human language  is the development of concepts that are to be communicated. in this paper  a model is proposed that describes the formation of a particular type of concepts. 
　a situation concept is a part of the state of an environment that determines how the environment will present itself to a certain agent in response to  possibly absent  actions of that agent. therefore  a situation concept is an agent specific aspect of the complete state of the environment. in many environments  the state of an environment can not be completely determined from the current sensor inputs. thus  knowledge about the interaction history with the environment yields extra information about the current state. situation concepts can be formed by agents by observing patterns in the sequence of inputs from the environment  actions of the agent  and subsequent evaluative feedback. they allow an agent to predict some aspect of the future  e.g. the evaluative feedback that will follow a certain action  or the next input from the environment given the action. 
　an important characteristic of situation concepts is that they can be developed by autonomous agents  since only evaluative feedback is assumed to be available from the environment. this distinguishes the method from 
1 	cognitive modeling 
traditional concept learning methods such as decision tree learning  see e.g.  quinlan  1    which require instructive feedback and thus are a form of supervised learning. l although unsupervised learning methods  such as clustering  can also be viewed as methods for concept formation  these are less suitable as a basis for an agent that has to adapt itself to an environment  since feedback on how well the agent is performing can by definition not be taken into account. 
　it is assumed here that an autonomous agent should learn to produce successful behavior based on evaluative feedback. this feedback may be provided directly by the environment  as is usually assumed in reinforcement learning  or it may be determined by the agent itself based on its internal state and its interaction with the environment  which seems to correspond better to how humans and animals function. when such an agent adapts its behavior to an environment  its choice of actions will come to depend on its interaction history with that environment. however  the number of possible interaction histories may be large  even if histories of small length are considered  so that the exact same history is unlikely to recur frequently. in the interest of learning  it is therefore necessary to generalize. 
　some generalization methods for reinforcement learning can be used as a basis for situation concept formation. a prerequisite is that the representation of the states of the environment is adapted to the learning problem  and provides a division of the interaction space into regions  such that an agent only needs to consider a region within that space  and not the specific interaction history  a point within that region   in order to decide which action to take. a good example of such an algorithm is the u-tree method  mccallum  1   which uses the kolmogorov-smirnov test to determine whether the distribution of long-term expected rewards within a region of the state-action space  determined by features on the interaction history  varies or not. however  most generalization methods for reinforcement learning can not be used as a basis  either because the representation of the interaction space is not adapted to the learn-
 for an exposition of the difference between evaluative and instructive feedback  see e.g.  sutton and barto  1   pp. 1. 

ing problem  e.g. plain discretization  cmac  albus  1    or because no crisp division of the state-action space is used  e.g. neural networks . 
　in cognitive science literature  many models for concepts are discussed  see e.g.  lakoff  1; van orman quine  1; putnam  1 . when viewed as a cognitive model for a specific type of concepts  situation concepts distinguish themselves from other models by the level of detail at which they are specified. since this level allows direct implementation  their validity can be tested in computational experiments  as testified by this paper. it should be emphasized that situation concepts are an idealized model of a particular class of concepts  and are not claimed to be a general model for the formation of concepts. nonetheless  the possible forms of situation concepts are diverse  as may be judged from the examples in the paper. 
　situation concepts are especially suited to serve as a basis for communication. in the model of language evolution investigated here  concept formation interacts with a process linking concepts to words or signals  see  steels  1; steels and vogt  1 . in literature on the evolution of language  communication often corresponds directly to actions  which limits communication to the instruction of other agents. examples include  werner and dyer  1   where sounds tell agents in a. simulation how to move to the emitter of the sound   yanco and stein  1   where a leader robot instructs a following robot what way to move  and  oliphant  1   where concepts are abstract and are modeled as having a one to one correspondance with situations. an exception is  maclennan  1   where the term situation is also used to describe what the symbols that are communicated represent. the meaning of those situations is quite different from situation concepts though  since they are equal to the input of the agent  hence no concept formation is involved. in  billard and hayes  1   an interesting experiment is described where a robot develops concepts as regularities in its own behavior. this is possible because actions are selected by a process independent of concept formation  which explains why the problem mentioned above with relation to unsupervised learning plays no role here. since the meaning of concepts in that work  objects in the environment of the robots  is fixed in advance for one of the robots  the teacher  though  it does not deal with the initial creation of the concepts  with which we will be concerned here. 
　situation concepts are constructed individually by each agent. since the concepts are based on experience with the same environment  there should be strong similarities between the conceptual systems of different agents  given that they are of the same type or species. this provides a basis for the development of communication. when agents link signals they receive and produce to their current situation  a system of communication may result where the individual situation concepts of agents are associated with shared signals. this principle is demonstrated in a simulated environment. the question that will be investigated here is whether the communication that results from this process is useful. 
　the structure of the paper is as follows. section 1 formally defines situation concepts in general and describes how agents form a specific type of situation concepts in the experiments of this paper. section 1 describes how agents adapt associations between concepts and signals in order to develop a system of communication. section 1 explains how agents may utilize situation concepts once a system for communicating them has been learned. the setup of the experiments is described in section 1. in section 1  the benefit of communicating situation concepts is measured. finally  section 1 presents conclusions drawn from the experiments. 
1 	formation of situation concepts 
in the most general formulation  a situation concept is a subset of the possible histories of an agent's interaction with its environment with the property that knowing to which situation concept the actual history of interaction corresponds  allows the agent to predict  some aspect of the future. as an example  let's consider the advent of a thunder storm. both seeing a flash of lightning and hearing a roaring sound of thunder are indicators that in a few moments  it may start to rain. thus  these observations may be grouped together to form a situation which has the property that a shower is likely to arrive within short  whereas this possible future event will be less likely in the case of a bright blue sky. in this example  the situation is based on observations in the recent past  and the prediction concerns future observations. actions of the agent or evaluative feedback played no role. another example is the schema mechanism described in  drescher  1   where the context and an agent's action are used to predict the result of the action. in that framework  a context is specified as a set of conditions and can be viewed as an instantiation of situation concepts  since it defines a subset of the possible histories of interaction  viz. the current input  and has predictive value. 
　to formally describe interaction histories  time will be discretized here  which is a simplification of situation concepts in general. at time t the complete interaction history hmax is defined as the following set of symbols: 

resenting the input  action and reward  an evaluative feedback  at time t. situation concepts are defined for a subset h of this complete history: 

　a situation concept sp is a membership function that accepts a value for each element of an interaction history 
h within the corresponding domain   i m for xt  an for  and r for   and yields a boolean value. if and only 
if this value is true at time t  the situation concept applies; equivalently  it may be said in this case that the agent is in situation 
	de jong 	1 

　in the rest of the paper  the interaction history of situation concepts will consist of the current input from the environment  so that . they are cho-
sen such as to allow to predict the subsequent reward given an action the agent may choose. in the experiments  the formation of situation concepts is based on the adaptive subspace algorithm of  de jong and vogt  1   which recursively splits a space into two halves in a selected dimension  based on some split criterion. the split criterion here is whether the distribution of rewards over the sensor space differs between the two halves  which yields an algorithm similar in function to the previously mentioned u-tree algorithm and the continuous state generalization algorithms in  uther and veloso  1 . initially  the complete sensor space is a single region. regions have a one to one correspondance with situation concepts  and hence there is a single situation concept. when the distribution of rewards varies substantially within a region of the sensor space  this region is split in half  thus replacing it with two halfsized regions. this principle is applied recursively  and terminates when each situation corresponds to a region of the sensor space within which rewards are distributed homogeneously. 
　the result of concept formation is a tree which divides the sensor space into situations  represented by internal nodes  and for each situation contains a subtree representing possible actions in that situation  where each leaf stores an estimation of the reward following the selection of the corresponding action in that situation. an example of sue!  a tree is shown in figure 1. the actions that are distinguished depend on the situation and are constructed based on the same principle as the situations. 
   action selection depends solely on the situation  not on the specific input determining the situation. the tree of situations and actions is traversed from left to right  following the conditions in the nodes that apply to the current input. this yields the current situation  represented as an internal node of the tree. the possible actions are now represented in the leaves of this node's subtree. greedy action selection would select an action determined by the leaf with the highest estimation of the subsequent reward. for learning though  exploration is necessary. in the experiments here  the choice of explorative actions is based on the estimation error when the action was last selected and the time since it was last selected  and hence combines error based and recency based properties. for an overview of other exploration policies  see  thrun  1 . 
1 	development of communication 
situation concepts organize the possible inputs an agent may receive into groups such that experience gained with a certain input influences the reward estimation of similar inputs. apart from speeding up learning  this form of generalization provides a basis for the development of communication. although the specific concepts agents create may differ  they result from a search for patterns 
1 	cognitive modeling 
	sensor space distinctions 	  action space distinctions 

figure 1: example of a tree that defines situation concepts. nodes to the left of the dotted line divide up the sensor space by constraining the range of a sensor   f and - represent the outcome of the inequality   nodes to the right divide up the action space. the dotted rectangle contains four situation concepts. 
in interactions with the same environment. if a relation between the individual concepts of the agents and a shared set of signals can be found  this would allow the agents to 'speak a common language'. to this end  agents maintain a set of signals for each situation. an association between a signal and a situation has a use score and a success score. when an agent is in situation 1  it selects a signal associated with s and emits it. after every agent has produced the signal corresponding to its situation  every agent receives the collection of signals produced. upon receiving these signals  each agent increases its use scores for the associations between these signals and the current situation. since the conceptual systems of agents may differ  the signals associated with a certain state of the environment may differ from agent to agent. 
1 	benefitting from communication 
the ability to communicate enables a capacity of gaining knowledge or information that cannot be attained through use of the ordinary perceptual devices. this advantage explains why so many animals  including humans  have retained the faculty to develop communication in the course of evolution once it evolved. an inspiring example is the alarm call system of vervet monkeys. ingenious experiments involving playing back the calls produced by these monkeys show that these animals 

have a warning system with specific calls for different kinds of predators  seyfarth et a/.  1 . this example demonstrates the principle of how situation concepts can be useful when communicated. when a monkey did not detect the threat of an approaching predator  successful interpretation of the alarm calls produced by other community members may induce awareness of its perilous situation. put in abstract terms  the signals an agent receives from the other agents allow it to deduce that its situation is different from what it had observed using ordinary perception. 
　it should be understood that the ultimate meaning of a situation concept is determined by its predictive value  and not by the pattern in interaction history that has been observed to be correlated with this aspect of the future. in terms of the alarm calls example  the situation corresponds to the presence of a predator  rather than to the observation of the predator by a monkey  even though situation concepts are by necessity initially constructed as correlations between interaction histories and consequences. therefore  when a significant aspect of an agent's environment cannot be perceived directly through perception  communication may be the only way to determine the actual situation. 
　the benefit of communication may surface when sensor information is incomplete. the resulting uncertainty may be partially resolved by means of communication. once a coherent mapping between situations and signals exists  the likelihood of being in a certain situation given the signals an agent receives can be determined using hayes' formula: 
where is a signal that was perceived  and u is a situation. if the probability of a certain situation given the signals is high enough  the agent may decide that it is in that situation  and not in the situation indicated by its sensors  or  in general  its interaction history . 
　the use of hayes' formula assumes that a coherent mapping between sit nations and signals is already available. however  since this is initially not the case  agents need to adapt their private associations between situations and signals. depending on the process of adaptation  a coherent mapping may or may not emerge. two sources of information are available as input to this adaptation process. firstly  an agent may use its sensors to determine its situation and update the use scores of the associations between that situation and the signals it receives from the other agents. secondly  the situation may be determined from the signals emitted by the other agents. to calculate the probability of being in a situation given the signals using bayes' formula  a linear combination of the use and success scores is filled in for  in the above formula; the remaining two values are obtained from counts of the occurence of situations and signals. this second source of information indicates more directly whether the link between a signal and a situation can increase the performance of the agent. concretely  the estimated value of the action and the actual reward following the action are compared to decide whether the determination of the situation was correct or not. if the magnitude of the difference is small  the success scores of the associations between the signals and the situation should be increased. conversely  if the absolute difference exceeds a threshold  they should be decreased. sending signals is not followed by evaluation  and hence does not influence scores. 
　figure 1 shows an outline of the algorithm specifying when the situation is determined based on signals  and how association use and success are updated. 

figure 1: an outline of the algorithm. the main choice is whether the agent uses signals or sensors to determine its situation. this choice determines whether to adapt the use or the success of the association between the situation and the signals received from other agents. 
1 	experimental setup 
in the experiments  five agents can move horizontally and vertically on a grid  see figure 1. input consists of the agent's own horizontal and vertical coordinates  and an input indicating the type of a predator that is present or the absence of predators. actions consist  of moving one step  left or right or staying  and selecting a vertical position. 
　a predator of random type is created in 1% of the timesteps at a random horizontal position  provided no predator is present yet. three different types of predators exist. the vertical position of an agent determines whether it is safe from the predator or not  and since the number of vertical positions is three  each position corresponds to a single type of predator. the horizontal position of an agent determines whether it can see the 
	de jong 	1 


figure 1: visualization of the experimental environment. horizontal positions determine the visibility of the predator  vertical positions function as abstractions of hideaways  only the middle row is safe here . 

figure 1: histograms of the fraction of successful determinations of the situation based on communication when a predator first arrives and is invisible to the agent. each line is the average of five repetitions of the same experiment. the interval during which a predator is present was varied between t = l and t=1. the graph shows that when the interval is long enough  agents benefit from communication and determine the right situation in substantially more than the fraction of 1  dotted line  that would be expected without communication. 
predator. the scope of the agents' perception amounts to 1% of the field; hence  for each agent  1% of the predators are expected to be invisible. when a predator is invisible to an agent at creation time it will remain so until it is removed again  i.e. until the end of the situation. 
1 	measuring the benefit of 
communication 
the previous section demonstrated how communication may be of benefit to an agent. our current purpose will be to investigate whether this benefit does indeed arise. if such a benefit can be measured convincingly  this would indicate that an effective system of communication has emerged. 
　if the predator is invisible to an agent  there is a chance of 1 in 1 that the agent can randomly select the right vertical position. but if the agent has the right vertical position in significantly more than a third of all cases where a predator is present and invisible to the agent  
1 	cognitive modeling 
this is an indication that the agent benefits from the signals it receives from other agents. however  this way of measurement has a possible problem. if a predator arrives and is invisible to an agent  the agent will receive a low success. since the processes of learning and adaptation are active continuously  the agent's estimation of the position's attractiveness will slowly but surely decrease. when the value of the action corresponding to the position has decreased below another action's value  and the agent will start to choose that other action  and move to another position. the speed of this process may be increased by the exploration mechanism  which will at times select the action of moving to another position upon which the value of that action increases  since its reward is higher than the original estimation. because the number of positions is limited  the agent will eventually hit the position where it's safe from the predator. 
　the problem can be circumvented in the following way. at the first timestep after the creation of a predator  the only information available to an agent for which the predator is invisible consists of the signals that are produced by other agents that can sec the predator. thus  if the agent moves to the correct position at this timestep more often than in a third of the cases  it must have extracted information from communication. since the event that a predator is created and is invisible to an agent that uses the signals to determine its situation at that same moment is rather infrequent  the number of measurements is scarce. therefore  this information is measured over a period of 1 timesteps. 
　there are numerous factors that influence the course of the experiment  including the increase and decrease of association strengths  removal of infrequent signals  and selection of the signal an agent produces. however  a single factor has been found to be very strongly related to the development of successful communication. this factor is the duration of a situation  and the relationship can  besides the feasibility of learned communication of situation concepts  be seen as a general result of this research. 
　experiments have been performed where the duration t of the intervals during which a predator is present varied from a single timestep up to 1 timesteps. to visualise the information  a histogram has been made where the fraction of correct situation determinations is calculated over bins of 1 timesteps. in order to get a more reliable estimate  the experiment has been repeated a number of times for each parameter setting. because of the duration of the experiments  the number of runs per parameter setting was limited to 1. in the graph in figure 1  each line represents the average of five runs with different random seeds for a chosen duration of situations. 
　the graph shows how the benefit of communication depends on the duration of the interval. when predators stay for only a single timestep  the fraction of successful determinations of the situation based on signals in case of an invisible predator stays well under one third  which means that the agent is doing worse than when it would 

randomly choose its position. however  as the duration of the intervals increases  so do performance and speed of convergence. for intervals of 1 or more timesteps  the fraction of successful guesses is already higher than a third  and for intervals of 1 or more steps the agents reach perfection in determining which predator is present based on communication. 
1 	conclusions 
a model for the formation of a particular type of concepts  called situation concepts  has been described. situation concepts capture information about how the environment of an agent will respond to its actions. they can be constructed by analysing patterns in the history of interaction between the agent and its environment. apart from providing a particularly detailed model of concept formation  situation concepts are especially suited to serve as a basis for communication. since agents interact with the same environment  successful communication of the situation allows agents to be better informed about their environment than their sensors alone would permit  which improves the ability to select appropriate actions. 
　both the formation of situation concepts and the subsequent development of learned communication have been demonstrated in a simulation experiment. moreover  the possible benefit of communication as an extra information source has been observed in the experiment by monitoring the actions of agents at moments when the sensors provided incomplete information. finally  a strong relationship was found between the duration of situations and the development of successful communication. 
