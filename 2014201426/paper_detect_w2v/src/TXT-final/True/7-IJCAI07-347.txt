
this paper presents a distributed knowledge representation and data fusion system designed for highly integrated ambient intelligence applications. the architecture  based on the idea of an ecosystem of interacting artificial entities  is a framework for collaborating agents to perform an intelligent multi-sensor data fusion. in particular  we focus on the cognitive layers leading the overall data acquisition process. the approach has been thoroughly tested in simulation  and part of it has been already exploited in successful applications.
1 introduction
the ambient intelligence  ami  paradigm highlights the need for autonomous and distributed systems that are able to  understand  users' intents using sensor data collected by a network of heterogeneous devices and to exhibit an intelligent behavior to provide users with context-based services  possibly taking decisions on their behalf.
¡¡during the last few years  several approaches have been proposed to develop the idea of a smart space  i.e.  a functional interface towards services that are aimed at improving the users' quality of life. this concept arises from the mutual role played by different disciplines  encompassing topics ranging from health care monitoring  barger et al.  1  to mobile robotics  broxvall et al.  1    from intelligent surveillance applications  kong et al.  1  chen et al.  1  to knowledge representation  augusto and nugent  1 . the complexity of ami systems requires an efficient management of the information flow exchanged by the involved services: pervasive and distributed systems can be considered truly  intelligent  only if a close interaction among the several architectural layers  and their subsystems  is achieved. moreover  the related increased complexity of the networks connecting sensors and actuators requires the combination of possibly ambiguous information. as a consequence  reliable data fusion techniques must be used as well.
¡¡the aim of a data fusion process is to maximize the useful information content acquired by heterogeneous sources in order to infer relevant situations and events related to the observed environment. in order to be effective  data fusion does not operate in isolation: on the contrary  it must be supported by prior knowledge guiding data interpretation  and it must coexist with a reliable architecture providingdata acquisition  filtering  etc.
¡¡several data fusion models have been designed and in part successfully used in different applications reported in literature. in particular  the extended jdl  joint directors of laboratories  model  white  1  received great attention: hypothesizing five layers occurring in a typical information acquisition process  jdl characterizes heterogeneous processes using the same functional framework. present architectures for ami mainly address data fusion at the numerical level  usually exploiting sound and well-defined techniques like bayesian inference  such as the well known kalman filter  dhaher and mackesy  1    parameter estimation  kong et al.  1   fuzzy logic  chen et al.  1   hagras et al.  1  or other methods  disregarding data fusion at the symbolic level.
¡¡in this paper we propose a multi-agent cognitive architecture aimed at designing integrated ami applications. while in section 1 we introduce the main concepts related to the architectural approach  in section 1 we focus on its data fusion capabilities distributed throughout the system detailing the representation at the symbolic level. next  actual implementation and experimental results are presented and discussed. conclusion follows.
1 an ecosystem of artificial entities
the presented architecture is designed to support numerical as well as symbolic data fusion. in particular  data fusion is considered as a decentralized process managed by several cognitive-orientedtasks. an ecosystem  according to  odum  1   is  an area of nature that includes living organismsand non-living substances that interact to produce an exchange of materials between the living and non-living parts . in ami this definition can be extended to support the intuition that the smart space is an ecosystem whose artificial entities interact for the fulfillment of their goals: one of them is the  well being  of the users.
¡¡the basic building block of our  ecological space  is the concept of  agent . therefore  a smart space can be modeled as a collection of agents {¦Á} attending different tasks. agents can be further classified into two disjoint sets: whilst device-related {¦Ád} agents manage sensors for data acquisition or actuators  cognitive {¦Ác} agents perform data fusion and apply control rules to guide the system behavior.
¡¡more specifically  in the context of an ami system  {¦Ád} agents interact with hardware devices  thus acting as the bridge between the physical world and the cognitive layers of the architecture. while dealing with device control  they can also perform preliminary data analysis and react to emergency situations using simple decision making procedures  e.g.  checking if a numerical value is over a given threshold   or by providing inputs to cognitive agents. {¦Ác} agents are aimed at applying given control rules to incoming data in order to issue low level references back to {¦Ád} agents. they are organized in specialized networks performing tasks related to data filtering  feature extraction  symbolic inferences  knowledge representation  data fusion and planning.
¡¡regardless of the category  each agent ¦Áj can be formally defined as a 1-element vector    where ¦È specifies the agent capabilities  ¦Ã is a set of goals that ¦Áj can contribute to achieve  and ¦É and ¦Ø are operators returning  respectively  the set of data needed by ¦Áj to perform its tasks and the set of data produced by ¦Áj. agents can aggregate in more complex niches  characterized by a common goal g to fulfill. according to the above definition of smart space based on an ecological approach  we define a goal g as the result of the cooperation of n agents. in particular  g = ¦Ø ag   where ag = {¦Áj : j = 1 ... n} is the niche of the involved agents  and ¦Ø is the previously introduced operator returning the relevant output data of ag.
¡¡niches are the ecological counterpart of the concept of  subsystem . from a broader perspective  niches themselves can be modeled as agents and  as such  they are possibly part of larger niches. consider  for example  a surveillance system based on several sensors: laser rangefinders  cameras  etc. according to our approach  it can be viewed as a niche composed by a collection of simpler cooperating agents  some responsible for providing feature-based information  others for data fusion  etc. these considerations lead us to use indifferently the generic term  agent  in the following discussion  and to adopt a recursive definition of agent  ¦Án+1 = ag = {¦Áj : j = 1 ... n}. an exact formalization is outside the scope of the paper.
¡¡it is worth noticing that the given definitions do not assume any specific restriction about agent situatedness or inter-agent communication. in particular  it seems reasonable to assume that {¦Ád} agents should be considered embedded in the devices they are dealing with. for example  an agent managing analogical data originating from a temperature sensor will reside on the board which performs signal acquisition. no assumption is made about embodiment of {¦Ác} agents. again  a kalman filter or an entire localization system used for people tracking could be scheduled - in principle - on a workstation which is not physically located within the smart space. nonetheless  if cooperating agents can be distributed in a network according to specific needs  we must ensure that information among them can be shared in some way. thus  in the following  we assume that  for each pair  i j  of communicating agents  there exists a communication channel ci j   formally   ¦Ái ¦Áj ci j ¦Ái ¦Áj    where ¦Ái and ¦Áj are cooperating agents such that  a subset of  ¦É ¦Ái  is provided by  a subset of  ¦Ø ¦Áj  or viceversa.
1 the ecosystem as an integrated model for data fusion
the jdl extended model is a five-layers architecture specifically designed to deal with heterogeneous information provided by multiple sources. in particular  whilst base layers deal with data segmentation  feature extraction and symbol grounding  advanced layers are designed to operate on symbolic information and metadata: e.g.  finding relationships between symbols  adaptating to user needs through learning  etc. in the following  the data fusion capabilities distributed throughout the proposed architecture will be discussed with respect to the five layers of the jdl model.
1 level 1: sub-object assessment
level 1 involves acquiring  filtering and processing raw data in order to extract feature based information. since the goal of this level is to provide level 1 with manageable information  no semantic meaning is assigned to the features. in our architecture  level 1 capabilities are achieved through a tight coupling between device and cognitive agents. in particular  suitable niches are designed according to the goals of level 1  i.e.  arranging incoming data in predefined formats. raw data coming from {¦Ád} are usually preprocessed and then  if necessary  sent to the proper cognitive agent for feature extraction. usually  data related to environmental sensors  e.g.  temperature or smoke sensors  do not need further processing  and can be directly exploited by numeric or even symbolic data fusion techniques. on the other hand  other kinds of data  e.g. provided by laser rangefinders or cameras  need feature extraction techniques in order to be useful for the information acquisition process  i.e.  manageable in real time .
¡¡recall the previously introduced example of a surveillance system based on laser and camera data. level 1 could involve the fulfillment of the goals gl and gbb  respectively  to obtain lines from range data and bounding boxes from images  assumed that lines and bounding boxes are used as features . the first goal is solved by instantiating the following niche  or agent  ¦Álfe =   where lfe stands for  line feature extractor    is a laser device and  is an agent implementing a line extraction algorithm. analogous considerations hold for a bounding box extractor agent ¦Ábbe.
1 level 1: object assessment
the main objectives of level 1 are the combination of data acquired by level 1 and the maintaining of coherent models for data and symbols. in particular  this level addresses topics related to numericaldata fusion and data association  and then the symbol grounding problem  harnad  1 .
¡¡numerical data fusion techniques and data association do not deserve further investigation in this paper  being well studied in literature. it suffices to note that  with respect to the problem of tracking the user metric position through laser and/or cameras  at this level it is possible to combine in a new niche a level 1 niche with a suited collection of agents  e.g.  a kalman filter agent and a motion model agent ¦Ácmm . the symbol grounding problem is defined as  the process of creating and maintaining a correspondence between symbols and sensor data that refer to the same physical object represented within an artificial system   harnad  1 . still unresolved in its general formulation  the symbol grounding problem arises whenever a symbolic component is added to an artificial system.
¡¡our architecture deals with symbolic knowledge representation and data fusion by introducing a cognitive agent ¦Áckb managing a knowledge base described using a description logic. description logics usually consist of a terminology box  tbox   representing concepts  descriptions and their relationships  roles   and an assertional box  abox   describing the actual scenario in terms of the involved concepts and descriptions. tbox and abox must be carefully designed for the problem at hand. therefore  a brief description of the scenario we consider is necessary. we focus on the problem of active monitoring of aging and disabled people: in particular  we want to design a pervasive system supervising their activities and reacting to emergency situations.
¡¡the tbox allows level 1 symbolic data fusion by implementing two layers: a representation of the smart space  i.e.  objects  of the physical world and devices  which is updated by sensors  and the data fusion structure  responsible for creating meaningful instances of concepts from individual symbols originating from sensor data. corresponding instances are created within the abox. in order to update the abox in real time  we assume the availability of a comprehensive niche of agents providing ¦Áckb with heterogeneous data. the aim of is to perform fusion of simple information provided by a redundant network of devices. describing in detail all the concepts used in the tbox is impossible within the scope of this paper. therefore  we only briefly discuss concepts which will be useful in later paragraphs.
modeling the smart space
in order to arrange sensor data in semantic structures  the tbox first represents the entire smart space using a topological representation. it is divided in places  by means of the place concept   and then each place in areas. specific definitions of area  e.g. toilettearea or bedarea  are defined. for each physical device type  e.g.  lasers or cameras  but windows or doors as well   a corresponding device concept is available in the tbox. a device is defined as an object with a position in the environment and an actual state  updated regularly by the proper niche through an established communication channel. devices are classified in sensordevice  characterized by an influence area   i.e.  their scope in the environment modeled as a collection of areas: in al syntax   infarea.area   and in actuatordevice. for each sensor or actuator  a corresponding child of device is introduced  e.g. laserdevice or windowdevice.
¡¡in our architecture  each device is managed by a specific agent. an agent is defined using an al definition corresponding to the one introduced in section 1  using roles linking to the concepts capability  goal  and data. next  a deviceagent is modeled as a child of agent with an additional role specifying its controlled device. for each device concept  e.g.  laserdevice   a corresponding deviceagentis introduced e.g.  laserdeviceagent   characterized by a corresponding specification of data. as an example  consider a line based feature  as providedby ¦Álfe  see section 1 : in al syntax it is modeled as a child concept of data  characterized by specific information related to the feature itself  e.g.  distance  direction  etc.  through the use of roles. finally  the user concept models human users monitoredby the system. moreover action is used to model user interactions with the environment  e.g. go  cook  etc.
¡¡in this layer  the abox contains instances of the concepts device  agent  area  data  etc. sensory data are mapped to instances of data  thus updating specific roles of device instances. therefore  they are not really given a semantic meaning. for these reasons  this layer does not suffer from the symbol grounding problem  because association between sensor data and symbols is designed a priori.
a symbolic data fusion structure
symbolic data fusion is achieved through the well known mechanism of subsumption  which is the main reasoning scheme of description logic-based languages. given two concepts  namely c1 and c1  we say that c1 is subsumed by
c1  and  using al syntax  we write is more general than or equivalent to c1. specifically  the subsumption operates on the descriptions of the given concepts. in the following  given a concept c  we will denote its description d by appropriately defining an operator ¦Ä such that d = ¦Äc  and its instances i by an operator ¦Î such that i = ¦Îc.
¡¡let's start by an example  considering again the problem of user position tracking. suppose we are not interested in metric information; instead  the knowledge of the areas visited by the user is sufficient. at our disposal we have three sensors: one camera and two pir  passive infra red  detectors. in our architecture  a niche could be arranged as follows. three device agents  ¦Ádcam  ¦Ádp1 and ¦Ádp1  are present. ¦Ádcam provides a cognitive agent ¦Ácbbe with raw images. ¦Ácbbe extracts bounding boxes from the moving objects which are then passed to another agent ¦Ácblob  able to extract color blobs from the bounding boxes. these data are used to associate a specific bounding box with a user  whose dress colors are known. no spatial information is provided: if a user is within the scope of the camera  only the place in which he or she is can be inferred  not a specific area. the details of the process are not really relevant: it could be possible as well to use intelligent wearable technology and rfid tags to perform this association. the symbol grounding problem which should arise is thus simplified by the redundancy of the sensor network. on the contrary  and ¦Ádp1 are not able to infer user identity  but they can provide boolean information about the presence of someone in a specific area  according to the sensor range .
¡¡in the abox  cameradev is a cameradevice  while pirdev1 and pirdev1 are instances of pirdevice. the niche of cognitive agents composed by ¦Ácbbe and ¦Ácblob is abstracted by functionality in useridagent  controlling cameradev. useridagent provides data about user identity  i.e.  instances of the cameradata concept. pirdev1 and pirdev1 are managed by piragent1 and piragent1  respectively. moreover  a user is characterized by a role id specifying its identity  such that  id.cameradata  and by a position i.e.  a collection of areas.
¡¡the data fusion process is then managed by checking the result of subsumption of the infarea role of each device  see algorithm 1 . the cameradata concept is used to identify the instance of user whose position is to be computed. moreover  the user position is initialized to the description of the cameradev.infarea role. assuming that the camera is able to observe three areas  namely area1  area1 and area1 in the abox  the description d is inizialited to area1 area1area1. then  for each pirdevice such that something was detected  the role infarea is checked. again  assuming that dp1 = ¦Äpirdev1.infarea = area1area1 and dp1 = ¦Äpirdev1.infarea = area1  we have d  dp1  dp1. as a consequence  dp1 = area1 is the new user position.

algorithm 1 compute user area

require: id = ¦Îcameradata; p1 p1 = ¦Îpirdata
ensure: user area
1: for all u such that u = ¦Îuser do
1:	if id ¦Äuser.id then 1:	d = ¦Äcameradev.infarea
1:	for all p such that p = ¦Îpirdevice do
1:	if d ¦Äp.infarea then
1:	d = ¦Äp.infarea
1:	end if 1:	end for
 1:	end if 1:	¦Äuser.pos = d
1: end for

¡¡generalizing  symbolic data fusion processes can be developed by adding proper cognitive agents cooperating with ¦Áckb  implementing the required algorithms. for example  algorithm 1  computing an user position  can be managed by a cognitive agent ¦Áccua  operating on the knowledge base. moreover  because for each cognitive agent there is a symbolic counterpart within the knowledgebase  each data fusion process can be thought of as an epistemic operator k operating on concepts described by the input and output data of the corresponding ¦Ác when a particular configuration of sensor data is updated within the knowledge base.
1 level 1: situation assessment
the main goal of this level is to find relationships among level 1 objects. again  this level is to be modeled on the basis of the level 1 entities  according to the specific scenario. as previously pointed out  we are interested in tracking  sequence of  user situations in order to detect and react to arising anomalies. for these reasons  we provide the tbox with anotherlayer modelingthe situations we want to monitor. because we are using a descripion logic-based language  we implicitly obtain a hierarchical representation.
modeling the situations
we start by defining the situation concept  related to a user. next  we further detail this concept on the basis of the user position  i.e.  area . thus  we can define situations like neartoilette  inbed  nearstove etc. these concepts are characterized by the role in restricted to be  respectively  toilettearea  bedarea  stovearea etc. of course  this approach can be iterated: the situation nearstove is specialized in cooking  cleaningstove  etc.  e.g. on the basis of data coming from a smoke sensor placed on top of the stove.
¡¡despite its simplicity  this tree-like layer proves to be effective in simulation experiments. moreover it is characterized by a number of advantages compared to other more complex models:  i  it is easily manageable and extensible: new situation branches can be added by creating new concepts  given that the system is able to distinguish among different situations through  a combination of  sensor data;  ii  its creation can be automated: actual work is focused on creating decision trees from data sets obtained in simulation whose nodes are concepts conveniently defined;  iii  using the subsumption  a system exploiting the tree for managing an active monitoring system can be easily implemented.
¡¡within the abox  we have a generic situation s such that s = ¦Îsituation  corresponding to u = ¦Îuser. assume now that we want to track the user activities in the kitchen. the following example  although incomplete  explain how the data fusion process is carried out at this level. suppose that we inferred the user position to be stovearea  using algorithm 1  implemented by a cognitive agent ¦Áccua. in other words  an operator kcua was fired  which updated u.
¡¡basically  for each epistemic operator k relative to a user u it is possible to derive a new description to be added to its situation s. obviously  this description  which we define as ¦Äk  is operator dependent. this implies that  for each branching concept of our situation tree  we must implement an epistemic operator k providing the necessary ¦Äk to further detail the classification  i.e.  a corresponding ¦Áck is to be istantiated  conveying the required information to perform data fusion.

algorithm 1 classify situations

require: k;id
ensure: classification or alarm
1: if k is fired then
1: s = ¦Îsituation : id = ¦Äs.id
1:	¦Ä	¦Ä	¦Äk
1:	ifthen
1:unexpected classification1:end if1: end if

¡¡using the information provided by kcua  it is inferred that s  nearstove. according to the situation tree  this concept can be specialized in cooking or cleaningstove. a new epistemic operator  kss  is thus introduced. it corresponds to a niche of agents communicatinginformation about the detection of smoke by a specific sensor located over the stove. this operator provides the system with a description ¦Äkss used  e.g.  to classify the user situation s as cooking. the overall process can be modeled at the metalevel using a new epistemic operator kc  where c stands for  classification   implementing algoritm 1. if ¦Äs is inconsistent  an alarm can be raised.
detecting sequences of situations
as an example of how to use the symbolic data fusion mechanism presented so far  we focus in this section on the problem of detecting classes or sequences of situations. this task can be accomplished by adding new concepts to the knowledge base and new corresponding operators. sequences of situations are modeled using the sitseq concept  which is a collection of situations managed by a role madeof such that  madeof.situation. a particular sitseq is monitoredsitseq  specifying the interesting situation to be monitored through the role interesting.
¡¡when kc is fired  the corresponding situation instance is added to the madeof role. in order to detect sequences  several approaches are equally legitimate. for example  the frequency at which situations occur is an important indicator of periodic user behaviors. consider the problem of monitoring user health status by checking its visits to the toilette. this can be achieved by instantiating a new concept  toiletteseq  characterized by  interesting.neartoilette. each time the madeof role is updated  its definition is compared to ¦Äinteresting. by applying a new operator ka implementing an alarm condition  based  e.g.  on the frequency of the occurrences of the interesting situation in ¦Ämadeof   it is thus possible to fire specific alarm behaviors. for example  if the user is living in a private apartment within an assisted-living facility  a remote human supervisorin the nurserycan be notified about the user problems.
1 level 1: impact assessment
the level 1 of the jdl model is responsible for predicting the effects of the system behavior over the entities  devices and users  modeled by the system itself. each device is augmented by a description of its behavior modeled as a state machine. the purpose of this representation is twofold:  i  modeling each device as a fluent  i.e.  an entity whose state changes in time  in order to reason at the temporal level;  ii  determining expected state values given the actual state and inputs  thus being able to detect device faults and react accordingly. this design choice can be extended to involve a planning system  embedded in the representation itself  able to predict the sequence of actions  and  above all  their supposed effects on the environment and users  necessary for the fulfillment of a givengoal. the system can be implementedin practice by defining a new operator kp to perform the planning process. our approach is very similar to the one described in  mastrogiovanni et al.  1   thus not deserving further details.
1 level 1: process refinement
level 1 deals with topics ranging from learning to input refinement or inter level information flow management. as previously discussed in section 1  learning is the focus of actual work  so it is not longer discussed here. input refinement is managed by our architecture as follows. a simple mechanism  introduced in section 1  is used to infer possible device faults. if it is the case  or if a particular device is needed within a particular area  e.g. a gas sensor to detect gas leaks   the device network can be physically reconfigured

figure 1:  left  the simulation environment;  right  map of an on going experimental set-up.
through the use of mobile robots. in our perspective  mobile robots are mobile extensions to the smart space. they are provided with local device or cognitive agents communicating with other distributed niches. given the high level of system integration  cognitive agents running on fixed workstations can cooperate with device agents on board of mobile robots. as a consequence  the operator kp can be used to instantiate a new problem whose corresponding solution will be used to move the robot toward the specified area  thus implementing the reconfiguration.
¡¡inter level information flow management deals with techniques able to guide data acquisition. in our architecture  this can be accomplished by a new operator  kac  performing an active classification procedureoverthe situation concepts. recall the situation hierarchy introduced in section 1. for each branching level  we assume the availability of a correspondingepistemic operator k able to providea description ¦Äk useful for the classification. whenevera situationconcept has a non null set of child concepts  and no information is available from the corresponding operator  the system can decide by purpose to query the specified cognitive agent or to instantiate an alternate method to obtain the same information  i.e.  by requiring a network reconfiguration through the use of mobile robots.
1 implementation and experimental results
in our actual implementation  {¦Ád} agents exploit the echelon lonworks fieldbus for distributed control and programming. {¦Ác} agents are implemented using ethnos  a multi agent framework developed for distributed robotics and ami applications  piaggio et al.  1 . the knowledgebase is developed embedding in ethnos classic  a description logic which guarantees sound and complete subsumption inferences. planning capabilities required by level 1 are achieved using a pddl compatible planner.
¡¡the cognitive agents of our framework have been tested in a simulation environment built using the architecture itself. it consists of a niche composed by agents implementing simulated devices and user behaviors  visual interfaces  see fig.1 on the left   etc. simulated experimental results are carried out by adding specific agents implementing instances of patterns of user activities  and providing sensors with data sets recorded through real sensors  particular data sets have been developed to simulate fire  gas leaks  etc. .

algorithm 1 base pattern

require: a = {a1 ... an}; e = {e1 ... em}; epdf
ensure: a specific user behavior
1: for all i such that i = 1 ... n do
1:	perform action ai
1:	choose j according to epdf
1:	fire the event ej
1: end for

¡¡each base pattern  see algorithm 1  is a sequence of parameterized actions  e.g.  movements  interactions with the environment  etc. examples of base patterns are
aanswer phone call = {answer  talk  hang-up} or alunch = {goto-kitchen  goto-stove  cook  wait 1   goto-table  eat}. it is worth noticing that not all the user actions are treated as discrete events: e.g.  user movements  i.e.  goto-someplace  correspond to trajectories in the cartesian space. moreover  during each iteration in algorithm 1  an event ej is chosen to possibly introduce a perturbation in the user current action. events can range from waiting a certain amount of time to interacting with appliances  from receiving phone calls to completely changing the current pattern with a new one. events are selected according to a non-uniform outcome probability distribution epdf.
¡¡in all the experiments  are able to track the user with cameras  pirs  lasers and other sensors  maintaining also multiple hypotheses through subsumption. another agent   is able to fire alarms whenever the user remains in the bedarea for more than a specified time. moreover  the toiletteseq sequence of situations is detected multiple times  thus firing proper alarms.
¡¡specific experiments are aimed at testing the active classification system. for example  during the execution of the pattern alunch  after the user has moved to the stovearea  the event answerphonecall is selected. this implies that the current pattern is replaced by aanswer phone calls. after some time  is not updated with the expected information. thus  a specific query to ¦Ácss is made. if the smoke sensor is responding  the system reminds the user about his previous cooking action. on the contrary  if no smoke is detected  it is inferred that the user was doing something else  the user could be asked about it . after some time  if a cook action is performed  the epistemic operator kss operates on the knowledge base in order to infer that the new user situation is cooking; if not  a new classification is made.
¡¡the overall system is being tested at istituto figlie di n.s. della misericordia  savona  italy  an assisted-living facility for elderly and disabled  see fig.1 on the right .
1 conclusion
in this paper we presented a hybrid knowledge representation and data fusion system developed for integrated ami applications. despite its simple architecture  it is able to manage heterogeneous information at different levels   closing the loop  between sensors and actuators. based on the concept of an ecosystem of artificial entities  the system architecture has been thoroughly tested in simulation  and part of it has been tested in many real applications. future work will involve an
in depth investigation about the integration between all the subsystems in a real  complex  experimental set-up.
