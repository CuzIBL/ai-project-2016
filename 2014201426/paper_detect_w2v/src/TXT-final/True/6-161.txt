 
recent experiments have indicated the possibility to use the brain electrical activity to directly control the movement of robotics or prosthetic devices. in this paper we report results with a portable non-invasive brain-computer interface that makes possible the continuous control of a mobile robot in a house-like environment. the interface uses 1 surface electrodes to measure electroencephalogram  eeg  signals from which a statistical classifier recognizes 1 different mental states. until now  brain-actuated control of robots has relied on invasive approaches- requiring surgical implantation of electrodes- since eeg-based systems have been considered too slow for controlling rapid and complex sequences of movements. here we show that  after a few days of training  two human subjects successfully moved a robot between several rooms by mental control only. furthermore  mental control was only marginally worse than manual control on the same task. 
1 introduction 
there is a growing interest in the use of physiological signals for communication and operation of devices for physically-disabled as well as able-bodied people. over the last years evidence has accumulated to show the possibility to analyze brainwaves on-line in order to determine the subjects' mental state that is then mapped into actions such as selecting a letter from a virtual keyboard or moving a robotics device  birbaumer et al  1; kennedy et al  1; millan  1; millan et al  1; 
pfurtscheller and neuper  1; roberts and penny  1; serruya et al  1; taylor et al.  1; wolpaw and mcfarland  1; wolpaw et al  1 . this alternative communication and control channel  which does not require the user to perform any physical action  is called a brain-computer interface  bci . 
　a bci may monitor a variety of brainwave phenomena. most bcis use electroencephalogram  eeg  signals; 
i.e.  the brain electrical activity recorded from electrodes placed onto the scalp. the main source of the eeg is the synchronous activity of thousands of cortical neurons. measuring the eeg is a simple noninvasive way to monitor brain electrical activity  but it does not provide detailed information on the activity of single neurons  or small clusters of neurons  that could be recorded from microelectrodes surgically implanted in the cortex. 
   some groups exploit evoked potentials-the automatic responses of the brain to external stimuli-recorded from either scalp or intracranial electrodes  for a review  see  wolpaw et al.  1  . evoked potentials are  in principle  easy to pick up but constrain the subject to synchronize themselves to the external machinery. a more natural and suitable alternative for controlling devices is to analyze components associated with spontaneous mental activity. thus  some researchers measure slow cortical potentials-whose negative amplitudes are related to the overall preparatory excitation level of a given cortical network-over the top of the scalp  birbaumer et al.  1 . other groups look at local variations of eeg rhythms. the most used of such rhythms are related to the imagination of body movements and are recorded from the central region of the scalp overlying the sensorimotor cortex  pfurtscheller and neuper  1; wolpaw and mcfarland  1 . but  in addition to motorrelated rhythms  other cognitive mental tasks are being explored  millan et al  1; roberts and penny  1  as a number of neurocognitive studies have found that different mental tasks-such as imagination of movements  arithmetic operations  or language-activate local cortical areas at different extents. in this case  rather than looking for predefined eeg phenomena as when using slow cortical potentials or movement rhythms  the approach aims at discovering mental-specific eeg patterns embedded in the continuous eeg signals. yet  another kind of spontaneous signals is the direct activity of neurons in the motor cortex measured with implanted electrodes  kennedy et al  1; serruya et al.  1; taylor et al  1; wessberg et al  1 . 
robotics 	1 　recent experiments have shown the near possibility to use the brain electrical activity to directly control the movement of robotics or prosthetic devices. in these experiments  several monkeys have been implanted with microelectrodes recording the activity of single neurons  their spiking rate  in the motor and premotor areas of the cortex. then  the monkey's hand trajectory was predicted  and replicated online with a robot arm  from the activity of the neural populations  wessberg et al  1 . also  after appropriate training  monkeys were able to move a computer cursor to desired targets using only their brain activity  serruya et al  1; taylor et al  1 . until now  brain-actuated control of robots has being only tried with this kind of invasive approaches-requiring surgical implantation of electrodes-since eeg-based systems have been considered too slow for controlling rapid and complex sequences of movements. in this paper we show that two human subjects could  within a few days  learn to master a portable eeg-based brain-computer interface that recognized three mental states. subjects successfully moved a robot between several rooms by mental control only. furthermore  mental control was only marginally worse than manual control on the same task. 
1 brain interface protocol 
eeg-based brain-computer interfaces are limited by a low channel capacity. most of the current systems have a channel capacity below 1 bits/second  wolpaw et al  1 . one of the main reasons for such a low bandwidth is that they are based on synchronous protocols where eeg is time-locked to externally paced cues repeated every 1 s and the response of the bci is the average decision over this period  birbaumer et al  1; pfurtscheller and neuper  1; wolpaw and mcfarland  
1 . in contrast  our approach uses an asynchronous protocol that analyzes the ongoing eeg to determine the subject's mental state  which they can voluntarily change at any moment. the rapid responses of the bci  together with its performance  see section 1   give a theoretical channel capacity in between 1 and 1 bits/second. 
　two volunteer healthy subjects  a  and  b  wore a commercial eeg cap with integrated electrodes  white spots in figure 1 . eeg potentials were recorded at the 1 standard fronto-centro-parictal locations f1  f1  c1  cz  c1  p1  pz  and p1. the sampling rate was 1 hz. the raw eeg potentials were first transformed by means of a surface laplacian  sl  computed globally by means of a spherical spline of order 1  perrin et al  1  1 . this spatial filtering yields new potentials that should represent better the cortical activity due only to local sources below the electrodes. then  we used the welch periodogram algorithm to estimate the power spectrum of each channel over the last second. we averaged 1 segments of 1 second with 1% overlap  what yields a frequency resolution of 1 hz. the values in the frequency band 1 hz were normalized according to the total energy in that band. thus an eeg sample has 1 features  1 channels times 1 components each . eeg samples were computed every 1 ms  i.e.  1 times per second . 
　during an initial training period of a few days  the two subjects learned to control 1 mental tasks of their choice. the subjects tried the following mental tasks:  relax   imagination of  left  and  right  hand  or arm  movements   cube rotation    subtraction   and  word association . the tasks consisted of getting relaxed  imagining repetitive self-paced movements of the limb  visualizing a spinning cube  performing successive elementary subtractions by a fixed number  e.g.  1=1  1=1  etc.   and concatenating related words1. after a short evaluation  the experimental subjects  a  and  b  chose to work with the combination of 1 tasks relax-left-cube and relax-left-right  respectively. in the sequel  we will refer to these mental tasks as  i.e.  relax is  and cube or right is neither subject had 
previous experience with bcis or mental training. 
　each day  subjects participated in four consecutive training sessions of about 1 min  separated by breaks of 1 min. during each training session subjects switched randomly every 1 s between the three tasks. subjects received feedback online through three colored buttons on a computer screen. each button is associated to one of the mental tasks to be recognized. a button flashed when an eeg sample is classified as belonging to the corresponding mental task. after each training session the statistical classifier was optimized offline. after this initial training  subjects learned to control mentally the mobile robot for 1 days. the results reported here were obtained at the end of the second day of work with the robot. during this training period  the user and the bci engaged in a mutual learning process where they were coupled and adapted to each other. 
1 statistical classifier 
the mental tasks  or classes  are recognized by a gaussian classifier trained to classify eeg samples as state  or  unknown . in this statistical classifier  every unit represents a prototype of one of the classes to be recognized. its output gives an estimation of the posterior class probability distribution for an eeg sample. the challenge is to find the appropriate position  and receptive field  of the prototypes in the high-dimensional input space described above to differentiate the desired classes. 
　although gaussian classifiers are well known  our implementation differs from classical ones in a few respects. we assume that the class-conditional density function of class is a superposition of  gaussians  or prototypes  and that classes have equal prior probabilities. in our case  all the classes have the same number of prototypes  namely 1. in addition  we assume that all four prototypes have an equal weight of 1. then  dropping constant terms  the posterior probability  of class  for sample  is 
   relax is done with eyes closed  whereas the other tasks arc performed with eyes opened. but the recognition of the task  relax  is not based on the detection of eye movements. 
	 1  
where nc is the number of classes and is the activation level of the ith prototype of the class 
 1  
where corresponds to the center of the ith prototype of class is the covariance matrix of class   and is the determinant of that matrix. in our case  is diagonal and common to all the prototypes of the class. in this way  we reduce the number of parameters and pool data to increase the accuracy of their estimation. 
   the response of the network for sample  is the class with the highest posterior probability provided that is 
greater than a given probability threshold of 1; otherwise the response is  unknown.  this rejection criterion keeps the number of errors  false positives  low  because recovering from erroneous actions  e.g.  robot turning in the wrong direction  has a high cost. the choice of this probability threshold was guided by a previous roc study where different subjects only carried out the initial training described before  hauser et al  1   and the actual value was selected based on the performance of the two subjects during the initial period of training. 
　to initialize the center of the prototypes and the covariance matrix of the class  we run a clustering algorithm  typically  a self-organizing map  kohonen  1   to compute the position of the desired number of prototypes. then  the covariance matrix is 
 1  
denotes the number of training samples belongis the nearest prototype of this 
　we then improve these initial estimations iteratively by stochastic gradient descent so as to minimize the mean square error. for every sample x in the training set  the update rule for all the prototypes of all the classes is 
 1  
where a is the learning rate  the target vector in the form l-of-c and a is the total activity of the network-i.e.  the denominator in  1 . intuitively  during training  units are pulled towards the eeg samples of the mental task they represent and are pushed away from eeg samples of other tasks. 
　finally  after every iteration over the training set  we estimate again the new value of  using expression  1 . 
it is possible to estimate the covariance matrices in more elaborated ways  including through gradient descent in order to minimize their contribution to the error function. 
the brain-computer interface responds every 1 s. 
firstly  it computes the class-conditioned probability for each class-i.e.  the mixture of gaussians in the numerator of eq.  1 . secondly  it averages the class-conditioned probabilities over 1 consecutive samples. thirdly  it estimates the posterior probability based on the average class-conditioned probability of each class using bayes' formula; cf eq.  1 . finally  it compares the posterior probability with a threshold value of 1. at the end of training  errors and  unknown  responses are below 1% and 1%  respectively. the theoretical channel capacity of the interface is hence above 1 bit/second  operation mode 1 . in addition  the interface could also operate in another mode  operation mode ii  where classification errors are further reduced by requiring that two consecutive periods of 1 s give the same classification response. in this mode ii errors and  unknown  responses are below 1% and 1%  respectively  and the theoretical channel capacity is about 1 bit/second. 

figure 1. one of the experimental subjects while driving mentally the robot through the different rooms of the environment during the first experiment. 
1 robot setup and control 
the task was to drive the robot through different rooms in a house-like environment  figure 1 . the robot was a small khepera  1 cm diameter  that closely mimics a motorized wheelchair. the robot moved at a constant speed of one third of its diameter per second  similar to the speed of a wheelchair in an office building. 
　to make the robot move along a desired trajectory it is necessary to determine the speed of the motors controlling the wheels at each time step. obviously  this is im-
robotics 	1 possible by means of just three mental commands. a key idea is that the user's mental states are associated to high-level commands  e.g.   turn right at the next occasion   that the robot executes autonomously using the readings of its on-board sensors. another critical aspect for the continuous control of the robot is that subjects can issue high-level commands at any moment. this is possible because the operation of the bc1 is asynchronous and does not require waiting for external cues  unlike synchronous approaches. the robot will continue executing a high-level command until the next is received. 
   the robot relies on a behavior-based controller  arkin  1  to implement the high-level commands that guarantees obstacle avoidance and smooth turns. in this kind of controller  on-board sensors are read constantly and determine the next action to take. the mapping from the user's mental states  or commands  to the robot's behaviors is not simply one-to-one  but  in order to achieve a more flexible control of the robot  the mental states are just one of the inputs for a finite state automaton with 1 states  or behaviors . the transitions between behaviors are determined by the 1 mental states  #1  #1  #1   1 perceptual states of the environment  as described by the robot's sensory readings: left wall  right wall  wall or obstacle in front  left obstacle  right obstacle  and free space  and a few internal memory variables. figure 1 shows a simplified version of the finite state automaton. the memory variables were required to implement correctly the different behaviors. thus  if the robot is performing the behavior  forward  and perceives a wall to the left  it switches automatically to the behavior  follow left wall . the actual transitions between the behaviors  forward  and  follow left/right wall  are not exactly as indicated in the figure  otherwise the robot would stay following walls forever. the transition to the behavior  forward  is necessary  for example  in the case the robot is approaching an open door and the user wants the robot not to enter into the room. on the other hand  the robot  stops  whenever it perceived an obstacle in front to avoid collisions  not all the transitions to the behavior  stop  appear in the figure for the sake of simplicity . briefly  the interpretation of a mental state depends on the perceptual state of the robot. thus  in an open space the mental state #1 means  left turn  while the same mental state is interpreted as  follow left wall  if a wall is detected on the left-hand side. similarly  mental state #1 means  right turn  or  follow right wall ; mental state #1 always implied  move forward . altogether experimental subjects felt that our control schema was simple and intuitive to use. 
　the khepera robot is a two-wheeled vehicle. it has 1 infrared sensors around its diameter to detect obstacles. the sensors have a limited perception range  what makes difficult the recognition of the different perceptual states from the raw readings. to overcome this limitation  the robot uses a multilayer perceptron that maps the 1 raw infrared sensory readings into the current perceptual state. 
　a final element is the use of an appropriate feedback indicating the current mental state recognized by the embedded classifier. this is done by means of three lights on top of the robot  with the same colors as the buttons used during the training phase. the front light is green and is on when the robot receives the mental command #1. the left light is blue and is associated to the mental command #1  whereas the right light is red and is associated to the mental command #1. thus  if the robot is following the left wall and is approaching an open door  a blue feedback indicates that the robot will turn left to continue following the left wall  and  so  it will enter into the room . on the contrary  a green feedback indicates that robot will move forward along the corridor when facing the doorway and will not enter into the room. this simple feedback allows users to correct rapidly the robot's trajectory in case of errors in the recognition of the mental states or errors in the execution of the desired behavior  due to the limitations of the robot's sensors . 

figure 1. finite state automaton used for the control of the robot. transitions between the 1 behaviors were determined by 1 mental states  #1  #1  #1   1 perceptual states  |o: left wall  o|: right wall  1: wall or obstacle in front   and some memory variables. the memory variables and some of the perceptual states are not shown for the sake of simplicity. 
1 experimental results 
after 1 and 1 days of initial training with the interface operating in mode 1  subjects  a  and  b   respectively  achieved a satisfactory level of performance  correct recognition was above 1% while errors were below 1% . at this moment  subjects started to learn to control mentally the robot with the interface operating in mode ii. during this second period of training subjects had to drive the robot mentally from a starting position to a first target room; once the robot arrived  a second target room was selected and so on. the starting position and the target rooms were drawn at random. 
　figure 1 shows a trajectory generated by subject  a  after two days of training. the robot had to visit 1 different rooms  drawn randomly  starting from location  s . 

although the figure does not show the details of the trajectory inside the rooms  the robot made a short exploration in each of them. during the experiment  the subject was driving the robot for about 1 minutes continuously. although the subject brought the robot to the desired room each time  there were a few occasions where the robot did not follow the optimal trajectory. this was mainly because the brain interface took a longer time than usual to recognize the subject's mental state. for instance  in one case the robot missed a turn because the brain interface did not recognize the appropriate mental state until the robot had passed the doorway of the desired room  and so the subject needed to maneuver mentally the robot to bring it back. in other situations  the robot's sensors perceived a wall or corner too close  thus making the robot stop automatically to avoid collisions. in these situations  the subject needed to turn  by mental control  the robot away from the phantom obstacle and then resume the trajectory. 

figure 1. trajectory followed by the robot under the mental control of subject  a  during one of the trials of the first experiment. the robot started in the bottom left room and then visited 1 other rooms  top center  top right and bottom right  sequentially. the figure docs not show the details of the trajectory inside the rooms. 

　qualitatively  the trajectory is rather good as the robot visited the 1 rooms in the desired order and it was never necessary to make significant corrections to the robot's active behaviors. but in order to evaluate quantitatively the performance of the brain-actuated robot  subjects  a  and  b  also carried out a second set of experiments in a slightly different arrangement of the rooms that were now located along the two sides of a corridor  figure 1 . 
　in a given trial  the robot must travel from a starting room to a target room as well as also visiting an intermediate room. the rooms and their order were selected at random. first  the subject made the robot visit the desired sequence of rooms by mental control. in a later session  the subject drove the robot along the same sequence of rooms by manual control. in this case  the subject used the same controller described above but  instead of sending mental commands to the robot  he simply pressed one of three keys. this procedure allowed us to compare mental and manual control for a system that is identical in all other aspects. in addition  the manual trajectory should be quite close to the optimal path that can be generated with the current controller. it is worth noting that the reason why the subject controls the robot mentally first and only afterwards manually is to avoid any learning process that could facilitate mental control. 
　table 1 gives the time in seconds necessary to generate the desired trajectory for three different trials for the two subjects. for each trial  the table indicates the time required for mental control and manual control. surprisingly  we can see that mental control was only marginally worse than manual control. on average  brain-actuated control of the robot is only 1% longer than manual control for both subjects. 
table 1. time in seconds for three different trials where subjects  a  and  b  controlled the robot first mentally and then manually. 
subject trial 
1 
1 
average 
1 
1 
average mental 
1 
1 
1 
1 
1 
1 
1 manual 
1 
1 
1 
1 
1 
1 discussion 

figure 1. environment used for the second set of experiments. 

in this paper we have reported first results of a brainactuated mobile robot by means of a portable noninvasive bci. although the quality and resolution of the brain signals measured with our eeg system are not comparable to those recorded by implanted electrodes  they are sufficient to operate robots in indoor environments. this is possible because of the combination of advanced robotics  an asynchronous protocol for the 

robotics 	1 

analysis of online eeg signal  and machine learning techniques. 
　the work described in this paper suggests that it could be possible for human subjects to mentally operate a wheelchair. but porting the current results to the wheelchair is not straightforward for  at least  two reasons. first  the performance of the bci will suffer once the subject is seated on a mobile platform. this will require longer training times for the subject. second  the current finite state automaton only allows for simple control actions  and so the resulting wheelchair could be too constrained for practical use in cluttered environments. in this respect  recent progress in eeg analysis  michel et al  1  suggests that a sufficient number of mental states can be recognized to control robotics and prosthetic devices and in a more natural and flexible way. in this approach we will transform scalp potentials-recorded with a sufficiently high number of electrodes  1  1 or more -to brain maps to get detailed information on the activity of small cortical areas. the gaussian classifier embedded in the bci would work upon selected parts of these brain maps instead of using eeg features. 
acknowledgments 
jrm is supported by the swiss national science foundation through the national centre of competence in research on  interactive multimodal information management  1 .  
