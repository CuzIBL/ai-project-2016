ion and specification  falcone and castelfranchi  1 . we can distinguish between several levels  but the most important are the following ones: 
  pure executive delegation vs. open delegation; 
  domain task delegation vs. planning and control task delegation  meta-actions  
the object of delegation can be minimally specified {open delegation   completely specified {close delegation  or specified at any intermediate level. we wish to stress that open delegation is not only due to x's preference  practical ignorance or limited ability. of course  when x is delegating a task to v  she is always depending on v for that task: she needs v's action for some of her goals  either domain goals or more general ones  like saving time  effort  resources and so on . however  open delegation is also due to x's ignorance about the world and its dynamics: fully specifying a task is often impossible or not convenient  because some local and updated knowledge is needed in order for that part of the plan to be successfully performed. open delegation is one of the bases for the flexibility of distributed and ma plans. 
　open delegation necessarily implies the delegation of some meta-action  planning  decision  etc. ; it exploits intelligence  information  and expertise of the delagated agent. only cognitive delegation can be  open   a goal  an abstract action or plan that need to be autonomously specified : thus  something thai non-cognitive agents cannot do. 
　the distributed character of the ma plans derives from the open delegation. in fact  x can delegate to y either an entire plan or some part of it {partial delegation . the combination of the partial delegation  where y might ignore the other parts of the plan  and of the open delegation  where x might ignore the sub-plan chosen and developed by y  creates the possibility that x and v  or y and z  both delegated by x  collaborate in a plan that they do not share and that nobody entirely knows: that is a distributed plan  grosz and kraus  1 . however  for each part of the plan there will be at least one agent that knows it. this is also the basis for orchestrated cooperation  a boss deciding about a general plan   but it is not enough for the emergence of functional and unaware cooperation among planning agents. 
1 strong sa: goals about the others action/goal  1＜ step  
in delegation x has the goal that y does a given action  that she needs and includes in her plan . if y is a cognitive agent  
x has also the goal that y has the goal  more precisely intends  to do that action. i call this  cognitive delegation : delegation to an intentional agent. this goal of x is the motive for influencing y  porn  1; castefranchi  1   but it does not necessarily lead to inducing or influencing y. the world may by itself realise our goals. in fact  it might be that x has nothing to do because v independently intends to do the needed action. 
　strong social action is characterized by social goals. a social goal is defined as a goal that is directed toward another agent  i.e. whose intended results include another agent considered as a cognitive agent: a social goal is a goal about other agents' minds or actions  like in eve's example . examples of typical social goals  strong sas  are: changing the other mind  communication  hostility  blocking the other goal   cognitive delegation  adoption  favouring the other's goal . 
we not only have beliefs about others' beliefs or goals 
 weak social action  but also goals about the mind of the other: eve wants that adam believes something; eve wants that adam wants something. we cannot understand social interaction or collaboration or organisations without these social goals. personal intentions of doing one's own tasks  plus beliefs  although mutual  about others' intentions  as used in the great majority of current ai models of collaboration  are not enough. 
　for a cognitive autonomous agent to have a new goal  he ought to acquire some new belief  castelfranchi  1 . therefore  cognitive influencing consists of providing the addressee with information that is pretended to be relevant for some of his goals  and this is done in order to ensure that the recipient has a new goal. 
influencing  power and incentive engineering 
the basic problem of social life among cognitive agents lies beyond mere coordination: how to change the mind of the other agent  how to induce the other to believe and even to want something  table 1 column b   how to obtain that y does or does not something  of course  normally -but not necessarily-.by communicating. 
　however  communication can only inform the other about our goals and beliefs about its action: why should he care about our goals and expectations  he is not necessarily a benevolent agent  an obedient slave. thus  in order to induce him to do or not to do something we need power over him  power of influencing him. his benevolence towards us is just one of the possible basis of our power of influencing him  authority  sympathy  are others . however the most important basis of our power is the fact that probably also our actions are potentially interfering with his goals: we might either damage or favour him: he is depending on us for some of his goals. we can exploit this  his dependence  our reward or incentive power  to change his mind and induce him to do or not to do something  castelfranchi  1 . 
　incentive engineering  manipulating the other's utility function  is not the only way we have to change the mind  behavior  of the other agent. in fact in a cognitive agent pursuing or abandoning a goal does not depends only on preferences and on beliefs about utility. to pursue or abandon his intention  y should have a host of beliefs  that are neither reducible nor related to his outcomes. for example  to do p y should believe that  p is possible   that 
 he is able to do p   that  p's preconditions hold   that  necessary resources are allowed   etc. it is sufficient that x modifies one of these beliefs in order to induce y to drop his intention and then restore some other goal which was left aside but could now be pursued. 
　the general law of influencing cognitive agents' behavior does not consist of incentive engineering  but of modifying the beliefs which  support  goals and intentions and provide reasons for behavior. beliefs about incentives represent only a sub-case. 
1 strong sa: social goal adoption  1＜ step  
let me now look at sa from y's  the contractor  the helper  perspective. social goal-adoption  shortly g-adoption  deserves a more detailed treatment  since: 
a  it is the true essence of all pro-social behavior  and has several different forms and motivations; 
b  frequently enough its role in cooperation in not understood. 
either agents are just presupposed to have the same goal  ex. 
werner  1   or the adoption of the goal from the other partners is not explicitly accounted for  tuomela and miller  1; levesque et al. 1; tuomela  1 ; or the reasons for adopting the others' goal and take part in the collective activity are not explored. 
　in g-adoption x is changing her mind: she comes to have a new goal or at least to have new reasons for an already existing goal. the reason for this  new  goal is the fact that another agent y wants to achieve this goal: x knows this and decides to make/let him achieve it. x comes to have the same goal of y  because she knows that is y's goal but not as in simple imitation: here x has the goal that p  wants p to be true  in order for y to achieve it. in other words  x is adopting a goal of y's when x wants y to obtain it as long as x believes that y wants to achieve that goal  conte and castelfranchi  1 . 
　among the various forms of g-adoption  especially for modelling agreement  contract and team work  g-adhesion or compliance has a special relevance. that occurs when the g-adoption is due to the other's request  implicit or explicit   to his goal that x does a given action  or better to his goal that x adopts a given goal. it is the opposite of spontaneous forms of g-adoption. so in adhesion x adopts y's goal that she adopts  she complies with y's expectations. 
g-adhesion is  the strongest form of g-adoption. 
agreement is based on adhesion; strong delegation is request for adhesion. in negotiation  speech acts  norms  etc. that are all based on the communication by x of her intention that the other does something  or better adopts her goal  for ex. obeys  g-adhesion is what really matters. 
1 	social agent's architecture and multiple goal-sources 
through social goal-adoption we obtain a very important result as for the architecture of a social agent: 
  goals  and then intentions  are not born all as desires or wishes  they do not derive all from internal motives. a social agent is able to  receive  goals from outside: from other agents  from the group  as requests  needs  commands  norms. 
　if the agent is really autonomous it will decide  on the basis of its own motives  whether to adopt or not the incoming goal  castelfranchi  1. 
　in architectural terms this means that there is not an unique origin of potential intentions  rao and georgeff  1  or candidate goals  bell and huang  1 . there are several goal origins or sources  bodily needs ; goals activated by beliefs; goals elicited by emotions; goals generated by practical reasoning and planning; and goals adopted: introjected from outside . all these goals have to converge at a given level in the same path  in the same goal processing  to become intentions and be pursued through some action. 
1 	motivation for g-adoption 
adoption does not coincide with benevolence  rosenschein and genesereth  1 . a relation of benevolence  indeed  is a form of generalised adoption. this has to do with the motivation for g-adoption. 
　benevolence is a terminal  non instrumental  form of gadoption  pity  altruism  love  friendship . goal-adoption can he also instrumental to the achievement of selfish goals. for example feeding chickens  satisfying their need for food  is a means for eventually eating them; instrumental gadoption also occurs in social exchange  reciprocal conditional g-adoption . 
　another motive-based type of g-adoption  that might be considered also a sub type of the instrumental one  is cooperative g-adoption: x adopts y's goal since she is cointerested in  some of  v's intended results: they have a common goal. collaborative coordination  1  is just one example of it. 
　the distinction between these three forms of g-adoplion is very important  since their different motivational basis  why x adopts  allows important predictions on x' s  cooperative  behavior. for example  if x is a rational agent  in social exchange she should try to cheat  not reciprocating v's adoption. on the contrary  in cooperative adoption x normally is not interested in free riding since she have the same goal as v and they are mutually dependent on each other as for this goal p: both jc's action and v's action are necessary for p  so jc's damaging y would damage herself. analogously  while in terminal and in cooperative adoption it might be rational in many cases to inform v about difficulties  obstacles  or defections  levesque et al.  1; jennings  1   in exchange  and especially in forced  coercive g-adoption this is not the case at all. 
　current ai models of collaboration  group  and organizations are not able to distinguish between these motive-based forms of goal adoption  while those distinctions will become practically quite important in ma collaboration and negotiation in the web  self-interested agents; iterated interactions; deception; etc. . 
1 	levels of collaboration 
in analogy with delegation  several dimensions of adoption can be characterized  falcone and castelfranchi  1 . in particular  the following levels of adoption of a delegated task can be considered: 
  literal help: x adopts exactly what was delegated by v  elementary or complex action  etc. . 
  overhelp: x goes beyond what was delegated by y  without changing y's plan. 
  critical help: x satisfies the relevant results of the requested plan/action  but modifies it. 
  overcritical help: x realizes an overhelp by  at the same time  modifying or changing the plan/action. 
  hyper-critical help: x adopts goals or interests of v that y himself did not consider; by doing so  x does not perform the action/plan  nor satisfies the results that were delegated. 
on such a basis one can characterize the level of collaboration of the adopting agent. 
　an agent that helps another just doing what is literally requested to do  is not a very collaborative agent. she has no initiative  does not care of our interests  does not use her knowledge and intelligence to correct our plans and requests that might be incomplete  wrong or self-defeating. 
　a truly helpful agent should care of our goals and interests going beyond our deiclegation and request  chu-carroll and carberry  1 . but  only cognitive agents can nonaccidentally help beyond delegation  recognizing our current needs case by case. 
　of course  there are dangers also when the agent takes the initiative of helping us beyond our request. troubles either due to misunderstandingfs and wrong ascriptions  or to conflicts and paternalism. 
1 	social goals as the glue of joint action: social-commitment 
although clearly distinct from each other  social action/goal and joint action/goal are not two independent phenomena. in order to have a theory of joint action or of group and organization a theory of social goals and actions is needed. in fact social goals in the minds of the group members are the real glue of joint activity. 
　i cannot here examine the very complex structure of a team activity  or a collaboration  and the social mind of the involved agents; or the mind of the group assumed as a complex agent. there are very advanced and valid formal characterisations of this  tuomcla and miller  1; levesque et al.   1; rao et a/.  1; grosz and krauss  1; wooldridge and jennings  1 . 1 would like just to stress how social action and goals  as previously characterised  play a crucial role in it. 
　no group activity  no joint plan  no true collaboration can be established without: 
a  the goal of x  member or group  about the intention of y of doing a given action/task a  delegation ; 
b  x's  intention that   grosz and kraus  1  y is able and has the opportunity to do a; and in general the 
 collaborative coordination  of x relative to y's task. this is derived from the delegation and from the necessary coordination among actions in any plan. 
c  the social commitment of v to x as for a  which is a form of goal-adoption or better of adhesion. 
　normally  both goal-adoption in collaboration and groups  and the goal about the intention of the other  influencing  are either ignored or just implicitly presupposed in those accounts. they mainly rely on the agents' beliefs about the intentions of the others; i.e. a weak form of social action and mind. the same is true for the notion of cooperation in game theory. as for the social commitment it has been frequently confused with the individual  non social  commitment of the agent to his task. 
   social commitment results from the merging of a strong delegation and the corresponding strong adoption: reciprocal social commitments constitute the most important structure of groups and organizations: 
   there is a pre-social level of commitment: the internal or individual commitment  cohen & levesque 1 . it refers to a relation between an agent and an action. the agent has decided to do something  the agent is determined to execute a given action  at the scheduled time   and the goal  intention  is a persistent one: for example  the intention will be abandoned only if and when the agent believes that the goal has been reached  or that it is impossible to achieve it  or that it is no longer motivated. 
   a  social commitment  is not an individual commitment shared by several agents. social commitment is a relational concept: the commitment of one agent to another  singh  1; castelfranchi  1 . more precisely  s-commitment is a four argument relation  where x is the committed agent; a is the action  task  x is committed to do; y is the other agent to whom x is committed; z is a third possible agent before whom 
x is committed. 
   social commitment is also different from collective or group commitment  dunin-keplicz and verbrugge  1  . 
the latter is the internal commitment of a collective agent or group to a collective action. in other terms  a set of agents is internally committed to a certain intention/plan and there is mutual knowledge about that. the collective commitment requires social commitments of the members to the others members and to the group. 
not only social commitment combines acceptance-based 
delegation and acceptance-based adoption  but when x is scommitted to y  then y can  is entitled to : control if x does what she  promised ; exact/require that she does it; complain/protest with x if she doesn't do a;  in some cases  make good his losses  pledges  compensations  retaliations . so social commitment creates rights and duties among x and y  castelfranchi  1 . 
although so relevant  and although it introduces some normative aspects  the social commitment structure is not the only important structure constraining the organizational activity and society. 
1 social structures and organization 
there is an implicit agreement about organizations in recent computational studies. either in dai theories of organization  bond  1; gasser 1   or in formal theories of collective activity  team or group work  joint intention  and  social agents   ex. levesque et al.  1   or in cscw approaches to cooperation  winograd  1   organization is in fact accounted for by means of the crucial notion of 
 commitment . however  this account is quite unsatisfactory  for a number of reasons: 
　　a  as already observed  the current definitions of 
commitment are insufficient to really account for stable group formation and activity: there is no theory of  social  commitment as a necessary premise for a theory of collective or group commitment  and normative aspects of commitment are ignored; 
　　b  agents seem to be completely free  also in organizations  to negotiate and establish any sort of commitment with any partner  without any constraint of dependence and power relations  of norms and procedures  of pre-established plans and cooperations. 
　current views of organization dominant in computer science  dai  cscw  risk to be too  subjective  and too based on communication.they risk to neglect the objective basis of social interaction  dependence and power relations  and its normative components. 
   both the  shared mind  view of group  team work  and coordination  just based on agents' beliefs and intentions  and the  conversational  view of organization  winograd  1   find no structural objective bases  no external limits and constraints for the individual initiative: the  structure  of the group or organization is just the structure of interpersonal communication and agreement  and the structure of the joint plan. the agents are aware of the social structure their are involved in: in fact  they create it by their contractual activity  and social organization lies only in their joint mental representations  social constructivism   bond  1;  gasser  1 . there is also a conspicuous lack of attention to the individual motivations to participate in groups and organizations: agents are supposed to be benevolent and willing to coooperate with each other. 
　coordination in a group or organization is not guaranteed only by a shared mind  joint intentions  agreed plans  shared beliefs   reciprocal benevolence  and communication; there are several structures in any m-a system: the interdependence and power structure; the acquaintance structure emerging from the union of all the personal acquaintances of each agent  ferber 1; haddadi and sundermeyer  1 ; the communication structure  the global net of direct or indirect communication channels and opportunities ; the commitment structure  emerging from all the delegation-adoption relationship and from partnership or coalitions formation among the agents; the structure determined by pre-established rules and norms about actions and interactions. each structure determines both the possibility and the success of the agents' actions  and constrains  when known  their decisions  goals and plans. the agents are not so free of committing themselves as they like: their are conditioned by their dependence and power  by 

their knowledge  by their possible communication  by their roles and commitments  by social rules and norms. 
1 	some concluding remarks and challenges 
why are agents social  because they interfere with and depend on each other. thus  to multuply their powers  their possibility to achieve goals ; to exploit actions  abilities  and resources  included knowledge and intelligence  of the others. 
why should ai agents be social  to really assist and help the users  and to coordinate  compete and collaborate with each other. 
why do we need cognitive  intelligent  autonomous agents acting on our behalf  in order to do open delegation exploiting local knowledge and adaptation  personal expertise and intelligence  and in order to receive over and critical help case by case: the deepest form of cooperation; that a reactive  although learning  agent cannot provide. 
which are the basic ingredient of cooperation  exchange  organization  goal delegation and goal-adoption. how to obtain adoption from an autonomous agent  by influencing and power. why should it waste its own resources for another agent  always for its own motives  autonomy  but of several kinds: benevolence  advantages  common goal  norms  etc. one should't mix up  self-interested   rational  with  selfish . 
why modeling individual social action and mind is necessary for modelling collective behavior and organization  because the individual social mind is the necessary precondition for society  among cognitive agents . in particular  one cannot understand the real glue of a group or team if one ignore the goals of coordination and influencing  the commitments  the obligations and rights relating one to another. without this  the collaboration among artificial agents will be unreliable  fragile and incomplete. 
why do we need emergent functional cooperation also among intelligent planning agents  emergence does not pertain only to reactive agents. mind cannot understand  predict  and dominate all the global and compound effects at the collective level. some of these effects are positive and self-organising. mind is not enough: not all cooperation is based on knowledge  mutual beliefs  reasoning and constructed social structure and agreements. 
what kind/notion of emergence do we need  an emergence simply relative to an observer  which sees something interesting or some beautiful effect looking at the screen of a computer running some simulation   or a merely accidental cooperation  mataric  1    like stars  cooperate  to the emergence of our beautiful constellations  are not enough. we need an emerging structure playing some causal role in the system evolution/dynamics; not merely an epiphenomenon. this is the case of the emergent dependence structure. possibly we need even more than this: really selforganizing emergent structures. emergent organisations and phenomena should reproduce  maintain  stabilize themselves through some feedback: either through evolutionary/selective mechanism or through some form of learning. otherwise we do not have a real emergence of some causal property  a new complexity level of organisation of the domain ; but just some subjective and unreliable global interpretation. 
　this is true also among cognitive/deliberative agents: the emergent phenomena should feedback on them and reproduce themselves without being understood and deliberated  elster  1 . this is the most challenging problem of reconciliation between cognition and emergence: unaware social functions impinging on intentional actions. 
acknowledgement 
i wish to thank amedeo cesta  rosaria conte  rino falcone  maria miceli of the ip-cnr group  since i'm just summarising an approach that was collectively developed. 
thanks also to the maamaw  atal and icmas communities were it was possible to explore around in ai social theory and systems  receiving both encouragement and insightful feedbacks. 
