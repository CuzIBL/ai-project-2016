 
we discuss the representation and use of justification structures as an aid to knowledge base refinement we show how justifica tions can be used by a system to generate explanations - for its own use-of potential causes of observed failures. we discuss specific information that is usefully included in these justifications to allow the system to isolate potential faulty supporting beliefs for its rules and to effect repairs 
this research is part of a larger effort to develop a learning ap prentice system  las  that partially automates initial construction of a knowledge base from first-principle domain knowledge as well as knowledge base refinement during routine use. a simple implementation has been constructed that demonstrates the feasibility of building such a system. 
i. introduction 
a learning apprentice system  is an interactive aid for building and refining a knowledge base. its aims are twofold' d  to partially automate initial construction of a knowledge base by generating shallow rules automatically from an approximate domain theory  and   n  to interact with users to help refine the knowledge through experience gained during normal problem solving in this paper  we concentrate on knowledge base refinement in our scenario  for problems where the performance program  i e  the component of the knowledge-based system that performs the problem 
solving  fails to make an important inference  or makes an incorrect inference  the user advises the las of the failure. the system tries to explain why the failure has occurred  perhaps via a focussed interaction with the user   and repairs or extends its knowledge base as required. 
mark of schlumberger this type of  knowledge acquisition in context  has previously been used to advantage in teiresias 1  1   in the context of the mycin system. its advantages include:  i  it happens in the normal course of use of the system  driven by failures  and therefore has the potential of tapping the knowledge of specialists without placing large additional demands on their time; and  di  because the specialist and system are working step by step through a specific problem  the learning is focussed on a relatively small portion of the knowledge base. 
our main focus here is explanation of failures - assignment of blame to specific items in the knowledge base. in terms of the general model of learning systems presented in   this is the task of the critic. like teiresias. we use the reasoning trace exhibited by the performance program to help focus the interaction be tween the las and the user however  instead of relying on the user to explain why a particular rule or set of rules might have failed  the las uses a type of dependency network - a justification structure -to construct possible explanations for the observed failure. 
the reasoning trace provides support for conclusions drawn by the performance program. the content of that support is the chain of rule firings that led to the conclusions. a justification structure. on the other hand  goes one step further. it records the support for an individual rule the content of the justification is the deeper domain knowledge from which the rule is derived  together with the assumptions and approximations that have been used in the derivation. for the purpose of refinement  the primary information captured in a justification structure is the manner in which errors propagate across dependency links. by using this information in concert with a taxonomy of error types  it is possible for the las to determine a constrained set of suspect supporting beliefs that can explain an observed failure of some supported belief. this infor mation is useful for focussing a dialogue between the las and the specialist. it is also essential input to an automated revision system. 
several researchers  1  have studied methods for recording logical dependencies between beliefs  and for using such dependencies to guide inference. the current work extends the concepts of truth maintenance and dependency-directed backtracking in that domain specific knowledge about how to propagate errors through a dependency network is used in addition to knowledge of the logical structure of the network itself. 
the xplain system of swartout also used justifications to generate explanations of its behavior for human users. by constrast  we focus here on using justifications to generate explanations for the system itself of potential causes of observed failures. this has led us to concentrate on determining precisely which information is usefully included in the justifications to allow the system to isolate potential faulty supporting beliefs for its rules and to effect repairs. 
we are using the dipmeter advisor* system in order to test our ideas in the context of a task  and performance program  that is already well understood . we have implemented subprograms to extend this system and have undertaken some analysis of the generality of the method. 

1 	r. smith et al. 
a. geological interpretation: the dipmeter advisor system 
the general task of the dipmeter advisor system is to infer the geological structures penetrated by a single borehole. for example  it might conclude that a late fault with strike 1бу has been penetrated at a depth of 1 feet. its primary input data is the dip or tilt of rock formations penetrated by the borehole  indexed by depth. it also uses data from a variety of other logging tools as well as information about the local geology. 
the system divides the interpretation task into an ordered series of subtasks involving pattern detection  data aggregation  and abstraction. after each subtask has been completed  the user is given the opportunity to examine  delete  or modify conclusions reached by the system. he can also add his own conclusions. in addition  he can revert to earlier stages of the analysis and repeat various subtask chains with different assumptions or data. 
the rules in the system are empirical associations applied by the rule interpreter in distinct rule sets using a forward-chaining control strategy. a simplified version of a rule used to determine that a previously detected normal fault is a late fault is shown in figure 
1. 
rule: nfr1 
if there exists a normal fault pattern  p   and there exists a red pattern  p 1   
such that the length of p1   1 ft.  and such that p1 is above the fault plane pattern of p  
then 
specialize p to be a late fault pattern 
figure 1: late fault rule. 
the geometry and dip patterns upon which nfr1 is based are shown in figure i-1. a rough justification for the rule is as follows: a late fault typically has a distortion region directly above the fault plane. the distortion region for a late fault is generally thin because the surrounding rock has been compacted  and is therefore not very plastic  at the time of faulting. the thin distortion region  projected onto the borehole  is manifested in dipmeter data as a short red pattern. the 1 ft. threshold is dependent upon assumed values for the distortion region thickness and the fault angle. the rule assumes that dipmeter patterns can be detected in the vicinity of the fault. this will be true if bedding is preserved  the borehole is not washed out  caved in   and if the tool is operating correctly. if  for example  the borehole were washed out over part of the distortion region  the length of the measured red pattern would be less than expected. 
we use this rule as an example throughout the paper. we show how its detailed justification can be used to isolate faulty supporting beliefs that can prevent it from firing in some situations. 
ii. describing error types and rule justifications 
the critic uses the type of error that the performance program has made  along with its reasoning trace  the current rule base  and justification structures to guide generation of plausible explanations of a failure and to focus on plausible repairs. 

figure 1: late fault geometry 
a. error types 
in examining the justification of an incorrect rule  it is useful for the critic to distinguish among several classes of errors because' u  it provides an additional constraint on the search for suspected supporting beliefs: and   u  different classes of errors suggest different repair strategies. the error classes currently used by our prototype las for beliefs are shown in figure 1  and break down into three main classes: 

figure 1: types of belief errors 
rule belief error: beliefs that are implications may suffer from one of the following classes of error: overgenerallefthandside  oglhs  - the rule applies in situations in which it should not: overspecificlefthandside  oslhs -the rule does not apply in situations in which it should; overgeneralrighthandside  ogrhs  - the rule fails to make assertions when it should or makes assertions that are too general  e g.. drawing a conclu sion about a normal fault where a conclusion about a late fault  a specialization of normal fault  is warranted ; and  overspecificrighthandside  osrhs -the rule either makes assertions when it should not or makes assertions that are too specific  e.g.  drawing a conclusion about a late fault where only a conclusion about a normal fault is warranted . 
numeric parameter error: a belief about the value of a numeric parameter may be incorrect by being an overestimate  oe  or underestimate  ue  of the correct value of the parameter. 
symbolic parameter error  spe : this is an error regarding beliefs which are neither implications nor assertions about numerical parameters. they simply have a truth value. for example  an erroneous assertion that a comparator is       when it should be       is a symbolic parameter error. 

we believe this error taxonomy to be useful in a variety of domains. it is also incomplete. we have not yet formalized  for example  errors in symbolic parameters for which a partial order can be established. in such cases  overspecific and underspecific may be appropriately added as subclasses of symbolicparametererror. 
b. justification structures 
we define a justification structure to be a network of beliefs connected by justification links. beliefs represent assertions and justification links record the derivational dependencies between beliefs. 
a belief contains assertion  type of belief  and degree of belief slots  in addition to its links in the justification structure . the assertion is the actual statement of the belief. the type of belief is one of definitional  i.e.. no further justification is required . theoretical  / e . based on the half-order theory - could be incor rect if the theory is incorrect   statistical  i e . justified by statistical experience   or default  / e.  cannot be estimated without infor mation either typically unavailable to the system or expensive to obtain . the manner in which the type of belief of a justified belief is propagated from its justifier beliefs is determined from the linkage rule  below  that enables the justification. 
the degree of belief is a numerical measure of the validity of beliefs whose type of belief is statistical or default. we have not yet explored its use. 
a justification link contains linkage rule and error propagation slots  in addition to its links in the justification structure . 
the linkage rule points to the rule of inference that enables the justified belief to be derived from the justifier beliefs  e g   modus ponens . it is described in more detail in the next section. 
the error propagation specifies the way in which errors in justifier beliefs propagate to the justified belief this form of this infor mation for a particular link is inherited from the linkage rule for the link. it allows the critic to focus on particular justifier beliefs that might be responsible for an error of a specific type in the justified belief. 
this slot is filled with a list of the form 

for example  suppose the error propagation slot for the justification link of the rule belief 1 has the value   oslhs clause!  oslhs clause1 belief 1   . this structure states that if the rule asserted by belief 1 suffers from an overspecificlefthandside error in clause1 of its left-hand side then clausel of the left-hand side of belief 1 could suffer from the same type of error. 
c. linkage rules 
a linkage rule specifies the rationale that allows a justified belief to be derived from its justifier beliefs. it can be either truth-preserving or non-truth-preserving. the only type of truthpreserving rule is deductive. it is essentially a logical proof of the validity of the derivation. 
while we hypothesize a number of non-truth-preserving linkage rules  the only one we have used to date is the abductive rule. abductive inference allows the conclusion of a- b to be drawn from b- a and a. for example  from the quasi-theoretical state-
	r. smith et al. 	1 
ment that meningitis causes fever and an observation of fever in a patient  abductive inference permits the conclusion that the patient is suffering from meningitis because fever is commonly associated with a number of other causes as well  the backward  interpretive  form of the causal rule can only be used to suggest the cause when the manifestation is observed.  for a general discussion of abduction  see .  
a linkage rule also contains type of belief propagation and error propagation slots. 
the type of belief propagation slot specifies the way that the 
types of belief of justifier beliefs are propagated to beliefs justified viathe rule. deductive rules  for example  propagate the minimum of type of belief of the justifier beliefs  according to the following partial order: definitional  theoretical  statistical  default the ab-
ductive rule is a default-producing rule regardless of the type of belief associated with the justifier beliefs  default is propagated as the type of belief of the justified belief. 
the error propagation slot specifies a template for propagating errors from justifier beliefs to justified beliefs. 
d. example: the nfr1 justification 
the hand-generated nfr1 justification structure is shown in figure ii-1. beliefs are indicated by nodes with names bi. justification links are shown between beliefs  but are not explicitly named. a capsule summary of some of the beliefs is shown. we show the entire justification structure to give some feel for its complexity. the actual number of nodes should not be taken too seriously because there is considerable latitude available with respect to what constitutes a belief and what constitutes a linkage rule. we have inserted knowledge of the task domain as beliefs and knowledge that is not specific to the domain as linkage rules  e.g.  geometry and algebra .1 
the general form of the justification is that it is based on the relative positions of three-dimensional regions associated with a fault. when these regions are penetrated by a borehole  measured data will be related to the zones that are the projections of the regions on the borehole  as manifested in patterns seen by a particular tool  e.g.  the dipmeter tool . 
nodes that are boxed in the figure are described in detail in the following. most linkage rules are deductive we only note a linkage rule when it has some special significance  e.g.  if it is non-truth-preserving . the logic encoding of each each belief assertion is shown. the reader may find it helpful to simply scan the justification at this point and refer back to it while following the example presented in section a. we only show error propagation information that is relevant to the example. the complete justification for nfr1 is found in  1  . 
b1: if p is a normal fault pattern and there exists a red pattern  p1  such that the length of pi is less than 1 ft. and pi is above the fault plane pattern of p  then p is a late fault pattern. 

   rule justifications provide support for the inferences made in the reasoning trace. similarly  we might coasider construction of another layer of justification - support for the inferences made in linking beliefs in the rule justification. we have not yet examined this sort of multilayer justification. 
1 r. smith et al. 
b1: if p is a late fault pattern  then p is also a normal fault 
pattern and there exists a p1 such that p1 is the distortion pattern of p  the length of p1 is less than 1 ft.  and p1 is above the fault 

	r. smith et al. 	1 


1 	r. smith et al. 
iii. reasoning from error types 
and justification structures 
the critic begins by considering a specific instance in which the user corrects or augments the performance program's conclusions. given any such failure  the first step is to determine specific types of errors in specific rules  that could have produced this failure. for example  if the user deletes a system-generated conclusion  then the rule that suggested this conclusion may be suspected to be in error1  with the possible error types overgenerallefthandside and overspecificrighthandside  either of these error types could have led this rule to suggest the incorrect conclusion . similarly  if the user adds a conclusion  then those rules whose right-hand side mentions that conclusion but which did not trigger are identified as possible errors of type over specificlefthandside  while rules that did apply but did not make the indicated conclusion may be suspected of overgeneralrighthandside errors.  of course  another plausible explanation for a failure of this type is absence of an appropriate rule.  
at this point  given a suspected belief  e.g.. a rule   and a list of possible error types for the belief  the critic examines the justification for that belief in order to generate a list of candidate hypotheses regarding possible causes of the error  / e.. bugs in the supporting beliefs  or approximations in the justification links relating the belief to its supporting beliefs . the method for generating and pruning hypotheses about the cause of the error is summarized below: 

this method for identifying suspect beliefs makes use of several kinds of information recorded in the justification structure for the offending rule  as well as knowledge of the context in which the rule failure occurred. these kinds of information and their use may be summarized as follows: 
the logical dependencies of one belief on another  recorded in the justification structure  provide the basis for generating candidate suspects. the justification structure is the basis for a  complete  generation of suspects  in the sense that the only possible errors in the underlying domain knowledge that could produce the detected rule error are those involving beliefs mentioned in the rule's justification structure. all the other sources of knowledge that enter into the process serve to constrain the suspects generated on this basis. 
the additional knowledge about error types  together with the 
error propagation knowledge associated with each justification link  allows the critic to prune the set of suspects. in other words  certain supporting beliefs on which the offending rule is based can be pruned as suspects when it can be shown that no error in those beliefs could produce the detected rule error. 
knowledge of the situation in which the failure occurred may allow the system to separately verify the correctness of suspected supporting beliefs. for example  rule nfr1 depends  among other things  upon the assumption that normal faults have associated distortion regions. if this rule is suspected of a failure  that supporting assumption may become suspect. but if there is strong direct evidence in the current situation that a distortion region is present  then that suspect may be pruned. 
type of belief knowledge propagated from supporting beliefs as specified by the associated linkage rule allows further ranking and pruning of suspects. 
a. example: use of the nfr1 justification 
as an example  we assume a scenario in which the user has indicated that a particular hypothesized  normal fault  should be specialized to a  late fault.  the las takes this as an indication that it has committed an error of omission by failing to make this specialization on its own  and invokes the critic to explain the failure. 
the critic begins by examining the reasoning trace of the performance program and determines that rule nfr1 could have drawn the correct conclusion  but failed to match. for simplicity we will assume that nfr1 is the only rule that could have drawn 
the correct conclusion.1. the critic examines the situation in which the rule was attempted and  through interaction with the user determines that: 1  the user agrees that the normal fault conclusion drawn by the performance program is correct; and  n  the performance program detected a satisfactory red pattern that is above the fault plane pattern of the normal fault  but is longer than 1 ft. in general  the critic uses a combination of the reasoning trace and the rule justifications to track down the source of the failure. if  for example  the red pattern had been found to be unacceptable to the user  then attention would have been focussed on the detector for that pattern. 
as a result of this preliminary analysis  the critic hypothesizes that rule nfr1 has committed an error of type overspecificlefthandside  specifically in clause 1. the critic now attempts to explain this error in terms of the justification for nfr1 {i.e.  for b1 in figure ii-1   in order to determine which types of errors in its supporting beliefs could have caused this error. the following paragraphs summarize the generation and pruning of suspect beliefs generated by the procedure explain described above. 
in the first step of this procedure  the justification of b1 is ex amined to find that it depends upon b1  and that the overspecific lefthandside error in b1 can only be explained by an over-
   of course if other rules are available which could have drawn the correct conclusion  then their justifications must be examined to generate additional hypotheses. while this may add substantially to the number of hypotheses that the critic must consider  it does not change the reasoning that the critic goes through in considering each hypothesis. 
specificrighthandside error in b1  as a result of the abductive linkage rule. 
the error propagation information associated with b1 follows from the linkage rule  and is used to determine the error type for b1. 
by propagating the error in b1 in this way  the problem of explaining the overspecificlefthandside error in b1 is reduced to the problem of explaining the corresponding overspecificrighthandside error in b1; specifically  in clause 1 of b1. note once more that the exact identification of the the error type for b1 is determined by a combination of propagating the error type from b1  and checking the left-hand side of the implication b1 against the known facts in the current situation. 
the overspecificrighthandside error in b1 is explained in turn by examining its justification. as shown in the figure  b1 is derived from b1 and b1. this step in the justification corresponds to a renaming of terms  and the beliefs themselves are not particularly interesting. however  one important point is worth noting: while the error in b1 can be explained by an overspecificrighthandside error in either b1 or b1  the first of these suspect beliefs is eliminated because its type of belief is definitional - hence above suspicion. 
the remaining error hypothesis  that b1 has committed an overspecificrighthandside error  is next propagated to its supporting beliefs. although any of the supporting beliefs could lead to an overspecificrighthandside error in b1  b1 is pruned because its type of belief of b1 is definitional. 
the type of belief of b1 is theoretical  / e. it can only be incorrect if the approximate domain theory is incorrect . our current critic ranks suspects that would require a change to the approximate theory lower in likelihood than suspects that would not require such a change. it will only consider making a change to the approximate theory if it cannot explain the failure in any other way. as a result  b1 is noted for later examination if another explanation cannot be found. as a result of this pruning  the critic focusses its attention on an overspecificrighthandside error in b1. 
the further error propagation from b1 to its supporting beliefs illustrates the importance of distinguishing error types to the task of eliminating suspects. in this case  while there are five beliefs that directly support b1  only two of these become suspects for explaining the detected error. this is because the error propagation information associated with b1 indicates that no kinds of errors in the other three beliefs could result in the present error. thus  the two candidate suspects at this point are overspecific righthandside errors in b1 and b1 
continuing in this manner  the critic finally arrives at two plausible explanations for the original rule error  corresponding to nodes b1-an underestimate of the distortion region thickness and b1-an understimate of the orientation. in order to resolve between these hypotheses  the critic will attempt to observe or infer the orientation and distortion region thickness from other casespecific data. if this course of action fails  it will rank these suspects hypotheses based on the relative degree of belief of the two default value assumptions. 
	r. smith et al. 	1 
now that the critic has isolated the possible explanations of the detected error  a decision must be made regarding whether and how to alter the offending rule. in cases where the explanation indicates that the training instance is a statistical outlier  i.e.  that the orientation is several standard deviations above the mean in this case   it may be best to leave the rule as is and simply update the statistics supporting the default value of the orientation. if the current case suggests instead that the default value is often incorrect {e.g.  that in fact in most cases the assumption is violated   then the default may be changed and the rule revised accordingly  e.g   change the maximum length of the red pattern in this rule to a larger number . in general  the decision of whether and how to change the rule must depend on a cost benefit analysis which takes into account benefits of changing the rule  e.g.. increased accuracy  as well as the costs  e.g.  referring to parameters such as orientation which may not often be known  and which therefore make the rule unusable in many cases  at present we plan for an interactive rule editor that will present the results of the critics analysis to the user to consider alternative rule repairs. 
iv. conclusions and directions 
we have shown the utility of a particular linkage of shallow rules to underlying domain knowledge as an aid to knowledge base refine ment in the context of a learning apprentice system. the linkage called a justification structure  explicitly records the assumptions and approximations involved in the derivation of a shallow rule furthermore  we have demonstrated the utility of maintaining a taxonomy of error types. information about the type of error that has been observed  together with the justification structure  can help focus the critic's search for plausible suspect beliefs 
the work reported here represents the initial results of our efforts to explore the representation and use of justifications to support automatic refinement of knowledge bases. while several recent research efforts have focused on constructing explanations  or justifications  to guide generalization learning  1 1   this work complements those efforts by considering complex explanations involving default assumptions  and non-truth preserving justification rules. 
while the importance of constructing and using justifications in learning is clear  there are several serious issues that remain to be understood. these include: 
it is still not clear precisely what statement about a rule should be justified. in this paper the focus is on justifying the logican correctness of the rule. however  in many cases the dipmeter advisor system rules are not  strictly speaking  correct. instead  they are convenient approximations to the truth. for example  the rule nfr1 is not correct since its preconditions are not logically sufficient conditions for assuring the existence of a late fault. to be correct it would require many more preconditions  including the condition that the borehole is not washed out  and that the fault angle is less than 1бу. unfortunately  such a logically correct version of the rule would not be very useful because one rarely knows enough about a given situation to assure that all the necessary preconditions actually are satisfied  e.g.  one typically does not know the angle of the fault . therefore  we create and use rules that are convenient falsehoods-simple enough to be useful in a broad range of 

  1 	r. smith et al. 

situations  and close enough to the truth to keep from creating disaster when they are incorrect. an appropriate justification for rules should therefore take into account tradeoffs between correctness  applicability  cost of application  cost of different types of failure  and utility of a rule. we intend to explore various criteria for characterizing the appropriateness of rules  and to extend our formalism to accommodate these criteria. 
we have only developed weak methods for dealing with the expected interaction of rule refinement and extension of the underlying domain theory. we have assumed  for the most part that the underlying theory is correct and that failures are due to violated assumptions and approximations used m deriving the rules. when this is not true  our only recourse is to engage  n a 
dialogue with the specialist. 
another fundamental issue lies in the difficulty of acquiring rule justifications. the justification of nfr1 involves some 1 sup porting beliefs. acquisition of large numbers of justifications with this complexity  along with acquisition of the rules themselves  could place a significant additional burden on our domain specialists. such a burden could have serious negative implications for practical use of justifications in knowledge base refinement. we have  however  succeeded in constructing a 
prototype system for generating interpretation rules from an ap proximate domain theory  and associated procedures for con structing the rule justifications based on the trace of the generation procedure. although this is provocative and encouraging  we do not yet understand the complexity of justifications  and we have much to learn about the difficulties of con structing complex justifications in a domains with imperfect theoretical underpinnings  such as geology . 
acknowledgements: 	john mcdermott  smedar kedar 
cabelli  and rich keller made a number of insightful suggestions and comments on an early draft of this paper. mike barley also tested some of the ideas. the reviewer offered a number of ex tremely helpful criticisms and suggestions. 
