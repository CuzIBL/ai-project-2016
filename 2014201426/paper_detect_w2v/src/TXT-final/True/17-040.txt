 
　　a notation is given for describing the inverse of multiple functions and of functions of multiple arguments. a technique based upon this notation is presented for taking a program written in pure lisp and automatically deriving a program which computes the inverse function of the given program. this technique differs from previous such methods in its use of heuristics to invert conditionals. 
1. introduction 
there are many applications in which it is useful to compute the inverse of some program  that is  to find another program such that feeding the output of the original program as input to the new program produces the original input. one such application is in program ming by specification: one would like to define a program to compute the square root of a number by the equation  〔x 1 = x rather than supplying an actual iterative method of solving the equation. another application of program inversion is in debugging. given a program and an erroneous result  one would like to step backwards through the program to trace the source of the error. yet a third application is in transforming the input domain of a program  such as the well known technique of multiplying polynomials by first performing an fft; to get the result back into the original domain one needs to find an inverse transformation. 
     several methods have been suggested for performing such inver sion. unfortunately they each suffer from several defects. mccarthy  suggests a generate and test approach; this will correctly find an inverse when it exists  but is computationally infeasible and cannot determine whether the inverse is unique. dijkstra  provides a technique for inverting programs symbolically  but requires that the programmer provide inductive assertions on conditional and loop statements. korf  suggests another method that automatically provides these assertions  but recursions derived using his method a-e not guaranteed to be well founded. several recent efforts  1  have gone into inverting prolog; this differs from inverting other programming languages in that prolog is less procedural and more declarative. methods for inverting procedural languages will thus also be useful for prolog  but the reverse is not necessarily true. 
　　this paper suggests a method of providing these assertions automatically by heuristic methods. this method will not always find an inverse for a program  but when one is found it will always correctly terminate when the output of the original program is given as input. in addition  if an inverse is found it will be the case that the original function was one-to-one-in principle the inverse could itself be inverted to recover the original program. 
　　the method described here has been implemented as a maclisp program. the program was able to derive the inverse of append  shown in detail below   a version of reverse as given in  1|  unary integer negation defined recursively using add1 and sub1  and several other such small programs. the example of unary negation is especially interesting as a case where korf's method is unable to find the inverse  because of the existence of two recursive clauses in its definition. 
1. inversion of multiple functions of multiple arguments 
the usual definition of the inverse of a function   	is the 
function such that for all x in d. unfortunately this notation does not lend itself well to inversion of functions of more than one argument. for instance  in the lisp programming language it is true that 
thus one intuitively thinks of car and cdr together as being the inverses of cons  but there is no one function that we can call cons 1. 
   on the other hand  we can express a relation between / and that does extend to multiple arguments and also to multiple functions: if we assume that   then by the above definition and the converse similarly holds. thus we have 

are both true. taking this as our definition of inversion  we say that cons inverts to car and cdr. 
　　in general we will say that some list of n functions fun  of m arguments each inverts to another list of m functions inv1 of n arguments each if  for all x1 and y   the set of equations 

simultaneously hold if and only if the inverse set of equations 

also simultaneously hold. note that this relationship is symmetric: inverting the inverses of a list of functions produces the original list. the requirement that all functions have the same number of arguments turns out not to be a problem; if necessary we can add dummy arguments to those functions that need them. 
　　since we are attempting to invert programs  we will need to have inverses for the primitive operations of the language we are inverting. in lisp  we will use the fact that cons inverts to car and cdr  and that add1 inverts to subb1. these can be used to define the other arithmetic and list manipulation functions usually found in a lisp implementation. 

1 	d. eppstein 
1. the inversion method 
we perform inversion as a search through a state space of program descriptions. each state is a set of facts  each of which is composed of a left side  a right side  and a set of preconditions. a fact can be interpreted as meaning that  if the preconditions all hold  the left side will be equal to the right side. we will use four operators to move from state to state: conditional expansion  precondition replacement  expression inversion  and conditional contraction. 
for example  suppose we want to invert the function append. 
that is  we want to find two programs that  given the result of a call to append  will return the first and second arguments. unfortunately there are many possible pairs of arguments that could have produced the same result from append; thus we need to introduce an auxiliary function to distinguish among them. one function we might use returns the length of its first argument and ignores its second; we will call it flength. we will call the arguments to it and append by the names f irstn and lastbutn for reasons that we shall see below. the definitions of our two original functions give us our initial state: 
append =  cond   null firstn  lastbutn  
 t  cons  car firstn  
 append  cdr firstn  lastbutn     
flength =  cond   null firstn  1  
	 t  add 	 flength  cdr firstn  
lastbutn     
　　the atoms on the left sides correspond to a call to each of the functions being defined  and those on the right side correspond to the arguments to those calls; there are no unbound variables. all initial facts have no preconditions  and their left sides are all atomic. similarly we will define a goal state as one in which all sets of preconditions are empty and the right sides are all atomic. no new atoms will be introduced by our transformations  and each atom will occur only on one side of our facts; thus the original arguments will become the names of the inverse programs  and the original program names will become the inverse arguments. 
     both facts in the current state have no preconditions  but the right side of each is a conditional expression. before we can perform any other transformations on the facts  we first separate out the conditional parts into preconditions. the conditional expansion operator does this; it replaces a fact for which the right side is a conditional expression with two facts  one corresponding to the case when the predicate in the condition is true and one corresponding to the case when it is false. applying this to each of the facts in our initial state produces a new state: 

　　note that the above state consists of four facts  each of which has a precondition of either  null firstn  or  not  null firstn  . the preconditions are combined in the above display merely for the sake of brevity. 
　　in our final inverse programs  we will need a conditional expression to determine which path the original programs took. another way to think of this is that the preconditions in the current state are functions of the arguments to the original functions  and we would like to replace them with new functions of the arguments to the inverse functions that are true exactly when the old ones were. this replacement is the heuristic portion of the inversion; in general there will be many possible preconditions but there seems to be no analytic method of finding them. 
　　the details of how we find the new precondition will be described below; in this case we notice that f length will be zero if and only if f i r s t n is null. once we have found our new precondition  we can use the precondition replacement operator. note that if we simply replaced all occurrences of the old precondition with the new one we would derive the useless fact 

but we would not produce 

without which we could not complete our derivation. taking this into account  we come up with a new transformed state: 

     now the derivation goes through a sequence of expression inversions  pulling functions from the right side of facts over to the left. this process is completely mechanical  but it is somewhat complicated so we will go through it one step at a time. first we notice that we have a call to addl as the outer call of the right side of a fact 
when we invert this call to subl  our state becomes 

　　in this case we inverted one function to one function  so the total number of facts in our state didn't change. when we invert cons to car and cdr  however  we get two facts where before we had one: 

     the above inversions were done on functions for which already knew the inverses. we must also invert recursive calls to the original functions into recursive calls to our new inverses. since in this case we have two functions of two arguments each  we will replace two facts with two new facts. this inversion cannot be split into two steps  because each new fact has parts from both of the old facts. note also that the arguments in the calls have to match exactly; it would not have changed the result of f length if the second argument in the recursive call were different  but it would have made it impossible to complete our inversion. performing the inversion  we get to a new state: 

　　now all but two of the right sides are atomic; these two can be made atomic by one more inversion  from car and cdr into cone. 

     we are almost at a goal state; the only remaining task is to remove the preconditions. this can be achieved by the conditional contraction operator  which acts inversely to conditional expansion: it takes two facts with opposite preconditions and identical right sides  and combines them into one fact having as a left side a conditional expression evaluating to either of the two previous left sides depending on which precondition is true. we must be careful here only to accept preconditions that are in terms of the inverse arguments  or we would not come up with a well-defined program; this is the reason for our precondition replacement above. two applications of conditional contraction produce a goal state: 

1. precondition replacement 
the above method provides a framework for inversion; we also need heuristics to be used in that framework for finding replacement preconditions. one such heuristic that is effective for many simple recursions uses a sort of data type system. all objects are members of type top  which is divided up into integers  conses  and n i l . unlike most data type systems we have types corresponding to major subsets of the integers: the negative numbers  the positive numbers  zero  and the unions of pairs of these sets. the main requirement on our type system is that it form a lattice; thus we also need a type bottom to which no object belongs. 
　　functions are assigned types that contain all their possible return values. thus cons always returns a cons  and add1 always returns a number  but car and cdr can return anything and so their type is top. the type of a function should itself be a function mapping from the function's input types to its output type  but for simplicity this is only actually done for addl and subl  e.g. addl will return positive numbers if its argument is non-negative . 
     given a list of new functions to be inverted  or a list of inverse functions to be used in further inversions  we can calculate their types by a simple relaxation process: we start by assuming that the return type of each of them is bottom. then we use that in evaluating the types of the expressions defining them  making no assumptions about the types of their arguments  to arrive at a new assignment of types  and iterate until no function's type is changed by the iteration. with our definition of f length  for example  the first iteration would result in a type of zero from the base clause  and bottom from the recursive clause  which combine to a type of zero. then the second iteration gives the same base clause type but the recursive clause is now known to return positive numbers  and so the new type becomes that of the non-negative numbers. adding one to a non-negative number as with adding one to zero returns a positive number  so in the third iteration the overall type doesn't change. thus the final type of f length is 
d. eppstein 	1 
that of the non-negative numbers. in a more complicated recursion the preliminary types of the recursive clauses might cause their new types to change  and so there could be up to as many iterations as the depth of the type lattice. 
　　now we can use our type system to provide replacement preconditions. this is done by looking for two facts with identical left sides  and identical preconditions except for the particular precondition we wish to replace  which should be true for one fact and false for the other. then we calculate the types of the right sides of the facts  and if the intersection of the two types is bottom then we can replace our precondition with a test for membership on the common left side in one of the two types. thus in the append example  f length is zero for the fact with precondition f i r s t n true  and it is positive  and therefore not zero  with f i r s t n false. 
1. future work 
the main obstacle to inversions with the current implementation is the inability of the heuristic described above to find replacement preconditions that are functions of more than one argument. more effort could be put into methods of finding complex predicates; it might prove fruitful for heuristics to notice whether the function being inverted is arithmetic or list processing and tailor the search accordingly. 
　　in the inversion of append we needed to introduce an auxiliary function. because append recurs linearly we could simply count the number of recursive calls  but this will not always be sufficient. work could be done in automatic detection of the need for such an auxiliary function  and in automatic generation of the function when its need is detected. 
　　some thought in the program transformation world has gone into the idea of a macsyma-like system for computer programs. the representations and operators used in this paper appear useful in other domains than inversion; one might study how applicable they would be in a more general program transformation system  and how they could be incorporated into such a system. 
acknowledgements 
i would like to thank my advisor  rich korf  for many helpful discussions and suggestions. this research was sponsored in part by a national science foundation student fellowship and by the defense 
advanced research projects agency under contract n1-c1. 
