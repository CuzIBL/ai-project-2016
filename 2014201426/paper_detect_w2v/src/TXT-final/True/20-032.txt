: 
     many problems in early vision are ill posed1. edge detection is a typical example. this paper applies regularization techniques to the problem of edge detection. we derive an optimal filter for edge detection with a size controlled by the regularization parameter and compare it to the gaussian filter. a formula relating the signal-to-noise ratio to the parameter  is derived from regularization analysis  showing that the scale of the filter is a function of the signal-to-noise ratio. we also discuss the method of generalized cross validation for obtaining the optimal filter scale. finally  we use our framework to explain two perceptual phenomena: coarsely quantized images becoming recognizable by either blurring or adding noise. 
1. 	introduction 
if edge detection is considered as a problem of numerical differentiation  the first step is to regularize it. standard regularization techniques suggest the use of gaussian-like filters before differentiation1. in this paper  we address the important issue of how to estimate the optimal scale of the filter  that is  the amount of smoothing required by the given image data. 
1. 	framework for edge detection 
regularization techniques for ill-posed problems 
a problem 
		 1  
for which the class 1 of solutions z  given a and u  is not compact  changes on the right-hand side of the equation can take u outside the set as  is called ill-posed. the approach suggested by tikhonov1 to deal with ill-posed problems is to construct approximate solutions of equation  1  that are stable under small changes in the data u. if the right-hand side of equation  1  is known only approximately  we have 	where 

may not exist since the last integral may diverge. furthermore  even if this ratio does have an inverse fourier transform  the deviation from zero  in the can be arbitrarily large  and  thus we cannot think of the exact solution of equation  1  as an approximate solution of the equation with approximate right-hand side. 
¡¡¡¡finding edges in an image is in general an ill-posed problem1  since it involves taking an appropriate derivative of noisy data  notice that we do not specify which derivative operator should be used: it may be a directional derivative1 or any other desirable differential operator . the differentiation of is ill-posed  since it can be viewed as a solution of equation 1 for the operator a of the form 

where h x  is the step function. as described by rheinsch' and by poggio and torre1  this problem can be regularized by smoothing the data before taking derivatives. the idea is to consider the regularized solution  to equation  1   with a being the imaging operator  such that z is sufficiently well-behaved for numerical differentiation. to approximate a solution of equation  1  one takes the solution of a different problem  that of minimizing the functional given bv. 
		 1  
that is close to the solution of the original problem for small values of the error in the data. tikhonov1 proved that for the case of one dimensional image data. here 
	gelger and poggio 	1 


1 	perception 

1. coarse quantized images can be better recognized when noise is added 
we first discuss the perceptual phenomena of improved recognizability of coarse quantized images when noise is added1. consider the image of figure 1a with 1 by 1 pixels. a coarsely quantized version of it is shown in figure 1c. the optimal filter for figure 1c  estimated as explained above  turns out to have a small scale of pixels corresponding to very low noise the sign of the zero-crossings  figure 1d  do not easily reveal a face. gaussian white noise with standard deviation 1 is the added to figure 1c  see figure 1e   making recognition easier. estimation of the optimal scale gives now a width of pixels. the corresponding zero-crossing contours reveal the face in a much better way. these results may shed some light on what the visual system may be doing. harmon and julesz1 claim that for the quantized image  high frequencies introduced by quantized blocking mask the lower spatial frequencies which convey information about the face  preventing recognition . 
in our framework two process determine recognizability of the face. the first process consists of the estimation of the signal-to-noise ratio the second step is to use  to set the optimal for then computing an appro-
priate derivative and corresponding  edges . in the case of the quantized image the ratio is large. is then small  which implies that a large bandwidth channel  in the spatial-frequency domain  is selected. the zero crossings for this channels do not easily allow face recognition because they mostly capture the box outlines. for noisy quantized images the ratio is small and correspondingly is large. this imply a filter with small bandwidth. in this case the small bandwidth filter suppresses the noise and  as a side effect  also the high frequency outlines of the boxes. 
this explanation is not in contrast with the one given by 
canny1 or by morrone  burr and ross when they claim 
 that added noise  more high frequencies  destroys the propensity to organize the image according to its spurious high-frequency structure  ...   but is more precise. 
	gelger and poggio 	1 

1. improved recognizability of coarse 1. quantized images by blurring 
blurring coarsely quantized images also improve recognition1. the explanation for this second perceptual phenomena is natural in our model. blurring is equivalent to using an effectively larger filter for edge detection. this has the effect of suppressing the spurious high frequency edges introduced by coarse quantization.* 
1. the method of generalized cross validation and regularization 
when so/n1 cannot be directly estimated  it is natural to consider the method of generalized cross validation 
 the gcv method states that the optimal value of a  can be obtained by minimizing the functional  here in one dimension  
 1  
assuming the filter to be gaussian-like  using the optimalfilter would be computationally more expensive  equation 
1 reduces to 

the method is computationally expensive but intrinsically parallel. we have implemented it on connection machine. we tested this method on different images including the ones in figure 1 with various amounts of noise. the important result was the consistence of the gcv with the results obtained by a method described earlier. slices of the image 1 pixels require 1 miliseconds for computing 
 using newton's method to find the minimun  the algorithm converges after 1 intensions of  therefore the gcv method takes in this case 1 seconds to find the optimal a. 
1. 	conclusion 
we have derived rigorously the optimal way of filtering images prior to numerical differentiation. we also obtained the precise relation between the scale of the filter and the signal-to-noise ratio of the image. some biological implications were also considered. in particular we suggested that humans can estimate the signal-to-noise ratio in the image from which the scale  is computed. only channels channels with the appropriate spatial-frequency band 
notice that blurring the quantized noisy image has the effect of increasing the estimate of signal-to-noise ratio  thereby reducing 1 to a value close to the one obtained for the quantized image. 
1 	perception 
are then used  the others being inhibited. in this framework it is possible to understand the perceptual phenomena of improved recognizability of coarsely quantized image when noise is added. when the signal-to-noise ratio is large  the estimated is small and the associated zerocrossings do not provide good information for recognition. when  is smaller  the estimated a is larger: the zerocrossings provide then a better information for recognizing the face in the image. when the signal-to-noise ratio cannot be estimated it is possible to use the method of cross validation for estimating the optimal 
acknowledgments: we are grateful to a. yuille for many discussions  with d.g. . thanks to e. gamble  m. gennert  and h. voorhees who were always helpful. 
