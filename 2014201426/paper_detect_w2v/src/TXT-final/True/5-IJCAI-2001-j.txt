
extracting rules from rbfs is not a trivial task because of nonlinear functions or high input dimensionality. in such cases  some of the hidden units of the rbf network have a tendency to be  shared  across several output classes or even may not contribute to any output class. to address this we have developed an algorithm called lrex  for local rule extraction  which tackles these issues by extracting rules at two levels: hrex extracts rules by examining the hidden unit to class assignments while mrex extracts rules based on the input space to output space mappings. the rules extracted by our algorithm are compared and contrasted against a competing local rule extraction system. the central claim of this paper is that local function networks such as radial basis function  rbf  networks have a suitable architecture based on gaussian functions that is amenable to rule extraction.
1	introduction
neural networks have been applied to many real-world  largescale problems of considerable complexity. they are useful for pattern recognition and they are robust classifiers  with the ability to generalize in making decisions about imprecise input data  bishop  1 . they offer robust solutions to a variety of classification problems such as speech  character and signal recognition  as well as functional prediction and system modeling where the physical processes are not understood or are highly nonlinear.
　although neural networks have gained acceptance in many industrial and scientific fields they have not been widely used by practitioners of mission critical applications such as those engaged in aerospace  military and medical systems. this is understandable since neural networks do not lend themselves to the normal software engineering development process. knowledge extraction by forming symbolic rules from the internal parameters of neural networks is now becoming an accepted technique for overcoming some of their limitations  shavlik  1; sun  1 .
　in this paper we describe our method of extracting knowledge from an rbf network which is classed as a local type of neural network. that is  its internal parameters are limited to responding to a limited subset of the input space. we also compare and contrast our technique with a specialized local type neural architecture. the extracted rules are examined for comprehensibility  accuracy  number of rules generated and the number of antecedents contained in a rule.
　the paper is structured as follows: section two describes the motivations for performing knowledge extraction. section three describes why the architecture of the radial basis functionnetwork is particularysuitable for knowledgeextraction. section four outlines how our knowledge extraction algorithm produces rules from rbf networks and section five explains the results of the experimental work. section six discusses the conclusions of the experimental work.
1	knowledge extraction
in this section we discuss motivations  techniques and methodology for knowledge extraction from rbf networks. rbf networks provide a localized solution  moody and darken  1  that is amenable to extraction  which section three discusses in more detail. it is possible to extract a series of if..then rules that are able to state simply and accurately the knowledge contained in the neural network. in recent years there has been a great deal of interest in researching techniques for extracting symbolic rules from neural networks. rule extraction has been carried out upon a variety of neural network types such as multi-layer perceptrons  thrun  1   kohonennetworks and recurrent networks  omlin and giles  1 . the advantages of extracting rules from neural networks can be summarized as follows:
the knowledge learned by a neural network is generally difficult to understand by humans. the provision of a mechanism that can interpret the networks input/output mappings in the form of rules would be very useful.

deficiencies in the original training set may be identified  thus the generalization of the network may be improvedby the addition/enhancementof new classes. the identification of superfluous network parameters for removal would also enhance network performance.
analysis of previously unknown relationships in the data. this feature has a huge potential for knowledge discovery/data mining and possibilities may exist for scientific induction  craven and shavlik  1 .
　in addition to providingan explanation facility  rule extraction is recognisedas a powerful technique for neuro-symbolic integration within hybrid systems  mcgarry et al.  1 .

figure 1: knowledge extraction system data flow and data transformation
1	radial basis function networks
radial basis function  rbf  neural networks are a model that has functional similarities found in many biological neurons. in biological nervous systems certain cells are responsive to a narrow range of input stimuli  for example in the ear there are cochlear stereocilla cells which are locally tuned to particular frequencies of sound  moody and darken  1 . figure 1 shows a network trained on a noisy xor data set for illustration. this network has two input features  two output classes and four hidden units.
　the rbf network consists of a feedforward architecture with an input layer  a hidden layer of rbf  pattern  units and an output layer of linear units. the input layer simply

figure 1: parameters for rbf network trained on noisy xor
transfers the input vector to the hidden units  which form a localized response to the input pattern. learning is normally undertaken as a two-stage process. the first stage consists of an unsupervised process in which the rbf centres  hidden units  are positioned and the optimum field widths are determined in relation to the training samples.
　the second stage of learning involves the calculating the hidden unit to output unit weights and is achieved quite easily through a simple matrix transformation.
　the radial basis functions in the hidden layer are implemented by kernel functions  which operate over a localized area of input space. the effective range of the kernels is determined by the values allocated to the centre and width of the radial basis function. the gaussian function has a response characteristic determined by equation 1.
		 1 
　the response of the output units is calculated quite simply using equation 1.
 1 
where:
w = weight matrix  z = hidden unit activations  x = input vector 	= n-dimensional parameter vector  = width of receptive field.
1	rbf training
the first stage was to train rbf networks to an acceptable level of accuracy on all data sets. the specific level of accuracy varied with each data set  the literature was examined to provide guidance on what accuracy levels could be achieved. the accuracy levels stated in the tables are the best out of up to 1 test runs. training of the rbf networks required the setting of three parameters  the global error  the spread or width of the basis function and the maximum number of hidden units. the value assigned to the global error setting may result in fewer hidden units being used than the maximum value. if the error value is not reached  training will terminate when the maximum number of hidden units has been assigned. the training and test data for the construction of the rbf networks were generally split 1.
1	data sets
in order to allow good benchmarking and comparison we used a mixture of well known benchmark data as well as two new vibration data sets for our tests. the data sets were selected from various sources but mainly obtained from the collection maintained by the university of california at irvine  uci . the vibration data sets were produced as part of two large projects which were concerned with the monitoring the health of industrial machinery. the data sets represent a variety of synthetic and real world problems of varying complexity  i.e. number of examples  input features and classes .
table 1: composition of data sets used in experimental work
data setexo/pi/pcdmxor binary 11noyesnoxor continuous 11yesnonoiris11yesnonovowell peterson 11yesyesnovowell deterding 11yesyesnoprotein yeast 11yesnonoprotein ecoli 11yesnonocredit japanese 11yesyesyescredit australian 11yesyesyesdiabetes pima 11yesnonomonks11noyesnosonar11yesnonovibration 11yesnonovibration 11yesnono　table 1 gives details of the data sets. the columns indicate the number of examples  the number of ouput features or classes  the number of input features  whether the data set contains continuous data or discrete data and the last column indicates if any data is missing.
1	lrex: rule extraction algorithm
the development of the lrex algorithm was motivated by the local architecture of rbf networks which suggested that rules with unique characteristics could be extracted. in addition  there was little published work on extracting rules from ordinary rbf networks  lowe  1 . therefore our work fills a substantial gap in rule extraction research.
　the lrex algorithm is composed of two modules: the mrex module extracts if..then type rules based on the premise that a hidden unit can be uniquely assigned to a specific output class. therefore  by using the centre locations of the hidden units an input vector could be directly mapped to an output class. experimental work performed on the simpler data sets tended to reinforce this belief. however  hidden unit sharing occurs within networks trained on non-linear or complex data. this phenomena reduces rule accuracy as several hidden units may be shared amongst several classes. the second module  hrex was developed to identify which hidden units are shared between classes. analysis of how each hidden unit contributes provides information to determine a class. the extracted rules are if..then type rules where any given hidden may appear across several classes. the next two sections describe how the mrex and hrex modules provide the user with complimentary types of extracted rules that explain the internal operation of the original rbf network.
1 mrex: input-to-output mapping the functionality of mrex algorithm is shown in figure 1.

input:
	hidden weights	 centre positions 
gaussian radius spread
output weights
statistical measure s
     training patterns output:
     one rule per hidden unit procedure:
train rbf network on data set
collate training pattern  hits  for each hidden unit
for each hidden unit
	use	correlation to determine class label
use  hits  to determine s select s format
for each
build rule by: antecedent join antecedents with and
add class label
write rule to file

figure 1: mrex rule-extraction algorithm
　the first stage of the mrex algorithm is to use the w1 weight matrix  see figure 1  to identify the class allocation of each hidden unit. the next stage is to calculate the lower and upper bounds of each antecedent by adjusting the centre weights using the gaussian spread . the lower and upper limits are further adjusted using a statistical measure s gained from the training patterns classified by each hidden unit. s is used empirically to either contract or expand each antecedents range in relation to the particular characteristics of these training patterns.
　the entire rule set for the iris domain is presented in figure 1. note that there are four extracted rules  one for each rbf hidden unit.

rule 1 :
if  sepallength	1 and	1  and if  sepalwidth	1 and	1  and
if  petallength	1 and	1  and
if  petalwidth	1 and then..setosa
rule 1 :1 if  sepallength	1 and1  andif  sepalwidth	1 and1  andif  petallength	1 and1  andif  petalwidth	1 and then..versicolor
rule 1 :1 if  sepallength	1 and1  andif  sepalwidth	1 and1  andif  petallength	1 and1  andif  petalwidth	1 and	1 
then..virginica
rule 1 :
if  sepallength	1 and	1  and if  sepalwidth	1 and	1  and
if  petallength	1 and	1  and if  petalwidth	1 and	1 
then..virginica

figure 1: mrex extracted rules from iris domain
1 hrex: hidden unit analysis
a different approach to rule extraction is taken by the hrex algorithm which uses quantization and clustering on the network parameters  weights and activation levels  to form an abstraction of its operation. the number of extracted rules is determined by the user who can place an upper limit on the rules extracted for each class. this is a useful feature since it enables a tradeoff to be made between rule size and rule comprehensibility. this is achieved by three important parameters:
   which determines the minimum weight value  postive  to be quantized as a  one   weights below this cutoff point are quantized to 1 and do not participate in rule extraction.
　which determines the minimum hidden unit activation level. hidden units with activation levels below this cutoff point will not be quantized and will play no further part in rule extraction.
n determines the maximum number of clusters that the training set  for each class  is divided into. this process abstracts the input space into a number of distinct regions which will require a separate rule to identify.
　these parameters are determined empirically for a satisfactory arrangement. figure 1 shows the algorithm in detail. note that valid rules consist of both a positive quantized weight  qw1  and a positive quantized activation  aqz  level. a rule consists of one or more hidden units which must all be active for the class lable to be satisified.

input:
output weights
	hidden unit activations	 training data 
output weights quantization modifier
hidden unit activation quantization modifier
maximum cluster number n
　　　training patterns by sorted by class t intermediate information:
quantized w1 weights qw1
quantized hidden unit activations qz
　　　average quantized hidden unit activations aqz output:
　　　one rule per cluster procedure:
quantize w1 weights with quantize hidden unit activations with
separate training patterns by class t for each class
partition qz up to nc clusters
for each n cluster
identify positive qz activations
calculate average aqz value for cluster
   identify positive qw1 weights attached to qz build rule by:
if aqz==positive and qw1 ==positive
hidden unit h belongs to rule join hidden units with and
add class label
write rule to file

figure 1: hrex rule-extraction algorithm
　some hrules rules extracted from the ecoli domainare presented in figure 1. for instance  for rule 1 to  fire   each antecedent must be satisfied so hidden units 1  1  1  1  1  1  1 and 1 must all be active. it can be seen that hidden unit 1 participates in both class 1 and class 1.
　hrex rules are useful for identifying the internal structural relationships formed by the hidden units. this is demon-

rule 1 class: 1
if  h1true  and h1true  and h1true  and h1true  and h1true  and h1true  and h1true  and h1true  then
class: 1
rule 1 class: 1
if  h1	true  and
 h1true  and h1true  and h1true  and h1true  then
class: 1

figure 1: hrex extracted rules from ecoli domain
strated on those rbf networks that have a poor performance on certain classes. these rbf networks produce hrex rules which exhibit a large degree of hidden unit sharing or in the worse cases fail to generate any hrex rules for these classes.
　figure 1 shows the accuracy of the hrex rules against the rule size  comprehensibility for rbf networks trained on the vibration 1  monks and sonar data sets. the vibration shows a steady increase in accuracy with each additional rule until it levels off at a cluster size of 1. the rules extracted from sonar actually lose accuracy beyond a certain point before the accuracy reaches a steady value. generating additional rules for the monks after the optimum cluster size is reached produces an oscillating effect where the accuracy does not level off.
1	analysis of results
the performance of the rbf rule extraction algorithm was compared with a related system called mcrbp/rulex which was developed by andrews and geva  andrews and geva  1 . mcrbp builds rbf-like networks with specialized activation functions. once the networks are trained  the rulex algorithm can then be used to extract if..then rules with boundaries. the rules extracted by rulex are in a very similar format to those produced by the author's system. table 1 shows the results of the experimental work. the first column identifies the data set. the second column presents the mrex accuracy alongside the original rbf accuracy. the third column details the hrex accuracy next to the original rbf accuracy and the fourth column shows the
rulex accuracy

figure 1: hrex rule size and complexity
table 1: comparison between rbf net  mrex  hrex and rulex accuracy
data setmrexhrexrulexxor binary 111xor continuous 111iris111vowell peterson 11-vowell deterding 111protein yeast 111protein ecoli 111credit japanese 111credit australian 111diabetes pima 111monks1/1/1sonar11-vibration 1/1/1vibration 1/1/1-　table 1 shows the number of rules generated by the three systems. the rule set size quoted for lrex is based on the unmodified basic version.
　rulex extracts highly compact rule sets compared with lrex. the majority of the domains can be represented with as few as 1 rules. unfortunately  rulex completely failed to generate rules for three of the domains. this problem was tracked down to the initial mcrbp network  as it was unable to form a viable classifier on the training data. therefore  any rules extracted would be invalid. rulex also failed to provide rules to cover a specific class in the vibration 1 domain. training the mcrbp networks took fewer attempts to reach acceptable accuracies than the equivalent rbf networks  typically 1 runs .
　mcrbp/rulex could not form a viable network on the vowel  sonar and vibration 1 domains. it is likely that the specialized architecture cannot cope with the large number of table 1: comparison between rule set size of mrex  hrex and rulex
data setmrexhrexrulexxor binary 11xor continuous 11iris11vowell peterson 1-vowell deterding 11protein yeast 11protein ecoli 11credit japanese 11credit australian 11diabetes pima 11monks11sonar1-vibration 11vibration 11-input features present in these data sets. however  by using non-overlapping local functions the mcrbp/rulex algorithm can form a rule from each function that is specific to a class. this requires fewer rules to form a classifier.
　the hrex algorithm produces fewer rules than the mrex algorithm and are generally more accurate. a smaller rule set enables a better understanding of the internal operation of the rbf network. further analysis of the hrex rules proved to be interesting as several of the rbf networks have up to 1% of their hidden units shared between the various output classes. such results tend to occur with those rbf networks that have lower accuracies and may implie that the original settings of the internal parameters during training were not optimal e.g. a badly chosen value for the width of the basis function can be a source of error.
1	conclusions
the work describedin this paperhas tackled the difficult issue of knowledge extraction from rbf networks which has been avoided in the literature because of the problems with overlapping neurons. the rules extracted by the lrex algorithm provide information about the original rbf network in two forms; an input to output mapping and information regarding those hidden units that participate in classification. the knowledge extracted by the mrex algorithm transforms the original rbf network into a rule based classifier. this makes the input to output mapping of the rbf network transparent and open to scrutiny. however  the number of rules produced is dependent on the number of hidden units and therefore a large number of rules may obscure the comprehensibility. this problem is partially solved by the hrex algorithm which can generate a maximum number of rules determined in advance by the user. the tradeoff is rule size  and generally accuracy  versus comprehensibility. some rbf networks may naturally be described by small rule sets that are accurate but still allow a good understanding of their internal structure. other rbf networks may have modeled complex functions and their hidden units are used by several classes  in which case the hrex algorithm will provide useful information regarding the extent of this activity.
references
 andrews and geva  1  r. andrews and s. geva. on the effects of initialising a neural network with prior knowledge. in proceedings of the international conference on neural information processing  iconip'1   pages 1- 1  perth  western australia  1.
 bishop  1  c. bishop. neural networks for pattern recognition. oxford university press  1.
 craven and shavlik  1  m. craven and j. shavlik. using neural networks for data mining. future generation computer systems  1.
 lowe  1  d. lowe. on the iterative inversion of rbf networks: a statistical interpretation. in proceedings of the international conference on artificial neural networks  pages 1  bournemouth  uk  1.
 mcgarry et al.  1  k. mcgarry  s. wermter  and j. macintyre. hybrid neural systems: from simple coupling to fully integrated neural networks. neural computing surveys  1 :1  1.
 moody and darken  1  j. moody and c. j. darken. fast learning in networks of locally tuned processing units. neural computation  pages 1  1.
 omlin and giles  1  c. w. omlin and c. l. giles. extraction and insertion of symbolic information in recurrent neural networks. in v.honavar and l.uhr  editors  artificial intelligenceand neural networks:steps towards principled integration  pages 1. academic press  san diego  1.
 shavlik  1  j. shavlik. a frameworkfor combiningsymbolic and neural learning. machine learning  1-1  1.
 sun  1  r. sun. beyond simple rule extraction: the extraction of planning knowledge from reinforcement learners. in proceedings of the ieee international joint conference on neural networks  lake como  italy  1.
 thrun  1  s. thrun. extracting rules from artificial neural networks with distributed representations. in g.tesauro  d. touretzky  and t. leen  editors  advances in neural information processing systems 1. mit press  san mateo  ca  1.
violation-guided learning for constrained formulations in neural-network time-series predictions
benjamin w. wah and minglun qian
department of electrical and computer engineering and the coordinated science laboratory
university of illinois  urbana-champaign
urbana  il 1  usa
	e-mail:	wah  m-qian  manip.crhc.uiuc.eduabstract
time-series predictions by artificial neural networks  anns  are traditionally formulated as unconstrained optimization problems. as an unconstrained formulation provides little guidance on search directions when a search gets stuck in a poor local minimum  we have proposed recently to use a constrained formulation in order to use constraint violations to provide additional guidance. in this paper  we formulate ann learning with cross-validations for time-series predictions as a non-differentiable nonlinear constrained optimization problem. based on our theory of lagrange multipliers for discrete constrained optimization  we propose an efficient learning algorithm  called violation guided back-propagation  vgbp   that computes an approximate gradient using back-propagation  bp   that introduces annealing to avoid blind acceptance of trial points  and that applies a relax-and-tighten  r&t  strategy to achieve faster convergence. extensive experimental results on well-known benchmarks  when compared to previous work  show one to two orders-of-magnitude improvement in prediction quality  while using less weights.
1	introduction
we study in this paper new formulations and learning algorithms for predicting stationary time-series using artificial neural networks  anns .
　anns for modeling time-series generally have special structures that store temporal information either explicitly using time-delayed structures or implicitly using feedback structures. examples of the first class include time-delayed neural networks  tdnn  and fir neural networks  fir-nn   whereas examples of the latter include recurrent neural networks  rnn   haykin  1 . in the anns studied in this paper  we use a hybrid architecture with a recurrent structure  whose neurons are connected by fir filters  instead of links

　　research supported by national aeronautics and space administration contract nas 1.
proc. int'l joint conf. on artificial intelligence  aaai  1.
with constant weights. we believe that such an architecture is more powerful for modeling unknown temporal information.
　time-series predictions using anns have traditionally been formulated as an unconstrained optimization problem of minimizing the mean squared errors  mse :
 1 
where is the number of output nodes in the ann  and are  respectively the actual and desired outputsof the ann at time   is a vector of all the weights  and the training data consist of patterns observed at . extensive research has been conducted in the past on designing anns with a small number of weights that can generalize well. however  such learning algorithms have limited success because little guidance is provided in an unconstrained formulation when a search is stuck in a local minimum in its weight space. in this case  the sum of squared errors in  1  does not indicate which patterns are violated and the best direction for the trajectory to move.
　to address the issue on lack of guidance  we have proposed recently a constrained formulation  wah and qian  1  on ann learning that accounts for the error on each training pattern in a constraint:
 1 
such that
where	prescribes that the error of the	output unit on the	training pattern be less than	  and
         . a constrained formulation is beneficial in difficult training scenarios because violated constraints provide additional guidance during a search  leading a trajectory towards a direction that reduces overall constraint violations.
　in time-series prediction  cross validations are often used to prevent data from over-fitting. there are two types of cross-validation errors: single-step validation errors that measure output errors when external inputs to an ann are
true observed data  and iterative validation errors that measure output errors when external inputs to an ann are predicted outputs from previous iterations.

figure 1: multiple validation sets in a training set.   and are three validation sets. the test test is used for testing the ann after learning is completed.
　in traditionallearningwith cross validations  a part of training patterns is reserved a priori in a validation set and not used in learning  and the single objectivein learningis to min-
imize validation errors. hence  errors measured in validation will not be included in learning. this approach is problematic because it allows only one validation set in learning and excludes patterns in the validation set to be used in learning. as a result  learning may not converge when the time-series contains multiple regimes or when training patterns are scarce.
　based on a constrained formulation  we have proposed a new cross-validation method  wah and qian  1  that defines multiple validation sets in learning and that includes the error from each validation set as a new constraint  see figure 1 . the use of multiple validation sets is especially suitable for time-series with inadequate training data and for time-series with multiple stationary regimes. the validation error for the output unit from the     validation set is defined by the normalized mean squared error
 	 :
		 1 
where is the variance of the true time series in   and is the number of patterns in the validation set.  note that errors on the test set in figure 1 are defined in a similar way.  the constrained formulation then becomes:
 1 
where  resp.   is the of the iterative  resp. single-step  validation error  and   and are predefined small positive constants.
　eq.  1  is a constrained nonlinear programming problem  nlp  with non-differentiable functions. the formulation  when applied to large time-series predictions  cannot be handled by existing lagrangianmethodsthat requirethe differentiability of functions. methods based on penalty formulations have difficulties in convergencewhen penalties are not chosen properly. sampling algorithms  wah and wang  1  based on our recently developed theory of lagrange multipliers for discrete constrained optimization  wah and wu  1   when continuous variables are discretized to floating-point numbers  are too inefficient for solving large learning problems. to address this issue  we present in this paper an efficient learning algorithm called violation-guided back-propagation  vgbp .
1	theory of lagrange multipliers for discrete constrained optimization
to use a lagrangian method to solve  1   we first transform it into an augmented lagrangian function:
 1 


　since  1  is not differentiable we discretize variables finely and solve the problem in discrete space using the theory of lagrange multipliers for discrete constrained optimization  wah and wu  1 . algorithm designed to solve constrained nlps in discrete space can be extended to solve constrained nlps in continuous space because numerical evaluations of continuous variables using digital computers can be considered as discrete approximations of the original variables up to a computer's precision. the theory in discrete space is summarized in three definitions and one theorem.
definition 1. is a finite user-defined set of points so that is reachable from in one step and that can
reach anypoint in the discrete weight space through	.
definition 1. point is a iff  1  is feasible at and the objective function is the smallest in . note that a of  1  is the same as a feasible point.
definition 1.   a discrete-neighborhood saddle point at   satisfies:
 1 
for all	and all real vector	.
theorem 1. first-order necessary and sufficient condition on  wah and wu  1 . a point in the discrete space of  1  is a iff it satisfies  1  for any   where means that each element of is not less than the corresponding element of .
　the theorem shows that solving  1  in discrete space is equivalent to  the much easier problem of  finding of
 1 . note that the theorem does not hold in continuous space. 1 violation-guided back-propagation
start
figure 1: an iterative learning procedure using a discrete constrained formulation for ann time-series prediction. the shaded box represents the routine to look for . r&t stands for our proposed relax-and-tighten strategy.in this section we describe an efficient algorithm to look for in the lagrangian space defined in  1 . the shaded box in figure 1  wah and chen  1  shows the framework with two parts: one performing descents in the subspace and another performing ascents in the subspace. as indicated earlier  random sampling in a lagrangian space with discrete is too inefficient. to this end  we propose in section 1 to use bp to compute an approximate gradient direction in order to generate a probe. since gradient descents may lead to infeasible local minima  we present a new annealing strategy in section 1 to help escape from infeasible points. last  we exploit special properties in the constrained formulation for ann learning and present in section 1 a new relax-andtighten  r&t  strategy to successively tighten constraints as more relaxed constraints are satisfied. the r&t strategy is depicted in the two boxes on the left of figure 1.
1	framework to look for
the loop in figure 1 performs descents in the subspace by generating candidates in box  a  and by accepting the candidates generated using deterministic or annealing rules in box  b . occasionally  the loop carries out ascents in the subspace by generating candidates in the subspace in box  c  and by accepting them using deterministic or annealing rules in box  d . in this subsection we present the functions of boxes  a    c  and  d  and leave the discussion of box  b  to the next subsection.
　for a learning problem with a large number of weights and/or training patterns  it is essential that the points generated be likely candidates to be accepted. since  1  is not differentiable  we choose an approximate gradient direction by setting output error   applying bp to compute the gradient of the mean squared errors of   generating a trial point using the approximate gradient and step size   and mapping the trial point to  discretized  floating-point space. in this way  a training pattern with a large error  and its corresponding lagrange multiplier  will contribute more in the overall gradient direction  leading to an effective suppression of constraint violations 
　step size used in deriving a candidate point must be dynamic because the same candidate point will be generated repeatedly using a fixed and a deterministic gradient algorithm. in our algorithm  we generate uniformly in and adapt dynamically based on the acceptance ratio of candidate points generated. the reason for the latter strategy is that a high indicates that the current direction is promis-
ing  leading to increases in and larger step sizes. on the other hand  a low indicates that the step size is too large for the current search terrain  leading to decreases in and smaller step sizes. after extensive experiments  we adjust as follows:
		if
		if
box  c  in figure 1 increases	as follows: 1 if true violation 1 
figure 1: progress of mse defined in  1  for	and
during learning of an ann to predict the mg1 time-series.
where is the tolerance defined in  1  and  1 . this rule penalizes a violated constraint relative to . we do not generate probabilistically because we like their effects on guidance to take place as soon as possible. the deterministic update of leads to the deterministic acceptance of in box  d .
1	probabilistic acceptances in the	subspace
since the gradient direction computed by bp does not consider constraints due to cross validation and the step size is chosen heuristically  it is possible that a search may get stuck in infeasible local minima. in previous studies  restarts are often used to help escape from such points. however  our experimental results have shown that uncontrolled restarts may lead to loss of valuable local information collected during a search. to solve this problem  we propose an annealing strategy in box  b  that decides whether to go from current point to according to the metropolis probability:
		 1 
where   and is a parameters introduced to control the acceptance probability.
　figure 1 plots the progress of the mean squared errors  mse  defined in  1  of training an ann to predict the mackey-glass-1 time-series  in short mg1  by using two fixed temperatures: and   respectively.  mg1 is used as a running example throughout this section unless specified otherwise. 
　when is combined with restarts  the algorithm accepts everytrial point generatedin the same way as traditional bp. figure 1 illustrates this behavior by showing a search that

1
	1 1 1 1
n  number of evaluations 
figure 1: decreases of maximum violation over all constraints between using a fixed temperature     and using a schedule of decreasing temperatures     every 1 evaluations    and was adjusted every 1 evaluations .

figure 1: decreases of maximum violation over all training patterns between using different initial violation tolerance  broken lines  and using our relax-and-tighten  r&t  strategy  solid line .
explores a local region in the first 1 evaluations  got stuck in an infeasible local minimum  and restarted to a new point without keeping any history information.
　on the other hand  using allows the search to accept trial points according to  1  and rejects poor points with high probability. consequently  the algorithm keeps implicitly the history information of points searched in the past and progresses smoothly without escaping into poor regions blindly.
　in contrast to conventional annealing schedules that start a search at high temperatures and decrease the temperature to zero as time runs out  we use a fixed temperature throughout the search. a fixed temperature is chosen so that local descents will only be carried out by bp and not by annealing at low temperatures  and that a search will always have an opportunity to explore better regions. figure 1 shows the improvements in maximum constraint violations when a fixed temperature is used as compared to those at low temperatures using a dynamic temperature schedule.
1	relax-and-tighten  r&t  strategy
it is undesirable to set violation tolerance initially in a search because we do not know whether such a violation tolerance can be achieved by the search. moreover  setting will result in considerably large violations in each pattern  leading to large 's  a rugged search space  and a more difficult search. on the other hand  if we set a loose initially  then most constraints can be satisfied easily  and the algorithm can focus on the few patterns with large constraint violations and increase their corresponding 's.
　another observation is that the progress of a search differs considerably for different fixed 's. these differences are illustrated in figure 1 that shows the average maximum violations for different  number of evaluations  over five independent runs. when is small  there is little difference in maximum violations. as is increased  runs with larger 's have faster decreases in maximum violation than those with smaller 's. eventually  all the curves level off when either all constraints are almost satisfied using the specified or further improvement is impossible using the given ann topology. the figure also shows a steeper rate of decrease of maximum violations with larger 's.
　our proposed r&t strategy exploits the different convergence behavior due to different 's by dynamically adjusting during a search in order to achieve the fastest convergence
rate through the search. this is done by choosing a loose
initially and by tightening when the maximum violation of all constraints satisfies   where . in this way  the search will try to use the largest possible at any time and will switch to a smaller as the convergence behavior using the original levels off.
　figure 1 illustrates the behavior of our proposed r&t algorithm. initially  we set   leading to the steepest convergence behavior. when the convergence behavior levels off  we switch to by tightening the constraints  again leading to the steepest convergence behavior for the range of used. by repeatedly tightening constraints  the convergence behavior of r&t leads to the envelope of the best convergence behavior at all times.
　the choice of the initial is not critical to convergence as long as it is large enough because the larger the is  the steeper the curve will be and the shorter the amount of time before it will level off and tighten . in our implementation  we set initial over all constraints 
　　  and . around those values  convergence is not sensitive to different 's and 's.
　the r&t strategy works well on a constrained formulation of ann learning because all constraints are defined in the same range  limited by the activation function  and all constraints have similar magnitudes. in a general constrained nlp in which constraint violations may vary in large ranges  it will be necessary but difficult to define different amount of relaxations for different constraints. as a result  r&t does not work well in solving general constrained nlps.
1	parameters in vgbp
in this section  we summarize the values of parameters used in vgbp. first  we set
 1 
where is the number of training patterns and is known when training begins  is the range in which ann outputs are normalized and is set to a default value of one  and is a constant. should be proportional to because  1  is proportional to when all patterns have approximately the

table 1: single-step and iterative test performance in on laser.  the test set consists of patterns from 1 to 1. as a comparison  we also show the performance on patterns from 1 to 1. boxed numbers indicate the best results; n/a stands for data not available. 
methodnumber of weightstrainingsingle-step predictionsiterative predictions11111fir network  wan  1 1.1.1.1.1.1scalenet: multi-scale ann  geva  1 n/a
1
11n/an/a
vgbp  run 1 1
11
1
1
1
vgbp  run 1 111111α
figure 1: robustness of vgbp with respect to in predicting the mg-1  mg-1  and sunspots time-series.
same level of violation. likewise  should be proportional to because affects  1  in a similar manner.
　figure 1 shows the average 's over 1 runs of vgbp under different 's for mg1  mg1  and sunspots.
since vgbp is robust over a wide range of   we set the default to be in our implementation.
　we further set in  1  to be . since is adjusted dynamically  its initialization has no significant impact on performance. the setting of   and in r&t has been discussed in section 1.
　in short  all the parameters in vgbp are set either by default or automatically  with no tuning required by users.
1	experimental results
we have evaluated vgbp with respect to and the number of weights on several benchmarks.
　laser is a set of chaotic intensity pulsation of an laser in the santa fe competition. in that competition  firnn  wan  1  took the first place. table 1 shows that vgbp improves over previous algorithms in terms of prediction quality as well as number of weights used.
　sunspots contains yearly average sunspot numbers from 1 to 1. using data from 1 to 1 for training and single-step predictions on four durations  table 1 shows that vgbp achieves much better performance on all prediction periods  while using less weights than previous designs.
　table 1 compares single-step prediction results using vgbp with previous work on 1 chaotic time series. the two sets of mackey-glass and henon map have one input and one output  whereas lorenz attractor and ikeda attractor have one input and two outputs as specified in  wan  1  and  aussem  1 .
table 1: single-step test performance in on sunspots for different algorithms. results on ar 1   wnet  comm are from  wan  1   scalenet is from  geva  1   and drnn is from  aussem  1 . boxed numbers indicate the best results; n/a stands for data not available; represents the number of weights/free variables used in each method. 
methodtrainingsingle-step testing11111ar 1 1.1.1.1.1.1wnet1.1.1.1.1.1ssnetn/an/a1n/an/an/adrnn1.1.1.1n/an/acommn/a11111scalenetn/a
1
1
1
n/a
n/a
vgbp111111　in terms of single-step predictions  table 1 shows that vgbp uses less weights and achieves impressive 's one to two orders of magnitude smaller than those of other methods.
　similarly  vgbp achieves much more accurate iterative predictions as compared to those of  wan  1  and  aussem  1 . for example  vgbp was able to achieve iterative-prediction 's of for mg1 and
for mg1  respectively  for the duration 1. in contrast  applying wan's training algorithm on fir-nn  wan  1  leads to iterative-prediction 's of for mg1 and for mg1. figure 1 plots the iterative predictions of the ann found by vgbp and that by wan's algorithm for mg1 and mg1. the figure shows that our iterative predictions are accurate for as many as 1 steps.
　in general  it may be hard to predict chaotic time series multiple steps into the future since they are unpredictable by their nature. for this reason  drnn  aussem  1  did not emphasize prediction performance  especially iterativeprediction performance  aussem  1 . however  our work has shown that it is possible to predict at least the first 1 steps for the mackey-glass time series  and better for the other three sets of chaotic time series  although iterative predictions are much harder for the latter. for example  we can achieve an of only for the first 1 steps of
henon map  whereas wan's algorithm achieves an	of
.
　in short  constrained formulations solved by vgbp lead to superior prediction performance for the benchmarks tested.
references
 aussem  1  a. aussem. dynamical recurrentneural networks towards prediction and modeling of dynamical sys-
table 1: comparison of single-step-prediction performance in	on five methods: carbon copy  c.c   linear and fir  wan  1  
drnn  aussem  1   and vgbp. carbon copy simply predicts the next time-series data to be the same as the proceeding data  
　　 . the training  resp. testing  set indicates patterns used for learning  resp. testing . lorenz attractor has two data streams labeled by and   respectively  whereas ikeda attractor has two streams - real     and imaginary     parts of a plane wave.
benchmarktraining settesting setperformance metricsdesign methodsc.c.linearfirdrnnvgbpmg1-1-
11111 1 # of weights1n/a11mg1-1-
11111 1 # of weights1n/a11henon11-
11111 1 # of weights1n/a11lorenz11-
1x1111 1 z1111 1 # ofweights1n/a11ikeda11-
11111 1 1111 1 # of weights1n/a11
1	1	1	1	1	1 t	t
	 a  mackey-glass-1	 b  mackey-glass-1
figure 1: comparisons of 1-step iterative predictions on two sets of mackey-glass time-series. solid lines represent actual data; long dashed lines indicate predicted data using vgbp; and short dashed lines are prediction results by running wan's fir-nn training algorithmin  wan  1 .
tems. neurocomputing  1-1  1.
 aussem  1  a. aussem. personal communications  march 1.
 geva  1  a. b. geva. scalenet - multiscale neuralnetwork architecture for time series prediction. ieee trans. on neural networks  1 :1  sept. 1.
 haykin  1  s. haykin. blind deconvolution. prentice hall  englewood cliffs  nj  1.
 wah and chen  1  b. w. wah and y. x. chen. constrained genetic algorithms and their applications in nonlinear constrained optimization. in proc. int'l conf. on tools with artificial intelligence  pages 1. ieee  november 1.
 wah and qian  1  b. w. wah and m. l. qian. timeseries predictions using constrained formulations for neural-networktraining and cross validation. in proc. int'l conf. on intelligent information processing  1th ifip world computer congress  pages 1. kluwer academic press  august 1.
 wah and wang  1  b. w. wah and t. wang. simulated annealing with asymptotic convergence for nonlinear constrained global optimization. principles and practice of constraint programming  pages 1  october 1.
 wah and wu  1  b. w. wah and z. wu. the theory of discrete lagrange multipliers for nonlinear discrete optimization. principles and practice of constraint programming  pages 1  october 1.
 wan  1  e. a. wan. finite impulse response neural networks with applications in time series prediction. phd thesis  standford university  1.
 wan  1  e. wan. combining fossils and sunspots: committee predictions. in ieee int'l conf. on nerual networks  volume 1  pages 1  houston  usa  june 1.
mobile robot learning of delayed response tasks through event extraction: a solution to the road sign problem and beyond
	fredrik linaker 	henrik jacobsson
department of computer science  university of sko：vde  sweden
department of computer science  university of sheffield  united kingdom fredrik.linaker  henrik.jacobsson  ida.his.seabstract
we show how event extraction can be used for handling delayed response tasks with arbitrary delay periods between the stimulus and the cue for response. our approach is based on a number of information processing levels  where the lowest level works on raw time-stepped based sensory data. this data is classified using an unsupervised clustering mechanism. the second level works on this classified data  but still on the individual time-step basis. an event extraction mechanism detects and signals transitions between classes; this forms the basis for the third level. as this level only is updated when events occur  it is independent of the time-scale of the lower level interaction. we also sketch how an event filtering mechanism could be constructed which discards irrelevant data from the event stream. such a mechanism would output a fourth level representation which could be used for delayed response tasks where irrelevant  or distracting  events could occur during the delay.
1	introduction
consider an automated robot driver that navigates the streets to reach a certain goal location. on its journey  it encounters road signs  describing the upcoming junctions. having detected a roadsign  the system needs to be able to later on make the appropriate decision based on this information. that is  based on a stimulus  the system needs to store information and then make an appropriate response once the junction has been reached. this may not occur for several seconds or even minutes  depending on the vehicle's traveling speed and the distances involved. this problem was described in  rylatt and czarnecki  1   which in turn was based on a more abstract description by  ulbricht  1 .
　the problem is in fact of a very general nature  in that it involves a delayed response task  figure 1 . such tasks are quite common in real-life  involving associations between inputs and actions at different points in time. as shown by  rylatt and czarnecki  1   most existing neural network approaches are however quite inept at handling these sorts of problems. rylatt and czarnecki showed that  in fact  even

figure 1: the delayed response task  adapted from  ulbricht  1 . the robot travels past a stimulus  here a light either on the left or the right side  then continues down the corridor for a number of steps until it reaches the junction at which time the robot needs to decide whether it should turn left or right  depending on the location of the light it passed earlier.
their own  for the task specially constructed  recurrent neural network architecture was unable to learn the appropriate associations if they lay more than just a few time-steps apart.
　in this paper  we present a quite different approach from rylatt and czarnecki  in that we do not work directly on the input sequence but instead let an unsupervised system extract a set of events from the inputs and then we work on this sequence of events. as we will show  the time intervals between events may in fact be arbitrarily large without affecting the performance of the system; a drastic change from previous approaches. we also describe a more complex situation  the 'extended road sign problem'  which involves having distractions occur during the delay period. our solution is based on having several information processing levels  as depicted in figure 1.
　level 1: contains raw multi-dimensional sensor data  which is time-step based1. this is the level where  rylatt and czarnecki  1  approached the delayed response task. we however argue  like  nolfi and tani  1   that real-world

task dependencies do most often not manifest themselves at this level of individual time-stepped neuronal updates  but rather on much slower time scales  involving several seconds or even minutes. rylatt and czarnecki's somewhat simplified simulations and specially modified neural network architecture was only able to learn dependencies which lay up to 1 time-steps apart. but as most robot systems have a high sampling frequency rylatt and czarnecki's system would not be sufficient. for example  the khepera robot we use in our experiments  has sensor sampling rates of approximately 1 times per second. rylatt and czarnecki's system would therefore  in effect  not be able to learn tasks involving even just single second delays. in the following  we will show that by using event extraction  the delays can instead be arbitrarily large and this enables the system to handle more realistic long-term dependencies.
　classification: the process whereby the raw multidimensional sensor data is divided into a set of classes. while  nehmzow and smithers  1  employed a set of manually pre-defined  fixed  classes for this   tani and nolfi  1  instead let the system determine the class structure by itself  thereby reducing the user intervention. however  tani and nolfi still had to manually specify the number of classes  and had to divide the training into several different phases. they also had large problems with inputs which were distinct but not very frequent in the training set  and the learning process was very slow. recently   lina ker and niklasson  1  have constructed a more flexible classification system  the aravq  which is able to swiftly classify inputs into a dynamic number of automatically extracted classes  overcoming most of the problems in tani and nolfi's system.  the aravq system is the one used in the following simulations. 
　level 1: contains raw time-step based multi-dimensional data which has been tagged with class labels. if each class is alloted a character in the alphabet  the input can be rewritten  with some loss of information  as a  very long  letter sequence. this is the level at which  ulbricht  1  approached the road sign problem  trying to learn associations between the letters in the sequence. she did not  however  provide any account for how the input had become this letter sequence  i.e. no level 1 nor any classification   thereby working on essentially ungrounded symbols. and  further  as her system was still time-step based  she had the same difficulties learning long-term dependencies as rylatt and czarnecki had in their level 1 system.
　event extraction: the process whereby only the transitions between class membership of the lower level data are extracted  thereby filtering out repetitions. this is a fairly straightforward mechanism as long as the class membership is exclusive  each input belonging to one-and only one- class ; if two succeeding inputs are classified differently  an event is generated. the detection of an event generates a signal to the next level.
　level 1: contains general events  interspersed over long periods of time. updates occur on a considerably slower time-scale than the time-step based levels below. this means that longer time-dependencies can be detected  as noted by  tani and nolfi  1 . while tani and nolfi's robot system worked at this level  it did not involve any coupling back to the real-world as the input was merely classified and filtered  and not acted upon in any manner. that is  their system did not use the extracted events to control the robot; it was only an idle observer of what was going on. we here provide an account for how extracted events can be used to learn delayed response tasks and also how this can be used to identify candidates which should pass through an event filtering on to yet another level.
　event filtering: the process which discards events which are considered as irrelevant for accomplishing the task. this process requires that the events have been rated with some sort of 'usefulness' score  related to how relevant they are for achieving the task. this event rating should ideally be based on a delayed reinforcement learning system  such as q-learning as rewardsin the real world do often not come immediately as an action is performed. in the following we provide a simpler but less realistic evaluation mechanism  based on a recurrent neural network which has learnt a simple supervised version of the task at level 1  see section 1 . the idea behind this is that once a simple version of the task has been learnt on a low level  it can be generalized to more complex situations on higher information processing levels that have access to longer time horizons.
　level 1: contains only the events which are considered as relevantfor achievingthe task. it is updatedon an even slower time-scale than level 1 and thus can handle events that have occurred even further apart.
　it is worth noting that from level 1 and upwards  the system can work on an essentially symbolic representation of the input sequence. these symbols provide a representation whose size is virtually independent from the dimensionality of the actual sensory and motor systems. this relaxes the information processing and storage demands on the system  assuming that the symbolic representation is more compact than its corresponding input  which usually is the case.
　the next section describes an example of how a simple system can be constructed  based on straightforward building blocks  in order to achieve the discussed information processing.
1	architecture
in addition to the information processing capabilities described in the previous section  the system needs to be able to control the robot  i.e. making the appropriate response once the cue for responding comes. there are several possibilities of executing actions. levels 1 and 1 are both time-step based  which means that the inputs can be directly coupled to a single action which lasts a proportionate single time-step. this can accommodate for simple  non-goal-oriented  and/or 'innate' reflex actions.
　however  associations between inputs at levels 1 and upwards are based on events. these events can occur at widely interspersed points in time. a single time-step action is therefore not appropriateas a response; the response should ideally affect the performance the entire time interval up to the next event. a simple solution is to repeatedly execute the same action until the next event occurs  e.g. to keep turning in one direction until the next event occurs. this would however be a very rigid and inflexible solution  not allowing the system to modify its responses into smoother real-time interactions.
　instead  we propose  that the event-based levels affect  or modulate  the actual input-to-output  sensation-to-action  mapping of the time-step based levels. this modulation would also give the system the ability to focus on particular sensor subsets which are of most importance to the particular response. we show this by manually constructing a set of very simple input-to-output mappings  or behaviours  which the event-based levels can choose between. each behaviour only works on a subset of the available sensory channels. as the higher levels themselves do not act directly on the actuators  there is also no need for between-level action selection  something which has caused problems in other layered control architectures such as brooks' well-known subsumption architecture. our architecture is summarized in figure 1.

figure 1: the architecture realizing information processing levels 1 through 1 in figure 1  including the means for con-
trolling the agent's actions.
　inputs from the robot sensors were fed through an aravq network  section 1   which classified the inputs into a set of classes. when the classification became different for two succeedingtime-steps  an event was generatedand a localistic representation of the winner was fed into a simple recurrent network  srn  see section 1   which learnt associations between inputs  events  and outputs  behaviours  at different time points. the srn specified which of the behaviours  section 1  the robot was to employ until the next event occurred.
1	the aravq
the adaptive resource allocating vector quantization  aravq  network  lina ker and niklasson  1  is a vector quantization network which contains a set of model vectors  representing event classes. when a series of novel and stable inputs are encountered  the system dynamically incorporates additional model vectors. the number of allocated model vectors is determined by the characteristics of the input signal  which in turn reflects the characteristics of the environment  or the agent-environment interaction  that underlies the sensory flow which we apply the aravq network to here. it is also biased by the aravq's parameter settings.
　the aravq has four user-defined parameters: a novelty criterion   a stability criterion   an input buffer size and a learning rate . these are all explained below. in order to cope with noisy inputs  the aravq filters the input signal using the last input vectors  which are stored in an input buffer . the values in the input buffer are averaged to create a more reliable  filtered  input  to the rest of the network. that is  a finite moving average  is calculated for the last time-steps.
　there is a set of model vectors  each one representing an event class   which is initially empty.  the aravq does not start working until the input buffer is filled  i.e  until time-step .  additional model vectors are only allocated when novel and stable inputs are encountered  i.e.  when the following criteria are fulfilled:
the input is considered as novel if the euclidean distance between the existing model vectors and the last inputs  compared to the distance between the moving average  and the last inputs is larger than the distance .
the input is considered stable if the difference between the actual inputs	and the moving average  is below the threshold .
　for convenience  we define the following general distance measure between a set of  model/filtered input  vectors and a set of actual inputs :

 1 
where denotes the euclidean distance measure. the distance between the filtered input and the actual inputs is defined as:
			 1 
and the distance between the existing model vectors and the actual inputs is:
                1  otherwise
　event class incorporation: if both the stability and novelty criteria are met  the filtered input is incorporated as an additional model vector:

otherwise
 1 
classification: each time-step  a winning model vector is selected  indicating which class the  filtered  input
currently matches:
	arg		 1 
　adaptation: if the winning model vector matches the  filtered  input very closely  the  filtered  input is considered to represent a 'typical' instance of the class  and the model vector is modified to match the input even closer:


otherwise
 1 
where is a user-defined learning rate. the structure of the aravq network is depicted in figure 1.

figure 1: the aravq network. the last inputs are buffered and used to calculate a filtered input  . this particular network has allocated two model vectors  and
   ; additional model vectors will be allocated automatically when novel and stable inputs are encountered.  in the following  model vectors are for convenience labeled       etc. instead of       etc. 
1	the srn
the simple recurrent network  srn   elman  1  is essentially a three-layer feed-forward network which stores a copy of the previous hidden activation pattern and feeds it as additional input at the next time-step. this provides a memory trace of previous inputs which enables the network to learn associations over several time-steps.
　the output of the srn  for an arbitrary number of nodes  is defined as:
 1 
where the hidden activation is defined as
 1 
　and is the input at time . the index is used for identifying the output nodes  and are used for the hidden nodes  at time and respectively   and is used for the input. biases are introduced as additional elements in the weight matrices  and  indexed with  . the function    is the sigmoid activation function .
1	behaviours
three different input-to-output mappings  or behaviours  were constructed: a corridor follower  a left wall follower  and a right wall follower. each behaviour only needed to use a subset of the available sensor readings; see figure 1. the khepera robot which was used has eight infrared proximity sensors with integer activation in the range   denoting no object present within sensor range and denoting an obstacle very close. the robot has two separately controlled wheels which can be set to integer values in the range
　　　　  denoting maximum backward spinning  no wheel movement  up to which rotates the wheel forward at maximum speed.
/* corridor follower */ if  sensor   1  {   motor left  = 1;   motor right  = 1; } else if  sensor   1  {   motor left  = 1;   motor right  = 1; } else {
left motor	right motor	  motor left  = 1;   motor right  = 1; }
 a  b /* left wall follower */ if  sensor   1  {   motor left  = 1;   motor right  =  1; } else if  sensor   1  {   motor left  = 1;   motor right  = 1; } else {   motor left  = 1;   motor right  = 1;
}/* right wall follower */ if  sensor   1  {   motor left  =  1;   motor right  = 1; } else if  sensor   1  {   motor left  = 1;   motor right  = 1; } else {   motor left  = 1;   motor right  = 1;
} c  d figure 1: the khepera robot and the hand crafted behaviours.
　in addition to the three hand crafted behaviours  a simple selection mechanism was implemented. at each time-step  it detected the most active output node of the srn and executed the code associated with the behaviour.
1	experiments
a simulated version of the khepera robot was used in the experiments. the activation of the eight distance sensors  the two motors  and two of the robot's light sensors  placed in concert with distance sensors 1 and 1 in figure 1 a   were normalized to the range and fed as input to the architecture. that is  the aravq network received a total of 1 inputs. the parameter settings of the aravq were  
         and . this led to the extraction of eight different event classes for the constructed t-maze environments shown in figures 1 and 1; each event class was allocated a separate shade and at each location  the winner of the classification process was plotted  leaving the trail shown in the figure.
　the event extraction discards the repetitions of each class  leaving sequences which are only six characters long. a character was manually assigned to each of the eight extracted classes  for presentational purposes. an interpretationof each
	a1	f 1	e1 a1

	 a 	 b 
figure 1: the two different cases for the delayed response task and the resulting input classification at each location along the simulated robot's path  the subscript denoting the number of repetitions of each class.
class is shown in table 1  based on how the aravq seems to apply the classes.
	model vector	interpretation

corridor
corridor + left light
corridor + right light junction
wall on left side only
wall on right side only left-turning corner
right-turning corner

table 1: the eight automatically extracted model vectors and how they can be interpreted.
　each of the three behaviours was also assigned a character  this time creating an 'output alphabet'  as shown in table 1.
	behaviour	description

corridor following
left side wall following
right side wall following

table 1: the three hand crafted behaviours.
　the srn worked on this eight-character input and threecharacter output alphabet. as two hidden nodes were used  a 1-input  1-hidden  1-output srn was created. network weights were randomly initialized in the interval   the learning rate was 1 and a momentum of 1 was used. the training set was the two extracted sequences  for the left and right turn  respectively  as shown in table 1. the network was trained for epochs using back-propagation throughtime  bptt  which unfolds the recurrentconnections of the network. the bptt here unfoldedthe network 1 times. the srn had no problemslearning the correct associations case	sequence

left turn
right turn

table 1: the extracted sequences of model vector winners and the behaviours that should be selected for the paths taken in figure 1.
between the light stimuli and and the behaviours and occurring two events later. that is  the system could turn in the right direction  irrespective of the length of the delay  as this information was removed in the event extraction. the road sign problem was thus solved. we now  however  have a similar problem to that of  rylatt and czarnecki  1   but on the level of intermediate events instead of intermediate time-steps. we call this problem 'the extended road sign problem'.
1	the extended road sign problem
while the length of the delay between the stimulus and the response has become irrelevant through the use of event extraction  the system would still have problems handling distracting events during the delay. that is  if the input changes drastically during the delay  intermediate events will be generated. this means that the problem of finding relationships between the stimulus and the subsequent response will become harder as there are a number of distracting events which have taken place in between. examples of this are shown in figure 1 where there is a right or left turn in the corridor after the stimulus has been passed  generating another three events which however are of no relevance for the task  i.e. they serve only as distractions.
	a1	f1	e1	a1

	 a 	 b 
figure 1: two examples of distracting events  turns  happening in between the stimulus  light  and the cue  junction .
　the srn still managed to find the correct association  but only if it was first trained on the simpler tasks  and then continued training on the more difficult examples shown above. the hidden node activation plot of an srn which has learnt the task is depicted in figure 1. note that a numberof clusters have formed for each of the functional states the robot can be in.

figure 1: hidden node activation of the srn.
　when irrelevant inputs  such as corners  input characters and    are received by the srn  the state remains relatively stable  i.e. it stays in the same location as the previous time-step. that is  large movements in the internal  hidden node  activation space occur only when functionally important events occur. when  for instance  input character  left stimulus  is received  the activation jumps to the upper right corner and stays there until the input character  the cue for responding  arrives. at that time  the activation quickly jumps to the upper left corner  making the robot activate its left wall following behaviour  effectively starting to turn left at the junction. a similar situation occurs if instead the other stimulus is present  where the bottom right and left corners are used by the srn.  before either stimuli has been encountered  the srn state is in the upper right corner  i.e. this particular robot has a bias for turning left at junctions. 
　we can now also sketch how a solution to the extended road sign problem might look. note that if the hidden activation space of this srn was clustered  using for example another aravq network  the functionally unimportant events would likely cause repetitions of the same class winner as they would lead to only small perturbations in the state space. only when functionally important events occur  such as the stimulus or cue  do large jumps in activation space occur  thereby leading to another class perhaps becoming the best match. then using the same filtering process used for repetitions of input patterns  the irrelevant events would be removed. note that this solution is based on a level 1 system  srn  which has already successfully learnt the associations in a relatively simple scenario. the filtering can then extract informationwhich effectivelylets the next higherlevel  level 1  handle delays with an arbitrary number of distracting events as they will be filtered out in the aforementioned process.
1	conclusions
we have shown how a layered information processing system can be constructed which handles delayed response tasks like the road sign problem  rylatt and czarnecki  1 . our solution is based on attacking the problem at a higher level of abstraction than the raw time-step based sensory data. as shown  the learning system  in this case an srn  has a considerably easier task when the redundant data has been filtered out  letting the system instead work on a sequence of discrete events. these events are grounded in sensori-motor interactions. as discussed  the event extraction provides the means for handling arbitrarily long delays between the stimulus and the subsequent cue for response.
　in addition to handling the road sign problem  we suggest an extended road sign problem. this involves distractions during the delay  thereby putting further demands on the system not to lose track of what it is supposed to do. as discussed  another abstraction level  which works on filtered event streams  could be added. this filtering would be taskspecific and would be based on that the system has already learnt  on a simple version of the task  which of the inputs are relevant. we believe this approach will steer us in the right direction on the road to acquiring more complex and intelligent behaviours from our robotic friends.
acknowledgments
this research was funded by a grant from the foundation for knowledge and competence development  1   sweden and the university of sko：vde  sweden.
references
 elman  1  j. l. elman. finding structure in time. cognitive science  1-1  1.
 lina ker and niklasson  1  f. lina ker and l. niklasson. time series segmentation using an adaptive resource allocating vector quantization network based on change detection. in proc. of the int. joint conf. on neural networks  volume vi  pages 1. ieee computer society  1.
 nehmzow and smithers  1  u. nehmzow and t. smithers. mapbuilding using self-organising networks in really useful robots. in proc. of the first int. conf. on sim. of adaptive behavior  pages 1. mit press  1.
 nolfi and tani  1  s. nolfi and j. tani. extracting regularities in space and time through a cascade of prediction networks. connection science  1 :1  1.
 rylatt and czarnecki  1  r.m. rylatt and c.a. czarnecki. embedding connectionist autonomous agents in time: the 'road sign problem'. neural processing letters  1-1  1.
 tani and nolfi  1  j. tani and s. nolfi. learning to perceive the world as articulated. in proc. of the fifth int. conf. on sim. of adaptive behavior  pages 1. mit press  1.
 ulbricht  1  c. ulbricht. handling time-warped sequences with neural networks. in proc. of the fourth int. conf. on sim. of adaptive behavior  pages 1. mit press  1.
norn finance forecaster - a neural oscillatory-based recurrent network for finance prediction
raymond s. t. lee and james n. k. liu
department of computing  hong kong polytechnic university
hung hom  hong kong
csstlee comp.polyu.edu.hk  csnkliu comp.polyu.eduabstract
financial prediction is so far the most important applications in contemporary scientific study. in this paper  we present a fully integrated stock prediction system - norn finance forecaster - a neural oscillatory-based recurrent network for finance prediction system to provide both a  long-term trend prediction  and b  short-term stock price prediction. one of the major characteristics of the proposed system is the automation of the conventional financial technical analysis technique such as market pattern analysis via noegm  neural oscillatory-based elastic graph matching  model and its integration with the time-difference recurrent neural network model. this will provide a fully integrated and automated tool for analytic and investigation of stock investment. from the implementation point of view  the stock pricing information of 1 major hong kong stocks in the period of 1 to 1 are being adopted for system training and evaluation.  as compared with contemporary neural prediction model  the proposed system has achieved challenging results in terms of efficiency and accuracy.
1. introduction
financial prediction such as stock prediction and foreign currency exchange rate forecast so far is one of the most important and hottest topics  both in the scientific and financial fields. in fact  due to the importance of this particular topic  a well-established school of concepts and techniques have been devised in the previous decades  namely the technical  murphy  1  and fundamental analysis  ritchie  1  techniques. however  owing to the fact that these tools are based on totally different approaches of analysis  they always give rise contradictory results. besides  'pattern matching' technique is still widely used for most financial analysts and market technicians. actually  there are numerous market patterns that have found  and believe  to exhibit repeated market moves following their occurrence. so they are especially useful for long-term financial trend prediction. these market patterns can be classified into two major categories: 'reversal patterns' and 'continuation patterns'  zirilli  1 . the correct identification of these patterns is a very useful information to predict the financial trend movement. however  the identification of these patterns so far is highly subjective and prone to errors. the major obstacles for the automation of this pattern matching process is that these patterns are highly variant and 'elastic' in the sense that they can exist under different appearances.
　　in this paper  we present an integrated neural networkbased financial prediction system which fully automates the process of 1  long-term trend prediction and 1  short-term  e.g. one-day  stock forecast. unlike the contemporary neural network-based financial prediction model  we have integrated and automated critical technical analysis tools into the proposed model  namely the market pattern identification scheme in trend prediction and oscillatorybased rsi  relative strength index  analysis technique. from the implementation point of view  stock information for 1 major hong kong stocks in the period from 1 to the end of 1  ten-year data  have been used. compared with other contemporary time series neural network prediction models including the feedforward backpropagation model from neuroforecaster and genetica  norn has achieved challenging results in terms of efficiency  accuracy and the ability to integrate critical technical analysis techniques.
1. norn: system framework
1 system overview
the neural oscillatory-based recurrent network model  norn  proposed in this paper is based on the integration of critical technical analysis techniques 1  market pattern analysis and 1  oscillator-based system with hybrid rbf  radial basis function  recurrent network for stock prediction. norn basically consists of the following modules:
* automatic market analysis module using noegm model;
* hybrid rbf recurrent network with tdsl  time-
difference structural learning  for stock prediction.
the major objective of norn on one hand is the provision of a fully automatic stock prediction model  based on an integrated recurrent neural network   and on the other hand  to integrate it with critical technical analysis techniques to increase the degree of accuracy.
1 market pattern analysis via noegm
noegm - system overview
the neural oscillatory elastic graph matching  noegm  model consists of three main modules: 1  multi-frequency bands feature extraction for the stock pattern using gabor filters; 1  automatic figure-ground tc pattern segmentation using neural oscillatory model; 1  invariant market pattern matching using elastic graph dynamic link model  egdlm .
　　actually noegm model has been applied to various invariant pattern recognition applications including face recognition  lee et al.  1   scene analysis  lee and liu  1a  and the latest research on tropical cyclone  tc  pattern recognition from the satellite pictures  lee and liu  1b; 1   based on composite neural oscillators as neural framework. a schematic diagram for the noegm model is shown in figure 1.

gabor filter feature extraction
neural oscillatory model for pattern segmentationphase i feature extraction module
phase ii figureground segmentation
phase iii -
egdlm
encoding dynamic links for query and template patternsmarket pattern recognition

egdlm elastic graph
matching module

quantified matching results
figure 1 - schematic diagram for the noegm model for market pattern recognition
feature extraction module
in this module  gabor filters of 1 different frequency bands
 φ  and 1 different orientations  θ  are being used  a total of 1 feature vectors of different attributes are extracted from the stock patterns. the filter function is given:
x1+y1
	gφ θ x  y =	   1σ  e1πiφ xcosθ+ysinθ 	 1 
pattern segmentation - neural oscillatory model
in the neural oscillatory model  neurons in our visual cortex are presented by numerous neural oscillators. a typical neural oscillator consists of an excitatory neuron  ui  and an inhibitory neuron  vi   which interacts and oscillates with other neurons according to external stimulus. in the model  each layer represents the whole visual horizon in 1d perspective. in each location  the  column  neural oscillators represent the set of  visual sensors   which is modeled by an array of feature vectors.
　　according to the model  with the presence of a subject in an image  eg. stock pattern   neurons that belong to the same segment are oscillated in a phase-locked mode with zero phase shift after sufficient cycles of neural oscillations  while neurons in different segments are oscillated out of phase and uncorrelated  lee and liu   1a .
　　in the neural oscillatory model  each stock pattern graph is broken into a 1d mesh of n = n1 x n1 composite neural oscillator sites. each site  column  consists of m layers of neural oscillators which denote the neural oscillation from each local feature response  e.g. using gabor filters .  in addition to the local excitatory and inhibitory neurons  the neural dynamics of the composite neural oscillators are activated/deactivated by the oscillatory model.
 vertical & horizontal  excitatory connections
　　neural oscillators within the same  column  are mutually activated with strength w|. in each feature layer  each neural oscillator is activated by the eight  closest  neighboring excitatory composite neurons with strength w .
 vertical & horizontal  inhibitory neurons  vi & vq 
　　to control the unexpected local phase locking   vertical  and  horizontal  inhibitors are introduced  which are governed by the inhibitory strength t|vi & t vq respectively.
  global  inhibitory neurons  v 
　　a global inhibitory neuron which receives excitation from all excitatory neural oscillators  and it inhibits all excitatory units with the signal tv. the neural dynamics are shown as follows:
dui	q	q	q	q	q	q	q	q	q	q	q	q  1 
= ui + sλ ui  βvi  θu + ici +wi| ui +wi ui  ti| vi  ti v  ti v 
dt
τ dviq = viq + sλ αuiq  γviq  θv    1  dt
　dvi = vi + sλ wi| vi  θv     	 1  τ
dt
　dvq q q q	 1  τ= v + sλ w  v  θv   dt
　dv 'v θv  	 1  τ =  v+ sλ w dt
c  segmentation criteria: correlation function σxy
   the segmentation criteria is governed by the  correlation factors   which are a measurement of the binding strength  phase relationship  between the composite neural oscillators and their  nearest  neighbors  given by: σ x   y   =   x 1    x  y x    1    x    y 1 y      y   1  1 
market pattern recognition - elastic graph dynamic link model  egdlm 
object recognition based on egdlm which described the recognition problem as an elastic graph matching mechanism between the attribute graphs of the image vectors  input layer  with the set of  memory  graphs in the object gallery  memory layer . the schematic diagram of egdlm network architecture for market pattern matching is shown in figure 1.
　　one of the most striking features of the egdlm is its  invariant  property. in the network model  only the topological relations between the neural oscillators  i.e. dynamic links  are encoded into the network. the pattern matching process is resembled to the 'elastic graph matching'  which is invariant under various transformations such as translation  rotation  reflection  dilation and occlusion  commonly occurred in pattern recognition.
　　egdlm object recognition model consists of two processes: 1  dynamic link initialization and 1  elastic graph matching module. in dynamic link initialization process  dynamic links  zij kl  between  memory  object graphs  obtained from market pattern templates  and query pattern are initialized according to the following rules:
zij kl =εjij jkl	 1  for jij （ a   jkl （ b.
   in the elastic graph matching module  attribute graph of the figure pattern  with neural oscillator vectors as nodes and correlation links as edges  is matched with each of the attribute graphs in the object gallery by minimizing energy function h z :
	1
	h z    =  （‘z z z z（ij	jl	ik	kl +γ‘ ‘（    k a（ zik  1    +γk a‘（    ‘i b（ zik  1   	 1 
　　　　　i j b k l a 	;  	i b where h z  is minimized using the gradient descent.

figure 1 - egdlm network architecture for market pattern matching
1 hybrid radial basis function networks for nonlinear time series stock prediction
hybrid rbf network  hrbfn  - system overview
the proposed hybrid rbf network  hrbfn   lee and liu  1  incorporates with two main technologies into the conventional rbf network for temporal time series prediction problem: 1  structural learning technique that integrates the  forgetting  factor into the rbf bp algorithm  ishikawa; 1 ; 1  a 'time difference with decay'  tdd  method is corporated into the network to strengthen the temporal time series relation of the input data sequence for network training.
　　the hrbfn consists of three layers. the first layer is the input layer which consists of two portions: 1  past network outputs that feedback into the network; 1  major co-relative variables are concerned with the prediction problem. past network outputs enter into the network by time-delay unit as the first inputs. these outputs are also affected by a decay factor γ that is governed by the following equation.
	γ =αe λk	 1 
　　in general  the time series prediction of the proposed network is to predict the outcome of the sequence x1t+k at the time of t+k that is based on the past observation sequence of size n  i.e. x1t  x1t-1  x1t-1  x1t-1 ...  x1t-n+1 and the major variables that influence the outcome of the time series at time t. for convenience  the following notations are used throughout the following network description: the numbers of input nodes in the first and second portions are set to n and m respectively. the number of hidden nodes is set to p. the predictive steps are set to k  so the number of output nodes is k. at the time t  the input will be  x1t  x1t-1  x1t-1  x1 ... x1t-n+1  and  x1 x1 ... x1m  respectively. the output is given by xt+k  denoted by pkt for simplicity  wijt denotes the connection weight between the i-th node and the j-th node at time t.
hrbfn - structural learning algorithms
the main idea of rbf learning algorithm with  forgetting  factor is to introduce a constant decay to connected weights that make the redundancy weight s  fade out quickly. the cost function of the structural learning algorithm is given by equation  1 .
	et  wijt	 1 
i  j
where e1t denotes the error square in traditional rbf learning  the second term is the penalty criteria. if delta rule is used  the learning rule of the weights is given by:
	 wijt+1 = η weijtt	t	 1 
+α wij
 
hrbfn - tdd method
the structural learning algorithm discussed above does provide a  dynamic  structure building of the neural network  but it cannot adapt the temporal time series relations of the input and output feedback data sequences into the model. in order to code with this problem  a temporal difference method with decay feedback is hybridized into the learning algorithm of the proposed model. the basic concepts are presented as follows.
　　in a typical time series prediction problem  given a series of past observations of time-step n at time t  i.e.  x1t  x1t-1  x1t-1  x1t-1 ... x1t-n+1   with the predictive time-step of k  we not only obtain the predicted output at time t+k  i.e. pkt   but more importantly is the sequence of future events started from time t  i.e.  p1t  p1t  p1t ...  pkt  . in other words  the network can provide an overlapping and inter-related event sequence as an additional  hint  for network learning  which can be implemented by using temporal difference technique  sutton  1 . besides  consider a sequence of temporal difference operations from time t+1 to t+k  the prediction from a  nearer  future normally has a higher level of confidence than a  far  future  so a decay operator is integrated into the learning algorithm in order to reflect the situation. with the integration of tdd methodology  the learning algorithm discussed in equation  1  will be modified into:
	  ij	=η k	t λt 1  phlt		 1 
		 wij
‘l =t 1    γ l  λt 1   wp1ijlt      
       where ε  is defined as:
　　 ε wijt = θ	 1  ε = 
	 1	otherwise
1. implementation
1 norn for stock prediction
introduction
in section 1 we have discussed the critical components of norn for automatic time series prediction and pattern recognition. in this section  we illustrate how these technologies can be integrated to stock prediction in the following ways: 1  long-term stock trend prediction; 1  short-term stock price prediction. a schematic diagram for the integrated norn model for stock prediction is shown in figure 1.

figure 1 - schematic diagram of the integrated norn model for stock prediction
　　the integrated norn model consists of the following main modules:
1  stock data pre-processing module; 1  noegm market pattern recognition module; 1  hybrid rbf network module for stock prediction.
stock data pre-processing module
from the implementation point of view  ten-year daily stock data  1  of 1 major hong kong stocks are being adopted. daily information includes daily high  low and closing stock value. the inputs of the hrbf recurrent network is generated by 1  pre-processed time series stock data  and 1  market pattern recognition results.
　　according to the different requirements and forecasting purpose of norn for stock prediction  the time series stock data are processed differently for the long-term trend prediction and short-term price forecasting.
a  data pre-processing  feature extraction  for long-termtrend prediction
for long-term trend prediction  since we are interested in stock pattern variation instead of daily price fluctuation  two types of inputs  pre-processed  are being used: 1  normalized daily closing stock value  xi ; and 1  normalized 'desired-value' for days between a buy and a sell signal  di  given by:
   ci  ci  j	 1  x j =   j=1...a  1＋ x j ＋1 ciλj
ci  ci  jwhere λj = p 1 ai=‘pa+1	ci	  j =1...a	 1 
	ci  clow	 1 
di =
chigh  clow
　　the main purpose of this data pre-processing  feature extraction  method given by equation  1  is to extract the difference between the current day's closing price  ci  and the previous a closes  ci-j . this difference is then normalized by dividing it with the closing price and the scaling factor λ.
　　in order to 'feed-in' the critical signal for trend prediction  the normalized 'desired-value' for the days between a buy and a sell signal  di  is being adopted. actually  this signal is based on the concept of 'oscillatorbased system' of the technical financial analysis discussed previously  a kind of 'neural-network oscillator' for stock prediction. for example  when this neural net oscillator rises above a sell threshold  it signals an alert that the market is approaching a trend change to the down side. on the other hand  when the neural net indicator falls below a buy threshold  it signals an alert that the market is approaching a trend changes to the up side. so  these oscillatory input nodes can provide an effective indicator for trend prediction.
b  data pre-processing  feature extraction  for short-termprice prediction
unlike long-term trend prediction  short-term stock price prediction focuses on the fluctuations of the stock value on daily basis. so  the strategy for creating input patterns is to use the daily change in price    values for open  close  high and low  to predict the next day's high  low and close.
　　using similar normalization approach  for each different type of   values  open  close  high and low   the volatility factor λ can be calculated as follows:
	λ =	1 ‘p c i	 1 
         p i=1 and each normalized input value is given by:
 xi =	 	  i =1...a  1 ＋ xi ＋ 1	 1  ciλ
　　the desired outputs  dh i  dl i  dc i  for the high  low and close values are also normalized in the similar approach as shown below: 	 1 
	hi+1  ci+1	 dl i = ci+1   li+1	 dc i =ci+1  ci
dh i =
	ciλh	ciλl	ciλc
　　another important fact for this kind of normalization is  once the predicted outputs  oh+1  ol+1  oc+1  are obtained  the predicted stock prices can be transformed easily based on the following equations:
ci+1 = 1 ci λc  oc   1 +ci  1  hi+1 = ci+1 +ci λhoh	 1  li+1 = ci+1  ci λlol	 1 
noegm market pattern recognition module
by using the neural oscillatory-based elastic graph matching  noegm   market patterns from the time series stock pattern for each stock can be extracted and recognition based on the market pattern templates for the 1  major reversal patterns and 1  major continuation patterns being shown in figures 1 and 1 respectively. from the implementation point of view  according to the type of market patterns being extracted from the time series stock price pattern  they are grouped into a set of three different input nodes: 1  reversal top pattern node; 1  reversal bottom pattern node; and 1  continuation pattern node.
hybrid rbf network module for stock prediction according to the schematic diagram of norn model  time series stock information of 1 hong kong major stocks in a period from 1 to the end of 1 are 'fed in' to the hybrid rbf network in the following two ways: 1  pre-processed time series stock data for each stock based on the normalization and transformation techniques discussed previously  with windows size ranging from 1 to 1 days  for long-term trend prediction  and 1 to 1 days  for shortterm stock prediction ; 1  market patterns being extracted and identified from the time series stock patterns  which is quantified by the correlation values discussed previously.
1 experimental results
from the system validation and performance evaluation point of view  three different types of experimental tests are conducted:
1  market pattern recognition test for noegm validation; 1  long-term/short-term window size evaluation test; 1  norn model performance test.
market pattern recognition test
in the test  four representative stocks from the four main business sectors  i.e. banking  finance investment  public utility and property  were used for system evaluation. they were: hsbc holdings  banking   tian on china investment  finance investment   hong kong telecom  public utility  and cheung kong holdings ltd.  property . based on the major market patterns being shown in figures 1 and 1 and the stock pattern for these stocks in the period from 1 to 1. the automatic pattern recognition result based on cnom model is shown in table 1.
table 1 - market pattern recognition test results
market patterns recognition rate *market
patternshsbc holdgs.tian on
china
invest.hong
kong
telecomcheung kong
holdgs.overalla  reversal patterns  top 1  1% 1  1% 1  1% 1  1% 1%b  reversal patterns  bottom 1  1% 1  1% 1  1% 1  1% 1%c 
continuation patterns1  1% 1  1% 1  1% 1  1% 1%overall1  1% 1  1% 1  1% 1  1% 1%note * the pattern recognition rates from different patterns are denoted by: matched cases / total cases   recognition rate % 
　　as illustrated in table 1  out of a total of 1 market patterns being identified for these four stock pattern series  the correct matching rate is over 1%  with a total of 1 correct matched patterns. the overall recognition rate ranging from 1%  for continuation patterns  to about 1%  for reversal top patterns .
　　actually  in view of the detailed recognition rate of the sub-category pattern for each type of market patterns  the recognition rates maintain an acceptable level of around 1 to 1%  except for some particular categories such as the 'round bottom' pattern in the reversal bottom patterns and the 'rectangles' pattern in the continuation patterns.
　　there is one important point needed to bring out and is it the 'basis' of the recognition test - that is  the 'total cases' figures are identified by human subjective justification which can be explained why some categories have scored a lower pattern  as there exist a certain degree of ambiguity in some template patterns.
　　for the processing speed of pattern recognition in our test  the average time for pattern segmentation and recognition are 1s and 1s respectively  as compared with the previous work based on composite neural oscillatory model  cnom  for cloud pattern recognition  lee and liu  1   the pattern segmentation and recognition are 1s and 1s corresponding to an improvement of 1 and 1% respectively due to lesser degree of complexity of the proposed model  lee and liu  1b . long-term/short-term window size evaluation test
as the window size of the stock prediction model can provide a deterministic factor for the network efficiency and accuracy  this experimental test aimed at the evaluation of the optimized window size for 1  long-term trend prediction and 1  short-term stock price prediction.
　　in the test  window sizes of 1 to 1 days  for long-term trend prediction  and 1 to 1 days  for short-term price prediction  were used respectively. the predicted output for these two sets of predictions are as follows:
1  long-term trend prediction:
-'predicted desired-value  di ' for days between a buy and a sell signal.
1  short-term price prediction:
- 'predicted next-day high  hi+1 
- 'predicted next-day low  li+1 
- 'predicted next-day close  ci+1 
　　based on the four typical stock items used in the previous test. table 1 shows the experimental results in terms of average percentage error of the norn model under different window sizes.
table 1 - norn model window size evaluation test results
long-term trend predictionshort-term price predictionwindow size  days av. %  errorwindow size  days av. % error1.1%1.1%1.1%1.1%*1.1%*1.1%1.1%1.1%1.1%1.1%1.1%1.1%　　as illustrated in table 1  the optimal window size for long-term and short-term stock prediction are 1 days and 1 days respectively  with average percentage errors of 1% and 1% being achieved.
norn model performance test
in this test  the ten-year  1  stock information of 1 major hong kong stocks were adopted. for comparison purpose  a neural network based forecasting aid 'neurotm forecaster' from neuro intelligent business software was adopted in the test. actually  neurotm forecaster provides the following neural network models:
1  time series feed-forward back-propagation model  ffbp  with different choices of transfer functions  which includes: standard sigmoid function  hyperbolic tangent function  neurofuzzy function  etc.
1  'genetica net builder' - based on genetic algorithms  ga  for the construction and optimization of the network model.
table 1 - norn model performance test results
 for next-day stock price prediction 
business typeneuro forecaster  average % error norn
 av. % error sigmoidhyberbolic tangentneurofuzzygeneticaa  banking1%1%1%1%1%b  finance  & investment1%1%1%1%1%c  public
utility1%1%1%1%1%d  property1%1%1%1%1%e  others1%1%1%1%1%overall1%1%1%1%1%　　for the ease of comparison  these 1 stock items are grouped under the four critical business sectors  namely: banking  finance and investment  public utility  property and others. the experimental results for the next-day stock price prediction are shown in table 1.
1. conclusion
in this paper  we have presented an innovative  fully automatic and integrated stock prediction model to serve the purposes of 1  long-term stock trend prediction  and 1  short-term stock price forecast. unlike contemporary neural network models for financial prediction  vellido et al.  1  which focus on the 'replacement' of the conventional financial analysis and prediction techniques with various neural net technologies  this paper explores a new era for the implementation of neural networks in financial engineering in which neural networks can be successfully integrated with conventional financial analysis techniques such as technical analysis tools to improve the efficiency and effectiveness of the financial prediction results.
acknowledgment
the authors are grateful to the partial supports of the departmental grant #h-zj1  central research grant #polyu 1e and the ijade projects of hong kong polytechnic university. references
 ishikawa  1b  m. ishikawa. structural learning with forgetting. neural networks  1  1  1.
 lee et al.  1  r. lee  j. liu and y. you. face recognition: elastic relation encoding and structural matching. in proceedings of ieee international conference on systems  man  and cybernetics  smc'1   tokyo  japan  pages 1  1.
 lee and liu  1a  r. s. t. lee and j. n. k. liu. an oscillatory elastic graph matching model for scene analysis. in proceedings of international conference on imaging science  systems  and technology  cisst'1   las vegas  usa  pages 1  1.
 lee and liu  1b  r. s. t. lee and j. n. k. liu. an automatic satellite interpretation of tropical cyclone patterns using elastic graph dynamic link model. international journal of pattern recognition and artificial intelligence  1  1  1.
 lee and liu  1  raymond. s. t. lee and james n. k. liu. tropical cyclone identification and tracking system using integrated neural oscillatory elastic graph matching and hybrid rbf network track
mining technique  ieee transaction on neural networks  1  1  1.
 murphy  1  j. j. murphy. technical analysis of the future markets. the new york institute of finance  prentice hall  new york  1.
 ritchie  1  j. ritchie. fundamental analysis: a back-to-the-basics investment guide to selecting quality stocks  chicago  irwin professional pub  1.
 sutton  1  r. s. sutton. learning to predict by the methods of temporal difference. machine learning  no. 1  pages 1  1.
 vellido et al.  1  a. vellido  p. j. g. lisboa and j. vaughan. neural networks in business: a survey of applications  1 - 1 . expert systems with application  1  1  1.
 zirilli  1  j. s. zirilli. financial prediction using neural networks  international thomson computer press  1.
a general updating rule for discrete hopfield-type
neural network with delay
shenshan qiu1 a  eric c.c. tsangb  daniel s. yeungb  xizhao wangb bdept. of computing  the hong kong polytechnic university
asouth china university of technology  guangzhou  1 china ausqiu scut.edu.cn; ssqiu 1cn.com  csetsang  csdaniel  csxzwang comp.polyu.edu.hkabstract
in this paper  the hopfield neural network with delay  hnnd  is studied from the standpoint of regarding it as an optimized computational model. two general updating rules for network with delay  gurd  are given based on hopfield-type neural networks with delay for optimization problems and characterized dynamic thresholds. it is proved that in any sequence of updating rule modes  the gurd monotonously converges to a stable state of the network. the diagonal elements of the connection matrix are shown to have an important influence on the convergence process  and they represent the relationship of the local maximum value of the energy function with the stable states of the networks. all ordinary dhnn algorithms are instances of gurd. it can be shown that the convergence conditions of gurd may be relaxed in the context of applications  for instance  the condition of nonnegative diagonal elements of the connection matrix can be removed from the original convergence theorem. new updating rule mode and restrictive conditions can guarantee the network to achieve a local maximum of the energy function.
1	introduction
recently the convergence of various connectionist models including discrete hopfield neural network  dhnn   hopfield  1; wilson and pawley  1; bruck  1   continuous hopfield neural network  chnn   hopfield  1  and network with delay  clouse and lee  1  has been studied extensively. since hopfield and tank  hopfield  1  first applied dhnn to the traveling salesman problem  dhnn  which has a very simple and efficient hardware implementation  has demonstrated the capability to solve a wide variety of combinatorial optimization problems. however  hopfield and tank's approach has been subjected to severe criticism on the quality of its solutions  especially for large-scale problems  wilson and pawley  1 . other issues concerning dhnn such as computational complexity  orponen  1   computational power  finite automata  equivalency and dynamic system simulation by dhnn are beyond the scope of this paper.
　it is well known that the dhnn without delay has an important property  i.e.  it always converges to a stable state when operating in a serial mode and to a cycle of length at most 1 when operating in a parallel mode  hopfield  1; wilson and pawley  1; bruck  1; xu et al.  1 . the problem of convergence is considered one of the most important theoretical issues in the study of the neural networks. however  in most optimization problems  the corresponding matrix and updating rule mode do not satisfy convergence conditions. therefore its application domain is rather limited.  to correct the deficiencies of the hopfield network  various attempts such as optimal parameter selection and infeasible solution elimination have been made. among these attempts  some are to maintain the structure of the hopfield network  while others are to modify the network structure. in  qiu et al.  1; qiu et al.  1a; qiu et al.  1b  a dhnn with delay is constructed and a serial  updating rule  mode similar to one in hopfield network without delay is also presented. but the corresponding convergence conditions are strictly constrained. it is also shown that the energy function is dependent on the updating rule mode. it is well known that a detailed specification for the convergence of dhnn is very critical to most of the applications and it remains an open problem on how much could the convergence conditions be relaxed.
　in fact  the convergence conditions  network architecture  network initial conditions as well as updating rule modes are intimately related. the aim of this paper is to extend the convergence conditions given in  qiu et al.  1  and to specify the updating rule mode which will make the energy function decrease monotonically with respect to the evolution time. the energy function is modified by means of a modified dhnn as well as its updating rule mode  so that the convergence of dhnn with delay is obtained.
　this paper has the following organization. section 1 is the introduction. section 1 gives a brief review for dhnn with delay. section 1 introduces some definitions and notations. section 1 discusses the convergence of dhnn with delay and presents the main result. the last section concludes the paper.
1	hopfield networks with delay
discrete hopfield neural network  dhnn   hopfield  1; wilson and pawley  1; bruck  1; xu et al.  1  is described as follows. the state of the network at time t is the vector x t = x1 t  x1 t  ... xn t  t . in general  the state of the network at time t+1 is a function of {w  q} and the state of network at time t. this network is thus completely determined by the parameters {w  q}  the initial state values x 1   and the manner in which the nodes are updated
 evolved . if at time step t  node xi is chosen for updating  then at the next time step t +1  xi  t +1  = sgn hi  t   =     1   hhii  tt  −  1                   1 
where hi    t = ‘n wij x j    t  qi .
j=1
　if only one neuron is allowed to change state at each time step by performing the state evolving equation  1  while the states of the other nodes are unchanged  then the network is said to be operating in a serial mode. if all the nodes are chosen to be updated at each time step by performing the state evolving equation  1   then the network is said to be operating in a parallel mode.
　a dhnn with delay is a computational model  similar to a multilayer perceptron in which all connections are feedforward. the difference between a dhnn with delay and a multilayer perceptron is as follows. the inputs to any node xi for dhnn with delay may consist of the outputs of earlier nodes not only during the current step t  but also during previous d time steps  t  1 t  1 ... t  d . following
 bruck  1; orponen  1   the state of a neuron is updated according to the following equation:
xi t+1 =s i hi t  （{1  1}                                     1 
where hi .
k=1 j=1
　in order to simplify the analysis presented later in this paper  only the special case d=1  q t  《q will be discussed here. s i     represents the content of the output function of the neuron and the updating rule mode. the quadruple n =  w1 w1 q s   is used to represent the model  1 . for instance  if w1 =on〜n   s i   =sgn     then the quadruple n = w1 w1 q sgn   represents the dhnn model.
1 	updating rule of dhnn with delay
let bn《{ 1}n represent the set of all vectors x =  x1  x1 
...  xn  t where each component xi assumes the value +1 or -1.we propose a new updating rule for dhnn with delay in order to extend the convergence conditions and establish an algorithm that will enable the network to escape from the local maximum points. the following is the definition of a generalized updating rule.
definition 1.  let n = w1 w1 q s   represent a dhnn with delay  starting from any initial vector x 1  = x 1 （bn . given a sequence of neural index subsets l k   {1 ... n} for k −1  the neural network is updated in the following form: when k =1  l 1  is a neural index subset by means of random selection  in general l 1  《{1 .. n}   xi  k +1  = xi  k   if i l k  and for i（l k   k  1  the following defines updating rule s :
	xi  k +1 =     xxii  kk    	otherwiseif xi  k h i  k   xi  k ti  k            1 
where hi  and
j=1
ti  k  《  wii1 + ‘ wij1 + 1 ‘ wij1
j（l k 	j（l k 1  j』i
　the updating mode is called the general updating rule for the neural network with delay  gurd for short. a sequence of neural index subsets l k    {1 ...  n} satisfying the above conditions is generalized in an evolution mode. it includes a serial mode for neural network with delay when the sequence of neural index subsets is chosen which satisfy l k  =1  xu et al.  1; sun  1 . the following gives an illustrated example.
example 1
	   1  1  1  	 1	 1  1 	   1   
	 	 	 
w1 =       1   1   1  1       w1 =     1  1 1  1    q =        1...1      
	  1	 1  	 
　the updating results of example 1 are presented in table 1. it is noted that  for each updating mode  the threshold of a neuron is different  depending on the given sequence of neural index subsets l k  which determines the sequence of updating mode. the threshold ti  k  changes with the updating time k. however  for a hopfield neural network  its threshold is a constant. so the stable state of the network is constrained. in other words  when the weights and threshold parameters of a network are given  its fixed points or stable states have been fixed  and they can not change with different updating modes  such as serial mode or parallel mode. on the other hand  the stable state of gurd mode is dynamically distributed based on a given sequence of neural index subsets l k  . of course  the global maximum point will not change with respect to different updating modes. only the local maximum points will be affected by these updating modes. thus this dynamically distributed mechanism and delay relation enable the network to escape from local maximum points and finally reach the global maximum point  similar to lme algorithm  peng  et al.  1   a strategy to identify which delay item can be regarded as a certain noise . this is what motivates the investigation on the updating mode and the delay neural network model.
ivs
codestate vector code; updated neuron indexspse.value111111111submax11111submax11111max11111max11111c11111c11111b11111a11111submax11111submax11111max11111max11111submax11111*submax11111max11111*maxtable 1. updating procedure from all initial values to sp for example 1
definition 1.  the function e u v  defined below is called a bivariate energy function on bn for n = w1 w1 q s  :
　　　　　　e u v  =utw1u+1utw1v 1utq                   1  where u = x t  v=x t 1 . in short  the bivariate energy function is written as e t 《 e x t  x t  1  .
1 	main results
based on the gurd mode  the neural network with delay has the following convergence properties.
theorem 1. let n = w1 w1 q s   be a dhnn with delay  operating in gurd mode s . suppose w1 is a symmetric matrix and w1 is a diagonal dominant matrix  i.e.  w w1ji . then for any k −1   x k 』1 or  x k 1 』1  it is
j』i
guaranteed that
　　　　　　 e k 《 e x k +1   x k   e x k   x k  1  − 1.       1  for any l k    {1 ... n} the equality holds if only and if x k+1 = x k = x k  1 .
proof: according to definition 1
           e u v  =utw1u + 1utw1v   1utq where 	u=x k   v=x k 1   q 	 	is 	a 	threshold 	vector q= q1 q1  ... qn t . then
e k  《 e x k  x k  1  ＋ ‘‘ wij1 +1wij1  +1‘qi . n	n	n
	i=1 j=1	i=1
for any k−1 i（l k   {1 ... n}and gurd in the operating mode  let  xi k 《xi k+1  xi k   e k 《e k+1  e k   we have
        e k 《xt k+1 w1x k+1 +1xt k+1 w1x k  1xt k+1 q  xt k w1x k  1xt k w1x k 1 +1xt k q.
               =‘n 1 xi k hi x k  +‘‘n	n   xi k    xj k  wij1
	i=1	i=1 j=1
                 +1‘‘n	n xi k +1  xj k  1 wij1
i=1 j=1
=‘n 1 xi k    hi x k  + 1‘n   xj k  wij1 +‘n   xj k  1  wij1       
	i=1	  	1 j=1	j=1	  
   +1 ‘  xj k 1    ‘n xi k w1ij   	       
	j（l k 1 	  i=1	  
= ‘ 1 xi k    hi x k  +1 ‘   xj k  wij1 + ‘  xj k 1  wij1   
	i（l k 	  	1 j（l k 	j（l k 1 	  
   +1 ‘  xi k 1    ‘n xj k w1ji   
	i（l k 1 	   j=1	  
 case 1  if  xi k  1  then xi k = 1 and xi k+1 =1.
thus we have
hi k     wii1 + ‘ wij1 + 1 ‘ w1ij
j（l k 	j（l k 1  j』i
 being a sufficient condition for   e k  i   1;
 case 1  if  xi k  1  then xi  k =1 and xi k+1 = 1.
thus we have
hi k   wii1   ‘ wij1   1 ‘ w1ij
j（l k 	j（l k 1  j』i
 being a sufficient condition for   e k  i   1;
 case 1  as w1 is a column diagonal dominant matrix  then  e k −1 when  xi k =1  xi k 1 』1. any nonzero update with  x k 』1 or  x k 1 』1 in the gurd is of these three cases. so  e k  − 1.
　tables 1 and 1 present the updating results of example 1. especially in table 1  the experimental results support our main theorem. it shows that our method is more likely to converge to the maximum or the submaximum values than the hopfield neural network method does  the hopfield neural network could be applied to the energy function of the example 1  after modifying the diagonal elements of the weight matrix . the three stable points  coded sps: 1 1  which are neither max nor submax value points  have the greatest energy function values.
ivs codeenergy f.valuestable
pointsrelation sp with
 efvalue 1-11submax1-11submax1.1max1-11max1.1c1.1c1.1b1.1a1.1submax1.1submax1.1max1.1max1.1submax1.1submax1.1max1.1maxtable 1. updating results to all initial values for example 1
　the following example 1 is a revised version of example 1. after modifying the original threshold vector  by adding a certain noise or standard gaussian noise  and the diagonal elements of the weight w1 . the updating results of example 1 are given in table 1. the experimental results of example 1 show a much better performance than example 1. there are only two stable points. sp 1 is the maximum value point and sp 1 is the submaximum value point.
example 1
	   1  1  1   	  1	 1  1  	    1   
  w
w1 =      1  1  1  1    1 =    1  1	1  1      q =        1..1      
	  1  1	1   	   1	 1 	 
　it is no surprise that the convergence performance of example 1 is better than that of example 1. this shows that by adjusting the original threshold values of the network parameters  one can change or decrease the local maximum value points. however  this improvement comes as a result of 1 times updating tests and 1 random selection of parameter threshold values. it remains an important open problem on how such threshold values can be adjusted to produce a better performance.
ivs
codeenergy f. valuestable pointse.value1-11max1-11max1-11submax1-11submax1.1max1.1max1.1submax1.1submax1.1max1.1max1.1submax1.1submax1.1max1.1*max1.1submax1.1*submaxtable 1. updating results to all initial values for example 1
　all the updating rules are summarized in table 1. the following illustration is used to explain the entries in table 1.
ivs
codestate vector code/updated neuron indexspse.value111111111max11111max11111submax11111submax11111max11111max11111submax11111submax11111max11111max11111submax11111submax11111max11111*max11111submax11111*submaxtable 1. updating procedure from all initial values to sps for example 1
　let the initial value x  1  = x  1  be   1  1  1  1 t （b1. the evolving operational process can be interpreted as follows. first choose a sequence of neural index subsets l 1  = {1} 
l 1  = {1}  	l 1  = {1}  	l 1  ={1}  	l k  = l i   i = k    k  1 / 1  1   k   1 
where  s  denotes the largest integer which is smaller than s ; bivariant{st  code efvalue= m1} represents the neuron state vector code st code  and the corresponding energy function value efvalue ;  and   l  i ★ means updating all elements of the neural index subsets in l i  .
initial 	value 	{1  efvalue= 1}  l  1   l 1   l  1   l  1 ★
{1 efvalue = 1}   l  1 ★.... it converges to the stable state 1.
theorem 1. let n =  w1 w1 q s   be a dhnn with delay  operating in a gurd mode. suppose w1 is a symmetric matrix and w1 is a diagonal dominant matrix  i.e.  for all i   w w1ji . then for any k −1  we have
j』i
 e k 《e u u  e u v −1   for u v（bn  v 』u      1 
the inequality holds if only and if  is a nonempty
k=1
set  and there is an index i such that
k=1
w1ii   ‘ w1ij   where u = x k +1  v = x k .
j』i
proof: according to definition 1
　　　　e u v =ut w1u+1ut w1v 1utq  where u = x k  v = x k  1   and q  is a threshold vector q= q1 q1 ... qn t. let  xi k 《xi k+1  xi k    e k 《e k+1  e k . then
       e k 《1xt k+1 w1x k  1xt k+1 q
       1xt k w1x k 1 +1xt k q
 =1xt k w1 x k  1 =1‘n  xi k  1   ‘n wjixj k    .  
	i=1	  j=1	  
without loss of generality  we assume that l k  1  《
{1 ... n}    xi  k  1  』 1   i（l k  1  . since w1 is a column diagonal dominant matrix  it implies that  e −1.
if  is a nonempty set of {1 ... n}   w1 is a
k=1
±
diagonal dominant matrix and there is an index i （ l k 
k=1
such that w1ii   ‘w1ji   we can conclude
j』i
  e 《 e u u   e u v    1.
on other hand  if  e《e u u   e u v ＋1  i.e. 
1− e=ut w1 u v  = 1   1‘n w1ii +‘‘n	n uiwij1 uj  vj    
	   i=1	j=1 i』j	  
	n	n
                    w1ji  −1
	i=1	j』i
 since w1 is a diagonal dominant matrix  hence w1ii =
‘w1ji is satisfied for all i（{1 ... n}. it is a contradiction as
j』i
there is an indexi such that w1ii  ‘w1ji . this completes the
j』i
proof of theorem 1.
　from the general updating rule  1  in theorem 1  it is noted that the network trajectory evolves in such a way that the energy function is always nondecreasing; that is   e k 《e x k+1  x k   e x k  x k 1  −1
using the inequality   1  in theorem 1 e x k+1  x k+1    e x k+1  x k  −1.
hence
　　　　e x k+1  x k+1  − e x k+1  x k  −e x k  x k 1          1  the network trajectory now has a new step  i.e.  at the  k +1 th step  instead of  updating from the k th step with initial values x k  x k  1    now updating from the k th step with initial values x k  x k . the modification allows the energy function to accelerate the rate of convergence and simplify the gurd. in the following  we define a new gurd rule.
definition 1.  let n =  w1 w1 q s   represent dhnn with delay  starting from any initial vector x 1  = x 1 （bn   given a sequence of neural index subsets l k    {1 ... n} for k −1  the neural network is updated as follows:
1  when k =1  l 1    {1 ... n} is a neural index subset by means of random selection  in general
l 1  《{1 .. n}  
1  for l k   {1 .. n}  if i l k    let xi  k +1  = xi k  and for i（ l k  . the updating rule s is given by:
	 	 	 
xi k +1 =       xxii  kk     otherwiseif xi k      .wii1 +1j（‘jl』 ik wij1       xi k hi k        1 
where hi.
j=1
　this updating mode is also called the simplified general updating rule for neural network with delay  sgurd for short.
　it is noted that both w1 being a symmetric matrix and w1 being a diagonally dominant matrix are required for the sgurd. comparing the two constrained conditions  1  and  1   one may easily conclude that the range region of x invariable condition  otherwise case in  1   decreases. it means that the energy function can reach the local maximum value in a short updating time. in other words  we only need to execute the sgurd rule 1n+1 steps at most  qiu et al.  1a . but for the hopfield network  the updating rule may require up to n1 steps in order to obtain a stable state when the energy function has reached to a local maximum  bruck  1 .
　it is noted that theorem 1 generalizes the results in  qiu et al.  1; qiu et al.  1a; qiu et al.  1b  which extend the constrained conditions of the weight matrices w1  w1. the requirement that the diagonal elements in w1 are nonnegative  serial mode  and w1 is nonnegative definite  parallel mode  are not necessary for the gurd mode. it has been shown that the updating rule process of the network and the activation process of the neurons are characterized by a dynamical process. but the sigmoid function still remains as the most popular choice for the network's activation function  and the serial  parallel and partially parallel modes are considered as important updating rule modes. there are no other modes.
corollary 1 after a finite number of updates  under the gurd mode  the neural network with delay will converge to a fixed point.
　in fact the fixed point is a local minimum point of the energy function. on the other hand  the convergence property is indispensable for any practical application design of neural network with delay.
1 	conclusion
in this article we have demonstrated how a generalized updating rule can cause the energy function to increase monotonously for neural network with delay. the gurd mode can operate in any sequence of updating modes. we have shown that the neural network with delay converges when operating in the gurd mode. the algorithm presented in  qiu et al.  1; qiu et al.  1a; qiu et al.  1b   including the original mhnn algorithm and the partially parallel mode algorithm  hopfield  1; wilson and pawley  1; bruck  1; xu et al.  1;sun  1; lee  1   can be easily derived from our main result which is supported by the experimental results of examples 1 and 1.
acknowledgements
the authors would like to thank reviewers for their comments and suggestions which helped in improving the manuscript. this research was partially supported by the national nature sciences foundation  china
 grant:1  and nature sciences foundation of  south china of university technology.
references
 hopfield  1  j j. hopfield. neural networks and physical systems with emergent collective computational abilities. proc. nat. acad. sci. usa  1: 1  1.
 wilson and pawley  1  g. n. wilson  and g. s. pawley.
on the stability of the traveling salesman problem algorithm of hopfield and tank. biological
cybernetics  1-1  1.
 bruck  1  bruck j  on the convergence properties of the hopfield model. proceedings of ieee  1 :1  1.
 clouse and lee  1  daniel s. clouse and giles c.lee. time-delay neural network: representation and induction of finite-state machines. ieee transactions on neural networks  1 :1  1.
 orponen  1  p. orponen. neural networks and complexity theory. proc.1th international symposium on mathematical foundations of computer science  pages 1 lecture notes in computer science 1  springer-verlag  berlin  germany  1.
 xu et al.  1  zongbin xu  guoqing hu and chungping kwong. asymmetric hopfield-type networks: theory and applications. neural networks  1 :1 1.
 sun  1  yi sun. a generalized updating rule for modified hopfield neural network for quadratic optimization. neurocompting  1-1  1.
 qiu et al.  1  shenshan qiu  eric c.c. tsang and daniel s. yeung. stability of discrete hopfield neural networks with time-delay  in proceedings of the 1 ieee international conference on system  man cybernetics  pages 1  nashville  tennessee  october  1.
 qiu et al.  1a  shenshan qiu  xiaofei xu  mingzhu liu and yadong wang. convergence of discrete hopfieldtype neural network with time-delay in a serial mode. journal of computer research & development 1  1 :1  1.
 qiu et al.  1b  shenshan qiu  xiaofei xu  chunsheng li and mingzhu liu. matrix criterion of dynamic analysis in discrete neural networks with delay. journal of software 1 :1  1.
 lee  1  donq-liang lee. new stability conditions for hopfield networks in partial simultaneous update mode. ieee transactions on neural networks  1 :1  1.
 peng  et al.  1  mengkang peng  narendra k. and allistair f. armitage. an investigation into the improvement of local minima of the hopfield network.
neural networks  1 :1  1.

neural networks and
genetic algorithms
neural networks and genetic algorithms

genetic algorithm based selective neural network ensemble
zhi-hua zhou  jian-xin wu  yuan jiang  shi-fu chen
national laboratory for novel software technology
nanjing university  nanjing 1  p.r.china zhou nju.edu.cn  {wujx  jy} ai.nju.edu.cn  chensf nju.edu.cn

abstract
neural network ensemble is a learning paradigm where several neural networks are jointly used to solve a problem. in this paper  the relationship between the generalization ability of the neural network ensemble and the correlation of the individual neural networks is analyzed  which reveals that ensembling a selective subset of individual networks is superior to ensembling all the individual networks in some cases. therefore an approach named gasen is proposed  which trains several individual neural networks and then employs genetic algorithm to select an optimum subset of individual networks to constitute an ensemble. experimental results show that  comparing with a popular ensemble approach  i.e. averaging all  and a theoretically optimum selective ensemble approach  i.e. enumerating  gasen has preferable performance in generating ensembles with strong generalization ability in relatively small computational cost.
1  introduction
since neural computing has no rigorous theoretical framework until now  whether a neural network based application will be successful or not is almost fully determined by that who is the practitioner. in general  the more experiences the practitioner has on neural computing  the more chances the application will have in gaining success. however  in real-world applications  the users are often those with little knowledge on neural computing. therefore the rewards that neural network techniques may return do not always appear.
   in the beginning of the 1's  hansen and salamon  showed that the generalization ability of a neural network system can be significantly improved through ensembling neural networks  i.e. training several neural networks and combining their results in some way. later  sollich and krogh  defined neural network ensemble as a collection of a  finite  number of neural networks that are trained for the same task. since it behaves remarkably well and is easy to use  neural network ensemble is regarded as a promising methodology that can profit not only experts in neural computing but also ordinary engineers in realworld applications. and neural network ensemble has already been used in many real domains such as handwritten digit recognition  hansen et al.  1   scientific image analysis  cherkauer  1   face recognition  gutta and wechsler  1; huang et al.  1   ocr  mao  1   seismic signals classification  shimshoni and intrator  1   etc. many works have been done in investigating why and how neural network ensemble works. the classical one is krogh and vedelsby  's work  in which they derived a famous equation e = e   a that clearly demonstrates that the generalization ability of the ensemble is determined by the average generalization ability and the average ambiguity of the individual neural networks that constitutes the ensemble.
   in this paper  the relationship between the generalization ability of the neural network ensemble and the correlation of the individual neural networks is analyzed  which reveals that in some cases ensembling an appropriate subset of individual networks is superior to prevailing ensemble schemes  i.e. ensembling all the individual networks at hand. based upon the recognition that the appropriate subset of individual networks is difficult to be found out directly  a genetic algorithm based approach named gasen  genetic algorithm based selective ensemble  is proposed  which trains several individual neural networks and then employs genetic algorithm to select an optimum set of individual networks to constitute an ensemble. experiments show that gasen is superior to a popular ensemble approach  i.e. averaging all that averages the outputs of all the individual networks at each output unit. experiments also show that gasen is superior to a selective ensemble approach that is theoretically optimum  i.e. enumerating that estimates the generalization ability of every possible subset of individual networks and then selects the best subset to make an ensemble. moreover  most ensemble approaches require their individual networks be independently trained. but at present there is no method can guarantee the independence when there are many individual networks. since gasen can increase the ambiguity of the ensemble through selecting the appropriate subset of individual networks  it does not claim independent training  which makes it more easily to use than many other ensemble approaches.
   the rest of this paper is organized as follows. in section 1  the relationship between the generalization ability of the ensemble and the correlation of the individual neural networks is analyzed. in section 1  gasen is proposed to find out the optimum subset of individual networks. in section 1  experiments on averaging all  enumerating  and gasen are reported. in section 1  related works are overviewed. finally in section 1  conclusions are drawn and several issues for future works are indicated.
1  generalization and correlation
suppose the learning task is to use an ensemble that comprises n individual neural networks to approximate a function f: rm ★ rn. the predictions of the individual networks are combined through weighted averaging  where a weight wi  i = 1  1  ...  n  is assigned to the individual network fi  and wi satisfies equation  1  and  1 :
	  1   wi   1	  1 
n
	  ‘wi =1	  1 
i=1
   therefore the k-th output component of the ensemble is computed according to equation  1   where fi k is the value of the k-th output component of the i-th individual network.
		n
	f k =‘ wi fi k	  1 
i=1
   for convenience of discussion  here we assume that each individual network has only one output component  i.e. the function to be approximated is f: rm ★ r. but note that following derivation can be easily generalized to situations where each individual network has multiple output components.
   suppose x （ rm is randomly sampled according to a distribution p x . the expected output of x is d x . the actual output of the i-th individual neural network is fi x .
then the output of the neural network ensemble is:
n
	 f    x =‘wi fi    x	     1 
i=1
   the generalization error ei x  of the i-th individual network on input x and the generalization error e x  of the ensemble on input x are respectively:
	ei          x = fi x   d    x 1	     1 
	 e   x =  f    x   d   x  1	 1 
   then the generalization error ei of the i-th individual neural network on the distribution p x  and the generalization error e of the ensemble on the distribution p x  are respectively:
	 ei =〈dxp x ei    x	 1 
	  e=〈dxp x e   x	 1 
   the average generalization error of the individual neural networks on input x is:
n
	 e   x = ‘wi ei    x	 1 
i=1
   then the average generalization error of the individual neural networks on the distribution p x  is:
	  e=〈dxp x e   x	 1 
   now we define the correlation between the i-th and the j-th individual neural networks as:   cij = 〈dxp        x fi x  d    x  f j    x  d   x    1 
note that cij satisfies equation  1  and  1 :
	 cii =ei	 1 
	 cij =c ji	     1 
considering equation  1  and  1  we get:
  e   x =  ‘n wi fi    x  d   x      ‘n wj f j    x  d   x      1 
	  i=1	   j=1	 
then considering equation  1  and  1  we get:
	n	n
	  e=‘‘wiwjcij	 1 
i= =1 j 1
different to krogh and vedelsby  's result
e = e   a   equation  1  utilizes the correlation between the individual neural networks to represent the generalization error of the ensemble. since the computation of cij only refers to fi and fj  equation  1  is easier to use than e = e   a in real-world applications.
   suppose that wi = 1/n  i = 1  1  ...  n   i.e. the predictions of the individual neural networks are combined via averaging. then equation  1  becomes:
	n	n
	  e=‘‘cij / n 1	 1 
i=1 j=1
   let's assume that the k-th individual neural network is deleted from the ensemble. then the generalization error of the new ensemble is:
	n	n
	e'=‘‘cij / n 1	 1 

considering equation  1  and  1  we get:
n
1‘cik +ek   1n 1 e
i=1
	e e'= i』k	1	 1 
 n 1 
   it is obvious that e   e＞ when equation  1  is satisfied  which means that the new ensemble that omits fk is more accurate than the original one that includes fk.
	 	 
	e     1 n c	 	 1 
‘ ik + ek   / 1n  1 
	  i=1	 
	  i』k	 
   considering equation  1  and  1  we get the constraints on fk:
   1n 1 ‘‘n	n cij  1 n 1 ‘n cik + n 1 ek  1 

   now a conclusion is arrived that after the individual neural networks are trained  in some cases ensembling an appropriate subset of individual neural networks is superior to ensembling all the individual networks. the individual networks that should be omitted satisfy equation  1 .
1  gasen
note that the individual neural networks to be omitted are hard to be found out directly by equation  1  due to the extensive computation required. moreover  following observation is noteworthy that in real-world applications the generalization error of the individual neural networks and that of the ensemble are all unknown. however  we can employ cross-validation to get their generalization error on a validation set  which can be used to approximate the actual generalization error.
   an approach named enumerating can be utilized to find out the appropriate subset of individual networks  which estimates the generalization error of all the possible subsets of {f1  f1  ...  fn} and then selects the best subset to make an ensemble. when n is a small number  enumerating can achieves optimum results. however  if n is a big number  such as n   1  enumerating is nearly impossible to be realized due to its excessive computational cost  it will estimates the generalization error of 1n -1 number of ensembles .
   here we present a practical routine to find out the appropriate subset of individual neural networks. assume we can assign to each individual neural network an optimum weight that exhibits its importance in the ensemble. then we can select the individual networks whose weight is bigger than a pre-set threshold λ to constitute the ensemble via averaging. suppose the weight corresponding to the i-th individual neural network is wi  which satisfies both equation  1  and  1 . then we have a weight vector w =  w1  w1  ...  wn . since the optimum weight should minimize the generalization error of the ensemble  considering equation  1   the optimum weight vector wopt can be expressed as:
	  n	n	 
	wopt = argmin  ‘‘wi wjcij   	 1 
	  i= =1 j 1	 
wopt.k  i.e. the k-th  k = 1  1  ...  n  component of wopt  
can be solved by lagrange multiplier. wopt.k satisfies:
	  n	n	  n	  
   ‘‘wiwjcij  1λ ‘wi  1   
	  i= =1 j 1	  i=1	   =1  1 
 wopt.k
equation  1  can be simplified as:
n
	‘wopt.kckj =λ	 1 
j=1 j』k
considering that wopt.k satisfies equation  1   we get:
n
‘c
wopt.k = nj=1n	 1  ‘‘c
i=1 j=1
   although equation  1  is enough to solve wopt in theory  it rarely works well in real-world applications. this is because in the ensemble of real-world applications there are often some individual neural networks that are quite similar in performance  which makes the correlation matrix  cij n〜n of the ensemble be an inreversible or ill-conditioned matrix so that equation  1  cannot be solved.
   since equation  1  can be viewed as an optimization problem  considering the success that has been obtained by genetic algorithms in optimization area  goldberg  1   gasen is proposed to find out the appropriate subset of the individual networks. after the individual networks being trained  gasen employs genetic algorithm to evolve the optimum weight vector wopt. then gasen selects the individual networks whose corresponding optimum weight component is bigger than the pre-set threshold λ to constitute the ensemble. note that if no individual network is washed out  i.e. every component of the evolved optimum weight vector is bigger than λ  all the individual networks are used to constitute the ensemble. we believe that this is corresponding to the situation that no individual networks satisfying equation  1 . following observation is noteworthy that the output of the ensemble is generated via averaging. in other words  the evolved optimum weight vector is only used in the selection of the individual networks. this is because we believe that using the weight vector both in the selection of the individual networks and the combination of the individual predictions is easy to cause overfitting.
   here gasen is realized by utilizing the standard genetic algorithm  goldberg  1  and a floating coding scheme that represents every component of the weight vector in 1 bits. therefore each individual in the evolving population is coded in 1n bytes where n is the number of the individual networks. note that since gasen can be viewed as an abstract approach rather than a concrete algorithm  it can be easily realized by employing diversified kind of genetic algorithms and coding schemes.
   let v denotes the validation set. the estimated value of the correlation between the i-th and the j-th individual neural networks is:
‘ fi    x  d   x   f j    x  d   x  
	cijv = x（v	 1 

   considering equation  1   the estimated generalization error of the neural network ensemble corresponding to the individual w in the evolving population is:
	n	n
	ewv =‘‘wi w jcijv =wt cv w	 1 
i=1 j=1
   it is obvious that ewv expresses the goodness of w. the smaller ewv is  the better w is. so we use f w  = 1/ ewv as the fitness function. note that w may violate equation  1  during its evolving. therefore it is necessary to do normalization on the evolved optimum w so that its components can be compared with λ. here we use a simple normalization scheme:
n
	  wopt.i = wi /‘wi	 1 
i=1
1  experiments
we use four regression problems to compare the performance of three ensemble approaches  i.e. averaging
all  enumerating  and gasen.
   the first problem is friedman#1 proposed by friedman . there are 1 continuous attributes. the data set is generated according to equation  1  where the noise item ε satisfies normal distribution n 1  1  and xi  i =1  1  ...  1  satisfies uniform distribution u 1  1 . in our experiments the size of the training set and the test set are respectively 1 and 1.
t =1sin πx1 + 1 x1   1 1 +1 + 1 +ε  1 
   the second problem is boston housing from uci machine learning repository  blake et al.  1 . there are 1 continuous attributes and 1 categorical attribute. the data set comprises 1 examples among which 1 examples make up the training set and the rest 1 examples make up the test set in our experiments.
   the third problem is ozone proposed by breiman and friedman . there are 1 continuous attributes. the data set comprises 1 examples. since the intention of the experiments is not to compare the ability of dealing with missing values  1 attribute and 1 examples that has missing values are omitted as briedman  did on the data set. therefore in our experiments there are 1 continuous attributes and 1 examples among which 1 examples make up the training set and the rest 1 examples make up the test set.
   the fourth problem is servo from uci machine learning repository. there are 1 categorical attributes. the data set comprises 1 examples among which 1 examples make up the training set and the rest 1 examples make up the test set in our experiments. note that some researchers  quinlan  1  believe that this problem is very difficult because it involves some kind of extreme nonlinearity.
   for each problem we use bagging on the training set to generate 1 single-hidden-layered bp  rumelhart et al.  1  networks. during the training process  the generalization error of each network is estimated in each epoch on a validation set generated via bootstrap sampling from the training set. if the error does not change in consecutive 1 epochs  the training of the network is terminated in order to avoid overfitting. then we use averaging all  enumerating  and gasen to ensemble those trained bp networks. in our experiments the genetic algorithm employed by gasen is implemented by the gaot toolbox developed by houck et al. . the genetic operators  including select  crossover  and mutation  and the system parameters  including crossover probability  mutation probability  and stopping criterion  are all set to the default values of gaot. the pre-set threshold λ used by gasen is set to 1. the validation set v used by gasen is also generated via bootstrap sampling from the training set. for every problem we perform 1 runs and record the average mean squared error and the standard deviation on
table 1  experimental results on averaging all  enumerating  and gasen
	averaging all	enumerating	gasen
data set
	error	deviation	error	deviation	error	deviation
friedman#1.1.1.1.1.1.1boston housing111111ozone111111servo111111the test set of the ensembles. the experimental results are tabulated in table 1.
   pairwise one-tailed t-tests indicate that the generalization error of gasen is significantly less than that of averaging all on friedman#1  boston housing  and ozone  while there is no significant difference between the performance of those two approaches on servo. we believe that gasen is superior to averaging all because ensembles generated by it are more accurate than that generated by averaging all in most cases. pairwise one-tailed t-tests also indicate that there is no significant difference between the performance of gasen and enumerating on all those data sets. considering that enumerating can hardly work when there are lots of individual networks due to its extensive computational cost  we believe that gasen is superior to enumerating because it can generate ensembles with comparable generalization ability in the cost of much smaller computation.
   following observation is interesting. through analyzing the ensembles  we find that gasen and enumerating averagely select a subset comprises 1 networks out of 1 individual networks to constitute the ensemble. and the subset selected by gasen is the same as that selected by enumerating in 1 runs out of 1 runs on friedman#1  1 runs out of 1 runs on boston housing  1 runs out of 1 runs on ozone  and 1 runs out of 1 runs on servo. it is obvious that the frequency of the appearance of same selected results is much higher than that should exhibit in random selection. considering that enumerating is an optimum approach when the size of ensemble is small  we believe that this observation verifies the goodness of gasen from another aspect. however  the reason for explaining the high frequency of the appearance of same selected results should be further explored.
1  related works
neural network ensemble has become a very active area and there are a large number of research groups working on it. besides the achievements cited in the brief review presented in section 1  some significant developments in this area can be found in  sharkey  1 . moreover  there are some works very related to this paper.
   yao and liu  employed genetic algorithm to evolve a population of neural networks. instead of choosing the best neural network in the last generalization as the final result  they regarded the entire population as a neural network ensemble and combining all the individuals in the last generalization in order to make best use of all the information contained in the population. although genetic algorithm is used in both their and our works  there are many differences among which a conspicuous one is that they intended to utilize the information contained in the genetic population rather than performing selection on the individual networks.
   liu and yao  proposed an ensemble learning approach  i.e. negative correlation learning  where all the individual networks are trained simultaneously through the correlation penalty terms in their error functions. rather than generating unbiased networks whose errors are uncorrelated  negative correlation learning can generate negatively correlated networks to encourage specialization and cooperation among the individual networks. the main reason that negative correlation learning can improve the generalization ability of an ensemble is that it increases the ambiguity item a in the famous equation e = e   a . in gasen  when individual neural networks are selected according to the evolved optimum weight vector  the ambiguity of the ensemble is also increased. this can be derived from the observation that the generalization ability of the ensemble generated by gasen is better than the ensemble that comprises same number of individual networks that rank toppest in generalization ability.
1  conclusion
in this paper  the relationship between the generalization ability of the neural network ensemble and the correlation of individual networks is analyzed  which reveals that in some cases ensembling a selective subset of individual networks is superior to ensembling all the individual networks. then a genetic algorithm based ensemble approach named gasen is proposed. experimental results show that gasen is a promising ensemble approach that is superior to both averaging all and enumerating.
   there are many works left to do in the near future. firstly  at present gasen has only been compared with averaging all and enumerating on several data sets. we plan to do comparisons with more ensemble approaches on more data sets. secondly  the pre-set threshold λ is an important parameter of gasen  which determines the individual neural networks that constitute the ensemble. we hope to find out the relationship between λ and the generalization ability of the ensemble so that we can set λ to appropriate values in real-world applications. thirdly  we want to explore why there is such a high frequency that gasen and enumerating select the same subset of individual networks to make an ensemble.
acknowledgements
the comments and suggestions from the anonymous reviewers greatly improve this paper. the national natural science foundation of p.r.china and the natural science foundation of jiangsu province  p.r.china  supported this research.
references
 blake et al.  1  c. blake  e. keogh  and c. j. merz. uci repository of machine learning databases  http://www.ics.uci.edu/~mlearn/mlrepository.html   department of information and computer science 
university of california  irvine  california  1.
 breiman  1  l. breiman. bagging predictors. machine learning  1 : 1  1.
 breiman and friedman  1  l. breiman and j. friedman. estimating optimal transformations in multiple regression and correlation  with discussion . journal of the american statistical association  1 : 1  1.
 cherkauer  1  k. j. cherkauer. human expert level performance on a scientific image analysis task by a system using combined artificial neural networks. in proceedings of the 1th aaai workshop on integrating multiple learned models for improving and scaling machine learning algorithms  pages 1  1. aaai.
 friedman  1  j. friedman. multivariate adaptive regression splines  with discussion . annals of statistics  1 : 1  1.
 goldberg  1  d. e. goldberg. genetic algorithm in search  optimization and machine learning. addisonwesley  reading  1.
 gutta and wechsler  1  s. gutta and h. wechsler. face recognition using hybrid classifier systems. in proceedings of the ieee international conference on neural networks  pages 1  1. ieee computer society.
 hansen and salamon  1  l. k. hansen and p. salamon. neural network ensembles. ieee trans. pattern analysis and machine intelligence  1 : 1  1.
 hansen et al.  1  l. k. hansen  l. liisberg l  and p. salamon. ensemble methods for handwritten digit recognition. in proceedings of the ieee-sp workshop on neural networks for signal processing  pages 1  1. ieee computer society.
 houck et al.  1  c. r. houck  j. a. joines  and m. g. kay. a genetic algorithm for function optimization: a matlab implementation  ncsu-ie technical report 1  north carolina state university  1.
 huang et al.  1  f. j. huang  z.-h. zhou  h.-j. zhang  and t. chen. pose invariant face recognition. in proceedings of the 1th ieee international conference on automatic face and gesture recognition  pages 1  grenoble  france  1. ieee computer society.
 krogh and vedelsby  1  a. krogh a and j. vedelsby. neural network ensembles  cross validation  and active learning. in advances in neural information processing systems 1  pages 1  1. mit.
 liu and yao  1  y. liu and x. yao. ensemble learning via negative correlation. neural networks  1 : 1  1.
 mao  1  j. mao. a case study on bagging  boosting and basic ensembles of neural networks for ocr. in proceedings of the ieee international joint conference on neural networks  vol.1  pages 1  1. ieee computer society.
 quinlan  1  j. r. quinlan. c1: programs for machine learning  morgan kaufmann  san mateo  california  1.
 rumelhart et al.  1  d. rumelhart  g. hinton  and r. williams. learning representations by backpropagating errors. nature  1 : 1  1.
 sharkey  1  d. sharkey  editor. combining artificial neural nets: ensemble and modular multi-net systems  springer-verlag  london  1.
 shimshoni and intrator  1  y. shimshoni and n. intrator. classification of seismic signals by integrating ensembles of neural networks. ieee trans. signal processing  1 : 1  1.
 sollich and krogh  1  p. sollich and a. krogh.
learning with ensembles: how over-fitting can be useful. in advances in neural information processing systems 1  pages 1  1. mit.
 yao and liu  1  x. yao and y. liu. making use of population information in evolutionary artificial neural networks. ieee trans. systems  man and cybernetics - part b: cybernetics  1 : 1  1.
neural logic network learning using genetic programming
chew lim tan  henry wai kit chia
school of computing
national university of singapore
science drive 1  singapore 1 tancl  chiawaik  comp.nus.edu.sgabstract
neural logic network or neulonet is a hybrid of neural network expert systems. its strength lies in its ability to learn and to represent human logic in decision making using component net rules. the technique originally employed in neulonet learning is backpropagation. however  the resulting weight adjustments will lead to a loss in the logic of the net rules. a new technique is now developed that allows the neulonet to learn by composing net rules using genetic programming. this paper presents experimental results to demonstrate this new and exciting capability in capturing human decision logic from examples. comparisons will also be made between the use of net rules  and the use of standard boolean logic of negation  disjunction and conjunction in evolutionary computation.
1	introduction
there has been a fair amount of interest in training neural networks using genetic programming  golubski and feuring  1 . gaudet  applied genetic programming on logic-based neural networks which basically represent standard logic  negation  conjunction and disjunction . similarly  an adaptive logic network  armstrong and thomas  1  uses linear threshold units at the leaf node level  while the parent nodes of the network are composed of  and  and  or  logic units. however  neural networks can also represent nonstandard logic. a neural logic network or simply neulonet has been proposed that emulates human decision logic which are often too complex to be expressed neatly using standard logic  teh  1; tan et al.  1 .
　in this paper  we begin by focusing on the integration of neulonets into a genetically programmed environment. first  we introduce the concept of neulonets and show how they can be combined to form complex decisions. we then describe a gp system for evolving neulonets  and discuss how genetic operations of crossover and mutation can be adapted to neulonet evolution. next  we demonstrate how the system can effectively solve a classification problem and extract rules from the evolved neulonet. finally we provide experimental results to substantiate the use of neulonets as an improvement over the use of standard logic networks in genetic programming.
1	neural logic network
a neulonet has an ordered pair of numbers associated with each node and connection  figure 1 . let be the output node and     ... be input nodes. let values associated with the node be denoted by        and the weight for the connection from to be      . the ordered pair for each node takes one of three values  namely   1  for true   1  for false and  1  for  don't know .  1  is undefined. the following activation function determines the output at :
if
 1 
if
otherwise.
	where	is the threshold  usually set to 1.

figure 1: a basic neural logic network - neulonet.
　by applying equation  1  on a network in figure 1  the network behaves like an expert system rule with an or logic operation as shown in the truth table.

pqp or q 1 
 1 
 1 
 1 
 1 
 1 
 1 
 1 
 1  1 
 1 
 1 
 1 
 1 
 1 
 1 
 1 
 1  1 
 1 
 1 
 1 
 1 
 1 
 1 
 1 
 1 figure 1: the above neulonet behaves like a disjunction rule.

p
p p
p1
p1
p1
pn
p1 p1
p1
pn
r
p1
p1
pn
p1 p1
p1
pn
 1 
 1  conformity
　　 1/n 1   1/n 1 
 1/n 1 
 1/n 1 
 1  conjunction
 1/n 1/n 
 1/n 1/n 
 1/n 1/n 
 1/n 1/n 
 1  unanimity
 1n 1n 
 1 
 1 
 1 
 1  overriding
　　 1/k 1   1/k 1 
 1/k 1 
 1/k 1 
at-least-k-yes  q
q
q
q
q
q
q
 p1 p1
p1
pn
p1
p1
p1
pn
p1 p1
p1
pn
 1 
v
p1
p1
pn
p1 p1
p1
pn
 1  
 
 1 
 1  priority
　　 1/n   1/n 
 1/n 
 1/n 
 1  disjunction
 1 
 1 
 1 
 1 
majority influence
 -1n 1 
 1/n 
 1/n 
 1/n 
 1  veto
　　 1/k   1/k 
 1/k 
 1/k 
at-least-k-no   
q
q q
q
q
 def
 1 
	p1	 1 
 1 
p1
 1 
pn
 1  silence means consentqr
 1 
	p1	 1/n 1/n 
 1/n 1/n 
p1
 1/n 1/n 
pn
 1  1-out-of-1 unless overriddenq　we call a network in figure 1 a net rule - a rudimentary network that can be chained with other similar networks just like in a conventional rule-based expert system. the power of a net rule  however  is not limited to standard boolean logic operations. a wide range of different human logic in decision making can be represented with net rules using different sets of weights. figure 1 shows some examples of net rules that emulate a human decision maker's behavior. human decision processes are often too complex to be expressed neatly using standard logic. one such complexity is that human reasoning can be biased by giving different degrees of importance to different factors. a simple and or or operation will be inadequate in representing varying degrees of bias.
　for instance  rule  1   priority  in figure 1 exhibits different degrees of influence on the outcome of with being the most important factor  while will only be considered when all other factors are unknown  i.e.  1 . another example can be seen in rule  1   silence means consent  where def represents the default action. if no one among     ...  has any opinion  or if there is an equal number of persons either for or against a motion  the default action is taken. in all other cases  the majority wins. net rules can combine to form composite net rules to achieve more complicated decisions. for instance  using the output of rule  1   unanimity  as the input to rule  1   veto   both with n set to 1  an xor operation can be realized as shown in figure 1.
　a neulonet combines the strengths of neural networks and expert systems  tan et al.  1 . it was proposed that a knowledge engineer could first encode his knowledge into component net rules and later use real examples to do refinement training to adjust the weights in the neulonet. training in this case is by means of backpropagation  teh  1   which will pervasively modify all weights in the network. it was shown that the neulonet's performance improves after the refinement training. however  one problem with backpropagation is that after training  the logic of the net rules may not be decipherable as the weights of the net rules have been altered. the trained net rules may not be reused easily. in view of this  a novel way of neulonet training by means of a genetic programming paradigm is now introduced.
1	genetic programming
genetic programming  koza  1  is an extension of the conventional genetic algorithm where instead of subjecting bit patterns to genetic evolution  the individuals in the gene population are computer programs. in the context of neulonet evolution  the problem statement may be stated as follows:
 given a set of input nodes  a library of net rules  an output node  and a set of examples containing instances of input values together with the corresponding output decision  apply genetic programming to construct a neulonet that represents a decision logic induced from the examples .
the solution may be carried out in three steps:
1. generate an initial population of neulonets comprising of random compositions of net rules according to the figure 1: examples of component net rules. available input nodes and the output node.


pqp xor q 1 
 1 
 1 
 1 
 1 
 1 
 1 
 1 
 1  1 
 1 
 1 
 1 
 1 
 1 
 1 
 1 
 1  1 
 1 
 1 
 1 
 1 
 1 
 1 
 1 
 1 figure 1: an xor composite net rule.
1. iteratively perform the following substeps until the termination criterion has been satisfied:
 a  fire each neulonet in the population and assign it a fitness value using the fitness measure.
 b  create a new population of neulonets by applying the following three operations to neulonets chosen with a probability based on fitness.
i. reproduce an existing neulonet by copying it into the new population.
ii. create two new neulonets from two existing ones by genetically recombining chosen parts using a crossover operation applied at a randomly chosen crossover point within each neulonet.
iii. create a new neulonet from an existing one using a mutation operation at a randomly chosen mutation point.
1. the neulonet that is identified to be the best individual is designated as the solution to the problem.
　for efficiency  the neulonet structure that undergoes evolution is a labeled tree implemented using a prefix-ordered  jump-table approach  keith and martin  1 . the initial population of neulonets are generated in a similar fashion as koza's   ramped-half-and-half  generative method.
we use a normalized fitness measure based on the errors produced by the neulonet    as well as the size of the neulonet  . the factor    is used to weigh the effects of accuracy over size in the fitness measure. a higher value for places more emphasis on finding an accurate solution at the expense of the size of the neulonet.
　the crossover operation involves swapping the chosen parts of two neulonets with constraints imposed on the swapping process to preserve the syntactic integrity. for instance  swapping should not leave any dangling intermediate output nodes as such nodes will not be able to receive input values during firing. figures 1 and 1 illustrate a crossover operation on two neulonets before and after the operation.
　the mutation operation involves changes to a chosen neulonet. a random mutation point is picked such that the neulonet whose root is the mutation point is replaced by another randomly generated neulonet. figure 1 shows the effect of the mutation operation on a neulonet with the  conformity  net rule replaced by a  priority  net rule.
　the probabilities assigned are:  i  reproduction: 1%   ii  crossover: 1%  and  iii  mutation: 1%.

figure 1: two neulonets before crossover operation.

figure 1: two neulonets after crossover operation.
　note that the  conformity  net rule appears redundant in the activation of a neulonet and might be deemed not to be doing anything significant in the evolutionary process. this kind of net rule is similar to an intron in biology  which is a chromosome that is never expressed and provides spacing between the genes  angeline  1 . however  levenick  notes that introns are useful in genetic algorithms.
1	proposed method
in  tan et al.  1   it was assumed that the knowledge engineer has some prior knowledge to construct a neulonet  which is later subjected to further refinement training. what if the knowledge engineer has only a set of examples without any other knowledge  one approach is to construct a neulonet with random weights and train it with the examples. the resultant neulonet is no different from an ordinary neural network  as it is difficult to interpret the logic semantics from the seemingly meaningless set of weights. another approach is to solve a set of inequalities arising from the activation function in equation  1   teh  1 . the solution is not unique. moreover  the process becomes more difficult with increasing number of inputs and it may not be always possible to find a set of interpretable weights to satisfy all the inequalities.
　the genetic programming paradigm proposed here provides a third alternative for constructing a neulonet from examples. we shall illustrate the process using a simple example from the space shuttle landing domain  michie  1 .

figure 1: neulonet with a mutated net rule.
this data set comprises 1 instances and 1 attributes. table 1 shows each instance being classified as either to auto-land or not. to conform to the input requirements of the neulonet structure  every distinct attribute-value pair has a corresponding boolean attribute in a transformed data set. the valid values for these new attributes can either be yes  no or unknown. in our example  the 1-attribute data set transforms to a 1attribute data set of boolean values.
stableerrorsignwindmagnitudevisclass     noautoxstab    yesnoautostablx   yesnoautostabxl   yesnoautostabmmnntail yesnoauto    outofrangeyesnoautostabss  lowyesautostabss  mediumyesautostabss  strongyesautostabmmppheadlowyesautostabmmppheadmediumyesautostabmmpptaillowyesautostabmmpptailmediumyesautostabmmppheadstrongyesnoautostabmmpptailstrongyesautotable 1: space shuttle landing domain data set.
　for a particular neulonet evolution run  a 1% accurate solution was produced in generation 1 which consisted of 1 basic net rules. further evolution produced another 1% accurate solution in generation 1 as shown in figure 1. this solution consisted of a  priority  rule rooted at   a  at-least1-yes  rule rooted at   and a  negation  rule rooted at .

figure 1: a solution to the shuttle-landing classification problem.
1	extracting rules from neulonets
extracting rules from neural networks has been studied by many researchers  gallant  1; gaudet  1; setiono and liu  1; tan  1; towell and shavlik  1 . existing work  however  basically utilizes standard logic  such as negation  conjunction and disjunction. the rules extracted are generally in the form of a decision tree equivalent to an and/or tree based on some classification of the example data. in our present work  the goal is to extract human decision logic from the neulonets. the extraction is in fact a straightforward process because the neulonets constructed are just a composition of net rules which by themselves fully express the human logic in use. as for the case of the space shuttle landing domain classification problem  the following net rules are easily identified from the solution in figure 1.
: negation magnitude strong 
	: at-least-two-yes 	  sign pp  wind tail 
: priority    error ss  visibility no 
　in layman terms  the decision to auto-land the space shuttle is biased towards any two or more positive factors for a  pp  sign  tail wind and a magnitude that is not strong. otherwise  the presence  absence  of an  ss  error will result in a decision to auto-land  manual-land  the shuttle. if this error is unknown  then the decision to auto-land  manual-land  depends on a negative  positive  visibility.
1	empirical study and discussion
our analysis above shows that the proposed approach of using net rules in genetic programming should perform well for data sets which encompass some form of ordered logic reasoning. this analysis will be further confirmed via experiments. in particular  we wish to verify whether using an extended set of net rules as logical units is comparable to  if not better  than merely using a limited set of net rules comprising the standard boolean logic of negation  conjunction and disjunction  rules  1    1  and  1  of figure 1 . we selected data sets commonly used and publicly available from the uc irvine data repository  blake and merz  1 . data sets containing discrete attribute data types were transformed to an equivalent binary data set with one attribute for each attributevalue pair in the original set. moreover  data sets containing continuous-valued attributes were pre-processed using a chi1 discretizer  liu and motoda  1  prior to the transformation. for the case of data sets having three or more class values  a separate data set that performs a boolean classification for each class value was created. table 1 summarizes the data sets used in our experiments.
data set# instances# attributesshuttle-landing-control1iris-setosa1iris-versicolour1iris-virginica1monk-11monk-11monk-11voting-records1breast-cancer-wisconsin1mushroom1table 1: data set summary. #attributes denotes the number of boolean attributes in the transformed data set.
　the entire library of net rules given in figure 1 was used for our experiments. each of the net rules  1  to  1   were represented by their 1- and 1-arity equivalents  while a 1-arity  1-out-of-1 unless overridden  rule  1  was used. as a large initial population was required to cater for a wide variety of neulonets that could be evolved  we implemented a distributed parallel gp-system on an ap-1 fujitsu distributed memory parallel processing system consisting of 1 nodes using a ring-type connection  niwa and iba  1 .
data setneulonetstandardshuttle-landing1%1%1  1 1  1 iris-setosa1%1%1  1 1  1 iris-versicolour1%1%1  1 1  1 iris-virginica1%1%1  1 1  1 monk-1%1%1  1 1  1 monk-1.1%1%1  1 1  1 monk-1%1%1  1 1  1 voting-records1%1%1  1 1  1 breast-cancer1%1%1  1 1  1 mushroom1%1%1  1 1  1 table 1: experimental results depicting classification accuracy for the best individual. the numbers below the accuracy value denotes the number of decision nodes and  number of generations .
in our experiments  we used an initial population of 1  each having a depth of not more than four component net rules  and allowed to evolve to a depth of not more than 1. the evolutionary process would proceed until the classification accuracy and size of the fittest individual were unchanged for the last 1 generations. the weighting factor used in the fitness measure was set to 1. to further simplify the best evolved neulonet  a set of eight most commonly used simplification rules were applied recursively to identify component net rules for elimination or recombination. results for evolving the best neulonet solution from an average of 1 runs using the set of net rules versus using standard boolean logic are presented in table 1.
1	classification accuracy
in terms of the classification accuracy  neulonet evolution provided a comparable  if not better  result than standard logic evolution in all cases. this was especially true for data sets having an ordered logic reasoning as in the case of the shuttle landing domain problem  or when the classification rules encompassed a  quantification  of standard boolean logic. for example  in the monk-1 data set  the classification rule is given by  thrun et al.  1  as follows: exactly two of
clearly  it would be difficult to achieve a high classification accuracy using only a composition of standard boolean logic units. however  in the case of neulonet evolution  the expressive power inherent in the set of net rules allowed for a more accurate solution tree to be evolved.
1	solution size
due to the neulonet's ability to handle more complex decisions  net rule evolution provided more compact solutions than their standard boolean counterparts for the same classification accuracy  particularly for data sets having non-trivial classification rules. using the best evolution runs for both empirical approaches in the monk-1 data set  the profiles for the number of decision nodes is shown in figure 1 for accuracies between 1% to 1%. observe that the profiles for both approaches are comparable in the case of classification accuracies of less than 1%  indicating that the classification rule learned thus far was still relatively simple. however  as the required accuracy increased  the apparent power of neulonets in deriving complex decision rules resulted in a significantly smaller solution size.

1 1 1 1
accuracy  % 
figure 1: profile for the number of decision nodes during net rule solid-line  versus standard boolean logic dotted-line  evolution.
1	number of generations required
a general drawback in net rule evolution was the longer time needed to converge to an ideal solution due to the larger size of the component net rule library. it has to be noted that the experiment conducted actually gave the standard logic an advantage in that the rule set is small  only negation and 1or 1-arity conjunctions and disjunctions   while the population sizes in both neulonet and standard logic evolution approaches were kept the same at 1 individuals. as a result  there were more opportunities for the small set of standard logic rules to quickly evolve to ideal individuals within the population. thus for problems involving simpler decisions  standard logic evolution attained the required accuracy faster. however  there were cases in which neulonet evolution was faster. this was observed from the accuracy profile for the monk-1 data set in figure 1.

1
1 1 1 1 1
generation
figure 1: accuracy profile for net rule solid-line  versus standard boolean logic dotted-line  evolution.
　for accuracies of less than 1%  standard logic evolution required slightly less generations. however  as the demand in accuracy increased  it became increasingly difficult to evolve a solution using only standard logic rules. the added advantage in expressing complex rules during neulonet evolution  on the other hand  produced a faster rate of convergence.
1	conclusion
genetic programming proves to be an interesting paradigm in constructing neulonets with the prescribed human logic net rules. the paradigm is also amenable to refinement training. a knowledge engineer could start by constructing neulonets based on the human expert's prior knowledge. the constructed neulonets may then be subjected to the genetic programming evolutionary process. thus step 1 of the genetic programming solution  i.e. generation of an initial random population  may be skipped and instead  the process will start from step 1 onwards.
　this new mode of neural logic network learning  whether learning from scratch or learning by refining the existing network  preserves the logic semantics understandable for general human decision making. the size of the net rule library determines the granularity of the decision steps and the processing time. a large library enhances the capability in expressing nuances among different decisions but at the expense of a longer time to converge.
　further experiments will be carried out to investigate this trade-off issue. variants of crossover and mutation processes  and fitness measures will also be studied. a long term plan in future is to apply genetic programming on fuzzy neural logic networks  teh  1 . for such networks  the values for input and output ordered pairs are real-valued between 1 and 1. genetic programming will thus be an attempt to evolve the best fuzzy decision rules. we envision an even more exciting horizon of fuzzy neulonet learning with genetic programming.
references
 angeline  1  peter j. angeline. genetic programming and emergent intelligence  in kinnear  k.e  ed.  1. advances in genetic programming. cambridge  mass.: mit press  1.
 armstrong and thomas  1  william w. armstrong and monroe m. thomas. adaptive logic networks. in the handbook of neural computation  fieseler  e. and beale e.  eds.  institute of physics publishing and oxford university press usa.
 blake and merz  1  catherine l. blake and c. j. merz. uci repository of machine learning databases. http://www.ics.uci.edu/ mlearn/mlrepository.html irvine  ca: university of california  department of information and computer science.
 gallant  1  stephen i. gallant. extracting rules from neural networks. in neural network learning and expert systems  chapter 1  1.
 gaudet  1  vincent c. gaudet. genetic programming of logic-based neural networks. in genetic algorithms for pattern recognition  pal  s.k. and wang  p.p.  eds.  boca raton: crc press  1.
 golubski and feuring  1  wolfgang golubski and thomas feuring. evolving neural network structures by means of genetic programming. in genetic progamming: proceedings of the second european workshop  eurogp'1  ricardo poli  et al  eds.  springer-verlag lecture notes in computer science  vol. 1  1.
 keith and martin  1  mike j. keith and martin c. martin. genetic programming in c++: implementation issues  in kinnear  k.e. ed.  1. advances in genetic programming. cambridge  mass.: mit press  1.
 koza  1  john r. koza. genetic programming: on the programming of computers by means of natural selection. mit press  cambridge  1.
 levenick  1  james r levenick. inserting introns improves genetic algorithm success rate: taking a cue from biology. in proceedings of the fourth international conference on genetic algorithms  belew  r.k; and booker  l.b.  eds.  san mateo  ca: morgan kaufmann publishers inc.  1.
 liu and motoda  1  huan liu and hiroshi motoda. feature selection for knowledge discovery and data mining. the kluwer international series in engineering and computer science  vol. 1  1  kluwer academic publishers  boston.
 michie  1  donald michie. the fifth generation's unbridged gap. in the universal turing machine: a halfcentury survey  rolf herken  ed.   1  oxford university press.
 niwa and iba  1  tatsuya niwa and hitoshi iba. distributed genetic programming: empirical study and analysis. in genetic programming : proceedings of the first annual conference 1  edited by john  r. koza et al.  1. cambridge  mass. : mit press.
 setiono and liu  1  rudy setiono and huan liu. symbolic representation of neural networks  computer  1   1.
 tan  1  ah hwee tan. cascade artmap: integrating neural computation and symbolic knowledge processing  ieee transactions on neural networks  1 : 1- 1.
 tan et al.  1  chew lim tan  tong seng quah  and hoon heng teh. an artificial neural network that models human decision making  computer  1   1.
 teh  1  hoon heng teh. neural logic network  a new class of neural networks called neural logic networks  singapore: world scientific.
 thrun et al.  1  sebastian thrun  et al. the monk's problems: a performance comparison of different learning algorithms. technical report cmu-cs-1  carnegie mellon university  pittsburgh  pa.
 towell and shavlik  1  geoffrey g. towell and jude w. shavlik. extracting refined rules from knowledge-based neural networks  machine learning  1   1.
sensitivity analysis of multilayer perceptron*
daniel s. yeung  xuequan sun  and xiaoqin zeng
department of computing  the hong kong polytechnic universityabstract
sensitivity analysis of neural network is useful for network design. pich└ used a stochastic model to describe the multilayer perceptron  mlp   but it doesn't match the true mlp closely  and too severe limitations are imposed on both input and weight perturbations. this paper attempts to generalize pich└'s stochastic model of mlp  and derive an universal expression of mlp's sensitivity for all sigmoidal activation functions  without any restriction on input and output perturbations. the effects of network design parameters such as the number of layer  the number of neuron per layer and the chosen activation function are analyzed  and they provide useful information for network design decision-making. furthermore  we use our sensitivity expression to design mlp for a given application. it can help to design the network structure  as well as the training of mlp.
1 introduction
the sensitivity analysis of neural network has been investigated for over 1 years. in 1  hoff used ndimensional geometry approach to analyze the sensitivity of adaline  hoff  1 . glanz  simplified hoff's results. after two decades  winter  derived an analytical expression for the probability of error in madaline caused by weight perturbation. stevenson continued winter's work  and established the sensitivity of madaline to weight error in 1  stevension  1a; stevension et al.  1b . cheng and yeung  use this geometrical arguments to analyze the sensitivity of neocognitrons. however  the their results are only fit for neurons with threshold activation function and binary inputs  and they are not applicable to other continuous activation functions. yeung and wang  try to apply the method proposed in  cheng and yeung  1  to the sensitivity analysis of the mlp. earlier in 1  choi and choi  present a thorough idea of sensitivity analysis of the mlp with differentiable activation functions. although their analysis is systematic  the result is only applicable when the network has been trained and the inputs are known  so it cannot be used for network design and construction.
　pich└  1  uses statistical approach to relate the output error and the change of weights in madaline with several activation functions such as linear  sigmoid and threshold. but pich└'s stochastic model is a simplification of the true mlp  and his result holds true only when the input and weight perturbations are small enough.
　this paper proposes an improved stochastic model which is better suited for the true mlp. we also present a function approximation method to derive an universal analytical expression of sensitivity for mlp with sigmoidal activation function. we assume no restriction on the amplitude of the input and weight perturbations. using this function approximation method  one can use three parameters to characterize the activation function. so not only the effects of input and weight perturbations  the number of neuron and the number of layer  but also that of the activation function on the sensitivity of mlp can be analyzed by the universal analytical expression.
1 the improved stochastic model of mlp
according to pich└'s stochastic model  all neurons have the same activation function. all network inputs  weights  input perturbations and weight perturbations are respectively independent identically distributed random  iidr  variables with zero mean; inputs and input errors  inputs and weight errors  weights and inputs  weights and weight errors are statistically independent from each other. this model has the following weaknesses:
1. the bias input is omitted. this is a basic component of
mlp;
1. the expectations of all network inputs are zeros. many applications don't satisfy this condition;
1. all network inputs have the same variance. it is also difficult for many applications to satisfy this requirement;
* this research work is supported by a hong kong polytechnic university    research grant number g-s1 and a hong kong cerg number 1e1. the correlations between the inputs and their corresponding perturbations are not considered. even if the inputs and their associative perturbations in the first layer are independent  there still exist correlations between the inputs and their corresponding perturbations in the successive layers of mlp.
　our improved stochastic model of mlp overcomes the above shortcomings in the following ways:
1. all network inputs are independent random variables with their own expectations and variances. the
expectation of the bias input is 1  and its variance is 1;
1. all input perturbations are independent random variables with zero mean and their own variances. the variance of the bias input perturbation is 1. the correlations between network inputs and their corresponding perturbations are expressed by their correlation coefficients;
1. all weights and their perturbations are independent random variables with zero mean and their own variances. the correlations between weights and weight perturbations are also expressed by their correlation coefficients;
1. except the correlations between inputs and input perturbations  weights and weight perturbations  all variables are independent from each other.
our model is a better description of the true mlp.
1 definitions
　first  some notations are introduced. the layers are indexed from 1 to l. the 1 layer is the input layer  and the lth layer is the output layer. the number of nodes in layer l is denoted by n l . the function g    denotes the activation function. neuron is the basic element of mlp  so one can first investigate the sensitivity of a single neuron  and then the whole mlp.
　suppose x l    x l are the input and input perturbation vectors of neuron i in layer l  wil    wil are its weight and weight perturbation vectors. d .  denotes the variance.
　definition 1: the absolute sensitivity of the neuron to input and weight perturbations is given by
sil .
　definition 1: the relative sensitivity of the neuron to input and weight perturbations is
	rel.sil def=	d g  wil +  wild t g   wx llt+  xxl   l      g wilt   x l    .
i
　since the outputs of mlp are the outputs of the neurons in the output layer  we can use the output neurons to represent the outputs of the mlp.
　definition 1: the absolute sensitivity of mlp to input and weight perturbations is
def
s =  s1l   s1l     snll  t .
　definition 1: the relative sensitivity of mlp to input and weight perturbations is
def
rel.s =  rel.s1l rel.s1l   rel.snll  t .
1 function approximation approach
if the sensitivity is directly calculated by using the above definitions  it will be very difficult to obtain an analytical expression for the sensitivity unless we restrict the amplitudes of the input and weight perturbations. but this would severely limit the range of application of our sensitivity analysis. so a function approximation approach is proposed to overcome this problem. this is based on the idea that a given class of activation functions can be characterized by a general function expression using a set of common characteristics  i.e.  parameters of this expression  which should satisfy the followings:
1  they can be used to approximate the activation function concerned  and
1  they should have the form convenient for sensitivity computation.
　the threshold and sigmoidal activation functions are commonly used for the mlps. it can be characterized by three factors: its maximum value  minimum value and obliquity  which are denoted by b  c and a respectively  different values of b  c and a represent different activation functions. the main idea of the function approximation approach is to use another function g a b c  x  to approximate g x  . the function g a b c  x  has the following form
　　　　b + c	 	 1  ga b c  x  =	+ f a b c  x  1
where
　　　　   b  1 c  1  e ax1   	x − 1 	 1  f a b c  x  =     b   c  	e ax1   	x   1
1 
	 	1
　the objective of function approximation is to determine the three factors a  b and c of g x    so that the distance between the two functions g x  and g a b c  x  is minimized.
the factors b and c are determined by
b = lim g x   	 1 
x★+±
c = lim g x  .	 1 
x★ ±
　the factor a can be found by solving the following problem
min 1 
a
　because g x  and g a b c  x  are antisymmetric about a certain point on the y-axis  problem  1  is equivalent to
+±
	min	〈 g x    g a b c  x   1 dx .	 1 
a
1
the commonly used sigmoidal activation function has the
　　　　　b + ce λx   we have a = πλ1 . form g x  = 1+ e λx 1
1 sensitivity of a single neuron
　according to the definitions of absolute and relative sensitivity  we need first derive the variances of the output and the output error of a neuron. the output of the unit j in layer l is
	yil = g wilt   x l  .	 1 
its output error is
　　 wilt   x l   .  1  the covariances between inputs and input perturbations  weights and weight perturbations are σxli xi = ρxli xiσxliσ l xi andσwl ij wij = ρwl ij wijσwl ijσ l wij   whereρ denotes the correlation coefficient.
　let σ1 and μ represent variance and expectation. we have
e wilt   x l   = e  wilt   x l +wilt   x l +  wilt   x l   = 1  1 
n l 1
d wil t   	 1 
j
d  wilt   x l +wilt   x l +  wilt   x l    	 1 
n l 1
1
	j=1	wij  	.  1 
n l 1
+‘ 1σxl   x σwl	  w +1σxl   x σ l w 1 +1σ l x 1σwl	  w  +σ l w	1
j
p
	v ' =  wilt   x l +wilt   x l +  wilt    x l .	 1 

σp
according to the lindeberg central limit theorem  when
n l 1 is large enough  u and v' are normally distributed with mean 1 and variance 1  i.e.  u ~ n  1  and v ~ n  1 . the correlation coefficient between u and v is
nl 1
l 1l
wijwi1  wi1
ρu v' = j=1	. 1 
σrσp
let  ρ
	v =	u  v '	u +	1	v'  
	1  ρu1  v '	1  ρ'u1  v '
we get v ~ n 1   and ρu  v = 1.
we introduce two notations 1 α=σr +σpρu  v '   1 　　　　　　　　β =σp	1  ρu1  v ' . then 1 wilt   x l =σru   1  wil +  wil  t   x l +  x l   =αu + βv . 1 　the distribution function of u  and the joint distribution function of u and v may be expressed as
　　　　1	 1  	 1  fu  u  =	e f  u v  =	e 1 u1+v1   .	 1 
now  the expectations of output and output error are
1
	e	e	du  	 1 
eedudv 1 
the variances of output and output error are
1
	d	e	du  	 1 
dedudv. 1 
　using our function approximation approach and the following polar coordinate transformation
	  u = r cos θ	 	 1 
  r − 1 θ （  1π 
  v = r sin θ
formulae  1    1    1  and  1  become
eyil == b + c   1 1 e yil = 1   1  arctg
l
i
     
	1t	 1 
+
　for each neuron in a given layer  its inputs and the associated errors are just the outputs and their associated errors of the former layer. so ylj 1 = xlj    y lj 1 =  xlj . now the covariance between ylj 1 and  y lj 1 can be calculated by
li+1 i =σlyi yi =  b   c 1 qil  	 1 
　all formulae are derived exactly except the approximation of the activation function. so there is no need for us to restrict the input and weight perturbations to be very small. the network sensitivity expressions are expressed in terms of a  b and c  i.e.  the activation function itself. this enables us to investigate the effect of a given activation function on the network sensitivity.
1  sensitivity of mlp
since the sensitivity of a mlp is defined to be the sensitivity vector of its output neurons  it will be necessary to calculate the sensitivity of neurons from the input layer to the output layer successively.
　the algorithm to calculate the sensitivity of the network is given by
1  based on the application requirement  determine the expectations and variances of network inputs
	1 1
	μxi  σxi   input perturbation ratios 	1xi1   the
σxi
correlation coefficients between inputs and input perturbations ρx1i xi   the variances of weights σwl ij 1  
1
	weight perturbation ratios wij	 and the correlation
σwl ij 1
coefficients between weights and weight perturbations
ρwl ij wij ;
1  using function approximation approach to determine a  b and c of the activation function;
1  let l=1  σxl 1 =σx1   σ l x 1 =σ 1x ;
1  for all neurons in layer l  calculate σlyi 1 and σ l yi 1 by applying formulae  1  and  1   and then σlyi yi   by formula  1 ;
1  if 	l l  	let 	l = l +1  σxli 1 =σly i 1   σ l xi 1 =σ l y1i 1  
σxli xi =σyl i 1yi   then goto step  1 ; else
1  calculate sil and rel.sil by formulae  1  and  1   then the absolute and relative sensitivities of mlp is
s =  s1l  s1l    s nll  t  rel.s =  rel.s1l  rel.s1l    rel.s nll  t   and the program is terminated.
1 effects of parameters on sensitivity
many factors affect the sensitivity of the mlp. these factors include the network inputs and input perturbations  weights and weight perturbations  and network architecture parameters such as the number of layer  the number of neurons in each layer and the activation function chosen. how these factors affect the sensitivity of mlp is an important criteria for neural network design in support of a particular application.
　the experimental results are shown in figures 1 to 1. the main results are:
1  the input and weight perturbation ratios are the two most important factors affecting the sensitivity of the mlp. the absolute and relative sensitivities increase when these two ratios do.
1  the network sensitivities increase with the absolute value of the input expectation and the input variance. the normalization of network input can help us decrease the network sensitivity;
1  the increase of weight variance causes the network sensitivity to increase. so we should limit the amplitude of the weight in training process;
1  when the number of neurons increases  the absolute and relative sensitivities increase  but when it is significantly large  the two sensitivities will nearly remain constant. the neuron number of later layers has more influence upon the absolute sensitivity than that of the previous layer.
1  the absolute and relative sensitivities increase with the number of layer. when the number of layer is small  these two sensitivities increase rapidly. otherwise they become flat. when the weight perturbation ratio increases  the absolute and relative sensitivities increase as well  i.e.  if the sensitivity is supposed to be less than a certain value  the number of layer could be small when the weight perturbation ratio is large.
1  the larger the obliquity a of the activation function is  the more sensitive the mlp is. the sensitivities increase with b-c. so the threshold mlp is the most sensitive one  and the activation function 1 
1+ e x
more suitable than tanh x .

figure 1: the relative sensitivity of mlp versus the number of neurons in each layer.

neuron versus obliquity a of the activation function.	the max and min value of the activation function.

figure 1: the relative sensitivity of a neuron versus the max and min value of the activation function.
figure 1: the absolute sensitivity figure 1: the relative sensitivity of of mlp versus the number of layer. mlp versus the number of layer.

1  the design of mlp
　in order to simplify the network design  we suppose that all weights have the same variances  and all weight perturbation ratios are identical. so all neurons in the same layer have the same sensitivity. we can use a output neuron's sensitivity to represent the network sensitivity vector.
　for a given application  suppose parameters l  b and c are determined by the network designer  from the sample set and the application environment  we can estimate the
1
following parameters: n1   n l   μx1i   σx1i 1   ρx1i   xi   	1xi1  
σxi
ρw  w   	1w . our goal is to find the unknown parameters σw
n1  ...  n l 1   a and σw1   such that sr   sr*   where sr* is a given  acceptable relative sensitivity.
　our solution is: first select a possible range for each of the unknown parameters; then using our sensitivity calculation algorithm to compute the mapping from {n1   n l 1  a σw1 } to {sr}; finally  according to the mapping  determine the region {n1   n l 1  a σw1 } that satisfies sr   sr* .
　we present the following example to show how to design a three-layer mlp.
　example: the input and output numbers are 1  and all inputs are independent random variables that are uniformly distributed over  -1 . suppose the correlation coefficient between weights and weight perturbations are 1. construct a three-layer mlp with input and weight perturbation ratios less than 1%  and the relative sensitivity of this mlp should be less than 1%.
for this example  the known parameters are l=1 
n 1 = n 1 = 1  μx1i = 1  σx1i 1 = 1   ρx1i   xi = 1 
ρw  w = 1  σ 1xi1 = σw1w = 1 sr* = 1. suppose b=1 
σxi
c=1  and the possible ranges for parameters a  n1 and σw1 are  1   1    1   1  and  1   1  respectively. using our sensitivity algorithm to calculate the mapping over the above ranges. here  we plot two contour maps of sr . when the obliquity a is large and small  the contour lines of sr with respect to n1 and σw are shown in figures 1 and 1 respectively. the region below the contour line at sr = 1 is our design result.
　our sensitivity analysis can be used to determine the network structure numerically. furthermore  it can estimate the permitted weight range for network training. we find that the larger n1 is  the smaller the maximum permitted weight variance is. that is to say  if we select larger number of neurons in the hidden layer  we must restrict the weight variance to be less in the training of mlp; when the obliquity of activation function increases  the solution region reduces. this means that if we select activation function with smaller obliquity  we can permit larger number of neurons in the hidden layer and larger weight variance in the network training.

	n1	n1
figure 1: the contour plot of relative figure 1: the contour plot of relative sensitivity of three-layer mlp with sensitivity of three-layer mlp with respect to n1 and σw . a=1. respect to n1 and σw . a=1.
1 conclusion
in this paper an improved stochastic model of mlp is proposed to better describe the  and the function approximation method is used to obtain an universal expression of the network sensitivity for sigmoidal activation functions. we use the expression of sensitivity to investigate the effects of network parameters on the network sensitivity. it is also used to design the network architecture and provide useful guideline for the network training.
