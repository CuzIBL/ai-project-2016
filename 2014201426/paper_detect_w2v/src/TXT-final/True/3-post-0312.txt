 
sentiment analysis is an example of polarity learning. most research on learning to identify sentiment ignores  neutral  examples and instead performs training and testing using only examples of significant polarity. we show that it is crucial to use neutral examples in learning polarity for a variety of reasons and show how neutral examples help us obtain superior classification results in two sentiment analysis test-beds.  
 
many machine-learning problems involve predicting an example's polarity: is it  significantly  greater than or less than some standard. one canonical example of learning polarity is sentiment analysis  the determination of whether a particular text expresses positive or negative sentiment regarding some issue.  
　the problem of how to exploit a labeled corpus to learn models for sentiment analysis has attracted a good deal of interest in recent years  dave et al 1  pang et al 1  shanahan et al 1 . one common characteristic of almost all this work has been the tendency to define the task as a two-category problem: positive versus negative. in almost all actual polarity problems  including sentiment analysis  there are  however  three categories that must be distinguished: positive  negative and neutral. not every comment on a product or experience expresses purely positive or negative sentiment. some - in many cases  most - comments might report objective facts without expressing any sentiment  while others might express mixed or conflicting sentiment. 
　researchers are aware  of course  of the existence of neutral documents. the rationale for ignoring them has been a reliance on two tacit assumptions: 
  solving the binary positive vs. negative problem automatically solves the three-category problem since neutral documents will simply lie near the boundary of the binary model 
  there is less to learn from neutral documents than from documents with clearly defined sentiment 
　the purpose of this paper is to show that there is no basis for either of those myths and that neutrals can be exploited in interesting ways to great effect. 
　we consider two labeled corpora. the first consists of 1 posts to chat groups devoted to popular u.s. television shows. the second consists of about 1 posts to shopping.com's product evaluation pages. both are equally distributed among positive  negative and neutral documents. 
　is it in fact the case that neutral documents lie near the boundary of a learned model that distinguishes positive and negative examples  to test this  we trained a linear svm on all positive and negative documents in the tv corpus. in figure 1  we show the signed distance from the boundary of the positive and negative training examples  in ascending order from left to right.  this svm correctly classifies 1% of the training examples.  in addition  we show the signed distance from the boundary of all neutral examples. there is no band near the boundary in which the preponderance of examples is neutral. we indicate the band around the boundary that is optimal in terms of overall classification accuracy  positive  negative  or neutral  when all examples in the band are classed as neutral. even using this optimal band  we attain accuracy of only 1%.  note that simply using the svm boundary to distinguish positive from negative and not classifying any examples as neutral would yield accuracy of 1%.  

figure 1 distance from boundary in the tv shows corpus 
 
similar results are obtained for the second dataset. 
　what happens when we try to solve the three-class problem using positive  negative and neutral training documents  five-fold cross-validation experiments using weka's implementation of multi-class svm yields accuracy of 1% for the tv corpus and 1% for the shopping.com corpus. interestingly  we will see that these results are far inferior to results obtainable by making even stronger use of neutral documents. 
　consider the algorithm used in this experiment for extending a binary algorithm to handle multiple classes  namely  pairwise coupling. in this approach  a model is learned for each pair of classes  positive-negative  positiveneutral  negative-neutral  and these models are then combined. weka's implementation  witten and frank 1  of the  hastie and tibshirani 1  algorithm treats the three constituent pairwise problems identically. that is  no allowance is made for the particular relationships that positive  negative and neutral examples stand in to each other.  
　the main point of this paper is that it is crucial to take these special relationships into account. we begin by running the following experiment. for each of the pairs  negative-positive  negative-neutral  and positive-neutral  we ran five-fold cross-validation experiments. for each example  we recorded how it was classed in the holdout set in each of the three experiments. 
　table 1 shows the actual class distribution of examples in the tv corpus assigned to each of the eight possible outcomes.  
 
pos vs neg pos vs neut neut vs neg original category neg neut pos neg neut neg 1 1   neg neut neut 1 1 1 neg pos neg   1   neg pos neut   1 1 pos neut neg 1 1   pos neut neut 1 1 1 pos pos neg   1  pos pos neut   1  1 table 1: class distribution of examples per pairwise outcomes in tv corpus 
 
　as can easily be computed from the table  the accuracies of the pairwise models in five-fold cross-validation trials on their respective category pairs are: positive-negative  1%; positive-neutral  1%; negative-neutral  1%. we want to parlay these pairwise models into the best possible threeclass model. to do this  let us define a stack  wolpert 1  as a mapping from each of the eight possible outcomes to some class. let an optimal stack be the mapping from each of the eight possible outcomes to the majority class of the examples with that outcome.  savicky and furnkranz 1  have considered when such optimal stacks  determined using holdout data  might permit optimal use of pairwise coupling. 
　for a given example  let's use the shorthand class1   class1 to mean that the learned model of class1 vs. class1 classed the example as class1. the optimal stack for this data can be neatly summarized as follows: 
  if positive   neutral   negative then class=positive 
  if negative   neutral   positive then class=negative   else class=neutral 
　this simple stack yields accuracy of 1% on the threeclass problem  which is significantly better than multi-class svm  and better than any of the constituent two-class problems .  
　what is most astonishing about this table is the following: when  according to our model for positive vs. neutral  a test example is classified as positive  it is not necessarily positive  but we can assert with certainty that it is not negative  despite not a single negative example being used in training.  likewise  when  according to our model for negative vs. neutral  a test example is classified as negative  it is not necessarily negative  but we can assert with certainty that it is not positive  despite not a single positive example being used in training.  
　an analogous  though not identical  principle holds in the shopping.com corpus. 
　these results strongly suggest that polarity problems be attacked by stacking results of pairwise coupling in nonstandard ways  taking full advantage of neutral examples. 
