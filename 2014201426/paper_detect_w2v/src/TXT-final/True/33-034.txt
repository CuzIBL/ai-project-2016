 
in planning a proof  a student searches through a space of inferences leading forward from the givens of the problem and backward from the to-be-proven statement. one dimension of growth of expertise is that students become more tuned in the search of this problem space. this can be shown to result from the application of various learning operators to production embodiments of the inference rules. rules are evaluated after the solution of a problem according to whether they led to or led away from the solution. rules that contributed to a solution are strengthened and an attempt is made to formulate general versions of these rules that will apply in other situations. rules that led away from the solution are weakened and a discrimination process is evoked to try to add features to the rules that will try to restrict them to the correct circumstances of application. composition is a learning process that collapses successful sequences of rule operations into single macro-rule productions. there is also a process that converts the backward reasoning rules formed by composition into forward reasoning rules. the effect of these learning processes is to put into production conditions tests for problem features that are heunstically predictive of the rule's success. 
introduction 
　i have been involved in research  anderson  greeno  kline  &. neves  1; neves & anderson  1  to characterize the organization of various proof skills possessed by high school students in geometry and to identify how these proof skills are acquired. in this paper i will concentrate on the skill involved in planning a proof to a geometry problem and  in particular  how the search for such a plan improves with practice. the direct goal in this research is to provide an accurate psychological model of bow high school students learn to do geometry problems by doing geometry problems. a perhapsnot-incidental by-product is a set of ideas for how learning mechanisms might be used to guide problem-solving. all this research is done in the context of a general production system simulation of human cognition called act. 

organization of the task and the skill 
　the planning process we are trying to model is how students find a sequence of legal deductions that allow them to derive a to-be-proven statement from the givens. figure 1 illustrates a triangle congruence problem which is simple but nonetheless is challenging for the just beginning student. it is taken from the textbook we have been studying  jurgensen  donnelly  maier  & rising  1 . figure 1 illustrates the attempt of one of our subjects to solve this problem. first he tried to use the sss method which worked on the p r e v i o u s h o w e v e r   he noted that there seemed no way to g e t a n d turned to side-angle-side. he immediately saw would provide one side and  another side. he had a little difficulty seeing the included angle. his protocol at the critical point  after identifying the two congruent segments  reads  but where would /l and  1 are right angles come in . . . oh  1 see how they work.  this evidence  consistent with the rest of the protocol  shows that he did not see that right angles implied angle congruence until he needed angle congruence for the sas postulate. at this point his plan was complete. he had some difficulty converting it into a legal two column proof  e.g.  remembering that the reason that justified  was called the  reflexive property of congruence   but there was no more planning in his protocol. 
　figure 1 illustrates in simple form the backward search that is typical of novices in geometry and other domains  larkin  mcdermott  simon  & simon  1 . our simulation program plans in part by generating such a planning tree. in this tree there are disjunctions of methods to accomplish a goal  e.g  either sss or sas to prove triangle congruence  and each method can break down into a conjunction of subgoals  i.e.. two sides and an included angle . novices and our simulation  with a novice knowledge base  tend to search such a proof tree in a depth-first manner. 
　in more experienced students one sees forward inference from the givens. for instance  in problem 1 a student with some experience would likely recognize that  are congruent before he had consciously chosen the side-angle-side method. potentially  geometry problems could be solved by pure forward search  but many potential forward inferences  eg.  those authorized by the reflexive rule  would be wasted. optimal 
1 

performance will arise from a mixture of forward and backward search. figure 1 gives a problem that nicely illustrates the trade-off between forward and backward search. the majority of the subjects we have looked at in solving this problem  all at some intermediate level of skill  first reasoned forward to the inference that m d without knowing how they would use the fact. then they worked backward to a proof plan that involved this forward inference. our simulation at one setting did the same  see anderson et al  1 for details . 

figure 1 
it has been documented in other domains such as physics 
 larkin. mcdermott. simon. & simon. 1  that the proportion of backward search decreases and the proportion of forward search increases with expertise. in our simulation the 
amount of forward inference depends on the existence of production rules that will make the forward inferences  on their strength  and whether various tests on their applicability are met. it is typical of our simulation that it will generate some set of forward inferences and then settle into a backward reasoning mode to complete the proof plan. this also seems typical of students who frequently starts off marking some set of forward inferences on the diagram. forward inferences tend to precede backward inferences in our simulation because they require less coordination and can therefore be more quickly executed. 
   it is clear that either in forward or backward inference mode  there is a serious search problem for students. in forward inference mode one wants to only make those inferences that will play an essential role in the final proof. in backward inference mode one wants to pursue only those methods that lead to success. neither our students nor the simulation are always successful in their search. however  it seems clear that one dimension of expertise is the ability to make more judicious decisions about the paths to search. the main focus of this paper is how that expertise is gained.  if the reader would like a problem likely to create the experience of search for his level of expertise. i suggest he consider solving the problem in figure 1.  
   the central theses of our work on geometry is that there are certain features of a problem that are predictive of the success of a particular inference path and that the student learns the correlations  through proving problems . some correlations between problem features and inference rules are logically determined. so. for instance  a student will learn that if he is trying to prove two triangles congruent and they both involve right angles  it is likely that he should try a right angle postulate. other correlations between problem features and inference rules reflect more about biases in problem construction than say logical necessity. so. for instance  a student learns that if he sees a triangle that looks as if it is isosceles  it is likely that he will want to prove that it is isosceles. whatever the reason for the correlation between features and inference methods  the student can use these 

   it is the character of heuristics that they should not always work and that it is possible to create problems that will violate these heuristics and which will  as a consequence  create difficulties. figure 1 illustrates such a problem which occurred in the textbook we were using. the problem appears as an exercise immediately after the section that presents the hypotenuse-leg postulate for right-angle triangles. the majority of the subjects we have given this problem to report reasoning from the fact that  are complementary to the fact that  is a right angle. then they can apply the hypotenuseleg theorem. however  a simpler proof exists by simply noting the two triangles share  and then applying the side-angle-side proof. however  subjects are led by various heuristics such as  1  problems tend to use the postulates introduced in the section;  1  if right-angles are mentioned and it is a triangle congruence problem  use a right-angle postulate;  1  use all the givens in a problem. students are generally not instructed as to such heuristics; they have picked them up by example. 

figure 1 
learning mechanisms 
   i will discuss six methods for using the experience of past problems to improve search on current problems. we have worked on each method in our computer simulation and have reason for believing that each is found in high school students. the first  analogy to prior problems  is somewhat distinct from the rest and will therefore be treated separately. the other five are principles concerned with extracting general and reliable rules from examples. they are the principles of rule evaluation  generalization  discrimination  composition  and forward inference formation  these last five make critical use of the production system architecture in which the simulation is 

1 

implemented. 	the first  analogy  does not. 
analogy 
　despite the fact that its role is somewhat singular in our theory  our protocols are rich in evidence of successful problem-solving by analogy and many more less than successful attempts to use analogy. in the theory  analogy involves two processes. first  there is the noticing of the similarity between the specifications of a current problem and the specifications of a previous problem. second  an attempt is made to map the solution of the previous similar problem to the current problem. the first process in our protocol is sufficiently rapid that it cannot be decomposed into substeps. a student will typically simply announce after reading the problem-- this is similar to problem x.  we have not been able to identify any instances where this problem x occurred any earlier than in the previous days lesson. so. there appears to be important memory limitations to the range of similarity noticing in analogy process. 
　we have implemented a partial graph matching process to model this similarity noticing. this partial matching process is also used in our work on generalization. the basic idea is an attempt to identify subgraphs on which the problems overlap. an early version of this is described in anderson  kline  and 
beasley  1  	1  and a more advanced version by kline 
 1 . the ideas are variations on techniques suggested by hayes-roth and mcdermott  1  and vere  1 . 
　such a similarity detection mechanism is very much influenced by how the problems are represented. consider fihure 1. in terms of many features such as shape and orientation  problems  a  and  c  are more similar than  a  and  b . however  it turns out that the more profitable similarities exist between  a  and  b . many of the unsuccessful attempts to use' analogy in our protocols can be accounted for by subjects being distracted by such superficial similarities. 

   in contrast to the rapid similarity-detection  the efforts to map a proof from one problem to another are quite long and definitely analyzable into substeps. it seems that the student has transformed his initial problem space into a new problem space of finding the mapping. we have not in our simulation work modelled this mapping process systematically. figure 1 illustrates one of the more striking examples of failure of the mapping. the student noted the similarity between the two  b  

figure 1 
problems and proceeded to copy the proof to one problem over to the other. the first line for part  a  read ro = ny so analogously he wrote afi   cd for part  b . the second line for part  a  read on = on so analogously he wrote bc   bc for part  b ! his semantic sensibilities detected the problem: he abandoned the attempt to use the analogy  and proceeded to solve part  b  on its own. 
　while these two examples illustrate analogy by showing how it can fail  it is clear that it succeeds more often than not. one major problem with it is that it does not provide any permanent benefit as seen by the fact that all analogies are to problems encountered in the current or previous day. it may be that formulating analogies causes more permanent operators to be formed. the generalization process that will be described could apply after solution by analogy although solution by analogy is not a pre-requisite to generalization. 

other more elaborate production embodiments of these rules are also possible. the simulation keeps a record of the rules it applied in working on a problem. by comparing this record with tlie final proof plan it can determine which choices of proof method in working backwards were successful and which were mistakes.. a little care is required here: suppose a goal is set to prove two angles congruent by showing they are corresponding parts of congruent triangles. suppose all methods tried for proving congruent triangles fail and the angle congruence is eventually proven by resorting to supplementary angle postulate. the mistake is not in the methods attempted for proving the triangles congruent rather the mistake was in setting the subgoal of triangle congruence. forward inferences can be classified as successful if they figure in the final proof 
and as mistaken otherwise. 
　success and error classifications are used by the learning mechanisms to be described shortly  but they are also used to simply strengthen or weaken the rules responsible for the decisions. the mechanisms for strengthening and weakening a 
1 
production and the impact of production strength on conflict resolution has been described elsewhere  anderson. kline. & beasley. 1   however  it is important to note that disastrous results will not occur if a bad rule is formulated since the strength evaluation mechanism will separate out successful from unsuccessful rules and eventually only the former will be selected in conflict resolution. this means that we do not have to be concerned that the learning mechanisms always be correct in the production rules they formulate. 
generalization 
　generalization attempts to extract common features of two instances and successfully apply the same inference method. this is done by testing for similarity between the problem descriptions before the rule of inference applies. consider contain one or two congruent pieces--not a specific side and angle. a more general production such as this could derive from the one above by further generalization  with appropriate 
representational assumptions  . 
1. 	in both cases  the initial 
1    although students do have these general rules without a doubt: it is unclear that they emerge by the generalization mcchams/m suggested above. as an alternative  they might derive by a retrospective analysis of a single problem rather than a generalization between two. our protocol data cannot inform us on this issue and we are tooling up to do the right kinds of controlled experiments. work on extraction of object categories  anderson & kline  1; fho & anderson. 1  has provided good evidence for a generalization process in that domain. 

　as in the case of generalization  the fact is indisputable that subjects form discriminations on their original rules. indeed  one subject articulated a rule essentially identical to p1 after the history illustrated in figure 1. however  again as in the case of generalization  what is unclear is whether these discriminations are achieved by the mechanisms described here. again  that issue awaits more detailed experimental research. 
composition 
the variables in this production have been named to correspond to the terms in figure 1 for purposes of readability. this production would immediately recognize the solution to a problem like that in figure 1. this composition is achieved basically by adding together the conditions of the five original productions and making them the condition of the composed production; adding together the actions and making these the action of the composed production  editing out the unnecessary or redundant clauses in the composed production. 

of 
     with collapsing 
the 
of 
these two same for 
it 
the system 
the 
working-
1 


figure 1 
are enough tests in the non-goal aspects of its condition to make it quite likely that the inferences will be useful. that is. it is unlikely to be an accident that the conjunction of tests arc satisfied. 

there is clear evidence for such a forward inference rule in some more advanced students. for them  the pattern in figure 1 is something that will trigger the set of inferences even when it appears embedded in a larger problem. however  we have poor evidence on what the exact origins are of this forward inference rule. 
final points 
　there are two major issues that need to be pursued. one. as noted throughout the paper  is the detailed empirical verification of these mechanisms. the second is a sufficiency proof of their operation by simulating a student's course through a textbook. while we have worked up individual examples of successful tuning by these learning mechanisms  we have not done the large scale simulation to show that their cumulative effect after hundreds of problems will match the degree of tuning we see in the typical student. we intend to pursue this and i am reasonably optimistic given that we have achieved success with such large-scale simulations of our learning mechanisms in the domain of concept formation  anderson & kline. 1  and syntax acquisition  anderson. 1 . 
