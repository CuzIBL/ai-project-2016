 
we study how an autonomous robot can attain a cognitive process that accounts for its symbolic manipulation of acquired knowledge without generating fatal gaps from the reality. the paper focuses on two essential problems; one is the symbol grounding problem and the other is how the internal symbolic processes can be situated with respect to the behavioral contexts. we investigate these problems by applying a dynamical system's approach to the robot navigation problem. our formulation  based on a forward modeling scheme using recurrent neural learning  shows that the robot is capable of learning grammatical structure hidden in the geometry of the workspace from the local sensory inputs through its navigational experiences. furthermore  the robot is capable of mentally simulating its own action plans using the acquired forward model. our assertion is that the internal representation obtained is grounded  since it is self-organized solely through interaction with the physical world. we also show that structural stability arises in the interaction between the neural dynamics and the environmental dynamics  which accounts for the situatedness of the internal symbolic process. 
1 	introduction 
the recent successes of behavior-based robotics  brooks  
1; maes  1  have led to an underestimation of the necessity of internal representation. the behavior-based robots are characterized by their direct sensory-motor maps  through which they can react rapidly to the dynamical environment. although the resultant reactivetype behavior of these robots can be quite complex depending on the adopted environment  the emergence of such complex behavior does not necessarily account for all aspects of intelligence. we consider that some intelligent activity should involve deliberative internal computation rather than merely reactive interaction between the environmental and the internal systems. an intelligent robot should be capable of mentally simulating 
1 	action and perception 
its own potential action plans through manipulating the knowledge of its internal model in a flexible way  before choosing a course of action. such internal computation should maintain certain combinatorial powers especially when the acquired knowledge contains grammatical complexity. we consider that the deliberative thinking paradigm of the traditional ai itself is not misleading. however  the paradigm faces two essential problems. one is the  symbol grounding problem  as harnad  harnad  1  has discussed  namely  how can the semantic interpretation of a formal symbol system be made intrinsic to the system  rather than just parasitic on the meanings in our heads  '' the other is how the symbolic process can be situated to the current context that is determined solely from the history of interacting with the environment. this paper discusses our novel approaches to address the above issues  in which we have used a mobile robot as an experimental platform. 
　conventionally  the problem of mobile robot navigation has been approached in rather straightforward manner. a global representation formula is employed: a robot builds an environmental map  represented in global coordinates  by gathering geometrical information as it travels  elfes  1; freyberger et a/.  1 . although a variety of methodologies has been proposed in this context  potential problems still remain  especially in robot localization. the localization is not always robust enough in the noisy environments of the real-world since there exist gaps between the knowledge of the global map and the information provided by the local sensory inputs. 
　kuipers  kuipers  1   mataric  mataric  1   and others have developed an alternative approach based on landmark detection. in this approach  the robot acquires a graph-type representation of landmark types. this representation is equivalent to a finite state machine  fsm   as a topological modeling of the environment. in navigation  the robot can identify its topological position by anticipating the landmark types in the fsm representation. although this scheme enables the robot to acquire grammatical knowledge of the obstacle environment by a local representation scheme  its stability is not clear in circumstances where incorrect landmark matching happens to take place. a fsm would halt if fed an illegal symbol. this navigation strategy is susceptible to such a crash if the landmark type is misread. 
although robustness can be enhanced through improving the landmark detection scheme by combining  for example  global positioning  as conducted in ref. mataric  1   or other sensor-fusion techniques  it would remain limited as long as the model is represented symbolically. 
　the above discussion has demonstrated that approaches using global maps or fsm cannot provide representation intrinsic to the robot. in this paper  we focus on the dynamical system's approach  beer  1; jordan  1  as an alternative  with the expectation that its language can be utilized to build an effective representational and computational framework for behavior-based robots. it is known from the theory of symbolic dynamics  crutchfield  1  that some classes of dynamical systems  for example chaos and fractals can provide combinatorial and linguistic power. therefore  there is the possibility that knowledge  which requires its own grammatical handling  could be represented as being embedded into such intrinsic dynamical functions. another characteristic  which we can take advantage of  is the phenomenon of entrainment that takes place between different dynamical systems which are coupled together. we will show that the internal symbolic process is naturally situated to the system's context by means of entrainment of the internal dynamics from the environment  through its interaction with the physical world. 
1 	navigation problem 
we consider how a mobile robot learns to navigate in an unstructured environment under the following conditions: 
  the robot cannot access its global position  but it must navigate based on its local sensory  range image  input. 
  there are no explicit landmarks accessible to the robot in the adopted workspace. 
  no apriori knowledge of the workspace geometry is given. 
previously  we have formulated the skill-based learning of navigation  tani and fukumura  1a; 1b . this scheme aims to ensure that a robot will acquire skills  a state-action map  for a fixed navigational task  such as homing or cyclic routing  under the supervision of a trainer. the current paper presents the formulation of model-based learning. the benefit of this type of learning is that the process of planning with the internal model enables the robot to adapt flexibly to different goal tasks. the specific application  shown later in this paper  is that after the learning process  the robot mentally simulates its action plans using the acquired model i.e. it conducts lookahead predictions of future sensory input for arbitrary motor programs. 
1 	architecture 
the yamabico mobile robot  lida and yuta  1  was used as an experimental platform  see figure 1 . we briefly review the navigation architecture  tani and fukumura  1b; 1a . yamabico can obtain the range image by a laser range finder in real-time. the ccd cameras 
laser projector 
figure 1: the yamabico mobile robot equipped with a laser range sensor. 
ranges for 1 directions  covering a 1 degree arc in front of the robot  are measured every 1 milli seconds by triangulation. the robot maneuvers by differentiating the rotation velocity of the left and right wheels  and it normally moves with a speed of 1 m/s. 
　in our formulation  maneuvering commands are generated as the output of a composite system consisting of two levels. the control level generates a collisionfree  smooth trajectory using a variant of the potential method  khatib  1   while the navigation level directs the control level in a macroscopic sense  responding to the sequential branching that appears in the sensory flows. the navigation level can be adapted through learning; the control level  on the other hand  is fixed. 
　firstly  let us describe the control level. the robot can sense the forward range readings of the surrounding environment in robot-centered polar coordinates given by rz l   i   n . the angular range profile rt is obtained by smoothing the original range readings through applying an appropriate gaussian filter. the maneuvering focus of the robot is a local peak  the angular direction of the largest range  in this range profile. the robot proceeds towards a particular potential hill  an open space in the environment  by targeting its peak with a constant control gain. this control scheme is implemented as follows: 
	vdif 	= 	kp.1f 	 1  
where vdif is the differential rotational velocity between the left and right wheels  of is the angular displacement of the focus point from the center  and kp is a constant gain. 
　the navigation level focuses on the topological changes in the range profile as the robot moves. as the robot moves through a given workspace  the profile gradually changes until another local peak appears when the robot reaches a branching point. at this moment of branching the navigation level decides whether to transfer the focus to the new local maximum or to remain with the current one. this is the essential point of our architecture. the navigation level functions only at branching point that appears in unconstructed environment. therefore the navigation decisions are made 
	tani 	1 

on the topological trajectory that is determined by the dynamics of collision-free maneuvering applied to the environment. 
　the navigation level makes decisions for each branch by utilizing the sensory input at that moment. two types of sensory inputs are used  one is the range image and the other is the local travel distance measured from the previous branch to the current one. the range image is compressed by the vector quantization technique known as the kohonen network  kohonen  1 . the n-dimensional vector  describing the range profile r at each branching sequential time n  is fed into the network  and the resultant mapping into an output vector pn of fewer dimensions / is obtained. more details of this application of the kohonen's net should refer to  tani and fukumura  1b . hereafter  all discussion focuses on the schemes for the navigational level  and we will describe  branching decisions  simply as  motor commands'' . 
　in the actual implementation  the robot sometimes drops into a concave dead end from which the robot cannot escape with its current maneuvering scheme. in this terminal point  the robot turns through 1 degrees and receives sensory inputs  then starts again. 
1 model-based learning 
our main concern is how a robot can acquire the internal model as an intrinsic function which enables the mental simulation of its own actions in the obstacle environment. here  we attempt to apply the scheme of forward modeling  jordan  1  to the problem. 
1 	forward modeling 
the objective is to build a forward model through which a robot can conduct lookahead prediction of the sensory input sequence  as the distal output  as a result of the given motor program  of the proximal input  in branching sequence.  hereafter  the term  motor program  denotes a sequence of motor commands.  the objective forward model is embodied using a standard discrete time rnn architecture  as shown in figure 1. the mapping function of the rnn can be written as; 
		 1  
where fc and fp are the nonlinear maps from the current branching step to the next branching step  and wc and wp denote parameter sets of connective weights. this rnn architecture receives the current sensory input pn  the current motor command xn  then outputs the prediction of the next sensory input pn+1- we employ the idea of the context loop  elman  1  which enables the network to obtain a certain temporal internal representation.  in figure 1  there is a feedback loop from the context units in the output layer to those in the input layer.  the current context input cn  a vector  is a copy of the context output in the previous time: by this means the context units remember the previous internal state. the navigation problem is an example of a so-called  hidden state problem   lin and mitchell  
1 	action and perception 

1 : a given sensory input does not always represent a unique situation/position of the robot. therefore  the current situation/position is identifiable  not by the current sensory input  but by the memory of the sensorymotor sequence stored during travel. adequate temporal internal representation of the travel history  by taking advantage of the context loop  can achieve just such a memory structure. 
　the forward model is acquired in the learning phase; the robot travels around the workspace with sampling the sensory-motor sequence in the branching  then the network is trained as off-line by using back-propagation through time algorithm  r.umelhart et a/.  1 . the learning succeds when it can extract certain grammatical structures from the sampled sensory-motor sequences. 
　after the learning phase is completed  the robot is operated in the so-called open-loop mode: the robot travels in the workspace by an arbitrary motor program while conducting the one-step lookahead prediction  predicts next sensory input as the result of the current motor command . the rnn predicts the next sensory input pn+1 inputting the current sensory input pn and the current motor command xn to the network. the rnn  in the beginning of the travel  cannot predict the next sensory input correctly since the initial context value is set randomly. however  the context value can get situated as the rnn continues to receive the sensory-motor 
sequence during the travel  then the rnn begins to predict correctly. 
after the robot is situated to the environment  the 
rnn can be switched into the closed-loop mode with stopping the robot at a branch point. now  a lookahead prediction of an arbitrary length for a given motor program can be made by copying the previous prediction of the sensory input to the current sensory input.  as indicated by a dotted line in figure 1  the closed-loop for the sensory input is made.  let us denote the motor program as x*. then the lookahead prediction of the sensory input sequence p* can be obtained by recursively applying x* to the rnn mapping function  with using the initial values of context units c1 and the sen-

sory input p   which have been obtained in the open-loop mode. 
1 	situatedness by entrainment 
this sub-section investigates the mechanism of situatedness by focusing on the coupling between the internal neural dynamics and the environmental dynamics. 
　first  we will define the term  attractor  for both of the environmental and the internal dynamics. let us consider the environmental dynamics f. we consider an infinite length of randomly generated binary sequences  the motor program x*  to be fed into the robot. let s* be the resultant state transitions of the environmen-
tal state in the branching sequence. the environmental state s can be represented by the robot's position  including the orientation  upon branching. in the ideal case with no noise in the environment  the infinite travel of the robot forms an invariant set **  since the trajectory of the robot is limited to be in a subspace of the entire workspace after an initial transient period. we define this invariant set as the attractor of f with respect to the excitatory input x*. also  we define an invariant set p* for the sequence of the .sensory input  which s * corresponds to. it is important to note that this attractor is the global attractor  since the robot's travel starting from any position in the workspace results in the same invariant set. for the neural dynamics /  let us consider a lookahead prediction of the rnn with respect  to a motor program x* of an infinite length which is randomly generated. this generates an infinite sequence of the transitions of the context c*. when this infinite sequence forms an invariant set  this invariant set c* is defined as the attractor of /. the sensory sequence which corresponds to c* is indicated as p*. depending on the learning process  the generation of the global attractor is not assured for /. since the objective of learning is to make the neural dynamics / to emulate the environmental dynamics f by means of the sequence of the sensory input  / in the limit of a learning process satisfies  for an arbitrary motor program x*  that: 
		 1  
the idea here is that there is  at least  one attractor for 
/ by which the lookahead prediction of the sensory input can be made correctly  as satisfying  1 . now let us consider the coupling of these two dynamics. in the openloop mode  the rnn predicts the next sensory inputs pn+1 using the current sensory inputs pn while the robot travels following the motor program x*. this coupling is schematically shown in figure 1. in this coupling  it is conjectured that two sequences p* and p* converge into the same sequence for all the initial states of .s1 and c1 if / has been formed as global attractor dynamics. this implies that the internal dynamics  with arbitrary setting of the initial state  always become coherent with the environmental dynamics and predict the sensory inputs correctly  as long as the internal model is embedded in the global attractor dynamics. 
　this feature of the entrainment of the internal dynamics by the environmental one assures an inherent robustness of the robot's behavior against temporal perturbations. the robot  during its travel  could lose its context 

if perturbed by noise. the robot  however  can get situated again by means of the entrainment as long as it continues to interact with the environment. 
1 experiment 
we conducted experiments on the scheme presented above using the mobile robot yamadico. the robot learns the forward model through trial and error. the robot samples the data of the sensory-motor sequence while it wanders around the adopted workspace for a certain period  then it learns the forward model of the navigation level using the data obtained off-line. after learning  the capability of lookahead predictions is statistically measured in order to examine how the robot learns the internal model. if its knowledge is found to be insufficient  the above process of learning is repeated through sampling more data. 
1 	learning and look-ahead prediction 
learning was repeated for rounds with increasing number of the sampled data sets. the sampled data set was fed into the rnn for off-line learning for each round  in which the network was re-trained with randomly set weight values. the training of the rnn was conducted for 1 steps  which are repeated if the mean square learning error per unit output cannot be decreased below 1. the adopted rnn architecture is three-layered having 1  1 and 1 units for the input  hidden  and output layers respectively. it has four context units. after each round of learning  the test of a given lookahead prediction is conducted for different 1 travels. each travel starts from an arbitrary free space in the workspace. the robot travels using random branching with the rnn switched in the open-loop mode until the rnn becomes able to predict the next sensory input correctly. the 
	tani 	1 


robot is stopped when the prediction error  for all sensory input units  becomes less than 1 twice in succession. then  lookahead prediction is conducted  with the rnn switched in the closed-loop mode  for an arbitrary motor program which comprises seven steps branching. thereafter  the robot is directed by the motor program in order to test the lookahead prediction. after 1 travels  the mean square prediction error per sensory input unit  mspe  is calculated. 
　in the first round of the learning  the robot sampled 1 input data and learned them. in the test  it took long steps  often more than 1 steps  until the rnn in the open loop mode supplied good predictions. in the ensuing lookahead predictions in the closed loop mode  the rnn could hardly predict more than three steps ahead. it seemed that the rnn learned only particular instances of the sampled sequences but not in a more general way. in the second round with learning 1 input data  the steps to capture the context were shortened  and the lookahead prediction often went smoothly for several steps. however  once the prediction failed in the middle of the sequence  it continued to fail for subsequent steps. in the third round with learning 1 input data  it was observed that the context could be recovered within several steps  and also that lookahead predictions be-
1 	action and perception 
came accurate except in cases with certain noise effects. since the rnn could predict correctly for sequences it had never learned exactly  it can be said that the rnn succeeded in extracting the necessary rules in the form of generalized ones. an example of the comparison between a lookahead prediction and its sensory sequence during travel is shown in figure 1. in  a  an arrow denotes the branching point where the robot conducted a lookahead prediction of a motor program given by 1. the robot  after conducting the predictions  traveled following the motor program  generating the trajectory of a  figure of eight1'  as shown. in  b  the left side shows the sensory input sequence  while the right side shows those of the look-ahead  the motor program and its context values. the values are indicated by the bar heights. it can be seen that the look-ahead for the sensory inputs agrees very well with the actual values. we examined the distribution of the prediction error for a single unit in the third round. it was shown that the fraction of  good  predictions with an error of less than 1 is more than 1 percent. since the robot could capture the context and then achieve good lookahead prediction regardless of the initial setting of the position and the context values  it is assumed that the robot succeeded in learning the forward model as embedded into the global attractor dynamics  through trial and error. 
　in order to confirm the formation of the global attractor in the experiment  we conducted the phase space analysis for the internal dynamics of the rnn. the rnn  switched to the closed loop mode  was activated for two thousand forward steps using input sequences of random motor commands. the phase diagram was plotted as a two-dimensional projection using the activation state of two context units  excluding 1 points from the initial transient steps. fig. 1 a  shows the resulting phase diagram  while  b  shows an enlargement of part of  a  in which a one-dimensional structure is seen. we repeated this several times with different initial values of the internal states  and found that they all resulted in the same attractor structure. it confirmed that the internal dynamics are self-organized in the form of the global attractor dynamics. although any theory has not been established to explain the creation of low-dimensional global attractor in the recurrent neural learning  its tendency is suggested in other numerical experiments  pollack  1; tani and fukumura  in press . 
　we have stated that the global attractor provides an inherent robustness for context dependent navigation as a natural consequence of coupling between the internal and the environmental dynamical systems. the following experiment demonstrates an example of autorecovery from temporal perturbation. the robot traveled in the workspace while predicting the next sensory inputs with the rnn switched to the open-loop mode. during this travel  an additional obstacle was introduced. the upper part of figure 1 shows the trajectory of the robot's travel; the lower part shows the comparison of the actual sensory inputs and corresponding one-step lookahead prediction. the branching sequence number is indexed beside the trajectory; this number figure 1: attractor observed in the internal dynamics. 
corresponds to the prediction sequence in the lower part of figure. the prediction starts to be incorrect once the robot passes the second branching point  as it encounters the unexpected obstacle. the robot  however  continues to travel and meanwhile the obstacle is removed. after the sixth brandling point  as the lost context is recovered by means of the regular sensory feed  the prediction returns to the correct evaluation. it is noted that the values of the context units in this branch are almost the same as those of the first branch. this shows that the robot recognized its returning to the same branching point by capturing the context of the travel again. 
1 	symbol grounding process 
a primitive conceptualization of the symbol grounding process is conjectured as the result of our experiments. figure 1 illustrates the concept. as the robot travels around the workspace  clusters of the sensory inputs are collected in the sensory space arising from its branching sequences. meanwhile the dynamical mapping is selforganized in the internal state space such that it accounts for the transitions among the clusters of the collected sensory inputs. if different symbols are assigned to each cluster of sensory inputs and internal state values  the mental simulation process carried out by the internal dynamics might be equivalent to the symbolic process of manipulating a set of terminal and non-terminal symbols. the terminal symbols are defined in the sensory space and the non-terminal one in the internal state space. here  our primitive symbols are not in the arbitrary shape of usual symbol tokens  hamad  1   but 

in the nonarbitrary shape based on the physical interaction between the robot and the environment. 
　one might consider that such symbolic processes can be represented in the form of a fsm more easily. we  however  consider that the internal representations by a fsm are still  parasitic  since symbols are manipulated into an arbitrary shape regardless of their meaning in the physical world. a crucial gap exists between the actual physical systems defined in the metric space and their representation in the non-metric space  which makes the discussion of the structural stability of the whole system difficult. in contrast to this state of affairs  the representation in our scheme can be said to be intrinsic to the system since it is embedded in attractor dynamics which share the same metric space with the physical environment. in this meaning  the structural stability arises in the interaction between the internal and environmental systems  which accounts for the situatedncss of the internal symbolic process. therefore  those symbols which have been self-organized through interaction with the physical world are naturally grounded. 
1 	conclusion 
this paper has described how symbolic processes arc selforganized in the navigational learning of a mobile robot. our study  based on a dynamical system's approach  has shown that the forward modeling scheme based on rnn learning is capable of extracting grammatical structure hidden in the geometry of the workspace from navigational experience. the robot was capable of mentally simulating its own actions using the acquired forward model. we have shown that such mental process by the rnn can naturally be situated with respect to the behavioral contexts  provided that the forward model learned is that embedded on the global attractor. finally it is concluded that the dynamical system's approach enables the robot to construct its symbolic process as grounded to the physical world. 
