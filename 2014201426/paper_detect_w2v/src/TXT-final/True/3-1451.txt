
assuming human image classification decisions are based on estimating the degree of match between a small number of stored internal templates and certain regions of the input images  we present an algorithm which infers observers classification templates from their classification decisions on a set of test images. the problem is formulated as learning prototypes from labeled data under an adjustable  prototype-specific elliptical metric. the matrix of the elliptical metric indicates the pixels that the template responds to. the model was applied to human psychophysical data collected in a simple image classification experiment.
1 introduction
consider a psychophysical experiment in which subjects classify a set of images into two classes. the image classes are designed such that correct responses require that the subjects detect the presence of certain features in certain regions of the image. given the images  and the subjects' classification decisions  is it possible to infer the feature templates the subjects have developed and employed 
　this represents an inverse problem in perception  in which the goal is to invert a  direct  model for the subject's responses with the goal of deriving the perceptual features used by the subject. the idea of employing inverse problem techniques is certainly not new in vision research  although it has been initially applied to low-level vision phenomena  bertero et al.  1 . the psychological literature on the subject of inverting perceptual similarity data is dominated by research on multidimensional scaling methods  mds . metrical mds  shepard  1  is probably the oldest inversion method allowing the derivation of features from similarities. a neural net-based inversion method for extracting features from judgments of similarity is presented in  lee  1 . more recent work in this direction has addressed the derivation of features involved in higher-level perceptual phenomena  cutzu and tarr  1; cutzu  1 .
　the model for the subjects' decisions in the image classification task considered in this work is a generalized nearestneighbor  1-nn  classifier  presented in detail in section 1. each of the two image classes is represented by a small set of image templates  or prototypes. given an input image that must be classified  its degree of match to all templates from all classes is estimated  and its class is determined by the class of the best matching template. our goal is to infer the prototypes of each class from a set of images labeled by human subjects. therefore  we are seeking to invert the nearest neighbor problem. this particular inverse problem has received considerable attention in the machine learning community. a comprehensive  recent review of the field is given in  toussaint  1 . one large class of algorithms  hart's algorithm  hart  1  and its numerous subsequent improvements  selects prototypes from among the labeled data points  a restriction that cannot be applied to our problem due to the presence of pixel noise in the test images.
　our algorithm belongs to the so-called prototype generation methods  which creates prototypes at new locations in feature space. the first such algorithm   chang  1   repeatedly merged nearest neighboring points from the same class as long as the classification error rate did not increase.  bezdek et al.  1  and later  mollineda et al.  1  refined  chang  1  by recursively merging clusters based on geometrical criteria.
　the nearest neighbor rule has been generalized by the use of an adaptable metric  a technique also employed in this paper  albeit differently. in  hastie and tibshirani  1  the metric is locally adapted to the training point neighborhood surrounding the query point at the time of classification. in  friedman  1  also a flexible metric is used for distance calculation in a neighborhood around the query point. however the ideas of recursive partitioning are used in determining the neighborhood for the query point. in  ricci and avesani  1  a reduced set of prototypes is selected from the training examples and a different metric is associated with each of the selected prototypes. this varies from our approach in two ways. firstly  the authors in  ricci and avesani  1  select the prototypes essentially in a random manner. secondly  we select prototypes that in general do not coincide with the training data points;
　a work whose spirit is similar to the present paper is  xing et al.  1 : the authors discuss the problem of learning a global  that is  valid throughout feature space  elliptical metric for 1-nn classification from classification data. the metric is fitted to the subject data by solving a convex optimization problem.
1 a model for prototype-based image classification
perceptual considerations required the use of a prototypebased image classifier in which the various prototypes  the image templates   specialize  in various regions of the image  i.e.  a template pays more  attention  to some pixels than to others. this was modeled as follows. let x （rd be an input image and ck （rd one of the templates. this prototype is characterized by a positive  semi  definite matrix qk which modulates the distance  degree of match  between the template and the image:
	d ck x 1 =  x ck tqk x c .	 1 
the elliptical metric matrix qk specifies the combination of image pixels the template ck  specializes  in. in the special case where qk is diagonal  the distance above reduces to:
		 1 
where qk i i  − 1. the pixels i for which qk i i  = 1 are ignored by the template ck. this distance measure is termed elliptical. under the elliptic norm  the set of points  each point in pixel space represents an input image  that lie at equal distance to the prototype is no longer a hypersphere  as for the euclidean metric  but a hyper-ellipsoid of arbitrary shape and orientation. each template is characterized by a different ellipsoid. interestingly  by endowing each prototype with its own  elliptical metric  the resulting voronoi cells are not necessarily convex or even connected.
　an equivalent formulation is derived by using similarity  rather than distance  to prototype: a point is assigned to the most similar prototype. we define the similarity to prototype as the probability of the point  belonging  to the prototype and we associate a gaussian pdf with each prototype. the shape of the gaussian varies from prototype to prototype  playing the role of the metric matrix qk. the similarity of point i to prototype k is  therefore: sik = c . or  expressed in gaussian
pdf form:

where the covariance wk = q k 1. therefore  under the 1nn rule  point xi is assigned to the prototype whose gaussian is the largest at xi.
1 finding prototypes for elliptical-metric 1-nn classifiers
each of the n points xi （ rd  the images  is labeled class 1 or class 1. we seek class-1 and class-1 prototypes which correctly label the n points under the 1-nn rule using the elliptical-norm-based similarity measure in equation  1 . computing a prototype entails determining its location ck as well as its metric matrix qk.
our prototype finding algorithm is as follows:
1. start with two prototypes  derived by applying gaussian clusters  algorithm explained below  with two centers to the full data set. go to step 1.
1. at iteration step t there are kt prototypes. consider the points assigned to prototype k  k = 1 ... kt  by gaussian clusters. there are nk1 class 1 and nk1 class 1 such points  with nk = nk1 + nk1. if nk1   nk1  then the prototype is labeled 1  otherwise it is labeled 1. the points of the minority class are  therefore  misclassified by this prototype. the  impurity  of the prototype was defined as the misclassification rate: rk =
. if the impurity of prototype k is greater than some user-defined threshold g  rk   g  then prototype k is considered for being split into two prototypes  just like a node in a classification tree is split when too impure . the splitting is performed only if the splitting reduces the impurities in the two resulting clusters. if a node does get split  we obtain a class 1 and a class 1 prototype. these  child  prototypes are placed at the centers of mass of the nk1  respective nk1 points. due to splitting  at the end of this step there are kt+1 − kt prototypes.
if no prototypes are split  go to step 1  else go to step 1.
1. re-apply gaussian clusters to the data set  ignoring point labels. gaussian clusters is initialized with the kt+1 prototypes determined at step 1. go to step 1.
1. the algorithm also returns a global classification errorrate which measures the errors caused by using the prototypes for classification. this error rate is defined by the total number of minority class points at all prototypes. the prototypes are labeled according to the majority class at the prototype. thus  for each prototype a center  ck   a covariance matrix  wk   and a class label are returned.
　observations: i  the algorithm has as sole adjustable parameter the impurity threshold g. the number of prototypes of either class is determined automatically. ii  the class labels of the points are solely used in splitting decisions  and are irrelevant to the gaussian k-means algorithm. iii  note the similarity to classification and regression trees  cart .
　the gaussian clusters algorithm fits k gaussian clusters to input data set. the gaussian clusters algorithm is basically like k-means clustering except that each center also has a covariance matrix associated with it. so for every iteration of the gaussian clusters algorithm when the new centers are being estimated we also estimate the new covariance matrices. this covariance matrix distorts the attraction of each center along the different dimensions.
1 results: artificial data
we applied our prototype finding algorithm to several synthetic data sets  illustrated in figures 1. these synthetic data sets were generated in two dimensions  two pixel images   so that the structure of the point clouds are clearly visible.
　in experiment 1  figure 1  there were 1 points of class 1  blue  and 1 points of class 1  red . the class 1 points were arranged in a single vertical band and the class 1 points were shared by 1 vertical and 1 horizontal band. as expected three centers have been assigned to the three distinct point clouds based on the desired purity tolerance.

figure 1: left: training set: class 1 points are blue  dots  and class 1 points  red  circles . right: the algorithm has found three prototypes  whose centers are indicated by yellow circles. the green lines indicate the axes of the gaussians. the cyan/magenta points  if present  are misclassified.
　in experiment 1  figure 1  there were 1 points of class 1  blue  and 1 points of class 1  red . the points were arranged into two non-overlapping  non-concentric circles. as seen in the figure two prototypes were assigned  one to each circle. note that the prototype centers are at locations where there were no training examples.

figure 1: left: training set: class 1 points are blue  dots  and class 1 points  red  circles . right: the algorithm has found two prototypes  whose centers are indicated by yellow circles. the green lines indicate the axes of the gaussians. the cyan/magenta points  if present  are misclassified.
　in experiment 1  figure 1   there were 1 points of class 1  blue  and 1 points of class 1  red . both the classes were drawn from a gaussian distribution  with different means and standard deviations. notice the overlap of the two point clouds. in the results obtained from the algorithm  we can see that the points assigned to the class 1 prototype surround the class 1 cluster: this non-convexity is an effect of the elliptical norm in determining nearest-neighbors.
1 results: psychophysical experiment data
the prototype finding algorithm was applied to simulated data and also to human image classification data collected in a psychophysical experiment in which the subjects had to discriminate between two classes of visual patterns. the visual pattern discrimination task is illustrated in figure 1. in this task  the observer is shown a single white square corrupted

figure 1: left: training set: class 1 points are blue  dots  and class 1 points  red  circles . right: the algorithm has found two prototypes  whose centers are indicated by yellow circles. the green lines indicate the axes of the gaussians. the cyan/magenta points  if present  are misclassified.
by additive gaussian pixel noise at one of four possible locations. the location of the square is randomly chosen on each trial. two of the possible locations are above the fixation point and two are below the fixation point  with each location being equidistant from the central fixation point. noise is added to each pixel in each of the four locations  with each location divided into a 1〜1 grid of pixels. no noise is added to the regions in between the four square locations  and the fixation point remains on the screen throughout the experiment. the observers task is to indicate whether the white square signal appeared above or below fixation. the contrast of the white square is manipulated across trials according to a 1-down 1-up adaptive staircase procedure to place it at a level where performance is at approximately 1% correct. accuracy feedback is given in the format of a high or low beep.
　before collecting human subject data two simulations were performed using the above experimental setup. the two models simulated were the  exemplar  model and the  prototype  model. in an  exemplar  model the observers are assumed to use multiple noisy  templates  to form a representation for each category. each of these templates are compared to the input to reach a classification decision. the templates used in the  exemplar  model simulation were the ideal templates  the four signals shown in figure 1 . in a  prototype  model observers are assumed to use a single summary representation for each category. thus the templates used in the prototype model simulation were combined versions of the two signals within each category. this resulted in a 'top' prototype template composed of the two top squares and a 'bottom' prototype template composed of the two bottom squares. for each of these two models a simulation with 1 trials was performed.
　four human subjects were tested. for each subject  1 experimental trials were conducted. the staircase procedure was used to keep the performance rate for each subject pegged at around 1% correct.
　since each white square was 1〜1 pixels  the classification images viewed by the subjects were 1 〜 1 pixels  the center of the display was a constant gray-level . therefore  the algorithm learned prototypes in 1-dimensional space. the simplifying assumption was made that there were no percep-

figure 1: top: the four types of stimuli used in the experiments  presented without noise. top left and top right represent the class  above fixation   and the bottom left and right represent the class  below fixation . bottom: an actual test image used during the experiments. the correct response is 'bottom'  since the bottom right square is  slightly  brighter. note the large noise level.
tual interactions between the pixels  and therefore the covariance matrices associated with the prototypes were restricted to being diagonal. a diagonal covariance matrix has one entry per pixel  and can be interpreted as an image-sized mask that indicates which pixels the corresponding prototype pays attention  responds  to.
　the algorithm yielded the expected templates when applied to the simulation data. figure 1shows the templates obtained on running the algorithm on the  exemplar  model simulation. as expected the centers represent the four different stimuli. the masks shown alongside each center show the relative importance of each pixel for that template. the masks are actually the inverses of the diagonal values of the diagonal covariance matrices. a whiter pixel in the mask indicates that the template is more sensitive to that particular pixel. the masks are quite noisy but one can see that the pixels of the image that include the stimuli are considered more important by the mask. to show the relative importance of each of the four quadrants we also displayed the masks averaged over each of the four quadrants  figure 1 . in this figure the higher importance of the quadrant containing the stimulus is clearly visible.
　figure 1 shows the templates obtained on running the algorithm on the  prototype  model simulation. as expected the two centers represent the combination of the stimuli that form each class. the masks shown alongside each center show the relative importance of each pixel for that template. the masks are again quite noisy but one can see that the pixels of the image that do not include the stimuli are considered more important by the mask. to show the relative importance of each of the four quadrants we also displayed the masks averaged over each of the four quadrants  figure 1 . in this figure the higher importance of the quadrants not containing the stimulus is clearly visible.
　the difference in the behavior of the mask across the  exemplar  and  prototype  simulations is interesting. in the case of the  prototype  simulation it seems that the classification into top  class 1  is made by the presence of darker pixels in both the bottom quadrants and vice versa.
　the algorithm yielded interesting results on the human subjects. three subjects  subjects 1 and 1  appeared to have used four centers  one for each corner square  and thus two per class  as can be seen in figures 1  1  1. the masks obtained for the subject data show that the pixels considered most important do not seem to follow any particular pattern. also the difference in importance across pixels is very small. this seems to lead to the conclusion that the human subjects based their decision on the entire image rather than on a particular quadrant.
　interestingly  subject two appears to have used two centers  one per class  figure 1 . the two centers correspond to the two top and bottom corners taken together. note that in no actual stimulus both corner squares are  on  simultaneously. this would correspond  in the language of the psychology of categorization  to a so-called  prototype model   while the other three subjects operated using an  exemplar model . the masks in this case are more distinct and like in the  prototype  simulation show a stronger response for the pixels in which the stimulus is absent. this can intuitively be explained by noting that for example in class 'top' no input image actually contains a stimulus in both the 'top left' and the 'top right' quadrant. however for class 'top' both the bottom quadrants can be expected to have a lower contrast value  because the stimulus is absent in the lower two quadrants. a similar intuition can be applied to the 'bottom' class.
	# 1  class 1	mask	# 1  class 1	mask

	# 1  class 1	mask	# 1  class 1	mask

figure 1: templates obtained: the 1  exemplar  centers and corresponding masks obtained by running our algorithm on the data generated by running an  exemplar  model simulation.
1 discussion
we introduced a prototype generating method for nearestneighbor classification. each prototype is endowed with its own elliptical metric  and our method is therefore related to adaptive metric methods such as  hastie and tibshirani 
	# 1  class 1	mask# 1	# 1  class 1	mask# 1

	# 1  class 1	mask# 1	# 1  class 1	mask# 1

figure 1: templates obtained: the 1  exemplar  centers and corresponding masks obtained by running our algorithm on the data generated by running an  exemplar  model simulation. the masks are averaged over each of the four quadrants to give an idea of the overall importance of each quadrant in the classification.
	# 1  class 1	mask

figure 1: templates obtained: the 1  prototype  centers and corresponding masks obtained by running our algorithm on the data generated by running a  prototype  model simulation.
1  and especially  xing et al.  1 . the prototypes are not a subset of the data points  and therefore our method belongs in the prototype generation category. however  as opposed to chang's method and its later refinements   bezdek et al.  1    mollineda et al.  1   we find new prototypes by recursively splitting clusters  rather than by aggregating them.
　the main contribution of this paper lies in the application of the prototype learning algorithm to understanding human image classification. if an image classification experiment is designed such that correct classification decisions require the detection of one of several class-specific features in certain regions of the image  then nearest-neighbor is an appropriate classification model. in the experiment described in this paper  class 1 was defined by the presence of feature a  top
	# 1  class 1	mask# 1

figure 1: templates obtained: the 1  prototype  centers and corresponding masks obtained by running our algorithm on the data generated by running a  prototype  model simulation. the masks are averaged over each of the four quadrants to give an idea of the overall importance of each quadrant in the classification.
	# 1  class 1	mask	# 1  class 1	mask

	# 1  class 1	mask	# 1  class 1	mask

figure 1: templates obtained: the 1  exemplar  centers and corresponding masks obtained for subject 1 by running our algorithm on the subjects classification data.
left  or feature b  top right  and class 1 by the presence of feature c  bottom left  or feature d  bottom right . any image contains only one of the four features  and  moreover  each feature occupies a specific image region. the algorithm correctly identified the regions of the image each prototype  specializes  in.
　in this situation  there are two equally effective decision strategies available to a nearest-neighbor classifier: 1. store two prototypes per class  one for each of the features a  b  c  d; or  1. store one prototype per class  one for the composite feature  a or b  and one for the composite feature  c or d . the first strategy corresponds  in the terminology of the psychology of categorization  to categorization by exemplar  and the second  to categorization by prototype. most interestingly  our algorithm revealed that one of the subjects employed the second strategy  and the other three the first. it
	# 1  class 1	mask

figure 1: templates obtained: the 1  prototype  centers and corresponding masks obtained for subject 1 by running our algorithm on the subjects classification data.
	# 1  class 1	mask	# 1  class 1	mask

	# 1  class 1	mask	# 1  class 1	mask

figure 1: templates obtained: the 1  exemplar  centers and corresponding masks obtained for subject 1 by running our algorithm on the subjects classification data.
	# 1  class 1	mask	# 1  class 1	mask

	# 1  class 1	mask	# 1  class 1	mask

figure 1: templates obtained: the 1  exemplar  centers and corresponding masks obtained for subject 1 by running our algorithm on the subjects classification data.
is important to note that a conventional analysis of error rates would not be able to distinguish between the two strategies.
