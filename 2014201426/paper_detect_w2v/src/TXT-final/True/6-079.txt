 
minesweeper is a one-person game which looks deceptively easy to play  but where average human performance is far from optimal. playing the game requires logical  arithmetic and probabilistic reasoning based on spatial relationships on the board. simply checking a board state for consistency is an np-complete problem. given the difficulty of hand-crafting strategies to play this and other games  ai researchers have always been interested in automatically learning such strategies from experience. in this paper  we show that when integrating certain techniques into a general purpose learning system  mio   the resulting system is capable of inducing a minesweeper playing strategy that beats the winning rate of average human players. in addition  we discuss the necessary background knowledge  present experimental results demonstrating the gain obtained with our techniques and show the strategy learned for the game. 
1 introduction 
minesweeper is a popular one-player computer game written by robert donner ami curt johnson which was included in microsoft windows c  in 1. at the beginning of the game  the player is presented with apx q board containing pq tiles or squares which are all blank. hidden among the tiles are m mines distributed uniformly at random on the board. the task of the player is to uncover all the tiles which do not contain a mine. at each turn the player can select one of three actions  moves : to mark a tile as a mine; to unmark a tile; and to uncover a tile. in the last action  if the tile contains a mine  the player loses; otherwise  the number of mines around the tile is displayed. in the 1 x 1 board depicted in fig. 1 left  the number 1 located on the second row from top indicates that there is one and only one mine hidden among the eight blank neighbouring tiles. 
　although the simplicity of its rules makes minesweeper look deceptively easy  playing the game well is indeed challenging: a player requires logic and arithmetic reasoning to perform certain moves given the board state  and probabilistic reasoning to minimize the risk of uncovering a mine when 
stefan wrobel 
fraunhofer ais  sankt augustin and university bonn  germany 
	i 	
figure 1: left: available information on a board. right: seven tiles can be determined safe  s  and one a mine m  
a safe move cannot be done. given the difficulty of handcrafting playing strategies for this and other games  ai researchers have always been interested in the possibility of automatically learning such strategies from experience. however  with the exception of reinforcement learning  tesauro  1   most of the playing strategies and heuristics used in game playing programs are coded and tuned per hand instead of automatically learned. in this work  we use a general purpose ilp system  mio  to learn a playing strategy for minesweeper. multirelational learning or ilp consists in learning from examples usually within the framework provided by clausal logic. 
　the task of learning rules to deduce minesweeper moves proved itself to be an arduous test for current multirelational learning systems. in this paper  we describe how recent optimizations make possible for mio to discover a minesweeper playing strategy. experimental results obtained by playing minesweeper using this strategy show a better performance than that obtained on average by non-expert human players. 
　the remainder of this paper is organized as follows. the next section discusses the complexity of the game and describes the learning task. section 1 describes the background knowledge  the learning system and the new techniques used. section 1 shows our empirical results on the effectiveness of the learning techniques  the strategy obtained and its performance at game playing. related work is surveyed in section 1 and section 1 concludes. 
1 minesweeper 
1 	why is minesweeper interesting  
minesweeper has been shown to be np-complete by simulating boolean circuits as minesweeper positions  kaye  1 . kaye describes the minesweeper consistency problem as the problem of determining if there is some pattern of mines in the blank squares that give rise to the numbers seen in a given 

board partially filled with numbers and marked mines  and thus determining that the data given is consistent. 
　one realizes the complexity of the game by calculating an estimate for the size of its search space. consider an 1 x 1 board with m = 1 mines; in this case at the beginning of the game the player has pq = 1 tiles from which to choose a move  i.e.  a tile to uncover  and in the last move  assuming the player does not uncover a mine  there are 1 tiles from which to choose one. this leads to  possible move sequences to win a game. alternatively  one can calculate the probability of a random player winning a game. in the first move the probability that the random player chooses a tile which does not contain a mine is 1  and in the last move it has 1 chance to choose the only tile without a mine. 
then  the probability of a random player winning a game is and that is only for the easiest playing level! 
　another measure of the complexity of minesweeper is the number of games won on average by non-expert human players. to estimate the average human performance playing minesweeper  we carried out an informal study. in the study  eleven persons who have played minesweeper before were asked to play at least ten times in an 1 x 1 board with 1 mines. every participant was told to aim for accuracy rather than for speed. in this study  a person won on average 1% of the games with a standard deviation of 1%. 
1 	the learning task 
in minesweeper there are situations that can be  solved  with nontrivial reasoning. for example  consider fig. 1 left where the only available information about the board state are the numbers. after careful analysis one finds that the squares with an s  see fig. 1 right  do not contain a mine  the square with an m is a mine  and the state of the blank tiles cannot be determined if we do not know how many mines are hidden in the board. there are other minesweeper situations where the available information is not enough to identify a safe square or a mine  as in fig. 1  and the best option available to the player is to make an informed guess  i.e.  a guess that minimizes the risk of blowing up by uncovering a mine. 
　in this work  we consider the learning task in minesweeper to be the induction of rules to identify all the safe squares  and squares with a mine which can be deduced given a board state. for instance  we want the system to learn rules to classify all the blank tiles in fig. 1 either as safe or mine. 
1 	the learning tools 
in machine learning it is possible to choose between a propositional representation  in the form of attribute-value tuples  and a multirelational representation  in the form of logic predicates . a multirelational representation has the expressiveness required to describe the concepts involved when reasoning about minesweeper  and is thus more intuitive than the propositional one. for this reason we use multirelational learning for the learning task described above. usually a multirelational learning system takes as input background knowledge b  positive  e+  and negative  e~  examples of a target 
　　a safe square is a blank tile which given the current board state cannot contain a mine. 

concept such that  and has to find a clausal theory t which minimizes the classification error on future instances. next we describe the background knowledge and the system used. 
1 	background knowledge 
the background knowledge provides the system with information about the domain and is given in the form of logic predicates  facts and rules  or clauses . a predicate is described as  and  in our case  argi indicates the argument's type. the background knowledge provided to the learning system about minesweeper is shown in table 1. the predicates in the background knowledge were defined by trying to abstract the concepts used by humans when explaining their own minesweeper playing strategies. these concepts were obtained from the first author's minesweeper playing experience and from minesweeper pages on the web. 
　in the predicates listed in table 1  a td is a determined or uncovered tile  i.e.  a number 1... 1 is shown on the tile; a tv is an undetermined or blank tile; board is the board state given as a list of characters 1... 1  m  u; zone is a list of determined tiles  and set is a set of undetermined tiles together with the number of mines hidden among those tiles. in addition  each symbol preceding an argument denotes how that argument should be instantiated when calling the predicate   is an input argument and should be instantiated to a non-variable term; is an output argument and should be uninstantiated  and a indicates that the constant value of an output argument can appear in a rule. 

1 	learning 

predicate 
zoneoflnterest +tu  +board  -zone  
totalminesleft +board -int  allmineslnfringe +board  -set  description 
. returns in zone the tiles which are determined neighbours of tu and the determined tiles which share an undetermined neighbour with them  see fig. 1 center . returns how many mines remained to be marked. gives the set of tiles in the fringe1 where all the remaining mines are. sethasxmines -td  +board  +zone  -set  gives in set the undetermined neighbours of td  td is in zone   and the number of mines hidden among them  sec fig. 1 right . 
diffsethasxmines +setl  +set1  -set  ... returns in set all and only the tiles of setl which are not also in set1 and the number of mines hidden among the tiles in set. 
inset +tu  +set  is true when tu is a member of set. lengthset +set +int  	is true when set contains int tiles. 
minesinset +set -#int  	returns the number of mines hidden among the tiles in set. 
table 1: minesweeper background knowledge 

1 	the system 
mio is an example-driven covering system  see fig. 1  introduced by pena castillo and wrobel  1b  which uses a progol-like declaration language and  the same as progol  muggleton  1   lower bounds the search space with a most specific clause   also called bottom clause . this  is a maximally specific clause which entails  covers  a positive example e. mio performs a general-to-specific  top-down  ida*  korf  1  search to find a clause to add to the theory. in addition  mio selects stochastically the examples from which it learns  performs parallel search to increase the stability of the example-driven approach  and enforces type strictness. three other techniques arc implemented in mio to allow the learning of minesweeper rules: macro-operators  or macros  for short  to reduce the search space  greedy search with macros to speed up the learning process  and active learning to guide the exploration of the instance space. 
macros 
macros in multirclational learning  pena castillo and wrobel  1a  are a formal technique to reduce the hypothesis space explored by a covering system. a macro is a sequence of literals  chosen from the bottom clause  which is created based on provider-consumer relationships between the literals. a literal is a provider if it has output arguments  and it is a consumer if it receives as an input argument a variable provided by another literal in the bottom clause. pena and wrobel show that by adding macros instead of literals to a clause  the number of clauses evaluated by the system is significantly reduced. 
greedy search with macros 
in  pena castillo and wrobel  1a  macros are used with ida*. it is well known that greedy search explores on average less nodes than ida*; however  greedy search could miss a solution because it underestimates the importance of provider literals without discriminative power which are nonetheless necessary to introduce new variables  this is known as the myopia problem . since macros add several literals at once to a clause  they might reduce the myopia of greedy search allowing us to gain in efficiency without losing 
1 fringe refers to all the blank tiles with a determined neighbour. too much in effectiveness. we implement a greedy search with macros which consists of a lookahead step where all the macros are combined with each other and the best evaluated clauses arc selected. then if the selected clauses can be extended  refined  the system tries to combine these clauses with all the macros available and selects the best candidates. this last step is repeated until there is no clause which can be extended and the best candidates are returned. 
active inductive learning 
in the covering algorithm a clause is learned which covers  explains  some positive examples and none  or few  negative ones; however  in domains such as games and puzzles  thousands of examples are required to contain most of the possible game situations; on the other hand  considering thousands of examples when evaluating a rule slows down the learning process. thus  to improve the efficiency of the exploration of the instance space  active learning  cohn et al  1  is included in mio. 
　active inductive learning consists of the following steps. at the beginning  mio learns from few randomly drawn examples and when it has learned some clauses gives these clauses to an active learning server. the active learning server returns to mio counterexamples*. these counterexamples are selected from examples given by a random example generator  or random sampler . while mio iterates on the new examples received  the server tests the rules obtained against randomly drawn examples  discards all the rules below a userdefined accuracy value and collects new counterexamples. this validation step on the server side avoids overfitting1. these steps arc repeated until a user-defined maximum number of iterations is reached or no counterexample is found. 
　active inductive learning is similar in spirit to integrative windowing  furnkranz  1  with two main differences: in our approach random sampling is done dynamically and a client-server architecture is used which allows to treat testing and learning as separated processes. 
   1  a counterexample is a positive example not covered by a set of clauses t or a negative example covered by at least one clause in t. 
   1 overfitting refers to obtaining results with high classification error over new data despite null or almost null training error. 


figure 1: a rule learned by mio. left: is the highlighted tile safe  center: zoneoflntcrest corresponding to the highlighted tile. right: applying difference operations to the sets determined by the tiles inside a circle is concluded that the tile 1 is safe 

1 	empirical results 
1 improvements obtained with each technique 
experiments were carried out to determine the effects on the rules obtained and on the system efficiency  of macros  greedy search with macros  and active inductive learning. to produce the training examples  we randomly generate board configurations and take all blank tiles with at least one determined neighbour as examples. if the blank tile does not contain a mine is labeled as safe  otherwise it is labeled as mine. afterwards  contradictory examples are removed. in the experiments  the learning task was to learn rules to identify safe tiles. the rule to discover mines was learned using the best setting  i.e.  using active learning  macros and greedy search . 
　for the completeness of this work  we ran progol  muggleton and firth  1  and foil  quinlan and cameron-jones  1  on the same learning task as mio; however  we failed to make the systems learn correct rules about safe tiles. progol search was interrupted due to search limits implemented in the system  although the maximum stack depth and resolutions steps were set to 1 and 1  respectively   and foil pruned determined literals which are needed. this might imply that the optimizations included in mio are indeed necessary to learn a minesweeper playing strategy. table 1 shows the empirical results with four mio settings. 
　all the experiments with active learning were performed with the same seeds which means that the same training examples are generated by the random sampler and that mio selects the same examples to guide the search. for the experiments without active learning  we took five random samples from the set of examples used in the active learning experiments. the size of the sample is equal to the number of examples received by mio when performing active learning  1 positive and 1 negative examples . we carried out an extra experiment where mio was given the complete set of examples  1 positive and 1 negative  used by the active learning server to test mio's rules and select counterexamples; however  this experiment was stopped after mio ran for 1 days. to reduce the running time of the experiments  we set the maximum number of clauses explored per search to 1 clauses. 
　table 1 shows that each optimization added to mio reduces the average number of rules  nodes  explored per search and the number of times the search is interrupted because of the search limit. without active learning  overfitting occurs and erroneous rules are obtained. the performance of the rules obtained with ida*+m is worse than that of the ida* rules because mio with macros explores a larger part of the hypothesis space and thus the ida* + m setting overfits more the training data. however  if no limit in the maximum number of clauses explored per search is set  both settings  ida* and ida*+m  obtain the same riles. the running time of the fastest setting  al+gs+m  is 1hrs. 
1 	rules learned 
table 1 shows the rules with the highest winning rate which were obtained by using both al+gs+m and al+ida*+m. an extra rule was obtained with the latter setting; however  this extra rule does not improve the playing performance. one important feature of the rules learned by mio is that they can be applied independently of the size of the board and the number of mines. the rules vary in complexity. rule s-l and rule m-l correspond to the trivial situations where a determined tile needs k mines and k: mines are already marked  and where a determined tile needs k mines and it has a; blank neighbours  respectively. 
　on the other hand  rule s-1 can be seen as one of the most complex rules because it involves three determined tiles to deduce a safe tile. fig. 1 left shows a board state where rule s-1 is the only one which allows to identify a safe tile. the rule obtains the zoneoflntcrest corresponding to the undetermined tile considered  fig. 1 center . then by applying difference operations on the sets determined by three uncovered tiles from the zoneoflnterest  see fig. 1 right   the set    1  is obtained and thus it is deduced that tile 1 is safe. 
1 	game playing 
to evaluate the performance at game playing of each set of rules obtained  we used each set of rules as the playing strategy of an automatic minesweeper player and calculated the percentage of games won by the player in 1 random games  see table 1 . the playing conditions were the same as the ones presented to the human players; i.e.  at the beginning the player is presented with an empty 1 x 1 board with m = 1 mines and can uncover a mine in the first move. note that in most minesweeper implementations  one never hits a mine in the first move. 

1 	learning 


table 1: performance of various mio settings used to learn rules about safe tiles  al = active learning  gs = greedy search ida* = iterative deepening a*  m = macros  

table 1: minesweeper rules learned by mio 

let us analyze the performance of the best rule set  see 
table 1 . in 1 games  the player made 1 moves from which 1 where random guesses  1 used rule s-l  1 used rule s-1  1 used rule s-1  and 1 used rule m-l. 
　in addition  we examined the effect of adding probabilistic reasoning. in the experiment  we instructed the player using the rules shown in table 1 to select a tile which minimizes the probability that an undetermined tile tu is a mine when none of the rules can be applied. is equal to where is a determined neighbour of returns the number of mines needed by td and 
returns the number of blank neighbours of tj. every 
time the player has to guess  it selects the tile which minimizes . this player wins 1 of 1 random games. 
1 related work 
1 	minesweeper playing programs 
there are several minesweeper programs available on the web. these programs are not learning programs but playing programs where the authors have embedded their own game playing strategy. among these programs  john d. ramsdell's pgms is quite successful winning 1% of 1 random games in a 1 x 1 board with 1 mines. 
　pgms plays using the equation strategy based on finding approximate solutions to derived integer linear equations  and probabilities. as mentioned by ramsdell   pgms represents the information available on the board as a set of integer linear equations. associated with an undetermined tile is a variable x that has the value 1 if the tile hides a mine  or 1 otherwise. an equation is generated for each uncovered tile with an adjacent undetermined tile. each equation has the form   where 1 is a set of undetermined 
tiles  and c is the number of mines hidden among 1. to simplify notation  this equation is written as    since the total number of hidden mines is known  an additional equation simply equates this number with the sum of all of the undetermined tiles. 
　every time a tile t is determined safe or a mine  the board changes are propagated to all the equations containing t and a new equation for the undetermined neighbours of t is added. 
i n addition  i	f	a	r	e two equations such 
that so is a proper subset of   the equation so is added. to determine whether a tile is safe or a mine  
pgms iteratively applies the following rules until none are applicable1: 


　we were surprised to notice that although mio was only given general background knowledge about minesweeper  the rules it learned are similar to the rules programmed in pgms. for example  mio's rule s-l and rule s-1 correspond to the first and third rule in pgms  respectively; and mio's rule m-l is similar to pgms second rule. to compare pgms performance with the performance of mio's best playing strategy  we let our best player  i.e.  the player using the rules in table 1 and probabilities  play 1 random games in a 1 x 1 board with 1 mines. its winning rate is also 1%. 
1 	multinational learning for games 
other work has been done which applies ilp systems to learn heuristics or playing strategies for games. ramon et al.  used tilde  blocked and raedt  1  to learn a theory that predicts the value of a move in go. morales  applied the system pal to learn chess patterns for constructing chess playing strategies. nakano et al.  presented an approach to generate an evaluation function for shogi mating problems using ilp. 
1 	conclusions and future work 
in this paper we described how the use of new ilp techniques such as macros  greedy search with macros  and active inductive learning allow mio to learn a minesweeper playing strategy. this learning task proved itself to be a challenging testbed for general purpose multirelational learning systems. 
　the best rules obtained by mio win 1% of the games in a 1 x 1 board with 1 mines  while on average a non-expert human player wins 1% of the games. the performance of the playing program using these rules as playing strategy improves to 1% when adding the use of probabilities. 
　by examining the games played using mio's rules  we notice that there are still situations where the player guesses without need  i.e.  a sure move can be deduced . as future work  we want to use other ilp systems  e.g.  tilde   and other machine learning approaches to learn minesweeper playing strategies and compare their performance. 
acknowledgments 
we thank all the persons who participated as guinea pigs playing minesweeper  the anonymous reviewers for their comments  and oscar meruvia for proofreading. the second author was partially supported by dfg  german science foundation   projects wr1-1 and wr1-1. 
