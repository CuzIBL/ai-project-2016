 
　　　this paper describes the design of an algorithm which learns a class of theories in the limit in a sublanguage of a f i r s t order language. the languages chosen are richer than those handled previously - needing a more efficient search through the version space. the language is not i n i t i a l l y known to the system  but is learned together with the theory. 
	1 	introduction and background 
　　　the word  learning  w i l l be used here to mean  developing class descriptions from examples of the members of the class . the work described here is a continuation of a series of efforts  1 1   to simulate the kind of learning where the efficiency of the learned description increases with increase in knowledge. this needs the ability to use the name of one class in the description of another. such a process is often called  multilevel learning   since the where-
withal for the description grows from the i n i t i a l features of the language to include the names of previously learned concepts as well as names of internally generated concepts used as additional features. the concepts as well as the features can be relations as well as classes. the descriptions of relations can be learned using the same technique as is used in learning the descriptions of classes. 
　　　the formal basis for this work is the concept of  learning in the limit   developed by gold  as a model for learning languages and extended by shapiro  to the learning of theories from facts in f i r s t order logic . since the descriptions of classes can be looked upon as sets of horn clauses  shapiro's general technique is applicable to the learning of the descriptions of classes and relations. the technique does not need that the examples be presented to the learning mechanism by a helpful teacher  as was assumed by some of the authors mentioned here. 
　　　in this present work wo have used a more general language than those usod in shapiro's experiments. the language chosen here seems more suitable to the purpose of concept learning. certain improvements to the technique have been made for pruning the search for descriptions in the chosen language. also  unlike shapiro's work  it has not been assumed that the language is 
1 	knowledge acquisition 
available to the learning algorithm: the algorithm learns the language as it learns the descriptions. apart from this  the work follows shapiro's guidelines quite faithfully. 
　　　in what follows we shall assume acquaintance with shapiro's approach and describe our language and algorithm in brief. 
	ii 	the class of languages 
　　　in the f i r s t order languages used here for forming descriptions  there are variables  constants and unary function symbols. no binary or higher arity function symbols are used. an atomic sentence or atom consists of a term followed by an equals sign followed by a constant. a term is either a variable or a function symbol followed by a term enclosed in parentheses. a predicate is either an atom or consists of a predicate letter of arity n  followed by n terms separated by commas. such a predicate is called 
a
 defined predicate. 	if a l l the terms occuring in 
a defined predicate are variables  then the predicate is called a leftside. a sentence consists of a horn clause  whose head is a leftside and whose body contains predicates. 
　　　for the purposes of this work  some of the predicate letters are considered to be in a 
　　　special class: 	these are called concept letters. a leftside formed with a concept letter is called a definlend. 
　　　predicates formed by concept letters are the ones which name concepts to be learned. predicate letters other than concept letters can be generated internally by the learning algorithm to further simplify complex descriptions. these are what people often call  features  in pattern recognition parlance. the processes of  feature extraction  and compression w i l l be described in the section on algorithms. 
　　　sentences as described above form the hypothesis language l of shapiro. the observation language l consists of ground sentences  which are defined to be those whose head is a definiend and whose body consists entirely of atoms. 
　　　a theory w i l l be defined to be a set of sentences and the definition of proofs and the definition of a theory implying a sentence is 

standard. instead of defining the model of a theory by an abstract mathematical structure  we shall define the word syntactically. given a theory  a ground sentence p:-b will be called minimal in the theory if it is implied by the theory and no ground sentence p:-a witha a subset 
of b  is implied by the theory. the model of the theory is the set of all ground sentences minimal in the theory. 
     it can be shown that given a ground sentence one can predict how long a proof of it from a theory is going to be. this predictability is required by shapirofs approach to learning. formal proof of this predictability and other claims will be published elsewhere . 
     for a proper application of shapiro's approach  we need proofs to be in a form in which at every step one of the resolvents is a ground sentence. an algorithm has been developed by us which  given any proof  can convert it into one of this desired form. such a proof can be used to initiate a process called  contradiction backtrace  for what is known as  credit assignment  in the field  i.e. to find out which sentences in a theory lead to proofs of false sentences. if a fact defines a certain ground sentence to be false and a proof for it exists from a theory  then the axiom to blame is found as follows. at each step of the proof the algorithm asks of the environment whether the ground resolvent is true  the sentence being in l   it is legal to ask the question . if it is false  one of the axioms used in its proof must be false. else the axioms involved in the proof of the other  non-ground resolvent must be false. the algorithm asks the same question at the different steps of the  guilty  tree t i l l it isolates the false axiom. 
     the learning algorithm described in the next section will use this algorithm as well as the check on provability described above. 
	1ll 	the algorithm and its convergence 
     at any point of its operation  the learning program's knowledge has two components: 	the knowledge of the language and the theory developed so far. 	the structure of the theory has been discussed already. 	the knowledge of the language associates with each concept letter a set of atoms which occur in some positive examples of the concept  i.e. facts with the concept at the head and 
marked true . 
     there are several major procedures used by thelearning algorithm. the first one is: sentences p:-a  where a is one of the atoms just added to the language. there is one such sentence added for each new atom. 
      the reader will note that the theory learned by the algorithm has a lot of disjunctions  but the disjuncts are not the positive examples themselves  as in rote learning. rather the disjuncts are alternative generalizations of the examples.  
the next major procedure is 
      1  shrink: invoked when it is found that the theory implies a ground sentence which has been 
marked false. 	first the algorithm locates the 
 or one of the  sentences at fault in the theory  asking questions of the environment as described in the previous section . if the culprit is a ground sentence  then shrink adds to  i.e. forms the conjunction with  the body one of the atoms in the language associated with the predicate at its head. in doing so care is taken that the resulting sentence is not implied by any other sentence of the theory. 
     it can be shown that if the model is consistent  i.e. if no false ground sentence has a 
     body which contains the body of a true ground sentence with the same head   then the algorithm given below converges to a correct theory for any finite model. however  the resulting theory can be unnecessarily complex. moreover  since these processes only learn theories with ground sentences  no infinite model can be explained with such theories. this drawback can be rectified 
with the following procedure. 
      1  generalize: this process is invoked onlv after the two previous processes working in two cooperating loops have resulted in a theory with ground sentences explaining all the known facts. generalize is brought into action if the previous loops have added to or shrunk the ground part of the theory in their current invocation. at this point  the algorithm looks for all pairs of sentences in the theory in which the body of the first is subsumed by an instance of the body of the second. in this case  the involved part of the body of the first is replaced by the substitution instance of the head of the second. 
     one other process is invoked for compression of the sentences of the theory. it is called dream and is merely a generalization of an application of the distributive law of boolean logic. dream is responsible for introducing the internally generated feature names. it can be shown that dream does not change the set of sentences implied by a theory. 

      l add: 	this procedure is invoked when the program encounters a positive example of a concept not implied by the current theory. 	it adds to the language by associating with the predicate at the head of the fact all the atoms in the body of the fact  unless the atom was already there . add 
also modifies the theory. at the first occurence of a positive example of the concept  the theory is augmented by p:-  where p is the definiend corresponding to the concept. the body of the sentence is empty  indicating that  everything is a skeleton of the algorithm is shown in figure 1. 
     the algorithm works infinitely  verifying the current theory continuously  changing it only when facts demand i t . the point to be made here is that the algorithm is such that as long as a theory 
exists in the language  it can be found in a finite period of time and no modification is needed after that. 

a p.  	else it augments the theory by adding the 
	banerji 	1 


     the main loop of the algorithm consists of two other loops  the first working with add and shrink and the other working with generalize and dream. it has already been indicated that the first loop always terminates with a ground theory for the finite set of facts currently available in f+ and f . the second loop only introduces those generalizations that do not imply any known false facts - it does not remove any true known facts. it is possible that the generalizations introduced will explain true facts as well as false facts as the outer loop continues. it can  however be shown that in the kind of infinite models that theories of this class of lnaguages can express  sentences are bound to occur which lead to generalizations which explain only the true facts  provided that if any sentence of the theory contains two defined predicates in its body  the two predicates model disjoint sets of ground sentences. thus the algorithm does learn theories of infinite models in the limit in this restricted class of theories. finite models  of course are learned as soon as all the minimal true sentences are constructed by add and shrink. 
iv discussion of efficiency 
     there are two distinct phenomena that affect the time efficiency of the algorithm. one  there is the limit to the number of times the three successive inner loops to the program would be entered to make the theory compatible with the currently available examples. calculation of the worst case complexity  as far as the inner loops are concerned  leads to the conjecture that the time complexity would be exponential in the number of atoms in the language conjecture. so the overall efficiency of the program really depends on whether it can develop the theory as soon as it has gathered the minimal number of atoms the theory needs. 
1 	knowledge acquisition 
     the answer to this latter question depends very heavily on the second aspect of the efficiency  to wit  how many times the main loop will have to be entered before the correct theory can be discovered by the algorithm. unfortunately  the answer to the question is entirely dependent on the property of the input sequence. it is our conjecture looking at some example theories that for each theory a minimal set of examples exist which suffices to make the algorithm discover the theory. one can only make a probabilistic estimate of how late it will be before the crucial examples are presented to the algorithm. 
     presently an experiment is being carried out on this matter using a markov model as source of examples. it is intended that this model will also be used in the theoretical estimation of the average efficiency of the overall algorithm. 
v acknowledgements 
     the work described in this paper was supported by the national science foundation under grant 
dcr-1 to the saint joseph's university. 	the preparation of the manuscript was supported by the saint joseph's university as a part of thecontribution to research in machine learning undertaken in cooperation with the benjamin franklin partnership with the state of pennsylvania and with expert systems international  inc. 
vi 