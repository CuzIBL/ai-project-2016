 
this paper presents an incremental learning algorithm within the framework of a fuzzy intelligent system. the incremental learning algorithm is based on priority values attached to fuzzy rules. the priority value of a fuzzy rule is generated based on the fuzzy belief values of 
the fuzzy rule derived from the training data. the fuzzy incremental algorithm has three important properties. it can detect and recover from incorrect knowledge once new knowledge is available; it will not lose the useful knowledge generated from the old data while it attempts to learn from new data; and it provides a mechanism allowing to emphasize on knowledge learnt from the new data. the incremental fuzzy learning algorithm has been implemented in a fuzzy intelligent system for automotive engineering diagnosis. its performance is presented in the paper. 
1 introduction 
in recent years  machine learning has found widespread applications in engineering and manufacturing areas. one dimension to categorized machine learning algorithms is whether an algorithm operates in an incremental or non-incremental mode. in non-incremental learning  an algorithm infers a concept once  based on 
the entire set of available training instances. in the incremental learning  a machine learning algorithm revises the current concept definition  if necessary  in response to each newly observed training instance. nonincremental learning has been the center of research attention in the machine learning community mitchell  1; weiss and kulikowski  1; hutchinson  1  for many years  but incremental learning has received very little attention. an incremental learning algorithm updates its hypotheses as a new instance arrives without reexamining old instances. human learning is an incremental process. we learn many tasks over a life-long time and the accumulated knowledge guides our subsequent learning. in many engineering applications  data 
fuzzy intelligent system 
tie qi chen 
ece department 
the university of michigan-dearborn dearborn  m 1 u. s. a. 
for an intelligent system to learn are available through time. one typical application problem is to test vehicles at the end-of-line in automotive assembly plants. the engineering aspects of different vehicle models often differ from each other. even vehicles of the same model but different years can have different engineering diagnostic features. when vehicles of a new model or vehicles of the same model but different year are manufactured  we usually have very little data available to build a sufficient knowledge base through machine learning. our research aim is to investigate an incremental learning algorithm that can learn diagnostics knowledge whenever data become available. for example  if we developed an intelligent diagnostic system through machine learning from vehicle samples of a 1 vehicle model to detect engineering faults  we would apply the system to the test of new vehicles made in 1 on the assembly lines at the beginning of the manufacturing. as the 1 vehicle model is produced in assembly plants  the system would learn incrementally to update its knowledge base from the new vehicle data samples in order to perform the diagnostics task reliably. 
　utgoff presented his study in incremental induction of decision trees utgoff  1 . bohn investigated the incremental unsupervised learning scheme for function approximation bohn  1   and fu etc. has investigated incremental back propagation learning networkstfu et al  1 . in this paper  we present our study in incremental learning in the framework of a fuzzy intelligent system. the fuzzy intelligent system has the ability to learn classification  which is fundamental to intelligent behavior. many of concept learning can be considered as classification problems: identifying bad signals  classifying fault classes of signals  vehicle test  etc. 
　the incremental fuzzy learning algorithm is designed to have the following features: 
  the knowledge used in most intelligent systems in industrial applications are generated either from engineers1 experience or from data sets  which  from time to time  can be incorrect due to missing data or incorrect understanding of the problem. the incremental 

1 	uncertainty and probabilistic reasoning 

learning algorithm should detect and recover from incorrect knowledge once new knowledge is available. 
  the incremental learning algorithm should not lose the useful knowledge generated from the old data while it attempts to learn from new data. 
  it should provide a mechanism allowing a user to emphasize on knowledge learnt from the new data. in many applications  data becoming available contain more information about the problem under the study. the ability of specifying emphasis of knowledge learnt from a specific data will give more flexibility during fuzzy learning. 
1 	a fuzzy incremental learning system 
the incremental learning algorithm developed for the fuzzy incremental learning system simulates the way a human being learns. when a person encounters an instance of concept that is never seen before  he first tries to find a match in his knowledge base  the brain . if he cannot find a good match  he will update his knowledge by learning from this new instance. he never throws away what he has already learned before. in fact  he makes himself adaptive to the new case by just changing a small part of his knowledge. 
　　let us assume that there is a knowledge base kb that contains a set of fuzzy rules and fuzzy membership functions generated from a training data set. fuzzy rules can be completely characterized by a set of control variables  and each of which is associated with a set of fuzzy terms for the convenience of description we assume there is only one solution variable y  and y is associated with fuzzy terms 
 each fuzzy rule in kb has the following format: 

where m n    and 
f. the degree to which the fuzzy action is taken depends on the degree of truth in the antecedent proposition. we assume the existing knowledge base kb is generated from a set of training data  1   through an automatic fuzzy learning algorithm. 
　the incremental learning algorithm first assigns a priority measure to each fuzzy rule  r  in the kb using the following formula: 
training set tr  is the sum of the fuzzy belief values of all the samples that match the antecedent proposition in rule r and the truth value of the data samples matches the consequence of rule r   is the sum of the belief values of all the data samples that match the antecedent proposition in r but the truth values of the data samples do not match the consequence of rule r. the priority assignment to a fuzzy rule r truly reflects how the frizzy rule represents features of the training data. we use an example to illustrate the priority assignment scheme. let us assume we have two control variables x  and x1 and one solution variable y  each of the variables is associated with three fuzzy terms {low  medium  high}. table 1 listed three possible contradiction fuzzy rules: 

　for a data sample s in the training set  if s matches the antecedent of these three rules  its target value must match one of the three consequences. in this example  
1 data samples support r1  1 data samples support r1 and 1 support r1. in order to find out which rule has the largest effect  we need to compute the belief value of the rules. the belief value of a rule is computed by applying and operator onto the belief values of all the control variables involved. if the belief value of a rule is not zero  we say the data entry fires the rule. if the data entry fires two or more rules that have the same consequence  an or operator is applied. there are different types of and/or operators. the most common one is the min/max proposed by l. a. zadeh zadeh  1   which is the one used in the incremental learning algorithm. if we assume the highlighted entry in table 1 as the fuzzy rule generated from a training data set  the priority measure for the fuzzy rule is 

where n= 1. 
　let us assume that we are given a new training data set tr-new from which we intend to learn new knowledge based on the existing knowledge base kb that contains fuzzy membership functions  fuzzy rules and the associated priorities. 
　in order to learn from the new training data set  trnew  the incremental learning algorithm assigns a new priority value to each fuzzy rule r using the formula: 

where  is the priority value of the fuzzy rule r generated from the training data tr  and m is the number of data samples in tr-new. the next step in the incremental algorithm is to segment  using the existing fuzzy membership functions in kb  the data samples in tr-new into the clusters specified by the control variables and their fuzzy terms. every data sample in tr-
	murphey and chen 	1 



table 1. an example of generation of fuzzy rules. 

table 1. three fuzzy rules generated from rules in table 1. 

new should belong to one of the clusters. table 1 shows an example. in this example  we have two 
control variables x1 and x1  and one solution variable y  each of which has three fuzzy terms  {low  medium  high}. each of the fuzzy terms of y form a possible fuzzy rule for the antecedence in its entry. we listed in the table the number of data samples and the average belief value for every possible fuzzy rule. in each cluster defined by the control variables  there are three possible fuzzy rules  which have conflict consequences. a fuzzy rule is generated for each cluster by selecting the one that has the largest influence on its data entries  which is measured by the average belief value of the fuzzy rule. the priority value for each of the new fuzzy rules is computed by 

where n and m is the total number of data entries in the training set tr and tr-new respectively  sw is the sum of the fuzzy belief values of all the samples in tr-new that match the antecedent proposition in rule 
r and the truth value of the data samples matches the 

1 	uncertainty and probabilistic reasoning 

the data samples do not match the consequence of rule 
　the next step in the incremental algorithm is to compare the newly generated fuzzy rules with the prior rules in kb. if a new rule is the same as one of the existing rules  we increase the priority of the existing rule. if the new rule conflicts with one of the existing rules  we decrease the priority of the existing rule. if the priority of the existing rule becomes negative  we replace the rule with the new rule. if the new rule is different from all the existing rules  we add it into the fuzzy rule knowledge base. 
　in order for the incremental learning algorithm work properly  the prior fuzzy rules in kb must be in the singleton form. a fuzzy rule is in the singleton form if it contains all the control variables in its antecedence and the solution variables in its consequence  each variable is associated with one fuzzy term  and the variables are joined by the conjunction operator  and.  all the fiizzy rules in table 1 are in the singleton form. however in order to improve the performance of a fuzzy system  techniques have been developed to merge eligible singleton rules into compact rules lu and chen  1 . for example  the six fiizzy rules in table 1 can be merged to the three equivalent compact rules and the priority values of each compact rule is the sum of the priorities of its singleton rules. we use one example to explain why we need to decompose compact rules before applying the incremental learning algorithm to the kb. suppose we the fiizzy rule in table 1 rl:  if  is low  then  is medium . when we incrementally learn new fiizzy rules from a new training set  every new fiizzy rule that has the following form:  if is anything and is low  then  is anything other than medium  will conflict with rl. the priority of rl decreases every time when there is a conflicting rule. and finally rl would be replaced by one new rule when its priority becomes negative. this may cause some problems. first  the coverage  in the input space  of the new rule may be much smaller than the old rule that was replaced. for example  table 1 showed that the coverage of  is low  is smaller than the coverage of  is don't care . second  the new rule may not be a real winner. for example  if the priority of the old rule decreases mainly because of the repeated generation of rule a:  if  is l o w and x1 is low  then y is high . but it is possible that  when the priority reaches zero  rl is finally replaced by rule b:  if x1 is l o w and x1 is low  then y is low . even though the real winner should be rule 
a  not rule b. the old rule is actually replaced by rule b just because rule b is generated at the right time. 
　therefore we need to decompose all the compact rules in kb into singleton forms before we apply the incremental learning algorithm. it is rather straightforward to derive its singleton rules from a compact fuzzy rule  since the domain of the fiizzy variables and fiizzy terms are known. however  there is no way to find the respective priority values of the individual singleton rules. one solution is to divide the priority value of the compact rule equally among the singletons. 
　the incremental learning algorithm can be summarized as follows: 
1. decompose all the fiizzy rules in the existing knowledge base  kb  into singletons  and divide the priority of every compact fiizzy rule equally among its singletons. 
1. initialize the fuzzy rule table with all the singleton rules  and re-compute the rule priorities using the sizes of the previous and the new training sets. 
1. scan through the new training set sequentially. for each data entry: 
1 generate the dominant rule and compute its priority value based on the fiizzy belief value. 
1 compare the new rule with each of the prior rules. 
1 if the new rule is an existing one  we add the priority value of the new rule to that of the existing rule. 
1 if the new rule conflicts with an existing rule  we subtract priority value of the new rule from that of the existing rule. and if the belief value of that rule becomes negative  we replace that rule with the new rule. 
1 if the new rule is different from all the rules in the rule table  if the rule table is not full  we add new rule into the table. otherwise  if the lowest priority value in the rule table is lower than the priority value of the new rule  we replace it with the new rule. but before we throw away the fuzzy rule with the lowest priority value  we subtract its priority value from all the rules in the rule table.  rule aging.  
　the incremental algorithm allows to emphasize the new fiizzy rules generated from tr-new by multiplying a weight factor that is greater than 1 to the priority value of each new fiizzy rule before it is compared with the existing fiizzy rules. 
　the fiizzy inference engine used in the incremental learning has two important characteristics. first it incorporates multiple knowledge sources  learning from training data sets as well as from expert knowledge during the fiizzy inference by assigning priorities to these individual knowledge sources. the summation of the priorities over the knowledge sources should be 1. this knowledge source priority is multiplied to the rule priority as the weight of a fired rule. the second characteristic characteristic is that the fiizzy inference engine attempts to make the best decision for any input test sample. it is often that the knowledge base does not contain a complete set of fiizzy rules  which can cause certain input samples 
	murphey and chen 	1 


table 1. the test results of current-year vehicle data using the knowledge base generated from the training data of 

table 1. the test results of the current year vehicle data after incremental learning from the vehicles of the same year using the knowledge based generated from vehicles of the previous year model 

firing no fuzzy rules. in particular in many applications when the training data set is small to generate a sufficient knowledge base  a data sample can hit no existing rules during the fuzzy inference procedure. in order to solve this problem  we developed the following inference scheme that fires the nearest rule to the input sample. generally  a fuzzy rule can be considered as a frizzy cluster in the input space. for instance  a frizzy rule written as 

represents a fuzzy cluster located at the center paint of the frizzy membership functions of  x is low  and y is high . based on this concept  we define the following distance measure between a data sample and a frizzy rule. let an input data sample be  ...  an}  where a  is the instantaneous value of frizzy variable  is a set of frizzy terms associated with each control variable in  is a symbol that serves as  don't care . with the introduction of a frizzy rule can always be written in the following general form: 
for i = 1 ...  n  z is a solution variable and p is a frizzy term. for example  for a system has three control variables   and the frizzy terms are {low  medium  high}  if we have a 
frizzy rule: 

we can rewrite the rule equivalently as  

　the distance between a data sample i and a frizzy rule k is defined as 

where is the center point of the fuzzy membership function of frizzy variable x; for frizzy term  
otherwise  which sets the fuzzy rule that has the shortest distance to sample i is fired. 
1 	experiments 
we have applied the incremental learning algorithm to test defect vehicles at the end-of-iine in automobile assembly plants. as automotive electronic control systems become more advanced and sophisticated in recent years  malfunction phenomena have also become increasingly more complicated. the major us automotive companies have launched an end-of-line test site at every north american assembly plant to test every new automobile before it is shipped to a dealer. during the test  a number of components such as engine and transmission are checked based on the sensory data acquired at the test site. we applied the incremental learning algorithm to learning the vehicle diagnostic knowledge from the vehicle data of the current year using the knowledge learnt from the vehicles of the same model of the previous year. we then tested the vehicles of the same model of the current year using the combined knowledge base. the sensor data acquired at the test site are the feature vectors of vehicles  which serve as the input to the incremental learning algorithm. from table 1 we can see that the knowledge base generated from the vehi-

ran 	uncertainty and probabilistic reasoning 

cle samples of the previous year was not sufficient to detect defective vehicles  the fuzzy system detected only 1% percent of the bad vehicles. when the fuzzy diagnostic system used the knowledge base generated by the incremental learning algorithm from the training data of the currant year vehicles and the knowledge base generated from the vehicle data of the previous year  it was able to detect more than 1% of good vehicles and more than 1% of the bad vehicles see table 1   which is a significant increase from the 1%. 
1 	conclusion 
we have presented an incremental fuzzy learning algorithm. it is particularly useful in applications where learning data become available through the application of the system. the fuzzy inference com* ponent uses multiple knowledge sources and has the capability of firing nearest rules for an input data. the fuzzy learning and the inference algorithms have been implemented in a fuzzy intelligent system for automotive engineering diagnosis used in the end-ofline test in automotive assembly plants. the experimental results show that the incremental learning algorithm is very effective. 
acknowledgments 
this work is supported in part by a grant from nsf dm1 and a contract from the ford motor company. 
