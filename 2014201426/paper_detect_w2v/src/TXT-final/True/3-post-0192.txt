
scaling ai algorithms to large problems requires that these algorithms work together to harness their respective strengths. we introduce a method of automatically constructing hhmms using the output of a sequential data-mining algorithm and sequential prediction algorithm. we present the theory of this technique and demonstrate results using the mavhome intelligent environment.
1 introduction
an important component of an intelligent environment is to anticipate actions of a human inhabitant and then automate them. the decision of which action to execute must be correct in order to avoid creating excess work for humans in the form of correcting wrong automated actions and performing manual actions.
　we examine the problem of learning human inhabitant behavioral models in the mavhome intelligent environment and using this to automate the environment. an event in the environment is described by the time of the event  the device/sensor zone  the device/sensor number  the new value of the device or sensor  the source of the vent  e.g.  sensor network  powerline controller   and the inhabitant initiating the event  if known .
1 solution strategy
to automate the environment  we collect observations of manual inhabitant activities and interactions with the environment. we then mine sequential patterns from this data using the ed sequence mining algorithm. finally  a hierarchical markov model is created using low-level state information and high-level sequential patterns  and is used to learn an action policy for the environment.
1 mining sequential patterns using ed
our data mining algorithm  ed  mines sequential patterns from observed activities. data is processed incrementally and sequential patterns are mined according to their ability to compress the data using the minimum description length principle. periodicity  daily  every other day  weekly occurrence  of episodes is detected using autocorrelation and included in the episode description. if the instances of a pattern are highly periodic  occur at predictable intervals   the exact timings do not need to be encoded and the resulting pattern yields even greater compression value.
1 predicting activities using alz
to predict inhabitant activities  we borrow ideas from text compression. by predicting inhabitant actions  the home can automate or improve upon anticipated events that inhabitants would normally perform in the home. our active lezi  alz  algorithm  gopalratnam and cook  1  approaches this problem from an information-theoretic standpoint. alz incrementally parses the input sequence into phrases and  as a result  gradually changes the order of the corresponding markov model that is used to predict the next symbol in the sequence. frequency of symbols is stored along with phrase information in a trie  and information from multiple context sizes are combined to provide the probability for each potential symbol as being the next one to occur. in our experiments  alz proved to be a very accurate sequential predictor. however  accuracy is further improved when the task is restricted by ed to only perform predictions when the current activity is likely to be part of a frequently-occurring pattern.
1 decision making using prophet
work in decision-making under uncertainty has popularized the use of hierarchical hidden markov models and partially observable markov decision processes. recently  there have been many published hierarchical extensions that allow for the partitioning of large domains into a tree of manageable pomdps  pineau et al.  1; theocharous et al.  1 . although the hierarchical pomdp is appropriate for an intelligent environment domain  current approaches generally require a priori construction of the hpomdp. given the large size of our domain  we need to seed our model with structure automatically derived from observed inhabitant activity data.
　unlike other approaches to creating a hierarchical model  our decision learner  prophet  actually automates model creation by using the ed-mined sequences to represent the abstract nodes in the higher levels of the hierarchy. lowest-level states correspond to an environment state representation together with an alz-supplied prediction of the next inhabitant action. to learn an automation strategy  the agent explores the effects of its decisions over time and uses this experience within a reinforcement learning framework to form control policies which optimize the expected future reward. the current version of mavhome receives negative reinforcement when the inhabitant immediately reverses an automation decision  e.g.  turns the light back off  or an automation decision contradicts user-supplied safety and comfort constraints  e.g.  do not let the temperature exceed 1 degrees .
1 environments
all of the algorithms described here are implemented in mavhome and are being used to automate two environments  shown in figure 1. the mavlab environment contains work areas  cubicles  a break area  a lounge  and a conference room. mavlab is automated using 1 x-1 controllers and the current state is determined using light  temperature  humidity  motion  and door/seat status sensors. the mavpad is an on-campus apartment hosting a full-time student occupant. mavpad is automated using 1 controllers and provides sensing for light  temperature  humidity  leak detection  vent position  smoke detection  co detection  motion  and door/window/seat status sensors.

figure 1: the mavlab  left  and mavpad  right  environments.
1 case study
as an illustration of these techniques  we have evaluated a week in an inhabitant's life with the goal of reducing the manual interactions in the mavlab. the data was generated from a virtual inhabitant based on captured data from the mavlab and was restricted to just motion and lighting interactions which account for an average of 1 events per day. we trained alz and ed on real data and then repeated a typical week in our resisim simulator to determine if the system could automate the lights throughout the day in real-time.

figure 1: prophet generated hhmm with production nodes abstracted.
　alz processed the data and converged to 1% accuracy after 1 iterations through the training data  and accuracy was 1% on test data. when automation decisions were made using alz alone  interactions were reduced by 1% on average. next  ed processed the data and found 1 episodes to use as abstract nodes in the hpomdp  as shown in figure 1. the hhmm model with no abstract nodes reduced interactions by 1%  and the combined-learning system  prophet bootstraped using ed and alz  was able to reduce interactions by 1%  as shown in figure 1.

figure 1: interaction reduction.
　experimentation in the mavpad using real inhabitant data has yielded similar results. in this case  alz alone reduced interactions from 1 to 1 events  the hpomdp with no abstract nodes reduced interactions by 1% to 1 events  while the bootstrapped hpomdp reduced interactions by 1% to 1 events.
　in this research we have shown that learning algorithms can successfully automate an intelligent environment. we see that synergy between these algorithms can improve performance  as ed-produced abstractions in the hierarchy coupled with a prediction produced by alz improved automation performance for prophet. a full system deployment in the mavpad is currently being conducted.
