
many mdps exhibit an hierarchicalstructurewhere the agent needs to perform various subtasks that are coupled only by a small sub-set of variables containing  notably  shared resources. previous work has shown how this hierarchical structure can be exploited by solving several sub-mdps representing the different subtasks in different calling contexts  and a root mdp responsible for sequencing and synchronizing the subtasks  instead of a huge mdp representing the whole problem. another important idea used by efficient algorithms for solving flat mdps  such as  l ao* and  l rtdp  is to exploit reachability information and an admissible heuristics in order to accelerate the search by pruning states that cannot be reached from a given starting state under an optimal policy. in this paper  we combine both ideas and develop a variant of the ao* algorithm for performing forward heuristic search in hierarchical models. this algorithm shows great performance improvements over hierarchical approaches using standard mdp solvers such as value iteration  as well as with respect to ao* applied to a flat representation of the problem. moreover  it presents a general new method for accelerating ao* and other forward search algorithms. substantial performance gains may be obtained in these algorithms by partitioning the set of search nodes  and solving a subset of nodes completely before propagating the results to other subsets.
　in many decision-theoretic planning problems  the agent needs to perform various subtasks that are coupled only by a small sub-set of variables. a good example of this is our main application domain: planetary exploration. in this domain  the agent  an autonomous rover  must gather scientific data and perform experiments at different locations. the information gathering and experiment running task at each site is pretty much self-contained and independent of the other sites  except for two issues: the use of shared resources  such as time  energy and memory   and the state of some instru-

 qss group inc.
ments that may be used at different locations  for instance  warmed-up or not . the rover has only limited resource for each plan execution phase and it must wisely allocate these resources to different tasks. in most problem instances  the set of tasks is not achievable jointly  and the agent must dynamically select a subset of achievable goals as a function of uncertain events outcome.
　these problems are often called oversubscribed planning problems. they have a natural two-level hierarchical structure  meuleau et al.  1 . at the lower level  we have the tasks of conducting experiments at each site. at the higher level  we have the task of selecting  sequencing and coordinating the subtasks  in the planetary rover domain  this includes the actions of tracking targets  navigating between locations  and warming-up instruments . this hierarchical structure is often obvious from the problem description  but it can also be recognized automatically using factoring methods such as that of  amir and englehardt  1 .
　the potential benefit of hierarchicaldecompositionis clear. we might be able to solve a large problem by solving a number of smaller sub-problems  potentially gaining an exponential speed-up. unfortunately  the existence of an hierarchical decomposition does not imply the existence of an optimal decomposable policy. thus  one must settle for certain restricted forms of optimality  such as hierarchical optimality  andre and russell  1   or consider domains in which compact optimal policies exist  such as those that satisfy the reset assumption of  meuleau et al.  1 .
　this paper formulates an hierarchical forward heuristic search algorithm for and-or search spaces  which we refer to as hierarchical-ao*  hiao* . this algorithm exploits a hierarchical partition of the domain to speed up standard ao* search  nilsson  1 . it may be applied anywhere that ao* may be applied  that is  for all problems that can represented as an acyclic and-or graph  provided an hierarchical partition of the search space is defined. this could be mdps or any other search problem.1 although there is no formal guarantee that it will result in actual performance improvements  our simulations with the rover domain show that it has a great potentialfor oversubscribedplanningproblems. furtherwork

1
　　like standard ao*  hiao* is not designed to work on problems that contain loops. a similar extension to that in  hansen and zilberstein  1  is required to handle these problems.
is required to show the relevance of this approach in a more general setting. however  this paper outlines directions that could benefit a wide variety of application domains  and other forward search algorithms such as a*.
　the reason why forward heuristic search can be beneficial in hierarchical mdps is pretty obvious. it is the wellknown benefit of using reachability information and admissible heuristic. the most efficient algorithms for solving flat mdps  such as  l ao*  hansen and zilberstein  1  and  l rtdp  barto  et al.  1; bonet and geffner  1   accelerate the search by pruning states that cannot be reached from a given starting state under an optimal policy. the same benefit can be expected in a hierarchical representation of the problem. hierarchical algorithms such as abortupdate  meuleau et al.  1  must resolve similar subproblems  but in different calling contexts. implementations based on classical mdp solverssuch as valueiteration or policy iteration  which ignore the initial state  must consider all possible contexts. forward search algorithms consider only reachable contexts  and with a good heuristic function  only a subset of these.
　more interesting are the reasons why hiao* can outperform standard heuristic search over flat-domains as implemented in standard ao*. the first reason has to do with the order and efficiency of the value propagation step  which is known to be the costliest part of ao*. hiao* embodies a lazy approach to value updates: the update work is concentrated within a particular sub-domain each time  and work on other domains is postponed until their value is needed.
　the second benefit of the hierarchical partitioning of the domain is the possibility to use macro-connectors. when the optimal solution over a subset of states is known  it can be represented as a macro-connector similar to the temporally abstract actions or macro-actions used in reinforcement learning  sutton et al.  1 . macro-connectors are then used while solving other subsets of states  to accelerate the traverse of the graph.
　the third benefit of forward heuristic search in a hierarchical representation is the possibility of using a known solution of a subtask to seed the algorithm in charge of solving similar subtasks. as will become apparent later  the dynamics within a sub-problem is not influenced by the calling context. the latter influences the value of nodes  and thus the optimal policy  but not the search space structure. therefore  we can reuse expanded solutions for different calling context  using them as starting points. although farther expansion will be required  we are likely to benefit from much of this work.
　finally  with a decomposed domain  we believe that one can formulate more accurate heuristic functions that are appropriate for each of the sub-domains. a simple example would be the assessment of the value of a sub-domain under new calling contexts. we can simply use the value computed for similar contexts. a more sophisticated example would be the use heuristics specifically designed for a particular subdomains.
　in this paper  we focus on explaining and testing the first three points above. we provide an abstract  and quite general interpretation of the use of any hierarchical decomposition in ao* in terms of  1  propagation order   1  extra level by-passing edges  and  1  local solution re-use. these three properties emerge naturally when one attempts to search hierarchically  and they can be used given an arbitrary partitioning of the state space  that is  beyond the application to oversubscription planning . this formulation  its abstract interpretation  and its evaluation in the rover domain are the main contributions of this paper.
　in the next section  we explain how we model hierarchical mdps. then  we review the ao* algorithm  we explain the new hiao* algorithm  and we show how it can be applied to oversubscribed planning problems. finally  we describe our empirical evaluation of hiao* and conclude.
1 hierarchical mdps
a markov decision process  mdp   puterman  1  is a four-tuple  where s is a set of states  a is a set of actions  t : s 〜 a 〜 s ★  1  is the transition function which specifies for every two statesand action a （ a the probabilityof making a transition fromwhen a is executed  and r : s〜a〜s ★ r is the reward function. we augmentthe above description with a concrete initial state sinit （ s  obtaining a quintupleinit. in this paper  we focus on bounded-horizonmdps  in which the length of each trajectory is bounded by a finite number  and we use the undiscounted expected reward criterion.
　we shall concentrate on factored mdps which have the form. here x is a set of state variables  and a t r sinit are as before. the variables in x induce a state space  consisting of the cartesian product of their domains. to simplify notations  we assume all variables are boolean  that is  they are fluents. typically  it is assumed that the transition function t is also described in a compact manner that utilizes the special form of the state space  such as dynamic bayes net  dean and kanazawa  1  or probabilistic strips rules  hanks and mcdermott  1 . in this paper  we do not commit to a concrete action description language  but we expect it to be variable-based such as the above methods  as we assume that it is easy to identify the relevant variables with respect to an action a （ a. this is the set of variables whose value can change when a is executed  as well as those variables that affect the probability by which these variables change their value and the immediate reward received for executing a.
　an hierarchical decompositions of an mdp consists of a set of smaller factored mdps. in its definition  the notion of a projection of t and r plays a central role. let x be some subset of the variables in x. the projection of t over x w.r.t. action a （ a is well defined if a does not affect the value of the variables inand the transition probabilities and reward of a do not depend on the value of these variables. in that case  the actual projection can be obtained by fixing some arbitrary value to the variables in.
　formally  we define a hierarchical decomposition of a factored mdp init as a tree of factored mdps  mh = {m1 ... mn}  where mi =
. each mi is just a factored mdp. the
only differenceis that its set of actions  a+i contains a number of special control actions which signify the passing of control to its parent or one of its children. these actions encode the hierarchy  too. more specifically  xi   x; a+i is the union of some subset ai   a together with two types of control actions: μj corresponds to passing control to a child process mj  and abort signifies the passing of control back to the parent process; ti is the projection of t over xi  such that ti is well-defined; ri depends on xi and ai only; and siniti is the projection of sinit over xi. in addition    for every  and when-
ever x （ xi”xj then x （ xk for every k such that mk is on the path between mi and mj  which is known as the running intersection property . see  meuleau et al.  1  for a more detailed description of this model. a decomposition of m into mh can be obtained automatically by a straightforward extension of the methods described in  amir and englehardt  1  for deterministic planning domains.
　as an illustration  fig. 1 describes a decomposition of a simple planetary rover domain into three sub-domains. m1 is the top-level domain in which we control the position of the rover and the choice of which subtask to perform next  these are the μi actions . m1 and m1 represent the subtasks associated with experimenting on of one of two rocks. m1 shares some variables with its children  and the resource level is a variable shared by all.
1 hierarchical ao*
we start with a short review of the ao* algorithm. next  we show how a hierarchical partition of the search nodes may be exploited to accelerate the algorithm  and we provide the pseudo-code of a new general algorithm called hierarchicalao*  hiao* .
1 the ao* algorithm
ao*  nilsson  1  is a generalization of a* to and-or graphs. as such  it can be applied to the problem of generating a policy for an mdp given an initial state  assuming there are no loops in the transition graph  hansen and zilberstein  1 . in mdps  an or node corresponds to a choice of an action at a state  and an and node corresponds to the set of possible states resulting from each such choice. the possible and nodes are annotated by their probability.
　ao* maintains two basic structures: the explicit graph and the greedy graph. the explicit graph simply depicts the portion of the search space that has been expanded so far. the greedy graph is a subgraph of the explicit graph which represents those nodes that are reachable by the greedy policy. to obtain the greedy graph  one needs to perform dynamic programming in the explicit graph  propagating values bottomup from the leaf nodes  using their heuristic values  to the root node. the value of an and node is the expected value of its children  and the value of an or node is the maximum over the value of its children. if we note the choice that yielded this maximum  we can now generate the greedy graph by simply following these choices starting at the root node. the pseudocode for ao* is described in algorithms 1 - 1.
　if an admissible heuristic function is used in ao*  then the value of each node may only decrease at each iteration.1when we update the value of a node outside the greedy graph  the greedy graph may not be affected because the update can only reduce the value of the node. thus  a choice that was sub-optimalcannotbecomeoptimal. consequently new node values need only be propagated up edges marked as optimal 
1: create set z containing only the state s.
1: repeat
1: remove from z a state s such that no descendent of occurs in z.
1:	set
and mark the connector associated with the best action in	optimal.
1:	ifdecreased at previous step  it cannot increase  then
1: add all parents of s along connectors marked as optimal to z.
1: until z is empty.algorithm 1: update s .
1: initialize the explicit graph g to the start state sinit. 1: mark sinit as open.
1: solve s1 sinit .
1: return the greedy solution graph starting at sinit.
algorithm 1: hierarchical ao*.
i.e.  denoting the optimal choice in that state.
　in most cases  the most expensive parts of ao* are:  1  the update stage  where we propagate value changes up the explicit graph  alg. 1 ;  1  the computation of the fringe  that is  the set of open nodes in the greedy graph  line 1 of alg. 1 . we show below how a partition of the states expanded by ao* may be exploited to accelerate these two operations.
1 the hiao* algorithm
we now assume that the state space s is partitioned into subsets s1 ... sk. furthermore  we assume that these subsets are organized in a hierarchy in the form of a tree 1 so that:  1  the starting state sinit belongs to the root subset denoted s1;  1  state transitions are possible only between states in the same subsets  or between two states belonging to two subsets one being the parent of the other. these choices are motivated by the hierarchical mdp framework presented above  where a child subset represents a subprocess that can be called from the current subset/process  therefore  we sometime use the term  subprocess  to designate a child subset . however  our formalism is general and can be applied to any instantiation of ao* where a hierarchy of nodes can be defined.
　the hiao* algorithm is presented in alg. 1 - 1. the algorithm also uses the same function expand   as standard ao*  alg. 1 . the basic principle of this algorithm is the following: each time that the optimal action in a state leads to a child subset  in other words  each time it appears optimal to call a subprocess from the current state   we recursively call the hiao* algorithm to solve this child subset completely before continuing solution of the current level. we explain below how this simple mechanism may benefit the algorithm.
1: while the greedy solution graph starting at s contains some open nodes in si do
1:any open node of the greedy graph starting at s in si.
1:	unmarkopen.
1:	expand
1: mark all nodes created at previous step and that belong to a child of si as outdated.
1:	hierarchicalupdatealgorithm 1: function solve si s .
delaying the propagation of new values: the main principle implemented by hiao* is to delay the propagation of new node values in between states belonging to different subsets. let us first consider why delaying updates might be useful. suppose that we have expanded node u and then node v  and following their expansion  their value has changed. in standard ao*  following the change in value in u we would propagate this information upwards along marked edges. then  we would repeat the process for v. however  it is quite possible that u and v have common ancestors  and thus we will update these ancestors twice. sometimes  such an update is important because it influences our choice of which node to expand. sometimes  such an update can be delayed  and we can save the repeated update of shared ancestors. hiao* tries to exploit the second case  assuming it happens more often than the first case.
　the general scheme we propose for delaying updates is as follows. we associate to each subset si a set of nodes to update zi similar to the set z used in alg. 1. at any particular point  the algorithm has a single subset of nodes in focus and performs the standard ao* operations only inside of that subset. whenever a state s （ si is expanded and thus needs to be evaluated  we insert it into zi and enter a loop that will propagate its value up into the graph by emptying and re-filling the set zi  as in standard ao*  alg. 1 . however  each time that a new value needs to be propagated to a state s belonging to another subset is necessarily the parent or a child of is added to zj and not to zi  line 1 of alg. 1   and so  it is excluded from the loop that works only with zi. so  the propagation is limited to the subset si  and nodes that would need to be updated but belong to another subset sj are just stored in zj  but they are not re-evaluated yet and their new value is not propagated yet.
　so  when are the nodes inupdated  the answer depends on the hierarchical relation between sj on si. if sj is the parent of si  then the states that have been put in zj during the solution of si are updated when the algorithm moves focus from si back to its parent subset sj. if sj is child of si  then the states in zj are updated at the latest possible time  that is  when we want to evaluate a state outside of sj that may lead into sj under the optimal action. this may never happen if calling subprocess sj is the optimal decision in none of the states visited by the algorithm later on  in which case we save all the work of updating states in sj. in practice  this is implemented through the use of outdated markers  as explained below.
one of the basic principle of the hiao* algorithm is that 
1: zi := zi “ {s}.
1: while
1: remove from zi a state s such that no descendent of occurs in zi.
1:	set
 
callthe optimal action in s  and mark the associated connector as optimal.
1:	while executing	may lead to states that are
not in si and that are marked as outdated do
1:	for each child sj of si do
1:	for each	such that
and s is marked as outdated do
1:	unmark s as outdated.
1:	hierarchicalupdate sj  null .
1:	s	j	 .
1:	set
 
callthe optimal action in s  and mark the associated connector as optimal.
1:	ifdecreased at previous step  it cannot increase  then
1: for each state s that is a parent of s along a connector marked as optimal do
1:	ifthen
1:	add	.
1:	else
1:	  the subset containing s.
1:	add s to	j.
1:	if sj is a child of si then
1:	mark s  and all its predecessors in sj along connectors marked as optimal  as outdated.algorithm 1: function hierarchicalupdate si s .
when we are done updating a node in si that can possibly lead to a node s in a child subset  under the optimal action  then we must know with accuracy the set of optimal decisions that leads from s either to terminal states  or back into si. a node of sj is marked as outdated if the greedy subgraph starting at that node has a chance of not being accurate or complete. suppose that the algorithm is currently working in subset si and needs to propagate a new value to a state s belonging to a child sj of si. then  as explained above  the update of s is delayed and s is just added to zj  line 1 of alg. 1 . in addition  all nodes of sj  above  s in the greedy graph are marked as outdated  line 1 and 1 of alg. 1 . later  if we want to evaluate a node outside of sj that can lead to a state  the value of s may not be accurate  because we have delayed propagation of new values in sj. if this is the case  then s must be marked as outdated and  consequently  two operations are performed:  1  we purge the set zj and update all the nodes in sj that need to be re-evaluated using a recursive call to hierarchicalupdate    line 1 of alg. 1 . this may change the greedy policy in sj below some of the entry nodes of sj  including node s;  1  the greedy graph starting at s in sj is updated through a call to solve    line 1 of alg. 1 . so  the outdated marker in s may be deleted  line 1 of alg. 1   but the markers of all other entry nodes are kept.1 if we later get to update another state outside of sj and that can lead to  then the outdated marker of s will indicate that the greedy graph belowneeds to be updated  even if no new node has been added to zj in the mean time.
convergence: as long as the problemcontains no loop  hierarchical ao* is guaranteed to terminate in finite time and to return the optimal solution:
theorem 1 if the heuristic h is admissible  then hiao* returns the optimal policy in finite time.
hiao* may not always be efficient  particularlyif the number of connections between subsets is large. however  we claim that  in the case of oversubscription planning  the state partition induced by the hierarchy is efficient and allows leveraging the general principle presented above. the simulation results presented in this paper support this claim.
　we now present two acceleration techniques that can be implemented in hiao* to get further leverage from the hierarchy  but are not used in the pseudo-code of alg. 1 - 1.
optimizing the algorithm: the hiao* algorithm presented above exhibits the following inefficiency. if an action a leading to a state  appears optimal in state
   then the algorithm will solve completely the sub-problem sj starting in s before returning to state s. in the process of solving sj  the q-value of action a in s may only decrease  so that it may happen that  before we are done solving sj  a does not appear as optimal in s anymore. the algorithm presented above will not detect this and singlemindedly continue solving sj until the greedy policy starting in s is known  which can be highly inefficient.
　this issue can easily be addressed under an additional hypothesis that is satisfied in the hierarchical planning context described above and that could easily be relaxed to deal with a more general case. we assume that each action either does not change the partition subset  in the case of hierarchical planning  this holds true for all primitive actions a （ a   or it leads with certainty to a single state belonging to a different subset  this is the case of control passing actions μi and abort . then  we can modify the algorithm by adding a threshold parameter τ to the function solve s s  so that  when the value of s falls below τ during the solution of s  the function exits. in the initial call to solve  line 1 of alg. 1   the threshold parameter is set to  ±  so that optimization will be pursued until its end. later calls  line 1 of alg. 1  are performed in the following way: while computing the value of a state  lines 1 and 1 of alg. 1   we record the q-value of the best action that does not change the partition subset  primitive action   the q-value of the best action that induce a change of subset  control-passing action   and the q-value of the second best control-passing action. if a control-passing action appears optimal and we enter the loop in lines 1 to 1  then the threshold parameter τ used for the call to solve   in line 1 is set to the q-value of the best primitive action  or the second best control-passing action  depending on which is greater. in this way  solve aborts the solution of a child subset as soon as the action leading into it does not appear optimal anymore. note that the outdated marker is removed  line 1 of alg. 1  only if solve completed.
by-passing levels: two of the operations of standard ao* require it to traverse up or down a large part of the explicit graph. the function expand   selects a node on the fringe of the greedy graph. this requires computing the fringe  which is done by following marked edges down from the root note. this operation is often one of the most costly.1 the function
update   also propagates information up the graph  when determining the greedy parents of a recently updated nodes  line 1 of alg. 1 . because hiao* performs the standard ao* operations only inside of a subset of nodes  it saves time on both operations. first  the search graph projected to each subset is smaller  so that the size of the fringe for that subset and the time to compute it is likely to be  much  smaller. of course  by doing this  we expand the most promising fringe node in a given subset  and not in the entire greedy graph as ao* does. so  we influence the order in which nodes are selected for expansion  which may have good or bad consequences. second  as explained before  hiao* postpones the propagation of some values from a subset to another other  and thus limits the propagationof informationup in the graph. to gain more leverage  hiao* may be augmented with macro-connectors that represent the effect of applying the greedy solution for a subset of nodes. macro-connectors are then used when solving other subsets  to accelerate the traverse of the graph. imagine  for instance  that u belongs to
si  and applying some action a leads from 
  and then applying a leads from we add an explicit edge between and we use it when solving si. by doing this  we build  in effect  a projection of the greedy graph on si. the new edge between helps us during the solution of si in two circumstances: when we compute the fringe  we can jump over a large number of states that flat ao* would have considered individually; and similarly when we determine the greedy parents of a recently updated node. creating and maintaining macro-connectors increases the complexity of hiao* slightly  but the efficiency gained compensates for this extra cost. indeed  our simulations showed that this is one of the major causes of the good performances exhibited by our algorithm.
1 application to oversubscription planning
we now focus on the class of problems that motivates this work  that is  oversubscribed planning problems. following  meuleau et al.  1   these problems are naturally modelled in the hierarchical planning framework presented above with a two-level hierarchy. there is a single root process m1 and multiple leaf/child processes mi  i = 1 ...n representing the different subtasks the agent can select to perform. for each subprocess mi  we define:
  x．i = xi ” x1 are the separator  shared  variables between m1 and mi. the shared variables include  but are not limited to  the shared resource levels. they may also include  for instance  the state of instruments used to perform several subtasks.
are the private variables of mi. typically 
they represent the state of advancement of the subtask.
  x1 i = x1   xi is the difference of m1 and mi.
the set of private variables of m1 is defined as
. we also define various classes of states: s = 1x  si = 1xi  s．i = 1x．i  si = 1xei  s1 i =
1 i.
　we restrict our attention to domain satisfying the reset assumption of  meuleau et al.  1 . the reset assumption states that whenever the process moves into a child sub-mdp  the state of the private variables of this sub-mdp is the same. it holds true in the rover domain because the rover must have its arm stowed and all of its instruments parked prior to any movement  and so  this is its configuration when it arrives at a new rock/subtask. moreover  actions of preparing the rock for a measurement  such as coring the rock  have to be redone if we abort this rock before completing the measure  because it is not possible to put the rover arm exactly at the place it was when the rock was cored. so  all intermediate work towards the goal is lost once we move to another rock. note that variables that are not private to the child sub-mdp  such as resource levels  are not reset to their initial value when we abort the subtask. note also that this assumption is not as restrictive as it may look  since the user may modify the sets x．i if needed: if some intermediate work may be preserved when we abort a subtask mi before its completion  then the fluent representing this intermediate state should be moved from x i to x．i. however  hiao*  as well as the algorithms in  meuleau et al.  1   work better if the separation sets are as small as possible.
　under the reset assumption  the space of reachable states is naturally partitioned into a hierarchy of subsets. the root subset s1 represents the states where all subtasks are in their initial condition. for each subtask i and each state s1 i （ s1 i  there is a child subset si s1 i  containing all states where  1  mi is not in its initial condition   1  the private variable of every other subtasks  have their initial value  and  1  the variables in x1 i are equal to s1 i  and so  s1 i represents the context in which subtask i is called. all other states  for instance  states where two subtask are not in their initial state  are not reachable. the abort-update algorithm of  meuleau et al.  1  is an instance of asynchronous policy iteration  bertsekas and tsitsiklis  1  that that exploits this property. here  we stress that this hierarchical partition may serve as the basis to an implementation of hiao*. in a sense  hiao* is to abort-update what standard ao* is to
policy iteration.
reusing macro-actions: as explained above  when we apply hiao* on an oversubscribed planning problem  there is a subset si s1 i   for each subtask mi and each context s1 i in which mi may be started. for a fixed i  the dynamics within
si s1 i  do not depend on the context s1 i. the latter influences the value of states where we transit when we abort the subtask  the exit values   and so  the optimal policy  but not the structure of the explicit graph representing si s1 i . therefore  if we have computed part of the explicit graph for a given context  we can reuse/copy it when we want to solve the same subtask in another context. we might need to expand this graph further  because different exit values may induce different policies. similarly  this seed may contain some nodes that we would not have created if we started the solution of subtask i in the new context from scratch. however  we could benefit from this because much of the work of expanding the graph is already done.
optimality: hiao* finds the optimal solution within the predefined hierarchy  which is the definition of hierarchical optimality andre and russell  1 . as shown in  meuleau et al.  1   if the problem satisfies the reset assumption  then there is an absolute optimal policy that can be encoded in the hierarchy defined above. therefore hiao* finds the optimal policy if the reset assumption holds. if the reset assumption does not hold  hiao* based on the hierarchy defined above finds an hierarchical optimal policy  which may be of lesser value than an absolute optimal policy. however  we can use a different hierarchical representation of the problem that would guarantee absolute optimality. this is achieved by defining a subset si s i  for each subtask mi and each state s i （ s i = 1x xi  note that  now  the context also includes the private variable of subtasks mj  for all
1 experimental evaluation
the goal of our empirical evaluation is to show that the fundamental structural changes of hiao* are beneficial. for this purpose  we used several problem instances from a complex planetary rover domain. in this domain  an autonomous rover must navigate in a discrete graph representing its surrounding and the authorized navigation paths  and schedule observations to be performed on different rocks situated at different locations. each action as an uncertain positive resource consumption and a probability of failing. the domain also contains a significant amountof uncertaintycoming from the tracking mechanism: to perform some measurement on a rock  the rover must be tracking this rock; and to navigate along a path  it must be tracking one of the rocks that enables following this path. however  the rover may randomly loose track of some rocks while navigating along some path  and there is no way to re-acquire a rock once the rover lost track of it  the probability of losing track of a rock depends on the rock and the path followed . each problem instance is naturally decomposed in a two-level hierarchy where the root task is responsible for navigating in the graph  tracking the rocks  and performing some measures that are not bound to a rock  such as taking a panoramic camera picture. each subtask represent a rock and may possibly contain several goals  several

figure 1: execution time on a sample rover problem.
measures may be taken on the rock .
　our test problems are far out of reach of standard flat mdp solvers such as value iteration  as well as hierarchical algorithms based on flat mdp solvers such as the abort-update algorithm of  meuleau et al.  1 . for instance  the problem used in fig. 1  with an initial resource of 1  as a total number of 1 fluents  and so 1 states  which is way above what a standard mdp solver can handle. once the problem is hierarchically decomposed  the root mdp contains 1 fluents  and so  1 states   and each sub-mdp contains 1 fluents  1 states   and so  it cannot be solved by abortupdate. therefore  hiao* outperforms approaches based on flat mdp solvers. this is due to the well-known advantage of reachability and heuristic information that focus the search only on the relevant parts of the state space.
　it is more interesting is to compare hiao* with standard ao*  which uses reachability and heuristic information  but does not leverage from the hierarchical structure of the domain. figure 1 presents a typical performance curve. it was obtained using a problem instance involving 1 rocks  1 goals per rock  and 1 goals in the root process  panoramic images . it shows the evolution of the solution time of standard ao* and hiao* as a function of the initial resource available to the rover. although the complexity of the problem increases badly with the initial resource  this increase is much less in hiao* due to the savings during value updates and graph traversal. very similar results were obtained with nearly all problem instances that we tried  the advantage of hiao* increasing with the problem size. the only exceptions are tiny problem instances that are solved in fraction of seconds by both algorithms.
　the results depicted above were obtained using a version of hiao* that implements delayed propagation  as described above  and that uses macro-connectors to by-pass subprocess states when solving the root process. these two principles are pretty general and can be implemented in any instance of ao*  provided that a hierarchical partition of the state space is defined. however  the algorithm used does not implement macro-action re-use  which is more specific to oversubscription planning. we tried macro-action re-use but did not ob-
 bonet and geffner  1 bonet  b.; and geffner  h. 1. labeled rtdp: improving the convergence of real-time dynamic programming. in proceedings of the thirteenth international conference on automated planning and scheduling  1.
menlo park  calif.: aaai press. dean and kanazawa  1 dean  t.; and kanazawa  k. 1. a model for reasoning about persistence and causation. computational intelligence 1 :1. hanks and mcdermott  1 hanks  s.; and mcdermott  d.v. 1. modeling a dynamic and uncerain world i: symbolic probabilistic reasoning about change.
artificial intelligence 1 :1. hansen and zilberstein  1 hansen  e.a.; and zilberstein  s. 1. lao*: a heuristic search algorithm that finds solutions with loops. artificial intelligence
1-1 :1. meuleau et al.  1 meuleau  n.; brafman  r.; and benazera  e. 1. stochastic oversubscription planning using hierarchies of mdps. in proceedings of the sixteenth international conference on automated planning and scheduling  1. menlo park  calif.: aaai press. nilsson  1 nilsson  n.j. 1. principles of artificial intelligence. palo alto 
calif.: tioga publishing company. puterman  1 puterman  m.l. 1. markov decision processes: discrete stochastic dynamic programming. new york  ny: wiley. sutton et al.  1 sutton  r.s.; precup  d.; and singh  s.p. 1. between mdps and semi-mdps: a framework for temporal abstraction in reinforcement learning. artificial intelligence 1-1 :1. amir and englehardt  1 amir  e.; and englehardt; b. 1. factored planning. in proceedings of the eighteenth international joint conference on artificial intelligence  1. san francisco  calif.: morgan kaufmann. andre and russell  1 andre  d.; and russell  s. 1. state abstraction for programmable reinforcement learning agents. in proceedings of the eighteenth national conference on artificial intelligence  1. menlo park  calif.:
aaai press. barto  et al.  1 barto  a.g.; bradtke  s.j.; and singh  s.p. 1. learning to act using real-time dynamic programming. artificial intelligence 1-1 :1. bertsekas and tsitsiklis  1  bertsekas  d.p.; and tsitsiklis  j.serve any significant change in the solution time with this option turned on  we sometimes observed a very small decrease in the performances . in a sense  this is pretty encouraging  as the most general modifications to standard ao* search turn out to be also the most efficient.
1 conclusions
we showed how ao* can be modified to make use of hierarchical decompositions of a domain. this leads to the first forward search algorithm that explicitly deals with hierarchical domains. we analyzed the relationship between standard ao* and the hierarchical version in terms of its effect on the order of propagation and the introduction of shortcuts in the form of edges that by-pass levels. although there is no formal guarantee that these modifications will induce an actual performance improvement  our experimental evaluation using over-subscribed planning problems indicate that they are  indeed  beneficial. therefore  this paper outlines research directions that could benefit a wide variety of application domains  and possibly other forward search algorithms. in future work  we shall examine an additional possible benefit of hierarchical decompositions: the ability to formulate specialized and more accurate heuristic functions.
acknowledgements
this work was supported by nasa intelligent systems program under grant nra1. this work was performed while ronen brafman was visiting nasa ames research center as a consultant for the research institute for advanced computer science. ronen brafman was supported in part by the paul ivanier center for robotics research and production management and the lynn and william frankel center for computer sciences at ben-gurion university.
