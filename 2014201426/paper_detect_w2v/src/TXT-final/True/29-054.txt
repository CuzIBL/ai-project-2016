 
propositional strips planning problems can be viewed as finite state automata  fsas  represented in a factored form. automaton minimization is a well-known technique for reducing the size of an explicit fsa. recent work in computer-aided verification on model checking has extended this technique to provide 
automaton minimization algorithms for factored fsas. in this paper  we consider the relationship between strips problem-solving techniques such as regression and the recently developed automaton minimization techniques for factored fsas. we show that regression computes a partial and approximate minimized form of the fsa corresponding to the strips problem. we then define a systematic form of regression which computes a partial but exact minimized form of the associated fsa. we also relate minimization to methods for performing reachability analysis to detect irrelevant fluents. finally  we show that exact computation of the minimized automaton is np-complete under the assumption that this automaton is polynomial in size. 
1 	introduction 
in this paper  classical planning refers to the propositional variant of strips planning  fikes and nilsson  1 . classical planning is based on a factored representation for describing planning domains in terms of rules that specify how the dynamic features of the domain  called fluents  change over time. classical planning problems can be viewed as finite state automata where states correspond to assignments to fluents  the rules compactly encode the state-transition function  and the task is to determine if it is possible to reach some state satisfying the goal from the initial state. 
　there are well-known algorithms for reducing the size of explicitly represented fsas by collapsing groups of states that are bisimulation equivalent  i.e.  states that behave the same1 under every action sequence  hopcroft  
1
two states behave the same under an action sequence 1; paige  1 . these automaton minimization algorithms rely  however  on the explicit representation of the fsa being minimized. recent work on model checking in the computer-aided verification community  burch et a/.  1  has explored the problem of automaton mini-
mization for fsas represented in factored forms. 
　given a classical planning problem  fsa minimization techniques compute a  possibly  smaller fsa that captures all the essential information in the problem formulation; we call this fsa the minimal model for the planning problem. the states of the original fsa are partitioned into blocks which constitute the  aggregate  states of the minimal model. this paper explores the relevance for classical planning of the recent model checking work on automaton minimization for factored fsas. 
　fsa minimization is in general much more aggressive than classical planning solution techniques. in minimization  states are grouped together based on identical behavior under all sequences of actions. in contrast  in classical planning solution techniques  we are interested primarily in the goal connectivity and distance to the goal of different states  and are not generally interested in differentiating states based on other variations in behavior {e.g.  two states that differ only on the basis of action sequences that don't involve goal states may be equivalent for the purpose of planning . 
　nevertheless  the algorithms for minimizing a factored fsa bear a significant resemblance to the classical planning technique of goal regression.1 the basic step in each algorithm is to find the preimage of a set of states under an action-that is  those states that can reach the given set in one step under the given action. this similarity is the basis for our comparisons. 
　to assist in our comparisons  we define the new concepts of partial and approximate minimization. a partial minimization of an fsa is a partition of the states of the fsa which is strictly coarser than the minimal partition-that is  a partition that can be refined into the minimized fsa partition. an approximate partial minimization is a partial minization except that in place 
if they both reach accept states or both reach reject states under the sequence. 
     1  goal regression is just backward chaining search from a goal  or subgoal  representing a set of states. 
	givan & dean 	1 


1 	planning and scheduling 

node and action label  there can be only one arc from that node with that action label. note that such a diagram describes a deterministic finite state automaton. we use the term  model  for a state transition diagram that captures the dynamics of a planning problem: 
definition 1 we say that a state-transition diagram is a model for a classical planning problem if 
1. the nodes form a partition of the planning state space  and 
1. for any state q  node v1 containing q  node v1  and action 
 a  fa q  is in v1 if there is an arc from v1 to v1 labelled  and 
 b  fa q  is in v1 only if there is an arc from v1 to v1 labelled 
if conditions 1 and 1 a  hold without condition 1 b  we say that the diagram is a partial model. if condition 1 is additionally relaxed to merely require the nodes to cover the state space  but perhaps overlap   we say that the diagram is an approximate partial model  sometimes abbreviated  approximate model  . 
note that there can be more than one model for a given planning problem  corresponding to different partitions of the domain  though in general most partitions cannot be used to define a model. every modelof a problem contains all the information in the original problem: models smaller than the original problem can be viewed as compact forms of the original problem. it is a theorem that for every problem there exists a minimal model-a model with a partition p such that every other model uses a refinement of p. figure 1 depicts the model for a particular planning instance with a degenerate partition consisting of singleton blocks  and figure 1 a  shows the minimal model for the same problem. reachability queries on the minimal model have the same answers as those on the original model. 
　we note that every model is associated with a partition of the state space-that partition formed by the nodes of the model. similarly  any partition induces at most one model  some partitions cannot be used to form models . we will be somewhat free in referring to models as partitions. we also use a particular partial order on partitions  and hence on models : we say that a partition p1 is coarser than a partition p1 if p  can be refined into p1-and we say that p1 is finer than p . 
   a partial model is a diagram in which every arc is  correct   i.e.  corresponds correctly to the planning problem  but may have missing arcs as well as blocks which need to be refined. we call a partial model generic for a planning problem if it is coarser than the minimal model for that problem  so that further refinement could generate the full minimal model. the minimization process described below computes a series of generic partial models leading eventually to the minimal model. an approximate partial model is additionally allowed to be undecided about which block certain states will fall into  by having blocks overlap . an approximate model can always be converted into a partial model by disambiguating the overlaps-i.e.  shrinking blocks until they are disjoint. if an approximate model can be so converted into a generic partial model  we also call the approximate model generic. 
the model minimization a l g o r i t h m . 	let b and 
c be blocks of partition p and let a be any action. we define the split operation as follows 

where p' is p with c replaced by1 c and c  defined by 

lee and yannakakis  describe a model minimization algorithm which uses the split operation to compute the minimal model for an fsa in factored form. in its application to planning  the algorithm begins with an initial partition p1 consisting of two blocks  those states that satisfy the goal and those that don't. the algorithm then repeatedly chooses some b  c  and a and computes a refined partition  = split #  c  pi   . when no additional refinement is possible  the resulting partition induces the minimal model of the problem. this algorithm calls split polynomially many times in the size  number of blocks  of the final partition. if we want to compute the most compact representation of each block in the partitition  then split is np-hard. 
　several variations on model minimization are relevant for this work. first  lee and yannakakis describe a variant we will call reachable model minimization which computes a model that is minimal for the states reachable from the initial state  but arbitrary for other states-space precludes making this notion more formal here. second  it is possible to replace the split operation with operations that do more splitting than split1. we call a block-splitting operation spl1t' #  c  p    adequate if it produces a partition of c that refines split b  c  p   . performing model minimization with an adequate splitting operation produces a  possibly reduced  model which is not necessarily minimal. figure 1 b  shows a reduced model generated using an adequate but nonoptimal splitting operation  fsplit  which we define later. 
complexity of minimization. there are planning problems for which the shortest solution is exponentially long in the length of the problem description  bylander  1 . this fact directly implies that there are problems with exponentially large minimal models  and therefore that minimization must take at least exponential time. however  one might hope that in those cases where the minimal model is  small   minimization could find it quickly. unfortunately  by a reduction from sat  we are able to show that even when the minimal model is polynomial in size  minimization is np-hard. 
1
 if either c or c  is empty  then split b  c  p  = p. 
     1  such operations may be more efficient  as we discuss below  which is why we would do this. 
	givan & dean 	1 


figure 1: reduced models for case in which the goal is 
a:  a  minimal model for a general representation and  b  minimal model for fluentwise representation. 
theorem 1 given a bound and a planning problem whose minimal model is polynomial in size  the problem of determining whether there exists a model of size no more than the bound is np-complete. 
1 	regression 
in this section  we argue that classical regression computes an approximate partial model of the planning problem. but regression doesn't compute just any partial model-it computes a partial model capturing certain useful information1. we say that a partial model captures solvability for an action sequence if every path that achieves the goal with that action sequence is represented in the model: 
definition 1 a partial model captures solvability for action sequence if every path 
such that achieves the goal has a corresponding path in the model such that each qi is in block 
we say that an approximate partial model captures solvability for an action sequence if it can be disambiguated into a partial model which does. we also refer to capturing solvability for a set of action sequences  meaning capturing solvability for each sequence in the set. 
　the key to understanding regression as minimization lies in thinking of the subgoals generated by regression as representing sets of states  those states that satisfy the subgoal . each such set of states shares a simple property: it is the set of all states which can reach the goal under a particular action sequence  the reverse of the sequence of actions under which the goal was regressed to get that subgoal . a regression search tries different action sequences  for each one generating a subgoal corresponding to the set of states which achieve the goal under that sequence. each new subgoal/set of states is generated by a regression step from a previous subgoal/set of states. if a subgoal is ever true of the initial state  then the search terminates. 
　note that different subgoals could be true of the same single state-i.e.  the sets of states described could over-
1
　　every planning problem admits the trivial partial model built from the trivial partition into singleton sets with no arcs  as well as the trivial partial model built from the goal/non-goal partition  again with no arcs. 
1 	planning and scheduling 
lap. the sets of states corresponding to the subgoals can be viewed as nodes in an approximate partial model  where the regression steps which generated the states correspond to arcs in the model. because the subgoals may overlap  the partial model is approximate  but each regression step locally preserves the fact that the diagram being constructed is a generic partial model which captures solvability for the action sequences which have been regressed. the following theorem can be proven by induction on the number of regression steps taken. 
theorem 1 at any point  the regression graph is a generic approximate partial model which captures solvability for the action sequences considered by the regression search to that point. 
   the model minimization algorithm described in the previous section also takes simple local steps  analogous to regression steps  using the split operation to construct sets of states which behave uniformly under selected action sequences. at the completion of minimization  the blocks of the resulting partition correspond to sets of states which behave the same under all action sequences. but along the way  the partition constructed at each step forms a partial model in which states in the same block behave the same only for selected action sequences. just as regression search involves a search strategy to select which regression to do next  model minimization must also select which split step to do next- in each case extending the set of action sequences which have been explored. minimization strategies which always split the block containing the initial state correspond closely to regression strategies.1 
　the central distinction between simple regression and minimization is that minimization constructs a series of generic partial models whereas regression constructs a series of generic approximate partial models. the regression subgoals may overlap considerably  whereas minimization at all times maintains a partition. for some problems  this difference illuminates a potential inefficiency in regression-the same state can be  regressed  many times under the aegis of different but overlapping subgoals. we introduce a variant of regression which we call systematic regression to eliminate this difference. 
　in systematic regression  each subgoal must be disjoint from all previous subgoals. in order to achieve this  the regression search must maintain a boolean formula describing the set of states which have not yet been covered by a subgoal1. each new subgoal must be conjoined with this boolean formula to ensure its disjointness with previous subgoals. just as in simple regression  a search strategy controls the order of the regression steps taken- 
1
　　 the reachable model minimization algorithm referred to in the previous section does exactly this-in its efforts to construct a minimized reachable model it will split only the block containing the initial state. 
1
　　 this set of states corresponds to the block containing the initial state during minimization  and can also be viewed as the set of states which have not yet been found goalconnected by regression. 

figure 1: two trees of regressed formulas for the problem shown in figure 1:  a  computed using systematic regression and  b  computed using standard regression. 
systematic regression differs from simple regression only in that the individual regression steps are modified to maintain the disjointness of the subgoals generated. figure 1 shows the regression graphs generated by both systematic and simple regression for the example problem shown in earlier figures. 
theorem 1 the regression graph generated by systematic regression at any point is a generic partial model which captures solvability for the action sequences considered by the regression search to that point. 
   if the boolean formula for a subgoal is unsatisfiable  systematic regression must stop searching below that  subgoal-it is this pruning that reduces the number of subgoals generated compared to simple regression. for some problems  systematic regression will generate exponentially fewer subgoals than simple regression  due to the elimination of overlap. for an example of this phenomenon  consider a planning problem with n stages where at each stage there are two choices of action sequence which result in the same state in the next stage  via different paths . minimization will construct o n  blocks on such a problem  but regression will construct 1n  subgoals. unfortunately  systematic regression depends on an unsatisfiability test at each node which is np-hard; in practice the usefulness of systematic regression will be limited to those cases where there is substantial overlap between subgoals  i.e.  many different action sequences have similar effects  and will depend on the crowing efficiency of the best known satisfiability testers  selman et al.  1 . 
theorem 1 unlike simple regression  systematic regression never generates more subgoals than there are blocks in the minimal model. 
1 	reachability analysis 
computing the minimal model for a planning problem relies critically on the split operation  which we've indicated can have exponential cost. one way around this problem is to compute instead a refinement of the minimal model by using a variant of split which is less expensive and does at least as much block splitting. 
     1  allowing excess splitting can be cheaper because it relieves the splitting operation of the task of deciding whether such a refined model has many of the same advantages of the minimal model: reachability in the refined model still captures reachability in the original problem  for instance. the disadvantage to computing an overly refined model is that the model may have many more states than the truly minimal model  giving up the advantage of reduced size that was originally sought. nevertheless  there are problems for which a significant problem size reduction can be gained using an adequate but nonoptimal split operation. 
　to guarantee that the resulting model is a refinement of the minimal model  the splitting operation used must be adequate: it must do at least as much splitting as split would have done. the option to do extra splitting allows us to consider using a representation for partitions which cannot represent every partition: if a split is called for which we cannot represent  we can always perform additional splitting to get a representable partition  the representation must have at least this property  though . one such partition representation is what we call a fluentwise partition representation. given a set of fluents x1  consider the partition of the state space where two states are in the same block exactly when they agree on the values of the variables in x . we call any partition which can be represented in this manner a fluentwise partition. note that most partitions of the state space are not fluentwise partitions. 
　we now define an adequate split operation fsplit for manipulating fluentwise partitions. given fluentwise partition p  blocks b and c from p  and action a  we define fsplit b  c  p  to be the coarsest fluentwise refinement of split p  c  p  . fsplit is easily computed in time linear in the size of its inputs. using fsplit in place of split  the model minimization algorithm can find a  possibly  reduced model which refines the minimal model in time polynomial in the original problem size.1 the model found may of course have exponentially more states the minimal model. a model found by fsplit minimization is given in figure 1 b . 
　fsplit minimization is a minimization-oriented description of a familiar and simple reachability analysis which can be used to simplify propositional planning problems. specifically  a simple transitive closure can determine the set of fluents relevant to the problem  which is the least set p of fluents containing every fluent which appears in the goal description and every fluent which appears in the precondition for some action rule whose postcondition contains a fluent in p. the set of relevant fluents can easily be computed in polynomial time. once this set is computed  the problem can be reduced by removing the irrelevant fluents along with any actions whose rules mention them. the resulting state space is exactly the blocks of the partition found by fsplit 
to split-the most trivial variant of split would just split 
fully into a partition of singleton sets. 
   1  note that the fluentwise partition representation is an implicit representation; the final partition can have exponen-
tially many blocks but can still be constructed in polynomial time. 
	givan & dean 	1 
minimization  
1 	related work 
burch et al.  is the standard reference on symbolic model checking for computer-aided design. our algorithms and analyses were primarily motivated by the work of lee and yannakakis  and bouajjani et al. . backstrom and klein   bylander   
and gupta and nan  l1  provide basic results concerning the complexity of strips planning and special cases. etzioni  describes a particular algorithm for reachability analysis and provides a survey of related techniques. 
　in  dean and givan  1  we show how model minimization can be used to solve implicit  or factored  markov decision processes  mdps  with very large state spaces  and prove that our model minimization based algorithms are asymptotically equivalent to existing methods  e.g.   boutilier et a/.  1   that operate on implicit mdps. in  dean et a/.  1  we show how model reduction techniques can be used to trade time for space in computing approximately optimal solutions to markov decision processes. finally  in the longer version of this paper  we show how the methods of this paper can be used to understand the advantages of the explanationbased reinforcement learning algorithm developed by di-
etterich and flann . 
1 	conclusions 
in this paper  we demonstrate how traditional methods for solving propositional strips planning problems can be viewed in terms of finite automata  model  minimization. given a finite automaton whose statetransition function is defined by a set of strips rules  we show how regression search and simple reachability analysis can be viewed as methods for constructing a finite automaton of reduced size. we also show how existing model minimization methods can be applied to solve propositional planning problems and determine that solving such problems in the case in which the minimal model is polynomial in the size of the input is npcomplete. 
　it should be noted that there are potential pitfalls in extrapolating from recent success in computer aided verification using model minimization techniques to possible gains in tackling strips problems. the verification problems were rendered easier in part due to symmetries in hardware and software that result in significant aggregation in the state space. similar sorts of symmetry may exist in some factory domains but whether or not the resulting reductions are enough to render the problems tractable remains to be seen. 
