
we introduce an approach to autonomously creating state space abstractions for an online reinforcement learning agent using a relational representation. our approach uses a tree-based function approximation derived from mccallum's  utree algorithm. we have extended this approach to use a relational representation where relational observations are represented by attributed graphs  mcgovern et al.  1 . we address the challenges introduced by a relational representation by using stochastic sampling to manage the search space  srinivasan  1  and temporal sampling to manage autocorrelation  jensen and neville  1 . relational utree incorporates iterative tree induction  utgoff et al.  1  to allow it to adapt to changing environments. we empirically demonstrate that relational utree performs better than similar relational learning methods  finney et al.  1; driessens et al.  1  in a blocks world domain. we also demonstrate that relational utree can learn to play a sub-task of the game of go called tsume-go  ramon et al.  1 .
1 introduction
this paper introduces a method that combines the expressive power of a relational representation with the learning power of reinforcement learning  rl . the goal is to autonomously learn a relational state space approximation while simultaneously learning to act optimally. a relational representation enables an agent to reason at a higher level  which can allow an agent to learn in more difficult problems  kaelbling et al.  1 . rl is an ideal technique for real-world control because it can learn to achieve a goal without being told how to accomplish it. there has been considerable recent interest in combining these techniques  tadepalli et al.  1; van otterlo  1 .
　the primary contribution of this paper is the introduction of an online rl method  relational utree  that can autonomously construct its own tree-based function approximation using a relational representation. utree  mccallum  1  develops its own tree-based state space  allowing it to focus on the most important aspects of observations and to ignore irrelevant ones. traditionally  a state representation is either designed by the user or learned from the policy.
　learning in a relational representation introduces two key challenges. the first is the exponential growth in search space and the second is that relational environments tend to have a high degree of autocorrelation. this has been shown to cause a selection bias that makes distinctions to appear useful when they are not  jensen and neville  1 . relational utree compensates for the size of the search space by using stochastic sampling  srinivasan  1 . autocorrelation violates the independent and identically distributed assumption made by many statistical techniques. we compensate for the effects of temporal autocorrelation by temporally sampling.
　we separately address the need to adapt to changes in the environment by incorporating efficient tree restructuring  utgoff et al.  1 . this allows relational utree to create more compact trees with the same representational power and helps to prevent overfitting in stochastic environments.
　the most similar works are the g  finney et al.  1; chapman and kaelbling  1  and tg algorithms  driessens  1; driessens et al.  1 . there are several major differences between tg  which is based in part on galgorithm  and relational utree. the primary difference is that relational utree can dynamically restructure its trees while tg must build a new tree from scratch. this allows relational utree to adapt to changes in the environment and to correct early mistakes made in the tree. while relational utree uses graphs to represent observations  tg uses first order logic predicates. in addition  tg creates a separate policy tree  called a p-tree  while relational utree derives its policy from the q-value tree. finney et al.'s  approach is also based on g algorithm but uses a deictic representation  while relational utree makes use of a full relational representation and incorporates tree restructuring. we empirically compare the performance of relational utree to these approaches on blocks world environments.
1 algorithm description
the relational utree algorithm follows the utree algorithm closely. we use the standard rl and partially observable markov decision process  pomdp  notation where  at each time step t  the agent executes an action at （ a  and receives an observation ot+1 （ o  and a reward rt+1 （    sutton and barto  1; kaebling et al.  1 .

figure 1: a  example blocks world configuration. b  partially observable blocksworld1  finney et al.  1  observation. c  fully observable blocksworld1  driessens et al.  1  observation.
an observation takes the form of an attributed graph g =
. v is the set of all objects in
the environment  represented by vertices in the graph and e is the set of all relationships  represented by edges  mcgovern et al.  1 . a v  and a e  are the set of attributes for the vertices and edges respectively  the elements of which are discrete or real valued attributes. a v  and a e  may contain zero or more elements. t v  and t e  are required discrete valued types for vertices and edges. example observations for blocks world are shown in figure 1. some attributes and relationships are omitted for readability. the graphical representation used does not place individual identifiers on objects  but instead objects are identified by their type  attributes  and relationships to other objects. this property of graphical representations is advantageous for generalizing concepts.
　our relational utree description uses mccallum's  notations. we refer to the set of distinctions that lead to a tree node and the state represented by a leaf node as s. a transition instance  tt = tt 1 at 1  t  t   represents one step of the agent's experience. the set of instances contained in a leaf node s is denoted t  s   and the set of instances contained in a leaf node s where the next action is a is t  s a . the time ordered set of all transition instances isthe leaf node to which a specific transition instance belongsh = {t1 t1 ... t|h|}. is denoted by l tt .
1 relational utile distinctions
we refer to a distinction as being utile if and only if the distinction statistically separates the set of transition instances so that the agent is better able to predict reward. the sets of possible distinctions are: object ex-
variable memories empty list
 list of all blocks 
 list of all blocks 
 one green block 
figure 1: example variable memory creation as the instance from figure 1c is dropped down the tree.
istence { x h  | x （ t v  h （ n}  relationship existence   and
attribute value { a  valuea o1 h  |  a valuea  （ a o1  o1 （ {m v “m e } h （ n}  where h is the history index  m is the memory  x is a parameter limiting the number of previous observations that can be considered  and n is the set of natural numbers.
　the variables o1 and o1 are pointers to variable memories. variable memories reference previous distinctions in s  allowing simple distinctions to be used to construct complex queries. for each type of distinction  the set of variable memories created when an instance is dropped down a node with that distinction is given by: {v （ vi | t v  = x} for object distinctions  { e v1 v1  （ ei | t for relationship distinctions  and {p （ vi “ei |  a valuea  （ a v  a = x valuea =y} for attribute value distinctions.
　figure 1 shows an example of how relational utree uses variable memories. as the observation shown in figure 1 c  falls down the root node  blocks are added to the variable memory. the second node selects blocks from this list with  color = green  and saves the matches.
　relational utree allows static objects to be referenced so that their non-static attributes may be accessed. the set of static objects is defined as s =th vi. a focal object  f （ v  can be incorporated to allow an agent to reason deictically. let m v n  be the set of object variable memories for the node n. at the root node  nr  m v nr = s“{f}. the set of object variable memories created by the distinction at a given node  n  is denoted m v n . if we let np be the parent node to n  then the set of object variable memories at any node  n  is defined as m v n = m v np “m v np . we similarly define m e n   given m e nr = 1/.
1 the relational utree algorithm
the relational utree algorithm works as follows:
1. create a tree with no distinctions. initialize t  s  = 1/ and h = 1/.
1. take one step of experience in the environment. chooseεthe actionprobability of choosing a random action. record theat 1 to be the policy action of l tt 1   with experience as tt = tt 1 at 1  t  t and h = h “{tt}.
using standard decision tree methods  drop tt down the tree. save tt to the leaf node  l tt = s  setting t  s = t  s “{tt}. mark all tree node n （ s as stale  where a stale node indicates that the distinction at that node may need to be changed during restructuring.
in some environments  observations ot and ot+1 are autocorrelated. for example  in the blocksworld1 environment shown in figure 1  c   the objects and relationships will remain largely the same regardless of the next action performed. this is an example of temporal autocorrelation  and can cause a feature selection bias  jensen and neville  1 . in these situations  we remove autocorrelation through temporal sampling. every c steps  tt is forgotten  where c is a user defined value.
1. with the leaves of the tree representing the states  perform one step of value iteration using equations 1 - 1. the equations for estimated immediate reward and estimated probability of arriving in state s after executing action a in state s are given in equation 1 and 1 and directly follow mccallum's equations.
q 	 1  s
u s = maxq s a  a（a
	‘	r 1 t
r （t  s a  i	 1 
pr
1. update the tree every k steps by first ensuring the quality of current distinctions  followed by expanding the tree by adding new distinctions at the leaves. all stale tree nodes n are updated as follows.
 a  first  stochastically generate a set of distinction trees Φ. include the existing distinction tree  φn  in the set Φ  with Φ = Φ“{φn}. a distinction tree is made up of one or more distinctions on a set of instances  organized into a tree structure. we consider distinction trees with depth up to some constant k  and consider larger depths only if no utile distinction trees are found. each distinction tree φ （ Φ defines a set of fringe leaf nodes l.
for each fringe leaf node s （ l  the set of expected future discounted rewards for s makes up a distribution δ s  given by equation 1  mccallum  1 . δ s = {rti +γu l ti+1   | ti （ t  s }  1 
calculate the kolmogorov-smirnov distance between each pair of distributions  denoted ks δ1 δ1 . let pφ be the set of these p-values  given by equation 1.
	pφ = {ks δ si  δ sj   |  si sj （ l}	 1 
choose the best distinction tree from among Φ and the current distinction tree  φn  using equation 1.
		 1 

figure 1: let n be the current node  and c n  = {n1 n1} denote the children of n. a  φn1 = φn1 = φ. perform tree transposition by setting n and . b   and c.
reclassify the instances t  n1  using the n1 subtree.	c 
c n1  = c n1  = 1/. set   and use φ to reclassify the instances t  n1 “t  n1 
if there is no pbelow the user specified value  then n is pruned from the tree. we used p = 1 for this paper. otherwise  φn is replaced by φ through a series of tree transpositions. for distinction trees of depth greater than one  the distinctions are 'pulled-up' one at a time  beginning with the root distinction.
 b  once the best distinction tree at a given node is determined  the tree is restructured following utgoff et al. . if the current distinction at n is already the best  φn   then we are done. otherwise  a recursive depth first traversal of the tree is applied until one of the base cases  shown in figure 1  is reached. at this point  the utile distinction  φ  is  pulled-up  by recursively performing the tree transposition steps shown in the figure. after a single  pull-up  has been performed  the next base case in the tree is addressed until the best distinction tree  φ  is at the target node  n.
when the tree restructuring operation has completed for n  mark it as not stale. if the node has changed through tree restructuring  then mark all nodes in its subtree as stale. continue to apply step 1 to each stale child node of n. this process continues until no branches are stale  and the quality of the distinctions in the tree are ensured. finally  perform value iteration until convergence.
1. every k steps  expand the tree at the leaves. for each leaf node of the tree  s  determine the best distinction tree for the instances at that node using the process outlined in step 1  a . if the new distinction tree is utile  then expand the tree by adding a subtree at the leaf s and dropping the instances t  s  down the new distinction tree. this removes s from the list of leaves and adds the set of leaves l to that list. continue expanding the tree until it is no longer utile to do so. perform value iteration until convergence after expansion is done.
1. repeat at step 1 until stopped.
1 stochastic sampling
we use stochastic sampling  srinivasan  1  to address the large space of possible distinctions introduced with a relational representation. srinivasan shows that if we can sample tests stochastically that we can look at only a small fraction of the total and still be highly confident in finding one that is among the best possible. the number of tests that must be sampled is given by n  where α is the probability of finding a test in the top  1〜k %  srinivasan  1 . the key to this equation is that the sample size does not depend on the number of possible distinctions.
　for this paper  we have used k = 1 and α = 1 to be 1% confident in finding a distinction in the top 1%. in this situation we only need to sample 1 distinctions. by gradually reducing k  we can move the search for distinctions toward an exhaustive search. with our values  it took under a second to expand a leaf node containing 1 instances. when we reduce k to 1  it takes two minutes to do the same expansion. similarly  with k = 1 the expansion time for the leaf node is almost 1 minutes. this demonstrates that an exhaustive search of the distinction space is not feasible. to compensate  we use stochastic sampling.
1 tree restructuring
in the early stages of learning  an agent will have only seen a fraction of the environment and may create a state representation that is not well suited to the true nature of the environment. to prevent the tree from over-fitting and to allow it to adapt to changing environments  relational utree implements online tree restructuring based on the iterative tree induction algorithm  utgoff et al.  1 . iterative tree induction ensures that the best split for the instances is used at each node of the tree  beginning with the root and working its way to the leaves.
　the original iti algorithm kept track of a list of statistics for each possible test at every tree node. because relational utree is instance based  this would be redundant. while iti looked at the list of statistics for a node to decide the current best test at that node  relational utree regenerates tests for the node and decides which is best directly. keeping track of all possible tests is not a practical solution in this situation because of the large search space for distinctions in relational environments. this large search space is a well known problem for inductive logic programming  dzeroski et al.  1 . although it is more computationally expensive to recompute the tests  restructuring leads to significantly smaller trees which reduces overall computation time.
1 experimental results
1 blocks world results
we apply relational utree to two versions of the blocks world domain. the first  blocksworld1  is a partially observable blocksworld task with low-level actions and two blocks  as in finney et al. . the second  blocksworld1  is a fully observable domain with high-level relational actions and three blocks  as in driessens et al. . both domains contain moveable colored blocks and unmovable table blocks.
example observations for both domains are shown in figure 1.
　in the blocksworld1 domain  the agent has a focus marker and a deictic marker. the agent perceives all attribute information for the focused object but none for the marked object. the marker is only observable if it is adjacent to the focus marker. for example  if the marker is below the focus block  then the agent will observe a block object  a marker object  and a relationship indicating the block object is on the marker object. the small difference from finney's domain arise from the translation from a deictic representation to a truly relational one. the goal is to pick up the green block  which requires first removing any blocks covering it. the actions available to the agent are identical to that of finney: move-focus direction   focus-on color   pick-up    put-down    marker-to-focus marker   and focusto-marker marker . the agent is given a reward of +1 for reaching the goal  a penalty of -1 for invalid moves and -1 per time step.
　the second domain  blocksworld1  is fully observable and the task is to stack the green block on the red block. the actions are move x y  for unique blocks x and y. as with driessens  the agent received a reward of 1 for reaching the goal in the minimal number of steps and a 1 otherwise.
　the performance of relational utree with and without tree restructuring for both domains is shown in figure 1  left panels . empirical performance is ε-optimal  with ε = 1  for both domains. these results are averages across 1 runs. because this is online performance  large changes to the tree's structure are reflected as temporary drops in performance. this happens less frequently as the tree converges.
　in the more difficult blocksworld1 domain  relational utree converges faster than finney's approach with more accurate results. after 1 training instances finney's performance was approximately 1% with final convergence to 1%. our method converges to 1% of optimal  due to the use of ε-greedy exploration methods  and does so within the first 1 steps.
　comparatively  the actions in the blocksworld1 domain are higher level which allows the agent to discover the goal much faster than in blocksworld1. the performance of driessens' tg algorithm on the same domain was comparable. tg does not explore the environment  and does not use an ε-greedy exploration method like we do. this allows their algorithm to converge to an average reward of 1  while we converge to an average reward per trial of 1.
　figure 1  right panels  compares the tree sizes with and without tree restructuring for the two domains. in both domains  performance is comparable but the average tree size is considerably smaller when tree restructuring is used. the agent is able to construct a smaller tree to capture the same amount of information because it can remove irrelevant information gained early in learning. the use of restructuring introduces an increased variance due to the temporary loss in performance directly following a large tree restructuring. however  smaller trees result in a significant improvement in running time.

figure 1: learning curves for relational utree in the blocksworld1 and blocksworld1 domains. tree sizes  with and withouttree restructuring  are shown for both domains on the right.
1 autocorrelation
to detect potential temporal autocorrelation  we used randomization on sets of observations. we perform 1 randomizations on this data  each time performing a kolmogorov-smirnov test. the test statistics form a distribution which can be analyzed to find the effective sample size  similar to what was done with χ1 by jensen and neville . if there is no autocorrelation  the effective sample size should match the actual sample size used in the tests.
　the kolmogorov-smirnov test compares two distributions  of sizes n1 and n1. the total size of the data  n1+n1  remains constant throughout  while the proportion of data split into either distribution can change from one distinction to the next. in our experiment  the actual number of instances varied but the proportions that a specific distinction created was held constant. we use p  to represent the relative sizes of the two distributions. by substituting p into the original equation for ks  given by  sachs  1   we obtain
r =  1〜d kαα 1  and ne = 1〜  1〜 pr p1   for the effective sample size ne. kα and dα are the critical values for the ks test.
relationship holding existsobject block existsaction move up1%
no sampling
 1%
drop every 1th
1%
drop every 1th
1%
figure 1: effective sample size relative to actual sample size with variable amounts of sampling.
　figure 1 shows the results of our detection and removal of the temporal autocorrelation in the blocks world domain. the top pie chart for each group is the effective sample size without sampling. the lower two pie charts are for removing every 1th or every 1th instance. effective sample sizes for an object existence  relationship  and action test are shown.
the effective sample size is dramatically lower without sampling and small amounts of sampling dramatically increase the sample size. tests on actions have no temporal autocorrelation because there is no direct correlation between what action will be performed and what the most recent action was. since autocorrelation causes a feature selection bias  jensen and neville  1   relational utree used sampling to remove the autocorrelation.
1 tsume go results
the tsume go domain is a sub-task of the game of go where stones have already been placed in different configurations. the task is to identify the best move for protecting the player's stones or capturing the opponent's stones. relational utree learns to play the best first move of a tsume go game. relational utree is trained on a set of 1 randomly sampled problems from the gotools database  wolf  1   and then tested on a set of 1 randomly sampled independent problems from the same database. the agent receives a reward between 1 and 1 for correct answers depending on the quality of the move and is penalized  1 for incorrect attempts. it is also penalized with  1 for invalid moves such as placing a stone on top of another stone or trying to move off the board.
　similar to ramon et al.'s  approach  we test relational utree's approximation by ranking moves using the qvalues. across 1 runs  relational utree averaged 1% accuracy on the test set after one move. ramon et al.'s  approach obtained 1% accuracy on a test set of 1 problems generated by gotools  after training on 1 problems. we are encouraged by our results and are exploring this domain in greater detail as future work.
1 discussion
due to the significant performance difference between finney and the large degree of similarities between our algorithm and finney's  it is useful to discuss why relational utree was able to overcome some of the problems previously reported. relying on observation history to disambiguate states and using state values to determine a policy before the states are disambiguated is a difficult problem that can be overcome through the use of tree restructuring. as the agent continues to learn  it carries older instances whose histories reflect outdated policies. as the agent's performance increases  the vast majority of new observations will conform to an increasingly consistent policy. given sufficient experience with the new policy  old observations will be in such a minority that splitting on them will no longer be statistically significant. another method would be to remove the oldest memories of the agent when they are likely to no longer be relevant but this approach requires another parameter.
　finney's approach uses a combination of the g-algorithm and utree to learn with a deictic representation. in their approach  once the tree has been expanded at a node  all the instance information that caused that split is dropped. this is in contrast to the approach taken by relational utree  which saves instances and continues to use all observations to decide if a split is utile. we hypothesize that this difference is the cause of their convergence issues. each split relies only on the most recent observations to see how the environment behaves. this could lead to incorrect assumptions if the current set of data is not representative of the entire environment.
　another problem encountered comes from the nature of pomdps. if the agent in blocksworld1 performed the action focus on color red   its history of observations would not tell it what state it was in. finney suggests that history based decision tree algorithms will never be able to fully disambiguate the state space. while it is true that the agent's history would not help it to know the current state of the world  this information is not required for optimal behavior. instead  the optimal behavior for this agent is to explore. balancing the need to explore to discover information about the environment  and seeking out potential rewards  is a primary property of pomdps  kaebling et al.  1 . as such  the optimal policy would explore the environment  thus providing the agent with the useful historical observations that it needs.
1 conclusions and future work
we have introduced relational utree  a significant modification to the utree algorithm that automatically creates a treebased function approximation in a relational representation. relational utree allows us to apply the advantages of the utree algorithm to inherently relational environments without the need to convert into propositional logic. we demonstrated that relational utree is able to learn in a blocks world domain and on the task of tsume go. relational utree addresses the exponential growth in search space of a relational representation using stochastic sampling. we also demonstrated that temporal sampling was necessary to address the issues of autocorrelation that arise in a relational representation. we separately show that incorporating tree restructuring into relational utree gives it the critical ability to learn compact representations and to adapt to changing environments.
　current and future work focuses on applying relational utree to more complex relational domains  including the full game of go. we are also exploring ways to improve the efficiency of storing and handling large numbers of observations. we are studying knowledge transfer and background knowledge using relational utree. the ability to approximate a state space independently of a human designer allows for many interesting future applications.
acknowledgements
we would like to thank the anonymous reviewers for their insightful comments. this material is based upon work supported by the national science foundation under grant no. nsf/cise/reu 1.
