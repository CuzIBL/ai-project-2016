collective object identification
	parag singla	pedro domingos
department of computer science and engineering
university of washington
seattle  wa 1  u.s.a.
{parag  pedrod} cs.washington.edu
　
　in many domains  the objects of interest are not uniquely identified  and the problem arises of determining which observations correspond to the same object. for example  in information extraction and nlp we need to determine which noun phrases refer to the same entity. when mergingmultiple databases  a problem of keen interest to many large scientific projects  businesses  and government agencies  we need to determine which records represent the same entity and should therefore be merged. this problem  first placed on a firm statistical footing by fellegi and sunter   is known by the name of object identification  record linkage  de-duplication and others. most approaches described to solve this problem are variants of the original fellegi-sunter model  in which object identification is viewed as a classification problem: given a vector of similarity scores between the attributes of two observations  classify it as  match  or  non-match.  a separate match decision is made for each candidate pair  followed by transitive closure to eliminate inconsistencies. typically  a logistic regression model is used. we call this the standard model.
　making match decisions separately ignores that information gleanedfrom one match decision may be useful in others. for example  if we find that a paper appearingin proc. ijcai1 is the same as a paper appearing in proc. 1th ijcai  this implies that these two strings refer to the same venue  which in turn can help match other pairs of ijcai papers. in this paper  we propose an approach which accomplishes this propagation of information. our approach makes decisions collectively  performing simultaneous inference for all candidate match pairs  and allowing information to propagate from one candidate match to another via the attributes  or fields  they have in common. our model is based on conditional random fields  lafferty et al.  1 . we call our model the collective model. figure 1 a  shows a four-record bibliography database and 1 b  shows the corresponding graphical representation for the candidate pairs  b1 b1  and  b1 b1  in the collective model. there are three types of nodes in the figure. record-match nodes are boolean-valued and they correspond to asking the question  is record bi the same as record bj   field-match nodes are also boolean-valued and they correspond to asking the question  do field values bi.f and bj.f  for the field f  represent the same underlyingproperty   field-similarity nodes are real-valued nodes taking values in the domain  1  1  and they encode how similar two field val-
record       titleauthorvenueb1 b1 b1 b1object identification using crfs   
object identification using crfs     
learning boolean formulas
learning of boolean expressions  linda stewart
  linda stewart
bill johnson
william johnsonproc. aaai 1
proc. 1th aaai proc. aaai 1
proc. 1th aaai
record match node	field match node	field similarity node
 a  a bibliography database

 b  collective model  fragment 
figure 1: example of collective object identification. for clarity  we have omitted the edges linking the record-match nodes to the corresponding field-similarity nodes.
ues are  according to a pre-defined similarity measure. the values of these nodes can be directly computed from data  and hence they are also called the evidence nodes. intuitively  an edge between two nodes represents the fact their values directly influence each other. note how dependencies flow through the shared field-match node corresponding to the venue field. inferring that b1 and b1 refer to the same underlying paper will lead to the inference that the corresponding venue strings  proc. ijcai-1  and  proc. 1th ijcai  refer to the same underlying venue  which in turn might provide sufficient evidence to merge b1 and b1. in general  our model can capture complex interactions between candidate pair decisions  potentially leading to better object identification.
　for random fields where maximum clique size is two and all non-evidence nodes are boolean  the inference problem can be reduced to a graph min-cut problem  provided certain constraints on the parameters are satisfied  greig et al.  1 . our formulation of the problem satisfies these constraints. since min-cut can be solved exactly in polynomial time  we have a polynomial-time exact inference algorithm for our model. we follow the standard approach of gradient descent to learn the parameters. calculating the exact derivative is intractable as it involves an expectation over an exponential number of configurations. we use a voted perceptron algorithm  collins  1   which approximates this expectation by the feature counts of the most likely configuration  which we find using our polynomial-timeinference algorithm with the current parameters.
　combining models is often a simple way to improve accuracy. we combine the standard and collective models using logistic regression. for each record-match node in the training set  we form a data point with the outputs of the two models as predictors  and the true value of the node as the response variable. we then apply logistic regression to this dataset. notice that this still yields a conditionalrandomfield. we performed experiments on real and semi-artificial databases  comparing the performance of  a  the standard fellegi-sunter model using logistic regression   b  the collective model  and  c  the combined model.
　the first set of experiments was on cora database  which is a collection of 1 different citations to computer science research papers. we cleaned it up by correcting some labels and filling in missing values. this cleaned version contains references to 1 different research papers. we used the author  venue  and title fields. the second set of experiments was done on the bibserv.org database  which is the result of merging citation databases donated by its users  citeseer  and dblp. we experimented on the user-donated subset of bibserv  which contains 1 citations. table 1 reports the results for these databases. the combined model gives the best performance on both cora and bibserv  followed by the collective model. transitive closure helps these on cora but hurts all models on bibserv  where recall was close to 1% even without transitive closure . the best combined model outperforms the best standard model in f-measure by about 1% on cora and 1% on bibserv.
　to further observe the behavior of the algorithms  we generated variants of the cora database by taking distinct field values from the original database and randomly combining them to generate distinct papers. figures 1 a  and 1 b  compare the performance of the collective and standard models as number of clusters and level of distortion in the data are table 1: f-measures on cora and bibserv before and after transitive closure.
modelcorabibservbeforeafterbeforeafterstandard1%1%1%1%collective1%1%1%1%combined1%1%1%1%
1 1 1 1 1 1 1 1 number of clusters	distortion
 a  f-measure vs. number  b  f-measure vs. distorof clusters	tion level
figure 1: experimental results on semi-artificial data.
varied  respectively.1 the collective model clearly dominates the standard model over a broad range of number of clusters and level of distortion.
　in summary  determining which observations correspond to the same object is a key problem in information integration  citation matching  natural language  vision  and other areas. we have developeda collective approachto this problem  where information propagates among related decisions via shared field values  and shown experimentally that it outperforms the standard one of making decisions independently.
acknowledgments
this research was partly supported by onr grant n1-1  by a gift from the ford motor co.  and by a sloan fellowship awarded to the second author.
