 
　　　an expectation-based system  ngp  for 	parsing 	english 	noun groups into the conceptual dependency representation is described. 	the system is 	a 	part of eli  english language interpreter  
which is used as the front end to several natural language understanding systems and is capable of handling a wide range of sentences of considerable complexity. ngp processes the input from left to right  one word at a time  using linguistic and world knowledge to find the meaning of a noun group. dictionary entries for i n dividual words contain much of the program's knowledge. in addition  a limited ability for the handling of slightly incorrect sentences and 
unknown words is incorporated. 
1. introduction 
　　　every natural language processor has to have the a b i l i t y to interpret noun phrases. this paper describes a set of programs called ngp  noun group processor  which is an integral part of eli  the english language interpreter  riesbeck and schank 1  which serves as the front end to three of the yale natural language understanding systems  sam  pam and weis. sam is a system capable of understanding stories such as various newspaper reports by using scripts 
 schank and abelson 1  1; cullingford 1  1 . pam is an understanding system which uses general knowledge about peoples' goals and plans  wilensky 1 . weis is a system which understands and classifies a great variety of isolated newspaper headlines on international relations. thus  our task was to process not only noun phrases of considerable complexity but also to interpret newspaper headlines  which are not always grammatically correct. the following two examples illustrate the kind of sentences our system is able to handle. 
1. a connecticut man  john doe  age 1  of 1 college avenue  new haven was pronounced dead 
at the scene by dr. 	dana 	blauchard  	medical examiner. 
1. funeral of india's shastri attended by ussr kosygin and usa humphrey. 
this work was supported in part by 	the 	advanced 
research 	projects 	agency 	of 	the department of 
defense and monitored under the office 	of 	naval 
research under contract n1-c-1 
　　　to process such a large scope of sentences the program makes extensive use of i t s knowledge of the problem domain and the redundancy of natural language expressions. this saves effort and permits correct processing of such irregularities of input text as missing commas and articles  or slightly incorrect word order. it also provides for the a b i l i t y to ignore unknown words or  in some cases  to make plausible interpretations of unknown words. this knowledge is kept in the dictionary. the control mechanisms remain domain independent. 
　　　ngp is a production-like system which uses expectations as i t s basic control mechanism. the problem with every production-like system is the tendency for the accumulation of a large number of expectations fighting for a chance to be tested. in this work i have tried to develop a theory of how various expectations are organized and processed  which  i believe  is in fact a theory of how people process natural language. the basic guiding principle for this theory was i t s intuitive plausibility. 
!  noun group semantics 
　　　in this paper we w i l l discuss two classes of noun groups according to the conceptual structures they generate: pp - picture producers and ctp - concept producers. 
　　　pp's are defined by schank  schank 1  as concepts which tend to produce pictures of real 
world items in the mind of a hearer. for example  
 1  a big red apple 
is a picture producing noun group. to understand such an item means to identify the structure in the memory which corresponds to this item if such a structure exists or to create one according to some frame. this is done in two stages. in the f i r s t stage  we analyze the input phrase and translate it into an expression in conceptual dependency  schank 1  1  1 . this expression should preserve in a language independent form a l l the information contained in the surface phrase. thus  1  w i l l generate 
 #phys1bj type  apple  color  x  
size  y  determ  indef    
where x and y are points on the color and size scales. in the second stage  we identify the cd expression with the existing memory structures by performing the necessary memory search and feature matching. 
　　　a cd expression for a pp consists of a header followed by a property l i s t . the header is similar to a superset pointer in hierarchically organized memory systems. it points to a 
　　　frame of properties that the pp is expected to have. the property l i s t explicitly given in the cd expression must be compatible with this frame. thus a  #pers1n  is expected to have firstname  

natural lan*rua♀e-1: hershman 1 

lastname  residence  e t c . but a  #physobj  is n o t . a l l p r o p e r t i e s not included in the frame must be s p e c i f i e d by a rel clause. for example   1  john doe  the passenger of the car is represented by 
x: 	 //person fistname  john  lastname  doe  
rel    -   $drive passenger x         
       sam's memory program accepts 1 general classes of pp's: //person  //physobj  //organization  //locale  //road  //group  and //polity  which can be i l l u s t r a t e d by the f o l l o w i n g examples: 
 1  john -  //person firstname  john   
 1  table =  //physobj type  *table*   
 1  navy -  //organization branch  navy   
 1  1 foxon rd 	-  //locale streetnumber  1  streetname  foxon  
streettype  road   
 1  route 1 =  //road roadnumber  1  roadtype  highway   
 1  john and -  //group 
	mary 	member  //person firstname  john   
                   member  //person firstname  mary     1  usa -  //polity type  country  name  usa   
       very o f t e n noun groups do not describe any r e a l world items. consider the f o l l o w i n g sentence: 
 1  john voted in the 1 presidential election. 
the 1 presidential election does not produce a s i n g l e   p i c t u r e   in the mind of the hearer. rather  it points to a complicated concept i n v o l v i n g the names of the candidates  p r i m a r i e s   v o t e r r e g i s t r a t i o n   e t c . the knowledge about t y p i c a l e l e c t i o n s is normally organized in a 
s c r i p t - l i k e form. the verb voted s p e c i f i e s the r o l e john played in the e l e c t i o n s c r i p t . thus  the meaning of  1  is the invocation of the e l e c t i o n s c r i p t and the i n s t a n t i a t i o n of the s c r i p t r o l e s . the cd representation of the 1 presidential election produced by the parser looks as f o l l o w s : 
selection type  presidential  time  1  
ref  def    
where $election is a script name and type and time are script parameters. this output is i n terpreted by the script applier. all script 
names 	and 	parameters which appear in the cd expression must be recognizable by the 	script 	applier. 
1* basic noun group parser 
the goal and the general methods of the noun 
group parser  ngp  are identical to the rest of eli  i.e. the goal of ngp is the extraction of the conceptualizations that underlie the input. expectations are its basic mechanisms of operation.  see riesbeck and schank 1 . however  the control structure and the order in which the expectations are stored and tested in ngp are very different from those of eli. to put it briefly  in eli a l l the expectations are placed in one pool and are tested whenever a new word or concept is considered. ngp takes advantage of the relatively rigid structure of english noun groups to select and order suitable expectations at each point of the process. the program examines the words of the input string from left to right. the basic loop of the analyzer consists of two steps: 
1. the dictionary definition of the current word is loaded into the active memory. 
1. relevant expectations are selected and tested. if an expectation is satisfied  the actions associated with it are executed. 
this basic loop i s similar to the monitoring control program of eli or any other productionlike system. the difference is in the selection and ordering of expectations. this process is rather complicated and i w i l l try to describe it systematically and in increasingly greater detail throughout the res t of the paper. i w i l l begin by presenting the analysis of a simple example: 
 1  large chinese restaurant 
first  ngp sees the word large. the dictionary definition of large is a program which can test the environment when large is brought into the active memory and build the i n i t i a l semantic node for i t . these semantic nodes  called ngp nodes in the program  are the construction sites where various parts of the future cd expression are being assembled. the node for large  say ngp1  has an expectation attached to it which says   i f the next semantic node is an inanimate pp then attach modifier size  x  to i t   . ngpl is saved in a stack called modlist. 
	the word chinese builds 	the 	semantic 	node 
ngp1  whose semantic value is  *china*  and which has an expectation saying   i f the next semantic node is a //physobj then attach the modifier madein  *china*  to i t   if it is a #person or an 
#organization then attach the modifier partof  *china*  to i t   . having done this  the monitor checks the expectation attached to ngpl. it fails and ngp1 is placed on the top of modlist. 
node can be a restaurant type then attach 	it 	to the current node . 	now the monitor goes into the expectation testing mode of operation. 	it 	sees 
natural 	language -1: gershman 
1 　　　next comes the word restaurant. it builds the semantic node ngp1 whose semantic value is  #organization occupation  restaurant   and which has an expectation:   i f the previous semantic 
two sets of expectations: those attached to ngp1 looking   f o r w a r d   at ngp1 and those attached to ngp1 looking  backward  at ngp1. expectations attached to ngp1 are not considered because ngp1 is hidden by ngp1. f i r s t   the monitor t e s t s those expectations of the c u r r e n t node which look  backward    c a l l e d backward in the program . if there are no such expectations or if a l l of them f a i l   the monitor t e s t s the   f o r w a r d   expectat i o n s   c a l l e d forward in the program  attached to the previous semantic node. if an expectation is s a t i s f i e d   the stack is popped and the process is repeated u n t i l no expectations are s a t i s f i e d . i n t u i t i v e l y   modlist contains those m o d i f i e r s which have not yet been attached. the c u r r e n t node  which is kept in ngap  is the focus of assembling a c t i v i t i e s at each s t e p . in our example  *china*  can be a restaurant type  the expectat i o n is s a t i s f i e d   the value of ngp1 is m o d i f i e d   and ngp1 is removed from modlist. the f o l l o w i n g diagram i l l u s t r a t e s the t r a n s i t i o n : 
before: modlist - ngp1  ngp1 
ngap - ngp1 
	ngp1 - 	 //organization 
occupation  restaurant   
after: 	modlist - ngp1 
ngap - ngp1 
	ngp1 - 	 //organization 
occupation  restaurant  
	type 	 *china*   
now the monitor sees ngp1 on the top of the stack. since ngp1 does not have any backward expectations l e f t   the forward expectation of ngp1 is t e s t e d . note that at t h i s p o i n t   ngp1 does not correspond to any p a r t i c u l a r word  but represents the combined meaning of chinese restaurant. large can be attached to ngp1 and the r e s u l t i n g s t r u c t u r e i s : 
modlist - empty 
ngap - ngp1 
ngp1 - 	#organization 	occupation  restaurant  
type 	 *china*  size 	 x   
       so f a r   we have introduced the f o l l o w i n g concepts: 
semantic nodes - are the n u c l e i around which a l l c o n s t r u c t i o n a c t i v i t i e s are done. the value of a semantic node is a piece of conceptual s t r u c t u r e which might be used in assembling the cd expression f o r the whole noun group. 
backward and forward - are the two groups of expectations attached to a semantic node. 
ngap - holds the current semantic node. 
modlist - is a stack which holds a l l previous semantic nodes. 
the basic c o n t r o l algorithm of ngp  which was i n f o r m a l l y described w i t h the help of the above example  now can be stated in more precise terms: 
step1 read new word. execute i t s d e f i n i t i o n and put the r e s u l t i n g semantic node in ngap. 
step1 if modlist is empty then go to 	step1 	else go to step1. 
step1 if ngap does not have any 	backward 	expect a t i o n s go to step1  otherwise go to step1. 
step1 evaluate backward expectations of ngap. in case of f a i l u r e go to step1  otherwise pop the stack and go to step1. 
step1 if the semantic node on the top of modlist does not have any forward expectations then go to step1  otherwise go to step1. 
step1 evaluate forward e x p e c t a t i o n s . in case of f a i l u r e go to step1  otherwise pop the stack and go to step1. 
step1 put the content of ngap  current semantic node  on modlist and go to step1. 
the underlying assumptions of t h i s algorithm are:  a  people read noun groups from l e f t to r i g h t . 
 b  people do not passively accumulate words u n t i l they decide that they have reached the head noun. i n s t e a d   they make decisions about the i n t e r p r e t a t i o n s and combinations of words as soon as it becomes possible   i . e . as soon as an expectation is s a t i s f i e d   . thus  in a phrase meat shop owner  meat shop is i n t e r preted before owner is read. 
 c  expectations attached to words which come l a t e r in the phrase usually are stronger than those of preceding words. in the sequence of words of a simple noun group   l i k e fearless chinese soldier  words on the l e f t are u s u a l l y m o d i f i e r s of some word on the r i g h t . a modif i e r normally has forward expectations f o r a f a i r l y l a r g e class of items it can modify. on the other hand  it is r e l a t i v e l y seldom that a 
word is looking for a p a r t i c u l a r modifier on i t s l e f t . 
       so f a r   i have c a r e f u l l y avoided one very important problem. my basic c o n t r o l algorithm does not have a stop statement. where does a noun group end  this problem is discussed in the next s e c t i o n . 
1# the problem of boundaries 
       one problem that any noun group processor has to solve is the problem of boundaries. where does a noun group end  in most cases the answer t o t h i s question i s quite simple: things l i k e 
verbs  commas  p r e p o s i t i o n s   and a r t i c l e s t e r m i nate most noun groups. in p r a c t i c e   however  none of these i n d i c a t o r s is very r e l i a b l e . consider the f o l l o w i n g example that ngp had to deal w i t h : 
 1  the u.s. 	forces fight in 	vietnam 	is 	hope-
less. 
this example i l l u s t r a t e s the d i f f i c u l t i e s a r i s i n g 
from the ambiguity of the part of speech c l a s s i f i c a t i o n of the words forces and fight. when the context does not provide an e a r l y disambiguation we have to make a guess and then l a t e r c o r r e c t it if necessary. as a f i r s t guess  ngp c o l l e c t s the maximum number of elements i n t o a noun group. thus it includes both forces and fight r a t h e r than stopping a f t e r the u.s. 
 1  bill  john  and mary left. 
natural 	lan*ua*e-1:   rshman 1u  1  bill kicked john  and mary kicked bill. 
       bill  john  and mary in the second example c o n s t i t u t e one semantic u n i t -
 1group member  //person firstname  bill   member  //person firstname  john   
member  #person firstname  mary    
but is it reasonable to consider t h i s phrase as a s i n g l e noun group on the surface level  example  1  shows t h a t john  and mary might be d i f f e r e n t groups. expectations e x t e r n a l to the noun group must decide whether these three words can be c l u s t e r e d in one group. the same is true f o r examples  1  and   1     where the phrase on the tray may or may not be attached to the noun phrase the glass. 
 1  john saw the glass on the tray.  1  john put the glass on the tray. 
on the other hand  the p r e p o s i t i o n of in the phrase of state in example  1  
 1  u.s. assistant secretary of state 
marshall green 
is predicted by the noun secretary  and can be i n t e r p r e t e d by the noun group processor without outside help. this brings in the f o l l o w i n g p r i n c i p l e of noun group processing: 
	any unexpected word which 	is 	incompatible 
　　with the current noun group terminates the group on the preceding word. control is returned to the higher l e v e l r o u t i n e which c a l l e d the noun group and which decides how the group w i l l be used. it might be attached to a preceding noun group or used otherwise. 
semantically  a phrase l i k e 
 1  a recent yale graduate  jim meehan  1  assistant professor of computer science 
at uci  was awarded . . .   
is one pp and  t h e r e f o r e   should be considered one noun group. from the processing point of view  we need a more r e s t r i c t e d d e f i n i t i o n of surface noun groups. a surface noun group   o r   s i m p l y   noun group  is a s t r i n g of words which can be processed by ngp w i t h o u t r e l i n q u i s h i n g c o n t r o l to the higher processor. 
       what are the r u l e s of c o m p a t i b i l i t y which determine the boundaries of a surface noun group  a l l semantic nodes t h a t can be used in a noun group must belong to one of the f o l l o w i n g 
       classes: adjective  adverb  noun  title  name  number  determ  and bogus.  this i n f o r m a t i o n is stored on the node under the property marker . class bogus is reserved f o r unknown words and w i l l be discussed l a t e r . class title contains a l l the words which can be followed by a name: p r o f e s s o r   d o c t o r   patrolman  p r e s i d e n t   e t c . the noun group is processed from l e f t to r i g h t as long as the f o l l o w i n g conditions are s a t i s f i e d : 
 1  each word which is not s p e c i f i c a l l y expected must belong to one of the classes mentioned above. 
 1  no word can precede a determ. 
 1  adjectives  adverbs  and numbers cannot be preceded by e i t h e r nouns  titles  or names. 
 1  titles and nouns 	cannot 	be 	preceded 	by 	a 
name. 
 1  a name cannot be immediately 	preceded 	by 	a noun. 
 1  a name cannot be preceded by a determ. for example  phrase  1  w i l l be processed as four separate noun groups: 
 a  a recent yale graduate - ends with a comma  but even if t h i s comma were missing  the phrase would have been terminated at the same place by name  using rules 1 and 1 
 b  jim meehan - ends w i t h a comma 
 c  1 - s p e c i a l case of a noun group 	- 	an 	age group 
 d  assistant professor of computer science at uci - ends w i t h was which is a verb noun groups of computer science and at uci are processed without leaving ngp since the word professor sets up expectations f o r them. 
       rules  1  -  1  are much looser than the usual s y n t a c t i c rules f o r noun groups  see  f o r example  winograd 1 . but our goal is not the r e j e c t i o n o f s y n t a c t i c a l l y i n c o r r e c t sentences. we introduce r e s t r i c t i o n s only where they h e l p   where t h e i r absence creates disambiguation or processing d i f f i c u l t i e s . 
       the other d i s t i n c t i v e feature of our r u l e s is that they are generated dynamically and can be changed by a c t i o n s of any e x p e c t a t i o n . this is how  f o r example  possessives are handled:  1  police chief's new car f i r s t   the node f o r police chief is b u i l d : 
ngp1: 
	value 	-  #person occupation  police-chief   
marker - title 
then the program sees the possession mark which s a t i s f i e s a special d e f a u l t e x p e c t a t i o n . the a c t i o n of t h i s expectation transforms ngp1 i n t o : 
ngp1: 
value -  #person occupation  police-chief   
marker - adjective 
forward -   i f the next node is a #physobj then make it possby the value of ngpl   i . e . by   person occupation  police-chief     
	1  	p u t t i n g pieces together 
       in the previous s e c t i o n i described the basic noun group processor. complex noun groups 
are broken i n t o simpler phrases which are p r o cessed separately. separately  however  does not mean independently. the previously b u i l t p a r t of the noun group can a f f e c t the analysis of the remaining p a r t s . in t h i s s e c t i o n i w i l l describe the mechanism of t h i s i n t e r a c t i o n and how various parts of a noun group are put together. 

natural 	langua ge-1: 	gershman 
1 

       in accordance w i t h our general p r i n c i p l e s   t h i s process is d r i v e n by a h i e r a r c h i c a l l y organized set of e x p e c t a t i o n s . there are two kinds of expectations:  1  those dynamically generated by the input and  1  d e f a u l t expectations supp l i e d by the c o n t r o l mechanism. these d e f a u l t expectations are designed to catch such unexpected things as a p p o s i t i v e s   addresses  age groups  e t c . for example  when we hear a connecticut man in 
 1   the award was given to  a connecticut man  john doe  age 1  of 1 college avenue  new haven. 
we do not n e c e s s a r i l y immediately expect to hear h i s name  age  and address  although we know t h a t as a person he has these c h a r a c t e r i s t i c s . these are secondary  d e f a u l t expectations which are tested only i f o t h e r   e x p l i c i t expectations f a i l . in the above example the processing goes as f o l lows. f i r s t   a connecticut man is c o l l e c t e d   generating: 
 1   #person gender  male  
residence  //locale state  *conn*    
at t h i s p o i n t   c o n t r o l returns to eli which t e s t s the expectations which were pending before we reached t h i s phrase. one of these expectations is s a t i s f i e d and i t s a c t i o n puts s t r u c t u r e  1  i n t o the w a i t i n g s l o t in a l a r g e r frame: 
 actor  nil   -   *atrans*  object  *award*  to  #person gender  male  
residence  #/locale state  *conn*     
the s l o t that  1  f i l l e d is remembered in the v a r i a b l e c a l l e d lastng. then comes john doe. no e x p l i c i t expectations are s a t i s f i e d . the monitor goes to a special mode c a l l e d trap. trap checks whether lastng was a person and  if so  checks the d e f a u l t expectations about a person. the name expectation is s a t i s f i e d and the specialized a c t i o n which c o l l e c t s personal names is executed. as a r e s u l t name m o d i f i e r s are attached to the male connecticut r e s i d e n t : 
 #person gender  male  
residence  #locale state  *conn*   
firstname  john  lastname  doe   
a f t e r t h i s   c o n t r o l goes back to the top l e v e l processor. this reads the next word    1   . again  no expectations are immediately s a t i s f i e d and the monitor traps i n t o the secondary expect a t i o n s . the age expectation is s a t i s f i e d and the specialized a c t i o n which c o l l e c t s age speci f i c a t i o n groups is executed. the r e s u l t is an age m o d i f i e r which is attached to .john. of 1 
college avenue also goes to trap  which c a l l s the address group processor. the f i n a l r e s u l t i s : 
 #person gender  male  
residence  #locale state  *conn*  
streetnumber  1  
　　　　　　　　　　　　streetname  college avenue   firstname  john  lastname  doe   
       the f o l l o w i n g example i l l u s t r a t e s a s l i g h t l y d i f f e r e n t problem: 
 1  louis cappiello  yale police chief 
in order to f i g u r e out that being a yale police chief is louis cappiello's occupation we f i r s t have to c o l l e c t both noun groups. this is done w i t h the help of another secondary expectation c a l l e d extra-noungr t r a p . louis cappiello generates: 
 //person firstname  louis  lastname  cappiello   yale police chief generates: 
 //person occupation 	 yale-police-chief   
then another secondary expectation t e s t s to see if lastng and extrang could be the same t h i n g . if so  the two groups are merged. 
       appositives can be a r b i t r a r i l y complex: from simple name groups to complicated p r e p o s i t i o n a l phrases and r e l a t i v e clauses. very r a r e l y are they e x p l i c i t l y expected. they are handled by the secondary expectations based on the gene r a l p r o p e r t i e s of things and the knowledge about the ways these things can be expressed in eng l i s h . trap represents an attempt to implement the mechanism c o n t r o l l i n g the i n t e r a c t i o n between these expectations. 
       trap is s t i l l in the experimental stage of development. i t s flow of c o n t r o l is rather comp l e x . i n g e n e r a l   f i r s t   i t t r i e s t o f i n d and t e s t expectations about general p r o p e r t i e s of the item in lastng. for example  f o r a person it t r i e s to c o l l e c t s p e c i a l m o d i f i e r s such as name  age  and address. if a l l these expectations f a i l   trap checks f o r possible appositives such as simple extra noun groups  p r e p o s i t i o n a l phrases  or r e l a t i v e subclauses. if one of these a p p o s i t i v e s is c o l l e c t e d   trap f i r s t checks the e x p l i c i t expectations which may have been pending   f o r example  a which-clause might want to be attached to a p a r t i c u l a r physical object  and then checks the secondary expectations a g a i n . this time  it may catch some p r o p e r t i e s which it missed the f i r s t time because they were encoded in a more complicated form. in order to c l a r i f y t h i s d e s c r i p t i o n l e t us f o l l o w a few more examp l e s : 
 1  john doe of general motors 
the subgroup 	of 	general 	motors 	is 	caught 	by 
trap's p r e p o s i t i o n a l phrase e x p e c t a t i o n . since there are no s p e c i f i c expectations which can l i n k john doe and general motors  the d e f a u l t one  attached to of is checked. i t s a c t i o n l i n k s the 
two groups as f o l l o w s : 
  person firstname  john  lastname  doe  somerel  organization 
orgname  general-motors    
somerel means t h a t we 	do 	not 	r e a l l y 	know 	the 

natural laneuage-1: hershman 1 

exact nature of the r e l a t i o n s between john doe and general motors. 
in the f o l l o w i n g example 
 1  us navy task force which has been on patrol duty in the indian ocean   l e f t the area  
the which clause is c o l l e c t e d by trap's subclause expectation and is attached to us navy task force by an expectation associated w i t h which. the r e s u l t i s : 
x:  #gr-org partof 
 #organization branch  navy  partof  *usa*   rel   actor x 
	 -  	 $patrol place  *indian-ocean*      
subclause processing represents a d i f f i c u l t problem on i t s own. the problem of subclause boundaries  f o r example  is as complex as that of noun groups. in solving i t   i used the same philosophy as f o r noun groups boundaries: the c u r r e n t subclause is f i n i s h e d when the next word is not expected by any expectations from that subclause. 
       the t r a d i t i o n a l stumbling block of a l l parsers - and c o n j u n c t i o n - is also handled by a series of trap e x p e c t a t i o n s . although  in d i f f i c u l t cases we cannot avoid b a c k t r a c k i n g   simple cases l i k e 
 1  john and mary ate soup and lasagna and left. 
can be processed by the program with the help of the f o l l o w i n g h e u r i s t i c s . if and is not s p e c i f i c a l l y expected and occurs in the sentence between two noun groups which can be combined in one semantic u n i t then it is i n t e r p r e t e d as a 
l i n k between the two noun groups. otherwise  if and occurs in the sentence a f t e r the verb it is i n t e r p r e t e d as a l i n k between two clauses. 
       a l l examples presented so f a r deal with noun groups d e s c r i b i n g p i c t u r e producers. the next example shows how concept producers are handled. 
 1  	 castro condemned  the execution 
of thousands of communists in indonesia. 
the execution r e f e r s to the s c r i p t $execution. this s c r i p t has among i t s r o l e s the victim of the execution. among the expectations associated w i t h the s c r i p t there is one which expects the v i c t i m to be a person  or a group of people  i n troduced by the p r e p o s i t i o n of. hearing the word execution sets up an expectation f o r the word of 
 someone . thousands of is another u n i t which creates a group whose members f o l l o w . this exp e c t a t i o n is s a t i s f i e d by communists. when in indonesia comes it is not expected by anybody. hence  the noun group c o l l e c t i o n is suspended and the execution which is now transformed i n t o : 
 $execution victim  //group member 
 #person occupation  communist  compnum  order val  1      
is placed in the mobject s l o t of mtrans f o r  condemned . a f t e r t h i s   in indonesia is c o l l e c t e d : 
 loc val  *inside* partof   indonesia    
now the processor must decide whether indonesia was the place where the execution occurred or where it was condemned by castro. in the absence of other e x p e c t a t i o n s   the program picks the f i r s t a l t e r n a t i v e . 
       to conclude t h i s s e c t i o n   i would l i k e to discuss the treatment of words unknown to the program. people have a l i m i t e d a b i l i t y to i n t e r p r e t such words from context  o r   at l e a s t   to ignore them. we t r i e d to put some of t h i s kind of i n t e l l i g e n c e in our programs. the problem has two aspects. f i r s t   we have to f i g u r e out what r o l e the unknown word  or words  might play in the sentence and then i n t e r r o g a t e the context to f i n d out what meaning t h i s word might have. the b o r d e r l i n e between these two tasks is very vague. as of now  most of the f i r s t part is handled by 
ngp and most of the second part by rick granger's program called foul-up  granger 1 . the f o l lowing examples i l l u s t r a t e how the ngp p a r t works. 
 1  john ate a f1 fish. 
foo is i n t e r p r e t e d as 	an 	unknown 	m o d i f i e r 	and ignored. 
 1  john ate a blue foo. 
the output of ngp 
 //bogus color  blue  lexval  foo  ref  1ndef   is handed 	to foul-up f o r f u r t h e r i n v e s t i g a t i o n . 
 1  dr foo baz ate a blue fish. 
foo baz are i n t e r p r e t e d as the f i r s t and the l a s t names of a person whose occupation is doctor. 
 1  foo's fish was bad. 
foo is i n t e r p r e t e d as the l a s t name unless  1  and  1  occurred in the same s t o r y   in which case foo would have already been defined as a f i r s t name. 
 1  john was taken to the hospital by foo ambulance. 
foo is i n t e r p r e t e d to be a name of an ambulance company  since ambulance has a backward expectat i o n looking f o r a company name. 
 1  1 foo baz avenue 
natural 	language-1: 	gershman 1 foo baz is i n t e r p r e t e d as the name of an avenue. 
1
	* 	comparison w i t h other work and conclusions 
　　　the work  presented in t h i s paper is a f u r ther development of eli. the main d i f f e r e n c e 
between t h i s program and most other parsers  see  f o r example  winograd 1  woods and kaplan 1  is that it does not separate i t s l i n g u i s t i c knowledge from i t s general world knowledge. in other programs the analysis is done in two stages. f i r s t the input is analyzed s y n t a c t i c a l l y and then the r e s u l t is i n t e r p r e t e d semant i c a l l y . for example  lunar  woods and kaplan 
1  uses the augmented t r a n s i t i o n network grammar  woods 1  to generate possible synt a c t i c i n t e r p r e t a t i o n s of a given sentence and then applies i t s domain knowledge to determine whether the i n t e r p r e t a t i o n is meaningful. thus  noun groups are parsed purely s y n t a c t i c a l l y and t h e i r meaning is not established u n t i l the whole sentence is parsed. in each noun group the f i r s t noun is assumed to be the head noun. if l a t e r t h i s turns out to be i n c o r r e c t   the system backs up and t r i e s to accumulate more elements i n t o the noun group. for example  the c o r r e c t processing of the phrase president jimmy carter which cont a i n s three nouns w i l l r e q u i r e lunar to back up t w i c e . this means that a great deal of unnecessary e f f o r t i s spent i n f i n d i n g s y n t a c t i c a l l y p l a u s i b l e but meaningless parses. this is espec i a l l y true when one t r i e s to relax some syntact i c rules t o allow f o r s l i g h t l y i n c o r r e c t sentences. in ngp the parsing is done by the use of r u l e s most appropriate in a given s i t u a t i o n   semantic or s y n t a c t i c . thus  in the example above  the programs contained in the d i c t i o n a r y entry f o r the word president w i l l immediately c o l l e c t jimmy carter. most of the program's l i n g u i s t i c knowledge i s not b u i l t i n t o i t s c o n t r o l s t r u c t u r e but stored in the d i c t i o n a r i e s and used as a part of i t s general knowledge. this makes the program very f l e x i b l e   e a s i l y e x t e n s i b l e   and provides f o r the c o r r e c t processing of  ungrammatical  sentences. 
       another important d i f f e r e n c e between t h i s program and both winograd's and the lunar system is in the representation of meaning. the meaning of a sentence in winograd's system is a program f o r manipulating blocks. the meaning of a sentence in the lunar system is a request for i n formation about some p r o p e r t i e s of the rocks from the moon. both these systems are very s p e c i a l ized and not e a s i l y e x t e n s i b l e to other domains. our analyzer is based on the conceptual dependency representation system which is not l i m i t e d to any p a r t i c u l a r domain. the same program can 
handle a wide v a r i e t y of t o p i c s   from car a c c i dent reports to state v i s i t s to china. 
　　　the r e s u l t s presented in t h i s paper show that both l i n g u i s t i c and world knowledge are r e quired for correct and e f f i c i e n t handling of noun groups. the program demonstrates the p o s s i b i l i t y and the advantages of the simultaneous a p p l i c a t i o n of both kinds of knowledge  without separ a t i n g the process of understanding i n t o syntact i c and semantic stages. the program provides an i n t u i t i v e l y p l a u s i b l e model for a h i e r a r c h i c a l l y organized  expectation based c o n t r o l mechanism f o r analyzing noun groups. 
	1. 	