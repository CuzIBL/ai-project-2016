
collaborative web search uses the past search behaviour  queries and selections  of a community of users to promote search results that are relevant to the community. the extent to which these promotions are likely to be relevant depends on how reliably past search behaviour can be captured. we consider this issue by analysing the results of collaborative web search in circumstances where the behaviour of searchers is unreliable.
1 introduction
traditional approaches to web search are term-based; they assume that relevance is best understood from the terms within documents. it has been shown that typical web users are not experts when it comes to searching for documents - they routinely provide ambiguous queries  lawrence and giles  1   making it difficult for search engines to predict their needs. in such an environment  query and document terms are not always a good indication of relevance and so content-based approaches often fail  furnas et al.  1 . recent innovations have seen the introduction of new sources of relevance knowledge. for example  the work of  brin and page  1  has famously demonstrated the usefulness of inter-document relationships by exploiting link-connectivity information. more recently researchers have also focused on ways to exploit context in web search as a way to disambiguate vague queries  either by explicitly establishing the search context up-front or by implicitly inferring the context as part of the search process  see  lawrence  1  . yet others have focused on leveraging knowledge about the query-space to directly address the correspondence problem  by mining query logs in order to identify useful past queries that may help the current searcher  e.g.   glance  1; raghavan and sever  1; wen et al.  1  . the work

 
모모this material is based on works supported by science foundation ireland under grant no. 1/in.1/i1.of  smyth et al.  in pressb  has suggested another source of relevance knowledge: in the collaborative web search  cws  approach patterns of queries and result selections from a community of users are used to re-rank the results of an underlying search engine. a community can be a welldefined group of users  such as the employees of a given company  or it can be an ad-hoc group of individuals  such as the users of some topical web site  for example a motoring web site. the point is that many searches can be traced back to communities of users and our research indicates that these communities are likely to submit similar queries and select the same types of results  smyth et al.  in pressb . in a recent analysis of search logs from a variety of sources we have found that within communities of searchers up to 1% or more of queries share at least 1% of their query terms with past queries from the community; see  smyth et al.  in pressb . for example  in  smyth et al.  in pressa  we describe the results of a recent trial of cws within a corporate context and a community of about 1 searchers  the employees of an irish software company . the data collected as part of this trial indicates that 1% of queries share half of their query terms with previous queries. the results of this trial go on to show that cws can take good advantage of this type of repetition and regularity to significantly enhance search performance.
모cws relies on a relevance assumption-that the selection of a page for some query is a reliable indicator of page relevance-which cannot be fully relied upon. search engines often return pages that turn out not to be relevant  and users often mistakenly select them. the question is: how sensitive are the results of cws to selection noise  we will answer this question in what follows by analysing the impact of selection noise on result precision.
1 collaborative web search
cws is a form of meta-search  relying on the search services of a set of underlying search engines  but manipulating their
results in response to the learned preferences of a given community of users. a key data structure in cws is the hit matrix  h. it represents the search behaviour of a given community of users and each time a member of a community selects a result pj in response to some query qi the entry in cell hij is incremented. in turn  the relevance of a page pj to qi can be estimated as the relative number of selections pj has received in the past for qi; see equation 1.
		 1 
		 1 
more generally  the relevance of a page pj to some query qt can be calculated as the weighted sum of its relevance to a set of queries that are similar to qt  namely q1 ... qn  with each individual relevance value discounted by the similarity between qt and the query in question; see equation 1. the similarity between qt and the query in question  qi is calculated as in equation 1; it is worth noting that we have recently evaluated a variety of alternative and more sophisticated similarity metrics  the results of which are presented in  balfe and smyth  1; in press .
		 1 
모thus on receipt of some target query  qt  cws dispatches it to a set of underlying search engines and their results are combined to form a meta-search result-list  rm. at the same time  qt is compared to other queries in the hit-matrix to select a set of similar queries  q1 ... qn  that are selected if their similarity to qt exceeds some set threshold. the results selected for these queries in the past are ranked by their weighted relevance to qt  according to equation 1  to produce a new promoted result-list  rp. rp is combined with rm to produce rt  which is then returned to the user; in our implementation rt = rp 뫋 rm. for further detail on the technical details of the cws architecture and operation see  smyth et al.  in pressb .
1 evaluation
the success of cws depends on the quality of its promoted results  rp  and their quality in turn depends on the reliability of the user selections that underpin the core relevancy calculations. in this evaluation we will assess the quality of these promotions under different degrees of selection noise with an experiment using the trec terabyte collection  see http://www-nlpir.nist.gov/projects/terabyte  and the f뫣 sreal search engine뫣  blott et al.  in press .
1 the trec terabyte collection
this collection consists of over 1 million web pages  approx  1gb  crawled from the .gov domain during early 1. the trec terabyte track included 1 random topics as target search topics. each topic included a short textual description and during the evaluation competing search engines were evaluated with respect to their ability to locate pages relevant to these topics. after the evaluation a relevance engine was made available to help with the evaluation of new search techniques. this engine provides ground-truth relevance for the topics and allows for the detailed analysis of result-lists in relation to the test queries.
1 training the hit-matrix
normally in cws the hit-matrix is trained by the searches of a given community of users  but we need a mechanism for manipulating selection noise and so we need a more controlled experimental framework. for this we require a set of queries and a method for judging the relevance of the results that are returned and that might be selected by users. we generate queries by extracting subsets of terms from the trec topic descriptions  after first removing commonly occurring stop words; for each topic we generate 1 queries with between 1 and 1 terms each. to simulate the action of a searcher we use the official trec relevance engine  which is capable of identifying all result pages that are relevant for a given topic. thus  for a training query q generated from topic t  we can identify the k pages returned by a baseline search engine  see  blott et al.  in press   that are relevant to t as the basis for updating our hit-matrix for topic t. during the update we use two types of noise. typea noise occurs when additional non-relevant results are selected and thus during training we assume that the user selects all k retrieved documents that are relevant and an additional n% of k non-relevant pages. typeb noise occurs when users fail to select all of the relevant results returned and thus during training we assume that the user only selects  1 n % of the k relevant results and n% of k irrelevant results returned for each query.
1 precision analysis
to assess the precision of cws we use the official trec test queries that formed the basis of the trec 1 evaluation; none of these queries were used in training. two different versions of cws are used for query similarity thresholds of   1 and  = 1  with different types and levels of selection noise introduced. each test query is replayed and the percentage of relevant results for different result-list sizes is computed. the average of these precision values is computed to produce an overall mean average precision  map  for each version of cws. we also compute a baseline map for the trec benchmark search engine used in  blott et al.  in press   which serves as the underlying engine for cws.
모the results are presented in figures 1 and 1. each graph shows the map for the baseline and for cws with type a and b noise. they show that cws offers significant precision increases over the baseline. for example  for the   1 threshold  at the 1% noise level  cws delivers over twice the precision of the baseline  1 vs. 1 . we also see that these precision benefits degrade gracefully as noise is increased  and the benefits are preserved even for high noise levels. for instance  even with 1% type a noise we see that cws delivers a map of 1  which is greater than the corresponding baseline map  1 . we see that cws is more sensitive to type b noise  especially for the  = 1 threshold. here  cws map falls below the baseline for 1% noise;

figure 1: similarity threshold   1

figure 1: similarity threshold 뫟 1
this corresponds to a situation where in many search sessions no relevant results are selected by users.
1 conclusions
cws personalizes search results for a community of likeminded searchers based on their prior search histories. it is appropriate in a wide variety of search scenarios because many web searches are initiated within a community context; for example  the searches initiated from a search box on some themed web site or the searches of some online social group. when responding to a new search query  cws exploits the results of searches for similar queries that have taken place in the past  for a given community  and actively promotes those results. thus  results that are consistently selected for queries will tend to be promoted  although care must be taken to limit the influence of promotional biases as a result of selection noise or malicious users.
모in this paper we have evaluated the performance of cws when search histories contain result selections that are unreliable. obviously  if users select results that are not relevant to their query then there is the risk that these results will be promoted in the future. the question that we have attempted to answer is the degree to which cws is sensitive to such noisy selections. our results indicate that cws is relatively robust to noise with significant precision benefits available even for very high levels of selection noise. this bodes well for cws and is in agreement with the performance benefits witnessed in live-user trials  in which noisy selections are likely to occur. in finishing  it is worth highlighting that the cws approach has been fully implemented in the i-spy system which can be accessed at http://ispy.ucd.ie.
