 
we describe some simple h e u r i s t i c s combining evaluation and mathematical induction which we have implemented in a program that automatically proves a wide v a r i e t y of theorems about recursive lisp f u n c t i o n s . the method the program uses to generate i n d u c t i o n formulas is described at l e n g t h . the theorems proved by the p r o gram include that reverse is i t s own inverse and that a p a r t i c u l a r sort program is c o r r e c t . appendix b contains a l i s t of the theorems proved by the program. 
key words 
lisp  automatic theorem proving  s t r u c t u r a l i n d u c t i o n   proving programs correct. 
introduction 
we are concerned with proving theorems in a f i r s t order theory of l i s t s   akin to the elementary theory of numbers. we use a subset of lisp as our language because recursive l i s t processing functions are easy to write in lisp and because theorems can be n a t u r a l l y stated in lisp; furthermore  lisp has a simple syntax and is universal in a r t i f i c i a l i n t e l l i g e n c e . we employ a lisp i n t e r p r e t e r to ' r u n ' our theorems and a h e u r i s t i c which produces i n d u c t i o n formulas from i n f o r mation about how the i n t e r p r e t e r f a i l s . we combine with the i n d u c t i o n h e u r i s t i c a set of simple r e w r i t e rules of lisp and a h e u r i s t i c f o r g e n e r a l i z i n g the theorem being proved. 
our program accepts as input a ljsp expression  e . g .   
 equal  reverse  reverse a   a   
possibly i n v o l v i n g skolem constants   e . g .   a  b and c throughout t h i s paper  which stand f o r u n i v e r s a l l y q u a n t i f i e d variables ranging over a l l l i s t s . the p r o gram attempts to show that the value of the input expression is always equal to t {whenever the skolem constants are replaced by a r b i t r a r y l i s t s   . theorems we have proved automatically include: 
 equal  reverse  reverse a   a  
        implies  or  member a b   member a c    member a  union b c    and 
 ordered  sort a   
where equal is a p r i m i t i v e f u n c t i o n   i . e . b u i l t i n t o the theorem prover  but reverse  implies  or  member  union  ordered  and sort are defined by the user of the program. the program uses only i t s knowledge of the lisp p r i m i t i v e s and the lisp d e f i n i t i o n s supplied by the uber. no f u r t h e r information is required of the user. 
this paper describes many aspects of the program in b r e v i t y . a thorough presentation is forthcoming in part ii of moore*'a: t h e s i s . 
our lisp subset 
we use a subset of pure lisp which has as p r i m i t i v e s nil  cons  car  cdr  cond  and equal. we do no.t prove theorems about functions that involve side e f f e c t s   rplaca  quote  or label. we use l i s t s of nil to represent natural numbers: 1 is nil  1 is  cons n i l nil   and adp1 is defined as; 
	 lambda  x  	 cons nil x   . 
 our arithmetic is thus a version of peano successor a r i t h m e t i c .   
our equality p r i v i t i v e is equal rather than eq. our cond p r i m i t i v e takes three arguments   f o r s i m p l i c i t y without loss of power .  cond a b c  in our system is  cond  a b   t c   in more t r a d i t i o n a l lisp systems. 
the userof the theorem prover supplies function d e f i n i t i o n s almost exactly as in lisp  with the f u n c t i o n define. for example  
define    append {lambda  x y  
 cond x 
 cons  car x  
¡¡ append  cdr x  y   j y       . 
eval 
our lisp i n t e r p r e t e r   eval  is s i m i l a r in many ways to a normal lisp i n t e r p r e t e r ; eval applies f u n c t i o n defi n i t i o n s and handles p r i m i t i v e s l i k e cond. eval is recursive; it evaluates arguments before applying and evaluating f u n c t i o n d e f i n i t i o n s . our eval has special provisions f o r handling skolem constants and terms in which they appear. the f o l l o w i n g examples i l l u s t r a t e the behaviour of our eval: 
eval  nil   - nil eval { a   = a 
eval   cons a b    =  cons a b  
eval   car  cons a b     = a 
	eval 	 cdr  car  cons a b j    =  cdr a  
eval   cond  cons a b  c d    = c 
eval   append  cons a b  c    =  cons a 
 append b c   
the l a s t example is j u s t i f i e d because regardless of the values of a  b and c  the f i r s t argument to append is not nil  so that the cond in the d e f i n i t i o n of append can be evaluated. 
eval t r i e s to evaluate  append b c  f u r t h e r but f a i l s because it 'recurses i n t o 1 the skolem constant b. 
 see the d e f i n i t i o n of append above.  
when evaluating the form  foo ti . . . t n   where foo is a defined f u n c t i o n   we r e c u r s i v e l y evaluate the arguments f i r s t . c a l l the value o f t i   t j . eval binds the formal variables of foo to t h e i r values  tj   and then evaluates the d e f i n i t i o n of f o o . if a recursive c a l l of foo is encountered in t h i s f u n c t i o n body the arguments are evaluated aa u s u a l . then  if one of the evaluated arguments i1 a car or cdr expression  it is 
added to a l i s t called the bomblist. in this case the definition of foo is not re-applied for this recursive c a l l . the current evaluation of the function body is continued in the hopes of adding more terms to the bohblist. finally  eval returns  foo t1 . . . tl  . 
thus  in evaluating  append b c  the recursive call 
 append  cdr b  c  is encountered in the definition of append.  cdr b  is added to the bohblist indicating recursion on b. finally   append b c  is returned as the value of  append b c . 
evaluation and induction 
partial evaluation is sufficient to prove a few t r i v i a l theorems  for example: 
 equal  append nil b  b  
evals to t since partial evaluation of the append yields b  even though the structure of b is not known. however  induction is usually needed to prove even simple theorems about recursive lisp functions. 
it is intuitively clear that evaluation arid induction are complements. the paradigm for evaluating a simp e recursive function foo is: evaluate  foo  cons a b   in terms of  foo b  and handle the nil case separately. the paradigm for a simple inductive proof that  foo x  is t for any argument x is: show that  foo ml  is t  and then assuming that   1 p  is t  show that  foo  cons a b   is t. 
in particular  recursion starts with some structure and decomposes it while induction starts with nil and builds 
up. this duality cim be used to great advantage: evaluation can be used to reduce the induction conclusion  foo  cons a b   to a statement involving the induction hypothesis.  fqo b t provided that the  cons a b  is one cf the structures that foo decomposes in i t s recursion. 
suppose that we wish to prove by induction that  foo x  is t for a l l x. to show that  foo nil  is t  the obvious thing- to do is call eval and let evaluation solve the problem  for example  eval   append nil b    is b  . we then assume that {foo b  is t  and try to show that  foo  cons a b   is t  for a new skolem constant a. the obvious thing to do now is to call 
eval again and let the recursion in foo decompose the  cons a b . the result w i l l  hopefully  be some simple expression e  involving  foo b ; we then use the hypothesis that  foo b  is t to show that e is t. this process is illustrated by the examples in the next two sections. 
of course  if foo has more than one argument  one must choose which one s  to induct upon. but the link between evaluation and induction makes the choice obvious: induct on the structures that foo recurses on  that i s   on the structures that are being recursively decomposed by foo  by choosing those structures we insure that when eval is called on the induction conclusion   foo  cons a b    foo will be able to recurse at least one step and the problem w i l l be reduced by eval to one involving the induction hypothesis   foo b . 
however  the terms that foo is trying to recurse on are just those that generate the 'errors' noted earlier. to determine what to induct upon we f i r s t eval the expression  expecting to fail  and then i n duct upon some term on the bohblist  that i s   some term which eval failed to evaluate. 

using the induction hypothesis and generalization. 
using the induction hypothesis is not always as easy as it was above. a good example occurs in our program's proof of: 
 1   equal  reverse  reverse a   a   where the definition of reverse i s : 
	 lambda 	 x  
 cond x 
 append  reverse  cdr x   
          cons  cab x  nil   nil . 
if we induct on a in  1  we find that the nil case evaluates to t. we therefore assume  1  as our induction hypothesis and try to prove: 
 1   equal  reverse  reverse  cons a1 a     cons al a   this evaluates to: 
 1   equal  reverse  append  reverse a   cons a1 nil    
 cons al a   
we now wish to use the induction hypothesis   1 . since it is an equality our heuristic is to 'crossf e r t i l i z e '  1  with i t   by replacing the a in the right-hand side of  1  by the left-hand side of  1   giving: 
 1   equal  reverse  append  reverse a   cons a1 nil     cons al  reverse  reverse a    . 
we then consider  1  to be 'used' and throw it away. we must now prove  1  . 
at this point we note that  reverse a  is a subformula which appears on both sides of an equal. furthermore  from the definition of reverse the program can determine that the output of  reverse a  can be any l i s t at a l l . on these grounds we choose to generalize the theorem to be proved by replacing  reverse a  in  1  by a new skolem constant  b  and set out to prove: 
 1   equal  reverse  append b  cons a1 nil     cons al  reverse b   . 
but  1  is easy to prove. eval tells us to induct on b. the nil case evals to t. assuming  1  as the induction hypothesis  we eval the 'cons case':  equal  reverse  append  cons b1 b  c1nsa1 nil    
 1   cons al  reverse  cons b1 b     and get 
 1   equal 
 append  reverse  append b  cons a1 nil    
 cons b1 nil   
 cons a1  append {reverse b   cons b1 nil    . 
we now use our hypothesis   1   by cross-fertilizing 
 1  with i t   replacing  reverse  append b  cons a1 nil    in the left-hand side of  1  by the right-hand side of  1   yielding: 
 1   equal 
 append  cons a1  reverse b    cohs b1 mil    cons a1  append  reverse b   cons bi nil     
finally   1  evals to t because the left-hand side append evaluates to: 
 cons a1  append  reverse b   ccns b1 nil     
which is the right-hand side  so the equal returns t. the theorem is therefore proved. 
our theorem prover takes 1 seconds to produce this proof. if the reader thinks that this theorem is utterly t r i v i a l   he is invited to try to prove the similar theorem: 
 equal  reverse  append a b   
¡¡¡¡¡¡¡¡¡¡¡¡¡¡ append  reverse b   reverse a     which is also proved by the program. 
a description of the program. 
besides eval there are five basic subroutines in our system: normalize  reduce  fertilize  generalize  and induct. below are brief descriptions of these routines. 
normalize applies about ten rewrite rules to lisp expressions. 	for example: 
 cond  cond a b c  d e  becomes  ccnd a  cond b d e   cond c d e    and  cond a a nil  becomes a. 
appendix c lists the rewrite rules. 
reduce attemptsto propagate the results of the tests in cond statements down the branches of the cond tree. 
thus  
 cond a  cond a b c   p a   becomes  cond a b  p nil  . 
fertilize is responsible for 'using' the hypothesis of an implication when it is an equality. a theorem of the form: 
¡¡¡¡¡¡x = y - p y  is rewritten to p x  v x / y. 
we 	make fertilizations of the form: 
x =¡ö y - f z  = g y =  f z  = g x  v x / y 
before any other kind. we call such substitutions 'cross-fertilizations'; we prefer cross-fertilizations because they frequently allow the proofs we want. after f e r t i l i z i n g we never again look at the equality hypothesis although we retain it for soundness. 
generalize is responsible for generalizing the theorem to be proved. this is done by replacing some common subformulas in the theorem by new skolem constants. to prove something of the form: 
¡¡¡¡¡¡p f a   = q f a   we try proving p b  = q b   and to prove plfla   -q f a   we try p b  - q b   
where b is a new skolem constant. however  if the subformula f a  is of a highly constrained type  for instance  it is always a number  an additional condition is imposed on the new skolem constant. 
if the theorem to be generalized i s : 
 equa1  add  length a  b   add b  length a      

generalize produces as output: 
 cohd  lengtype c   equal  add c b   add b c   t  
where lengtype is a lisp function w r i t t e n by generalize from the lisp d e f i n i t i o n of length. in t h i s p a r t i cular case  the function w r i t t e n  by generalize has precisely the d e f i n i t i o n of numberp  namely: 
 lambda  x  
 cond x 
 cond  car x  nil  numberp  cdr x    
t     . 
to perform the generalization described in the previous s e c t i o n   generalize wrote the 'type f u n c t i o n ' f o r reverse:  lambda  x  t   
which was recognized as being no r e s t r i c t i o n at a l l and then ignored. the problem of recognizing the output of a recursive function is c l e a r l y undecidable and very d i f f i c u l t . to write these type functions  generalize uses some h e u r i s t i c s which arc often u s e f u l . 
induct is the program that embodies our i n d u ' t i o n h e u r i s t i c . we now describe the form in which it presents the new induction formula to the other routines and how the induction hypothesis is saved f o r use. 
if the theorem to be proved by induction is  f1 a  and eval indicates that f1 recursen on the cdr of a  the output of induct i s : 
 cond  foo nil  
 cond  f1 a   foo  cons a1 a   t  nil . 
which becomes the theorem to be proved. this is  just the lisp expression f o r : 
 foo nil  &   f1 a  -   foo  cons a1 a       . 
the d e f i n i t i o n s of and and implies are in appendix a. 
the precise form of the induction formula output by induct is d i c t a t e d by the types of ' e r r o r s ' encountered by eval. for example  if both the car and the cdr of a occur on the bomblist  then the induction formula i s : 
 foo nil  &    foo a1  &  foo a   -  foo  cons a1 a       . 
for simultaneous recursion on two variables   e . g . lte in appendix a  or cdring twice in a function   e . g .   ordered   induct produces appropriate induction formulas. a l l o f t h i s information i s collected from the bomblist produced by eval. 
control structure of the program. 
the c o n t r o l s t r u c t u r e of our system is very simple. to prove that some lisp expression  thm  always evaluates to t  we execute the f o l l o w i n g loop: loop: set oldthm to thm; 
set thm to r e d u e   n 1 r m a l i z e   e v a l   t h m       ; if thm = t  then return; if thm is not equal to oldthm  then goto loop; if f e r t i l i z a t i o n a p p l i e s   then set thm to fertilize thm  otherwise  if thm is of the form  cond p q nil  
then set thm to  cond induct{generalize p   q nil  
otherwise  set thm to induct generalize thm  ; goto loop; 
it should be noted that a l l of the important c o n t r o l structure is embedded in the lisp expression thm. for example  when induct needs to prove the conjunction of the nil case and the induction step  it is a c t u a l l y done by replacing the expression thm by a lisf expression which has value t if and only if that conjunction is t r u e . if the nil case evaluates to t  then eval returns the second conjunct  which becomes the theorem to be proved. 
conclusion. 
we find it natural to use the routines eval  normalize  and reduce both to rewrite lisp expresssions; and prove theorems. our experience confirms  and was motivated by  a conviction that proofs and computations are essentially s i m i l a r . this conviction was inspired by bob kowalski and pat hayes  and the beauty of lisp. cur program is in the style of theorem proving programs w r i t t e n by woody bledsoe. 
we would l i k e to note that our program uses no search and applies no lemmas. consequently our theorem prover frequently reproves simple facte l i k e the r.r~ociativity of append. the philosophy of our 
program is to make the correct guess the f i r s t time and to pursue one goal with power and perseverance. 
our program uses structural induction  which was i n t r o duced into the l i t e r a t u r e by b u r s ' a l l  1   although it was used e a r l i e r by mccarthy and painter  1  in a compiler correctness proof. common a l t e r n a t i v e inductive methods f o r recursive languages are computational induction  park  1  and debakker and scott  1  and recursion induction  mccarthy  1 . both are e s s e n t i a l l y induction on the depth of function c a l l s . milner  1  and milner and weyhrnueh  1  describe a proof checker f o r s c o t t ' s logic f o r computable functions  scott  1  which uses computational i n d u c t i o n . the most commonly used method is for flowdiagram languages and was suggerted by naur  l1  and floyd  1 .  n t h i s approach  inductive assertions are attached to points in a program and are used to generate ' v e r i f i c a t i o n c o n d i t i o n s '   which are theorems which roust be proved to e s t a b l i s h the correctness of the program. king  1   good  1   cooper  1  and gerhart  1  have implemented systems which use t h i s method for languag s which include assignments  possibly to arrays  find jumps or loops  but without defined procedure c a l l s . the user supplies the inductive assertions and the systems generate the v e r i f i c a t i o n conditions. king and cooper have incorporated automatic theorem provers which attempt to prove the theorems generated. topor and b u r s t a l l  1  use a f l o y d - l i k u method on a language with procedure c a l l s . they require user supplied inductive assertions but a symbolic i n t e r p r e t e r   l i k e our evai.  generates the v e r i f i c a t i o n conditions  deutsch  1  also uses symbolic e v a l u a t i o n . wegbreit  1  and katz and manna  1  present heuristics f o r generating inductive assertions automatically. brotz and floyd  1  have implemented an arithmetic theorem prover very similar to ours. their system generates i t s own induction formulas and uses the generalization h e u r i s t i c we use  without 'type f u n c t i o n s '   . they induct upon the right-most skolem constant appearing in the statement of the theorem rather than using eval and the bomblist as we do. their h e u r i s t i c w i l l always choose a term recursed upon  due to r e s t r i c t i o n s on the forms of recursive equations allowed  but it w i l l not always choose the one we choose. darlington and b u r s t a l l  1  describe a system which w i l l take functions such as the ones in our lisp subset and write equivalent 
programs which are more e f f i c i e n t . this system w i l l replace recursion by i t e r a t i o n   rnerge loops  and use data structures   d e s t r u c t i v e l y   when permitted. 
appendix a contains the definitions of the lisp functions we use in the proofs of the theorems in appendix b. the program automatically proves a l l of the theorems in appendix b. the average time it takes to prove each theorem is 1 seconds on an icl 1 using pop-1. the time is almost completely spent in pop-1 l i s t processing  where the time for a cons is 1 microseconds  and for car and cdr it is 1 microseconds. 
our work is supported by a british science research council grant. our thanks to professor bernard meltzer. 
machine intelligence 1. pp. 1 -1  eds meltzer  b. 
and michie  d.  edinburgh university press. 
scott  d.   1 . 'outline of a mathematical theory of computation1 . oxford university computing laboratory  programming research croup  technical monograph prg-1. november 1. naur  p.   1   'proof of algorithms by general snapshots'. bit  vol. 1  pp. 1. 
floyd  r.w.  {1 . 'assigning meaning to programs'. in proceedings of a symposium in applied mathematics. vol. 1. mathematical aspects of computer science  pp. 1.  ed. schwartz  j.t.  . 

