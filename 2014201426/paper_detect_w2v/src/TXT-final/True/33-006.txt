 
　　　we present a model of natural language use meant to encompass the language-specific aspects of understanding and production. the model is motivated by the pervasiveness of non-generative language  by the desirability of a language analyzer ana a language production mechanism to share their knowledge  and the advantages of knowledge engineering features such as ease of extention and modification. 
	this model has been 	used 	as 	the 	basis 	for 
phran  a language analyzer  and phred  a language production mechanism. we have implemented both these systems using a common knowledge base; we have produced versions of phran that understand spanish and chinese with only changing the knowledge base and not modifying the program; and we have implemented phran using the query language of a conventional relational data base system  and compared the performance of this system to a conventional lisp implementation. 
1 	introduction 
　　　the need to cope with large quantities of knowledge has led to the emergence of  knowledge engineering issues in a r t i f i c i a l intelligence. as it is desirable in practice for a system to be robust  modular  extensible  and easy to modify  a good deal of attention has been paid to the problem of designing systems that manifest these properties. much of this research presumes that these goals w i l l require ways of appropriately structuring the knowledge needed by the system  and thus is concerned with producing useful knowledge representations. 
　　　constructing a natural language processing system may be viewed in exactly this manner. both natural language analysis programs  those that input sentences and output meaning representations  
and natural language production programs  those that look at meaning representations and output sentences  require a large body of knowledge  namely  knowledge about what the utterances of the language mean. however  the tendency has been to resist this point of view  and treat language knowledge as being somehow special. thus while existing natural language processing systems vary considerably in the kinds of knowledge about language they possess  as well as in how this knowledge is represented  organized and u t i l i z e d   the knowledge possessed by most of these systems has not been subjected to the sort of knowledge engineering analysis that knowledge of other kinds of knowledge-based systems have undergone. 
　　　we propose an alternative a model of language use that is derived from viewing language processing systems as knowledge-based systems. the knowledge that needs to be represented and organized here is the large amount of knowledge about what the utterances of a language mean. in this paper  i describe some of the theoretical underpinnings of the model  and then describe two 
 research sponsored by the office of naval research under contract n1-c-1. 
programs  phran and phred  that are based on these ideas. we have conducted a number of experiments with these systems that have some bearing on the u t i l i t y of the model's presumptions  including testing these systems on other languages  spanish and chinese   and implementeing one of them in a 
relational data base system. 
	1 	the assumptions of the model 
	1 	the importance of non-generative language 
　　　language user knows a great number of facts about what utterances of their language mean. that i s   they know the meanings of a large number of words  and know the rules for relating these meanings to the occurrence of those words in an utterance. moreover  they know the significance of a set of meaningful linguistic units that are not necessarily understood in terms of their components. we call a l l such units phrases . included in this set are idioms  canned phrases  lexical collocations  cliches  structural formulas  and other non-generative language structures. for example  the language user needs to know the particular fact that  out of the blue  means unexpectedly  and that   person1  bear  person1  a  sentiment  is a way of expressing a continued sentiment of one person toward another tas in john bears mary a grudge    our conjecture is that such units constitute a very considerable fraction of the language knowledge needed by an intelligent language processor. 
　　　in most theories of language  non-generative forms are usually considered to be theoretically uninteresting entities  or i r r i t a t i n g special cases that violate the aesthetics of one's theory. however  if such structures do play a central role in language use  then most language processing is actually the application of these special case rules. this is precisely the point of view we take. that i s   while our model allows for the more traditional  very general word-to-meaning mappings  these mappings play no priviledged role. both generative and non-generative knowledge is represented and applied uniformly - the only difference is in the degree of abstractness of the knowledge encoded. 
　　　once this view is taken  both language analysis and language production become kinds of data base management problems. the knowledge about the meanings of phrases of different shapes and abstractness is the data base. the problem is to represent this knowledge so it can be applied uniformly  and so it can be accessed correctly and e f f i c i e n t l y for various language processing tasks. 
　　　while we believe that the notion of the primacy of phrase units is psychologically sound  we in fact take the data base notion quite seriously. that i s   in terms of building practical  efficient language processing systems  the dominating problem may be one of data base management rather than computational complexity of the language processing algorithm. we w i l l discuss the implications of this hypothesis below. 
1 

　　　it should also be mentioned that we do not view our acceptance of a theory based on special cases as an abandonment of the hope of finding scientifically interesting generalisations to make about language. in fact  we believe there are principles of language use that can be derived from our approach. they are just not the principles one normally associates with language structure. rather they are general principles of the application of this language knowledge. interestingly  they are instances of more general principles that are also applicable to knowledge application that have no relation to language per se. the nature of some of these princinles is discussed in wilensky and arena f 
1  1a   
	1 	sharable knowledge base 
     language analysis and language production are of course very different problems. in language analysis  the task is to identify the meanings of incoming utterances; in production  the goal is to choose a language form the best encodes one s idea and intentions. however  in spite of these differring natures  it is reasonable to ask what knowledge these tasks share in common. as the language the user speaks and understands is more or less the same  it would not seem unreasonable that knowledge he uses to encode an idea in a sentence and knowledge he uses to understand the meaning of that very same sentence should somehow be related. 
     in our model  it is assumed that the knowledge uaed for analysis and for production is by and large the same. that is. there is only one data base of knowledge about the meaning of a language's forms. this knowledge base may be indexed and therefore accessed differently for different tasks  thus accounting for some or the asymmetries between the analysis and production. but the language knowledge used by both tasks is the same knowledge represented the same way. 
     'there are a number of reasons for believing that this assumption may be true for human language processors. por example  people do not generally use words that they cannot understand  a possibility if their understanding and production knowledge were uncoupled. also  it is certainly possible to talk about the meaning and use of a word or phrase independently or whether one is understanding or saying i t . in fact  in our common understanding  separate analysis and production definitions for words are not recognized. that is  we do not normally believe that a word has one meaning when you say it and a separate meaning when you hear i t . 
     however  the knowledge engineering reasons for this decision are more compelling. by having the knowledge of the two components be a shared data base  only one form of representation is needed. moreover  the addition of new knowledge to this data base extends the capabilities of both systems simultaneously. one need only assert a piece of knowledge about the meaning of a phrase to the data base  and system will be able to understand that phrase when it occurs  as well as be able to use that phrase to express an idea for which the phrase is appropriate. as this requirement forces knowledge to be represented declaratively  the other benefits of such representations are enjoyed as well. 
1 	benefits of declarative representations 
　　　if language knowledge is to consist of one large data base used both for analysis and production  then it is imperative that this knowledge be stored in a highly declarative format. only in this banner can the same knowledge be used for two quite different tasks. structuring the knowledge in this fashion entails several traditional knowledge engineering advantagea. for example  in this format  knowledge about the language is kept separate from the processing strategies that apply this knowledge to the understanding and production tasks. thus adding new knowledge requires only adding new assertions to the data base  not writing and debugging new code. 
　　　in addition  other knowledge besides the meaning of a phrase can be easily associated with such declaractive representations. for example  the context in which a certain phrase is appropriate may be stored together with the meaning of that phrase; the analyzer can use such knowledge to help infer the context  the production mechanism to decide whether or not to use that phrase in a particular situation. such additional information would be more difficult to introduce into a system that did not have phrasal knowledge stored as objects  i. e.# that wasn't phrasally oriented and didn't use declarative representations. 
1 phran and phred 
     we have been developing this model of language use in two related programs  phran  phrasal analyter  and phred  phrasal english diction . phran is a language understanding program written by 
yigal arens. it reads english sentences and produces representations from them that encode their meaning. phred is a natural language production mechanism developed by steven upstill. phred takes meaning representations as input and expresses them in english sentences. 
     both phran and phred share a common data base of language knowledge. this data base contains declarative representations about what the phrase of the english language mean. this knowledge is stored in the form of pattern-concept pairs. a pattern is a phrasal construction of varying degrees of specificity. for example  it may be an exact literal string  such as so s your old man'; it may be a pattern of limited flexibility such as   nationality  restaurant   or  person   kick  the bucket*'; or it may be a very general phrase such as   person   give   person   object  . 
     the concept part of a pattern-concept pair is a conceptual template that represents the meaning of the associated phrase. the conceptual template is a piece of meaning representation with possible 