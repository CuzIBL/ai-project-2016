 
scientific discovery is a complex process  and in this paper we consider three of its many facets - discovering laws of qualitative structure  finding quantitative relations between variables  and formulating sfructural models of reactions. we describe three discovery systems - glauber  bacon  and dalton - thr.t address these three aspects of the scientific process. glauber forms classes of objects based on regularities in qualitative data  and states abstract laws in terms of these classes. bacon includes heuristics for finding numerical laws  for postulating intrinsic properties  and for noting common divisors. dalton formulates molecular models that account for observed reactions  taking advantage of theoretical assumptions to direct its search if they are available. we show how each of the programs is capable of rediscovering laws or models that were found in the early days of chemistry. finally  we consider some possble interactions between these systems  and the need for an integrated theory of discovery. 
introduction: the diversity of discovery 
　scientific discovery is a process through which we acquire knowledge about the world this knowledge takes many forms  ranging from empirical regularities to structural models  and from qualitative relations to numerical laws. the diversity of scientific knowledge is accompanied by a diversity of processes for generating that knowledge. for instance  one would expect that quite different forms of reasoning led to the discovery of the ideal gas law  to the classification of organisms  and to the formulation of the atomic hypothesis. 
　given the diversity of scientific discovery  two basic questions present themselves. first  what are the various types of scientific knowledge and the processes that lead to them  second  how do these forms of reasoning interact to enable science as a whole to advance  in this paper we provide a response to the first of these questions in the form of three al systems that address different aspects of the discovery process. one of these programs focuses on finding laws of qualitative structure  another is concerned with discovering quantitative relations between variables  and the third deals with the formulation of simple structural models. below we discuss each of the systems and its application to some of facet of the history of chemistry. we will reserve our comments on the second question - how these systems might interact - until after we have described the systems themselves. 
p. langley is affiliated with the robotics institute  while j. m. 
zytkow  g. l. bradshaw  and h. a. simon are associated with the department of psychology. this research was supported by contract n1-1 from the office of naval research. 
discovering qualitative laws 
　by the 1th and 1th centuries  chemists had made considerable progress in classifying substances on the basis of observable properties. for example  the class of acids had been defined in terms of its members' sour taste  their changing the color of organic dyes  dissolving metals  and so forth. exceptions to these characteristics occurred  but sufficient regularity was present to make acid a useful concept. along with acids  other classes such as metals  alkalis  and salts had been formulated in terms of similar properties. in addition to basing classes on properties of individual substances  the early chemists also noted relations between substances. thus  they formulated the qualitative law  acids combine with alkalis to form salts   later generalizing this by replacing alkalis with the more abstract notion of a base. 
glauber: a qualitative discovery system 
　in order to better understand the processes through which such laws were found  we constructed a qualitative discovery system. we have named the program glauber  after the 1th century chemist who played an important role in developing the theory of acids and bases. glauber inputs qualitative facts  such as  hydrochloric acid tastes sour  and  hydrochloric acid combines with sodium hydroxide to form sodium chloride   and produces two forms of output: a set of abstract classes  such as acids  alkalis  and salts  along with their members; and a set of laws  such as  acids taste sour  and  acids react with alkalis to form salts   stated in terms of these classes. 
　we should say a few words about glauber's representation of data  since it has implications for the system's discovery methods. facts are represented using a simple frame-like structure  consisting of a predicate followed by a number of attribute-value pairs. the facts mentioned above are represented by the propositions  has-quality object  hydrochloric-acid  taste  sour   and  reacts inputs  hydrochloric acid sodiumhydroxide  outputs  sodium-chloride  . in the second expression the predicate is reacts  the two attributes are inputs and outputs  and their respective values are  hydrochloricacid sodium-hydroxide  and  sodium-chloride . in this example  the inputs attribute has two values  which represent the two substances that combine in the reaction. glauber knows that the order of these values is not significant. 
noting patterns and defining classes 
　glauber inputs a set of facts such as the above  and iterates through all symbols that occur as values  searching for facts that have the same predicate and the same value for a given attribute. for example  upon considering the symbol sour  the system would note that a number of chemicals - hydrochloric acid  nitric acid  and sulfuric acid - all have a sour taste. when such a regularity is discovered  glauber defines a new class and 
　
1 p. langley et al. 
stores the symbols that differ in these facts as members of the class. in addition  the program formulates a pattern that is identical with these facts  but in which the differing values have been replaced by the class name. if we call the class formed in this example sour tasters  then the three substances would be stored as members of this class  and the associated pattern would be represented as  has quality object  sour tasters  taste  sour  . 
　relational patterns can also be discovered. for instance  suppose that while focusing on sodium hydroxide  glauber notes that this chemical combines v/ith hydrochloric acid to form sodium chloride  with nitric acid to form sodium nitrate  and with sulfuric acid to form glauber's salt  na1so1  in this situation  glauber would create two classes. the first  let us call it sodium-hydroxide-reactors  contains hydrochloric acid  nitric acid  and sulfuric acid  while the second  sodium hydroxideresults  contains sodium chloride  sodium nitrate  and glauber's salt the associated pattern would be stated as  reacts inputs 
 sodium hydroxide sodium-hydroxide reactors  outputs  sodiumhydrox ide-results  . 
combining classes and recursing to higher levels 
　the early chemists noted that certain patterns tended to occur together  and glauber achieves a similar insight. the system compares classes and combines those having a high percentage  determined by a system parameter  of elements in common. the new class is then compared to others so that further combinations can occur. for example  having generated the initial classes and patterns described above  glauber notes that every member of the sour-tasting class also fits the pattern associated with the sodium hydroxide reacting class  and vice versa . as a result  the members of these two groups would be combined into a new class. this class would have two associated patterns  one involving taste and the other concerning reactions. the process is repeated  until eventually glauber arrives at the three classes we know as acids  alkalis  and salts  each with a set of associated patterns. 
　since patterns are stated in the same manner as the initial facts  glauber can recursively apply its abstraction methods to the patterns themselves. using this strategy  the system notes that hci  hn1  and h1 all react with with alkalis to produce salts  leading it to define a new class containing these elements. upon realizing that this class is identical with the class of acids defined earlier  it combines the two concepts  and formulates the general law  reacts inputs  acids alkalis  outputs  salts  . thus  glauber arrives at one of the central results of the 1th 
century chemists. when provided with additional data about metals and their reactions with acids  the system also defines the more abstract notion of base  along with the more general law that acids react with bases to form salts. although the current version of glauber treats all classes as equivalent  the introduction of more data will require future versions to focus attention on some classes  such as those occurring in the most patterns  in favor of others. 
discovering quantitative laws 
　around the turn of the 1th century  three fundamental discoveries were made concerning quantities of substances forming chemical compounds. the first of these was proust's  1  law of constant proportions  which states that the weight ratio of constituent elements is constant for a given compound. the second advance was dalton's  1  formulation of the law of multiple proportions. this law asserts that when two elements combine to form several different compounds  the ratios of their combining weights are always small integer multiples of one another. the third was gay lussac's  1  discovery of the law of combining volumes  which states that gases combine in small integer ratios by volume. these three discoveries provided the foundation for a quantitative theory of chemical reactions  and ultimately led to the determination of the atomic weights of the elements. although the work of dalton and gay-lussac was at least partially motivated by the atomic hypothesis  we shall see that data-driven methods are sufficiently powerful to find these laws. 
finding numerical relations in noisy data 
　we have explored the process of quantitative discovery through bacon.1  the sixth in a line of programs named after sir francis bacon. given a set of independent variables. bacon.1 varies one of them  looking for relations between that term and some dependent variable. once a functional relation has been found  the parameters in that function are given the status of dependent terms at a higher level of description. when the system varies the next independent term  it looks for a relation between that variable and the new higher level terms. this process continues  with bacon.1 recursing to higher levels of description  until all the independent terms have been incorporated into a complex quantitative relationship we will not discuss this process in any great detail  since it has been described for earlier versions of bacon  1  1 . 
　unlike previous versions  bacon.1 is capable of dealing with significant amounts of noise in its data. the program uses a differencing technique to find the best polynomial function for relating two terms. however  it also considers polynomial relations between functions of these terms  so that relations such 
	1 	1 
as y = ax1 + bx + c  and sin y  -- alog x  + b can be found. the differencing method accepts any relation that accounts for more than a user specified percentage of the variance in the data. when this requirement for explained variance is high  bacon.1 behaves much like its predecessors: if the data are noise-free  it generates only a single hypothesis; however  if the data are noisy  it fails to find any relation at all. in contrast  when the setting is low  the system tends to generate a number of alternate hypotheses  whether the data are noisy or not. 
　in cases where a number of competing hypotheses have been generated  bacon.1 must have some way to order these hypotheses. in addition to the explained variance  the system takes into account the complexity of each law  measuring this by the number of terms that make up the polynomial expression. the user can specify the exact role played by the two criteria  but in our experiments with the system  we have found that the ratio of explained-variance to complexity gives good results. once the score for each hypothesis has been calculated  a threshold score is computed  and only those laws exceeding the threshold are retained. bacon.1 also takes the generality of each law into account. for example  if two laws are found to describe the relation between y and z when x = 1  but one of these laws does not fit well when x = 1  then that law will be rejected. in this way  the system ensures that only hypotheses holding across a broad range of data are retained. 
intrinsic properties and common divisors 
　while the above heuristics are useful for discovering relations between numerical terms  they cannot be used to relate nominal of symbolic independent terms to numeric dependent variables  and this is precisely the situation in which the early chemists found themselves. for instance  the independent terms in proust's  dalton's  and gay-lussac's chemical experiments were 
　
the elements or compounds involved  while the dependent terms were numerical measures such as weight or volume. in such cases  bacon.1 defines intrinsic properties that take on numeric values  and associates these properties with the nominal terms. 
　given control over the substances entering and resulting from a reaction  as well as the weight of the first substance that is used  the system gathers the data in table 1. upon varying the amount of oxygen used to form nitric oxide  no   the program discovers that the two weights w1 and w1 are linearly related with a slope of 1 and a zero intercept. upon varying the output of the reaction  bacon.1 examines the weight relations for the compound nitrous oxide  n1 . in this case  the law is also linear  but the slope has changed to 1. a similar result is obtained for nitrogen dioxide  and in this case the slope is 1. 

table 1. determining the combining weights for reactions. 
　the slopes that bacon.1 finds in these experiments are closely related to the weight ratios found by proust. having found these ratios  the program defines an intrinsic property  say p  whose values are associated with the three nominal values under which they occur. thus  the value of p for the triple nitrogen/oxygen/nitric oxide would be set to 1  the value for nitrogen/oxygen/nitrous oxide would be 1. and the value for nitrogen/oxygen/nitrogen dioxide would be 1. as stated  these intrinsic values simply store an already known fact. however  they can be retrieved in future experiments involving the same chemicals  and used to make predictions or to discover new empirical laws. 
　proust's insight about combining weights laid the groundwork for dalton's law of multiple proportions  and bacon.1 includes a heuristic which lets it discover just such a relation in the data from table 1. this heuristic operates whenever the system is about to define a new intrinsic property  examining the values of the new property to see if they  or their inverses  have a common divisor. in this case  bacon would note that 1  1  and 1 have the common divisor 1  and would replace these intrinsic values with their corresponding integers 1  1  and 1. later  if other common divisors were found for other pairs of elements  the program would define a higher level intrinsic property based on these divisors  and associate them with thoso pairs of elements. thus  the common divisor 1 would be associated with the nitrogen/oxygen pair  the divisor 1 with carbon and oxygen  and so on. these relations are formally equivalent to dalton's law of multiple proportions. bacon takes a similar path in discovering gay-lussac's common divisors for combining volumes  and has even arrived at the correct relative atomic weights of hydrogen  oxygen  and nitrogen from similar data. in summary  bacon's mechanisms account for many of the quantitative laws found by chemists in the early 1th century. 
p. langley et al. 1 
formulating structural models 
　although dalton's atomic hypothesis was readily accepted by many chemists  its application to specific reactions was far from clear. dalton inferred the structure of various compounds using his rule of greatest simplicity  along with the assumption that all elements were monatomic. this led him to conclude that a molecule of water was composed of a single hydrogen atom and a single oxygen atom. in contrast  avogadro  1  employed gay-lussacs data on combining volumes and the assumption that equal volumes of gas contained equal numbers of particles. using this information  he inferred diatomic models for hydrogen and oxygen and a different structure for water. 
searching the space of structural models 
　in order to understand the process by which chemists constructed structural models of chemical reactions  we have implemented a third discovery system - dalton - that focuses on this issue. the system knows that two quantities are important for any model of reaction - the number of molecules of each substance that takes part  and the number of particles in each molecule. suppose the system is told that hydrogen reacts with oxygen to form water  and is asked to construct a molecular model of this process. in this case  the program must determine the number of hydrogen  oxygen  and water molecules  and the internal structure of each type of molecule. the system operates by starting with a model in which no commitments are made  and successively refines this model as it proceeds. 
　starting with a model of the form  ho-  w   dalton first considers the number of hydrogen molecules involved. lacking any theoretical bias  the system assumes the simplest choice of a single hydrogen molecule. if this choice later causes difficulty  the model-builder can back up and try another path. similar initial choices are made for oxygen and water. this is represented by the proposition   h   o  -   w    in which each molecule is enclosed in parentheses. now dalton must determine the internal structure of each type of molecule  and it assumes for both hydrogen and oxygen a single elementary particle  say h and o   giving the model   h   o  - *  w  . at this point  the program invokes the theoretical assumption that the total number of particles in any reaction is conserved. this gives the final model   h   o  -*  h o    which is equivalent to that originally formulated by the human dalton. in this case  the program has arrived at an acceptable solution without needing to backtrack. 
altering the search process 
　in the above run  the system had no theoretical biases other than a belief in conservation of particles and a desire to construct as simple a model as possible. however  if we give dalton some additional information about the water reaction  its behavior changes significantly.'avogadro believed that the combining volumes which gay-lussac observed were related to the number of molecules involved in the reaction. given this assumption  and knowledge of the combining volumes   our program instead postulates two molecules of hydrogen and water  while retaining the assumption of one oxygen molecule  giving the partially specified model   h   h   o  -   w   w  . 
　at this point the system considers the internal structure of the hydrogen and oxygen molecules  and initially assumes both to be monatomic. however  for the resulting model    h   h   o  -   w   w    there exists no decomposition of water in terms of h and o that satisfies the conservation assumption  so the program 
　
1 p. langley et al. backs up and considers another alternative. at this point dalton hypothesizes the oxygen molecule as composed of two particles  and since this satisfies conservation  a final model is constructed:   h   h   o o  -+  h o   h o  . while this model differs from the modern day one  it is consistent with guy-lussac's data and encounters difficulty only when other reactions are considered. for example  when the ammonia reaction is encountered  dalton must revise its monatomic assumption for hydrogen  and arrives at the correct water model:   h h   h h   o o  -   h h o   h h o  . 
　since theoretical assumptions can influence dalton's behavior to such a great extent  we should mention the form in which this information is presented. dalton is stated as a production system  and in default mode it uses a few simple rules to formulate simpler models first  and more complicated ones as necessary. however  if new condition-action rules are added to the system  they take precedence over the default rules and can direct search down paths that might otherwise not be considered. thus  one can insert a rule that would match if the combining volumes of substances are known  and use this information to determine the number of molecules used in the model. the conservation assumption is implemented in a similar fashion  so that it generates a molecular structure of a reaction's output that uses all particles occurring in the input. while the current version of dalton is capable of formulating only very simple structural models  it does provide an initial account of this process  and the manner in which theoretical assumptions can alter the search strategy. 
discussion 
　although we have considered only chemical discoveries in our examples  each of the systems we have described is stated in a very general fashion and there is no reason they could not be applied to other domains as well. this is one direction in which we should apply our future research efforts. however  an even more interesting possibility presents itself. a complete theory of the scientific process must not only account for different types of discovery; it must also explain the interactions between these different facets. although we have not yet linked our three systems computationally  we have considered some steps towards creating such an integrated model of discovery. 
   for example  qualitative laws generally appear earlier in the development of a field than do quantitative lawo. thus  one can imagine a system like glauber first discovering laws of qualitative structure  and then passing this information on to a bacon-like system  which would use it to determine the variables it should consider and the experiments it should run. similarly  data-driven discovery often precedes theory-driven discovery. thus  one can imagine bacon arriving at regularities such as guy-lussac's law of combining volumes  with dalton employing this information to direct its search process. of course  information could flow in the other direction as well. once dalton had determined the molecular structure of a pair of elements in one reaction  it might predict the combining volumes for new reactions; it could then pass these expectations on to bacon  where such expectations could play an important role in dealing with noisy data. in the field of genetics  glauber might use data about inherited characteristics to classify offspring into genotypes  and dalton might use this classification in replicating mendel's two-trait model of heredity. in the other direction  glauber might view dalton's models as data  and note the distinction between dominant and recessive traits. 
　in addition to being interesting in their own right  such interactions would provide important constraints on our models of discovery. for instance  the current version of bacon must be supplied with a set of variables by the programmer  and the usefulness of bacon's discoveries is judged mainly by the user. thus  there are very few constraints on either the system's inputs or its outputs. we do not feel that bacon fares any worse on these dimensions than other learning and discovery systems  but these are still issues that should be addressed. in attempting to construct an integrated discovery system  we expect that the interactions between different components will constrain the approaches we explore. thus  by requiring bacon's expectations to come from glauber or dalton  and by insisting that bacon's discoveries be used by the other systems  we hope to account for facets of discovery that could not be explained by studying the various components in isolation. 
　before closing  we should say a few words about the relations between our our systems and earlier al research on discovery. for example  the patterns generated by glauber bear some resemblance to those produced by brown's  early system  while its approach to classification is related to lenat's  heuristics for mathematical discovery  and to michalski and stepp's  conceptual clustering strategy. however  the details of glauber's operation differ considerably from each of these programs. bacon's techniques for finding numeric laws in the presence of noise are reminiscent of gerwin's  early work in this area  though bacon can deal with more complex functions and employs a different curve-fitting method. finally  dalton's search for molecular models is similar in some ways to dendral's  search for organic compounds to explain mass spectrographs  though the latter explored p. much larger space of hypotheses and required considerable knowledge of chemistry to direct its search through that space. thus  while our discovery systems are related to earlier work in the area  they also differ in some important ways. furthermore  unlike the earlier programs  our systems show a potential for being combined into a more complete  integrated theory of discovery. 
