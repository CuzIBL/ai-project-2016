
as computer systems continue to increase in complexity  the need for ai-based solutions is becoming more urgent. for example  high-end servers that can be partitioned into logical subsystems and repartitioned on the fly are now becoming available. this development raises the possibility of reconfiguring distributed systems online to optimize for dynamically changing workloads. however  it also introduces the need to decide when and how to reconfigure. this paper presents one approach to solving this online reconfiguration problem. in particular  we learn to identify  from only low-level system statistics  which of a set of possible configurations will lead to better performance under the current unknown workload. this approach requires no instrumentation of the system's middleware or operating systems. we introduce an agent that is able to learn this model and use it to switch configurations online as the workload varies. our agent is fully implemented and tested on a publicly available multi-machine  multi-process distributed system  the online transaction processing benchmark tpc-w . we demonstrate that our adaptive configuration is able to outperform any single fixed configuration in the set over a variety of workloads  including gradual changes and abrupt workload spikes.
1 introduction
the recent introduction of partitionable servers has enabled the potential for adaptive hardware reconfiguration. processors and memory can be added or removed from a system while incurring no downtime  even including single processors to be shared between separate logical systems. while this allows for more flexibility in the operation of these systems  it also raises the questions of when and how the system should be reconfigured. this paper establishes that automated adaptive hardware reconfiguration can significantly improve overall system performance when workloads vary.
　previous research  wildstrom et al.  1  has shown that the potential exists for performance to be improved through autonomous reconfiguration of cpu and memory resources. specifically  that work showed that no single configuration is optimal for all workloads and introduced an approach to learning  based on low-level system statistics  which configuration is most effective for the current workload  without directly observing the workload. although this work indicated that online reconfiguration should  in theory  improve performance  to the best of our knowledge it has not yet been established that online hardware reconfiguration actually produces a significant improvement in overall performance in practice.
　this paper demonstrates increased performancefor a transaction processing system using a learned model that reconfigures the system hardware online. specifically  we train a robust model of the expected performanceof different hardware configurations  and then use this model to guide an online reconfiguration agent. we show that this agent is able to make a significant improvement in performance when tested with a variety of workloads  as compared to static configurations.
　the remainder of this paper is organized as follows. the next section gives an overview of our experimental testbed. section 1 details our methodology in handling unexpected workload changes  including the training of our agent  section 1  and the experiments used to test the agent  section 1 . section 1 contains the results of our experiments and some discussion of their implications. section 1 gives an overview of related work  and section 1 concludes.
1 experimental testbed and system overview
servers that support partitioning into multiple logical subsystems  partitions  are now commercially available  quintero et al.  1 . each partition has independent memory and processors available  enabling it to function as if it were an independent physical machine. in this way  partitions  and applications running on separate partitions  are prevented from interfering with each other through resource contention.
　furthermore  these servers are highly flexible  both allowing different quantities of memory and processing resources to be assigned to partitions  as well as supporting the addition and removal of resources while the operating system contin-
ues running. hardware is also available that allows partitioning on the sub-processorlevel; e.g.  a partition can use as little as  of a physical processor on the hosting system  quintero et al.  1 . because reconfigurable hardware is not  yet  easily available  the research reported in this paper simulates reconfiguration of partitions on multiple desktop computers.
　the remainder of this section gives a high-level overview of the testbed setup. a brief description of the tpc-w benchmark and a discussion of some modifications in our testbed can be found in section 1. the software packages we use are given in section 1. the hardware and simulation of sub-processor partitioning and reconfiguration are explained in section 1. finally  an overview of the implementation of the tuning agent is presented in section 1. further testbed and system details can be found in  wildstrom et al.  1 .
1 tpc-w
tpc-w is a standardized benchmark published by the transaction processing performance council. it dictates an instantiation of an online bookstore  with 1 dynamically generated web pages as the user interface. these pages are divided into six browsing and eight ordering pages. relative performance of the system under test  sut  is determined by using one or more external machines  called the remote browser emulators  rbes   running a set of emulated browsers  ebs . these ebs represent individual users of the site and may be browsing the store  searching  and/or placing orders.
　each user follows one of three defined workloads  or mixes: shopping  browsing  or ordering. given a current page requested  the specification defines the respective probabilities of each possible next page for each mix. this results in different ratios of browsing and ordering page references for each mix. these relative percentages are summarized in table 1.
mixbrowsing	shopping	orderingbrowsing pages1%	1ordering pages1%	1table 1: expected access percentages of different pages for the tpcw mixes  specified by  garcia and garcia  1 .
　a single run of the benchmark involves measuring the throughput during a fixed-length measurement interval. the system is allowed to warm up prior to the measurement interval. throughput is measured in web interactions per second  wips   which is the overall average number of page requests returning in a second.
　many commercial systems that publish performance results involve large numbers or heterogeneous machines in complex setups. for simplicity  this work only considers the situation with a single database server  back-end  and a single web server  front-end ; an illustration can be found in figure 1. although the throughputof this relatively small system  reported in section 1  is significantly less than that of a commercially built system  this is due to the substantial difference in overall resources  and the throughput is not unexpected for an experimental system.
　the tpc-w specification places some strict restrictions on various facets of the system. one example is that most pages contain a set of random promotional items displayed at the top; these items are expected to be randomly selected each time the page is generated. we relax this requirement: in our

figure 1: the 1 machines used in the physical setup.
implementation  a set of items is cached for 1 seconds and reused for all pages desiring these promotional items during that time period. other modified specifications can be found in  wildstrom et al.  1 .
　the primary reason specifications are modified is that our intention is to overwhelm the system  whereas the tpc-w specifications are explicitly designed to prevent this from happening. nonetheless  we use tpc-w because it is a convenient way of generating realistic workloads.
1 software
any tpc-w implementation must implement at least 1 modules as part of the sut: a database  an application server  and an image server. the implementation used in this work uses postgresql 1.1 for the database and apache jakarta tomcat 1.1 as both the application and image servers. the java code used by the application server  both for dynamic web page generationand database interaction is derivedfrom a freely available tpc-w implementation from the university of wisconsin pharm project  cain et al.  1 . slight modifications are made to the code: first  to use tomcat and postgresql; second  to allow limited caching of data; and third  to allow the number of connections to the database to be limited. the numberof connectionsis controlledthrougha java semaphore  with fairness enabled . the number of connections allowed is one reconfigurable resource  controlled through a new administrative servlet.
　furthermore  the rbe is modified in two ways. first  connection timeouts are not treated as fatal and are rather retried. also  the ebs are not required to all run the same mix and can change which mix they are using during a benchmark run.
1 hardware
the physical hardware used in this work consists of 1 identical dell precision 1n systems  each with a 1 ghz processor and 1gb ram. a gigabit ethernet switch networks the systems through the built-in gigabit ethernet interfaces. as show in figure 1  one machine is used for each of the frontand back-end systems  while a separate machine hosts the rbe and the tuning agent. in a true reconfigurable system  the tuning agent would likely reside either inside the partitionable system or on a management system.
　although  in practice  the front- and back-end systems are physically independent machines  they are meant to represent partitions within a single reconfigurable system with a total of 1ghz of processing power and 1 gb ram. in order to simulate partitioning such a system into 1 partitions  cpu and memory are artificially constrained on the two machines. the cpu is constrained by a highly favored  periodic busy-loop process; memory is constrained using the linux mlock   subroutine. the constraints on the two systems are set in such a way as to only allow  overall  one full 1 ghz processor and 1gb memory to be used by the combined front- and backends. for example  if the back-end is allowed 1 ghz  the front-end only has 1 ghz available.
　by using both of these constraining processes simultaneously  simulation of any desired hardware configuration is possible. additionally  the processes are designed to change the system constraints on the fly  so we can simulate reconfiguring the system. in order to ensure that we never exceed the total combined system resources  we must constrain the  partition  that will be losing resources before granting those resources to the other  partition. 
1 the tuning agent
the tuning agent handles real-time reconfiguration. there are three phases to the reconfiguration. first  the number of allowed database connections is modified. once this completes  any cpu resources being moved are constrained on the machine losing cpu and added to the other; then memory is removed from the donor system and added to the receiving system. each step completes before the next is begun.
　there are two types of tuning agents we simulate. the first is an omniscient agent  which is told both the configuration to switch to and when the reconfiguration should occur based on perfect knowledge. the omniscient agent is used to obtain upper bound results. this uses a known set of configurations that maximizes the system performance  thus allowing us to have a known optimalperformanceagainst which to compare.
　the second agent is one that makes its own decisions as to when to alter the configuration. this decision can be based on a set of hand-coded rules  a learned model  or any number of other methods. the agent we discuss in this paper is based on a learned model that uses low-level system statistics to predict the better option of two configurations. this learned version of the tuning agent is discussed in detail in section 1
1 handling workload changes
while provisioning resources in a system for a predictable workload is a fairly common and well-understood issue  oslake et al.  1   static configurations can perform very poorly under a completely different workload. for example  there is a common phenomenon known as the  slashdot effect   where a little-known site is inundated by traffic after being featured on a news site. we consider the situation where this site is an online store  which is configured for a normal workload of ordering and shopping users. the large number of unexpected browsing users appearing can overwhelm such a site that is not prepared for this unexpected change in workload. we call this situation a workload spike.
　in addition to such drastic changes  the situation where the workload gradually changes is also possible and must be handled appropriately.
　unfortunately in practice  the workload is often not an easily observable quantity to the system. while it is possible to instrument the system in various ways to help observe part or all of the workload  this would require customizing the middleware for each online store.
　however  previous work  wildstrom et al.  1  has shown that low-level operating system statistics can be used instead to help suggest what configuration should be used in a workload-oblivious way. this approach has the advantage of not requiring any customized instrumentation. by instead using out-of-the-boxversions of software  this method allows for easy replacement of any part of the system without needing significant reimplementation. low-level statistics also do not refer to workload features  and so might be easier to generalize across workloads. for these reasons  we use the lowlevel statistics in preference to customized instrumentation of either the operating system or the middleware.
1 training the model for a learning agent
in order to automatically handle workload changes  we train a model to predict a target configuration given system statistics about overall resource use. to collect these statistics  each machine runs the vmstat command and logs system statistics. because it is assumed that a true automatic reconfigurable system would supply these statistics through a more efficient kernel-level interface  this command is allowed to take precedence over the cpu constraining process.
　vmstat reports 1 statistics: 1 concerning process quantity  1 concerning memory use  1 swapping  1 i/o  1 cpu use  system interrupts  and context switches. in order to make this more configuration-independent  the memory statistics are converted to percentages. the resulting vector of 1 statistics  1 from each partition   as well as the current configuration of the system  comprise the input representation for our trained model. the model then predicts which configuration will result in higher throughput and the agent framework reconfigures the system accordingly.
　for our experiments  we consider two possible system configurations using 1 resources: cpu  memory  and number of connections  table 1 . a wide range of possible cpu  memory  and connection limits were investigated  and the selected configurations maximize the throughput for the extreme situations. in particular  connection limits  although not a hardware resource  were necessary to keep the database from becoming overwhelmed by large numbers of queries during heavy browsing periods.
databasewebserverconfig.cpu	mem.cpu	mem.conn.browsing	1 gb	1 gb1ordering	1 gb	1 gb1table 1: configurations  resource distributions and database connections allowed  used in the experiments.
　in order to acquire training data  1 pairs of varied tpcw runs are done. each pair of runs consists of one run of a set workload on each configuration; the workload consists of 1 shopping users and a random number  between 1 and 1  of either browsing or ordering users  1 pairs each . each run has 1 seconds of ramp-up time  followed by a 1 second measurement interval  during which 1 seconds of vmstat data are also collected.
　from the combination of wips and system statistics gathered on each run  a set of training data points are created for each pair in the following way. first  the system statistics from each run are divided into non-overlapping1 second intervals. the average system statistics over each interval are the input representation for one data point. next  the configuration with the higher throughput  in wips  is determined to be the preferred configuration for all data points generated from this pair. in this way  each of the 1 pairs of runs generates 1 data points.
　given training data  the weka  witten and frank  1  package implements many machine learning algorithms that can build models which can then be used for prediction. in order to obtain human-understandable output  the jrip  cohen  1  rule learner is applied to the training data. for the generated data  jrip learned the rules shown in figure 1.
　as can be seen in figure 1  jrip determines a complex rule set that can be used to identify the optimal configuration for unobserved workload. 1 of the 1 supplied systems statistics are determined to be of importance; these 1 are evenly split over the front- and back-end machines. we can see that all of the front-end statistics used are either related to execution time or memory use  while the back-end statistics sample almost all statistic areas. we also note that the rules specify a means of identifying one configuration over the other; the browsing-intensive configuration is taken as the  default. 
　if we look at the rules in some more depth  we can identify certain patterns that indicate that the rules are logical. for example  rules 1 and 1 both set a threshold on the amount of time spent by the database waiting for i/o  while rule 1 indicates that a large percentage of the memory on the database is in use. all three of these indicators point to a situation where more memory could be useful  as in the database-intensive configuration . when memory is constrained  the database files will be paged out more frequently  so more time will be spent waiting on those pages to be read back in. other trends are discussed in  wildstrom et al.  1 .
　to verify our learned model  we first evaluate the performance of jrip's rules using stratified 1-fold cross validation. in order to prevent contamination of the results by having samples from a single run appearing in both the training and test sets  this was done by hand by partitioning the 1 training runs into 1 sets of 1 runs  each set having 1 data points . the 1 trials each used a distinct set as the test set  training on the remaining 1 sets. in this test  jrip correctly predicts the better target configuration 1% of the time.
　one important facet of the rules learned is that they are domain-specific; although these rules make sense for our distributed system  different rules would be necessary for a system where  for example  both processes are cpu-heavy but perform no i/o  such as a distributed mathematical system . while we do not expect rules learned for one system to apply to a completely different system  training a new set of rules using the same methodology should have similar benefits. by learning a model  we remove the need to explore the set of possibly relevant features and their thresholds manually.
1 evaluating the learned model
we present two types of workload changes: the gradual change and the workload spike. we concentrate our evaluation on the workload spike  as sudden changes in workload require faster adaptation than a gradual change.
　for simplicity  we describe only the simulation of a browsing spike below; ordering spikes are simulated in a similar fashion. three random numbers are generated {x1 x1 x1} （  1 . the base workload consists of 1 shopping users with x1 ordering users. this workload reaches the steady state  1 seconds of ramp-up time   and then there are 1 seconds of measurement time. at that point  the workload abruptly changes to a browsing intensive workload  with x1 browsing users replacing the ordering users. the spike continues for 1 seconds. after this time  the workload abruptly reverts to an ordering intensive workload  with x1 ordering users. after 1 more seconds  the measurement interval ends.
　we also simulate a gradual change. for this  we begin with a workload that consists of 1 shopping users and 1 browsing users. after 1 seconds of ramp-up time and 1 seconds of measurement time  1 browsing users are converted to the ordering mix; this repeats every 1 seconds until all the users are running the ordering mix  at which point the measurement interval continues for 1 more seconds.
　each workload is tested under 1 hardware configurations. as baselines  both static configurations execute the workload. additionally  because we know when the spike takes place and when it ends  we can test the optimal set of configurations with the omniscient agent. for the gradual change  we can see where each configuration is optimal and force the omniscient agent to reconfigure the system at that point. finally  the learning agent is allowed to completely control the configuration based on its observations.
　the agent continuously samples the partitions' system statistics and predicts the optimal configuration using a sliding window of the most recent 1 seconds of system statistics. if a configuration chance is determined to be beneficial  it is made immediately. after each configuration change  the agent sleeps for 1 seconds to allow the system statistics to reflect the new configuration.
1 results and discussion
evaluation of the learning agent is performed over 1 random spike workloads. of these workloads  half are browsing spikes and half are ordering spikes. each workload is run 1 times on each of the static configurations  as well as with the learning agent makingconfiguration decisions  and finally with the omniscient agent forcing the optimal hardware configuration. the average wips for each workload are compared using a student's t-test; all significances are with 1% confidence  except where noted.
　overall  the learning agent does well  significantly outperforming at least one static configuration in all 1 trials  and outperforming both static configurations in 1 of them. there are only 1 situations where the adaptive agent does not have the highest raw throughput  and in both case  the adaptive agent is within 1 wips of the better static configuration.
configurationspike typeadapt.browsingorderingomnisc.ordering1111browsing1111
figure 1: jrip rules learned by weka. numbers are averages over a 1-second interval.table 1: average results  in wips  of different configurations running a spike workload.
the agent never loses significantly to either static configuration. results can be found in table 1.
　in addition to performing well as compared to static configurations  the learning agent even approaches the accuracy of the omniscient agent. in 1 of the 1 ordering spike tests  the adaptive agent is no worse than 1 wips below the omniscient agent  actually showing a higher throughput in 1 tests1. one typical example of the throughputs of each of the four configurations on an ordering spike can be seen in figure 1.

figure 1: wips throughput for each of the configurations during an ordering spike  averaged over 1 runs. the graph at the bottom shows how many learning agents had chosen each configuration at a given time; these choices are all averaged in the  adaptive  graph.
　in handling browsing spikes  the agent consistently exceeds the throughput of one static configuration and always performs at least as well as the other static configuration. in 1 of the 1 tests  the agent actually wins significantly over both configurations. however  the agent has more room for improvement than in the ordering spike tests; on average  the learning agent is 1 wips below the omniscient agent.
　in many of the trials  we see some sudden  anomalous drops in throughput  at approximately 1 seconds in the browsing and omniscient configurations in figure 1 . these drops can sometimes confuse the agent. we believe this confusion is due to abnormal database activity during the anomaly. the cause of the anomalies has been identified1; future work will eliminate these anomalies.
　in addition to spikes of activity  we test gradual changes in workload to verify that the agent is capable of handling gradual changes as detailed in section 1. over 1 runs  the average throughputs of the browsing- and ordering-intensiveconfiguration are 1 and 1 wips  respectively. the learning agent handles this gradual change gracefully  winning overall with an average throughput of 1 wips. there is also room for improvement  as the omniscient agent  which switches configurations when there are 1 users running each of the browsing and ordering workloads  significantly outperforms the learning agent with an average throughput of 1 wips.
　this method for automatic online reconfiguration of hardware has definite benefits over the use of a static hardware configuration. over a wide variety of tested workloads  it is apparent that the adaptive agent is better than either static configuration considered. while the agent has room for improvement to approach the omniscient agent  omniscience is not a realistic goal. additionally  based on the rule set learned by the agent  it is apparent that the problem of deciding when to alter the configuration does not have a trivial solution.
1 related work
adaptive performance tuning through hardware reconfiguration has only recently become possible  so few papers address it directly. much of the work done in this field thus far deals with maintaining a service level agreement  sla . while this work is similar  relevant examples are cited below   this is a fundamentally different problem than that which we are investigating  where there is no formal sla against which to determine compliance. this section reviews the most related work to that reported in this paper.
ibm's partition load manager  plm   quintero et al. 
1  handles automatic reallocation of resources.	while extensively configurable in terms of thresholds and resource limits  it must be hand-configured and follows strictly the rules set out by the thresholds. in contrast  our approach learns the appropriate thresholds to invoke a reallocation.
　menasce＞ et al.  discuss self-tuning of run-time parameters  threads and connections allowed  using a model based approach. the authors suggest that a similar method should be extensible to hardware tuning. this requires constructing a detailed mathematical model of the system with the current workload as an input; our work treats the system as a black box and workload as an unobservable quantity.
　karlsson and covell  propose a system for estimating a performance model while considering the system as a black box using a recursive least-squares estimation approach  with the intention that this model can be used as part of a self-tuning regulator. this approach is intended to help meet an sla goal  using latency as the metric  but only to get as close as possible to the sla requirement without exceeding it  rather than maximizing performance.
　urgaonkar et al.  use a queuing model to assist in provisioning a multi-tier internet application. this approach is intended to handle multiple distinct servers at each tier and assumes that there are unused machines available for later provisioning. our approach is intended to have just oneserver at each tier with a fixed total amount of processing power.
　norris et al.  address competition for resources in a datacenter by allowing individual tasks to rent resources from other applications with excess resources. this frames the performance tuning problem as more of a competitive task; we approach the problem as a co-operative task.
　cohen et al.  use a clustering approach to categorizing performance and related problems. using similar lowlevel statistics to us  they identify related problems  given a signature summarizing the current system status. this work is primarily geared toward simplifying problem diagnosis and analysis  whereas our work works toward automatically correcting the problem.
1 conclusion
the rapid development of reconfigurable servers indicates that they will become more commonly used. these servers run large  distributed applications. to get the most out of the server  each application should receive only the hardware resources necessary to run its current workload efficiently. we demonstrate that agents can tailor hardware for workloads for a given application.
　this work's main contribution is the introduction of a method for automatic online reconfiguration of a system's hardware. this method shows significant improvement over a static allocation of resources. although an agent is only trained for one specific domain  the method is general and is applicable to a large number of possible combinations of operating systems  middleware  and workloads.
　our ongoing research agenda includes further work with the learning agent to approach the optimal results  as well as investigation on different workloads. we also want to predict the benefit of a reconfiguration  both on our simulated reconfigurable machines and on true reconfigurable hardware.
acknowledgments
the authors thank ray mooney and the rest of the cognitive systems reading group for valuable input throughout the research and helpful critiques of the paper. this research was supported in part by nsf career award iis-1  a darpa acip grant  and an ibm faculty award.
