 
this paper is concerned with modeling planning problems involving uncertainty as discrete-time  finite-stale stochastic automata solving planning problems is reduced to computing policies for markov decision processes classical methods for solving markov decision processes cannot cope with the size of the state spaces for typical problems encountered in practice as an allernative  we investigate methods that decompose global planning problems into a number of local problems solve the local problems separately and then combine the local solutions to generate a global solu tion we present algorithms that decompose planning problems into smaller problems given an arbitrary partition of the state space the local problems are interpreted as markov decision processes and solutions to the local problems are interpreted as policies restricted to the subsets of the state space defined by the partition one algorithm relies on constructing and solving an abstract version of the original de cision problem a second algorithm itcratively approximates parameters of the local problems to converge to an optimal solution we show how properties of a specified partition affect the time and storage required for ihese algorithms 
1 	introduction 
we are concerned with solving planning problems posed as markov decision processes spec lfically  given a dynamical model described as a stochastic process  t g markov chain  with a large  discrete state space and a performance criterion  e g   minimize the expected time or cost to reach a goal   construct a policy  plan  mapping states to actions that realizes the specified performance criterion or approximates it to within some specified tolerance 
　　this work was supported by the air force and the ad vanced research projects agency of the department of de tense under contract no f1 c-1 and by the national science foundation in conjunction with the advanced 
research projects agency under c ontract no 	iri-1 

figure i three views of a three dimensional state space with the corresponding local strut-turre of spnce shown to the right the top view representh the unstructured stale space the middle view represent an abstraction obtained b  projection and the bottom view represents a decomposition obtained by partitioning the stales into aggregate states 
1 	factoring large state spaces 
large state spaces present a number of cnallenges lo begin with  the problem has to be efficiently encoded a 
factored state-space representation uses state variables to represent different aspects of the overall state of the system ' co npact encodings for stochastic professes can be achieved for many applications using fat i ore d state space representations where the size of the model is usually logarithmic in the size of the state space  dean and kanazawa  1  similarly  policies for large faetored state spaces can often be efficiently encoded using decision trees that branch on state variables  bou tiher it at 1  assuming that both the problem  a stochastic process  and the solution  a policy  can be encoded in a compact form  we would like to generate solutions in lime bounded by some small factor of the problem and solution size 
   'propositions representing fluents in strips opualors  fikes and nilsson 1l  correspond lo state variables in a factored state-apace representation 
	dean and lin 	1 


figure 1 region by-region dimensionality reduction a three-dimensional space is represented as the union of two-dirnensional abstract subspaces shaded dark grav 
   a factored state-space representation with it boolean state variables represents an n-dimcnsional state space with  states we assume that all of the state variables are relevant in at least some portion of the stale space and so the dimensionality of the problem cannot be reduced without suffering some ioss in performance however  it is very likely that not all statt variables are relevant in all portions of the state space i  when you are planning to take a walk in southern florida you ran neglect the possibility of snow  figure 1 lllustratis thru viws  of a multi-dirnensional state space the bottom view in winch the state space is partitioned into aggregate states is the view we are most interested in 
1 	dimensionality reduction 
in this paper  we assume that a domain expert has partitioned the state space into m regions such that in each region only a small subset  of size no more than of the set of all state variables  is relevant for decision making in other words  for each region  we are concerned with an abstract subspace of size no more than 
 the size of the union of these abstract subspaces is no more than  the problem of automatically constructing such a partition is not addressed in this paper  but see  lin and dean  1  for some relevant techniques figure 1 illustrate* how a three-dimensional state space might be represented as the union of twodimensiona  abstract subspaces 
   there exist methods for computing policies that are polynomial in the size of the state and action spaces  papadimitriou an d tsitsiklis 1   puterman  1   but these methods are impractical for large state spaces  given 1 state variables  instead of considering the large state space as a whole  we are interested in decomposition methods that deal with the smaller subspaces of individual regions 
1 	combining local solutions 
our framework is a special case of divide and conquer given a markov decision process and a partition of the state space into regions   i  reformulate the problem m terms of smaller markov decision processes over the sub-
spaces of the individual regions.   n  solve each of these  ubproblenib and then  m  combine the solutions to obtain a solution to the original problem 
　in the best case  all of the subproblems are independent and combination is trivial  e g   a manufacturing task that involves assembling and testing several components each of which is assembled independently  in 
1 
such cases  it does not matter how you enter a region of the partition or how you leave  the only thing that matters is the cost accrued while in that portion of tht state space in the more likely case  the subproblems are weakly coupled to one another so that  for example  what you do in one region only affects what you do in a few neighboring regions examples of weakly-coupled systems include staged manufacturing and military planning problems and robot navigation tasks 
　we associate a set of topologically motivated param eters with each region r these parameters summarize the interactions between r and the other regions in the partition a specific estimate of the parameter values associated with region r allows us to construct a markov decision process over the subspace associated with r b} solving such a markov decision process  we determine a local policy on the region r  which is a solution to the subproblem associated with r in this paper we describe two basic methods for combining solutions to subproblems in order to generate a solution to the global problem 
　the first combination method is illustrated in an algorithm called hierarchical policy construction which considers particular sets of parameter values that have an intuitive topological interpretation these sets of pa rameter values give us a set of candidate local policies associated with each region we then construct an abstract markov decision process by considering individual regions as abstract states and their candidate local policies as abstract actions the solution to this abstract markov decision process assigns a particular candidate policy to each region thus yielding a policy on the entire state space hierarchical policy construction produces an optimal policy only in special cases however it does so relatively efficiently and has an intuitive interpretation that makes it particularly suitable for robot navigation domains 
　the second method of combining solutions involves it erative approximation of the optimal parameter values i i   those values associated with optimal solutions to the global problem on each iteration of the iterative approximation method we consider for each region r a specific estimate of the parameter values for region r and solve the resulting markov decision process to obtain a local policy by examining the resulting local poh eies  we obtain information to generate a new estimate of the parameter values that is guaranteed to improve the global solution this information about local policies also tells us when the current solution is optimal or within some specified tolerance  and therefore when it is appropriate to terminate the iterative procedure 
1 	overview of the paper 
in section 1  we provide a brief introduction to markov decision processes section 1 describee the parameters modeling the inter-regional interactions  and the construction of a markov decision process on a region r given a specific estimate of the parameter values for r section 1 presents the hierarchical policy construction algorithm we describe the construction of abstract decision processes from a base-level process  and the use of 

such abstract decision processes to construct policies for the base-level process section 1 illustrates the method 
of the iterative approximation and briefly addresses is sues concerning convergence  optimally  and complex-
ity details are available in a longer version of the paper 
 dean and lin  1  
	dean and lin 	1 


1 



ciated with the current policy repository 
proposition 1 the iterative method described above improves the solution quality on each iteration  and con verges. to an optimal solution in a finite number of steps 
　for a proof of this proportion and a more detailed description of the algorithm see the longer version of this paper  dean and lin  1  our approach to analyse involves  1  reformulating this iterative method in terms of solving large linear programs and  n  applying a reduction to the methods of kushner and chen  that solve these large linear programs for markov decision processes using dantzig-wolfe decomposition in the following  we briefly discuss the convergence rate and the time and space complexity of this iterative method 
  empirical experience suggests that the dantzig-wolfe method of decomposition upon which our analysis of the iterative method is based converges to within 1% of the optimum fairly quickly  although the tail convergence rate can be very slow  see page 1 m  m s bazaraa 1   in other words it is likely that after only a small number of iterations in the iterative method we are able to produce a solution of good quality  hut it may not be worthwhile to continue after reaching 1% of the optimum 
  the computational task in an iteration is decom-posed into two subtasks  i  deriving and solving local processes over local regions as subproblems and maintaining a policy repository of up to previously generated policies where v is the union of periphery  r  for the regions r in the 
original partition p 
the computational cost in an iteration is critically affected by the structure of the partition q  i  the maximum number of base-level states in a region in the partition q  and  n   the total number of base-level states in the coupling region for the partition q 
m   ompared with solving the original base-level process as a whole  the first subtask can be achieved more efficiently by applying the standard techniques for markov decision processes over individual regions this is a natural advantage of decomposition trchniques  which divide large problems into suliprohlems of traclable size 
the second subtask is achieved by maintaining a  matrix whose computational 
efficiency critically depends on the topology of the given partilion p the second subtask can be performed efficiently if the size of v is relatively small this is the additional cost to pay for decomposition techniques since we need to combine the solutions to subproblems 
  in other words this iterative method is promising if the given partition p evenly divides the whole state space into many regions  and the number of states in the peripheries of the regions in p is small 
　in the longer version of this paper  we also describe other iterative methods that do not necessarily converge 
1ft 
to an optimal solution but allow intuitive interpretation and more computational efficiency we are currently testing these algorithms on a set of benchmark problems since the discussion is somewhat lengthy and requires some understanding of both howard's policy iteration  howard i1  and bellman 1 value iteration  bellman 1  for solving markov decision processes we refer the interested reader to the longer version of the paper  dean and lin  1  
1 	related work 
the related work on abstraction and decomposition is extensive in the area planning and search assuming  deterministic action models  there is the work on macro operators  horf  1  and hierarchies of state-space operators  sacerdoti  1   knoblock  1  c losely related is the work on decomposing discrete event systems modeled as  deterministic  finite state machines  zhong and wonham 1   caines and wang  1  
　in the area of reinforcement learning  then  is work on deterministic action models and continuous state spaces  moore and atkeson  1  and stochastic models and discrete state spaces  kaelbling  1  the hierarcl ncal policy construction method described in section 1 provides an alternative formulation of kaelbling s hierarchical learning algorithm  kaelbling  1  and suggests how moore and atkeson's parti-game algorithm might be extended to handle discrete state spaces 
   the analysis hinted at in thih paper and found in the longer version of the paper borrows heavily from lh  work in operations research and combinatorial optimization for representing markov decision processes as 1m ear programs  d epenoux 1   d erman  1   rush ner and kleinman  1  and decomposing large sys teint generally  dantzig and wolfe  1   lasdon  1  and markov decision processes specifically  kushner and 
chen  1  the approach described in  dean el al 1   dean et at   1  represents a special case of the framework presented here  in which the partition consists of singleton sets for all of the states in the envelope and a set for all the states in the complement of the envelope 
1 	conclusion 
the benefit of decomposition  techniques is that we are able to deal with subproblems of smaller size  the tradeoff is that extra effort is required to combine the solutions to these subproblems into a solution to the original problem the leverage of decomposition techniques is or thogonal to that of standard techniques used to solve the original problem in the case of problem instances of very large size  decomposition techniques are often valuable even if standard polynomial-time algorithms are avail able 
　we provide decomposition techniques for markov decision processes  given an arbitrary partition of the state space into regions subproblems correspond to local markov decision processes over regions associated with a a parameter that provides an abstract summary of the interactions among regions we present two methods for 

combining the solutions to subproblems a hierarchical construction approach and an iterative improvement approach the hierarchical construction method provides a quick solution with an intuitive interpretation the iterative method is guaranteed to converge to an optimal solution in a finite number of iterations for practical purpose*  a small number of iterations should be suffi nnt for a solution of near optimal quality 
acknowledgements 
　we thank   raig bontiher  moises goldszinidt steve hanks  david smith  and mike williamson for their com ments on the content and presentation of the ideas described in this paper 
