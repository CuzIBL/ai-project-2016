 
weak causal relationships and small sample size pose two significant difficulties to the automatic discovery of causal models from observational data. this paper examines the influence of weak causal links and varying sample sizes on the discovery of causal models. the experimental results illustrate the effect of larger sample sizes for discovering causal models reliably and the relevance of the strength of causal links and the complexity of the original causal model. we present indicative evidence of the superior robustness of mml  minimum message length  methods to standard significance tests in the recovery of causal links. the comparative results show that the mml-ci  the mml causal inducer  causal discovery system finds better models than tetrad ii given small samples from linear causal models. the experimental results also reveal that mml-ci finds weak links with smaller sample sizes than can tetrad ii. 
1 	introduction 
our research on automating causal discovery aims at developing methods of reliably recovering the structure  and parameters  of causal models from sample data. given such a method  several factors will affect the correctness of the discovered model  including the quality of the available data  the size of the sample obtained and the strength of the causal links to be discovered. 
　having developed methods which  given large samples  discover causal models that are generally as good as or better than those discovered by tetrad ii  wallace  korb and dai  1   we report here initial results on the robustness of the two methods when using small samples and in discovering weak links. in section 1  we describe the sample size and weak link discovery problems. in section 1  we give a brief analysis of the relation-
1 	probabilistic reasoning 
ship between sample size  link strength and the discovery of causal links. section 1 presents the test strategies. section 1 provides the experimental results of the causal model discovery algorithms across a range of sample sizes and with various small path coefficients. in particular we compare the results of the mml induction system mmlci  the mml causal inducer   wallace.korb and dai  
1  with that of tetrad ii  glymour et al  1; schemes  1; spirtes et al  1 . 
1 	robustness of causal discovery 
let   corresponding to random variables  be a set of nodes and  be a set of links  a causal model m is a directed acyclic 
graph  together with numerical parameters reporting the strength of the connections  where  means that z  is a direct cause of xj rela-
tive to v. such directed acyclic graphs that are used to represent causal theories are variously called causal models  causal graphs  causal networks and belief networks 
 cooper and herskovits  1  and  russel and norvig  1 . a causal network gives a concise specification of the joint probability distribution  pearl  1 . each node in the causal network has a conditional probability table that quantifies the effects that the parents have on the node; linear causal networks  e.g.   wright  1   provide the same information under the assumption that each effect variable is a linear function of its parents  allowing the numerical parameters to be attached to causal links independently. 
　recently  causal models  especially in the form of bayesian nets  have been widely employed for the representation of the knowledge with uncertainty  including use in expert systems  shafer  1 . in consequence  interest has grown in the learning of causal models as well. various learning strategies have been developed. these methods include spirtes et al.'s tetrad i and 
ii based upon significance tests for partial correlations  
pearl and verma's approach  pearl  1  and  pearl and 
verma  1  using conditional independencies  hecker-

man's bayesian approach  heckerman  1  and  heckerman et al  1 . in 1  madigan and york introduced markov chain monte carlo model composition  mc1   mdigan et al  1  for approximate bayesian model averaging  bma  and recently further developed the gibbs mc1 and the augmented mc' 1 algorithms  mdigan et al  1  for the selection of bayesian models. more recently wallace et al developed the mml-ci  wallace korb and dai  1  based on mml induction  a bayesian minimum encoding technique and suzuki proposed a mdl  minimum description length  principle based bayesian network learning algorithm using the branch and bound technique  suzuki  1 . 
   here we examine the particular problem of the robustness of the two causal discovery algorithms which have been developed for inducing linear causal models  namely mml-ci and tetrad ii. in particular  we compare the models these algorithms produce when presented with varying sample sizes and samples generated from original causal structures with varying strengths of causal relationship. the robustness of the discovery technique in dealing with small samples is an important issue for machine learning  since autonomous  resource-constrained agents must be prepared to learn interactively with environments that will not tolerate unbounded sampling. we need to estimate the reliability of a derived model. also  although we do not here report on large causal models  we would expect that problems with robustness with small samples for small models will manifest themselves also with large samples for large models  suggesting difficulty in scaling up a learning algorithm to cope with realistic examples of causal discovery. here  the large model refers to the model with large number of links. 
1 the influence of sample size and link strength 
for any learning technique which converges on the underlying probability distribution in a prediction task  the predictive accuracy will be sensitive to sample size  model complexity and the strength of the correlation between measured variables. in general  predictive accuracy of a recovered model will be a function of sample size  quality of the data and the ability of the learner  dai  1 . in the discovery of causal models verisimilitude of the model discovered relative to the original model  and the probability distribution implied  will also be affected by sample size  model complexity and the strength of causal association between measured variables. for practical purposes  starting from similar prior domain information  better learning ability will reveal itself in faster convergence upon the underlying model  or  to put it the other way around  in the robustness of discovery given smaller sample sizes. here we examine such robustness in mml-ci and tetrad ii. 
　the probability of discovering from sample data the existence of a particular causal link depends  in part  upon the strength of that causal link. in the case of a single causal path between two nodes being a single  direct causal link  in standardized models  the path coefficient is identical to the correlation between the two nodes  making the relation between sample size and detectability of the link plain. tetrad ii is sensitive to the strength of the causal relation quite directly: it determines whether a link is present or not by applying significance tests potentially to all orders of partial correlation  removing the effects of all subsets of v excluding the nodes under consideration. in consequence  ordinary concerns about the robustness of significance testing apply to tetrad ii - and for each link these concerns will apply not to a single significance test  but to a battery of significance tests.1 things are worse than ordinary for tetrad ii  however: because a high-order partial correlation estimate depends upon estimates of the marginal correlations for each pair of variables involved  the uncertainties associated with each estimate will accumulate  which results in high standard errors  variance  for high-order partial correlation estimates and in the need for very large samples to get significant results. the reliance on significance tests for high-order partial correlations suggests that tetrad ii will be unlikely recover the structure of a larger model without quite large samples available. in other words  the larger the order of such a significance test  the greater the sample size must be for an effect of constant strength to be detected. as a result  as the authors admit  scheines  1   tetrad ii has a tendency to omit arcs for larger models even with fairly large sample sizes. 
　mml-ci does not depend upon a test as rigid as significance tests at a fixed level: it reports an arc whenever the presence of such an arc leads to a reduction in the message length for a joint encoding of the causal model and the sample data  wallace korb and dai  1 . that is  given a sample with m instances over n variables  the message length is calculated according to the following formulas: 
		 i  
 this involves a trade-off between greater simplicity of the model  and commensurately higher prior probability  and greater accuracy in accommodating the given sample data  and so a higher likelihood for the model  via shannon's definition of information. 
　in detail  the mml encoding of causal models and data is given in the following equations  see  wallace korb and dai  1  for a detailed explanation . we 
   'this is true even though tetrad ii takes steps to reduce the number of significance tests required per pair of nodes  in its  pc algorithm   scheines  1 . 
	daletal. 	1 
start by dividing the code for the model into two parts  corresponding to the causal structure and the numerical parameters: 
		 1  
we use 
		 1  
which provides an efficient encoding for a directed acyclic graph  when m is a count df the linear extensions of the dag. 
where: is the number of arcs incident on the variable is a hyper-parameter reflecting the expected strength of the causal links to node i  set to 1 in all experiments reported here ; is the variance; are the parameters; and is the n x n data matrix. 
to encode the data requires a message of size: 

where rij is deviation of the data from the linear pre-
diction. 
   in mml-ci's discovery the relation between sample size and.the strength of causal links remains  of course; but the possibility of mml-ci finding weaker links sooner seems intuitively more likely  because such links will be reported as soon as the improvement they afford in encoding the data overcomes the increased cost of reporting a somewhat more complex model. 
1 	testing strategy 
to examine the influence of sample size on the discovery of causal models experimentally we chose six models varying in complexity: models 1 through 1 in figure 1-. we used these models to generate sets of sample data of various sizes stochastically  which in turn were given as input to mml-ci and tetrad ii to determine what causal models would be discovered. in the case of tetrad ii default values were employed exclusively; no prior information about the temporal order of variables was provided to either algorithm. 
　the first model is simplest  having only one link and two variables. in this case  the path coefficient is exactly equal to the correlation between the two variables. this makes the existence of the causal link extremely easy to find  although not its direction . model six is the most complex model  having five variables and seven 
1 	probabilistic reasoning 

figure 1: six test models 
arcs. three of the models contain weak links with coefficients less than 1  namely models 1  1 and 1. these six artificial models were manually designed for the following testing purposes:  1  the learning difficulties associated with model complexity in terms of the number of variables;  1  the learning difficulties associated with model complexity in terms of the number of arcs;  1  the learning difficulties associated with the strength of the links. in each case we generated data sets with 1  1  1  1  1  1  1 and 1 instances. then we ran both mml-ci and tetrad ii using all eight data sets for each of the six models. 
　in a second experiment we looked at the effect of link strength on the recovered model. in this case we used model 1  above  with the strength of the causal arc varied between 1 and 1  in each case generating the same range of sample sizes as above. 

figure 1: mml-ci sample size test results 
1 	experimental results and analysis 
sample size and model complexity in our experiments  we focus on linear models with gaussian error and assume no hidden variables. we use tetrad ii default settings with a significant level of 1. the pc algorithm is the one applied on fully measured models with continuous variables. figure 1 reports the mod-


figure 1: tetrad ii sample size test results 
els discovered by mml-cj from the 1 data sets  while figure 1 reports those discovered by tetrad ii. the shading indicates for each model at what point the algorithm discovered the original model or a model statistically equivalent to the original. statistically equivalent causal models are those which can be used to specify the same class of probability distributions over the variables 
 perhaps using distinct parameterizations .  verma and pearl  1  report a simple graphical criterion of equivalence which can be used to identify the statistically equivalent models in our figures: two causal models are statistically equivalent if and only if they have the same skeleton  undirected graph  and they have the same vstructures  nodes that are the children of two parents which are themselves non-adjacent . such models cannot be distinguished on the basis of sample data alone  chickering  1   so the discovery of one is as good as the discovery of another in this experiment. 

figure 1; comparison of edges omitted 
　for tetrad ii  in figure 1  undirected arcs reflect the fact that tetrad was unable to determine an arc orientation; for these arcs  either orientation is allowed by tetrad  so long as the resulting graph is acyclic and so long as no new v-structures are introduced by selecting such an orientation. we counted the resulting tetrad graph as satisfactory  and so appears shaded  if no such selection of arc orientations results in a causal model that is not statistically equivalent to the original model. 

figure 1: comparison of arrows omitted 
　although in this study we have not performed significance tests on the results  i.e.  by generating large numbers of samples of each model for each sample size   the trend is fairly clear. for all of the models showing any complexity  i.e.  for model 1 and above  mml-ci has found the correct model at smaller sample sizes than has tetrad ii. in the case of model 1 tetrad ii was unable to recover the weakest link even when supplied 1 samples  while for model 1 tetrad ii found all the links but failed to discover the v-structure at node 
d. 
　figures 1 and 1 compare mml-ci with tetrad ii in the manner used by spirtes  et al.  scheines  1 . figure 1 graphs the percentage of edges of the original model which mml-ci and tetrad ii have failed to recover  by sample size. figure 1 graphs the percentage of arc orientations missed by each program  but not counting cases where a graph with an incorrect arc orientation is statistically equivalent to the original model . of course  both algorithms display the expected convergence towards zero errors - expected because tetrad ii is  in effect  a classical estimation technique whereas 
mml-ci is  in effect  a bayesian estimation technique  
	dai etal. 	1 


figure 1: mml-ci weak link discovery results 
and so both fall under the general convergence results established for the respective classes of statistical inference procedures. it remains of interest  however  that in all of these measures mml-ci tends to display a more rapid convergence towards the true model - which is to say it appears to be more robust when dealing with smaller sample sizes. 

figure 1: tetrad ii weak link discovery results 
　sample size and weak link discovery figure 1 illustrates the experimental results for mml-ci on model 1 when the causal link from b to c takes varying degrees of strength  in particular coefficients ranging from 1 to 1. unsurprisingly  the results clearly reveal the fact that the weaker the association the larger the sample required to discover it. with the weakest coefficient of 1 in figure 1  mml-ci does not discover the link until provided with 1 samples. whereas with a weakest link of 1 and 1  the system discovered the link once provided with a data set with the sample size of 1 and 1 respectively. 
1 	probabilistic reasoning 

figure 1: 	comparison of edges omitted with small 
path coefficients 
　figure 1 illustrates like experimental results for tetrad ii. these results again show the inverse relationship between strength of causal relationship and the sample size required to discover it. given coefficients above our original 1 tetrad ii was able to discover the link between 1 and c that it had missed before. it remains clear in all of the test cases that mml-ci recovers the original causal model with fewer samples than tetrad 1. figure 1 and figure 1 report similar stories for the measures of arc omission and arrow omission. 

figure 1: comparison of arrows omitted with small 
path coefficients 

1 	conclusions 
the following conclusions appear to be supported by our experimental results.  1  the theoretical difficulties of significance testing with robustness appear to be manifested in tetrad ii's inferior robustness with respect to sample size. this shows up  for example  in tetrad ips inability to recover the weaker links  with coefficients below 1  with smaller samples.  1  the problem of arc omission given small samples is particularly acute for tetrad 1  in comparison with mml-ci  as model complexity increases  as predicted by our analysis in ′1. from the experimental results we also find that mml-ci shows promise not just in finding causal models that are as good as those discovered by tetrad ii in general  but given the constraints imposed by small samples or by weak causal links the models discovered appear to be characteristically superior to those discovered using the significance testing methods of tetrad. this is likely to be an especially important feature of causal discovery when causal models become large  for tetrad's method of examining partial correlations of all orders in 
such cases is both computationally expensive and lacking robustness. 
acknowledgement 
this work was conducted with partial assistance from arc grant .1. 
