 
　ai and connectionist approaches to learning from examples differ in knowledge-base representation and inductive mechanisms. to explore these differences we experiment with a system from each paradigm: 1 and back-propagation. we compare the systems on the basis of both prediction accuracy and length of training. the systems show distinct performance differences across a variety of domains. we identify aspects of each system that may account for these performance differences. finally  we suggest paths for cross-paradigm interaction. 
1 introduction 
research in machine learning has grown rapidly in recent years. a primary focus of study has been methods of learning from examples: a system accepts object descrip-
tions  e.g.  patient case histories  that are pre classified  e.g.  hypothyroid disease . based on this training  the system forms a knowledge base that can accurately classify new objects. historically  the dominant approach in ai assumes that the knowledge base is a flat or treestructured set of concept  descriptions. typically  each concept is a logical rule that defines class membership. 
　in contrast  connectionist methods  hinton  in press; mcclelland & rumelhart  1  assume a knowledge base of interconnected nodes  each of which computes a weighted sum of its inputs. external inputs  i.e.  ob-
ject features  are arithmetically combined and propagated through the network. this process terminates with the computation of external outputs that represent an object's classification. learning alters weights so that classification correctness is improved. 
　ai and connectionist approaches typically differ in object and knowledge-base representation  as well as the inductive mechanisms employed. this paper explores some implications of these differences by experimenting with a system from each paradigm: id1 and backpropagation. sections 1 and 1 describe id1 and back-
   *this work was supported by a grant from the vanderbilt university research council. 
1 	machine learning propagation  respectively. section 1 compares the systems in terms of the prediction accuracy attained in natural and artificially-constructed domains  and the amount of training required to achieve these accuracy levels. section 1 describes processing and representation differences between id1 and back-propagation  as well as between these systems and others of their respective paradigms. this discussion qualifies our study as it might relate to paradigm-wide comparisons and suggests foundations for work on hybrid systems. 
1 id1 
id1  quinlan  1  is a simple and effective ai method for learning from examples. the system constructs a decision tree from a set of training objects. at each node of the tree the training objects are partitioned by their value along a single attribute. an information theoretic measure is used to select the attribute whose values improve prediction of class membership above the accuracy expected from a random guess. the training set is recursively decomposed in this manner until no remaining attribute improves prediction in a statisticallysignificant manner by a user-supplied parameter of'confidence'  e.g.  1% . in our experiments we assume nominal attributes: those with a finite set of values  e.g.  color ♀ {red  blue  green} . 
id1 decision trees are equivalent to tree-structured 
disjunctive normal form  dnf  concepts. each path to a leaf is a conjunction of values  joined at the root by disjunction. quinlan and others have verified that this approach attains high levels of accuracy in an absolute sense and relative to other systems. these studies report favorable results in several natural domains  under idealized and noisy conditions. 
1 back-propagation 
in a feed-forward connectionist net  input nodes record observed features from the environment and pass 'activation' forward through an intermediate layer of 'hidden* nodes to an output layer. we assume that each node is linked to every node at the next layer via weighted interconnections. the total activation of a node is a weighted sum of its inputs. we encode nominal attributes using a set of input units  one dedicated to each value. for a particular object description  one of these units  e.g.  'red'  will be 1 and the rest  e.g.  'blue'  'green'  will be 1  representing feature presence and absence respectively. a set of such input units is allocated for each attribute. this representation has been used by sejnowski and rosenberg  1  and has advantages for nominal attribute encodings. our convention is that each output node corresponds to one class; the object is classified by the class whose output node has the highest activation. ideally  for any particular object the activation of one output node should be 1 and the others should be 1. 
back-propagation  rumelhart  hinton  & williams  
1; mcclelland & rumelhart  1  adjusts weights so as to improve the match between actual and ideal output. if there are 1 classes  output units  and an ob-
ject belongs to class 1  then the ideal output is  1 1 . if the actual output is  1 1 1 1  then the error for each output unit  1 -1 -1 -1  is backpropagated through the network. weight adjustment is proportional to the size  and sign  of the error  and the degree to which the lower-level node contributed to the output node's node's activation error. a user-supplied parameter of 'learning rate' is used to vary weight adjustment. 
   with 'sufficient' hidden units  back-propagation can converge on perfect classification  assuming no noise   but this number will vary with domain. when no hidden units are present  linearly separable classes are recognizable  which properly include 'x of n' functions: for a selected subset of the input features  where the subset is of size n   at least x must be present in order to qualify for class membership. logical conjunction and inclusive disjunction are special cases of the x of n function: x=n and x = l represent the conjunctive case where all features must be present and the disjunctive case where only one feature need be present. 
1 experimental comparisons 
this section describes empirical comparisons between 
id1 and back-propagation. comparisons of any kind  whether cross-paradigmatic or not  require that we justify system-dependent parameter settings  choose domains and encodings that are fair to both systems  and accept that systems may be designed for disparate applications. even if we agree on domains that allow the approximation of fair comparison  we must realize that systems may be superior along different dimensions  e.g.  cost versus correctness . this section compares the behavior of two systems. hopefully  we and the reader can avoid unfounded generalizations with respect to the paradigms more generally. section 1 analyzes system performance in light of paradigm-wide assumptions in order to qualify our comparative results and to suggest paths for cross-paradigm fertilization. 
1 experimental design 
id1 and back-propagation were tested in the natural domains of thyroid disease case histories  soybean disease case histories  stepp  1   and congressional voting records. in addition to the basic domains  we systematically introduce noise to each domain. finally  we test each system in a number of artificial domains  including exclusive-or which is not linearly separable  but which 
may be described by a simple logical expression. 
　for each domain  back-propagation was tested with varying numbers of hidden units  1  1  1  and learning rates  1  1  1 . of these  we report results with 1 hidden units and a learning rate of 1  which consistently optimizes or comes close to optimal asymptotic prediction accuracy and learning speed over all domains. id1 was tested with varying confidence levels  1%  1%  
1%  1% . in general  1% confidence does as well as others for domains  training schedules  and noise levels that we are investigating.1 
　all features were nominal and were given a binary encoding for back-propagation as described in section 1. class membership was similarly encoded for outputs. in all of the natural domains  back-propagation required far more object 'presentations' to converge on asymptotic accuracy than there were unique objects. thus  training objects were drawn randomly  with replacement  from a fixed pool of objects. for 1 and back-propagation a disjoint object subset was reserved to test  but not update  the knowledge base at intermittent points in training. back-propagation is incremental; after each testing point  learning resumes with the network weights derived by previous training. in contrast  1 is nonincremental; at each testing point 1 is constructed anew with the training set used previously  plus newly presented objects. id1 may see each object at most once for any particular trial. 
1 natural domains 
the graphs of figure 1 show the learning curves' of id1 and back-propagation in the congressional and thyroid domains. in the congressional domain id1 achieves and maintains 1% accuracy after approximately 1 objects  while back-propagation asymptotes at 1% accuracy after 1 objects. in the thyroid domain  id1 requires 1 objects to attain 1% accuracy. rack-propagation reaches and maintains 1% accuracy after 1 object presentations. in the soybean domain id1 averaged 1% 
1
　　 however  we report exceptions to these findings when they significantly improve performance  e.g.  1% versus 1% confidence; 1 versus 1 hidden units . 
	fisher and mckusick 	1 


accuracy over the test set. back-propagation reached perfect accuracy after 1 object presentations. 
　in these domains back-propagation reaches slightly higher accuracy levels  but not significantly so. moreover  back-propagation requires many more training presentations. another difference relates to the shape of the 'learning curves': id1 quickly achieves high levels of accuracy  e.g.  after 1 training objects or so  and then gradually converges on its asymptotic value. in contrast  the slope of back-propagation's curve is more gradual and uniform. 
   our training conventions for back-propagation assume that an object presentation is the primary unit of cost. in contrast to our incremental approach  shavlik  mooney  and towell  1  assume that the training objects are repeatedly presented until the network converges to near perfect prediction of this set. only then is the test set presented for classification. this batch convention assumes that each object  regardless of the number of times that it is repeated  is the basic unit of cost. their finding is that approximately the same number of objects are required to achieve similar accuracy levels. we  fisher  mckusick  mooney  shavlik  & towell  1  have reconciled these conventions and found them basically equivalent. in the incremental approach the cost per presentation  observation  is inexpensive  but many 
1 	machine learning 

observations are needed. in the batch approach the cost per observation is more expensive  but fewer observations are needed. in either case the empirically-observed time until convergence for back-propagation is up to sev-
eral orders of magnitude greater than id1  a property that our graphs reflect. 
1 noise 
the effect of noise was also explored. in a manner suggested by quintan  1  attribute values were randomly replaced according to a probability  e.g.  1%  that reflected the noise level. asymptotic accuracy for the congressional and thyroid domains under conditions of 1% noise are graphed in figure 1. regardless of noise level  i.e.  1% or 1%  or domain  back-propagation always attained accuracy levels greater than id1. however  back-propagation again requires significantly more observations to achieve these results  but this is not revealed by the bar graphs . the learning curves' are similar in shape to those of figure 1: id1 rapidly peaks and levels off  while back-propagation rises more slowly and uniformly. 
1 artificial domains 
artificial domains were constructed so that comparisons could be made under controlled circumstances. our experiments systematically vary the degree that attribute values are sufficient and necessary for class membership:  1.1  individual values are necessary and sufficient;  1.1  values are necessary  but not sufficient; 
 1.1  values are not individually necessary or sufficient  x of n ;  1.1  the necessity of a value's presence or absence is conditioned on the presence of other attributes  exclusive-or   in which no set of values are necessary or sufficient. 

1.1 sufficiency 	1.1 x of n 

each of four  1  artificial domains contained three  1  classes of objects. objects were described over 1 attributes. each class was describable as a conjunction of attribute values that were unique to that class. each such value was singly sufficient to distinguish the class. each of the four domains varied in the number of singlysufficient values  i.e.  domain 1: 1 of 1 attributes were individually sufficient; domain 1: 1 of 1 were sufficient; domain 1: 1 of 1 were sufficient; domain 1: 1 of 1 were sufficient . values of those attributes that were not sufficient were generated randomly  and thus were irrelevant to classification. 
   1 uniformly reached perfect performance by 1 objects  regardless of the number of individually-sufficient values. back-propagation is more sensitive to the number of sufficient values. when all attributes distinguish membership  convergence to perfect prediction required 1 objects  but when no hidden units were used only 1 objects were required. when 1 attributes were sufficient  1 objects were required for perfect performance  1 objects were required with no hidden units . when only 1 attribute was sufficient  and thus necessary too  1 observations were required. as the number of sufficient values decreased  back-propagation required more observations to reach asymptotic accuracy. 
1.1 necessity 
domains in the second set of experiments added to the complexity of the 'sufficiency' domains. each class was still describable as a conjunction of attribute values  but the values were not unique to that class: no value was singly sufficient to distinguish class membership.1 rather  only the entire conjunctive expression was sufficient  and necessary  to distinguish membership. once again  the size of the conjunctive expression varied from 1 to 1. 
　neither id1 or back-propagation averaged perfect performance in all domains for the maximum allotted training. back-propagation remained just below perfect prediction  about 1%  for conjunctions of size 1 and 1; id1 reached perfect accuracy  but required 1 training objects. back-propagation achieved perfect prediction after 1 objects for the conjunction of size 1; 1 averaged 1%  asymptotic accuracy. as the size of the con-
junctive target concept grew  it became more difficult for id1 to spot; each attribute individually transmitted less information. 
1
　　 except in the case where the conjunction is of size 1; note that this extreme is identical to the lone sufficient  and necessary  condition of 1.1. 
in these experiments there was no conjunctive description for any class. rather  a class was defined by an x of n function. more specifically  each domain contained only two classes  c and  c . c is associated with 1 'preferred' values  one for each attribute ; an object was a class member iff it contained at least x of the 1 values. in contrast to 1.1  our 'x of n' experiments disallow any single value set to be necessary. the size of x was varied between 1 and 1. 
　1 consistently attained accuracy levels in the vicinity of 1%  to 1% after 1 objects  but about 1%. accuracy was achieved after 1 objects. back-propagation reached average levels of 1%  to 1% within 1 observations. 
1.1 exclusive-or 
a final set of artificial domains insists that two attributes exhibit the exclusive-or relation  one and only one of two selected values are present . exclusive-or  like x of n  has no values or value combinations that are necessary for membership. however  'x of n' allows x or more selected values to be present  but exclusive-or requires exactly x values to be present. as such  exclusive-or is 
not linearly separable. 
　the version of 1 that we used  quinlan  1  was not capable of learning this function  averaging between 1% and 1%  accuracy depending on our confidence threshold. however  section 1 describes a new 1 descendenf  quinlan  1  that can undoubtedly reach perfect prediction in this domain. exclusive or also presents problems to back-propagation: it can not be learned without hidden units. with 1 hidden units  it required approximately 1 observations to achieve 1% accuracy  approximately 1%  accuracy after 1 observations.  
1 discussion 
experiments indicate that back-propagation achieves higher asymptotic accuracy levels under noisy conditions and selected artificial domains  but requires considerably more object presentations. this section identifies several principles of each system that may account for performance differences. to the extent possible  we tie our discussion to distinctions between ai and connectionist paradigms more generally. this discussion qualifies our results as they might apply to paradigm-wide comparisons and encourages the exploration of ai and connectionist hybrid learning systems.1 
1
　　in particular  we avoid the symbolic/subsymbolic distinction. this has proved an unhelpful distinction in that it does not promote short-term progress. this distinction artificially segregates research programs because it is often conveyed as a prescriptive  and unknown  boundary that each paradigm must observe. 
rather  we believe that useful distinctions are descriptive and pro-
	fisher and mckusick 	1 

1 representation and bias 
differences between id1 and back-propagation may be attributable to the size and form of the search space explored by each system. the primitive evidence combination function of back-propagation  i.e.  x of n  generalizes id1's primitive logical combinators  conjunction and inclusive disjunction . finer granularity enables back propagation to converge on logical concepts and others with less hardware  but each primitive must be specialized  which requires greater training. the dnf equivalent of x of n  for arbitrary x  is quite complex. the course primitives of id1 also suggests that it takes bigger steps in a uniform search space: it approximates the final solution more quickly  but it may accept less than optimal solutions because it 'oversteps' or 'understeps' the optimum. 
　the subsumtion relation between representation languages suggests that logical descriptions can be harnessed as a sort of 'admissible' heuristic that allow rapid approximation followed by slower refinement. this approach is taken by utgoff's  1b  perceptron trees  a hybrid of decision trees with linear threshold units as leaves. the decision tree brings about large cuts in the search space  with final convergence left to the leaves. evaluation of this particular approach must await further experimentation  but nonetheless it represents an important conceptual advance towards the development of hybrid systems. 
1 probabilistic versus logical classification 
a recent trend in machine concept learning is towards probabilistic representations  smith fa medin  1 . probabilistic concepts typically classify observations by a. summation of evidence  just as do connectionist network nodes. for example  fisher's  1  cobweb can be viewed as constructing a 'decision' tree of evidence summation units  nonlinear  with a variable threshold  i.e.  an object is placed in the node with the highest summation . arithmetic evidence combination has traditionally distinguished ai and connectionist learning methods  but cobweb illustrates that this should not be taken as a prescriptive difference. 
1 monothetic versus polythetic classification 
a weakness of id1 is that it is monothetic: learning considers the utility of a single attribute at a time. the predictive merits of attribute value combinations are not explicitly consider  presumably to the detriment of prediction accuracy. this seems evident in the comparisons of 1.1 and 1.1. in contrast  back-propagation is polythetic  in that the values of multiple attributes are simultaneously considered  summed . however  the monothetic property of id1 is not a general assumption of the mote interaction. 
1 	machine learning 
field. traditionally  ai concept learning methods have been search intensive precisely because they simultaneously consider the utility of many attributes. recently  quinlan  1  has introduced a polythetic extension to id1 that builds a monothetic decision tree  without using confidence measures to terminate decomposition   and then converts it to a set of production rules. each rule is a polythetic concept that is 'massaged' in order to improve its accuracy. that this extension was prompted by quinlan's comparison of id1 and a genetic classifier  which shares certain characteristics with connectionist nets   adds impetus to continued comparisons with this extension. quinlan's comparisons only occurred in an artificial domain similar to our exclusive-or function. our methodology promises to characterize the id1 extension across a wide range of domains. a determination of whether logic-based  but polythetic learning systems can overcome problems of granularity discussed in 1 must await experimentation. however  polythetic classification in ai learning systems need not preclude probabilistic representations as noted in 1. 
1 incremental versus nonincremental process-
ing 
id1 assumes that all observations are simultaneously available for processing  while back propagation processes observations as they become available. this distinction is somewhat true of the two paradigms more generally. however  id1 has recently spawned two incremental variants  1  schlirnmer & fisher  1  and ids  utgoft  1a . incremental learning more generally is becoming popular in aj learning research. the common thread in these systems  including connectionist methods and cobweb  is the use of 'probabilistic' representations. finer granularity allows more conservative steps through a search space. this conservatism is necessary; early in training  many observations are inconsistent with the evolving concept description. no observation should irrevocably impact the incomplete con cept description. 
1 constructive versus convergent search 
perhaps the most overt distinction between ai and connectionist systems is the manner in which they explore their respective search spaces. ai systems typically reconstruct the space upon demand  which is only defined implicitly by operators and an initial state to begin with. in contrast  most connectionist systems preenumerate a subset of the space  which is implicit in the number and interconnections between nodes. problems arise if too much  e.g.  slow convergence  or too little  e.g.  the concept cannot be learned  of the space is preenurnerated. important steps in reconciling these strategies have been explored by schlirnmer fa granger  1  and hampson fa volper  1 . schlirnmer fa granger's stagger 

system adapts connectionist evidence combination procedures to the 'constructive'  upon demand  approach: the emphasis is on technology transfer to al systems. in contrast  hampson k volper stress transfer to connectionist research: specialized disjunctive nodes can be enumerated and integrated on demand  thus facilitating rapid convergence. picking up on the discussion of 1  al systems appear well suited to enumerating an appropriate subspace that may then be refined. 
1 concluding remarks 
empirical comparisons have uncovered advantages and disadvantages of two specific learning systems. that these systems are from different paradigms is impetus for interaction. research of this ilk is being pursued by several researchers  some of whom we have discussed. in addition  future comparisons must increase the scope of our study to other learning systems and learning strategies. currently  we  fisher  mckusick  mooney  shavlik  k towell  1  are exploring an alternative training strategy for back-propagation that combines the incremental and batch approaches: small batches of training objects are incrementally presented and are processed until convergence  on the subbatch . our initial results 
suggest that using very small batch sizes  1 to 1  significantly reduces the total number of presentations required until asymptotic accuracy is achieved. we are pursuing these experiments and hope to flesh out an explanation of the phenomena in terms al concepts; most notably  can we view this process as simulating casebased reasoning and/or a specific to general search for the best classifier  either interpretation is a departure from the usual training strategy of moving from general  indiscriminate  towards greater specialization. hopefully  these explorations will improve back-propagation training time without detrimentally impacting accuracy. 
acknowledgements 
we thank ray mooney  jude shavlik  and geoff towell for influential discussions and debates. comments by richard sutton improved the correctness and clarity of discussion  as did comments by ijcai reviewers. 
bibliography 
fisher  d.  1 . knowledge acquisition via incremental conceptual clustering. machine learning  1  1. 
fisher  d.  mckusick  k.  mooney  r.  shavlik  j. & towell  g.  1 . processing issues in comparisons of symbolic and connectionist learning systems. proceedings of the sixth international machine learning workshop. ithaca  ny: morgan kaufmann. 
hinton  g.  in press . connectionist learning procedures. artificial intelligence. 
hampson  s. k volper  d.  1 . disjunctive models of boolean category learning  biological cybernetics  1  1. 
mcclelland  j. k rumelhart  d.  1 . explorations in parallel distributed processing  mit press  cam-
bridge  ma. 
quinlan  j. r.  1 . induction of decision trees. machine learning  1. 
quinlan  j. r.  1 . proceedings of the fifth international machine learning conference   1   ann arbor  mi: morgan kaufmann. 
rumelhart  d.  hinton  g.  & williams  j.  1 . learning internal representations by error propagation. in parallel distributed processing  vol. 1  d. rumelhart k j. mcclelland  eds. . mit press. 
schlimrner  j. & fisher  d.  1 . a case study of 
incremental concept learning. proceedings of the fifth national conference on artificial intelligence. 
philadelphia  pa: morgan kaufmann. 
schlimrner  j. k granger  r.  1 . 	incremental 
learning from noisy data. machine learning  i  1. 
sejnowski  t. k rosenberg  c.  1 . parallel networks that learn to pronounce english text. complex systems  l 
shavlik  j.  mooney  r.  k towell  g.  1 . symbolic and neural net learning algorithms: an experimental comparison. technical report  university of wisconsin  madison. 
smith  e. & medin  d.  1 . categories and concepts  cambridge  ma: harvard university press. 
stepp  r.  1 . conjunctive conceptual clustering: a methodology and experimentation. doctoral dissertation. university of illinois  urban achampaign  il. 
utgoff  p.  1a . id1: an incremental 1. proceedings of the fifth international machine learning conference   1   ann arbor  mi: morgankaufman n. 
utgoff  p.  1b . percetron trees: a case study in hybrid concept representations. proceedings of the seventh national conference on artificial intelligence  st. paul  mn: morgan kaufmann. 
	fisher and mckusick 	1 
