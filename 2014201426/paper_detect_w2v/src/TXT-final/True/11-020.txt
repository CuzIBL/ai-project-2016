 
　　　a scheme used in building models of three dimensional objects through binocular and motion parallax analyses is presented. some preliminary results in using the models for recognition are described  and a discussion of the major objectives summarizes the rationale of the work. the principal emphasis throughout the paper w i l l be that effective vision requires flexible  domain-free  three-dimensional modelling. 
introduction 
　　　object recognition and scene analysis research systems may be categorized bv the use they make of models. the 'hard-wired' approach so common in areas such as chromosome classification  and typical 'blocks world' analysis places them in the lower rank of modelling varieties. the descriptive primitives and their inter relationships which determine classifications are embedded implicitly in the operation of these schemes  and accommodation to other domains is out of the question. increased f l e x i b i l i t y can be attained through the more modular approach of supplying the system with certain pre-defined feature primitives from which it can compose appropriate object descriptions. this technique can be seen in the two-dimensional vision works of roberts  barrow  widrow  and turner  and has a very significant presence in many computeraided-design schemes   braid    voelcker   and the three-dimensional work of popplestone et a l . however  even in the vision work here the dependence on a particular domain is very heavy. no general shape descriptive mechanism is available  and each form to be recognized must be anticipated and encoded  or programmed  beforehand. with the static nature of their feature sets and their limited descriptive range  these systems have only cosmetic advantage over the 'hard-wired' approach. 
　　　it is common practice in well defined  task-oriented problems to introduce such domain-specific  insight-driven program tailoring whenever it w i l l lead to more direct and efficient solutions. in these cases  purist attitudes  arguing for generality and f l e x i b i l i t y   should rightly be abandoned. the long term prospects of  where the author is currently in a phd program machine vision  however  cannot be met by extension of programs dedicated and optimized in their performance to specific domains. in this  generality and f l e x i b i l i t y w i l l be essential ingredients. 
　　　a system  to show competence in visual processing  must  among other things  be able to both use and construct f u l l y descriptive  and this means three - dimensional  models of the objects in i t s environment. it must be able to look out on a scene and build models of whatever is there  hands  people  cars  etc.   and then be able to manipulate these models  comparing them with other descriptions it may build in analyzing some later viewed scene. regarded in this way  the program's role w i l l be seen to be quite passive - it w i l l not be acting .as. the models  but as an intelligent interface between those in i t s memory and the presented visual data. only in this way  with specific domain dependent knowledge removed from the processing can the wanted extensibility be sought. 
　　　note that the model building reguired of such a system i s   in a way  complementary to recognition. while recognition is a process of taking descriptions from memory and using them in the analysis of presented visual images  modelling is the process of analyzing such visual images to build descriptions of the objects from the present environment. since recognizing is associating the experiences of the present with those of the past  it is only appropriate that a recognition scheme also be a modelling scheme.. it needs to keep a record of i t s past experience. 
v i s i o n - 1 : 	baker 
1 　　　a large part of the reason for the proliferation of domain-specific vision research may l i e in the myopia inherent in the way sensors have been used. typically  an entire analysis is based upon a single television image. this may seem to be a reasonable compromise  as it does appear to allow the feeling and flavour of vision without the complications of three - dimensional or time analysis. unfortunately such a process has a striking resemblance to a stationary  one-eyed f l y ' s single-shot vision  and provides too weak a paradigm when the ever-present comparison is with that of our own human sight. a machine vision system  as the human system it tries to simulate  must be able to increase and refine the understanding it has of i t s environment - working in a domain of three-dimensional objects  i t s representation must encompass that three - dimensionality  yet a single  note single  projected image of some unknown object can reveal very l i t t l e of i t s 1-d nature. consider the task of trying to extract sufficient information from a television image not just to recognize some object  but to create a description that w i l l enable that object to be recognized whenever it is seen again  in any orientation  and under any viewing conditions. this weakness of the single view approach has been a re-enforcement for pre-analyzing two - dimensional projections  and thus imposing on the processing a domain of expectation. an escape from this domain dependence trap calls for a different  considerably stronger paradigm. 
　　　it was my intention in this work to explore the possibilities of machine vision in an unrestricted domain of objects  with viewing conditions as near those in which the human system operates as practicable  this excluded lasers  and other such direct ranging devices . the necessity of having a three-dimensional representation led me to consider ways of representing surface shape  and  in turn  three-dimensional object structure  and the need to obtain this structure through a television camera led me to the problem of determining means of making such three dimensional measures. 
　　　humans use binocular and motion parallax  as well as other innate and learned techniques  in distinguishing depths  and i determined to concentrate on seeing how an analysis of this binocular and motion parallax  as obtained through a mobile television camera  could reveal three dimensional shape and relationships.  similar 
approaches can be seen in the work of  baumgart   which started earlier and ran concurrently with this work  and the later work of  burr .  
　　　it is important not to build into a vision system any specific knowledge of shapes. this means we must exclude from consideration any process that takes regions from an image  infers their orientation from an analysis of shape   i . e .   a circle may appear as an ellipse   and uses these inferred shapes as primitives in i t s model description. it is only after we determine a context  based on experience  that we can do this in our vision  and a virgin modelling system  having no experience  and knowing nothing of the context that experience teaches  should similarly have no preconceptions of shape or shape implications. 
curvature. irregularities and building  motels 
       what i have done in this work in an attempt to keep shape preconceptions out of the processing is to chose a very low-level descriptive primitive  hopefully without a domain bias  and use this in specifying shape. the description is formed by locating particular second order irregularities in projected images  tracking them over a series of views  and building up a meshed network whose nodes are these irregularities  in 1 space   and whose arcs are 
v   s i o n - 1 : 
1 
the surface curvatures joining them. the model of a surface's shape  then  is this meshing of vectors and curvature descriptors - to be visualized perhaps as a wire-meshed exoskeleton. an object whole  which may consist of many surfaces  is defined in a similar manner  with vectors locating and orienting i t s constituent surfaces. figure 1 shows a single-surfaced object defined in this way. 
　　　the primitives of these shape descriptions are points of curvature irregularity - those positions in the image where constant curvature arcs  fitted to the contours  or edges   terminate. these occur most prevalently where shape irregularity is densest  and  being local measures  allow the analysis to be much less susceptible to projective anomolies and occlusions  the total surface shape  being a complex of local shape  only loses definition at the occlusion . they are psychologically interesting  being measures of the most discriminative aspect of shape  its smoothness and irregularity  remember attneave's cat   and their use as a metric puts no constraints on the type of shapes to be dealt with  any projected shape can be closely approximated with circular arcs  even polyhedral edges . 

	object studied from left 	object from front 
figure 1 
　　　the implementation forced several compromises in the professed intentions. clearly  cluttered scenes were not allowed in the modelling phase. objects studied were r i g i d   single-coloured  opaque solids  although earlier work was done with a multi-coloured object . a fixed camera frame made it necessary to rotate the objects  rather than the camera  for most purposes  these are 
equivalent . 
　　　the task of obtaining object descriptions of this form is implemented through two processes  programmed in macro on a pdp-1 . the f i r s t analyzes individual images of a scene  extracting 
raker 
contour descriptions based upon the irregularity measure. the second takes sequential pairs of such descriptions  correlates them  that is  correlates their irregularities   and constructs the meshed networks representing their shapes. 
     the protocol for the low level analysis is the following. an object  mounted on a spit  is photographed  the image analyzed  and the results of the analysis are passed to the correlation process. the object is then rotated on the spit  through a known angle  to a new orientation  where it is photographed  and the analysis repeated. further rotations are made  each being followed by the image acquisition  analysis  and transmission to the correlator. 
     each analysis first involves scanning the intensity array to find picture points that  probably  lie on region boundaries  a drocess which requires two passes over the array with a 1 by 1 pixel operator. the first pass locates the horizontal edges  the second the vertical  figure 1a . there is l i t t l e of special significance in this aspect of the processing.  the edge points  or intensity discontinuities  are positioned where the intensity gradient is greatest in an area bounded by either near-homogeneous areas  typically the middle of image regions   or intensity gradient inflections. circular arcs are then fitted through these points. the endpoints  or junctions of these arcs are the curvature irregularities used in the correlation  figure 1b . 


 viewed from 1c to left 	viewed from front edges running between end points of 1-d vectors determined by the correlation of the vertices of the 1 view descriptions of figure 1b. 
 gaps occur when 1 adjacent irregularities do not have correlates  figure 1a 

viewed from the left 	viewed from the front 
next correlation vectors fieure 1b 

   composite description from 1a and 1b formed by superimposing the 1 descriptions and binding them together with the tracked 'depth' arcs. figure 1c 
     the correlation process operates on the output of two sequential low level analyses. it begins by finding corresponding regions in the two views  using as measures distance apart  size  and average intensity . once these are established  it selects corresponding curvature irregularities and  correlating them  determines the three dimensional vector they imply  figure 1a . the measures used in selecting corresponding curvature irregularities include the concavity or convexity  both at the junctions and in the arcs on either side  these are topological tests   and the magnitude of their separation and the direction of their vertex bisectors  positional tests . to determine the vector  the correlation process must know the equation of the rotational axis  the spit  lying in the plane of projection  its distance from the camera  and the rotational angle change  as well as the two - dimensional 

v i s i o n - 1 : 	baker 1 

coordinates of the irregularities in the two views  the vector at point x in figure 1a was derived from the correlation of vertices 1 and 1 in figure 1b . figure 1b shows the positions of vectors from the next correlation  and figure 1c shows the 
composite description after these 1 correlations. 
　　　it isn't obvious  but this correlation works equally well for 'real' edge irregularities  such as the vertices of a cube  as it does for those on 'pseudo' edges  three-dimensional contours. with the former  figure 1a   the vector w i l l actually locate the vertex  within the digitization error   
while in the latter case  the vector w i l l indicate a point near the surface lying between the irregularities seen in the two projected views  figure mb . this may seem to be a flaw in the modelling  but is actually quite the opposite the distance above the surface is proportional to the angle of rotation and the convexity of the surface  and is not large - the arcs connecting these vectors  termed 'depth' arcs  l i t e r a l l y hold the model together. 

　　　each such vector may have up to four surface descriptor arcs leaving it  figure 1 . two of these may be to the l e f t and right  'breadth' arcs   and run to vectors adjacent  and derived from the same two individual views. the other two may extend to the front and rear  these are 'depth' arcs.. notice those arcs in figure 1c which were not present in either figure 1a or 1b . the l e f t / r i g h t arcs carry curvature information  as their shapes were seen in the two views correlated  but the depth arcs have no indication of curvature.. their shapes were not seen. in fact depth arcs are just inferred from the tracking of vectors as the object rotates  this is the motion component of the analysis . an ongoing clustering process collapses these 'depth' arcs when the irregularities they separate are within the digitization error of each other  and creates others when new irregularities approach earlier ones  the description is wrapping back around on i t s e l f   . 

1 possible surface descriptor arcs figure 1 
       these vectors and arcs  then  are the basis for surface shape description. since an object may consist of many surfaces  each is specified as a composite of i t s surface vectoral descriptions.  as mentioned earlier  the objects modelled were almost exclusively single-surfaced.  figure 1 shows the progression of the modelling through a sequence of ten views  in 1 degree increments  with the object of figure 1. part 'a' is the individual regions as found in the intensity arrays  part 'b' shows the 'breadth' arcs formed from the correlations  viewed from 1＜to the l e f t   and from the front   while part 'c' indicates the composite descriptions as they are formed  successive 'breadth' arcs joined with their tracked 'depth' arcs   again viewed from 1＜to the 
l e f t   and from the front. 
　　　figure 1 shows the completed model viewed roughly in the orientations depicted in figure 1. there are a few aberrant points on this model  notably in the l e f t figure at the extreme bottom right and the too l e f t . these arise from the correlation of irregularities whose local surface is nearly orthogonal to the rotational axis.. this error is d i f f i c u l t to avoid when only one axis is used. two perpendicular axes can be handled in this modelling scheme  but tests were only carried out for the case of one axis. details of the modelling  just mentioned here  are available in  baker   


v i s i o n - 1 : 	baker 
1 

be 
for 
from a very 
points 
although shape 
nothing 
	about 	orientations 
	the 	relative 	looations 	their 	surface 
progression of the modelling vectors. if shape comparison is to proceed  in 1 degree increments something must be found that will allow these figure 1 relations to be discovered. 
vision-1: baker 
1 


	from left 	from front 	from below 
model of same object as figure 1  but analyzed from a different orientation figure 1b 
　　　as each model is constructed  it is put in a pseudo-canonic form  'pseudo' because it cannot be guaranteed to be unique .  it is reoriented about a coordinate frame defined by its greatest breadth  and two other axes calculated normal to this. yet even this does not ensure a unique orientation  as the views used for the correlation are discrete projective slices  and an object having many similar large diameters could  depending upon the particular views seen  have any of them chosen as i t s maximal. to force a bit more order into the process  i assume that if two shapes are to be considered similar  then at least a certain number of their topologically significant features should correspond  note that the assumption could run into trouble where there is severe occlusion or where an object has a highly symmetric nature . this is implemented by keeping with each model a l i s t of i t s 1 most concave or convex vertioes  these characterize the local surface shape about a vector  and are indicated in figures 1a and 1b byo   the figure 1 is arbitrary  but must be at least 1 to enable the transformation equations to be determined  the more there are  the better the chance of finding a 
　　　match  but equally the longer it may take to discover i t   . the problem of finding the possible relationship between the two shapes is now reduced to finding similar .triangles in these 1 sets of 1 points  with the additional requirement that corresponding vertioes be of the same type either concave or convex   figure 1 . the similarity  rather than congruence  allows objects of different scale to be compared. 

　　　if no such pair of similar triangles can be formed among these points  then the surfaces may be considered to be different  with the above noted exceptions to the assumption . if there is such a pair  then the transformation that maps one set onto the other should equally map a l l points in that model onto the other model  however not necessarily in a point to point way . comparing the shapes is then a matter of reorienting and translating successive vectors of the one model  and determining how close each lies to the surface of the other model. this is done by finding which 'patch' of the other surface each point projects onto and determining its distance from that surface  figure 1 . a recursive process crawls about on the two meshmgs  branching along each arc  and backing up when a node vector lies too far from its opposing surface. 

　　　the theoretical error limit of the correlation process was about one f i f t h of an inch for the 1 by 1 images used  with a 1 inch field of view at about 1 feet   and the vector to surface distance allowed in the matching was twice this value. it would be possible  although it was not implemented  to look at the cumulative errors in point to surface mappings  and use these to adjust the i n i t i a l l y inferred transformation equations. this would be of major advantage whenever the similar triangle vertices are located to one side of the surface  where the digitization and correlation inaccuracies could lead to minimal error in the transformation for points near the vertices but significant errors as the distance from them increases. figure 1 shows both objects in the orientation in which they were successfully matched  1% of the points corresponded  while only 1% in the left model were successfully mapped onto the surface of the model in figure 1 . 

　　　models of figures 1a and 1b  drawn in the orientations in which they were found to match 
v i s i o n - 1 : 	baker 
1 figure 1 
　　　it is not my intention to suggest from this preliminary matching success that the memory of models be used in this way  as the extraction and use of commonly occurring shapes is c r i t i c a l for a recognition scheme that hopes to work in anything resembling real time. but  as stated  this comparison procedure is an important part of the generalizing  and it was necessary to show that the models could be manipulated and compared in this way. 
　　　my objective with this work now is to go back through much of it and bring it up working with larger  1 square  images of multi-coloured objects  then when satisfied with i t s performance at this level  to study the shape generalization problem. a few further  more futuristic  goals model modification to contain 'dynamic' structure information  making 'working' models of non-rigid objects   and self-organization of model memory  to provide efficient  perhaps context-sensitive  retrieval - indicate the potential for further development within this modelling framework. 
important points 
　　　this approach  stepping into multiple - view analysis  marks a significant change from previous work in machine vision. 
　　　lt permits a valuable reconsideration of programming approach. established vision methods  where a l l information available to the analysis is presented in one single view  force the analysis to be temporally local with their over-riding demand for an interpretation  and make the system particularly sensitive to the destructive influence of view-point anomolies and image noise. the analysis of parallax  with i t s correlating of many sequential images  allows one to loosen this dependence on 'clean' pictures  and leave the generalizing over errors or ambiguities of analysis to the more capable higher level process that works in time.  'dirty'  or structurally discontinuous sequences of pictures don't exactly help  but neither are they catastrophic.  
     different still is its approach to the. representation of objects and shape. for concise vet detailed descriptive models. as much as i t s uniqueness was underplayed in the discussion of shape matching  there is truly something canonic  and even psychologically significant  in the use of this irregularity-based representation. but most significant is the step this. takes towards establishing a mora reasonable kind  of i n i t i a l state knowledge in the system  previous efforts in computer vision have involved embedding a great deal of domain-specific knowledge  eg. the domain of tri-hedral convex polyhedra  into the workings of the process. in these systems the i n i t i a l state knowledge has served to define and constrain the environment. instead  this system is given  through an understanding of parallax  working knowledge of the behavior of physical objects in three - space. having ways of manipulating the environment  it is able to exploit this behavioral knowledge in analyzing the scene. the contrast  then  lias  in giving. the system not specific knowledge of the. forms  in its world  but knowledge specific to its determining 
those forms. 
acknowledgement 
part of this work was supported by two successive research contracts from the national engineering laboratory to professor donald michie  the machine 
intelligence research unit  edinburgh university  edinburgh  scotland. 
