 
　　this paper considers various factors affecting system organization for speech understanding research. the structure of the hearsay system based on a set of 
cooperating  independent processes using the hypothesize-and-test paradigm is presented. design considerations for the effective use of multiprocessor and network architectures in speech understanding systems are presented: control of processes  
interprocess communication and data sharing  resource allocation  and debugging are 
discussed. 
　　keywords: speech recognition  speech understanding  system organization  networks  multiprocessors  parallel processing  real-time systems  hardware for ai  software for ai. 

introduction 
　　system organizations for speech understanding systems must address many problems; effective use of multiple sources of knowledge  anticipation and goal-direction in the analysis of the incoming utterance  real-time response  continuous monitoring of input device s   errorful nature of the recognition process  exponential increase of processing requirements with the increase of desired accuracy  and so on. a particular model of speech perception  reddy et al.  1  which attempts to solve the above problems involves the use of cooperating independent processes using a hypothesize'and-test paradigm. this paper examines the effect of the problem constraints and the model on system organizations  presents the structure of a system 
currently operational on a pdp-1 computer  and discusses the implications of multiprocessor and network architectures. 
　　unlike many other problems in artificial intelligence  speech understanding systems are characterized by the availability of diverse sources of knowledge  e.g.  acoustic-phonetic rules  phonological rules  articulatory models of speech production  vocabulary and syntactic constraints  semantics of the task domain  user models  and so on. a major problem  then  is to develop paradigms which can make use of all the available sources of knowledge in the problem solution. at the same time  absence of one or more sources of knowledge should not cripple the system. suppose each source of knowledge is represented within the system as a process. in order to remove or add sources of knowledge  each process must be independent  i.e.  it must not require the presence of other processes in the system. but at the same time each process must cooperate with the other processes  i.e.  it must be able to effectively use the information gathered by them about the incoming utterance. thus  a major design step is to establish what information is to be shared among processes and how this information is to be communicated so as to maintain the independence of individual processes while still allowing for necessary process cooperation. 
　　knowledge available in the acoustic signal represents only one part of the total knowledge that is brought to bear in understanding a conversation. a good example of this is when one is interrupted by an appropriate response from the listener to a question that is as yet incomplete. in general  a human listener can tolerate a great deal of sloppiness and variability in speech because his knowledge base permits him to eliminate most of the possibilities even as he hears the first few words of the utterance  if not before! . we feel that this notion of anticipation  prediction  and hypothesis generation is essential for machine perception systems as well. in general  we expect every source of knowledge to be able to generate hypotheses in a given context  or verify hypotheses generated by others using different representations of knowledge  if necessary. the implication is that knowledge processes be organized within the system so as to reduce the problem of recognition and understanding to one of prediction and verification. 
* this research was supported in part by the advanced research projects agency of the department of defense under contract no. f1-c-1 and monitored by the air force office of scientific research. 
1 　　in tasks such as chess and theorem-proving  the human has sufficient trouble himself so as to make reasonably crude computer programs of interest. but  because humans seem to perform effortlessly  and with only modest error  in speech  and visual  perception tasks  similar performance is expected from machines  i.e.  one expects an immediate response and will not tolerate any errors. to equal human performance  a speech understanding system mutt be able to understand trivial 
questions is soon as they are uttered. this implies that various processes within the system should be allowed to operate at soon as there is sufficient incoming dati  without waiting for the completion of the whole utterance. if the processes within the system are independent and unaware of the existence of each other  then the system must provide facilities for activation  termination  and resource allocation for each of the processes. further  if a process can be deactivated before it reaches a natural termination point  provision must be made to preserve the state of the process until it is reactivated. also  it is necessary to provide interlocks on the data that are shared among many processes. 
     this has several implications for system organization. the system must monitor the input device continuously to determine whether speech is present; this requires non-trivial processing. if the system is unable to process the incoming data  automatic buffering must be provided. if the system is to run on a timesharing system  provision must be made to ensure that no data is lost because the program is swapped out for a period of time. if the speech understanding system is to consist of a set of cooperating independent processes  it is further necessary that they be able to be interrupted at unpreprogrammed points - if the microphone monitoring program is not activated in time to process the incoming utterance  it could lead to irrevocable loss of data. these considerations lead to two additional requirements that are not commonly available on existing time-sharing systems  viz.  process-generated interrupts of other processes and user servicing of interrupts. 
     one of the characteristics of speech understanding systems is the presence of error at every level of analysis. to control such errors and permit recycling with improved definitions of the situation  one uses techniques such as feedforward  feedback  and probabilistic backtracking. if such facilities do not exist within the system  they have to be programmed explicitly. 
　　speech  by its nature  appears to be computer intensive. a substantially unrestricted system capable of reliably understanding connected speech of many speakers using a large vocabulary is likely to require systems of the order of a proposed ai machine  bell  freeman  et al.  1a   i.e.  processing power of 1 to1 million instructions per second and memory of 1 to 1 million bits.* to obtain such processing power  it appears necessary to consider multiprocessor architectures. decomposition of speech processing systems to effectively use distributed processing power requires careful consideration even with primitive systems. our model of cooperating independent processes  each representing a source of knowledge  leads to a natural decomposition of the algorithms for such machine architectures. 
the current henrsay system 
　　in this section we briefly describe the hearsay speech understanding system as it now exists at c-mu.  more detailed 
descriptions of the system are given in ready et al.  1a  this volume ; erman  1; and neely  1.  we shall stress those aspects of its organization which are responsive to the constraints and model outlined above. this system represents a 
first attempt to solve those problems; thus  some of the constraints are only partially or poorly met  while others are satisfied in a more constricted way than necessary. we shall point out these limitations as they are described  later sections on closely-coupled and loosely-coupled processor network architectures describe possible corrections and improvements of the system. 
* smaller and substantially cheaper systems can be built to perform useful but restricted speech understanding tasks. 
     the hearsay system is implemented as a small number of parallel coroutines  see figure . each coroutine  module  is realized as   separate job in the pdp-1 time-sharing system; thus the time-sharing monitor is the primary scheduler for the modules. in general  the modules may achieve a high degree of  pseudo-  parallel activity  through the use of shared memory and a flexible inter-process message system*   but  in practice  we limit the parallelism to a very modest amount. this limitation is imposed for two reasons: first  since the pdp-1 is a uniprocessor system  there is nothing to be gained  in the time domain  by increasing the parallelism; and  second  the greater the amount of parallelism  the more difficult it is to control and debug the programs within a time-sharing system that is not designed for cooperating processes {jobs . 

　　the model of recognition specifies that there be separate processes  each representing a different domain of knowledge. we have chosen three major domains of knowledge: acousticphonetics  syntax  and semantics: 
1. the acoustic-phonetic domain  which we refer to as just acoustics  deals with the sounds of the language and how they relate to the speech signal produced by the speaker. this domain of knowledge has traditionally been the only one used in most previous attempts at speech recognition. 
1. the syntax domain deals with the ordering of words in the utterance according to the grammar of the input language. 
1. the semantic domain considers the meaning of the utterances of the language  in the context of the task that is specified for the speech understanding system. 
     these processes  according to the model  are to be independent and removable; therefore the functioning  and very existence  of each must not be necessary or crucial to the others. on the other hand  the model also requires that the processes cooperate and that the recognition should run efficiently and with 
1 * the facilities provided for inter-job control and communication are similar to those developed for the stanford hand-eye system  feldman and sproull  1 . 
good error recovery; these dictates imply that there be a great deal of interaction among the processes. thus we seem to have opposing requirements for the system. these opposing requirements led to the design of the following structure: 
each process interfaces externally in a uniform way that is identical across processes; no process knows what or how many other recognition processes exist. 
a mediator  rover {recognition overiord   handles the interface to each of the processes and thus serves as the linkage connecting the processes; the processes are called rover's  sons.  
　　the interface is implemented as a global data structure which is maintained by rover. each of rover's sons puts information into this data structure in a uniform way. each may access information submitted by its brothers  but in a manner which leaves the source of that information anonymous. this mechanism is analogous to a bulletin board on which messages can be left by several people and for which there is a monitor who accepts the message and arranges them in appropriate places on the board for others to react 
　　this anonymous interface structure is appropriate only if the global data structure can be designed in such a way as to allow the processes to communicate meaningfully; i.e. there must be a common language which allows them to transmit the kind of information they need to help each other to work on the problem. we resolve this problem by using the word as the basic unit of discourse among the processes. 
　　the basic element of the global data structure is the word hypothesis which represents an assertion that a particular word  of the input language lexicon  occurs in a specified position in the spoken input. a sentence hypothesis is an ordered linear sequence of word hypotheses; it represents an assertion that the words occur in the sentence in the order that the word hypotheses appear in the sentence hypothesis. in addition  the unique  word  filler may appear as a word hypothesis; this is a placeholder and represents the assertion that zero or more as yet unspecified words occur in this position in the spoken sentence. in general  there may be any number of sentence hypotheses existing at any one time. 
　　the interactions among the source-of-knowledge processes are carried out using the hypothesize-and-test paradigm prescribed by the model. in general  any process may make a set of hypotheses about the utterance; all the processes  including the hypothesized may then verify  i.e. reject  accept  or re-order  these hypotheses. in particular  hypothesization occurs when a recognition process  acoustics  syntax  or semantics  chooses a filler word from a sentence hypothesis and associates with it one or more option words  each of which it asserts is a candidate to replace all or part of the filler. verification consists of each process examining the option words and rating them in the context of the rest of the sentence hypothesis. 
　　several restrictions have been placed on the implementation of this general scheme. first  at any time only one part of the shared  global data structure  i.e.  one sentence hypothesis  is accessible to the processes for hypothesization and verification. second  the processes go through the hypothesization and verification stages  and several other subsidiary stages  in a synchronized and non-interruptable manner. finally  only one process is allowed to hypothesize at any one time. again  these restrictions were imposed both because parallelism on a uniprocessor does not accomplish any throughput increase and because the available programming and operating systems make a 
　　more genera  implementation difficult to specify  debug  and instrument. these restrictions are mitigated somewhat by carefully adjusting the time grain of the processing so that each non-interruptable phase is not  excessively large.  
　　each sentence hypothesis has a confidence rating associated with it which is an estimate of how well it describes the spoken utterance. this rating is calculated by rover  besed on information supplied by the recognition processes. errors in processing become evident when the overall rating given to a sentence hypothesis begins to drop; at that point  attention is focused on some other sentence hypothesis with a higher rating. this switching of focus is the mechanism that provides the error recovery and backtracking that is necessary in any speech understanding system. 
clolsely-coupl ed processor system organizatkins 
　　as discussed in the introduction  in order to do real-time speech understanding a substantial amount of computing power is required. recent trends in technology indicate that this computing power can be economically obtained through a closelycoupled network of  simple  processors  where these processors can be interconnected to communicate in a variety of ways fe.g.  directly with each other through a highly multiplexed switch connected to a large shared memory  bell et el.  1   or through a regular or irregular network of busses  bell et al.  1  . however  the major problem with this network approach to generating computing power is finding algorithms which have the appropriate control and data structures for exploiting the parallelism available in the network. the model for a speech understanding system as previously discussed  which is decomposed into a set of independent processes cooperating through a hypothesize-and-test paradigm  represents a natural structure for exploiting this network parallelism. 
　　there exist three major areas for exploitation of parallelism in the structure of this speech understanding system: preprocessing  hypothesization and verification  and the processing specific to each source of knowledge. the preprocessing task involves the repetition of a sequence of simple transformations on the acoustic data  e.g.  detection of the beginning and end of speech  amplitude normalization  a simple phoneme-like labeling  smoothing  etc. this sequence of transformations can be structured as a pipeline computation in which each transformation is a stage in the pipe. thus  through this pipeline decomposition of the preprocessing task  a limited amount  i e   1  of parallel activity i$ generated. 
　　the hypothesize-and-tett paradigm for sequencing the activity of the different sources of knowledge can also be structured so as to exhibit parallelism  but the amount of parallelism is potentially much greater. this parallel activity is generated by the simultaneous processing of multiple sentence hypotheses and the simultaneous hypothesization and verification by all sources of knowledge. the simultaneous processing of multiple sentence hypotheses  rather than processing just the currently most likely candidate  can conceptually introduce unnecessary work. but in practice  because of the errorful nature of the processing  there may be a considerable amount of necessary backtracking to find the best matching sentence hypothesis. it is appropriate to quote a conjecture of minsky and papert  1  section 1.1  on this point: 
 while for the exact match problem  relatively small factors of redundancy in memory size yield very large increases in speed  . . .  for the best match problem  . . . for large data sets with long word lengths there are no practical alternatives to large searches that inspect large parts of the memory. 
1 thus  the parallel activity generated by simultaneous processing of more than one sentence hypothesis can result in a proportional speed-up of the recognition process.* correspondingly  simultaneous hypothesitation and verification by all sources of knowledge also results in a proportional speedup of the recognition process because each source of knowledge is independent and is designed so that its knowledge contirbution is additive. 
     finally  the verification algorithm of each source of knowledge can be decomposed into a set of parallel processes in two ways: the first kind of decomposition is based on the fact that verifications are performed on a set of option words rather than a single word at a time. thus  for each source of knowledge there can be multiple instantiations of its verification process  each operating on a different option word. the second kind of decomposition involves the parallelizing of the verification algorithms themselves; thus  each instantiation of a verification process may itself be composed of a set of parallel processes. however  this set of instantiations may not be totally independent because the rating produced by the verification process may be dependent on the particular set of option words to be verified and also on the local data base which is common to all the instantiations. for example  the acoustic verification process is a hierarchical series of progressively more sophisticated tests. the first few levels of testing look only at the context of a single option word  while the more sophisticated tests compare one option word against another. thus  only at the first few levels of tests can the acoustic verification algorithm be parallelized in a 
     straightforward manner. 
　　the parallelism generated by parallelizing the hypothesizeand-test control structure and the verification processes are multiplicative in their parallel activity  i.e  performing in parallel the updating of n sentence hypothesis where each hypothesis invokes m verification processes and each verification process operates on o option words leads to a potential parallelism of n*m*o . this parallelism  together with the pipeline parallelism of the preprocessing  leads to what appears to be a large amount of potential parallelism to be exploited by a closely-coupled network. however  it is still not clear just how much potential parallel activity exists over the entire recognition system; nor is it known how much of this potential will be dissipated because of software and hardware overhead. 
     in order to answer these questions  a parallel decomposition of the hearsay speech understanding system is now being implemented on c.mmp  a closely-coupled network of pdp-1** which communicate through a large shared memory  bell et al.  1 . the c.mmp hardware configuration can contain up to 1 pdp-ll'sj the highly multiplexed switch that connects processors to memory permits up to 1 simultaneous memory references if these 