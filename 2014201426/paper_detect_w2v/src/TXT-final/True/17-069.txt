 
   this paper describes an approach to knowledge base refinement  an important aspect of knowledge acquisition. knowledge base refinement is characterized by the addition  deletion  and alteration of rule-components in an existing knowledge base  in an attempt to improve an expert system's performance. seek1 extends the capabilities of its predecessor rule refinement system. seek   in this paper we describe the progress we have made since developing the original seek program:  a  seek1 works with a more general class of knowledge bases than seek   b  seek1 has an  automatic pilot  capability  i.e.  it can  if desired  perform all of the basic tasks involved in knowledge base refinement without human interaction   c  a metalanguage for knowledge base refinement has been specified which describes both domain-independent and domain-specific metaknowledge about the refinement process. 
i knowledge acquisition and the knowledge base refinement problem 
   the problem of constructing an efficient and accurate formal representation of an expert's domain knowledge  the knowledge acquisition problem  is a key problem in al.* as a practical matter  the most difficult aspect of expert system design is the construction of the knowledge base; the rate of progress in developing useful expert systems is directly related to the rate at which it is possible to construct good knowledge bases. 
   the knowledge acquisition problem can be divided into two phases. in phase one the knowledge engineer extracts an initial rough knowledge base from the expert   rough  in the sense that the overall level of performance of this knowledge base is usually not comparable to that of the expert in the 
*this research was supported in part by the division of 
research resources  national institutes of health. public health service  department of health  education  and welfare  grant p1 rr1. 
second phase  the knowledge base refinement phase  the initial knowledge base  s progressively refined into a high performance knowledge base. in terms of a rule-based knowledge base  phase one involves the acquisition of entire rules  indeed entire sets of rules  for concluding various hypotheses. the refinement phase  on the other hand  is characterized not so much by the acquisition of entire rules but by the addition  deletion  and alteration of rulecomponents in certain rules in the existing knowledge base  in an attempt to improve the system's performance. obviously the foregoing description of knowledge base construction is an idealization. in practice the line between these two phases is not as sharply drawn. ** 
   a knowledge base refinement problem can be thought of as an optimization problem in which we start with a proposed general solution to a given set of domain problems and the goal is to refine it so that a superior solution is obtained. the proposed solution is a working knowledge base that is in need of minor adjustments  but not a major overhaul  i.e.  one assumes that the rules given by the expert are basically  sensible  propositions concerning the problem domain. the refinements applied to the rules of this knowledge base must not only meet the obvious requirements of being syntactically and semantically admissible  they must also be conservative  in the sense that they tend to preserve  as far as possible  the expert's given version of the rules. employing rule refinements that meet these requirements makes it more likely that the construction of a refined knowledge base will not simply be a matter of  curve fitting.  but will result in a knowledge base that is more robust yet at the same time  close  to the actual knowledge of the expert 
¡¡**in this paper we limit our concern to knowledge bases that are structured collections of production-rules. unless otherwise stated  when we use the term  expert system.  we mean  properly speaking   production-rule based expert system.  furthermore we confine our attention to refinements of production rules that can be achieved as the result of the sequential application of certain generic refinement operations that are either generalization or specialization operations. 
   
1 	a. ginsberg et al. 
ii the basic 	approach; empirical analysis of rule behavior using case 	knowledge 
a. overview 
   in this section we briefly review the basic approach to knowledge base refinement taken by seek  - an approach that we have continued to employ in seek1. 
   a fundamental assumption of this approach is that case know/edge can be used to drive a process involving empirical analysis of rule behavior in order to generate plausible suggestions for rule refinement. case knowledge is given in the form of a data base of cases with known conclusions  i.e.  each case contains not only a record of the case observations but also a record of the experts conclusion for the case. empirical analysis of rule behavior involves gathering certain statistics concerning rule behavior with respect to the data base of cases: suggestions for rule refinements are generated by the application of refinement heuristics that relate the statistical behavior and structural properties of rules to appropriate classes of rule refinements. we will shortly explicate the nature of the statistical evidence gathered and give an example of these rules. 
   our basic control strategy is a combination of  divide and conquer*' together with a goal-directed backward chaining mechanism. we assume that the expert and knowledge engineer can identify a finite set of final diagnostic conclusions or  endpoints;  these are the conclusions that the expert uses to classify the given cases. one can then confine one's attention to the refinement of rules that are involved in concluding a particular endpoint. e.g.  if the domain is rheumatology one may decide to work on refining those rules involved in concluding the single final diagnosis systemic lupus. this is the divide and conquer part of the strategy; it means that at any given moment the system is applying the refinement heuristics only to a proper subset of the rules in the domain knowledge base. the goal-directed backward chaining mechanism comes into play once an endpoint has been chosen. if our chosen endpoint is systemic lupus  for example  we begin by applying the heuristics to all the rules in the knowledge base that directly conclude systemic lupus  i.e.  rules whose right hand side is this conclusion. a rule that directly concludes some endpoint will  in general  have components on its left hand side that themselves are the conclusions of some other rules; such components are called intermediate hypotheses. the rules that conclude intermediate hypotheses may themselves include components that are intermediate hypotheses. whenever the refinement heuristics suggest modifying an intermediate hypothesis ih  such as deleting it from some rule  the rules that conclude ih are thereby implicated as candidates for refinement. 
b. some statistics and a heuristic 
   at the highest level  many refinements of production rules may be thought of as falling in one of two possible classes: generalizations and specializations. by a rule generalization we mean any modification to a rule that makes it  easier  for the rule's conclusion to be accepted in any given case. a generalization refinement is usually accomplished by deleting or altering a component on the left hand side of the rule or by raising the confidence factor associated with the rule's conclusion. by a rule specialization we mean modifications to a rule that make it  harder  for the rule's conclusion to be accepted in any given case. a rule specialization is usually accomplished by adding or altering a component on the left hand side or by lowering the confidence factor associated with the rule's conclusion . 
   on the side of evidence for rule generalization  one of the concepts we have employed in both seek and seek1 is a statistical property of a rule computed by a function that we call gen rule . gen rule  is the number of cases in which  a  this rule's conclusion should have been reached but wasn't   b  had this rule been satisfied the conclusion would have been reached  and  c  of all the rules for which the preceding clauses hold in the case  this one is the  closest to being satisfied.  a measure of how close a rule is to being satisfied in a case  based on the number of additional findings required for the rule to fire  is easily computed given the case data  for details of the algorithm used by seek see ; seek1's closeness measure is essentially the same . 
   on the side of evidence for rule specialization  one of the concepts we have defined is a statistical property of a rule that is computed by a function we call speca rule . speca rule  is the number of cases in which  a  this rule's conclusion should not have been reached but was  and  b  if this rule had failed to fire the correct conclusion would have been reached  i.e.  the correct conclusion was the  second choice  in the case  due to its having the second highest confidence   and the only circumstance preventing its being the  first choice  is the fact that this rule is satisfied. if there is more than one satisfied rule that concludes the incorrect first choice then none of these rules has its speca measure incremented; instead we have defined an additional concept to cover this situation called specb rule : each of these rules has its specb measure incremented. 
   to get a feeling for the sort of heuristics employed by these systems  suppose that for a certain rule r it has been found that gen r     speca r  + specb r    in other words the evidence suggests that it is more appropriate to generalize than specialize r. another piece of information would help us decide which component of r should be deleted or altered  viz.. the most frequently missing component  i.e.  the component of r that has the lowest frequency of satisfaction relative to the cases that contribute to gen r . 
   
the function that computes this statistic is called mfmc rule . 
mfmc rule  also tells us the syntactic category of this most frequently missing component for example  one sort of component often used in medical diagnostic systems is called a choice component. these have the form 
where k  the choice number is a positive integer and the c's 
i 
are components  findings or hypotheses  but not choices . a choice component is satisfied iff at least k of its c's are satisfied. if we know that the rule r should be generalized and that mfmc r  is a particular choice component  then a natural thing to do is to decrease the choice number of that choice component. being conservative we decrease the choice number by 1. 
   to summarize the discussion in this section we now display in full the particular heuristic we have described. if: gen rule     speca rule  + specb rule   & mfmc rule  is choice-component c 
then: decrease the choice-number of choice-component c in r u l e . 
reason: this would generalize the r u l e so that it w i l l be easier to s a t i s f y . 
	i l l the seek 	experience 
   a salient feature of the original seek program  is that it was not designed to solve the entire knowledge base refinement problem on its own  rather it was intended to help  interactively  an expert or knowledge engineer solve the overall problem by offering potential solutions to various subproblems that arise along the way. seek helps its user in the following ways:  a  it provides a performance evaluation of the knowledge base relative to the case data base   b  using its statistical concepts and heuristics it identifies rules that are plausible candidates for refinement and suggests appropriate refinements   c  a user can instruct seek to calculate what the actual performance results of a particular refinement to the knowledge base would be. and if the user desires. seek will incorporate the change in the knowledge base. 
a. basic cycle of 	operation 
   although control in seek always resides with the user  and there are a number of paths and facilities available to the user at almost every point  seek can be thought of as having a basic cycle of operation. the system is given an initial knowledge base and the case knowledge data base. seek first obtains a performance evaluation of the initial knowledge base on the data base of cases. this is done by  running  the initial knowledge base on each of the cases in the data base  and then comparing the knowledge base's conclusion with the stored expert's conclusion. the performance evaluation consists primarily of an overall score  e.g. 1% of cases diagnosed correctly  as well as a breakdown by final diagnostic 
	a. ginsberg et al. 	1 
category of the number of cases in which the system agrees with the expert in reaching a particular diagnosis. i.e.   true positives.  and the number of cases in which the system reaches that diagnosis but the expert does not  i.e..  false positives.  
   the user must decide on a diagnosis for which he would like to see refinements in the knowledge base in order to obtain better performance  e.g.. if the domain is rheumatology the user may decide to try to upgrade the system's performance in diagnosing systemic lupus. for the sake of brevity  we call this user-specified diagnosis the gdx for the current cycle of operation  where the  g  stands for  given   since this is a directive that the user must give the system. the next part of the cycle involves computing statistical properties concerning the rules of the knowledge base that conclude the gdx. plausible refinements are then generated by evaluating a set of heuristics similar to the one presented above for each of these rules  as well as any rule that becomes implicated via an intermediate hypothesis  see section ii.a above . 
   once seek has given its advice - we think of eacn piece of advice as a possible  experiment  to improve the knowledge base - the user will initiate an experimentation phase. this is a sub-cycle in which the user  interacting with seek  determines the exact effect of incorporating any one of the proposed experiments. the user will then decide which  if any  of these refinements should be accepted  and instructs seek accordingly. this ends the basic cycle  which can now be repeated starting with the modified knowledge base. this process continues until the user is satisfied with the overall performance evaluation. 
b. limitations 
   one of seek's limitations has already been mentioned: it does not have the capability to attempt to solve a refinement problem on its own. we discuss how seek1 removes this limitation in section iv.a below. 
   another important limitation of seek is that it does not work with a general production rule system  rather it expects that the domain knowledge base will be written in a form known as the criteria table representation. this mode of representation requires the knowledge engineer to specify a list of  major  observations and a list of  minor  observations for each possible  diagnostic  conclusion in the knowledge base. rules for reaching particular conclusions are then stated in terms of the number of majors and minors for the conclusion   requirements  and  exclusions.  the latter are additional observations or conclusions  or conjunctions of such  that are relevant to the diagnosis: a requirement is some condition that must be satisfied to reach the conclusion; an exclusion is some condition that  rules out  the conclusion. furthermore  any rule can reach its conclusion at one of only 
   
1 a. ginsberg et al. three possible confidence levels  viz. possible  probable  definite. as an example  assuming that a list of majors and minors for the conclusion systemic lupus has been specified  a rule for concluding the latter might state that if  at least  two of the majors and two of the minors are present then the conclusion is warranted at the  definite  level. 
   while this mode of representation has proven to be useful in the rheumatology domain  and other medical applications  it is in fact not as powerful a representation language as that of expert  or similar production rule systems  in the sense that one can write knowledge bases in general production rule languages that are not translatable into the criteria table format. however  any criteria table can be translated into production rule syntax. thus the set of criteria table knowledge bases is a proper subset of the set of production'rule knowledge bases. 
   seeks knowledge engineering knowledge  i.e.  its statistics and heuristics  was formulated with reference to the criteria table representation scheme  and criteria table concepts also were embedded in the control structure of the program. as a consequence  certain forms of rule refinement were not available or were restricted in seek  e.g.  changing a rule's confidence factor was limited to making  jumps  from one level to another  such as probable to possible. in general  seek could do very little with a knowledge base that was not written in a criteria table format. 
   seek1  on the other hand  is a refinement system that will work with any knowledge base written in expert's rule representation language. in designing seek1  we found it was possible to decouple seeks knowledge engineering concepts from the criteria table representation; we were able to apply many of these concepts in relation to features of more general types of production-rules. for example  criteria table rule-components using the notion of majors and minors are special cases of rule-components using choice-functions. decreasing or increasing the number of majors or minors required by a rule  is a special case of decreasing or increasing the choice-number of a choice-function. thus the example heuristic given above in section ii.b is a generalization in seek1 of two separate similar heuristics originally stated in seek  one for majors  one for minors. 
   in moving to a more general representation language as the target language for knowledge base refinement  we broadened the scope of the set of generic refinement operations available to the system. for example  confidence factors for generalization experiments may be increased based on an average of the highest-weighted  erroneous  conclusion for a set of misclassified cases. 
   from the programmer's point of view  seek's own know/edge base  the representation of its knowledge engineering statistics and heuristics  was strictly separate from its control structure. however  this was not the case from the point of view of the user  since there was no facility by which the user  qua user and not qua programmer  could access and modify seek's own knowledge base  in the way that a user can modify the domain knowledge base. our approach to this issue forms part of a broader project which we describe in section iv.b.1 below. 
iv seek1: an expert system for knowledge base refinement 
a. automatic pilot capability 
   unlike seek. seek1 is a system that can present plausible solutions to the overall refinement problem without the need for interaction with an expert. the output of seek1 running in automatic pilot mode is not a list of suggested rule refinements for a particular gdx   given  dx   rather it is a refined version of the entire knowledge base  i.e.  a set of rule refinements to the initial knowledge base which yield an improvement in overall performance. in this section we describe seek1's current automatic pilot capability. 
   the attempt to find a sequence of refinements that optimizes performance is a search problem. where there is a search problem of sufficient complexity  good heuristics must be found to guide the search. as we will see  seek1's current automatic pilot algorithm is a heuristic search algorithm  in the sense that it uses a classic  weak method   hill-climbing. 
   when running in automatic pilot mode seek1 makes three types of decisions that were previously made by the user of seek:  a  choice of gdx for the current cycle   b  which rule refinement experiments to try   c  which refinements to incorporate in the knowledge base given the results of the experiments  see figure iv-1 . additionally seek1 has to know when to stop. 
in the current implementation  seek1 orders the potential 
gdx's in descending order according to a simple measure on the number of  false negatives  and  false positives.  information that is given by the performance evaluation phase. potential rule refinement experiments for a gdx are ordered by simple measures on the statistics used in generating the refinement  eg.  if the generalization heuristic given in section ii.b fires  the quantity gen rule  -  speca rule  + 
specb rule   is used as an estimate of the expected net gain to be derived by performing the experiment 
   information of this sort could be used to limit the number of experiments performed in a cycle. however  in the current implementation  the information is used only to determine the order in which gdx's are chosen and experiments attempted; ultimately every potential gdx  for which perfect performance has not been obtained  is chosen  and every experiment suggested by the heuristics is performed. 
   
in other words  an automatic pilot cycle involves attempting  according to the ordering just given  every proposed refinement experiment for every potential final diagnostic conclusion in the knowledge base.  of course  the number of experiments generated by the heuristics represents a small fraction of the total number of logically admissible refinements.  out of all these experiments seek1  accepts  only one  the one that gives the greatest net gain in knowledge base performance fot all final diagnostic 
	a. ginsberg et al. 	1 
conclusions  not just for one gdx . an internal record of the accepted refinement is kept; and then the next automatic pilot cycle begins. if the current automatic pilot cycle is such that no attempted experiment leads to an actual net gain. seek1 stops. 
   we present a simplified example in order to illustrate the preceding remarks. let us suppose that we have a 
rheumatology knowledge base dealing only with the two final 

1 a. ginsberg et al. diagnoses systemic lupus and rheumatoid arthritis  that a data base of 1 cases is available  and that our human expert has diagnosed 1 of these cases as systemic lupus and the other 1 as rheumatoid arthritis. suppose that the initial performance evaluation computed by seek1 is as follows: 

   the measure seek1 uses to compute gdx order is the maximum of the false negatives and false positives. thus in our example systemic lupus would be the first diagnosis in the gdx ordering since it has 1 false negatives  i.e.  1 out of the 1 cases that should have been diagnosed as systemic lupus were not therefore seek1 will first generate refinement experiments for systemic lupus. 
	continuing 	the example  	suppose 	that 	rule 	r 	concludes 
systemic lupus  and seek1 finds that gen r  = 1  speca r  = 
1. specb r  = 1  and mfmc r  = choice-component c. these findings would satisfy the antecedent of the refinement heuristic presented in section ii.b. therefore seek1 will post the decreasing of c's choice-number as a refinement experiment seek1's estimate of the expected net gain of performing this experiment is given by gen r  -  speca r    specb r  + 1.  this is an estimate; the only way to know what the precise effect of decreasing the choice-number of c will be. is to decrease it  and then recompute the system's performance on the entire data base of cases.  once all the refinement experiments for systemic lupus have been posted and ordered according to their expected net gain  seek.1 performs all the experiments on this list as ordered. if seek1 finds that decreasing the choice-number of component c in rule r leads to an overall performance gain of 1 cases  i.e.  the  bottom line  performance total for both rheumatoid arthritis and systemic lupus improves from 1 to 1  and this turns out to be the maximum net gain of all the experiments for lupus  seek1 records this fact. 
   next  it will select rheumatoid arthritis as the g d x and repeat the process. suppose that the aforementioned experiment for rule r yields a greater net gain than the best refinement experiment for rheumatoid arthritis. then seek1 will  accept  the refinement to rule r  i.e.. it will modify its internal copy of the domain knowledge base to reflect this refinement  and a new cycle will commence. 
   the automatic pilot algorithm just described is a hillclimbing procedure: at each step seek.1 is guided totally by the  local  information as to which proposed refinement on the current knowledge base results in the best improvement  
i.e.  leads in the direction of  steepest ascent  when seek1 stops it is because a maximum has been reached. this may very well be only a local maximum. while a local maximum represents a  dead end  to the current seek1. we are experimenting with special statistics and heuristics that will  kick in  only when a dead end is reached  and which will hopefully allow the system to discover a better maximum if one exists. 
b. a metalanguage for representing 	meta-level knowledge 
1. metaknowledge in knowledge base refinement 
   it is clear from the examples in section ii.b that a refinement system requires metaknowledge of both the syntax and semantics of the  object  system's language  i.e.  the representation language of the domain knowledge base. for example  gen  mfmc  speca. and specb presuppose a working knowledge of what it is for a rule or a rule-component to be satisfied. other researchers have shown ways in which metaknowledge can aid in the general knowledge acquisition process  and in enhancing an expert system's performance . in this section we describe a metalanguage designed specifically for the refinement task. using this metalanguage one can define knowledge engineering concepts and heuristics  such as gen rule   as well as domain specific metaknowledge - e.g.  the fact that case findings x and y are incompatible in terms of a set of primitive concepts and operations. 
   one motivation for a metalanguage was alluded to in section iii.b  where we mentioned that seek's knowledge base of heuristics and statistics was inaccessible to the user of the system. the ability to easily access and modify this knowledge base is quite desirable for designing and experimenting with refinement concepts. for example  some of the current statistics for seek1 are not likely to be as useful with respect to an expert system that employs a scoring scheme for combining confidence factors. useful variants of these statistics could be defined within the same metalanguage that we have developed for seek1 
   in general  even within one expert system framework  different styles of knowledge bases are possible; it is likely therefore that different styles of refinement will be needed. for example  some knowledge bases employ a taxonomic ordering of hypotheses. such an ordering provides knowledge that could be used  together with appropriate control heuristics  to formulate a more efficient version of seek1's automatic pilot algorithm. a knowledge base refinement metalanguage will allow for the representation of such control heuristics  see figure iv-1 . a refinement metalanguage will allow the expert or knowledge engineer to represent the knowledge that a certain component in a rule should not be altered under any circumstances  or that if a change to component x is made  component y must be changed as well  or that additions to any rule with conclusion c should be drawn from a specified list of components  etc. it will also 
   
allow for the definition of special-purpose statistics that may be of use in suggesting plausible rule refinements  e.g.  the frequency of occurrence of a certain combination of findings in a specified subset of cases. 
1. defining statistics in seek1's metalanguage 
   seek1's statistical concepts can be specified in a settheoretic metalanguage that employs only a small number of refinement primitives together with some appropriate notions from simple set theory  arithmetic  and logic. using these primitives it is possible to experiment with variations on seek1's statistics and define domain specific statistics as well. 
a set-theoretic definition of concepts such as gen rule  
 see section ll.b  requires refinement primitives of the following sorts. some primitive variables are needed to provide the system or a user with the ability to  access  various  objects  in the domain knowledge base and the data base of cases. for example  rule is a variable whose range is the set of rules in the domain knowledge base  case is a variable whose range is the set of cases in the data base of cases  and dx is a variable whose range is the set of possible final diagnostic conclusions in the knowledge base. in addition some primitive functions are needed to allow one to refer to selected parts or aspects of a rule or a case  e.g.  rulecf rule  is a function whose value is the confidence factor associated with rule  pdx case  is a function whose value is the expert's conclusion in case   pdx  stands for  physician's diagnosis    and cdx case  is a function whose value is the conclusion reached for the current knowledge base in case   cdx  stands for  computer's diagnosis  . as an example of the way in which these primitives can be used  note that using the notions of pdx case  and cdxicase  one may define a misdiagnosed case as any case for which  dx case  ¡Ù cdx case . 
   certain special sets of objects are of importance in the knowledge base refinement process  and it is therefore useful to have primitives that refer to them  e.g.  rules-for dx  is a function whose value is the set of rules that have dx as their conclusion. finally various primitives that in some way involve semantic properties of rules  or the performance characteristics of the knowledge base as a whole are useful  e.g.. satisfied rule-component  case  is a predicate that is true iff rule-component is satisfied by the findings in case  and false otherwise  and modelcf dx  case  is a function whose value is the system's confidence factor accorded to dx in case. 
   seek1's refinement knowledge base was designed using the metalanguage we have just outlined . implementation was achieved by incorporating the aforementioned primitives as procedures and functions  and then coding  by hand  highlevel set-theoretic definitions as efficient procedural forms employing these primitives. currently we are experimenting 
	a. ginsberg et al. 	1 
with a system in which the primitives described above  and others  are available to the user and can be combined to form expressions designating sets  variables  and functions of interest to the user. 
v discussion 
   seek1 currently has ten statistical concepts and nine heuristics for generating refinements. working in automatic pilot mode on a rheumatology knowledge base of approximately 1 rules with 1 final diagnostic categories  and using a data base of 1 cases. seek1 was able to increase the overall performance of the system from a value of 1%  1  to a value of 1%  1 . it used approximately 1 minutes of vax-1 cpu time. the total number of experiments tried was 1. out of which 1 were accepted.*** 
   in evaluating the usefulness of seek1's automatic pilot capability it is important to keep in mind that the expert is still the final judge. despite the assured gain in performance with respect to the given data base of cases  and the reasonable expectation of performance enhancement with respect to new cases  the expert may agree with only a subset of the total number of refinements suggested by seek1****. the measure of seek1's usefulness is not  however  simply how many of its experiments the expert accepts; even rejected experiments have value: they point out areas of the knowledge base that need to be examined if enhanced performance is to be achieved. 
   validity and consistency are important goals in developing expert systems. yet the design of these systems is often lacking in a coherent formal approach for achieving these goals. the approach to knowledge base refinement described here can lead to a more solid foundation for designing and validating expert system knowledge bases. 
vi acknowledgments 
   we would like to thank casimir kulikowski for his helpful suggestions concerning this work  and kevin kern for programming assistance. 
¡¡***the system has not yet been tested on alternative knowledge bases. 
¡¡****the incorporation of domain-specific metaknowledge in seek1 might enable the system itself to sometimes reject a refinement that in some way violates the expert's understanding of the domain  even though it may improve performance. 
1 	a. ginsberg et al. 
