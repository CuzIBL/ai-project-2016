the stanford hand-eye project 
by 
j.a. feldman  g.m. feldman  g. falk  g. grape  j. pearlman  i. sobel  j.m. tenebaum 
computer science department 
stanford university 
stanford  california 

     there is a large continuing project at stanford a r t i f i c i a l intelligence laboratory aimed to-
wards the development of a system capable of i n teresting perceptual-motor behavior. this paper presents a brief outline of the currently active efforts and suggests references for more detailed information. a more thorough discussion of the effort to organize a visual perception system is presented. 
acknowledgement 
　　　the work reported here depends on efforts by many people besides the authors and is supported in part by the advanced projects agency of the department of defense under contract sd-i1. 
	1. 	an overview 
　　　the work on integrated  robots   though widely discussed  is s t i l l poorly understood even within the a r t i f i c i a l intelligence community. like 
any large research and development effort  a robot project is d i f f i c u l t to describe in a way which is comprehensive but not superficial. 
　　　in this paper we w i l l attempt to provide an overview of our current goals and approaches to achieving them. these are a number of detailed papers on various aspects of the stanford effort 
which are referred to here  including several works in progress. these latter are included because they should be available from their authors considerably in advance of their formal publication. 
　　　the overall goal of the hand-eye project is to design and implement a system which exhibits interesting perceptual-motor behavior. an important subgoal is that the problems that arise in the design of system components be solved in ways 
which are sufficiently general to be scientifically interesting. thus  for example  we have put 
considerable effort into understanding depth perception although the special environment we are using allows for ad hoc solutions. the possible applications of our work and its relevance to the study of animal behavior have been secondary areas of interest. 
　　　our f i r s t hand-eye system used many ad hoc solutions and was mainly concerned with the problems of combining the minimum necessary hardware 
and software components. this primitive  but complete system for block-stacking under visual control was completed in may i1  and has been described elsewhere . the functional diagram of figure 1 provides a sufficient description for our purposes. 	our most recent work has involved the redesign of the system configuration and 
more careful study of each of the component programs . 
　　　our attempt to develop an integrated handeye system has forced us to confront several ai problems which had received l i t t l e previous attention. the two causes underlying the new problems are the complexity of the desired behavior and the innate perversity of inanimate objects. pattern recognition  problem solving  modeling  etc. which have been studied in idealized contexts take on new aspects in the hand-eye system. the most striking result to date is that traditional approaches to these problems have not proved adequate. we are not yet in a position to make definitive statements on what is needed  but a com-
mon understanding of the issues is arising among robot builders. nilsson's paper in this volume 1  contains a good discussion of the general situation. 
     the main principle which has emerged from the stanford work is the dependence of everything on everything. for example  one might use entirely different perceptual strategies with a ran-
dom access  image dissector  camera than with a scanning  vidicon  device. this inseparability contributes to high entrance cost of hand-eye research; there i s   as yet  no way to experiment 
with a part of the program without detailed knowledge of the other parts. 
　　　much of our effort has gone towards reconciling this mutual interdependence of programs with the inherent independence of programmers. the problem is exacerbated at a university by the need of graduate students to produce clearly separable contributions to the project. 
　　　these facts  plus the availability of systemsoriented students  encouraged us to undertake a rather ambitious system-programming project i n cluding a submonitor  a high-level language  and a new data structure. 	the goal of this project is to produce a hand-eye laboratory in which it 
w i l l be relatively easy to experiment with new ideas in perception  modeling  problem-solving and control. this laboratory w i l l also  hopefully  provide a testing ground for many related 
a r t i f i c i a l intelligence projects currently underway; section 1 contains a discussion of some of these. 
the hand-eye laboratory w i l l have to accomo-
-1-

date programs whose total size is several times the size of core memory. further  as we w i l l show in section 1  the order in which these programs are executed cannot be determined in advance. these programs must be able to communicate with each other and with a common global model which represents the system's knowledge of the world. since many operations require moving physical devices  like the arm and camera  which entail long delays  we would like to allow parallel execution of hand-eye subprograms. a l l of these requirements can be met by the addition of one basic feature  the pseudo-teletype  to the pdp-1 time-sharing 
monitor. a pseudo-teletype is simply a buffer set up by one job which acts as the control console of another job. subprograms are each set up as a separate job; a l l active  jobs w i l l be automatically time-shared by the main monitor. the submonitor is responsible for handling messages  some interrupts and changes to the global model and w i l l also 
be able to record i t s actions as an aid to debugging the system. 
　　　the language and data-structure designs are closely tied to the submonitor and to each other. the language is an extension of our algol compiler 
 along the lines of the associative language  leap   1   . the central concept of leap and the underlying data structure is the association: attribute   object = value. the use of associations for world-modeling is described in detail in . an important new concept in this version of leap is the use of local and global associative structures. every atomic object  item  is either local or global; the associative structure local to a subprogram may contain associations including global items  but not vice-versa. any attempt to a l ter the global associative structure is trapped to the submonitor which determines when the alter-
ation should be allowed. 	the language contains primitives for local and global associations  message handling and interrupt processing. 	preliminary versions of the submonitor  language  and data-structure are currently in operation and seem to be providing the desired increase in programming 
ease. 
　　　work on the hand-eye problem proper has continued in paralled with the system development. much of this work has been directed toward the development of a flexible set of vision programs  the subject of section 1 of this paper. to pro-
vide a sense of direction and to bound our aspirations  we proposed a class of tasks which we hope to have the hand-eye perform. the main task is the 
building of f a i r l y complex constructions  castles  out of simple blocks. the blocks were restricted to being plane-bounded and convex. the castle 
might be e x p l i c i t l y described by a set of associations relating i t s sub-parts or we might simply be given one or more views of i t . even this task is too d i f f i c u l t for the system to solve in gene r a l   but it has provided a useful context for the development of various routines. 
　　　building a castle out of children's blocks is a problem in which there is no technical literature. shapiro  has concerned himself with the development of optimal strategies for doing this with our mechanical hand which can only place a block 
with l/k inch accuracy. 	the f i r s t problems 
attacked were the development of heuristics for stability analysis and for generating the proper sequence of actions assuming ideal placement. subsequent work w i l l remove this restriction and attempt to develop strategies which compensate for observed imperfections in the performance of the 
mechanical manipulator. one of the most interesting aspects of this task is the various levels of feedback which can be used in the building process. in some cases  one need only know that a block is s t i l l in place and tactile feedback is sufficient. if the situation is more c r i t i c a l one might visually determine the placement error and alter the remainder of the strategy according-
ly. finally  there is the possibility of adjusting the block  under visual control u n t i l the error is sufficiently small . an important part of the castle building problem has been solved by pieper   1  in his development of an obstacle avoidance program for the arm. 
　　　the use of visual feedback in block stacking presents a rather different problem than those normally discussed in picture processing. the vision routine has the job of determining the accuracy with which some block was placed. the total scene may be very complicated and it would 
be absurd to perform a complete scene analysis. furthermore  the properties of the blocks to be examined may be known in great detail and the vision routine would be able to take advantage of this fact. one of our major efforts has 
been directed toward solving these problems of context-sensitive visual perception. the overall system designed to do this is quite complex and is the subject of the next section. 
1. the organization of a visual perception system 
　　　perception  and most particularly visual perception  is a complex process requiring a system which is sensitive to a l l the various levels of detail of the environment. furthermore  since the available data is potentially overwhelming  consider the number of different viewpoints  the system must have both the mechanisms and 
appropriate strategies to select what data are 
worthy of its attention and what level of detail is best suited to the current perceptual goal. 
　　　we w i l l concentrate on these two aspects of visual perception - levels of detail and strategies for attention. data from a scene may be structured to varying degrees. at the lowest level lie the intensity and color of the light 
at a particular point in the visual f i e l d ; at a higher level are those objects in the visual scene which we dignify by the use of nouns; at a s t i l l higher level one notices interrelationships and relative motion between objects. at the highest level one is aware of the total s i t -
uation - as  danger! collision imminent.  each of these levels of perception is necessary and we 
must integrate a l l of them. ordinarily  we are conscious only of our perceptions of objects and 

-1-

situations  but the fact that we can learn to draw indicates that lower level details are perceived and can be made accessible to consciousness. 
     it is curious that we must learn to draw as if the lower levels of visual patterns are coalesced into objects at a preconscious level. this notion gives rise to a simplified theory of perception held by many workers in perception and pattern recognition. the theory is embodied in a strategy of perception which places attention f i r s t at the lowest level of detail and then extracts successively higher levels u n t i l the organization of the entire scene is understood. thus  by processing intensity and color d i s t r i butions one obtains texture  edges  and corners. from this information regions are extracted and these in turn are associated into bodies. then the bodies are identified as objects and their various interrelationships are derived. thus: points -  lines -  regions -  bodies -  objects -  scene 
     essentially  a l l the early work on visual perception  including our own  proceeded along these lines. to some extent  the beautiful work of guzman  ＜n finding the distinct bodies in a perfect line drawing had an undesirable effect on the f i e l d . guzman's program was so successful that it sent people on a quest for the perfect line drawing program. although we have had 
considerable success  1  at generating linedrawings  it has become apparent that the s t r i c t bottom-to-top processing sequence is not optimal. we w i l l present some general discussion on the organization of vision systems and then describe our current efforts. 
     the model of vision which we fine useful i n volves routines at various levels  cooperating in an attempt to understand a scene. there is a large body of psychological evidence  1  i n -
dicating the dependence of perception upon global information and upon preconceived ideas. 	many of the well known optical illusions f a l l in this class. 	one can also show that there are simple scenes which are ambiguous in the absence of global information  but are easily resolved in context. 
     a most striking case of this is the ground plane assumption   which has become a cornerstone of a l l robot perceptual systems. from a 
monocular image it is impossible  in general to calculate the distance of an object from the camera. i f   however  the object is lying on a known plane  one whose transformation to image coordinates is available  then the depth of the object1 s base vertices is known. this particular piece of global information has been i m p l i c i t l y used for depth information  but has many other uses. 
consider the following line drawing. 

　　　if one knew that this object were lying on the plane determined by abc which was known  then one would know the projection of each point in the image onto the abc plane. each point e.g. f must be on the line determined by its projection onto the abc plane and the lens center. if the line af is perpendicular to the plane we then 
know the length of af. 
　　　further  we can often determine whether or not af is perpendicular to the plane from the information available. the lens center  point a 
and the projection of point f determine a plane  
which contains the line af. if this plane is perpendicular to abc then the line af is also  for objects which are at a l l regular . if one knew the lengths of af  bg  and cd and their angles with the abc plane  then the coordinates of f  g  and d are computable and assuming f  g  
d and e are in a plane is sufficient to determine e. thus the ground plane assumptions plus some global regularity conditions allow for the complete description of an object from a single 
monocular view. of course  these conditions may not hold  but falk has some encouraging results in object recognition using these kinds of techniques . 
　　　a somewhat more basic problem arises in the consideration of the following image: 


　　　the interior edges might very well be less distinct and be missed by the program which f i r s t tried to form a line drawing. at some higher perceptual level  a program could detect the ambiguity and attempt to find the interior edges. with the contextual information available  the 

system could then use highly specialized tests to determine the presence of an edge. further  since the area involved is relatively small  it might a l so be reasonable to apply very sensitive operations 
which are too costly to use on an entire scene. in both cases we see how our system organization facilitates a perceptual strategy involving selective attention. a vision system which worked s t r i c t l y bottom-to-top would have no notion of attention. there would be a standard line finding op-
eration  followed by an attempt to f i t intersections  etc. these are inherent limitations  in any such system balancing noise sensitivity with a b i l i t y to perceive d e t a i l . the flexible organization discussed here allows for the use of different hardware and software components in different contexts and has much greater potential. 
　　　those readers unfamiliar with the field w i l l probably feel that we have set up an elaborate straw man. cognoscenti w i l l recognize the man as real enough  but w i l l be looking for a way to 
make our grand design operational. the remainder of this section w i l l be devoted to a discussion of how we are attempting to do t h i s . 
　　　the goal  once again  is to produce a flexible visual perception system capable of selective attention and of integrating information from a l l levels of perception. an obvious prerequisite for such a system is a monitor  language  and data structure capable of i t s support. our proposed design was described in section 1. 
　　　a second necessary ingredient of any such system is a large set of flexible basic vision routines. among the necessary functions are: reading raw data  changing the camera position and parameters  edge finding  corner f i t t i n g   region finding  analysis into distinct bodies  i d e n t i f i -
cation of particular objects  and complete scene analysis. work is under way in a l l these areas but we w i l l be content to describe briefly some of the work which seems to be most interesting. 
　　　one important aspect of the general vision system is accomodation  the adaptation of the i n put mechanisms to the visual environment. 	selective attention can then be implemented in the 
vision hardware by choosing accomodative strategies which reflect current perceptual goals. for example  the camera could be sensitized to a specific color characteristic of a desired object  via a color f i l t e r   . this effects a gross reduction in the volume of information which must be input and subsequently searched to determine 
i t s relevance. 
　　　the camera parameters currently under computer control are the pan and t i l t angles  focus  magnification and d i g i t i z a t i o n level. there are two 
hard problems in accomodation which arise from the need for a common world model. when the camera is panned  it gets a new view. the images of objects in this new view must be placed in correspondence with the old images of the same objects. an even more d i f f i c u l t problem is to compute accurately the perspective transformation  applicable 
in the new situation. sobel  has developed techniques for these problems  relying heavily on the literature of photogrammetry. 
　　　a major area of interest at stanford has been the development of low-level edge and line finders the visual system of the original system was l i t tle more than a good edge follower pus a routine 
which used the ground plane assumption and the existance of only cubes to locate objects. there have been extensive analytical and practical studies of various spatial f i l t e r i n g and edge finding techniques   1   1 . more recently  we have begun to look at feature verifiers which w i l l use global information and a prediction to help ident i f y a feature. 
　　　there are also programs which do f a i r l y well at corner finding  region extraction  etc. these are f a i r l y flexible and might be incorporated i n to a vision system organized as we have suggested. the real problem is to develop routines for these tasks which are sensitive to possible errors and ambiguities and know when to ask for help. a related issue is the language for communicating 
between vision programs at various levels. we have just begun to seriously confront these issues 
　　　we are currently completing an interactive version of our grandiose vision scheme. grape is extending his programs  to allow for user intervention at several stages in the scene analysis process. as intermediate stages of analysis are displayed  the user w i l l be able to interrupt and add information to the system. using this system and some hard thought  we hope to come up 
with a reasonable f i r s t cut at the multi-level vision system. the process of refining this system and adding to its basic capabilities w i l l   like the poor  always be with us. 
1. related work in a r t i f i c i a l intelligence at stanford 
　　　the robot problem  in some sense  encompasses the entire field of a r t i f i c i a l intelligence there is nothing in a r t i f i c i a l intelligence work which would not be useful in the ultimate robot. the precise degree to which various other efforts should be coordinated with a robot project is unclear. traditionally  for the past three years   the m.i.t. group has kept quite s t r i c t l y to handeye problems which the s.r.i  group has concentrated on combining as much of i t s work as possi b l e . the stanford group is somewhere between there are a large number of a r t i f i c i a l i n t e l l i -
gence projects at varying distances from the hand-eye e f f o r t . 
　　　one closely related development is concerned with improvements in the devices used for the mechanical hand and eye. the research or  vision devices has been largely analytical  but consideration is being given to building a laser system which w i l l directly produce a three-dimensional image. the work on arms and hands is con-
ducted largely by the mechanical engineering department and has been rather more active. 	this 

-1-

effort has produced one dissertation   two complete arm systems  and a variety of proposals for others . in the visual perception area  there are attempts to solve such problems as face 
and person recognition. there is also a s i g n i f i cant effort underway to operate a motorized cart under computer control. the cart and its sensing devices are operational and the programming for this task has begun. although the cart project 
w i l l use some of the vision routines developed in the hand-eye e f f o r t   i t s goals are quite different. the main problems being attacked in the cart project are vision from a moving object and the related problems of control. this project is expected to grow considerably in the near future. 
　　　the most relevant of the many theoretical efforts is the work on the use of automatic theorem proving methods as a technique for building strategies . some such mechanisms w i l l eventually be part of the hand-eye system and there 
are efforts to axiomitize some hand-eye tasks. however  there are very d i f f i c u l t theoretical and practical problems to be solved before a theorem prover w i l l be able to develop strategies as flexible as the one for castle building described in section 1. 
　　　the work on systems programming discussed b r i e f l y in section 1  contains a number of interesting problems in its own right. the use of many parallel programs operating on a single global data structure is a problem of considerable current interest. even more intriguing is the possi b i l i t y of problem-directed resource allocation. the control program for a particular hand-eye task w i l l attempt to choose an optimal sequence of 
vision  manipulation and computation routines for achieving i t s goal. it seems reasonable that such a control program could allocate resources  core  processor  etc.  better than a blind scheduling algorithm; we are designing the system to allow for experimentation along these lines. 
　　　certainly one would like the ultimate robot to communicate with people in natural language. there is a large effort under colby  to develop models of human belief structures and programs which can construct these belief structures from natural language statements. another important continuing effort is that of reddy  1  1i  on speech recognition. this work has been quite successful and has actually been combined with the original hand-eye system in a demonstration program. much more elaborate natural language com-
munication systems for hand-eye could be produced if there were a scientific advantage to be gained. 
　　　one project in natural language processing which seems particularly relevant is that of becker   1 . he is developing a model of human cognitive structure which attempts to encompass both perceptual and verbal behaviour. currently in i t s early stages of development  this model may become a serious contender for the basis of the general problem solver in the next generation robot. 
　　　as these projects and the hand-eye system develop  we expect them to have an increasing effect on one another. the remaining problems are immense  but the entire approach seems more sound and realistic than was the case a few years 
back. 
