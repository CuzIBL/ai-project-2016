constrainft satisfaction 
constraint satisfaction 1: sat 

p r o p 1 let t be a constant  the last prop predicate is named and is defined to be the first of the three predicates 	 in this order  which has at least t variables in its denotational semantics. 
each prop predicate results in a dpl procedure  
giv-
ing satij. these programs are different only in prop predicate  except satq which need not count the occurrences of variables. 
　we run the 1 programs  compiled using gcc with optimization  on a pc with a 1 mhz pentium cpu under linux operating system on a very large sample of random 1-sat problems generated by using the method of mitchell et al. mitchell et a/.  1 . given a set v of n 
boolean variables we randomly generate 
m clauses of length 1. each clause is produced by randomly choosing 1 variables from v and negating each with probability 1. empirically  when the ratio m/n is near 1 for a 1-sat formula f  f is unsatisfiable with a probability 1 and is the most difficult to solve. we vary n from 1 variables to 1 variables incrementing by 1  for each n the ratio clauses-to-variables  m/n  is set to 1  1  1  1  1  1  1. at each ratio and by each program  if n   1 then 1 problems are solved  if 1  1 then 1 problems are solved  if n = 1 then 1 problems are solved  and if n = 1 then 1 problems are solved. a problem is solved successively by all the 1 dpl procedures before another to ensure the same environment to all programs. due to the lack of space  we only present the experimental results for the ratio m/n = 1 in figures 1  1  and 1  where the dpl procedures corresponding to the curves are listed in the same order from top to bottom. the experimental results on the other ratios give exactly the same conclusions. 
1 a pure up heuristic versus a pure mom's heuristics: sato vs sata 
sato systematically examines all the variables by unit propagation at all nodes  using a pure up heuristic  while sata does not examine any variable so and employs a pure mom's heuristic. one might believe that sato would be simply too slow  but it is not the case. sato is much faster than sata. in fact from figures 1 and 1  all dpl procedures using a up heuristic in our experimentation are substantially better than sata in terms of search tree size and real run time. 
　note that mom's heuristic used in sata is similar to the so-called two-sided jeroslow-wang rule  hooker and vinay  1   with the only difference that a clause of length i is counted as 1 clauses of length i+1 instead of 1. our experiments suggest that 1 is better than 1. 1 is 
1 	constraint satisfaction 
also similar to the exponential factors in c-sat  dubois et a/.  1  where 1 ternary clauses are counted as 1 binary clause. 

figure 1: mean search tree size of each program as a function of n for hard random 1-sat problems at the ratio m/n = 1 

figure 1: mean run time of each program as a function of n for hard random 1-sat problems at the ratio m/n = 1 
　sato actually is slower than five other programs based on balanced restrictions of variables to be examined by unit propagation  but not substantially so  except satz . the surprisingly good performance of sato confirms the power of up heuristics for selecting the next branching variable and suggests that its effect for detecting failed literals is only secondary. 
1 	restricted up heuristics 
figure 1 illustrates the number of variables examined by different restricted up heuristics at a node. 

figure 1: average number of variables examined at a search tree node in a given depth when solving hard random 1-sat problems of 1 variables and 1 clauses  1 problems are solved  for 1 programs 
1 restriction by total number of binary occurrences of a variable 
four programs  realize this type of restrictions. while a classical mom's heuristic selects the next branching variable having maximum binary occurrences  the restricted up heuristics examine a set of variables having more binary occurrences than others  including the variable having maximum binary occurrences. from figure 1  it is clear that the more variables are examined  the smaller the search tree size is. 
1 balanced restriction by total number of binary occurrences of a variable 
four programs realize this type of restrictions. the prop predicates require that a variable occurs both positively and negatively in binary clauses to balance the search tree. we compare the 
duet 	and observe that 
examines strictly fewer variables than and is faster than it in spite of a slightly larger search tree. in particular   examine almost the same number of variables  see figure 1   but the balanced restriction gives a faster dpl procedure. 
　we pay special attention to since they seem to be the best balanced restrictions. 
1 dynamic restriction as a function of search tree depth 
sat1 realizes this restriction. a general observation when solving 1-sat problems using a dpl procedure is that there are more and more binary clauses when descending from the search tree root and the denotational semantics of a prop predicate such as prop 1 becomes larger and larger. furthermore  the nodes are more numerous near the leaves and the branching variables play a less important role there. it appeared that one could restrict more the variables to be examined by unit propagation near the leaves without important loss on the search tree size so as to obtain some gain in terms of real run time. 
　posit's up heuristic  called bcp-based heuristic   freeman  1  realizes this idea: under the level 1 of a search tree  at most 1 variables are examined by unit propagation. 
　uses from the top of a search tree  but under the depth empirically fixed to it uses prop1  where n is the number of variables in the initial input 1-sat problem. note that if 
1  so sat1 generally strengthens the restriction later than posit. 
　from figures 1 and 1 sat1 is not better than sat1  although it makes many fewer unit propagations to examine variables  see figure 1   suggesting that the search tree depth is rather irrelevant to the restriction of up heuristics. 
1 dynamic restriction by number of variables to be examined 
the relatively poor performance of sat1 seems due to the small number of variables examined at each node  see figure 1   though these variables have many binary occurrences. a careful analysis shows that even sat1   the best one up to now  examines few or no variables at some nodes  especially near the root where there are few binary clauses  although these nodes are more determinant for the final search tree size. propz is then introduced to ensure that at least t variables are examined at each node  t being empirically fixed to 1. near the root  all free variables are examined to exploit the full power of up heuristic. as soon as the number of variables occurring both negatively and positively in binary clauses and having at least 1  1  binary occurrences is larger than t  only these variables are examined to select the next branching variable. 
1 	related work 
c-sat  dubois et al.  1  examines some variables by unit propagations  called local processing  near the bottom of a search tree to rapidly detect failed literals there. pretolani also uses a similar approach  called pruning method  based on hypergraphs in h1r  pretolani  1 . but the local processing and the pruning method as are respectively presented in  dubois et al.  1  and  pretolani  1  do not contribute to the heuristic to select the next branching variable. we find the first effective exploitation of up heuristic in posit  freeman  1  
	li & anbulagan 	1 
and tableau  crawford and auton  1  which use a similar idea as in c-sat to determine the variables to be examined at a node by unit propagation: x is to be examined iff x is among the k most weighted variables by a mom's heuristic. 
   the main difference of satz with tableau and posit is that satz does not specify a upper bound k of the number of variables to be examined at a node by unit propagation. instead  satz specifies a lower bound. in fact  satz examines many more variables by an optimal combination of unit propagation and mom's heuristics. 
   given the depth of a node  table 1 illustrates the average number of variables examined  #examined vars  at the node by satz  with the depth of the root being 1. in order to compare with c-sat  tableau and posit we also give the theoretical value of kc  for c-sat   kt  for tableau  and kp  for posit  at the node  respectively according to the definitions of k in  dubois et al.  1; crawford and auton  1; freeman  1 . 

table 1: average number of variables examined in satz at a node in a given depth when solving a hard random 1sat problem of 1 variables and 1 clauses  1 problems are solved  compared with theoretical value of k in c-sat  
tableau and posit 
　it is clear that satz examines many more variables at each node than any of c-sat  tableau or posit. near the root  satz examines all free variables. elsewhere satz examines a sufficient number  t  of variables. 
　we compare c-sat  tableau  posit and satz on a large sample of hard random 1-sat problems on a sun sparc 1 workstation with a 1 mhz cpu. the 1-sat problems are generated from 1 sets of n variables and m clauses at the ratio rn/n = 1  n steping from 1 variables to 1 variables by 1. 
　we use an executable of c-sat dated july 1. the version of tableau used here is called stab and is the same used for the experimentation presented in  crawford and auton  1 . posit is compiled using the pro-
1 	constraint satisfaction 
vided make command on the sun sparc 1 workstation from the sources named posit-1.tar.gz1. table 1 shows the performances of the 1 dpl procedures on problems of 1  1  and 1 variables  where time standing for the real mean run time is reported by the unix command /usr/bin/time and t size standing for search tree size  number of nodes  is reported  or computed from number of branches reported  by the dpl procedures. 

table 1: mean run time  in second  and mean search tree size of c-sat  tableau  posit and satz on ratio m/n=1 
　table 1 shows that satz is faster than the above cited versions of c-sat  tableau and posit  satz's search tree size is the smallest  and satz''s run time and search tree size grow more slowly. table 1 shows the gain of satz compared with the cited version of c-sat  tableau and posit at the ratio m/n=1. each item is computed from table 1 using the following equation: 

where value is real mean run time or real mean search tree size and system is c-sat  tableau or posit. from table 1  it is clear that the gain of satz grows with the size of the input formula. 

table 1: the gain of satz vs. c-sat  tableau and posit in terms of run time and search tree size on the ratio m/n=1 computed from table 1 
   the central strategy of satz is to try to reach an empty clause as early as possible. further along the line  we make two relatively small resolvents-driven improvements in satz. the first improvement is the preprocessing of the input formula by adding some resolvents of length  1  the second improvement consists in refining yet more the heuristic h in the nodes where all free variables are examined by unit propagation. refer to figure 1  when p r o p z is equal to propo we define w x  as the number of resolvents the newly produced binary clauses would result in in f' by a single step of resolution.  is similarly defined. 

　satz improved in this way solves many real-world or structured sat problems where previous heuristics were not successful. for example  table 1 shows the performance of the 1 dpl procedures on the well-known bei-
jing challenging problems1  where a problem that can not be solved in less than 1 hours is marked by    1  and the version of tableau is called ntab1. it is clear that satz is much more efficient and solves many more problems in less than two hours. 

table 1: run time  in sec.  of beijing challenging problems 
1 	conclusion 
we found that up heuristic is substantially better than 
mom's one even in its pure form realized by propo where all free variables are examined at all nodes. in its restricted forms based on combinations of unit propagation and mom's heuristics  the more variables are examined  the smaller the search tree is  confirming the advantages of up heuristic  but too many unit propagations slow the execution. the combinations realized by p r o p 1 and prop1 represent good compromises. 
　a dynamic restriction such as prop1 which strengthens the restriction under a fixed depth of a search tree fails to work better than the static restriction prop1. we design the dynamic restriction along another line: propz ensures that at least t candidates are examined by unit propagation at every node of a search tree by successively using prop1  prop1 and propo  giving the very efficient and very simple dpl procedure called satz. 
　satz is favorably compared with several current stateof-the-art dpl implementations  c-sat  tableau and posit  on a large sample of hard random 1-sat problems and the recent beijing sat benchmarks. the good performance of satz on the structured or real-world sat problems shows that up heuristic can tackle new problems or problem domains where mom's heuristics were not successful and enhances the belief that if a dpl procedure is efficient for random sat problems  it should be also efficient for a lot of structured ones. 
acknowledgments 
we thank olivier dubois  james m. crawford and jon w. freeman for kindly providing us their dpl procedures and anonymous referees for their comments which helped improve this paper. 
