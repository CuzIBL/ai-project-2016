 
when autonomous agents attempt to coordinate action  it is often necessary that they reach some kind of consensus. reaching consensus has traditionally been dealt with in the distributed artificial intelligence literature via negotiation. another alternative is to have agents use a voting mechanism; each agent expresses its preferences  and a group choice mechanism is used to select the result. some choice mechanisms are better than others  and ideally we would like one that cannot  be manipulated by untruthful agents. 
coordination of actions by a group of agents corresponds to a group planning process. we here introduce a new multi-agent planning technique  that makes use of a dynamic  iterative search procedure. through a process of group constraint aggregation  agents incrementally construct a plan that brings the group to a state maximizing social welfare. at each step  agents vote about the next joint action in the group plan  i.e.  what the next transition state will be in the emerging plan  using this technique agents need not fully reveal their preferences  and the set of alternative final states need not be generated in advance of a vote. with a minor variation  the entire procedure can be made resistant to untruthful agents. 
1 	introduction 
 the field of distributed artificial intelligence  dai  is concerned with coordinated  efficient activity by groups of autonomous agents. activity in multi-agent worlds often requires agreement by the agents as to how they will act  and the reaching of consensus is a major con cern of dai. the formation of multi-agent plans has been approached in several different ways: through the use of synchronization techniques  ceorgeff  1j  such as those used in operating systems  through the distribution of single-agent planners  corkill  1   such as noah  and through centralized planners that ensure coordination  rosenschein  1 . 
   in this paper  we present a new approach to deriving multi-agent plans. we consider how agents could reach consensus using a voting procedure  without having to reveal full goals and preferences  unless that is actually necessary for consensus to be reached . our technique also does away with the need to generate final alternatives ahead of time  instead  candidate states arise at each step as a natural consequence of the emerging plan . the agents iteratively converge to a plan that brings the group to a state maximizing social welfare. 
1 	the scenario 
our scenario involves a group of n agents operating in a world currently in the state so. each agent has its own private goal. since all agents operate in the same environment and may share resources  it is desirable that they agree on a joint plan for the group that will transform the world to an agreed-upon final state. 
   each agent is assumed to have a value  a worth  that it associates with states that satisfy its goal. this worth can be used to assign a utility to any state  goal or not  that is reached by a particular plan  the techniques for doing this assignment are discussed below . 
   given the existence of such a worth function  we want to give the agents a method for choosing a group plan. the agents will all participate in the choice process  as well as in carrying out the resulting multi-agent plan. the group plan should then result in a compromise state that is in consensus.1 
1 	a n e x a m p l e 
consider a simple scenario in the slotted blocks world. there are four slots  a b c d   five blocks  1 1 1   and the world is described by the relations: on obj1 obj1 ---obj  is stacked onto obj1  clear  obj  there is no object on obj; and 
at obj slot --obj is located at slot. the function loc obj  returns the location  slot  of obj. slots themselves function as  stationary  objects  e.g.  block 1 in slot 1 could be described by on 1 b  . 

   *this research was partially supported by the israeli ministry of science and technology  grant 1  
l
　　the decision procedure  to be presented below  may also serve in a single-agent planning scenario  where an agent is trying to integrate a group of disparate goals. 


	1 	distributed al 

	1 	constraints 
there are several important aspects of  and requirements for  the procedure above to succeed  which we discuss in this section. figure 1 shows three simple scenarios in the 
slotted blocks world that will help us explain the issues involved. in these examples  two agents can achieve a consensus state that fully satisfies both agents' goals. there are three slots  and several blocks in each world. 
only the move operator is available  and it costs 1 under all circumstances. 1.1 aggregation of functional constraints the generation of consensus sets of constraints is based on the aggregation of the individual sets of con-
straints. as the third example in figure 1 shows  this is not always trivial. here  there is a ceiling that makes it impossible for more than two blocks to be stacked. this 
figure 1: three scenarios in the slotted blocks world time a1's goal is  1 1  while g1 - a 1  1 . we assume that the function h b  returns the height  in number of blocks  at slot b. as in all our scenarios  s1 satisfies e  of both agents.1 following the second step of his plan  each 
of the agents has as temporary constraints  and c x   where x is the block he wants to move onto slot b. these constraints enable each agent to move  his  block to slot b after removing block 1. 
　the aggregation of these constraints requires careful analysis. first  it must be recognized when the aggregated constraints of two identical terms such as 
will be   or even had block 1 been located on block 1 in the initial state of 
our example  the third solution would be appropriate. using it in the given scenario  however  would yield as the aggregated set of constraints in the second step 
　　　　　　　　　　　the induced states of this set cost 1 move operators  while the actual plan that achieves the mutual goal costs only 1. the problem here is that both constraints are temporary  each agent needs a free 
space for one block only momentarily . thus  in this case  the aggregated height should stay 1  leading to a 
state that is only three move steps distant from the initial state. unfortunately  it not clear how in general this 
subtle analysis is to be done. 
evaluation of sets of constraints 
　evaluation of sets of constraints plays an important role in the search procedure. one straightforward worth 
function for an arbitrary set a might be built by taking the worth of a goal state  assumed to be available   subtracting the cost of the single-agent plan from a to the goal  then subtracting the agent's share of the cost 
of the multi-agent plan to get from start state sq to a. 
　note  however  that using the above equation the worth of .so for an agent would simply be the worth of his goal  minus the cost of his one-agent plan to reach that goal  in a one-agent scenario this would be true for every set . thus  since the evaluation function does not capture the notion of progress in the plan  the agent has no motivation to carry out his plan at all. 
　there are several ways to refine the worth function so as to solve this problem. one way is by making the 
1 . note that by its nature  the height constraint is temporary  since it always is a precondition of an action that 
	1 	distributed al 
true preferences is the dominant strategy. 
　in our procedure  the agents are participating in many intermediate votes  and alternatives are generated dynamically  as a consequence of the intermediate votes . therefore  the original version of the c t m cannot be used efficiently. instead we use an iterative variation of the c t m ; at each step  the tax is defined with respect to all previous steps  but is actually levied only at the final 
step. we use the following definitions for the stepwise clarke tax mechanism: 
1 	manipulative/insincere agents 
in choosing a state that maximizes social welfare  it is critical that agents  at each step  express their true worth values. however  if our group consists of autonomous  
self-motivated agents  each concerned with its own utility  and not the group's welfare   they might be tempted 
to express false worth values  in an attempt to manipulate the group choice procedure. this is a classic problem in voting theory: the expression of worth values at each 
step can be seen as an  iterative  cardinal voting procedure  and we are interested in a non-manipulable voting 
scheme so that the agents will be kept honest. we have investigated other aspects of this problem in previous work  ephrati and rosenschein  1b . 
   fortunately  there do exist solutions to this problem  such that the above plan choice mechanism can be used even when the agents are not necessarily benevolent and honest. if the social welfare function is taken to be the  weighted  sum fum  or average  of the individual utilities  it is possible to ensure that all agents will vote honestly. this is done by minor changes to the procedure of section 1  that allow it to use a variant of the clarke tax mechanism  ctm . 
   in  ephrati and rosenschein  1  we proposed the ctm as a plausible group decision procedure. the basic idea of the mechanism is to make sure that each voter has only one dominant strategy  telling the truth. this phenomenon is established by choosing the alternative 
that scores the highest sum of bids/votes and then taxing some agents. the tax  if any  equals the portion of the agent's bid for the winning alternative that made a difference to the outcome. given this scheme  revealing 

	1 	distributed al 

served as a basis for the dconsa system  pope et al  1  where agents were not assumed to have complete information about their local environments. the combination of local plans was done through  interaction constraints  that were pre-specified. 
　the concept of solution that our algorithm employs  maximization of social welfare  also resembles the approach taken in consensus  clark et al  1  where several expert systems  elect  a plan that scores the highest rating with respect to the individual points of view. there  however  the election refers to different complete global plans that each expert generates. 
   another advantage of our proposed process is that it can easily be modified to deal with dynamic priorities. since the search is guided by the vote taken at each step  it is possible to allow the agents to change their  tastes  or priorities over time  for example  due to environmental changes . as an example  in the multifireboss phoenix system  moehlman and lesser  1  planning  the actions needed to assess and contain fires  is performed by several spatially distributed agents. the system addresses  through a sophisticated negotiation protocol  the dynamic allocation of resources. our algorithm would solve this problem in a direct manner  without negotiation. at each time interval  the agents would vote over the possible relevant distributions  one step of the algorithm per time interval . given the individual utilities  the accurate distribution of resources would be chosen that maximizes the social utility  minimizes the damage according to the group's perspective . in addition  as mentioned in section 1   there is no need to assume that the agents are benevolent. 
1 	conclusions 
we have introduced a new dynamic  iterative voting procedure. it enables a group of agents to construct a joint plan that results in a final state that maximizes social welfare for the group. the technique is more direct and formally specified than other consensus procedures that have been proposed  and maintains agent privacy more effectively. techniques such as these provide a natural method for the coordination of multi-agent activity. conflicts among agents are then not  negotiated  away  but are rather incrementally dealt with. agents iteratively search for a final state that maximizes the entire group's utility  incrementally constructing a plan to achieve that state. the search can be constructed so that any manipulation by an untruthful agent will harm the agent more than it helps him. 
references 
 chapman  1  i . chapman. planning for conjuctive goals. artificial intelligence  1 1  1. 
 clark et al  1  r. clark  c. grossner  and t. radhakrishnan. onsensus: a planning protocol for cooperating expert systems. in proceedings of the eleventh international workshop on distributed artificial intelligence  pages 1  glen arbor  michigan  february 1. 
 cor kill  1  d. cor kill. hierarchical planning in a distributed environment. in proceedings of the sixth international joint conference on artificial intelligence  pages 1  tokyo  august 1. 
 ephrati and rosenschein  1l  e. ephrati and j. s. rosenschein. the clarke tax as a consensus mechanism among automated agents. in proceedings of the ninth national conference on artificial intelligence  pages 1  anaheim  california  july 1. 
 ephrati and rosenschein  1a  e. ephrati and j. s. rosenschein. multi-agent planning as search for a consensus that maximizes social welfare. in pre-proceedings of the fourth european workshop on modeling autonomous agents in a multi-agent world  rome  italy  july 1. 
 ephrati and rosenschein  1b  e. ephrati and j. s. rosenschein. reaching agreement through partial revelation of p