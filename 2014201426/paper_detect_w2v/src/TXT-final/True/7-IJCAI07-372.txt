
we identify some weak points of the lrta* k  algorithm in the propagation of heuristic changes. to solve them  we present a new algorithm 
lrta*ls k   that is based on the selection and updating of the interior states of a local space around the current state. it keeps the good theoretical properties of lrta* k   while improving substantially its performance. it is related with a lookahead depth greater than 1. we provide experimental evidence of the benefits of the new algorithm on real-time benchmarks with respect to existing approaches.
1 introduction
real-time search interleaves planning and action execution in an on-line manner. this allows to face search problems in domains with incomplete information  where it is impossible to perform the classical search approach.
　a real-time agent has a limited time to planify the next action to perform. in such limited time  it can explore only a relatively small part of the search space that is around its current state. this part is often called its local space.
　this paper considers some weak points of the updating mechanism of the lrta* k  algorithm  hernandez and meseguer  1 . with this purpose  we present lrta*ls k   based on local space selection and updating. local space selection is learning-oriented. local space is divided into interior and frontier. updating is done from the frontier into the interior states  so some kind of lookahead is done. each state is updated only once. if the initial heuristic is admissible  it remains admissible after updating. lrta*ls k  keeps the good properties of lrta* k .
　the paper structure is as follows. in section 1 we expose the basic concepts used. in section 1 we describe some weak points of lrta* k . in section 1  we present lrta*ls k   explaining the lookahead and update mechanisms. in section 1  we relate lrta*ls k  with lookahead greater than 1. in section 1  we provide experimental results. finally  in section 1 we extract  some conclusions.
1 preliminaries
the state space is defined as  x  a  c  s  g   where  x a  is a finite graph  c : a   1   is a cost function that associates each arc with a positive finite cost  s  x is the start state  and g  x is a set of goal states. x is a finite set of states  and a  x  x   { x  x |x  x} is a finite set of arcs. each arc  v w  represents an action whose execution causes the agent to move from v to w. the state space is undirected: for any action  x  y   a there exists its inverse  y  x   a with the same cost c x  y  = c y  x . k n  m  is the cost of the path between state n and m. the successors of a state x are succ x  = {y| x  y   a}. a heuristic function h : x   1   associates with each state x an approximation h x  of the cost of a path from x to a goal  where h g =1  g  g. the exact cost h* x  is the minimum cost to go from x to a goal. h is admissible iff  x  x  h x   h* x . h is consistent iff 1  h x   c x w  + h w  for all states w  succ x . a path  x1  x1   . .  xn  with h xi  = h* xi   1  i  n is optimal.
　lrta*  korf 1  is a real-time search algorithm that is complete under a set of reasonable assumptions. lrta* improves its performance over successive trials on the same problem  by recording better heuristic estimates. if h x  is admissible  after a number of trials h x  converges to their exact values along every optimal path. in each step  lrta* updates the heuristic estimation of the current state to make it consistent with the values of their successors  bonnet and geffner  1 . originally  lrta* performs one update per step. some versions perform more than one update per step.
1 lrta* k 
lrta* k   hernandez and meseguer  1   is a lrta*based algorithm that consistently propagates heuristic changes up to k states per step  following a bounded propagation strategy. if the heuristic of the current state x changes  the heuristic of its successors may change as well  so they are reconsidered for updating. if the heuristic of some successor v changes  the successors of v are reconsidered again  and so on. the propagation mechanism is bounded to reconsider up to k states per step. this updating strategy maintains heuristic admissibility  so lrta* k  inherits the good properties of lrta*  in fact  lrta* k reduces to lrta* when k=1 . experimentally  lrta* k  improves significantly with respect to lrta*.    the updating mechanism is implemented with a queue q  that maintains those states that should be reconsidered for updating. we have identified some weak points:
1. if y enters q  after reconsideration it may happen that h y  does not change. this is a wasted effort.
1. a state may enter q more than once  making several updatings before reaching its final value. would it not be possible to perform a single updating per state 
1. the order in which states enter q  combined with the value of k parameter  may affect the final result.
as example  in the figure 1  i   a  b  c and d are states  the left column is the number of the update iteration  and the numbers below the states are their heuristic values. moving from a state to a successor costs 1. sucessors are revised in left-right order. the current state is d  iteration 1 shows the initial heuristic values. in iteration 1  h d  changes to 1  q = {c}. in iteration 1  h c  changes to 1  q = {b  d}. in iteration 1  h b  does not change. in iteration 1  h d  changes to 1  q = {c}. in iteration 1  h c  does not change. after five iterations no more changes are made and the process stops. we see that c and d enters two times in q  d is updated twice while c is updated only once. if k = 1  the final result depends on the entering order in q. if the left successor goes first  the states d  c  b will enter q in that order  producing the heuristic estimates of figure 1  ii . the agent moves to c  and then it may move again to d. if the right successor goes first  the states in q will be d  c  d  causing heuristic values equal to those of iteration 1. then  the agent moves from d to c  and then to b  not revisiting d.
　in  hernandez and meseguer  1  it is required that updates are done on previously visited states only. in that case  weak point 1 is solved by the use of supports 1. however  there is a version of lrta* k   called lrta*1 k   which updates any state  not just previously visited states . in this case  supports can only partially solve this issue.
1a b c d 1 11	1	11	11	1	11	11	1	1iter.	
	 i 	 ii 	 iii 
figure 1.  i  example of lrta* k  updating;  ii  if successors enter q in left-right order  and k=1  state d can be revisited;  iii  example of lrta*ls k  updating.
1 lrta*ls k 
trying to solve those weak points  we propose a new algorithm lrta*ls k   based on the notion of local space around the current state. formally  a local space is a pair  i  f   where i x is a set of interior states and f x is the set of frontier states  satisfying that f surrounds i inmediate and completely  so i	f =  . lrta*ls k  selects the local space around the current state and then updates its interior states. each state is updated only once. under some circumstances  we can prove that every interior state will change its heuristic. the number of interior states is upper-bounded by k. if the initial heuristic is admissible  lrta*ls k  maintains the admissibility  so it inherits the good properties of lrta*  and lrta* k  .
1 selecting the local space
　we want to find a local space around the current state such that its interior states will have a high chance to update its heuristic. we propose the following method 
1. set i =    q = {x | x is the current state}.
1. loop until q empty or |i| = k
extract a state w from q. if w is a goal  exit loop. otherwise  check by looking at succ w  that are not in i if h w  is going to change  that is  if h w    minv{succ w -i} h v  + c w v   we call this expression the updating condition . if so  include w in i  and succ w    i in q.
1. the set f surrounds i inmediate and completely.
for example  let us apply this strategy to figure 1  i . it starts with i = {d} since h d    minvsucc d  h v  + 1. then  it checks the successors of d  adding c to i  i = {c  d} since h c    minv{succ c -i} h v  + 1. then  it checks the successors of c that do not belong to i  that is  b. since h b  =
minv{succ b -i} h v  + 1  it is not possible to add more states to i. then i = {c  d} and f = {b}. if the heuristic is initially consistent  all interior states of the local space  i  f  built with the previous method will change their heuristic  as proven in the following result.
proposition 1. if the heuristic is initially consistent  starting from x lrta*1  k=  will update every state of i.
proof. by induction in the number of states of i. if |i| = 1  then i = {x}  the current state. in this case  h x  is updated because by construction it satisfies the updating condition. let us assume the proposition for |i| = p  and let us prove it for |i| = p + 1. let z  i  z  x  y = argminvsucc z  h v  + c z v . if y  i  z satisfies the updating condition by construction. if y  i  let i' = i - {z}. since |i'| = p  every state of i' will be updated  so y will be updated  passing from hold y  to h new y   hold y    hnew y . we will see that this causes z to be updated. we consider two cases:
1. if y is still argminvsucc z  c z v  + h v . the initial heuristic is consistent so h z   c z y  + hold y    c z y  + hnew y . so z satisfies the updating condition and h z  will change.
1. if w = argminvsucc z  c z v  + h v   w  y. if w  i'  z satisfies the updating condition by construction. if w  i'  w has passed from hold w  to hnew w   hold w    hnew w . since y was the initial minimum  we know that c z y  + hold y    c z w  + hnew w . so  h z   c z y  + hold y    c z w  + hnew w . then  z satisfies the updating condition and h z  will change.    lrta*1 k=  reaches all interior states because every successor of a changing state enters the queue q  which has no limit in length  k= .                                                  qed.
if the heuristic is admissible but not consistent  some interior states may not change. for instance  consider the states a-b-c-d in a linear chain  with heuristic values 1  1  1  1  and b is the current state. the previous method will generate i = {b  c}. h b  will change to 1  but h c  will not change.
1 updating the local space
lrta*ls k  updates the interior states of  i  f  as follows 
loop while i is not empty:
1. calculate the pair of connected states  i  f   i  i  f  f  f  succ i   such that  i  f  = argmin v  i  w  f  w  succ v  c v  w  + h w .
1. update h i  = c i f  + h f .
1. remove i from i  include i in f.
for example  in figure 1  i   i = {c  d} and f = {b}  the results of each iteration with the new updating appear in figure 1  iii . in iteration 1   i  f  =  c  b   and h c  changes to 1. in iteration 1   i  f  =  d  c   and h d  changes to 1. as i =  process stops. update keeps admissibility  as proved next.
proposition 1. if the initial heuristic is admissible  after updating interior states the heuristic remains admissible.
proof. let  i  f  = argmin v  i  w  f  w  succ v  c v  w  + h w . since i  i and connected to a frontier state f  it will be updated  it satisfies the updating condition by construction . there is an optimal path from i to a goal that passes through a successor j. we distinguish two cases:
1. j  f. after updating
h i =c i  f  + h f 
c i  j  + h j                   i  f  minimum c v w  + h w 
	c i  j  + h* j 	h admissible
	=h* i 	because optimal path
1. j  f. if i contains no goals  the optimal path at some point will pass through f. be p the state in the optimal path that belongs to f and q the interior state in the optimal path just before p. after updating
h i =c i  j  + h j 
	c q  p  + h p 	 i  f  minimum c v w  + h w 
	k i  p  + h p 	k i  p  includes c q  p 
	k i  p  + h* p 	h admissible
　　　=h* i                             because optimal path in both cases h i h* i  so h remains admissible.            qed.
proposition 1. every state updated by lrta*1 k=  is also updated by lrta*ls k= .
the proof is direct  but it is omitted for space reasons. with these selection and updating strategies  the weak points of lrta* k  are solved partial or totally. regarding point 1  if the heuristic is consistent all interior states will change its heuristic estimator  propositions 1 and 1 . if the heuristic is just admissible  some internal states may not change  example in section 1 . point 1 is totally solved  since the updating strategy considers every state only once. about point 1  it is not solved since the final result may still depend on the order in which successors are considered and the value of k parameter. since lrta*ls k  performs a better usage of k than lrta* k   non repeated states and with high chance to change   we expect that  with the same k value  the former will depend less than the latter on the successor ordering. if the heuristic is consistent  after updating interior nodes the local space is locally consistent and agent decisions are locally optimal  pemberton and korf  1 .
　it is important to see that the new update method makes a more aggressive learning than lrta* k   because lrta* k  updates a state x considering all its successors  while lrta*ls k  considers those successors that are frontier states only. one update of lrta*ls k  may be greater than one update of lrta* k . for instance  see the updating of h d  in figure 1  i : it goes from 1 to 1  and then to 1  in two steps. in figure 1  iii   h d  goes from 1 to 1 in one step.
1 the algorithm
the lrta*ls k  is a algorithm based on lrta* similar to lrta* k . the algorithm appears in figure 1. the main differences with lrta* appear in the lrta-ls-trial procedure  calling to selectionupdatels. this procedure performs the selection and updating of the local space around the current state. procedure selectionupdatels first performs the selection of the local space and then updates it. to select the local space  a queue q keeps states candidates to be included in i or in f. q is initialized with the current state and f and i are empty. at most k states will be entered in i. this is controlled by the counter cont. the following loop is executed until q contains no states or cont is equal to k. the first state v in q is extracted.
the state y   argminwsucc v   w  i h w  + c v  w  is computed. if h v  satisfies the updating condition  then v enters i  the counter increments and those successors of v that are not in i or q enters in q in the last position. otherwise  v enters f. when exiting the loop  if q still contains states then these states go to f. once the local space has been selected  its interior states are updated as follows. the pair  i  f    argmin vi  wf  wsucc v  h w  + c v  w  is selected  h i  is updated  i exits i and enters f.
    since the heuristic always increases  compleneteness holds  theorem 1 of  korf  1  . heuristic admissibility is maintained  so convergence of to optimal paths is guaranteed in the same terms as lrta*  theorem 1 of  korf  1  . lrta*ls k  inherits the good properties of lrta*.
procedure lrta*-ls k   x  a  c  s g  k 
for each x  x do h x    h1 x ; repeat
lrta*-ls-trial x  a  c  s g  k ; until h does not change;
procedure lrta*-ls-trial x  a  c  s g  k  x   s; while x  g do
selectupdatels x  k ;
y   argminwsucc x   h w  + c x w  ; break ties randomly  execute a  a such that a =  x  y  ; x   y;
procedure selectupdatels  x  k 
q  x; f  ; i  ; cont   1; while q   cont   k do
v   extract-first q ;
y   argminwsucc v   w  i h w  + c v  w ;
if h v    h y  + c v  y  then i  i  {v}; cont   cont + 1; for each w  succ v  do
     if w  i  w  q then q   add-last q w ; else
if i   then f  f  {v};
if q   then f  f  q; while i   do
 i  f    argmin vi  wf  wsucc v  h w  + c v  w ; h i    max h i   c i  f  + h f  ;
i  i - {i};
f  f  {i};
figure 1: lrta*ls k  algorithm.
1 lookahead and local space
real-time agents restrict planning to the local space  koenig  1 . basically an agent performs three steps:  i  lookahead on the local space   ii  updating the local space and
 iii  moving in the local space.
　on lookahead  in rta*  lrta*  korf  1; knight  1  and in lrts  bulitko and lee  1  the local space is determined by the depth of the search horizon. the search tree  rooted at the current state  is explored breadth-first until depth d. in the lrta* version of  koenig  1  and in rtaa*  koenig and likhachev  1   the local space is determined by a bounded version of a*  limiting the number of states that can enter in closed. lrta*ls k  tries to find those states that will change in the updating process. lookahead is limited by the k parameter: a maximum of k states can enter the set of interior states. about updating  there are two approaches: updating the current state only  like lrts with the max-min rule   and updating all interior states of the local space  like rtaa* that update all states in closed and lrta*ls k  . regarding moving  for unknown environments the free space assumption is assumed  koenig et al.  1 . in rtaa* the agent tries to move to the frontier of the local space. if it finds an obstacle  the whole process is repeated again. in lrta*-based algorithms the agent moves to its best successor.
　figure 1 shows an example of a goal-directed navigation task on a grid  legal moves: north  south  east  west; all moves of cost 1  with three different algorithms: lrta*ls k=1   rtaa* with lookahead 1 and lrts  with parameters =1 and t=  with lookahead 1. the visibility radius is one  bulitko and lee  1 . black cells are obstacles. the initial heuristic is the manhattan distance. the current state is indicated with a circle. with similar lookahead  lrta*ls k  expands less states  the set of interior states contains 1 states with k = 1  because only those 1 states will changes their heuristic  and after updating it obtains a heuristic more informed than rtaa* and lrts.
　the updating mechanism of lrta*ls k  is a general method. therefore  it is possible to use it with different lookahead mechanisms  like those of rtta* and lrts.
1 experimental results
we compare lrta*ls k  versus lrta* k . in addition  we compare lrta*ls k  with rtaa* and lrts  algorithms with lookahead greater than 1. as benchmarks we use these
four-connected grids 
  grid1: grids of size 1 with a 1% of obstacles placed randomly. in this type of grid heuristics tend to be slightly misleading.
  grid1: grids of size 1 with a 1% of obstacles placed randomly. in this type of grid heuristics could be misleading.
  maze: acyclic mazes of size 1 whose corridor structure was generated with depth-first search. here heuristics could be very misleading.
　results are averaged over 1 different instances. in grids and mazes  the start and goal state are chosen randomly assuring that there is a path from the start to the goal. all actions have cost 1. as initial heuristic we use the manhattan distance. the visibility radius of the agent is 1. results are presented in percentage with respect to the value of row 1%  in terms of total search time  solution cost  trials to convergence  number of updated states  and time per step  for the convergence to optimal path.
　comparing lrta*ls k  and lrta* k   we consider first trial and convergence to optimal paths. results for convergence to optimal paths appear in table 1  where the lcm algorithm  pemberton and korf  1  is also included  lcm has the same updating mechanism as lrta* k   but without supports and limitation of entrances in the queue . lrta*ls k  converges to optimal paths with less cost  number of trials and total time than lrta* k  for all values of k tested between 1 and   except for grid1 in total time with k = 1 . respect to time per step  lrta*ls k  obtains better results than lrta* k  except for grid1. lrta*ls k  requires slightly more memory than lrta* k   except for grid1 with k =  . lrta* k =   and lcm have the same cost and number of trials to convergence  but lrta* k=  improves over lcm in time because the use of supports. lrta*ls k =   has similar results in cost and number of trials to convergence  requiring less time than lrta* k=  and lcm  except for grid1 in time per step . we observe that the worse the heuristic information is  the better results lrta*ls k  obtains  for all values of k. for grid1  lrta*ls  1  improves over lrta* 1  in steps and trials  but it requires more running time. this is due to the extra overhead of lrta*ls k  has over lrta* k   minimizing on two vs. one argument   that counterbalances the benefits in steps and trials.
　results for first trial appear in table 1. lrta*ls k  obtains a solution with less cost than lrta* k  for all tested values of k between 1 and   except for maze with k = 1 . respect to time  lrta*ls k  obtains better solution for maze and grid1 than lrta* k . in grid1  lrta* k  shows better results in total time and time per step. trying to improve the running time  we have developed
lrta*ls k -path  that only updates states that have been visited previously  like lrta* k  and lcm . lrta*ls k path improves the cost of the solution and total time for small values of k  and this improvement is larger when worse is the heuristic information  in grid1 it improves for k = 1 only  in maze it improves for k = 1  1  1 and 1 . this fact can be explained as follows. due to the free space assumption  lrta*ls k  may perform an inefficient use of k  updating states that are blocked  will never appear in any solution . since a great part of the states in maze are blocked  is better to update only states in the current path  as the results show. considering memory  lrta*ls k  uses more memory than lrta* k  and lrta*ls k -path with increasing k and more than lcm with k = .
　comparing with lookahead algorithms  results for first trial appear in table 1. comparing lrta*ls k  and rtaa*  the former obtains costs equal to or better than the latter in grid1 and maze for all values of k. however  from k = 1  rtaa* obtains slightly better costs in grid1. rtaa* takes more time in finding a solution for all values of k in all benchmarks. considering time per step  lrta*ls k  requires a smaller time for all values of k in all benchmarks  except for maze with k = 1  1 . from k = 1 in maze and from k = 1 in g1  rtaa* uses more memory than lrta*ls k . in g1  rtaa* uses less memory for all values k. lrts uses the radius of a circle centered in the current state as lookahead parameter  while lrta*ls k  and rtaa* use the number of the states they consider in advance. to perform a fair comparison  we use lrts  with parameters =1 and t=  lookahead values that generate circles including k states  where k is the lookahead of lrta*ls k  and rtaa*. lrts does not show a good performance in terms of cost and time to find a solution respect to lrta*ls k . lrts uses less memory than lrta*ls k  and smaller time per step.
　in summary  lrta*ls k  shows better performance than lrta* k  both in first trial and convergence to optimal paths. sometimes updating only previously visited states could improve performance: if the heuristic quality is good  it is advisable to update any state  but with bad quality heuristics it is safer to update visited states only. in first trial  lrta*ls k  performs equal or better than rtaa* in two benchmarks  while there is no clear winner for the third. lrta*ls k  performs better than lrts. on memory usage  lrts wins  while the second is unclear between
lrta*ls k  and rtaa*.
1 conclusions
trying to solve some inefficiencies in lrta* k  propagation  we have developed lrta*ls k  a new real-time search algorithm. it is based on the selection and update of a local space  composed of interior and frontier states. the number of interior states is upper-bounded by k. lrta*ls k  updates the interior states from the heuristic values of frontier states  so it performs a kind of lookahead with varying depth. if the heuristic is initially consistent  all interior states are updated. experimentally  we show that lrta*ls k  improves over lrta* k   lookahead 1 . and improves over rtaa* and lrts  with lookahead greater than 1 .
