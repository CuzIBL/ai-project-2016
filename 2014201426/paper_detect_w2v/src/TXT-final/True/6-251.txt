 
we present an approach for learning part-of-speech distinctions by induction over the lexicon of the cyc knowledge base. this produces good results  1%  using a decision tree that incorporates both semantic features and syntactic features. accurate results  1%  are achieved for the special case of deciding whether lexical mappings should use count noun or mass noun headwords. comparable results are also obtained using opencyc  the publicly available version of cyc. 
1 introduction 
in semantic lexicons  a lexical mapping describes the relationship between a concept and phrases used to refer to it. this mapping includes syntactic information for deriving variant phrases  including the part of speech of the headword. selecting the part of speech for the lexical mapping is required so that proper inflectional variations can be recognized and generated for the term. although often a straightforward task  there are special cases that can pose problems  especially when fine-grained speech part categories are used. 
　to reduce the need for linguistic expertise in producing these lexicalizations for a large knowledge base like cyc  lenat  1   linguistic criteria can be inferred from decisions that have been made by lexical knowledge engineers in lexicalizing preexisting terms. 
　the cyc knowledge base  containing 1 concepts and over one million axioms 1 divides roughly into three layers. the upper ontology formalizes fundamental distinctions  e.g.  tangibility versus intangibility . the lower ontology collects specific facts  often related to concrete applications  and the middle ontology encodes commonsense knowledge about the world. the kb also includes a broad-coverage english lexicon mapping words and phrases to terms throughout the kb. 
natural language lexicons are integrated directly into the 
cyc kb  burns and davis  1 . binary predicates  as in 
 namestring hebcompany  heb'   map names to terms. a 
   'these figures and the results discussed later are based on cyc kb v1 and system vl.1. see www.cyc.com for detailed documentation on the kb and  o'hara et al.  1  for more technical details related to this work. 
denotational assertion maps a phrase  specified via a lexical concept with optional string modifiers  into a concept  usually a collection. the part of speech is specified by cyc's speechpart constants. the simplest type of denotational mapping uses the denotation predicate. for example   denotation device-word countnoun 1physicaldevice  indicates that sense 1 of the count noun 'device1 refers to physicaldevice  via the wordforms  device  and  devices  . three additional predicates account for phrasal mappings: compoundstring  headmedialstring  and multiwordstring are used for phrases with the headword at the beginning  the middle  and the end  respectively. 
　these denotational assertions  excluding lexical mappings for technical  informal and slang terms  form the training data for a lexicalization speech part classifier. 
1 	inference of lexicalization part of speech 
our method of inferring the part of speech for lexicalizations is to apply decision tree learning over existing lexical mappings. for each target denotatum term  the corresponding definitional information  e.g.  isa   asserted or inferable via transitivity  is extracted from the ontology. for simplicity  these definitional types are referred to as ancestor terms. associations between the lexicalization parts of speech and common ancestor terms underlie the lexicalization speech part classifier and its special case  the mass-count classifier  distinguishing  e.g.   much sand  from  many books  . to reduce the size of the training feature vector  only the most frequent 1 atomic terms from the thousands of possible ancestor terms are selected  after excluding certain internal bookkeeping constants. 
　given a training instance  such as a denotation from a lexeme into a specific cyc concept using a particular speechpart  e.g.  massnoun or a countnoun   the feature specification is derived by determining all the ancestor terms of the denotatum term and converting this into a vector of occurrence indicators  one indicator per reference term. then the headword is checked for the occurrence of a set of commonly used suffixes. if found  the suffix itself is added to the vector  in a position set aside for suffixes of the same length . the part of speech serves as the classification variable. 
　we use decision trees for this classification. part of the motivation is that the result is readily interpretable and can be incorporated directly by knowledge-based applications. a 

1 	poster papers 

opencyc cyc instances 
classes 
entropy 1 
1 
1 1 
1 
1 baseline accuracy 1 
1 1 
1 table i: mass-count classification over cyc lexical mappings  using cyc reference terms and headword suffixes as features. instances is size of the training data. classes indicates number of choices. baseline selects most frequent case. accuracy is average in the 1-fold cross validation. 
opencyc cyc instances 
classes 
entropy 1 
1 
1 1 
1 
1 baseline accuracy 1 1 1 
1 table 1: general speech part classification using cyc. 
simple fragment from the resulting decision tree shows how ontological features interact with morphological ones: 
if  isa abstractinformationalthing  then 
if  suffix -  -cr   then 
if  not isa somethingexisting  then agentivenoun if  isa somethingexisting  then massnoun 
if  suffix =  -cd   then massnoun if  suffix 	 -al   then adjective if  suffix =  -or   then agentivenoun 
   table 1 shows the results of 1-fold cross validation for the mass-count classification. this was produced using the j1 algorithm in the weka machine learning package  witten and frank  1   which is an implementation of quilan's c1  quinlan  1  decision tree learner. this shows that the system achieves an accuracy of 1%  an improvement of 1 percentage points over a baseline of always selecting the most frequent case. the opencyc version of the classifier also performs well. this suggests that sufficient data is already available in opencyc  available online at www.opencyc.org  to allow for good approximations for such classifications. 
   the mass/count noun distinction can be viewed as a special case of speech part classification. running the same classifier using the full set of speech part classes yields the results shown in table 1. here the overall result is not as high  but there is a similar improvement over the baseline. 
1 	discussion 
contextual part of speech tagging  brill  1  has received substantial attention in the literature  but there has been relatively little written on automatically determining default lexicalization parts of speech. woods  woods  1  describes an approach to this problem using manually-constructed rules incorporating syntactic  morphological  and semantic tests  via an ontology . our rules are induced from the knowledge base  which alleviates the need for rule maintenance as well as rule construction. 
   this paper shows that an accurate decision procedure  1%  for determining the mass-count distinction in lexicalizations can be induced from the lexical mappings in the cyc kb. the performance  1%  in the general case is also promising  given that it is a much harder task with over 1 part of speech categories to choose from. the features incorporate semantic information  in particular cyc's ontological types  in addition to syntactic information  e.g.  headword morphology . although the main approach incorporates cyc's conceptual distinctions  it can be extended to non-cyc applications via the wordnet mapping  otlara et al.  1 . 
　this work is just a small initial step in applying machine learning techniques to the massive amount of data in cyc. the recent release of opencyc enables wider investigation and exploitation of the information in the cyc knowledge base for intelligent applications. 
acknowledgements 
the lexicon work at cycorp has been supported by many staff members  and  in part by grants from nist  darpa  and arda. the first author is currently supported by a gaann fellowship from the department of education. the work utilized nmsu resources obtained through mil grants e1a-1 and e1a-1. 
