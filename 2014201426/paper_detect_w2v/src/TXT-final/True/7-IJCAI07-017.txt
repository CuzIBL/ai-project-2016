
caching  symmetries  and search with decomposition are powerful techniques for pruning the search space of constraint problems. in this paper we present an innovative way of efficiently combining these techniques with branch and bound for solving certain types of constraint optimization problems  cops . our new method significantly reduces the overhead of performing decomposition during search when dynamic variable orderings are employed. in addition  it supports the exploitation of dynamic symmetries that appear only during search. symmetries have not previously been combined with decomposition. finally  we achieve a superior integration of decomposition and caching with branch and bound than previous approaches. we test our methods on the maximum density still life problem and show that each of our ideas yields a significant gain in search performance.
1 introduction
as the variables of a constraint satisfaction problem  csp  are assigned during backtracking search the problem can break into disjoint parts. consider a csp consisting of the variables {a b m x y } and two constraints c1 a b m  and c1 m x y  . if we make the assignment m = m  then the resulting reduced csp will consist of two disjoint subproblems that share no variables. one subproblem is over the variables a and b with the constraint c1 m=m a b  while the other subproblem is over x and
y with the constraint.
we call these disjoint subproblemscreated by variable assignments components. the two components created by the assignment m = m can be solved independently: any solution  to the first  and solution
to the second  can be combined with m = m to obtain a solution to the original csp 
. since the worst case complexity of solving a csp is exponential in the number of variables  decomposition into components can yield significant computational gains.
﹛this insight has been exploited to perform search where decomposition is applied recursively  e.g.   bayardo & pehoushek  1; darwiche  1; park & gelder  1; sang et al.  1; dechter  1; amir & mcilraith  1 . this can yield a reduction in the worst case complexity of search from 1o n  to no w   where n is the number of variables of the problem and w is the tree width of the csp-graph  the graph determined by the constraint scopes   darwiche  1 .
﹛a component produced by decomposition at one point of the search tree might appear at many other nodes of the search tree. caching allows us to solve each component once and then reuse that solution in the rest of the search. when caching is added to decomposition the worst case complexity of search can be further reduced  from no w  to 1o w   darwiche  1; bacchus  dalmao  & pitassi  1 . this can be a significant speedup in practice  e.g.  see the results in  sang et al.  1  . of course caching requires space  but in this case the space requirementsare completely flexible. in particular  caching is used only to speedup the algorithm-it is not required for correctness. thus we can cache as many solved components as we have space for-within certain practical limits the morespace we have for caching the faster the search will proceed. furthermore  we can always prune the cache of less useful items if available space is exhausted.
﹛decomposition and caching impose a significant overhead during search  but these techniques are still very effective for more complex constraint problems  e.g.  finding the best solution  optimization   marinescu & dechter  1  or counting the number of solutions  sang et al.  1 . when a static variable ordering is used much of this overhead can be eliminated using data structures computed prior to search  darwiche  1 . however  dynamic variable orderings can yield significant reductions in the size of the search tree  enough to pay off their added overhead  e.g.   marinescu & dechter  1  . nevertheless  methods for reducing this overhead and for making these techniques even more effective are still needed to increase the practical benefits of dynamic decomposition.
﹛in this paper we present a method for making search with decomposition and caching more effective in the context of dynamic variable orderings. our key contribution involves a method for representing the common structure of an entire set of components in a single data structure we call a component template. the individual components that are instances of the template can thus share a single representation of their common information  making caching considerable more space efficient. with templates we can also increase the efficiency of cache lookup-we can access any of the template's instances by simple array indexing. templates also allow us to perform component detection during search more efficiently.
﹛another final key contribution of this paper is a method for automatically detecting symmetries between templates. once we have detected that two templates t1 and t1 are symmetric we can use the discovered symmetry mapping to map all instances of t1 to a symmetric instance of t1. thus the template symmetry encodes an entire set of individual component symmetries. this makes computing template symmetries much more cost effective than computing symmetries between individual components. template symmetries allow us to make more effective use of cached information-cached component bounds can now be used to provide bounds for all symmetric components as well. this can yield significant reductions in the size of the explored search space.
﹛finally  we show how to achieve a better integration between branch and bound and component caching by caching bounds on components rather than requiring that the components be completely solved prior to being stored in the cache  as done  e.g.  in  marinescu & dechter  1  .
﹛in the sequel we first expand on the background behind our approach. then we present our new technique of component templates and show how they can be exploited so as to achieved the benefits just described. then we present some initial empiricalresults on the test problemof maximumdensity still life.
1 background
in this paper  we concentrate on solving constraint optimization problems  cops  that have decomposable objective functions. however  our template technique could be used in other applications of componentcaching  search with decomposition and caching   e.g.  counting solutions.
a constraint optimization problem  cop   p  is specified by a tuple v dom   where v is a set of variables  for each v ﹋ v  dom v   is its domain of values  c is a set of constraints  and o is an objective function that assigns a value to all complete assignments of values to the variables. the typical goal in solving a cop is to find an assignment of values to the variables that maximizes o and at the same time satisfies all of the constraints in c.
﹛our techniques are effective on cops that have decomposable objective functions and constraints. in particular  we require that o be decomposed into the sum of objective subfunctions   such that each oi is dependent on only a subset of the variables scope oi    v  and that each constraint c ﹋ c also be dependent on only a subset of the variables scope c    v.1 the constraints and objective sub-functions can be unified by treating each constraint as an additional objective sub-function mapping satisfying assignments to 1 and violating assignments to  ﹢. thus the overall
 unified  objective function becomes  and the problem is simply to maximize this augmented objective function.  this formulation is like a soft-constraint problem . hence  in this paper we regard a cop as being the tuple v dom o where o includes both the original objective sub-functions and the hard constraints encoded as additional objective sub-functions. we use the term objectives to denote the sub-functions in o.
﹛note that we could equally use an objective function that is decomposed into a product rather than a sum of objectives; similarly we could cast the problem as a minimization task rather than a maximization task.
components. in backtracking search each node of the search tree n corresponds to a set of variable assignments  and these assignments might cause the problem to be broken up into disjoint components. a component is a subset of the original problem that has been isolated by a set of assignments. here we present a formalization of this idea tailored to our subsequent developments.
﹛a component   dom o is a tuple  where 老.v   v  老.o   o and 老.a is a set of assignments {vi = ai ...}  subject to the following conditions. let vars 老.a  be the set of variables assigned values in 老.a.
1.
1.
1.
1. p is minimal. that is  there is no other tuple  that satisfies conditions 1 with and with at least
one of these sets being a strict subset.
﹛that is  a component contains a set of variables and all of the objectives over these variables. furthermore  these objectives are isolated from the rest of the problem by a set of assignments 老.a: all of the variables they mention are either variables in the component or are instantiated in 老.a. furthermore none of the variables of the component  i.e.  the variables in 老.v  are assigned in 老.a.
the components at a node. at each node n some set of assignments a have been made  and some set of variables u remain unassigned. the components at n  老1 ...老k  are those components such that  a  老i.v   u  the variables of the components are unassigned    b  老i.a   a  the current assignments isolate the variables of the component .
example 1 consideracopwithvariables {a  b  m  n  x  y } and constraints c1 a b m   c1 x y n   and
c1 m n . at anodenwherejust theassignmentm=a has been made  there will be two components: 老ab with 老ab.v = {a b}  老ab.o = {c1} and 老ab.a = {m = a} and 老xyn with 老xyn.v = {x y n}  老xyn.o = {c1 c1}  and老xyn.a = {m = a}.
computing the components at a node n is easily accomplished by standard algorithms for detecting the connected components of a graph  e.g.  union-find or depth-first search. in particular  we consider an undirected graph gn  that contains a node for every objective in o and for every uninstantiated variable v . there is an edge between two nodes in gn if and only if one of the nodes is a variable node v   the other is an objective node o  such that v ﹋ scope o .
observation 1 the connected components ofgn correspondtotheminimalcomponentsofn.inparticular 老 isa componentatn ifandonlythereexistsaconnectedcomponentc ofgn such老.v isthesetofvariablenodesinc 老.o is thesetofobjectivenodesofc and老.a aretheassignments madetotheinstantiatedvariablesoftheseobjectives.
this observation can be verified by realizing that conditions  1  and  1  in the definition of a component  above  can be achieved by incrementally adding connected objectives to 老.o and connected variables to 老.v stopping when there are no more connections to follow. this is precisely what connected components algorithms do  these algorithms also compute minimal components . 老.a can then computed after 老.v and 老.o have been finalized. note also that any objective that has been fully instantiated at the node n will become an isolated node in gn; i.e.  a single node component. these fully instantiated objectives form components with no variables  one objective  and the assignments required to fully instantiate that objective.
example 1 supposeinourexamplewenextassignn = b  sothatonlythetwoassignments m = a and n = b have beenmade. thiswillgenerate1components: 老ab isunaffectedbythenewassignment but 老xyn isnowsplitinto twocomponents
.notethe老mn containsnovari-
ables justasinglefullyinstantiatedobjective andthatthe component老xy doesnotcontainsm = a initsassignment seteventhoughitsparentcomponent老xyn did.
computation benefits of components. if 老 is a component then the value of any assignment a to its variables  老.v  is equal to the sum of its objectives 老.o evaluated at the set of assignments a ﹍ 老.a. note that the objectives of 老 are functions only of 老.v and the assignments in 老.a  thus any complete assignment to 老.v along with 老.a is sufficient to fully instantiate all of these objectives  yielding a single numeric value for each objective which we can then sum . the value  maximal value  of 老  value 老   is the maximum value that can be achieved by any assignment to its variables 老.v:
value 老  =	max	.
a:a is an assignment to 老.v o﹋老.o
a solution to the component is any assignment to its variables that achieves its  maximal  value. note that components corresponding to fully instantiated objective have a value equal to the value of the instantiated objective. note also that the value of a component can be computed by examining assignments to the component's variables only  the rest of the problem can be ignored.
proposition 1 letn.a bethesetofassignmentsmadeata node n andlet 老1 ... 老k bethesetofcomponentsat n. themaximalvaluethatcanbeobtainforanycompleteset ofassignments a tothevariablesofthecop p suchthat a   n.a  i.e. atanyleafnodeinthesubtreebelow n   is value 老i . furthermoreacompleteassignment a achievesthismaximalvalueifandonlyifitisequalton.a unionedwithasolutionforeachcomponent老i.
this proposition follows from the fact that the values of the components are independent of each other. computationally  this means that we can solve each component independently  and that we obtain further computational advantage by applying decomposition recursively as we solve the individual components.
1 templates
now we introduce our new idea of component templates used to represent the shared information of a group of components  each of which then becomes an instance of the template. the basic idea is quite simple  with most of the innovation arising from how templates can be exploited algorithmically.
﹛from the definitions above it can be observed that for any two components 老1 and  then 老1.o=老1.o: both of these sets are all the objectives mentioning these variables  and no others due to minimal . furthermore  the variables assigned in 老1.a are identical to the variables assigned in 老1.a: both of these sets must assign all variables of the 老i.o not in 老i.v. in fact the only difference between two non-equal components containing the same  non-empty  set of variables is that the particular values assigned in 老1.a and 老1.a differ  and as a consequence value 老1  and value 老1  might also differ  since the objectives are being maximized subject to the differing values in 老1.a and 老1.a .
﹛we use component templates to represent all the components that have an identical set of variables. formally  a component template is a set of variables
t .v  objectives t .o  and another set of variables t .d disjoint from t .v called the dependency variables  such that every set of assignments a to the variables in t .d  a  generates an instance of the template t a and  b  every instance
t a is a component:.. that is  the instance is a component with the same variables and objectives as the templates and with a being the set of assignments that disconnects it from the rest of the problem.
example 1 for instance  consider the component 老ab =  seeninthepreviousexample. the componenttemplateincludes 老ab asoneofitsinstances.inparticular.
using templates during search. as described above  the components at each node n of a backtracking search can be determined by a connected components algorithm run on the graph gn. note however that gn contains only variables and objectives  it does not mention the actual values assigned to the instantiated variables. hence the algorithm actually identifies a set of templates. the components at the node n are the particular instances of these templates determined by the assignments at n.
﹛once a template is detected for the first time we create a data structure to represent the template instance and store this in a template cache. this data structure can then be used to efficiently detect when any of its instances are components of future nodes in the search as follows.
 observation 1 letabethesetofassignmentsmadeatnode n andlett beacomponenttemplate.ifa instantiatesallof thevariablesint .d andnoneofthevariablesint .v then  isoneofthecomponentsat n where
{v =a|v =a ﹋ a＿v ﹋ t .d} isthesubsetofa thatassigns thevariablesint .d.
we can efficiently detect when all of the variables in t .d are instantiated at a node using standard lazy watch techniques  moskewicz et al.  1 . once all of t .d has been assigned we test t .v. if all of these variables are unassigned then t has been triggered  and we know that t .v forms a component at the current node. all of the template's variables and objectives can then be removed from gn  further reducing its size. connected components can then be run on this smaller remaining graph to identify the other components at the current node. triggering components and reducing the size of gn in this way can yield a non-trivial improvement in the total time needed to perform component detection.
﹛once a template has been triggered  we need to access information about the particular instance that exists at the current search node . associated with each template is a value cache that is used to store upper and lower bounds on the values of its instances  solutions can also be stored for solved instances . if t a is a template instance  then t a.lb and t a.ub will denote the stored lower and upper bounds on. if the instance has never been seen before  these bounds are given some default initial values. the search in the subtree below the current node will either compute the value of the instance  making
   compute better bounds on its value  or backtrack without updating these bounds. once we have the template  accessing an instance's bounds can be very efficient. in particular  each variable in t .d has a finite domain of values  and each instance t a is defined by the values in a it assign to these variables. thus we can use an instance's defining sequence of values as an index into a multi-dimensional array. many instances of the template might  however  never be encountered during the search  because of branch and bound pruning   so if such an array would be too large we can use the instance's sequence of values as a hash code to index into a small hash table more suitable for storing sparse data.
example 1 inourpreviousexample whenweset m = a forthefirsttime wecreateanewtemplatetab withtab.v = {a b} tab.o = {c1} andtab.d = {m} whichrepresent component老ab.aninstanceofthetemplateis immediatelycreated. searchproceedsoverthevariablesa andb returningtheupperandlowerboundsofcomponent 老ab undertheinstantiation m = a. theseareboundson themaximalvaluethatcanbeachievedbytheobjectivesin tab.o overallpossiblevaluesforaandbsubjecttom = a. theseboundsarestoredinthetemplatecacheas
a.lb and.ub i.e. asboundsindexedbythe assignmentm = a.
﹛ifweassign m = k laterinsearchwithaandbstill unassignedthentab istriggeredandtheboundsonthenew instanceareretrievedfromthetemplate'svalue cache.ifk = m thenthecachedupperandlowerboundscan bereusedatthisnewsearchnode.
template symmetries another key computational use of templates is to perform automatic symmetry detection between components at the abstract level of templates. in particular  we compute symmetries between templates during search  templates are only created during search . a symmetry between two templates can then be applied to all of their instances  thus allowing us to amortize a single symmetry computation over many different components. this is key in making automatic symmetry detection cost effective. to further reduce the cost of symmetry detection we confine ourselves to variable symmetries rather than finer-grain symmetries defined over variable-values.
﹛formally  we require a symmetry between two templates t1 and t1 to be a one-to-one and onto mapping 考 between the variables t1.d ﹍ t1.v and t1.d ﹍ t1.v such that
1. t1.d = 考 t1.d  and t1.v = 考 t1.v   where 考 applied to a set s is 考 s  = {考 v  |v ﹋ s}.
1. for any assignment a to all of the variables in t1.d ﹍ t1.v  the value of the objectives t1.o evaluated at a is identical to the value of the objectives of t1.o evaluated at 考 a   where 考 applied to a set of assignments a is 考 a  = {考 v   = a|v = a ﹋ a}.
 in otherwords  考 keeps the dependency variables and template variables separated  and it preserves the value of the template objectives. since the value of a template instance  is the maximum of the sum of the objectives t1.o under the fixed assignment a to the dependency variables t1.d and any assignment to t1.v  we have that
observation 1 if t1 and t1 aresymmetricunderthemapping 考 then for any instance of we have value value.
this means that any bounds we have computed for the component can be reused for the component.
﹛to automatically detect symmetries between templates during search we map the problem to a graph isomorphism problem by constructing a graph representation for each template. the graph representation has the property that two templates' graph representationsare graph isomorphicif and only if the templates are symmetric in the sense defined above. the graph isomorphism  which maps the vertices of one graph to the other  providesthe variableto variable symmetry mapping between the two templates.
﹛we solve the graph isomorphism problem using available graph automorphism software  in our case nauty  mckay  1  . as shown in  puget  1  such software can be surprising efficient even though graph isomorphism is not known to be of polynomial complexity. to utilize symmetries during search we proceed as follows. when a template t is first created  we construct its graph representation gt . nauty is then used to compute iso gt    a canonical isomorph of gt . t is symmetric to some previously cached template t  if and only if their graph isomorphs are equal  iso gt   = iso. by using hashing techniques on iso gt   we can find any isomorphic template in near constant time. if an isomorphic template t  is found we utilize the invertible mappings and  produced by
nauty to compute a symmetry map from.
to utilize this symmetry  we avoid allocating a value cache
 t 's instances. instead we mark t as being symmetric to and store the symmetry map 考. we continue to use t to detect when any of its instances are created  but  transparently to the rest of the code  whenever we read or store information about one of t 's instances we instead remap that access to the symmetric instance of t . thus  all instances of t are able to utilize bounds computed for instances of t . furthermore any bound computed for instances of t are stored as information about instances of t . since we might have many different templates being symmetric to t   symmetries always map to the earliest created template   this means that information computed for an instance of t can then be utilized by many other symmetric components.
example 1 considerthesamecopdescribedearlier.when weset n = b forthefirsttime wecreateanewtemplate txy with txy.v = {x y}  txy.o = {c1} and txy.d = {n} whichrepresentcomponent老xy.ifc1 isthesametype ofconstraintasc1 thenthegraphrepresentationoftab and txy willbethesame andanisomorphismbetweenthetwo templateswillbethefound inthiscasemappingvariable ntom.thecacheoftemplate txy willpointtothecache oftemplate tab underthemapping. ifwecreate aninstancewecanthenusethecachedresults
.lb and.
﹛notethatintheoriginalcop example1  ifnandmare notexchangablein c1 n m  thenthissymmetrydoesnot existuntilbothmandnareassigned.thatis ourmechanism candetectdynamicsymmetries.
﹛unfortunately space restrictions prohibit us from presenting the details of our template graphical representation. but we will mention that many choices for this representation exist. our representation utilizes nauty's ability to input coloured graphs to ensure that the computed graph symmetries keep the dependency variables and template variables separated  condition  1  above   it allows exploitation of the fact that some objectives have exchangeable variables 1 and it uses colours to ensure that only equivalent objectives can map to each other.
1 symmetric component caching search
the search algorithm given in figure 1 shows how we utilize the above ideas to perform recursive decompositions integrated with branch and bound. ccs+bb attempts to find the value for a single component given as a template instance t a. it is also provided with a lower bound lb  and can abort its computation as soon as it discovers that t a cannot achieve a value greater than this bound. even if the computation is aborted  however  the routine still stores the best bounds it was able to compute before termination  line 1. storing the bounds produced by a partial computation of a component's value allows a better integration with branch and bound. as described above  these bounds are stored in the template's value cache  or in some symmetric template's value cache .
﹛branch and bound inevitably implies that the search might attempt to compute the value of a particular template instance many times  aborting each attempt because of the current bound. by updating the component's bounds after each of these attempts work is saved. in particular  each new attempt can proceed more efficiently by utilizing the stronger bounds computed in the previous attempt. this approach is in contrast with that presented in  marinescu & dechter  1  
ccs+bb
1. if 
1. return
1. if lb  ta.lb lb := ta.lb
1. v := select variable from t .v to branch on
1. ts := find the templates contained in the graph consisting of t.ob and t.v  {v }.
1. foreach d ﹋ dom v  
1. foreach ti ﹋ts
1.	
1. foreach ti ﹋ts lb
1. lb.ub
1. ccs+bb
i	 	i
1. lb := max lb lbd 

figure 1: template component caching search with branch and bound and templates. try to compute value  but give up as soon as we discover that value.
where the cache is used only to store the values of fully solved components. hence  default initial bounds are always used when trying to solve an unsolved component  even when the search had computed better bounds in a previous attempt.
﹛the first thing the algorithm does  line 1  is to check if  a  the template contains no variables  in which case it contains only a single objective function that is fully instantiated by the assignments a  hence t a.lb and t a.ub are both equal to the value of the objective onlb
 in which case the required bound cannot be achieved ; or  c 
  in which case the component has al-
ready been fully solved  which actually captures case  a  as well ; in any of these cases the procedure can immediately return.
﹛otherwise we check if it is already known that the component can achieve a higher value than required  lb   line 1. in this case the algorithm is going to compute the component's maximum value  the computation cannot be aborted by bounding   and we can make it more efficient by resetting the lower bound to the higher value. a variable v to split on is then selected  and we determine how the component will decompose when this variable is assigned  line 1. this is done by a combination of template triggering and connected component analysis. once the triggered templates are removed from the constraint graph each remaining connected component forms a new template. any objective of the input template o ﹋ t .o whose only uninstantiated variable was
v forms a template t  with  and.
any instance of this template   will have upper and lower bounds equal to o evaluated at a. the other components  containing variables  will generate new templates upon which automatic symmetry detection is performed. as v is assigned different values  different instances of the templates in ts will be created and solved.
﹛lines 1 and 1  identify the new template instances  components  created by the current value of v . these components are solved in lines 1. we can abandon the assignment v =d  line 1  if at any time the sum of the upper bounds of these componentsfails to reach the required lower bound this sum changes as we compute the component values . we need from each component a value large enough so that if the other components reach their upper bound  the sum will exceed the lower bound required for the input component. this is the value lbi computed at line 1. when we have finished with v =d we compute bounds that can be achieved for the input component under this setting of v   line 1. it could be that these bounds exceed the inputed lower bound  i.e.  lbd   lb. in that case  the algorithm will continue to compute the input component's maximum value  by trying the remaining assignments to v . however  since v = d achieves at least lbd  any new value for v needs to achieve an even higher value  hence we can reset the lower bound  line 1  before attempting the next assignment to v . finally  after all values for v have been tried  we can update the bounds for the input component. note that if the computation succeeded in solving the component  then for some value d of v achieving the maximum we will have lbd = ubd and ubfor all. hence line 1 will set value as required.
constraint propagation. the algorithm can also employ constraint propagation over the hard objectives  the original constraints  to prune domain values that would necessarily lead to values of  ﹢. in particular  domain pruning will simply reduce the iterations we have to perform at line 1  the algorithm requires no other changes. it can be proved that this simple change is all that is needed  but here we provide only the intuition behind the proof.
﹛since the values pruned by constraint propagation violate hard constraints and thus make the sum of the objectives  ﹢  it can be seen that the parts of the search space that are avoided by not branching on the pruned values cannot contain an optimal solution to the cop. thus these pruned parts of the space cannot cause the algorithm to miss an optimal solution.
﹛the other part of the proof is to ensure that the parts of the space that are explored continue to compute the same values when propagation is used  so that overall the search still computes the optimal value. here the key element is showing that cached template values remain correct even when some the domains of its unassigned variables t .v have been reduced by constraint propagation. this can be seen by realizing that the template values correspond to a maximization over all possible assignments of the unassigned variables  subject to some fixed setting of the dependency variables . since pruned values violate hard constraints  the maximum cannot have arisen from any of the pruned values. that is  the maximization over all possible values of the template variables is equal to the maximization over all unpruned values of the template variables  and the cached template values remain correct.
﹛this highlights a subtely in the template algorithm. a template t cannot be triggered if any variable var ﹋ t .v is assigned a value. this is because the maximum value stored in t 's value cache might require that var be assigned a different value. that is  t 's cached values will might not be valid when var ﹋ t .v has been assigned. in contrast  if var's domain has been reduced to a singleton by propagation its value is forced and as we just explained t 's cached values are still valid. in this case t can be triggered. hence  our algorithm must treat variables with singleton domains  after propagation  differently from variables that have been assigned.
1 empirical results
we have implemented our approach and tried it on the maximum density still life problem  mdsl   larrosa  morancho  & niso  1 . this problem involves finding maximum density stable configurations in conway's game of life. in particular  we have a n℅n grid of cells that can be either dead or alive  implicitly surrounded by a boundary of dead cells. a cell is live and stable if it is surrounded by 1 or 1 live cells  it is dead and stable if it is surrounded by any other number of live cells. the goal is to find a stable configuration of the cells that has a maximum number of live cells.
﹛state of the art solvers for this problem  larrosa  morancho  & niso  1  employ an extensive amount of problem specific information. however  our solution is entirely generic; our aim is to use the problem to evaluate the effectiveness of our techniques. we use the most basic representation of the problem with n1 boolean variables  each one representing the alive/dead status of a single cell  n1 unary objective functions  one for each cell  assigning 1 to live cells and 1 to dead cells  and n1 hard objective functions  one for each cell  that assigns 1 to stable settings of the cell given its neighbour's values and  ﹢ to unstable settings.
﹛we solved mdsl using six different algorithms always performing gac constraint propagation on the hard objectives to prune domain values. all experiments were run on a 1 ghz pentium iv with 1gb of memory. the time limit for each run was set to 1 seconds.
﹛the algorithms we tested were.  1  a standard branch and bound algorithm  bb  which uses the variable ordering heuristic of domain size plus degree  both computed dynamically . the remaining algorithms use a heuristic that is biased toward completing rows or columns that have already been started in the grid; this tends to encourage the generation of components. we chose domain plus degree for bb because it performs better with this heuristic.  1  component branch and bound  c+bb . this version searches for components and solves them separately  i.e.  it performs search with decomposition. however  it does not use templates  nor does it cache already solved components.  1  template branch and bound  t+bb  is a template version of c+bb. its only improvement over c+bb is the use of templates to improve component detection. there is no template cache to store bounds for the instances.  1  component caching search + branch and bound  ccs+bb  extends t+bb by activating the template cache to store computed bounds for the instances.  1  symmetric component caching search + branch and bound  sccs+bb  extends ccs+bb by performing automated symmetric detection between templates.  1  asccs+bb which extends sccs+bb to exploit automorphisms as well as symmetries. in particular  automorphisms  also computed by nauty  tell us that different instances of the same template are equivalent  so we can utilize cached instance bounds for all automorphicinstances  as well as for instances of symmetric templates .
sizeasccs+bbsccs+bbccs+bbt+bbc+bbbbnodestimenodestimenodestimenodestimenodestimenodestime1111111111.111.111.111.111.11111.111*1.1.111*1.11*1.1.111*1.1.111*1.1.111*1.1.111*1.1na 1na 1na 11*1.1.11.11na 1na 1na 1table 1: nodes searched and time taken in cpu secs.﹛table 1 shows the relative performance of the six algorithms in terms of nodes searched and time taken. we see that decomposition  c+bb  yields significant improvements over standard branch and bound  bb  decreasing the size of the search tree. for the smaller problems c+bb takes more time  due to its larger overhead  but this overhead is quickly recouped as the problems get large and the reduction in the search tree achieved by decomposition becomes more significant. since t+bb does not employ caching  it does not reduce the size of c+bb's search tree  except for heuristic reasons . but it does provide a non-trivial improvement in efficiency. in particular  t+bb shows that template triggering does improve the efficiency of detecting components. the times in the table show that the overhead of detecting components is non-trivial. ccs+bb makes a further improvement by activating storage of bounds in the template  which results in a significant decrease in the size of the search space over t+bb. there is a correspondingdecrease in time. sccs+bb makes an improvement by performing symmetric detection between templates providing another significant decrease in the size of the search space. asccs+bb performs automorphism detection within a single template in addition to symmetries between template and provides another useful performance gain. we also see that on this problem automated symmetry detection is not adding a significant overhead. that is  the nodes/second search rate with symmetry detection is only 1% less than the search rate without symmetry detection on the largest problem. in all of these cases  the size of the cached information was never a problem. so we did not have to implement any strategy for pruning the cache.
1 conclusions
we have presented an algorithm which incorporates search with decomposition  caching  and symmetric use of the cache  while mitigating much of the computational cost associated with such techniques. component templates reduce the costs associated with dynamically finding components  and also offer effective and efficient caching during search. templates also allow us to use symmetries detected during search to make more effective use of previous computations.
references
 amir & mcilraith  1  amir  e.  and mcilraith  s. 1. partition-based logical reasoning. in proceedings of the international conference on principles of knowledge representation and reasoning  1.
 bacchus  dalmao  & pitassi  1  bacchus  f.; dalmao  s.; and pitassi  t. 1. algothims and complexity results for sat and bayesian inference. focs 1-1.
 bayardo & pehoushek  1  bayardo  r. j.  and pehoushek  j. d. 1. counting models using connected components. in proceedings of the aaai national conference  aaai   1.
 darwiche  1  darwiche  a. 1. recursive conditioning. artificial intelligence 1-1.
 dechter  1  dechter  r. 1. and/or search spaces for graphical models. technical report  school of information and computer science  university of california  irvine.
 larrosa  morancho  & niso  1  larrosa  j.; morancho  e.; and niso  d. 1. on the practical applicability of bucket elimination: still-life as a case study. journal of artificial intelligence research 1-1.
 marinescu & dechter  1  marinescu  r.  and dechter  r. 1. advances in and/or branch-and-bound search for constraint optimization. in workshop on p