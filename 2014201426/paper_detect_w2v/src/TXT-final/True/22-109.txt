ion in problem solving and learning* 
　
a m y unruh 
computer science dept. stanford university 
1 welch rd.  bldg. c palo alto  ca 1 
abstract 
abstraction has proven to be a powerful tool for controlling the combinatorics of a problemsolving search. it is also of critical importance for learning systems. in this article we present  and evaluate experimentally  a general abstraction method - impasse-driven abstraction which is able to provide necessary assistance to both problem solving and learning. it reduces the amount of time required to solve problems  and the time required to learn new rules. in addition  it results in the acquisition of rules that are more general than would have otherwise been learned. 
1 	introduction 
abstraction has proven to be a powerful tool for controlling the combinatorics of a problem-solving search  korf  1 . problem solving using abstract versions of tasks can provide cost-effective search heuristics and evaluations for the original  or  full   tasks which significantly reduce their computational complexity  and thus make large problems tractable  gaschnig  1  kibler  1  pearl  1  valtorta  1 . 
　abstraction is also of critical importance for learning systems. creating abstract rules can reduce the cost of matching the rules  thus improving their operationality  keller  1  zweben  1 . abstract rules can transfer to a wider range of situations  thus potentially increasing their usability and utility. abstract rules may also bo easier and/or cheaper to create  thus simplifying the learning process and/or making it more tractable. 
　in this article we are concerned with abstraction techniques that assist in both problem solving and learning. 
   *we would like to thank john laird and rich keller for providing valuable ideas and discussions about this research  and gregg yost for his help in re-conceptualizing and rewriting rl-soar. this research was sponsored by the hughes aircraft company artificial intelligence center  and by the defense advanced research projects agency  dod  under contract number n1c-1. the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies  either expressed or implied  of the hughes aircraft company  the defense advanced research projects agency  or the us government. 
paul s. rosenbloom 
information sciences institute 
university of southern california 
1 admiralty way 
marina del rey  ca 1 
the four key requirements such a technique should satisfy are: 
1. apply in any domain. 
1. reduce problem solving time. 
1. reduce learning time  therefore help in intractable domains . 
1. increase the transfer of learned rules. 
　the first requirement implies that the technique must be a general weak method that is applicable to domains without additional domain-specific knowledge about how to perform the abstraction. most problem solvers that utilize abstractions do so only when the appropriate ab-
stractions have been prespecified for them. the second requirement implies that  on average  the time to solve problems with abstraction should be less than the time without. implicit in this requirement is also that this should be true even if only one problem is being solved; that is  abstraction should help immediately  on the first problem seen in the domain. the third requirement implies that abstraction should be integral to the rule creation process. if the problem-solving time necessary to learn a rule is to be reduced  an approach that simply abstracts the output of the normal learning algorithm will not be sufficient. the fourth requirement implies that abstraction should result in the creation of generalized rules. even if the rule creation process is a justified method  such as explanation-based learning  mitchell et a/.  1   this can lead to a form of unjustified induction  though a useful one . 
　in this article we describe and evaluate an abstraction method which meets these four requirements. the following sections provide a description of the basic method  a discussion of how abstraction propagates through a problem  experimental results from an implementation of the method in two domains  and a set of conclusions and future work. 
1 	the abstraction method 
the abstraction method is based on the integration of learning and problem solving found in the soar system  laird et a/.  1 . in soar  problems are solved by search in problem spaces. decisions are made about how to select problem spaces  states  and operators  plus how to apply operators to states to yield new states  operator implementation . decisions are normally based on 
	unruh and rosenbloom 	1 
　
knowledge retrieved from memory by the firing of productions. however  if this knowledge is inadequate  an impasse occurs  which the system then tries to resolve by recursive search in subgoals. this leads to hierarchical processing in which control decisions can be based on multiple levels of look-ahead searches  and complex operators can be implemented by multiple levels of simpler operators  an operator aggregation hierarchy . learning occurs by converting subgoal-based search into rules that generate comparable results under similar conditions. this chunking process is a form of explanationbased learning in which the explanation is derived from a trace of the search that led to the results of the subgoal  rosenbloom and laird  1 . 
　abstraction occurs in this framework in the service of control decisions. if an impasse occurs because of a lack of knowledge about how to make a selection  the resulting search is performed abstractly. consider a simple example from a toy robot domain. suppose that among the operators in the domain are ones that allow a robot to push a box to a box  push-box-to-box box1x1   and go to a box  goto box  . the preconditions of the push-box-to-boxoperator are that the robot is next to the first box and that the boxes are in the same room. the precondition of the goto operator is that the robot is in the same room as the box that it wants to reach. the goal is to reach a state where the two boxes   b o x l and box1  are next to each other. in the initial state  the robot and the two boxes are in the same room together  but at different locations. 
　given this initial state  a control decision must be made that will result in the selection of an operator. with partial means-ends control knowledge  encoded as rules   the system can determine that the push-box-tobox boxl box1  operator is one of the possible alterna-
tives  but it may not be able to eliminate all of the other alternatives  leading to an impasse  and thus a subgoal. in the subgoal  a search will be performed by trying out each alternative until one is found that leads to the goal. when the push-box-to-box operator is tried  it will fail to apply because one of its preconditions - that the robot is next to the first box - is not met. however  if this precondition is abstracted away  then the operator can apply abstractly  as the robot itself couldn't actually do this and the goal of the abstract search will be achieved. from this abstract search  the information that the push-box-to-box operator is the right one to select is returned  and used to make the original control decision. simultaneously  a control rule is learned which summarizes the lesson of the abstract search. figure 1 illustrates this process. 
　though the basic idea of abstracting within control searches is simple  its consequences are far-reaching. one consequence is that the abstract search is likely to be shorter than the full search would have been because less now needs to be done. if the abstract searches are shorter  yet still return adequate control knowledge  then the time to solve the problem will be reduced  requirement 1  - as in the toy robot example. additional consequences arise because learning occurs via the chunking of subgoal-based search. if chunking is done over an abstract search  then the time required to learn about the task is reduced because of the reduced time to generate the explanation  req. 1 . in addition  because abstract searches lead to abstract explanations  the rules acquired by chunking abstract searches will themselves be abstract  and thus be able to transfer to more situations  req. 1 . these generalized control rules effectively form an abstract plan for the task. though these rules may not always be completely correct  limiting abstraction to control decisions ensures that unjustified abstractions will not lead to incorrect behavior - control knowledge in the soar framework affects only the efficiency with which a goal is achieved  not the correctness. 
　the actual abstraction of the control search occurs by impasse-driven abstraction. when an impasse occurs during the control search  it is resolved by making an assumption  instead further problem solving in another level of subgoals. impasse-driven abstraction belongs to the general class of abstractions that involve removing  or abstracting away  some aspects of the problem in question.  in the taxonomy provided by  doyle  1   our techniques fall under the category of approximation.  for example  in the toy robot example above  
when the precondition of the push-box-to-box operator failed during the control search  leading to an impasse  the system simply assumed that the precondition was met  and continued the abstract search as best it could.  another way of looking at this is that the system didn't care if the precondition was met . without abstraction  
　

1 	machine learning 
　
the impasse would lead to a subgoal in which the system would search for a state to which the operator could legally apply  by applying the goto operator . 
　impasse-driven abstraction is a general technique that can be applied to arbitrary domains without domainspecific abstraction knowledge; that is  it is a general weak method  requirement 1 . with it  the default abstraction behavior for the problem solver is to abstract away those parts of an operator which are not already compiled into rules  and which therefore generate impasses and require subgoals to achieve. this behavior results in abstraction of operator preconditions and abstraction of operator implementations. the former leads to a form of abstraction similar to that obtained in abstrips  sacerdoti  1   while the latter leads to behavior that is best described as successive refinement  stefik  1 . as an example of the latter  consider what happens when there is a complex operator for which a complete set of rules does not exist a priori about how to perform it. when such an operator is selected  some rules may fire  but an impasse will still occur because of what is left undone. without abstraction the system would enter a subgoal where it would complete the implementation by a search with a set of sub-operators. with abstraction  the system assumes that what was done by the rules was all that needed to be done. it then proceeds from the abstract state produced by this abstractoperator implementation. 
　another way to understand what impasse-driven abstraction is doing is to look at its effect on the explanation structure created as a byproduct of abstract search  and upon which the learning is based . figure 1 shows a simplified version of the explanation structure for the toy robot example. without abstraction  the rule learned from this explanation is: 
operator is push-box-to-box b1  b1  a 
in~same-room bl b1  a in-same-room bl robot  a 
　  n e x t - t o   b l   r o b o t   =  goal success. 
with abstraction  information that would normally be needed for the generation of the result is essentially ignored  and some subtrees of the unabstracted explanation tree - the circled substructure in the figure - no longer need to be expanded for the goal to be  proved .  another way of looking at this is that some nodes in the proof tree are effectively replaced with the value true. alteration of a proof tree in this manner has been proposed by  keller  1  as a method of forming approximate concepts.  the abstracted rule becomes: 
operator is push-box-to-box bl  b1  a in-same-room bl  b1  =  goal success. 
alteration of the explanation structure in this way has made the rule more general  and thus able to apply to a larger number of situations. 
　the same abstraction techniques extend  with no additional mechanism  to multi-level abstraction of both preconditions and implementations. the levels of refinement grow naturally out of the dynamic hierarchy of subgoals that are created during problem solving. consider multi-level precondition abstraction  for example. in the toy robot problem above  the abstract search that was performed was at the most abstract level - the search was cut off at the highest level of precondition subgoals. once this search is done  and the push-box-to-box operator is selected  it is necessary to do another search to determine what sequence of operators will satisfy its preconditions. in this particular example  the goto operator would be among the candidates. here no impasse of the goto operator application would occur  because its preconditions are already met. however  if an impasse did occur during this new search  it would lead to abstraction in the search. this new abstract search is one level more detailed than was the original one. the same cycle continues until a complete plan is generated in which nothing has been abstracted. 
　note that there is nothing in the impasse-driven abstraction techniques which prevents the problem solver from making use of additional domain-specific knowledge about what to abstract. the existence of such knowledge can certainly improve performance. however  domainspecific  abstraction knowledge is not often available. if it is not  then the impasse-driven techniques  as a weak method  are able to provide useful abstract problemsolving behavior when it would not otherwise have been possible. 
1 abstraction propagation 
thus far  we have presented the effects of impasse-driven abstraction on problem solving and learning. however  this is only part of the picture. an important feature 
	unruh and rosenbloom 	1 
of impasse-driven abstraction is the way in which the abstraction occurs dynamically during problem solving. each time an impasse occurs during a control search  some aspect of the problem gets abstracted. however  these bits of abstraction initially happen only locally - 
just because part of one particular operator application gets abstracted during one search step does not necessarily mean that the rest of the problem space will automatically be abstracted in a compatible fashion. once some part of a problem has been abstracted away  the effects must be propagated to later aspects of the problem  including the goal test. consider  for example  what would happen if the goal in the toy robot domain was to have two boxes adjacent and in the same room  but all of the  in-room  information in the problem space was abstracted away. if the  full   non-abstract goal test was used during abstract search  it would never succeed  and the abstract search would never terminate  unless all options became exhausted  or some monitoring process decided to kill it . it would be more desirable if the goal test of the abstract search was to be compatibly abstracted  so that it cared only about whether the two boxes were adjacent. 
　the general approach that we have taken is to develop a set of restrictions on the construction of problem spaces which  if followed  ensure appropriate propagation of the abstraction. the two restrictions -- problem-space factorization and assumption-based goal tests - do not limit what can be expressed  only how it is expressed. 
　a problem space is factored if it is designed so that the descriptions of problem space components  states  operators  or goals  are separated into any independent subparts which compose them; for example  by creating one production per sub-part. when problem-space components are factored  they may still be partially applicable to the task at hand  even if some of the problem-space knowledge is missing or ignored. for example  if an operator is composed of a number of sub-actions  and if each sub-action is described separately  some of the subactions may be able to apply even though there is not enough information available to allow the operator to apply in its entirety. in this way the operator applies abstractly. 
　for an example of operator factorization  consider the following simplified  robot domain  operator  which moves a robot through a door to a new room  and in the process keeps track of how many robots are currently in each room. the operator's preconditions are not shown here. if it is true that the operator  may apply   its preconditions are either met or have been ignored through abstraction. unfactored  the operator is: 


　thus  if information about the number of robots in either room is not available  the rest of the operator can still apply. additionally  if because of abstraction the previous location of the robot was unknown  it can still be  moved  to its new room. factorization enables abstract problem-solving behavior to be propagated dynamically; whatever can be done will be done  while what can't be done because of previously abstracted information is simply ignored. then  when part of a process is ignored  this in turn may cause new problem-space information to become abstracted.  there is some indication that factorization is not specifically an abstraction issue - if a problem space is factored  then more generalized learning can occur regardless of whether or not abstraction takes place . note that a factorization determines what may be abstracted in a problem space - the set of possible abstractions. it is the impasses that arise during problem solving which determine what actually is abstracted. 
　assumption-based goal testing refers to the problemsolver's ability to make assumptions about whether or not goals have been achieved during abstract problem solving. to do this  it is necessary to be able to detect that a goal has not been met  in addition to being able to detect that it has been met. under normal circumstances  the problem solver has enough information about a state to determine one or the other; that is  that the state either does or does not achieve the goal. however  when the problem is abstracted  neither test may succeed. under these conditions  the problem solver needs to make a default assumption as to whether the goal is met or not. such default assumptions can 
　
1 	machine learning 
　
be made about a goal as a whole  or if it is factored  about individual conjuncts of the goal. to do this properly  the problem solver needs to be supplied with additional information about which goals  and goal conjuncts  should be assumed true and which should be assumed false. rare termination conditions  for example  should be assumed by default to be unmet. this additional assumption information is not knowledge about what to abstract  or any particular abstraction. rather  it plays a part in determining the behavior of the system 
　
once abstraction has occurred. 
　the restrictions which support abstraction propagation are independent of what is abstracted  or what is expected to be abstracted. in fact  they are independent of whether problem information is missing because of deliberate abstraction  or because of some other reason  such as bad instrument readings  etc. . therefore  the problem spaces in which these restrictions have been followed could provide a more robust support for problem solving in noisy domains  and make assumptions based on the best data at hand  regardless of whether or not abstraction is deliberately used. 
1 experimental results 
experiments have been run with impasse-driven abstraction in two distinct task domains: a strips-like robot domain and a computer-configuration domain  ri-soar   rosenbloom et a/.  1 . the robot domain is similar to the one in the example presented earlier  but slightly more complicated: there are two robots and two rooms  with two doors between them  as well as two boxes. the rl-soar computer-configuration domain was based on a re-implementation of a portion of the classic ri expertsystem  mcdermott  1 . the two domains were chosen because they cover both a classical search/planning domain  the robot domain  and a classical expert system domain  computer configuration . moreover  the domains also differ in that the robot domain stresses abstractions based on operator preconditions  while the rl-soar domain stresses abstractions based on operator implementations. 
   to achieve further variation  two different problems were run in the robot domain  with the same goal  but with different initial states. in both problems the con-
junctive goal was to have the two boxes pushed next to each other  and to have the two robots  shake hands   to do this the robots had to be next to each other . the key difference in the initial states was that in the second problem one of the doors was locked  and there was no key.  this second problem should cause some additional complexity if the system abstracts away whether the doors are unlocked.  for each problem  the amount of search-control knowledge that was directly available to the problem solver was also varied. in one version  the problem solver started with means-ends knowledge that allowed it to directly recognize which operators helped solve which subgoals. in the other version  the problem solver could detect when a subgoal had been solved  but knew nothing directly about which operators helped solve which subgoals. in the rl-soar domain  two computer-configuration problems were also run. once again  the goal was the same - to have a configured computer - but the initial states were varied. 
   the problem spaces for these domains were designed according to the restrictions discussed in section 1. the key issues to be addressed by these experiments are the degree to which irnpasse-driven abstraction meets the four abstraction requirements presented in the introduction. 
   the first requirement was that the method should be applicable in any domain. the evidence to date is that 

the abstraction method has been applied to these two quite different domains. in both domains it was possible to apply the impasse-driven abstraction techniques. in the robot domain it was not necessary to add any abstraction-specific knowledge. w i t h rl-soar  it turned out that although the method was applicable  it was necessary to add a small amount of additional knowledge about the abstraction  to prevent random behavior. rl-soar is designed so that complex operators are implemented by multiple levels of simpler operators  to form an operator aggregation hierarchy. if abstraction occurred at the level of the top operator  then there was not enough information remaining in the problem space  all configuration work occurred in lower subgoals  to make an informed control decision. that is  the decisions became random. therefore  we instructed the problem-solver not to abstract at the top level in r l soar. default abstraction behavior at other levels of the operator hierarchy was not affected. it would be preferable for the problem-solver to be able to determine more intelligently  through experimentation  and the current amount of chunked vs. unchunked knowledge in the system   a useful level at which to begin abstraction. we are currently working on an abstraction method which builds on the impasse-driven abstraction techniques  and allows the problem solver to make such a determination. 
   the second requirement on the abstraction method was that abstraction should reduce the problem solving time required. table i shows the number of decisions that the problem solver required to solve each of the problems  and the ratio of the performance with abstraction to that without1. because several of the problems were completely intractable  an arbitrary cutoff was set at 1 decisions. 
   the overall trend revealed by these results is that abstraction does reduce the problem solving time  when measured in terms of number of decisions. moreover  the harder the problem  in terms of the amount of search required without abstraction  the more abstraction helps. even in the second robot problem  where the problem solver does indeed abstract away the test of whether it can get through the locked door  abstraction helps. it 
1
　　in the rl-soar runs  a few chunks learned were altered to avoid problems generated by the way the current version of soar copies information to new states. this difficulty is unrelated to the abstraction issues  and will be fixed in the next version of soar. 
	unruh and rosenbloom 	1 
　
turns out that this abstraction does not make the problem solver noticeably less efficient when doors are locked  since when it does not use abstraction it is still forced  during its search  to go to the door and try to open it before it realizes this is not possible. what abstraction was not able to do was to make all of the intractable tasks tractable. 
　hidden in the rl-soar numbers is another interesting phenomenon. in problem 1  abstraction reduced the amount of time required to generate a configuration  but the configuration was not as good as the one generated without  abstraction. the goal test for rl-soar is that there be a complete and correct configuration. not tested is the cost of the configuration. instead  rl-soar uses control knowledge to guide it through the space of partial configurations so that the first complete configuration it reaches is likely to be a cheap one. this use of control knowledge to determine optimality is a soft violation of the constraint that control knowledge not determine correctness  and thus abstraction can  and does  have a negative impact on it. a recoding of rl-soar to incorporate optimality testing into the goal test could avoid this  or it could simply be lived with as an effort/quality trade-off. 
　to return to requirement 1  the normal assumption in soar is that the time per decision is fairly constant  so the decision numbers should be directly convertible into times. however  it turns out that decisions for deep searches are considerable more expensive than ones for shallow searches because of the amount of additional information in the system's working memory. table 1 shows the actual problem solving times for the two r l soar problems  with and without abstraction. these numbers show that when actual run times are compared  the advantage of abstraction is even greater. 
　the third requirement was that abstraction should reduce the time required to learn. to evaluate this  we need to look at how long it takes to acquire control chunks  with and without abstraction. table 1 presents the relevant data. it shows the number of decisions that occurred before the control chunk for the first operator tie was learned  for one robot problem and one rl-soar problem. in both cases  abstraction greatly reduced the amount of effort required before the control rule could be learned. 
　the fourth requirement was that abstraction should increase the transfer of learned rules. rather than evaluate transfer directly  what we shall do is illustrate this effect by comparing a corresponding pair of abstract and non-abstract chunks from the robot domain  figure 1 . the two have identical tests up to a point; however  the non-abstract chunk cares whether the robot is next to the box to be pushed  and whether the robots  rooms  and 
1 	machine learning 
doors are arranged so that the robots will later be able to get together to shake hands. these extra conditions limit the domain of applicability of the non abstract rule with respect to the abstract rule. 
　together these experimental results provide support  though not yet conclusive support  for the ability of impasse-driven abstraction to meet the four key requirements on an abstraction method. 
1 conclusions and future work 
in earlier work we showed how an abstraction  once chosen  could be made to dynamically propagate through a problem space  unruh et a/.  1 . in this article we have built on that work  by turning it into a general weak method that does not require manual specification of how the problem spaces and goal tests are to be abstracted; the key ideas being impasse-driven abstraction and restrictions on problem space construction. we have also shown how this technique can yield multi-level abstraction and successive refinement. 
　another important way that the earlier results have been extended is by the performance of a set of experiments in two task domains. these experiments provided evidence for the satisfaction of four key requirements on an abstraction mechanism: that it should be applicable in any domain  that it should reduce problem solving time  that it should reduce learning time  and that it should increase the transfer of learned rules. however  in the rl-soar domain  the problem solver was provided with additional abstraction knowledge beyond the default which prevented it from abstracting at the highest level of the domain's operator hierarchy. this knowledge was necessary to make the abstraction useful; it prevented random control decisions stemming from too little information. 
　despite progress with the general weak method presented here  a number of issues remain to be addressed. the most important issue is how the weak method can be strengthened by using additional knowledge about domains and their abstractions. impasse-driven abstraction does appear to be a plausible technique to use in many situations. due to the experiential nature of chunking  those parts of the problem space that are familiar will be encoded as compiled knowledge  and thus won't generate the impasses which initiate abstractions. if the heuristic holds that  familiar  is  important   the default abstraction behavior may be quite useful. 
　but because the current method is weak  there must  be many circumstances in which it will not cause the most appropriate behavior to occur. we plan to try to use the combination of the weak method and experiential learning  chunking  to bootstrap the system to a richer theory of abstractions by learning about the utility of the abstractions that the system tries. one promising avenue of current research is the technique referred to in section 1  by which the system tries to determine through experimentation a helpful level of abstraction for a given problem context. there are many other ways to learn about an abstraction's utility as well. one possibility is empirical observation over a sequence of related tasks. alternatively  the problem solver might notice that an abstraction has caused a problem in a particular context  and  explain  to itself why this is the case  using its domain knowledge  failure-driven refinement of the abstraction  theory .  a final option would be for the problem solver to analyze its domain  if it has time to do so  and attempt to come up with a partially pre-processed abstraction theory  as in  benjamin  1  ellman  1  knoblock  1  tenenberg  1 . 
　a second item of future work is the extension of the experiments  both in breadth and depth. we will be looking at abstraction in a number of domains  and trying to empirically evaluate how domain characteristics impact the utility of abstraction. 
　a final item will be to evaluate the extent to which the restrictions on problem space construction presented in section 1 can improve the robustness of problem solving in noisy domains. 
