 
	polynomial 	time 	complexity 	is 	the 	usual 
'threshold' for distinguishing the tractable from the intractable and it may seem reasonable to adopt this notion of tractability in the context of knowledge representation and reasoning. it is argued that doing so may be inappropriate in the context of common sense reasoning underlying language understanding. a more stringent criteria of tractability is proposed. a result about reasoning that is tractable in this stronger sense is outlined. some unusual properties of tractable reasoning emerge when the formal specification is grounded in a neurally plausible architecture. 
1 	introduction 
understanding language is a complex task. it involves among other things  carrying out inferences in order to establish referential and causal coherence  generate expectations  and make predictions. nevertheless we can understand language at the rate of several hundred words per minute  carpenter and just  1 . this rapid rate of language understanding suggests that we can  and do  perform a wide range of inferences very rapidly  automatically and without conscious effort - as though they are a reflex response of our cognitive apparatus. in view of this such reasoning may be described as reflexive  shastri  1 . 
   as an example of reflexive reasoning consider the sentence 'john seems to have suicidal tendencies  he has joined the columbian drug enforcement agency.' we can understand this sentence spontaneously and without any deliberate effort even though  doing so involves the use of background knowledge and reasoning. informally  this reasoning may be as follows: joining the columbian drug enforcement agency has dangerous consequences  and as john may be aware of this  his decision to join the agency suggests that he has suicidal tendencies. as another example of reflexive reasoning consider the inference 'john owns a car' upon hearing 'john bought a rolls-royce'. we can make this inference effortlessly 
   *this work was supported by nsf grants iri 1 and the aro grant daal 1-c-1. 
1 	cognitive modeling 
even though it requires multiple steps of inference using background knowledge such as rolls-royce is a car and if x buys y then x owns y. 
   not all reasoning is  and as complexity theory tells us  cannot be  reflexive. we contrast reflexive reasoning with reflective reasoning - reasoning that requires reflection  conscious deliberation  and at times  the use of external props such as paper and pencil  e.g.  solving logic puzzles  doing cryptarithmetic  or planning a vacation . 
1 reflexive reasoning necessitates a strong notion of tractability 
in order to quantify the notion of reflexive reasoning introduced above  let us make a few observations about such reasoning. 
  reflexive reasoning occurs with respect to a large body of background knowledge. a serious attempt at compiling common sense knowledge suggests that our background knowledge base may contain as many as 1 to 1 items  guha and lenat  1 . this should not be very surprising given that this knowledge includes  besides other things  our knowledge of naive physics and naive psychology; facts about ourselves  our family  friends  colleagues  history and geography; our knowledge of artifacts  sports  art  music; some basic principles of science and mathematics; and our models of social  civic  and political interactions. 
  items in the background knowledge base are fairly stable and persist for a long-time once they are acquired. hence this knowledge is best described as long-term knowledge and we will refer to this body of knowledge as the long-term knowledge base  ltkb . 
  episodes of reflexive reasoning are triggered by 'small' inputs. in the context of language understanding  an input  typically  corresponds to a sentence that would map into a small number of assertions. for example  the input 'john bought a rolls royce' maps into just one assertion  or a few  depending on the underlying representation . the critical observation is that the size of the input   in   

is insignificant compared to the size of the long-term knowledge base   l t k b   1 
  the vast difference in the magnitude of   l t k b    about 1  and  in   a few  becomes crucial when analyzing the tractability of common sense reasoning. given the actual values of  in  that occur during common sense reasoning  there is a distinct possibility that the overall cost of a derivation may be dominated by the  fixed  contribution of   l t k b l . thus we cannot ignore the cost attributable to   l t k b   and we must analyze the complexity of reasoning in terms o f   l t k b   as well as  in . 
   in view of the magnitude of   l t k b     even a cursory analysis suggests that any inference procedure whose time complexity is quadratic or worse in   l t k b   cannot provide a plausible computational account of reflexive reasoning. however  a process that is polynomial in  in  remains viable. 
1 t i m e c o m p l e x i t y of reflexive reasoning 
observe that although the size of a person's   l t k b   increases considerably from  say  age seven to thirty  the time taken by a person to understand natural language does not. this suggests that the time taken by an episode of reflexive reasoning does not depend on the   l t k b   . in view of this it is proposed that a realistic criteria of tractability for reflexive reasoning is one where the time taken by an episode of reflexive reasoning is in-
dependent of   l t k b   and only depends on the depth of the derivation tree associated with the inference.1 
1 space c o m p l e x i t y of reflexive reasoning 
the expected size of the l t k b also rules out any computational scheme whose space requirement is quadratic  or higher  in the size of the kb. for example  the brain has only about 1 cells most of which are involved in processing of sensorimotor information. hence even a linear space requirement is fairly generous and leaves room only for a modest 'constant of proportionality'. in view of this  it is proposed that the admissible space requirement of a model of reflexive reasoning be no more than linear in   l t k b   . 
　to summarize  it is proposed that as far as  reflexive  reasoning underlying language understanding is con-
1
　　a small input may  however  lead to a potentially large number of elaborate inferences. for example  the input 'john bought a rolls-royce' may generate a number of reflexive inferences such as 'john bought a car'  'john owns a car'  'john has a driver's license'  'john is perhaps a wealthy man'  etc. 1
　　some of these inferences may be 'soft' inferences  but the issue of deductive versus evidential nature of inferences is irrelevant to our current concerns. 
1
　　the restriction that the reasoning time be independent of  ltkb  may seem overly strong and one might argue that perhaps logarithmic time may be acceptable. our belief that the stronger notion of effectiveness is relevant  however  is borne out by results which demonstrate that there does exists a class of reasoning that can be performed in time independent of  ltkb . 
cerned  the appropriate notion of tractability is one where 
  the reasoning time is independent of   l t k b   and is only dependent on  in  and the depth of the derivation tree associated with the inference  and 
  the associated space requirement  i.e.  the space required to encode the l t k b plus the space required to hold the working memory during reasoning should be no worse than linear in   l t k b   . 
   in spite of the apparent significance of reflexive reasoning there have been very few attempts at developing a computational account of such inference. some past exceptions being fahlman's work on n e t l  and shastri's work on a connectionist semantic memory . however these models dealt primarily with inheritance and classification within an is~a hierarchy. holldobler  l 1  and ullman and van gelder  nave proposed parallel systems for performing quite complex logical inferences  however  both these systems have unrealistic space requirements. the number of nodes in holldobler's system is quadratic in the the size of the knowledge base  kb  the number of processors required by ullman and van gelder is even higher. ullman and van gelder treat the number of nodes required to encode the background kb as a fixed cost  and hence  do not refer to its size in computing the space complexity of their system. if the size of such a kb is taken into account  the number of processors required by their system turns out to be a high degree polynomial. 
   a significant amount of work has been done by researchers in knowledge representation and reasoning to identify classes of limited inference that can be performed efficiently  e.g.  see  frisch and allen  1 ; 
 brach man and levesque  1 ;  patel-schneider  1 ;  dowling and gallier  1 ;  levesque  1 ;  selman and levesque  1 ;  mc a hester  1 ;  bylander et a/.  1 ;  kautz and selman  1  . this work has covered a wide band of the complexity spectrum but none that meets the strong tractability requirement discussed above. most results stipulate polynomial time complexity  restrict inference in implausible ways  e.g.  by excluding chaining of rules   and/or deal with limited 
expressiveness  e.g.  deal only with propositions . 
1 	a tractable reasoning class 
below we describe a class of reasoning that is tractable with reference to the criteria stated above. the characterization of such a class is different  but analogous  for forward and backward reasoning. in this paper we will focus on backward reasoning. 
some definitions: 

	shastri 	1 


facts are partial or complete instantiations of predicates. thus facts are atomic formulae of the form where t a are either constants or distinct existentially quantified variables. 
queries have the same form as facts. let us distinguish between yes-no queries and wh-queries. a query  all of whose arguments are bound to constants corresponds to the yes-no query: 'does the query follow from the rules and facts encoded in the long-term memory of the system * a query with existentially quantified variables  however  has several interpretations. for example  the query p a  x   where a is a constant and x is an existentially quantified argument  may be viewed as the yes-no query: 'does p a x  follow from the rules and facts for some value of x ' alternately this query may be viewed as the wh-query: tor what values of x does p a x  follow from the rules and facts in the system's long-term memory ' d 
consider a query q and a l t k b consisting of facts and balanced rules. a derivation of q obtained by backward chaining is threaded if all pivotal variables occurring in the derivation get bound and their bindings can be traced back to the bindings introduced in q. 
given a l t k b consisting of facts and balanced rules  a reflexive query is one for which there exists a threaded 
proof. 
1 	a class of t r a c t a b l e reasoning 
the worst-case time for answering a reflexive yes-no query  q  is proportional to  where: 
   is the number of distinct constants in q. 
  v is as follows: let vi be the arity of the predicate 
pi. then v equals  ranging over all the predicates in the l t k b . 
  d equals the depth of the shallowest derivation of q given the l t k b . 
   observe that the worst-case time is i  independent of  ltkb   ii  polynomial in  in  and iii  only proportional to d. 
   as observed in section 1  while  ltkb  may be as much as   in  is simply the number of  distinct  'entities' referred to in the input. in the context of natural language understanding   in  would be quite small  typically  less than 1 . we also expect v  the maximum arity of predicates in the l t k b to be quite small. 
1 	cognitive modeling 
　an answer to a wh-query can also be computed in time proportional to d  except that  in  now equals the arity of the query predicate q. 
　the space requirement is linear in  ltkb  and polynomial in  in . this includes the cost of encoding the ltkb as well as the cost of maintaining the dynamic state of the 'working memory' during reasoning. 
an informal explanation of the result 
the number of times a predicate p may get instantiated in a threaded derivation of a query cannot exceed this follows from the observation that p has at most v arguments and each of these can get bound to at most  in  distinct constants. since each predicate instantiation can contain at most v bindings  the propagation of argument bindings from one predicate to another can be carried out in time proportional to . this assumes that the correspondence  specified by the rules in the ltkb  between the arguments of the antecedent and consequent predicates are hard-wired. 
　it can be shown that the propagation of argument bindings from multiple predicates to a predicate can be carried out in parallel  see  mani and shastri  1  for a possible implementation of such a parallel binding propagation scheme . this means that the time required to carry out one step of a parallel breadth-first derivation is only proportional to  . it follows that the time required to carry out a d step parallel derivation is proportional to 
lower bound nature of above result 
　in general  derivations that involve unbalanced rules or those that do not satisfy the threaded property cannot be computed in time independent of  ltkb   if the available space is no more than linear in  ltkb   dietz et al  1 . this result follows from the observations that i  the common-element problem  i.e.  the problem of determining whether two sets share a common element  can be reduced to the problem of computing a derivation involving unbalanced rules and/or non-threaded derivations  ii  the sorting problem can be reduced to the common-element problem  and iii  the lower bound on the sorting problem is nlogn  where n would correspond to  ltkb  . thus derivations involving unbalanced rules and non-threaded derivations may not be computed in time independent of  ltkb  unless one makes use of more than linear space. 
1 	worst-case versus e x p e c t e d case 
the above result offers a worst-case characterization which assumes that during the derivation  all variables will get instantiated with all possible bindings involving constants in q. this will not be the case in a typical situation. in fact it may be conjectured that in a typical episode of reasoning  the actual time will seldom exceed 1d  see next section . 

1 a neurally motivated model of tractable reasoning 
we have proposed a neurally plausible model  shruti  that can encode a l t k b of the type described above  together with a term hierarchy and perform a class of forward as well as backward reasoning with extreme efficiency  shastri and ajjanagadde  1 ;  ajianagadde and shastri  1 ;  mani and shastri  1 ;  mani and shastri  1 ;  shastri  1 . shruti can draw inferences in time that is only proportional to the depth of the shallowest derivation leading to the conclusion. a shruti like model has also been used by henderson  to design a parser for english. the parser's speed is independent of the size of the lexicon and the grammar  and it offers a natural explanation for a variety of data on long distance dependencies and center embedding. 
   if we set aside shrutus ability to perform terminological reasoning  the class of reasoning that shruti can perform efficiently is a subclass of the class of reasoning specified in the previous section. the additional restrictions placed on shruti's reasoning ability are motivated by gross constraints on the speed at which humans can perform reflexive reasoning and gross neurophysiologies parameters such as: 
1.   the maximum period at which nodes can be expected to sustain synchronous activity  
1. w  the tolerance or the minimum lead/lag that must be allowed between the spiking of two nodes that are 
firing in synchrony  
1. the time it takes a cluster of synchronous nodes to drive a connected cluster of nodes to fire in synchrony. 
   the details of the model are beyond the scope of this paper and the reader is referred to  shastri and ajjanagadde  1 . let us however  state the additional constraints on the class of reasoning shruti can perform. 
1 a d d i t i o n a l constraints o n t h e reasoning p e r f o r m e d b y s h r u t i 
shruti can encode a l t k b of facts and balanced rules and answer yes to any reflexive yes-no query in time proportional to the depth of the shallowest derivation leading to a derivation of the query provided: 
1. the number of distinct constants specified in the query does not exceed k1  where k  is bounded by 
  biological data suggests that k1 is small  perhaps between 1 and 1 . 
the model suggests that as long as the number of entities introduced by the query is 1 or less  there will essentially be no cross-talk among the facts inferred during reasoning. if more than 1 entities occur  the window of synchrony would have to shrink appropriately in order to accommodate all the entities. as this window shrinks  the possibility of crosstalk between bindings would increase until eventually  the cross-talk would become excessive and disrupt the system's ability to perform systematic reasoning. the biological data suggests that a neurally plausible upper bound on the number of distinct entities that can occur in the reasoning process is about 1. of course  these entities may occur in multiple facts and participate in a number of inferences. it may be significant that the bound on the number of entities that may be referenced by the active facts during a derivation relates well to 1 ＼ 1  the robust measure of short-term memory capacity  miller  1 . note however  that shruti does not place a small limit on the number of facts that can be simultaneously active - indeed a very large number of facts can be involved in each derivation carried out by shruti. 
1. during the processing of the query  each predicate may only be instantiated at most k1 times. note that this restriction only applies to run-time or 'dynamic' instantiations of predicates and not to iong-term' facts stored in the system. as argued in  shastri  1  a plausible values of k1 is somewhere between 1. also  k1 need not be the same for all predicates. the application of a shrutl-like model to parsing by henderson also suggests that a value of k1 under 1 may be sufficient for parsing english sentences. 
some t y p i c a l retrieval a n d inference t i m i n g s 
if we set system parameters of shruti to some neurally motivated values  shruti demonstrates that a system made up of simple and slow neuron-like elements can perform a wide range of inferences  both forward  backward and those involving a type hierarchy  within a few hundred milliseconds. 
   if we choose the period of oscillation of nodes to be 1 milliseconds  assume that nodes can synchronize within two periods of oscillations and pick k1 equal to 1  shruti takes 1 milliseconds to infer 'john is jealous of tom' after being given the dynamic facts 'john loves susan' and 'susan loves tom'  this involves the rule 'if x loves y and y loves z then x is jealous of z . the system takes 1 milliseconds to infer 'john is a sibling of jack' given 'jack is a sibling of john'  this involves the rule 'if x is a sibling of y then y is a sibling of x . similarly  the system takes 1 milliseconds to infer 'susan owns a car' after its internal state is initialized to represent 'susan bought a rolls-royce'  using the rule 'if x buys y then x 
owns y' and the is-a relation  'rolls-royce is a car' . 
　if shruti's long-term memory contains the fact 'john bought a rolls-royce'  shruti takes 1 milliseconds  1 milliseconds  and 1 milliseconds  respectively  to answer 'yes' to the queries 'did john buy a rolls-royce'  'does john own a car ' and 'can john sell a car '  the last query also makes use of the rule 'if x owns y then x can sell y . note that the second and third queries also involve inferences using rules as well as is-a relations. 
　the above times are independent of  ltkb  and do not increase when additional rules  facts  and is-a relationships are added. if anything  these times may decrease if a new rule is added that leads to a shorter inference path. 
	shastri 	1 

1 	conclusion 
we have proposed a criteria for tractable reasoning that is appropriate in the context of common sense reasoning underlying language understanding. we have suggested that an appropriate measure of tractability for such reasoning is one where the time complexity is independent of  and the space complexity is no more than linear in  the size of the long-term knowledge base. we have also identified a class of reasoning that is tractable in this sense. this characterization of tractability can be further refined by cognitive and biological considerations. this work suggests that the expressiveness and the inferential ability of a representation and reasoning systems may be limited in unusual ways to arrive at extremely efficient yet fairly powerful knowledge representation and reasoning systems. 
