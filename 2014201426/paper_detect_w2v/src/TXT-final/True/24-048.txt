 level  pereira  1 . the key idea is that not only one half of a functional calculus should be used  which is the functional application operation conversion  but that the other half  i.e. functional abstraction deserves to be taken under consideration  as well. functional abstraction  so to speak  allows for hooking up the compositional semantics with the contextual information. the context of an utterance can be considered as a set of additional assumptions which help to derive the current sentence  pollack and pereira  1 . additional assumptions have to be  discharged  after successful derivation in order to perform a sound reasoning. the discharging of assumptions is exactly the task of functional abstraction. thus  a broadened view on compositionality can be taken. in particular  pereira's suggestions imply that the mechanisms for dealing with contextual information no longer are mere procedural appendage of the logically well-understood step of compositional semantics but that these mechanisms are part of the logical system which specifies how to construct a semantic representation for a sentence  or a text . 
　in the following  we investigate how pereira's suggestions can be implemented in the framework of the currently fashionable lexicalized approaches to grammar  pollard and sag  1  and many others   in our case a basic categorial grammar1. 
1
　　 similar approaches have been implemented by other people  see e.g.  geurts  1 . 
1
　　basic categorial grammars are a subsystem of combinatory categorial grammars  sec e.g.  steedman  1 . 
	konig 	1 

1 	t h e c o n s t r u c t i o n calculus 
an abbreviated version of pereira's construction calculus is given in figure 1 in a modified notation which allows to turn it easily into a parsing algorithm. thus  instead of semantic types  we use syntactic ones  i.e. those of categorial grammar . we assume that a proposition is a pair which consists of a syntactic category xi and a  partial  semantic representation si  a special case are variables ui . the symbols quant and pron are distinguished categories which designate  stored  quantified expressions and pronouns respectively1. the partial semantic representation of a quantified phrase is prefixed by the variable ui which is bound by its main quantifier. as a hypothetical proposition with category quant. in the quantifier abstraction rule  absq  such a hypothesis is discharged  i.e. the quantified expression is removed from the store and applied to an intermediate parse result. the pronoun licensing rule  licp  transforms a pronoun into a regular noun phrase which can be used in the subsequent derivation. the initial pron-proposition is considered as a hypothetical one  which has to be discharged by applying the pronoun abstraction rule  absp  to perform anaphora resolution. a derivation is successful if all stored quantified expressions and all pronouns have been discharged. for more details see  pereira  1   
figure 1 shows the derivation of the sentence  he 

　the application rules  app   and  app/  perform the ordered a beer  under the assumption that the prepurely compositional part of the construction of a seman- ceding sentence reads  a man entered.  instead of contic representation. the quantifier licensing rule  licq  structing a traditional predicate logic formula  a dis-
 stores  the semantic form of a quantified noun phrase 	course representation structure  drs  is built. a drs is either a pair of a list of discourse referents and a list 
　　for the sake of simplicity we assume that pronouns are of conditions  or a two-place term with functor  and the only kind of anaphoric expressions  and that anaphora two drs's as arguments. intuitively  an undischarged can only take quantified expressions as their antecedents. quantified expression corresponds to what is meant by 

figure 1: 	modified construction calculus - accumulation method 

the term accessible discourse referent in discourse representation theory. if a quantified expression is still undischarged at a certain node in a derivation tree  then its scope covers at least the phrase at the leaves of this subtree. 
1 i m p l e m e n t a t i o n issues 
in the following  we explain how the construction calculus can be implemented. nevertheless  we will stick to the natural deduction format to represent various possible algorithms. because of the similarity of natural deduction rules and horn clauses  several premises and one conclusion   a prolog implementation can be derived in a straightforward way. 
　the construction calculus in definition 1 is not yet a specification of an efficient algorithm. a theorem prover which is derived from this definition has to exploit the pecularities of the individual rules in order to increase the efficiency. one of its main tasks is to keep track of the additional propositions which are brought into the derivation by the licensing rules. we will focus on the handling of the set of undischarged quantified expressions. in order to ease the access  they have to be put into a separate data structure. 
1 	accumulation m e t h o d 
the most obvious method is to simply accumulate the information about undischarged quantified expressions starting from the leaves of the tree. for this purpose  propositions are now indexed by a set q of undischarged quantified expressions  or to be more efficient  by a set of pointers to undischarged quantified expressions : 

set union and set membership is indicated by a comma. lexical entries are assumed to come with empty sets. 
in the application rules the quantifier sets of the two daughter are simply combined. the quantifier licensing rule adds a quantified expression to the set  the quantifier abstraction rule removes an element. the pronoun manipulation rules do not change the set. figure 1 shows the revised calculus. 
　the suggested flow of data makes clear that under certain circumstances anaphora can be resolved before the quantifier scopes in a sentence have been completely 
determined. in the example 
 every man who loves a woman follows her to some country. ' 
the pronoun  her  may find its antecedent before the relative scopes of the quantifiers  every  and  some  are known. 
1 	threading method 
if we assume that we are dealing with anaphora only  i.e. that cataphora do not occur  a further change of the data structure will allow for a slight simplification of the calculus. anaphora want to know their left context  therefore it is sufficient to collect information from left to right in the well-known manner of information  threading . information is not only accumulated from the leaves towards the root of a derivation tree  but propagated down to the leaves which are located further right than the nodes where the information was originated. 
　each constituent can be characterized by the states of the set of accessible quantified expressions before and after it has been derived. hence  each proposition will be indexed by two sets q1  q1 of undischarged quantified expressions: 

the set q1 is the input set  and q1 the output set. the similarity to difference lists in prolog is not accidental. for lexical entries  the input and the output sets are equal. the input set of the first word of a sentence might either be empty or equal the output set of the preceding sentence. the newly revised calculus is presented in figure 1. an application rule connects the output set of its left premise with the input set of the right premise. the output set of the conclusion of the quantifier licensing rule contains one element more than the output set of its premise; for the quantifier abstraction rule  the inverse relation holds. the rules  licp  and  absp  would read in the  threading  notation: 

	k1nig 	1 

figure 1: modified construction calculus - threading method however  a quantified expression can only qualify as a potential antecedent of an anaphor if it occurs in the left context of the anaphor  i.e. if the quantified expression is a member of the input set of the anaphor. hence  the pronoun can access directly the set of its potential antecedents without making reference to a larger subtree of the derivation. the combined rule must perform the two tasks of the original rules  licp  and  absp  which are the formation of a result proposition  np : u  and the substitution of the variable up by the variable uq: 

　the modified rule works fine on the logical level. it will cause problems with the processing  because  in general  the input set will not be instantiated at the moment when the pronoun is encountered by the parser. the search in the set of possible antecedents has to be frozen as long as the variable which represents the set is still uninstantiated. the task of waiting until the appropriate part of the derivation has been built up is delegated to an underlying mechanism instead of mentioning it explicitly in the rule  absp . in the framework of concurrent logic programming languages  which provide a suspension mechanism  the set of undischarged quantified expressions may be considered as a stream. 
　since we presented the algorithm in the natural deduction format  one might assume that there are the usual structural rules silently working in the background. however  for a parser  the presence of the structural rules is harmful. propositions should not be arbitrarily omitted  duplicated or permuted. the weakening rule which allows for the omission of premises will be never needed unless vacuous abstraction is considered a legal phenomenon. in the case of the original construction calculus  the task of the permutation rule is to guarantee the arbitrary access to the quant- and pron-propositions. a first step has been done by representing the  syntactic  propositions and the purely semantic ones in two different data structures. in the threading method  the need for a separate data structure for the undischarged pronouns has disappeared  since pronoun licensing and pronoun abstraction have been merged into one rule. only for the handling of the list of undischarged quantified expressions  the permutation rule must be available in order to turn the list into a set. hence  the permutation rule need not be used in the calculus itself. the contraction rule does its work tacitly to prepare the way for applications of the rule  pron . obviously  a quantified expression might serve as the antecedent of several pronouns. this is the only the case where the use of a structural rule cannot be eliminated. but fortunately  by coupling it with the responsible rule  pron   the properties of the parser are not affected and the number of occurrences of the contraction rule is restricted to the number of pronouns in a sentence or a text. 
　the limited use of the contraction rule  i.e. copy rule  implies that the global stream of undischarged quantified expressions is finite. in addition  the stream is acyclic because it represents a traversal of an acyclic tree structure. all frozen tasks  of pronoun resolution  are arranged along this finite  acyclic stream  hence there will be neither the trap of an infinite search space nor the danger of a deadlock. thus  the algorithm is quaranteed to terminate for any input. 
1 	concurrent parsing 
concerning the processing methods which have been presented in the last sections  full search for all possible derivations is most easily performed by using the prolog backtracking mechanism. this leads to two known drawbacks. firstly  usually a lot of redundant work has to be done because the backtracking mechanism does not allow to reuse successful subderivations. secondly  since all data is local to one proof structure  there is hardly any basis to attempt several proofs in parallel. standard solutions to these problems exist already in the form of table-based parsing  or chart-parsing. for prolog implementations  the more conventional approaches realize the chart as a set of prolog data base entries  see e.g.  pereira and shieber  1 . 
   for a parsing method which also handles the processing of contextual information  the prolog data base approach becomes quite expensive. every time when an application step has been carried out  the data base entries which represent the nodes in the right daughter tree have to be exchanged in order to update their input sets. if one adopts  however  the somewhat more unconventional approach of parsing with nested streams  cf.  okumura and matsumoto  1  matsumoto and sugimura  1   the destructive operation of updating the context lists is done inexpensively by the prolog unification operation. 


figure 1: stream-based syntactic and semantic processing  analoguous rule variants are omitted  

　the propositions which cover portions of the derivation starting at the same position in the sentence form a stream i1. furthermore  each proposition is connected to the stream i1 of its alternative right neighbor constituents: 

figure 1 shows the rules of the stream-based parsing algorithm. the rule  ikup  realizes the lexical lookup of for a word w with category x and its right neighbor string  x. the applications rules do their usual work. however  one important feature of the prolog data base approach must be simulated here. each data-base lookup of an entry returns a new copy of this entry. looking up a proposition in the stream  however  returns the identical proposition for all accesses. in order to avoid variable 
clashes  the new proposition must result from combining a c f the proposition with the functor proposition. this kind of copying does not lead to the appearance of two copies of the same proposition in one  virtual  construction calculus derivation. the use of copies is reserved for alternative derivations  only1. the rules  pron    licq   and  add new elements to the stream. since this happens  spontaneously   the appropriate control structure must be provided to let these rules apply at most once to each stream element  e.g. by creating a process per rule and per stream. 
1
　　a more comprehensive argument for the soundness of this style of copying with regard to a chart parsing algorithm which handles hypothetical propositions has been given in  konig  1 . 
1 	c o n c l u s i o n 
based on pereira's semantic construction calculus  pereira  1   we have defined algorithms which perform the three phases of the construction of a semantic representation  composition  quantifier scoping  and anaphora resolution  in an interwoven manner. the investigation of the data flow lead to a stream-based algorithm which allows for a high degree of and-parallel processing. 
　in previous approaches  at least the anaphora resolution module had to access the semantic form  cf.  johnson and kay  1 . now  the semantic construction operations work independently of the underlying semantic representation. the only link between the construction algorithm and the specific semantic representation is the a-conversion operation  which could be replaced by other  possibly weaker constructors  e.g. based on unification. 
　what we have suggested so far is an algorithmic skeleton of extended compositional semantics. this skeleton will only become a full-fledged body if one adds the wealth of heuristics about anaphora resolution and constraints on quantifier scopes. further investigations concerning efficient structure sharing methods for semantic representations and contextual information are necessary in order to improve the overall performance when parsing highly ambiguous input. the algorithms seem still rather far away from the presumed way of cognitive language processing. information about possible antecedents for anaphora flows only along the paths of the derivation tree. improvements should be made towards a word-to-word transport of information which  of course  has to be filtered by the structural constraints. 
　based on the notion of extended compositionaiity as it is realized in the construction calculus  even semantic representation languages like kamp's discourse representation structures which have the reputation of being non-compositional can be handled in a compositional manner. 
	konig 	1 

   constructing semantic representations for a natural language utterance  and interpreting it  has some similarity to the evaluation of a computer program: programs are processed with regard to a given context  i.e. machine state . the similarity between programs and natural language has been observed in the literature  e.g.  van benthem  1   and has given rise to research programs concerning  dynamic logic  for natural language  e.g.  groenendijk and stokhof  1  muskens  1 . further investigation of the dynamics of natural language might give insight how to use parallel processing mechanisms for natural language analysis in a more sophisticated way. 
