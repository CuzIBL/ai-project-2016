an attack on the problems of speech analysis and synthesis 
with the power of an on-line system 
glen j. culler 
university of california  santa barbara 
santa barbara  california 

summary 
　　　how hard a problem can you solve  the answer to this question is no longer fixed by the sol-
ver's education and intelligence alone. we are already in an era where very substantial and maneuverable on-line systems can greatly enhance our capabilities. consequently  the d i f f i c u l t y of a 
problem must now be measured by i t s distance from the combined powers of a man-machine problem-sol-
ving union. furthermore  we wish to allow the starting man-machine combination to be used experimentally to develop an extended machine of i n creasing power in the direction required for the solution of a given hard problem. this is by no 
means just hand waving  for such an arrangement has already been used in a fundamental attack on the problems of speech analysis and synthesis. the substance of this writing consists of a simple description of the developing system with motivation for i t s development shown by direct i l lustrations of the structure of sounds in speech deduced through its use. 
introduction 
　　　the development of interactive software and hardware to permit convenient man-machine communication has been underway for approximately ten years. hardware which provides the channels for this communication necessarily relates to man's i/o  his senses. the software supporting this communication must consist of two parts: one which extracts the programmatic implications from the man's inputs to the computer system and the other which generates outputs perceivable by man's senses. the nature of these outputs depends upon the computer's programmatic perception and response to i t s own internal data  program  and status configurations. the use of speech as the mode of communication has become urgently attractive to many of us engaged in building interactive systems. there are many reasons for this concern: man's ease in chattering  the freedom to do manual things in parallel with speaking or listening  and the universal character of our existing communication systems. the required hardware is t r i v i a l ; it need only consist of a modest microphone and speaker system with an ordinary audio-amplifier 
which is attached to the a/d and d/a input-output of the computer to be used. the problem lies in the two part software. here is an outline of our approach to this problem: 
1 
1. asc1n wave functions 
determine a mathematical formulation natural for the representation of wave forms observed as microphone outputs during speech. 
1. asc1n transform 
develop algorithms required to transform the d i g i t a l representatio' of the microphone signal into the parameters of the mathematical formulation. 
1. asc1n inverters 
develop algorithms required to transform l i s t s of mathematical parameters into the d i g i t a l form required by the b/a which drives the speaker system. 
1. phone recognizer 
classify the parameters actually occuring in speech output as functions of the elements of speech. 
1. phone synthesizer 
generate parameter strings to drive the output system to produce high quality program controlled speech. 
1. linguistic formatter 
classify phone sequences to determine phonetic  phonemic  and prosodic content and l i s t an encoded representation as a linguistic string. 
1. voice synthesizer 
from linguistic strings  construct phone sequences to drive the phone synthesizer. 
1. linguistic analyzer 
extract meaning from linguistic strings. 
1. linguistic synthesizer 
construct linguistic strings from programmatic meaning. 
　　　at the present time we can announce excellent success in   l .     because we already have s u f f i ciently good success in  1.  and  1.  which i s   of course  the f i r s t criterion for the adequacy of   l .   . we have completed successful experiments in the pair  1.  and  1.  for a restricted set of speech elements and are currently engaged in completing this part of our effort. we can give a very tentative and premature definition of 'voice  and  linguistic strings  in relation to  1.  and  1. . only after  1.  and  1.  are complete can we make firm specifications for these definitions. at present  consideration of  1.  and  1.  are beyond the scope of our development. 
the speech on-line gystem 
　　　the i n i t i a l hardware complex started with an inter-connection of an early form of the u.c.s.b. on-line system with a process control computer. the configuration consisted of: 
1. rw-1 	polymorphic system 
p 
1. ibm-1 	mod ii process control computer 
the rw-1oo system was contributed to u.c. 
s.b. by the bunker-ramo corporation for further investigation of on-line systems. 
1 
       the ibm-1 system was made available on our arpa project  contract # af 1 -1l+ by the department of electrical engineering at u.c. s.b. 
1. tektronix 1 l l   1 	storage tube 
	k. microswitch 	operator-operand keyboard 
which were combined as shown in figure 1. 
　　　the f i r s t form of our speech station was reported in   l .   at  the conference for interactive systems   august 1. the principal hardware change since that time has been the addition of b i l l proctor's  nanohumper *  which is the right way to tackle the problem of broad band a/d conversion. our major task has been the experimental 
-
　　　 the tektronix 1 l l was donated to u.c.s.b. by the tektronix corporation to provide early experience in i t s use. k 
       the operator-operand keyboard was developed at u.c.s.b. under arpa contract # af 1 -1u as the input portion of a classroom system. 
* 
       records time and voltage of fixed voltage level transitions. thus the volume of data output is proportional to frequency rather than time. 

construction of software required for the investigation of  1.  and i t s validification by  1.  and  1. - roughly speaking  it consists of a set of operations which process a long data l i s t and a set of others which process a long parameter l i s t in the process control computer which is supervised by the early u.c.s.b. on-line system running in the rw-1oo system. for a detailed description of this system and i t s operations  the reader is referred to the final report arpa contract # af 1 -1. 
elementary sounds 
　　　after some i n i t i a l investigation of the i n adequacies of both fourier series and transforms as mathematical frames for representing the v o l tage signal output by a microphone during the speaking process  we turned to wave function re-
presentations of limited time duration. when one of these wave functions is given as the specified voltage used to drive a voice coil on an audio speaker  the result is an  elementary sound . sounds of arbitrary complexity can be constructed by superposition of these elementary sounds. the extent to which a l l speaking voices can be duplicated in this manner is a measure of the completeness of these sound elements as a basis for speech. the simplicity of the resulting representations of live speaking voices in terms of elementary sounds is a measure of the wisdom of selection of that particular basis  for simplicity of representation carries continuing value as we 
move up the ladder of efforts outlined above. the parameters used to characterize the elementary sounds can be motivated by considering the pressure wave function. this pressure wave is a disturbance propagating through the medium surrounding the speaker and can be recorded by a standing observer with a microphone. assuming the speaker and microphone are of excellect f i d e l i t y   we can thus obtain an experimental recording of an elementary sound. in the coordinate system of the observer  the disturbance w i l l have an amplitude 

	figure 1. 	envelope of an elementary sound. 
a  w i l l last for a certain time span s  and w i l l have associated with i t s occurrence a center time c half way through the disturbance. these are called the global parameters of the elementary sound  since they depend only upon i t s traveling envelope. now  within this traveling envelope  we characterize the pressure oscillations by n and 1  where n is the number of oscillations recorded during the time interval s and 1 is the phase of the internal oscillation at t = c. as a means to 

	a 	= 	amplitude 
	s = 	time span 
	c = 	traveling center time 
	1 	= 	oscillation phase 
	n 	= 	oscillation order 
figure 1. graph of pressure wave of an elementary sound with i t s asc1n parameters. 
familiarize the reader with the visual aspects of our wave functions and their asc1n parameters  we invite you to try estimating a l l parameters for those wave functions shown below. correct answers are given at the end of the paper  a in volts  s in milliseconds and 1 in radians. 
elementary strings: treble  mid  and bass 
　　　the speaking vcices of man are so personalized and rich in frequeny range that one despairs early of hoping to c aracterize speech in terms of statical averages o- frequences  extremes  zero crossings  etc. instead  we elect to carry out a detailed reduction of each speech expression to the elementary sounds of which it is composed  thus deferring sound recognition and interpretation processes as shown in the outline above. this is the purpose of the asc1n-transform of  1. . with classical transforms that are defined as mathematical processes  one can always state a transformation formula in explicit terms. doing 

-1-

it is often the most distinctive of the three. the mid string is the most familiar of the three in terms of voice; when combined with the treble  it makes a voice much like that recorded in an 
anechoic chamber. the bass is not often of distinctive importance; it represents much of the acoustic interaction of the room  the voice  and the recording system. in our on-line speech system we have included the facility for programmatically constructing digital filters. since we are s t i l l in the study phase  we have the freedom to carefully observe a sample word and experimentally select a means of separating out the strings. 
in crude terms  the treble is everything above 
1 hertz  the bass is everything below 1 hertz  and the mid is everything between. a good test for completeness of separation into strings is that the second derivative of each of the three 
must remain in the same category as the original string  or the separation is incomplete. 
     each string is then decomposed into its constituent elementary sounds by the method of evacu-
jj ation  i.e.  first remove those of primary influence from the string by insisting that after re-
moval of a wave function  the residue string is of minimum amplitude in the neighborhood of the one removed. after each evacuation the residue is a similar string of smaller amplitude  and the process can be repeated. in figure 1. we show the 
three strings  in the decomposition of the signal 
produced by a male voice saying  corby . as is apparent from this figure  the frequency is not constant across a string  but when properly measured for individual elementary sounds will pro-
vide an important parameter for sorting these sounds. the evacuation method is shown in fig-
ure 1. for the mid string of  corby  during the first 1 ms. 	figure 1. shows the sum of the first two evacuations in comparison with the original mid string. 
     each elementary string f t  can be expressed as a sum of elementary sounds through the evacua-
figure 1. wave functions of some typical tion process. this sum takes the form elementary sounds in their envelopes. 
so  however  does not remove the need for an a l gorithmic computational method  since these formulae frequently are not formulated for computa-
tional requirements but rather for descriptive mathematical expression. in the case of our asc1n transform  we can state an algorithmic method for computing the transform  although no mathematical formula is known. the computer effort required to carry out this algorithm is greatly benefited by some i n i t i a l reduction of complexity in speech da-
ta. 	for us  this reduction consists of decomposing the speech data into strings of elementary sounds of separated frequencies. 	these strings 
are in rough agreement with the classical selec-
tion of formants  although they occasionally differ. 	we distinguish three strings: 	treble  mid  and bass. 	in some sounds one or another of these strings may have very low amplitude  and with different sounds one or another may assume major im-
portance. in general  the treble string variation indicates most sharply transitions in sound; thus 
-1-. 



part  1.  of the outline is thus a computational analysis of how to solve 1  in real time without introducing undesirable computational anomalies. one can experiment with many methods and observe their shortcomings by listening to 1 . this way we can frequently hear troubles which are d i f f i cult to detect by ordinary means. we are s t i l l 
working to improve our methods here and produce a hardware specification for a  string  instrument  i.e.  a special-purpose module which can read a string of asc1n parameters and produce the real time sum 1 . 	three speech strings are capable of producing arbitrarily good speech. 
phones  the simplest structural elements in speech 
     the transformation of digital sample data to elementary strings and finally to lists of elementary sounds represented by lists of asc1n parameters puts us in a position to study these lists and determine which subsets have sufficient inner cohesion to be distinguished as speaking sounds. in figure 1. we show a  s  ac  1  and cu plotted against the index j for a single mid string recording of the word  odd . clearly  what catches our eye  and our ear as well  is the modularity of the above data and an apparent regularity of the evo-

- 1 -

iod. 	the pitch period of an elementary string is determined by the pitch functions of the principal 
phones  those of largest amplitude in the string. the principal phones of the f i r s t 1 ms. of the mid string of  corby  are shown in figure 1. 
　　　the condition of non-overlapping elementary sounds in phones is too stringent for some of the consonants whose elementary sounds have broad 
spans in the bass string and is too lenient for 
vowels  as we do not want to allow more than one elementary sound in the same phone per pitch per-
-1-

which provide high-fidelity reproduction and which open the way to future  perhaps general  computational analysis and synthesis of speech. 
acknowledgements 
　　　the work reported here was primarily supported by the advanced research projects agency  contract # af 1 -1. a number of dedicated co-workers have applied themselves in an extraordinary way and have contributed broadly to our present success. we are especially indebted to gordon buck and helen smith for their programming success; john greaves  gary nelson  and b i l l proctor as graduate research assistants; ray bjorkman  gordon buck and dennis grubbs for their hardware design and construction; professors jim howard  roger wood and their students for their continuing experimentation with our underlying engineering processes. finally  i would like to thank the arpa personnel  formerly ivan sutherland and presently larry roberts and robert taylor for their encouragement and stimulations to undertake this research. 
bibliography 
　1. culler  glen j .   proceedings of the symposium on interactive systems for experimental 
