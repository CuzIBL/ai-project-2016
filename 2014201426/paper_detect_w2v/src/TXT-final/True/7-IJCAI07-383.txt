
in many shortest-path problems of practical interest  insufficient time is available to find a provably optimal solution. one can only hope to achieve a balance between search time and solution cost that respects the user's preferences  expressed as a utility function over time and cost. current stateof-the-art approaches to this problem rely on anytime algorithms such as anytime a* or ara*.
these algorithms require the use of extensive training data to compute a termination policy that respects the user's utility function. we propose a more direct approach  called bugsy  that incorporates the utility function directly into the search  obviating the need for a separate termination policy. experiments in several challenging problem domains  including sequence alignment and temporal planning  demonstrate that this direct approach can surpass anytime algorithms without requiring expensive performance profiling.
1 introduction
important tasks as diverse as planning and sequence alignment can be represented as shortest-path problems. if sufficient computation is available  optimal solutions to such problems can be found using a* search with an admissible heuristic  hart et al.  1 . however  in many practical scenarios  time is limited or costly and it is not desirable  or even feasible  to look for the least-cost path. search effort must be carefully allocated in a way that balances the cost of the paths found with the required computation time. this tradeoff is expressed by the user's utility function  which specifies the subjective value of every combination of solution quality and search time. in this paper  we introduce a new shortestpath algorithm called bugsy that explicitly incorporates the user's utility function and uses it to guide its search.
　a* is a best-first search in which the 'open list' of unexplored nodes is sorted by f n  = g n  + h n   where g n  denotes the cost experienced in reaching a node n from the initial state and h n  is typically a lower bound on the cost of reaching a solution from n. a* is optimal in the sense that no algorithm that returns an optimal solution using the same lower bound function h n  visits fewer nodes  dechter and pearl  1 . however  in many applications solutions are needed faster than a* can provide them. to find a solution faster  it is common practice to increase the weight of h n  via f n  = g n  + w ，h n   with w − 1  pohl  1 . in the recently proposed ara* algorithm  likhachev et al.  1   this scheme is extended to return a series of solutions of decreasing cost over time. the weight w is initially set to a high value and then decremented by δ after each solution. if allowed to continue  w eventually reaches 1 and the cheapest path is discovered. of course  finding the optimal solution this way takes longer than simply running a* directly.
　these algorithms suffer from two inherent difficulties. first  it is not well understood how to set w or δ to best satisfy the user's needs. because it is linked to solution cost rather than solving time  it is not clear how to achieve a desired trade-off. setting w too high or δ too low can result in many poor-quality solutions being returned  wasting time. but if w is set too low or δ too high  the algorithm may take a very long time to find a solution. therefore  to use a weighted a* technique the user must perform many pilot experiments in each new problem domain to find good parameter settings.
　second  for anytime algorithms such as ara*  the user must estimate the right time to stop the algorithm. the search process appears as a black box that could emit a significantly better solution at any moment  so one must repeatedly estimate the probability that continuing the computation will be worthwhile according to the user's utility function. this requires substantial prior statistical knowledge of the run-time performance profile of the algorithm and rests on the assumption that such learned knowledge applies to the current instance.
　these difficulties point to a more generalproblem: anytime algorithms must inherently provide suboptimal performance due to their ignorance of the user's utility function. it is simply not possible in general for an algorithm to quickly transform the best solution achievable from scratch in time t into the best solution that would have been achievable given time t + 1. in the worst case  visiting the next-most-promising solution might require starting back at a child of the root node. without the ability to decide during the search whether a distant solution is worth the expected effort of reaching it  anytime algorithms must be manually engineered according to a policy fixed in advance. such hardcoded policies mean that there will inevitably be situations in which anytime algorithms will either waste time finding nearby poor-quality solutions or overexert themselves finding a very high quality solution when any would have sufficed.
　in this paper we address the fundamental issue: knowledge of the user's utility function. we propose a simple variant of best-first search that represents the user's desires and uses an estimate of this utility as guidance. we call the approach bugsy  best-first utility-guided search-yes!  and show empirically across several domains that it can successfully adapt its behavior to suit the user  sometimes significantly outperforming anytime algorithms. furthermore  this utility-based methodology is easy to apply  requiring no performance profiling.
1 the bugsy approach
ideally  a rational search agent would evaluate the utility to be gained by each possible node expansion. the utility of an expansion depends on the utility of the eventual outcomes enabled by that expansion  namely the solutions lying below that node. for instance  if there is only one solution in a treestructured space  expanding any node other than the one it lies beneath has no utility  or negativeutility if time is costly . we will approximate these true utilities by assuming that the utility of an expansion is merely the utility of the highestutility solution lying below that node.
　we will further assume that the user's utility function can be captured in a simple linear form. if f s  represents the cost of solution s  and t s  represents the time at which it is returned to the user  then we expect the user to supply three constants: udefault  representing the utility of returning an empty solution; wf  representing the importance of solution quality; and wt  representing the importance of computation time. the utility of expanding node n is then computed as
	u n  = udefault  	min	 wf ， f s  + wt ， t s  
s under n
where s ranges over the possible solutions available under n. we follow the decision-theoretic tradition of better utilities being more positive  requiring us to subtract the estimated solution cost f s  and search time t s .  in the discussion below  this will mean that lower bounds on f s  and t s  will yield an upper bound on u n .  this formulation allows us to express exclusive attention to either cost or time  or any linear trade-off between them. the number of time units that the user is willing to spend to achieve an improvement of one cost unit is wf/wt. this quantity is usually easily elicited from users if it is not already explicit in the application domain.  of course  such a utility function would also be necessary when constructing the termination policy for an anytime algorithm.  although superficially similar to weighted a*  bugsy's node evaluation function differs because wf is applied to both g n  and h n .
　of course  the solutions s available under a node are unknown  but we can estimate some of their utilities by using functions analogous to the traditional heuristic function h n . instead of merely computing a lower bound on the cost of the cheapest solution under a node  we also compute the lower

figure 1: estimating utility using the maximum of bounds on the nearest and cheapest solutions.
bound on distance in search nodes to that hypothetical cheapest solution. in many domains  this additional estimate entails only trivial modifications to the usual h function. search distance can then be multiplied by an estimate of time per expansion to arrive at t s .  note that this simple estimation method makes the standard assumption of constant time per node expansion.  to provide a more informed estimate  we can also compute bounds on the cost and time to the nearest solution in addition to the cheapest. again  standard heuristic functions can often be easily modified to produce this information. u n  can then be estimated as the maximum of the two utilities. for convenience  we will notate by f n  and t n  the values inherited from whichever hypothesized solution had the higher utility.
　figure 1 illustrates this computation schematically. the two solid dots represent the solutions hypothesized by the cheapest and nearest heuristic functions. the dashed circles represent other possible solutions  demonstrating a trade-off between those two extremes. the dotted lines represent contours of constant utility and the dotted arrow shows the direction of the utility gradient. assuming that the two solid dots represent lower bounds  then an upper bound on utility would combine the cost of the cheapest solution with the time to the nearest solution. however  this is probably a significant overestimate.1 note that under different utility functions  different slopes for the dotted lines  the relative superiority of the nearest and cheapest solutions can change.
1 implementation
figure 1 gives a pseudo-code sketch of a bugsy implementation. the algorithm closely follows a standard best-first search. u n  is an estimate  not a true upper bound  so it can underestimate or change arbitrarily along a path. this implies that we might discover a better route to a previously expanded state. duplicate paths to the same search state are detected in steps 1 and 1; only the cheaper path is retained. we record links to a node's children as well as the preferred parent so that the utility of descendants can be recomputed bugsy initial  u   
1. open ○ {initial}  closed ○ {}
1. n ○ remove node from open with highest u n  value
1. if n is a goal  return it
1. add n to closed
1. for each of n's children c 
1. if c is not a goal and u c    1  skip c
1. if an old version of c is in closed 
1. if c is better than cold 
1. update cold and its children
1. else  if an old version of c is in open 
1. if c is better than cold 
1. update cold
1. else  add c to open
1. go to step 1
figure 1: bugsy follows the outline of best-first search.
 step 1  if g n  changes  nilsson  1  p. 1 . the on-line estimation of time per expansion has been omitted for clarity. the exact ordering function used for open  and to determine 'better' in steps 1 and 1  prefers high u n  values  breaking ties for low t n   breaking ties for low f n   breaking ties for high g n . note that the linear formulation of utility means that open need not be resorted as time passes because all nodes lose utility at the same constant rate independent of their estimated solution cost. in effect  utilities are stored independent of the search time so far.
　the h n  and t n  functions used by bugsy do not have to be lower bounds. bugsy requires estimates-there is no admissibility requirement. if one has data from previous runs on similar problems  this information can be used to convert standard lower bounds into estimates  russell and wefald  1 . in the experiments reported below  we eschew the assumption that training data is available and compute corrections on-line. we keep a running average of the one-step error in the cost-to-go and distance-to-go  measured at each node generation. these errors are computed by comparing the cost-to-go and distance-to-go of a node with those of its children. if the cost-to-go has not decreased by the cost of the operator used to generate the child  we can conclude that the parent's value was too low and record the discrepancy as an error. similarly  the distance-to-go should have decreased by one. these correction factors are then used when computing a node's utility to give a more accurate estimate based on the experience during the search so far. given the raw cost-to-go value h and distance-to-go value d and average errors eh and
. to temper this inad-
missible estimate  especially when the utility function specifies that solution cost is very important  we weight both error estimates by min 1  wt/wf  /1. because on-line estimation of the time per expansion and the cost and distance corrections create additional overhead for bugsy relative to other search algorithms  we will take care to measure cpu time when computing utility values in our experimental evaluation  not just node generations.
1 properties of the algorithm
bugsy is trivially sound-it only returns nodes that are goals. if the heuristic and distance functions are used without inadmissible corrections  then the algorithm is also complete if the search space is finite. if wt = 1 and wf   1  bugsy reduces to a*  returning the cheapest solution. if wf = 1 and wt   1  then bugsy is greedy on t n . ties will be broken on low f n   so a longer route to a previously visited state will be discarded. this limits the size of open to the size of the search space  implying that a solution will eventually be discovered. similarly  if both wf and wt   1  bugsy is complete because t n  is static at every state. the f n  term in u n  will then cause a longer path to any previously visited state to be discarded  bounding the search space and ensuring completeness. unfortunately  if the search space is infinite  t n  is inadmissible  and wt   1  bugsy is not complete because a pathological t n  can potentially mislead the search forever.
　if the utility estimates u n  are perfect  bugsy is optimal. this follows because it will proceed directly to the highestutility solution. assuming u n  is perfect  when bugsy expands the start node the child node on the path to the highest utility solution will be put at the front of the open list. bugsy will expand this node next. one of the children of this node must have the highest utility on the open list since it is one step closer to the goal than its parent  which previously had the highest utility  and it leads to a solution of the same quality. in this way  bugsy proceeds directly to the highest utility solution achievable from the start state. it incurs no loss in utility due to wasted time since it only expands nodes on the path to the optimal solution.
　it seems intuitive that bugsy might have application in problems where operators have different costs and hence the distance to a goal in the search space might not correspond directly to its cost. but even in a search space in which all operators have unit cost  and hence the nearest and cheapest heuristics are the same   bugsy can make different choices than a*. consider a situation in which  after several expansions  it appears that node a  although closer to a goal than node b  might result in a worse overall solution.  such a situation can easily come about even with an admissible and consistent heuristic function.  if time is weighted more heavily than solution cost  bugsy will expand node a in an attempt to capitalize on previous search effort and reach a goal quickly. a*  on the other hand  will always abandon that search path and expand node b in a dogged attempt to optimize solution cost regardless of time.
　in domains in which the cost-to-goal and distance-to-goal functions are different  bugsy can have a significant advantage over weighted a*. with a very high weight  weighted a* looks only at cost to go and will find a solution only as quickly as the greedy algorithm. bugsy however  because its search is guided by an estimate of the distance to solutions as well as their cost  can possibly find a solution in less time than the greedy algorithm.
1 empirical evaluation
to determine whether such a simple mechanism for timeaware search can be effective in practice  especially with imperfect estimates of utility  we compared bugsy against seven other algorithms on three different domains: gridworld path planning  1 different varieties   multiple sequence alignment  used by zhou and hansen  to evaluate anytime a*   and temporal planning. all algorithms were coded in objective caml  compiled to native code  and run on one processor of a dual 1ghz intel xeon machine with 1gb ram  measuring cpu time used. the algorithms were:
a* detecting duplicates using a closed list  hash table   breaking ties on f in favor of high g 
weighted a* with w = 1 
greedy like a* but preferring low h  breaking ties on low g  speedy like greedy but preferring low time to goal  t n    breaking ties on low h  then low g 
anytime a* weighted a*  w = 1  that continues  pruning the open list  until an optimal goal has been found  hansen et al.  1  
ara* performs a series of weighted a* searches  starting with w = 1   decrementing the weight  δ = 1  following likhachev et al.  and reusing search effort 
a  from among those nodes within a factor of   1  of the lowest f value in the open list  expands the one estimated to be closest to the goal  pearl and kim  1 .
note that greedy  speedy  and a* do not provide any inherent mechanism for adjusting their built-in trade-off of solution cost against search time; they are included only to provide a frame of reference for the other algorithms. the first solution found by anytime a* and ara* is the same one found by weighted a*  so those algorithms should do at least as well. we confirmed this experimentally  and omit weighted a* from our presentation below. a  performed very poorlyin our preliminary tests  taking a very long time per node expansion  so we omit its results as well. on domains with many solutions  anytime a* often reported thousands of solutions; we therefore limited both anytime algorithms to only reporting solutions that improve solution quality by at least 1%.
1 gridworld planning
we considered several classes of simple path planning problems on a 1 by 1 grid  using either 1-way or 1-way movement  three different probabilities of blocked cells  and two different cost functions. the start state was in the lower left corner and the goal state was in the lower right corner. in addition to the standard unit cost function  under which every move is equally expensive  we tested a graduated cost function in which moves along the upper row are free and the cost goes up by one for each lower row. we call this cost function 'life' because it shares with everyday living the property that a short direct solution that can be found quickly  shallow in the search tree  is relatively expensive while a least-cost solution plan involves many annoying economizing steps. under both cost functions  simple analytical lower bounds  ignoring obstacles  are available for the cost  g n   and distance u  	bugsy ara*	aa*	sp	gr	a* unit costs  1-way movement  1% blocked time only	1	1	1
1 microsec	1	1	1 1 msec	1	1	1
	1 msec	1	1	1
	1 msec	1	1	1
 1 msec	1	1	1 1 sec	1	1	1 cost only	1	1	1
             unit costs  1-way movement  1% blocked time only	1	1	1 1 microsec	1	1	1
1 microsec	1	1	1
	1 msec	1	1	1
	1 msec	1	1	1
	1 msec	1	1	1
 1 msec	1	1	1 1 sec	1	1	1 cost only	1	1	1
　'life' costs  1-way movement  1% blocked time only1	1	1 microsec1	1	1 microsec1	1	1
	1 microsec1	1	1
	1 microsec1	1	1
1 microsec1	1	1
1 microsec1	1	1
	1 msec1	1	1
	1 msec1	1	1
 1 msec1	1	1 msec1	1	1 cost only1	1	1
table 1: results on three varieties of gridworld planning.
 in search steps  to the cheapest goal and to the nearest goal. these quantities are then used to compute the f n  and t n  estimates. due to the obstacles  the heuristics are not very accurate and the problems can be quite challenging.
　table 1 shows typical results from three representative classes of gridworld problems. anytime a* is notated aa*. each row of the table corresponds to a different utility function  including those in which speedy and a* are each designed to be optimal. recall that each utility function specifies the relative weighting of solution cost and cpu time taken to find it. the relative size of the weights determines how important time is relative to cost. in other words  the utility function specifies the maximum amount of time that should be spent to gain an improvement of 1 cost unit. this is the time that is listed under u   for each row in the table. for example   1 msec  in a unit cost problem means that the search algorithm can spend up to one millisecond in order to find a solution one step shorter. in other words  it means that a solution that takes 1 seconds longer to find than another must be at least 1 unit cheaper to be judged superior. the utility functions tested range over several orders of magnitude  from one in which only search time matters to one in which only solution cost matters.
recall that  given a utility function at the start of its search 
bugsy returns a single solution representing the best tradeoff between path cost and search time that it could find based on the information available to it. we record the cpu time taken along with the solution cost. greedy  notated gr in the table   speedy  notated sp   and a* also each return one solution. these solutions may score well according to utility functions with extreme emphasis on time or cost but may well score poorly in general. the two anytime algorithms  anytime a* and ara*  return a stream of solutions over time. for these experiments  we allowed them to run to optimality and then  for each utility function  post-processed the results to find the optimal cut-off time to optimize each algorithm's performance for that utility function. note that this 'clairvoyant termination policy' gives anytime a* and ara* an unrealistic advantage in our tests. to compare more easily across different utility functions  all of the resulting solution utilities were linearly scaled to fall between 1 and 1. each cell in the table is the mean across 1 instances.
　in the top group  unit costs  1-way movement  1% blocked   we see bugsy performing very well  behaving like speedy and greedy when time is important  like a* when cost is important  and significantly surpassing all the algorithms for the middle range of utility functions. in the next two groups bugsy performs very well as long as time has some importance  again dominating in the middle range of utility functions where balancing time and cost is crucial. however  its inadmissible heuristic means that it ocassionally performs very slightly worse than a* or ara* when time is of marginal importance and cost is critical.  anytime a* performed extremely poorly on the last group  taking many hours per instance versus 1 seconds for a*  so its results are omitted.  given that bugsy does not require performance profiling to construct a termination policy  this is encouraging performance. as one might expect  greedy performs well when time is very important  howeveras cost becomes important the greedy solution is less useful. compared to greedy  speedy offers little advantage.
1 multiple sequence alignment
alignment of multiple strings has recently been a popular domain for heuristic search algorithms  hohwald et al.  1 . the state representation is the number of characters consumed so far fromeach string; a goal is reached when all characters are consumed. moves that consume from only some of the strings represent the insertion of a 'gap' character into the others. we computed alignments of five sequences at a time  using the standard 'sum-of-pairs'cost function in which a gap costs 1  a substitution  mismatched non-gap characters  costs 1  and costs are computed by summing all the pairwise alignments. we tested on a set of five biological sequence alignment problems used by kobayashi and imai  and  zhou and hansen  1 . each problem consists of five relatively dissimilar protein sequences. each sequence is approximately 1 symbols long  over an alphabet of 1 symbols representing amino acids. the heuristic function h n  was based on optimal pairwise alignments that were precomputed by dynamic programming. the lower bound on search nodes
u  bugsyara*aa*spgra*time only1111 sec1111 sec1111 sec1111 sec1111 secs111cost only111table 1: results on protein sequence alignment.
to go was simply the maximum number of characters remaining in any sequence.
　table 1 shows the results  with each row representing a different utility function and all raw scores again normalized between 1 and 1. each cell represents the mean over the 1 instances  there was little variance in the scores in this domain . again we see bugsy performing well over a variety of time/cost trade-offs  even holding its own against greedy and a* at the two ends of the spectrum. the anytime algorithms fail to match its performance  despite our clairvoyant termination policy.
1 temporal planning
there has been increasing interest over the last ten years in applying heuristic search algorithms to ai planning problems  zhou and hansen  1 . in these problems  the search algorithm must find a sequence of actions that connects the initial state si and goal state sg. we tested our algorithms on temporal planning problems where actions take real-valued amounts of time  so-called 'durative' actions  and the objective function is to minimize the plan duration  makespan . to find the plan  we used the temporal regression planning framework in which the planner searches backwards from the goal state sg to reach the initial state si  bonet and geffner  1 . to guide the search  we compute h n  using the admissible h1 heuristic of the tp1 planner  haslum and geffner  1 . this heuristic estimates the shortest makespan within which each single predicate or pair of predicates can be reached from the initial state si. this is computed once via dynamic programming before starting the search  taking into account the pairwise mutual exclusion relations between actions in the planning problem.
　for bugsy  we also computed the expected number of steps to reach the shortest makespan solution  the expected makespan to the closest solution  and the expected number of steps to the closest solution. these three values are estimated by first extracting two different relaxed plans  hoffmann and nebel  1  that approximate the closest solution in terms of steps and shortest solutions in terms of makespan from a given search node. the makespan and number of regression steps in those two plans are then used as the cost and time estimates to the closest and cheapest solutions in bugsy. while both relaxed plans are extracted backward from the same relaxed planning graph starting from the same set of goals  the heuristics to order the goals and the actions supporting them are different. one favors actions that are close to the intial state si  as indicated by the h1 heuristic  and the other favors actions that take fewer steps to reach the goal from si. the second heuristic is based on another form of dynamic programming that is similar to h1 but estimates the number of search steps to reach each predicate and action from si instead of the minimum makespan.
　we tested the different search algorithms using 1 problems from five benchmark domains taken from the 1 and 1 international planning competitions: blocksword  logistics  zenotravel  rovers  and satellite. blocksworld involves building different block configurations using robot arms. logistics and zenotravel involve moving people or packages between different connected locations using airplanes and/ortrucks. in rovers  differentroverstravel  collect samples  take pictures  and communicate the data back to a lander. in satellite  several satellites carrying different sets of equipment need to turn to different objects and take pictures in different modes and communicate the data back to earth.
　table 1 shows results from the largest problem in each of the five domains. as before  each row represents a different utility function. due to the wide disparity in results for this domain  we took the logarithm of the raw utilities before normalizing them. both speedy and greedy perform very badly for temporal planning so we only show the comparisons between bugsy  ara*  anytime a* and a*. all algorithms returned the same results when cost was the only criterion. bugsy performs very well when time is important in all domains  significantly outperforms all other algorithms. when time becomes less important  either ara*  satellite  logistics  rovers  or a*  zenotravel  blocksworld  return solutions with better utility in all domains. in the instances where a* is the best  zenotravel and blocksworld when cost is important   then bugsy return solutions with similar utility to ara*. if one looks at the raw utility values  bugsy is generally one or two orders of magnitude better on those problems for which it outperforms the other search algorithms. and on the others  the utility achieved by bugsy is never more than a factor of 1 worse than that achieved by the best algorithm  making it much more robust than ara* or anytime a*.
1 discussion
we have presented empirical results from a variety of search problems  using utilities computed from actual cpu time measurements  demonstrating that bugsy is competitive with state-of-the-art anytime algorithms without the need for a separate termination policy and its extensive training data. for utility functions with an emphasis on solution time  it often performs significantly better than any previous method. for utility functions based heavily on solution cost  it can sometimes perform slightly worse than a* due to its inadmissible heuristic. overall  bugsy appears remarkably robust across different domains and utility functions considering that it has no access to training data or any information other than the user's utility function.
　note that bugsy solves a different problem than realtime a*  korf  1  and its variants. rather than performing a time-limited search for the first step in a plan  bugsy tries to find a complete plan to a goal in limited time. this is particularly useful in domains in which operators are not invertible or are otherwise costly to undo. having a complete path to a goal ensures that execution does not become ensnared in a deadend. it is also a common requirement in applications where planning is but the first step in a series of computations involving the action sequence.
　in some applications of best-first search  memory use is a prominent concern. in a time-bounded setting this is less frequently a problem because the search doesn't have time to exhaust available memory. however  the simplicity of bugsy means that it may well be possible to integrate some of the techniques that have been developed to reduce the memory consumption of best-first search if necessary.
　we have done preliminary experiments incorporating simple deadlines into bugsy  with encouragingresults. because it estimates the search time-to-go  it can effectively prune solutions that lie beyond a search time deadline. another similar extension applies to temporal planning: one can specify a bound on the sum of the search time and the resulting plan's execution time and let bugsy determine how to allocate the time.
1 conclusions
as nilsson notes   in most practical problems we are interested in minimizing some combination of the cost of the path and the cost of the search required to obtain the path  yet  combination costs are never actually computed ...because it is difficult to decide on the way to combine path cost and search-effort cost   1  p. 1  emphasis his . bugsy addresses this problem by letting the user specify how path cost and search cost should be combined.
　this new approach provides an alternative to anytime algorithms. instead of returning a stream of solutions and relying on an external process to decide when additional search effort is no longer justified  the search process itself makes such judgments based on the node evaluations available to it. our empirical results demonstrate that bugsy provides a simple and effective way to solve shortest-path problems when computation time matters. we would suggest that search procedures are usefully thought of not as black boxes to be controlled by an external termination policy but as complete intelligent agents  informed of the user's goals and acting rationally on the basis of the information they collect so as to directly maximize the user's utility.
acknowledgments
elisabeth crawford assisted with this project during a summer internship at parc. the members of parc's embedded reasoning area provided encouragement and many helpful suggestions.
