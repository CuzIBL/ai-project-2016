 
　　　we have constructed a deductive question answering system which accepts natural language input in japanese. the semantic trees of aseertional input sentences are stored in a semantic network and interrelationships -conditional  implicational  and so forth- are established among them. a matching routine looks for the semantic trees which have some relations to a query  and returns the mismatch information  difference  to a deduction routine. the deduction routine produces sub-goals to diminish this difference. this process takes place recursively until the difference is completely resolved  success   or there is no other possibility of matching in the semantic network  failure . standard problem solving techniques are used in this process. as the result the system is very powerful in handling deductive responses. in this paper only the part of the logical deduction is explained in detail. 
descriptive terns: question answering  deduction  natural language  semantic network  problem solving. 
i introduction 
   there are a few deductive question answering systems using natural language  almost a l l of which use logical expressions  especially the f i r s t order predicate calculus expression  as an intermediate language. however systems which use formal logics have problems: 
 1  syntactic and semantic analyses of natural language input are necessary to transform the input to logical expression without ambiguity. 
 1  the axiom set must be clearly defined and must not be contradictory. 
 1  predicates and variables must be fixed beforehand. this is a problem for the system's expansion. also this prevents mixing the f i r s t and higher order predicate calculus systems. 
 1  deduction using the resolution principle is cumbersome. usually question answering does not require a deep deductive process. 
 1  good quality of natural language output is very . 
hard to obtain from a logical expression. 
to avoid the above problems we have used a kind of session 1 natural language: systems semantic representation of natural language sentences as an intermediate expression. pur systern has the 
following characteristic features. 
 1  the question answering system is a composite of subsystems for language analysis  deduction  and language generation. 
 1  the parsed trees of sentences are permitted to have some ambiguities. ambiguities are resolved in the process of logical deduction  
 1  during the question answering process  the deduction ability is increased and the area which the system can deal with is also expanded. the deduction a b i l i t y of a system depends on how many theorems the system can use  and on how efficiently it can deal with them. we have constructed a system in which the available theorems increase during the question answering process. 
 1  facts can play the role of theorems. we think the distinction between facts and theorems is not clear enough. a statement can be used as a theorem at one time and as a fact at another time. for example  
       a human is an intelligent animal  plays the role of a theorem to answer is smith intelligent   
because smith is an instance of a variable 'human'. on the contrary it plays the role of a fact to the question 
       is a man an animal   because 'a human' is treated as an instance of a variable 'man'. 
in our system the assertions given by a user  which correspond to facts in usual systems  can play the role of theorems. 	this is accomplished by allowing a higher concept term to be a variable to i t s lower concept term. 	there is no distinction between them  and both facts and theorems have the same structures in the data base. 	this is the most significant character of the system we have developed. 
 1  in order to deal with a large data base  the system has a well organized data structure and relevant information to a question is accessed by a technique of indexing and retrieval  
 1  the deduction process is similar to that of humans. it allows introducing many heuristics into the deduction process. 
in this paper the details of deduction subsystem alone are explained. the other two subsystems w i l l be published elsewhere in the near future  
ii system organization 
1 　　a block diagram of our system is shown in fig. 1. the internal data base of the system is divided into two parts: 
 1  network  mutual connection  of  1 . the mutual connection consists of interrelationships such as conditional  implicational  and so forth. an input sentence is analyzed into a semantic tree  and it is read into the semantic network if it is an assertion and is not in the network yet. thus knowledge accumulates in a very natural way in the question answering process. an inverted f i l e of keywords makes it easy to extract information relevant to the question. 
     the parsing routine performs syntactic and semantic analyses of an input query sentence  and produces the parse tree. a network administration routine accepts the tree and relates it to the semantic network which contains sentences already accepted. 
　　　to accomplish a deduction  there are two main parts: the execution routine and the deduction routine. the execution routine  which plays the central role in the deduction process  searches through the network for sentences relevant to the current goal and matches them one by one against i t . the deduction routine manages the global information in the problem solving process such as goal-subgoal relationships  variable bindings 
 for example the word 'man' is bound to the word  smith'   and so forth. this routine also directs the execution routine to determine which sentence must be verified f i r s t . iil knowledge structure 
1 semantic trees. 
     we have applied a kind of dependency analysis to the input japanese sentences. 	a noun modified by an 
adjective is transformed into a kernel sentence having another kernel sentence related to the noun. the 
sentence 
kinben ma wito wa seiko suru 
　　　　　  a diligent man w i l l succeed.  is divided into two sentences like 
hito wa seiko suru 
　　　　　  a man w i l l bucceed.  and 
hito wa kinben da 
  a man is diligent.  
the parsed tree stfueture of this sentence is shown in fig. 1. 
　　　some sentences in japanese have two possible subject phrases  that i s   one which contains the reference particle 'ga' and the other which contains 'wa*. we consider the relational phrase with the particle 'wa' as indicating what the sentence talks about; the phrase with 'ga' is the subject phrase corresponding to the predicate in the sentence. 
zo wa hana ga nagai 
　　　　　  elephant has a long nose.  is a typical example. i t s l i t e r a l translation is   as for elephant the nose is long.  the tree structure of it is shown in fig  1. 
　　　sentences connected by and or ok are represented in the tree structure as shown in fig. 1. 
　　　a sentence which contains upper concept terms replaceable by their lower concept terms is considered as a theorem available to prove a statement which has the lower concept terms in i t . so upper-lower concept relationship among words plays an important role in our system. the input sentence in the form of   a wa b da  meaning a is a lower concept of b  and b is an upper concept of a  has a special structure to express the relationship clearly.   ningen wa kashikoi dobutsu da    a man is an intelligent animal.  is parsed as shown in fig. 1. 
     properties of sentences are attached to the top node of the parsed tree structure. the properties we treated are potential  active  passive  subjenctive  tense  and so forth. the assertion sentence is regarded as true  so that a sign t is given to the property part of the parsed tree. the signs f and u in the property part indicate false and undetermined respectively. 
1 semantic network. 
the network is constructed in the following way. 

1  1  in the case of an assertion sentence s   it is stored in the form shown in fig. 1a. 1'. 

 1  in the case of a negation sentence  schematically written as 'not s1 it is stored in the same form ae fig. 1a  but the property part is written as f. 
 1  if a sentence is - i f s1  then s . '   it is stored in the form shown in fig. 1b. 
 1  if a sentence is 'because s1  s1. it is stored in the form shown in fig. 1c. 
 1  if the sentences s1 and s1 in  1 -- 1  are found in the semantic network  they are not stored newly  
but the stored ones are used. for example the following sentences are stored in the network as shown in fig. 1d. 
because s1  s1. if s1  then s1. 
in this case because s1 is asserted as true  s1 is also 
true. 	1 
　　　the network and parsed trees have the following internal constructions. 

{1  branches in the network and trees are bi-directional for flexible transformation and for efficient search in the deduction process. 
 1  words are not stored in nodes of the parsed trees but by a pointer to the lexical entry of the word  fig. 1   . 
 1  the l e x i c a l e n t r y of a word  c a l l e d nlist  contains not only l e x i c a l information about the word  but also a l i s t of sentences  pointers to the e n t r i e s of the sentences in slist  which contains the word. nlist is a kind of inverted f i l e of keywords. 
co the node of the network is indicated by a pointer from a t a b l e   called slist  which contains informa-
t i o n about the sentence. the information of whether the sentence is true  t   false  p   or undetermined  u   and s o f o r t h i s stored i n t h i s l i s t . 
 1  d i f f e r e n t nodes in the network correspond to d i f ferent sentences. as a r e s u l t   information about 
a sentence can be r e t r i e v e d from a s i n g l e node in the network. 
iv execution routine 
　　　among many i n t e l l e c t u a l a b i l i t i e s of humans  we have implemented in t h i s study the deduction a b i l i t y baaed on the use of  the law of s u b s t i t u t i o n ' and 'the law of i m p l i c a t i o n . ' this is r e a l i z e d by the execution routine and the deduction r o u t i n e . the execution routine t r i e s to match a sentence s t r u c t u r e against another one  regarding an upper concept as a variable over i t s lower concepts. the deduction routine p r o duces subgoals and t e l l s the execution routine which sentence must be v e r i f i e d f i r s t . the execution routine searches through the network for the sentences which 
are equivalent to the goal sentence given by the deduct i o n r o u t i n e . it consists of three main p a r t s : keyword search  matching  and resolving d i f f e r e n c e s . 
1 keyword 	search. 
　　　the system has an i nv e r t e d f i l e of words c a l l e d nlist. by using t h i s f i l e   the execution routine takes out the sentences which contain words in the goal sentence. these selected sentences are presumed to be relevant to the current sentence. 



1 

1 
fig. 1 is an example. if the matching succeeds  the two structures  s-structure and t-structure  are equi-
valent and the difference is resolved. 
v deduction routine 
     the deduction routine controls the whole of the deduction process. this routine has a global knowledge of the process. this knowledge contains the 'anlmal x '  which are usually used in the predicate calculus system in order to restrict the range of vari-
ables. 
　　　we regard a l l words as variables which have their own domains of values. we illustrate this by the 
following example. 
 1  hito ga kenko nara-ba hito wa seiko suru 
     i f a man is healthy  the man w i l l succeed.   q  smith wa seiko suru ka   goal-subgoal organization  variable binding and so forth  	 will smith succeed    

the deduction routine tells the execution routine which sentence must be verified and which sentence  if the 
first t r i a l fails  has to be verified next. 
1 goal organization 
     the deduction method in our system takes a question q as a .goal and tries to verify it by means of 
matching it with the sentences stored in the network. if the t r i a l fails  the deduction routine searches through the network for such sentences as p-*q. those sentences p's  if any  are considered as subgoals to accomplish the previous goal. in the same manner sub-subgoals are produced to accomplish the subgoals. as the process advances  many goals are produced hierarchically. an and-or tree structure is used to remember the hierarchically organized relationships among goals. 
subgoals are created in various cases. 
 1  if a goal sentence g can not be determined to be true or false  subgoals are created by means of searching through the network for the sentences which are antecedents of g. 
 1  in the same case of  1   the negations of consequences of g are taken as subgoals. if they are proved to be true  the sentence g is determined to be false. 
 1  if the matching between two parsed trees is i n complete  subgoals to diminish the mismatches are created. 
　　　in addition to these cases  subgoals are also produced when a goal is divided into several subgoals. for example 'kare wa kinben de shojiki da'  he is diligent and honest  is divided into 'kare wa kinben da'  he is diligent   and 'kare wa shojiki da'  he is honest . 
     the goals are tried one by one  and when there remains no goal  the deduction process stops with a failure message. 	a goal which has several subgoals 
will succeed or not  depending upon whether the subgoals w i l l succeed or not. a goal keeps some information for i t s e l f . for example it has the information of whether it is an and-type or an or-type. depth of goal shows the depth between the top-goal  that i s   a question given by a user  and the present goal. the depth of the top-goal is 1 and the depth of the immediate subgoal is 1. 
     the deduction routine chooses a goal  the depth of which is the smallest of a l l   and tells the execution routine to verify i t . the indicators such as kotei  positive assertion   hitei  negative assertion   match  to be matched  and so forth show the effects of the goals' results to be transferred to their previous goals. kotei  hitei  shows that if this goal succeeds  the sentence corresponding to i t s previous goal is 
proved to be true  false . the subgoals which are produced in order to resolve the mismatch between two parsed trees have the indicator match. 
1 variable binding. 
     to use the law of substitution is one of most important a b i l i t i e s in this system. this is carried the system searches through the network to find out the sentence  1  which is expected to answer the given question. the matching between the consequent part of  1  and the question fails at f i r s t . the cause of mismatch is n difference between 'smith* and 'hito  man '. n routine is called to find out that hito is an upper concept of smith  which is proved by the information 'smith is a man.' in the network. thus a subgoal  the antecedent of  1   in which hito is replaced by smith is produced  that i s   'is smith healthy  '. as the deduction process proceeds  several such bind conditions are produced. each goal must be tried taking into consideration the related bind conditions produced during the former process. 
　　　the deduction routine has a stack to remember these conditions. 	this stack is illustrated in fig  1. each goal has a pointer to this stack and the routine can retrieve the corresponding bind condition of a goal. if a goal fails  then the bind condition generated during the t r i a l of the goal is abandoned. 	on the other hand if a goal succeeds  i t s condition is memorized for use in the succeeding process. 

vi comparison with the systems using predicate calculus 
　　　those systems which use predicate calculus translate the input into a predicate calculus formula  store it in the data base  and use a universal method of deduction such as the resolution method. in those systems common subexpressions appearing in different sentences are stored as many times as they appear in different logical formulas. this is not efficient. in our system the same subexpressions are stored only once and their relations to the other parts of sentences are 
stored by links. so these interrelationships can be utilized in the deduction process. especially when the system deals with a great amount of data and only a relatively small portion of the data has a direct relation to the given question  the quick access to these related expressions is very important in the deduction process. 
　　　which sentences or formulas are available for the current problem needs to be recognized easily  and to do this  a well organized data base is necessary. it is tempting to try to incorporate the use of property lists to speed up resolution. for example one may find it useful for each object symbol c to have access to a chained l i s t of a l l l i t e r a l s or clauses where c occurs. a d i f f i c u l t but more important problem is to 

recognize how a meaningful unit is related to another 
out by considering an upper concept as a variable over unit. it is desirable for the data base to contain 
i t s lower concepts. a word behaves as a constant when information about the interrelationships among the 
it is a lower concept of another word  and as a varimeaningful units. in our system the deduction procedure 
able when it is an upper concept of another word. can retrieve from a node those sentences which have some we do not introduce unary predicates such as'human x '  
1 

1 
