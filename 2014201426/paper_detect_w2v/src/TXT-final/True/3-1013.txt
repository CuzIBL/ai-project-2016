
a general method for defining informative priors on statistical models is presented and applied specifically to the space of classification and regression trees. a bayesian approach to learning such models from data is taken  with the metropolishastings algorithm being used to approximately sample from the posterior. by only using proposal distributions closely tied to the prior  acceptance probabilities are easily computable via marginal likelihood ratios  whatever the prior used. our approach is empirically tested by varying  i  the data   ii  the prior and  iii  the proposal distribution. a comparison with related work is given.
1 introduction
a key feature of the bayesian approachto statistical inference is that prior knowledge i.e. relevantinformationdistinct from the data  can be incorporated into the learning process in a mathematically rigorous and conceptually clear manner. on the assumption that a space of possible statistical models can be defined  prior knowledge is expressed via a prior distribution over this space. this distribution is then updated with the data using bayes theorem to produce a posterior distribution. the posterior distribution is the end result of learning and can then be used to make predictions about future data or  once suitably summarised  to give the data analyst insight into the domain of interest.
　the bayesian framework is compellingly simple  but there are many complexities in applying it to real data analysis. many of these difficulties are computational. for example  in high-dimensional spaces the posterior will be too complex to report directly so features of the distribution  e.g. mean and variance  must be extracted-requiring  in general  a difficult integration. these problems are being progressively alleviated by increased computing power and the subsequent use of markov chain monte carlo  mcmc  techniques to approximately sample from the posterior.
　in this paper an existing bayesian method for defining and using a very flexible class of prior distributions over models is further developed and applied specifically to classification and regression tree  c&rt  models. c&rt models are so well known in machine learning  and increasingly statistics  that this paper assumes familiarity with the basic properties of these models.
　the method is fully bayesian using a version of the metropolis-hastings mcmc algorithm to approximately sample from posterior distributions over the space of all possible c&rt models. even after eliminating a priori uninteresting trees  for example  those containing sparsely populated leaves  this will be a very large space. the key feature of our approach is that the user can declare structural prior knowledge to restrict and/or bias the prior distribution over this space.
　the rest of the paper is structured as follows. section 1 describes our language for defining priors. section 1 describes the specific priors that have been used for bayesian inference of c&rt models. section 1 presents our version of the metropolis-hastings  mh  algorithm and gives a convergence result for one special case. section 1 gives a representative sample of the results of our experiments. the paper concludes with a comparison with related work  section 1  followed by pointers to future work  section 1 .
1 defining priors with stochastic logic programs
our approach to defining priors is related to a line of research which was independently initiated by  chipman et al.  1  and  denison et al.  1 . the basic idea is to specify a prior distribution over a space of models with a stochastic program rather than by some closed-form expression:
instead of specifying a closed-form expression for the tree prior  p t   we specify p t  implicitly by a tree-generatingstochastic process. each realization of such a process can simply be considered a random draw from this prior.  chipman et al.  1 
a convenient language for defining such stochastic programs is stochastic logic programming  muggleton  1 . a stochastic logic program  slp  can be used to define a prior over a given space of statistical models by a two-step process. firstly  a standard logic program is written which defines the desired model space  the hypothesis space in machine learning parlance . we simply define a unary predicate cart/1 in a logic program such that each instantiation for t which makes cart t  true is a term in first-order logic which represents a c&rt model. we can exploit the expressiveness of first-order logic to represent c&rt models  in whichever logical representation is most convenient.
　at this point any c&rt models we wish to exclude from the hypothesis space can be so excluded by adding the appropriate constraints to the logic program. for example  suppose the user is faced with a classification task and knows  or wishes to assume  that the distribution over classes is constant over some rectangular region  a 'box'  of the attribute space. it follows that the box must be contained within a leaf of the 'true' tree so only trees with a leaf containing the box need be considered. in general  the user may wish to declare several such boxes. we have effected such constraints in our experiments by declaring facts such as those given in fig 1  and altering the definition of cart/1 to check that boxes determined by our declarations are not split in any tree.
%const class probs boxname var min max . const class probs box1 x1 -inf 1 . const class probs box1 x1 -inf 1 .
const class probs box1 x1 inf . const class probs box1 x1 -inf 1 .
figure 1: declaring rectangular regions within which the distribution over classes is constant.
　the stochastic element of the slp is most easily understood by first considering how the logic programming language prolog searches for logical consequences of a logic program. given a query such as :-cart t    find t such that cart t  is true    prolog will search for suitable ts with a deterministic depth-first search. when there is a choice of rules each of which might lead to a proof  prolog always chooses whichever rule occurs first in the logic program. if this rule leads to a dead-end  then prolog backtracks and tries the second rule  and so on.
　the basic slp idea is simple: probability labels are attached to rules in the logic program thus converting it into an slp. now when the search for proofs has to choose between rules  a rule is chosen probabilistically according to the probability labels. in this paper  if a chosen rule does not lead to a proof  then backtracking will try from amongst untried rules  revisiting the most recent choice-points first and renormalising the probabilities as necessary: we call this approach  introduced by  cussens  1   backtrackable sampling.
　now when the query :-cart t  is asked  there is a distribution over possible instantiations for t. since each t represents a c&rt model  this provides a prior distribution over this model space.
　in this paper we have extended the representational power of slps so that probability labels may be computed 'on the fly'. slp rules can now be of the form expprob : vars : rule. at each point at which rule is a possible rule to use  it is required that vars is a ground list and that expprob is a probability computable from vars. fig 1 has an example slp where the probability of growing a tree by splitting a leaf depends on the depth of that leaf.
　slps define a distribution over proofs  and to understand this distribution it is useful to represent each proof as a proof 1 - 1/d :  d  : cart leaf .
1/d :  d  : cart split- l r   :-
newd is d+1  splt split  
 newd  : cart l    newd  : cart r .
1:splt x1 . 1:splt x1 . 1:splt x1 .
figure 1: prior distribution over c&rt models where the probability of splitting a leaf depends on its depth d.
tree. fig 1 displays one such proof tree which proves that cart x1- x1- leaf leaf  leaf   is true  i.e. that this 1-leaf tree is in our model space.  figs 1 and 1 use an abbreviated representation of c&rt models  with split values omitted.  each proof tree simply consists of the rules and facts used in the proof 'bolted together' by equality constraints. the initial query appears in an equality constraint in the root node. conceptually  slps execute by probabilistically growing a proof tree  backtracking if the constraints become insoluble.
　to sum up  our priors are defined by a sampling algorithm within a logical framework. the sampling algorithm could  of course  be implemented in any programming language. it involves progressively building up a data structure representing the c&rt model by  i  making choices   ii  checking that constraints are not violated and  iii  backtracking if they have. the motivation for a logic programming implementation is that procedures  ii  and  iii  are built-in  and that logic is a convenientlanguage for declaringconstraints  such as our boxes .
　not all distributions can be directly sampled from  hence mcmc   so such distributions cannot be effectively represented by defining a direct sampling algorithm. however  when a statistical model can be viewed as the end result of some generative process  a generative description is wellmotivated. bayes nets can be generated by adding arcs  angelopoulos and cussens  1  and c&rt models by splitting leaves. our addition of backtracking extends the applicability of this generative view.
=
splt split1  cart l1 	cart r1 
	=	=	=
	splt x1 	cart leaf  cart leaf 
figure	1:	a	proof	tree	which	proves cart x1- x1- leaf leaf  leaf  
1 priors for bayesian c&rt
in this section we describe the actual priors we have used for the experimentsdescribed in section 1. fixing some notation  note that a given c&rt model t maps an example  described by a set of p predictor variables x = x1 x1 ...xp  to a distribution over a response variable y. in the case of classification trees  also known as decision trees  y is discrete and finite  and in the case of regression trees y is continuous. some c&rt implementations throw away information given by the distribution of y and simply return the majority class or mean value as appropriate  but this is just a design decision. fundamentally it is a distribution over y that is given.
　it follows that each tree t defines a conditional probability distribution p y|t x . this conditional distribution is the likelihood function of the following version of bayes theorem: p t|y x  = p t|x p y|t x /p y|x  whose lhs gives the desired posterior distribution over trees. note that the prior p t|x  is only prior to y  it is conditional on the predictor variables so that observed values of x in the data can be used to define sensible priors.
　importantly  this allows us to rule out a priori trees with leaves which contain few examples. there is nothing to stop a user allowing trees with sparsely populated leaves  but ruling out such trees is normal in this research area. it ensures that the space of possible tree structures is a reasonable  finite  size. in our experiments only trees whose leaves have at least 1 examples are permitted  following  denison et al.  1 . the predictors x could also be used to define a prior biassed towards even splits of the data if so desired  but we have yet to investigate the desirability of such an option.
　for most of our experiments we decided to use what we call a growtree prior  which is essentially that used by  chipman et al.  1 . attempting to use an slp to model an externally provided prior provides a test of the representational flexibility of slps: indeed we were unable to pass this test before we extended slps to have variable probability labels. using the growtree prior also allows better comparison with others' results.
　the growtree prior grows a c&rt tree by starting with a single leaf node and then repeatedly splits each leaf node η with a probability α 1+dη  β  where dη is the depth of node η and α and β are prior parameters set by the user to control the size of trees. unsplit nodes become leaves of the tree. if a node is split  then the splitting rule for that split is chosen uniformly. an abbreviatedfragment of the slp which expresses this prior is given in fig 1.
splt: splt :splt lf d .. a/b ..  :- ..
d1 is d + 1 
nwsplit is a * exp  1+d1  -b   ...
 nwsplit :splt lf d1 .. a/b ..    nwsplit :splt lf  d1 .. a/b .. .
 1-splt : splt :splt lf d .. ab lf  :lf = leaf d .. .
figure 1: growtree prior fragment defined with an slp
　we have also experimented with what we call edittree priors. here an 'initial' c&rt model is supplied. this can be any tree  for example the tree produced by the standard greedy algorithm or one manually entered by the user. this tree is then probabilistically 'edited'  by either growing  pruning or changing a splitting rule. the number of such edits is also probabilistic.
1 using the metropolis-hastings algorithm
the metropolis-hastings  mh  algorithm is an mcmc algorithm which defines a markov chain  t  i   with a transition kernel k ti ti+1  as follows. if t i  = t i   then t i+1  is producedby generatingti1 ゛ q t1|t i   for some proposaldistribution q. an acceptance probability α t t1  is used to decide whether to accept the proposed t1. t i+1  = t1 with probability α t t1   the proposed t1 is accepted  and t i+1  = t i  with probability 1   α t t1 . by setting the acceptance probability like this:
		 1 
the chain  t i   will converge to sampling from the desired posterior p t|x y  under weak conditions  whatever the starting point t 1  of the chain . it is not difficult to see  via bayes theorem  that if q t|t1 p t1|x  = rq t t1 q t1|t p t|x   for some function rq  then:
		 1 
in our approach we choose proposal distributions q which permit this simplification of the acceptance probability  and where the value rq t t1  is easily computable for each pair of trees t t1 . the crucial point is this: such a choice of q ensures that α t t1  is easily computable even though computing the prior probability for any given c&rt model  as opposed to merely sampling from the prior  may be prohibitively expensive. this contrasts with  chipman et al.  1  where  specifications  which  allow for straightforward evaluation of p t  for any t  are required. for us the computation of prior probabilities can be expensive due to backtracking. without backtracking slps are similar to stochastic-context free grammars  scfgs -particularly when probability labels are fixed  and not computed'on the fly'-andscfg dynamicprogramming algorithms could presumably be used to compute prior probabilities. ruling out backtracking greatly restricts the constraints the user can declare so we always allow for backtracking.
　since our trees do not explicitly define a distribution over classes at the leaves of the tree  our likelihoods are marginal likelihoods-we integrate over all possible class distributions. this integration automatically prevents over-fitting: trees with 1% training set accuracy do not generally have high marginal likelihood. to actually do the integration  we use exactly the same approach as  chipman et al.  1; denison et al.  1; 1 . for each leaf  the uniform dirichlet distribution  all parameters set to 1  is the distribution over all possible distributions over classes. the dirichlet assumption allows a closed form for the marginal likelihood p y|t x .
　our proposals can best be understood by first recalling that sampling c&rt trees from an slp prior is effected by sampling proofs from the prior as explained in section 1  and that each such proof has an associated proof tree  such as shown in fig 1. each proposal we have considered works by pruning the proof tree corresponding to the current c&rt model at some point  and then re-growing the proof tree from the pruning point using the sampling mechanism associated with the prior. our proposals only differ in how they choose where to 'snip' the proof tree. since only the sub-tree below the prune point is resampled  our proposals are not equivalent to proposing with the prior p t|x   except for one special case to be discussed shortly . instead each prune point k corresponds to proposing a tree according to p t|x t （ tk  where tk is the set of trees which may differ from the current tree only in the sub-tree under prune point k.
　one  overly  simple proposal corresponds to the independent metropolis-hastings algorithm which prunes away the current model completely so that a new model is sampled from the prior independently of the current model. for this proposal  denoted q1  we have the following mcmc convergence result. let μi be the distribution over trees produced at the ith iteration of this independent mh algorithm. let t be a c&rt tree with maximal marginal likelihood: then
       |μi   p ，|x y | ＋  1   p t |x /p t |x y  i  1  where | ， | denotes the total variation distance between two distributions. so there is exponentially fast convergence to the true posterior p ，|x y  using this independent mh algorithm. the catch is that  p t |x /p t |x y   the ratio between t 's prior and posterior probability  is tiny for any reasonably sized dataset  so in experiments  not presented here  the independentm-h algorithm performspoorly. the convergence result can be derived from one by  doob  1  which is given by  rosenthal  1 . to apply doob's result it is necessary 1to produce an upper bound on pt1 mint kq1 t t1   where kq is the transition kernel associated with q1. in fact  we can show  proof omitted  that this sum is exactly p t |x /p t |x y   thus establishing  1 . this upper bound for our discrete finite space is exactly half the size of the bound for the general independent mh algorithm established by  mengersen and tweedie  1 .
　a somewhat better performing proposal  denoted q1 n  cycles through proposals qk for k = 1 1 ...n for a usersupplied n  where qk is the proposal which prunes the proof tree at the kth choice point. we have rq1 n t t1  《 1  so that the acceptance probability is simply a likelihood ratio. however  our best performing proposal  denoted quc  makes a uniform choice of a prune point from all those available in the current tree. for quc  rquc t t1  = dt/dt1  where dt is the depth of tree t.
　one recent innovation has greatly increased the efficiency with which the space is explored. in all previous work using slps for mcmc  the prune points to which our proposals jumped were not organised in a proof tree  but in a sequence  a branch of the relevant sld-tree  in fact . essentially  this was because our previous proposal mechanism was closely modelled on prolog backtracking: if we backtracked to choice point k all c&rt building work done after that choice point was thrown away. now  if we backtrack to point k then only the proof tree below k is  stochastically  rebuilt  even if other parts of the proof tree were built chronologically later. translating this specifically to c&rt models  this means our proposals can now snip the current c&rt tree at any node  and re-grow the tree from there  leaving the rest of the c&rt tree unscathed. this makes it easier for the markov chain to head in the direction of high likelihood trees: sub-trees with high-likelihood tend to be altered rarely whereas proposed replacements for low-likelihood sub-trees are accepted relatively often.
1 experimental results
in our experiments we have used three datasets: the wisconsin breast cancer data  bcw   the kyphosis dataset  k  and the pima dataset  p . bcw was originally donated to the uci depository by  wolberg and mangasarian  1  and was used by  chipman et al.  1 . dataset k comes as part of the rpart r package for building and manipulating c&rts. dataset p is a uci dataset which  denison et al.  1 used for extensive bayesian c&rt analysis. following  chipman et al.  1  we have simply deleted 1 datapoints from bcw which contain missing values. in all cases the machine learning task is binary classification using integervalued predictors-1 predictors in the case of bcw  1 for k and 1 for p. all splits are binary: made by splitting on some threshold. there are 1 datapoints for bcw  1 for k and 1 for p.
　we have performed a large number of experiments  and analysed the results in many ways. only a small representative sample of this is reported here. data and software for reproducing all of our experiments can be found at http://www.cs.york.ac.uk/゛nicos/ sware/slps/mcmcms/. we used sicstus prolog 1 running under linux on two machines each with a 1ghz processor and at least 1mb ram. the computation of the loglikelihood ratio uses a c function called from prolog. running a chain for 1 iterations takes at most 1 minutes.
1 comparison to the standard c&rt algorithm
the contrasts between bayesian c&rt and the standard greedy algorithm for building a single c&rt model have been well explored in the existing bayesian c&rt literature  chipman et al.  1; denison et al.  1; 1 . the bayesian method represents posterior uncertainty better and makes a more thorough exploration of the model space. this is at the cost of more computation. how well the bayesian approach does in terms of predictive accuracy depends  of course  on the prior. when we do have useful prior knowledge it can help us if it can be incorporated into the prior distribution. facilitating this is our central motivation.
　a tree with maximal marginal likelihood is a maximum a posteriori  map  model when a uniform prior is assumed. call such trees mapunif trees. any mcmc run produces an approximation to a mapunif tree: it is the maximum marginal likelihood tree in the mcmc sample. since the standard greedy algorithm is closely connected to a search for a mapunif tree  buntine  1  it is interesting to compare the marginal likelihood of trees produced using the greedy algorithm to that of the mapunif tree approximations found in the the mcmc sample.
　the trees found by rpart for datasets bcw and k using default settings have  rounded  marginal log-likelihoods -1

figure 1: distribution of differences in estimated class posterior probabilities from two mcmc runs only differing in random seed.
and -1  and sizes 1 and 1  respectively. unsurprisingly  there are trees produced by mcmc runs with higher marginal loglikelihoods  i.e. with values closer to that of a mapunif tree . for bcw  resp. k  we can find a tree with 1  resp. 1  leaves and log-likelihood of -1  resp. -1 .
1 reproducibility of results
since the aim of using mcmc is to approximate the posterior distribution  it is important that inferences drawn from any reasonably long realisation of the markov chain are robust to changing the random seeds which determine the evolution of the chain. using our original sequence-based proposals  there was strong evidence that this was not the case: for example  plots of log-likelihood against iteration number  log-likelihood trajectories  could be quite different for experiments which were identical except for the random seeds used.
　to test our new proof-tree based proposals we performed the following experiment  amongst many others not reported here . two mcmc runs of 1 iterations were performed using the growtree prior  α = 1 β = 1  using only 1 of the pima dataset  differing only in the random seeds used. for each of the remaining 1 pima dataset examples each of the two mcmc samples were used to approximate the posterior probability that the example had class label 1. this was done by simply getting each tree in the mcmc sample to make a class prediction for the example based on the majority class at the appropriate leaf and setting the class posterior probability equal to the relative frequency of class 1 predictions. clearly  if both mcmc samples were perfect representations of the true posterior  then the difference in estimates of the class 1 posterior would be zero for each example. naturally  this is not achieved but the distribution of the differences in probability estimates  shown in fig 1  is highly concentrated about zero which provides evidence that our approach often produces values close to the true posterior  for different runs.
1 using local jumps
local jumping in tree space helps prevent getting stuck. the log-likelihood trajectory using q1 shown in fig 1  shows that the big jumps which q1 proposes are rarely accepted  so the chain remains stuck at the same model for long periods. this problem is even more pronounced if q1  the independent mh algorithm is used. compare this with other figures where the quc is being used.

figure 1: log-likelihood trajectory. prior=growtree  β = 1   data=bcw  mcmc=q1.

data=bcw  mcmc=quc  sequential. for lhs: prior=edittree. for rhs: prior=growtree  β = 1 
1 influence of priors
fig 1 compares log-likelihood trajectories using the edittree prior and the growtree prior respectively with all other parameters being equal. the distinct horizontal line in the edittree trajectory is clear evidence that the edittree prior is pulling the markov chain back to the initial tree. note that figs 1 all contain initial very low log-likelihoods  corresponding to the chain's initial c&rt model  which have been truncated for space reasons.
　 denison et al.  1  examined how successful their chains were at finding c&rt trees with high marginal likelihood using the pima  p  dataset. their maximum marginal log-likelihood was -1; our highest was -1. to test a hypothesis that many high likelihood c&rt models did not have high posterior probability for our priors  and hence were unlikely to be visited   we started chains from the loglikelihood=-1 c&rt model of denison et al.. fig 1 show the results where the rhs trajectory corresponds to a prior with a stronger bias towards smaller trees. in both cases the prior pulls away from high-likelihood c&rt models  all the more rapidly for the stronger prior.
　since the goal of including prior knowledge is to improve decision making under uncertainty  e.g. classifying test examples   we performed experiments where a known 'true' tree was used to generate synthetic train and test data. we then included boxes  see section 1  consistent with the true tree as constraints on a growtree prior  produced mcmc samples using the synthetic training data  and measured predictive accuracy on the synthetic test data. each of the 1 test examples was classified into its most probable class as estimated by the mcmc sample. this was all repeated for 1 random seeds. with no box constraints test-set accuracies were 1%  1% and 1%. with the box constraints given in fig 1  the test-set accuracy was exactly 1% for each random seed. these results indicate that accurate prior

figure 1: log-likelihood trajectories. in both cases: data=p  mcmc=quc  proof tree. prior=growtree. initial tree = denison's maximal likelihood. for lhs: β = 1. for rhs: β = 1
knowledge  i  helps convergence and  ii  increases predictive accuracy.
1 comparison with related work
this paper lies at the intersection of two lines of work: that on bayesian c&rt  chipman et al.  1; denison et al.  1; 1  and that on using slps for general bayesian model inference  angelopoulos and cussens  1 . the slp work had claimed to provide a general bayesian machine learning method but had only results for model spaces composed of bayesian nets. this paper backs up this initial claim by applying the basic framework of  angelopoulos and cussens  1  to c&rt model space. the slp method has also been improved in a number of ways:  i  probabilities no longer need be hard-coded constants   ii  the use of backtrackable sampling adds an element of search to the prior and  iii  the proposal mechanism now works on a  proof  tree structure which makes it easier to move through the model space.
　the most obvious difference from other bayesian c&rt work is that here all  non-parameter  priors are defined by an slp-however as we have seen slps can encode  at least some  priors originally expressed otherwise. secondly  in our approachthere is onlyone way of proposingnew c&rt models: by pruning and re-growing the proof tree. in the other bayesian c&rt work a variety of moves are used-five are listed in  denison et al.  1  p. 1 . the compensation for our severely restricted proposals is that no prior terms complicate the acceptance probability. constraining the proposal mechanism to produce such an acceptance probability is also a choice taken in  denison et al.  1 -although for this to work the proposal mechanism has to depend upon global parameters of the current tree. the biggest contrast with previous bayesian c&rt work is that we permit big jumps by pruning the proof tree near the root. in  denison et al.  1  it is noted that pruning off any given branch of a tree is straightforward in their approach but that how to generate a similar branch  to maintain reversibility   is not obvious . in the approach presented here it is obvious  we can just re-grow the proof tree because the proposal is based on the prior. in  denison et al.  1  the danger that many big jumps will propose trees with sparsely populated leaves is also noted-we avoid this problem by simply compelling the proposal mechanism to search for trees  via backtracking  with adequately populated leaves.
1 future work
the convergence result  1  for the independent mh algorithm is something we hope to generalise to other proposals. this will guide the choice of proposal mechanism in contrast to our current empirical approach. in ongoing work  angelopoulos and cussens  1  experimental results have been produced which show that tempering improves the rate of convergence of quc considerably. thirdly  like all other work  that we know of  on bayesian c&rt  we do not have full-blown convergence diagnostics implemented: a deficiency we hope to remedy.
　our current implementation does not fully exploit prolog's built-in backtracking: if this were possible this would permit a significant speed-up. a more radical approach is to adapt an existing prolog system to have our probabilistic mechanisms built-in.
acknowledgements
thanks to 1 anonymous reviewers for useful criticisms. this work was supported by the uk epsrc mathfit project stochastic logic programs for mcmc  gr/s1 .
