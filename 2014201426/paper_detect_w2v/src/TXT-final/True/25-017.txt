 
we extend work on difference identification and reduction as a technique for automated reasoning. we generalise unification so that terms are made equal not only by finding substitutions for variables but also by hiding term structure. this annotation of structural differences serves to direct rippling  a kind of rewriting designed to remove differences in a controlled way. on the technical side  we give a rule-based algorithm for difference unification  and analyze its correctness  completeness  and complexity. on the practical side  we present a novel search strategy for efficiently applying these rules. finally  we show how this algorithm can be used in new ways to direct rippling and how it can play an important role in theorem proving and other kinds of automated reasoning. 
1 	introduction 
motivation and context 
heuristics for judging similarity between terms and subsequently reducing differences have been applied to automated deduction since the 1s when newell  shaw  and simon built their  logic machine   nss1  for a propositional calculus. their intent was to simulate the behavior of a human on the same task. more recently  in resolution theorem proving  a similar theme of difference identification and reduction appears in  bs1; dig1; mor1 . in this work a partial unification results in a special kind of resolution step  e or rue-resolution  where the failure to unify completely produces new inequalities that represent the differences between the two terms. this leads to a controlled application of equality reasoning where paramodulation is used only when needed. the intention was not to design a human oriented problem solving strategy  but rather  to use differ-
   *this research was partially funded by the german ministry for research and technology  bmft  under grant its 1 and a serc postdoctoral fellowship. the responsibility for the contents of this publication lies with the authors. we thank the edinburgh mathematical reasoning group for their encouragement and criticism  in particular alan bundy and andrew ireland. 
1 	automated reasoning 
toby walsh 
dept. of ai  university of edinburgh  1 s. bridge  edinburgh  scotland 
 tw aisb.ed.ac.uk  
ence identification and reduction as a means of reordering a potentially infinite search space. 
¡¡here we report on research sharing both these cognitive and pragmatic aims. we have developed a general procedure called difference unification for identifying differences between two terms. difference unification extends unification in that it decides if terms are syntactically equal not only by giving assignments for variables but also by computing what incompatible term structure must be removed. this incompatible term structure  called wave-fronts  is marked by annotations which are used to direct a special kind of rewriting called rippling; rippling seeks to reduce the differences between the terms by moving the wave-fronts  out of the way  while not disturbing the unannotated parts of the terms 
related work 
this research is the outgrowth of previous work at edinburgh in inductive theorem proving. there bundy  bun1; bs+1  suggested that in proofs by mathematical induction  the induction conclusion could be proven from the induction hypothesis by rippling on the induction conclusion. rippling has been employed in the oyster/clam prover. a similar kind of rewriting was developed independently by hutter  hut1   from ideas in  bun1   and employed in the inka system. both systems have enjoyed a high degree of success stemming from several desirable properties of rippling. these include  see  bs+1   that rippling involves very little search and rippling always terminates since wave-fronts are only moved in some desired  well-founded  way - usually to the top of the term. 
research contributions 
motivated by a desire to apply rippling outside of inductive theorem proving  in bw1 we introduced difference matching which extends matching to annotate the matched term so it can be rewritten using rippling. we list there  as well as in  wnb1  several applications of this idea. in this report we take another step forward. our contributions are several fold. first we extend difference matching to difference unification whereby substitutions and annotations are returned for both terms. the rule based algorithm we give uses conventional unification in a transparent way whereby other additions to unification  such as equations or higher order patterns  
can be easily made. we prove the algorithm given is both sound and complete with respect to its specification. second  unlike difference matching  difference unification can return a large number of matches which we are not interested in; there may be exponentially many ways to annotate two identical terms. hence  we demarcate two restricted classes of useful answers  which we call strongly and weakly minimal . further  we give a novel search strategy  a meta-interpreter  that finds answers in these classes with minimal search. third  we give a thorough analysis of the complexity of difference unification and subproblems. finally  we provide examples of how difference unification can be used. in doing so  we present a new paradigm for theorem proving/problem solving whereby proof proceeds by alternating between annotating differences and reducing them. this combination is different from previous work combining rippling and difference matching since here successful rippling does not guarantee successful rewriting of one term with another; rather  it must be seen as one step  in possibly many  of difference reduction. this  along with differences from traditional rewrite based theorem proving  is developed in the next section. 
1 	applications 
1 	n o r m a l i z a t i o n 
we begin with a simple example that both introduces notation and illustrates how difference unification can be used to apply rippling in a new way: as an iterative difference reduction technique. in rippling's original role in inductive theorem proving  successfully rippling the goal always allows use of the induction hypothesis. more particularly  in an inductive proof the induction conclusion is an image of the induction hypotheses except for the appearance of certain function symbols applied to the induction variable in the conclusion. the rest of the induction conclusion  which is an exact image of the induction hypothesis  is called the skeleton. the function symbols that must be moved are the wavefronts. for example  if we wish to prove p x  for all natural numbers  we assume p n  and attempt to show p s n  . the hypothesis and the conclusion are identical except for the successor function s .  applied to the induction variable n. we mark this wave-front by placing a box around it and underlining the subterm contained in the skeleton   rippling then applies just those rewrite rules  called wave-rules  which move the difference out of the way leaving behind the skeleton. in their simplest form  wave-rules are rewrite rules of the form  by design  the skeleton 
a{y  remains unaltered by their application. if rippling succeeds then the conclusion is rewritten us-
ing wave-rules into some function of p n ; that is  into  may be the identity . at this point we can call upon the induction hypothesis. 
   an analogous situation occurs in difference matching. if we can match two terms  annotating one with wavefronts  then successful rippling allows rewriting one to the other. however  this fails with difference unification as both terms are annotated. for example  consider the associative  infix  function symbol +. the following are wave-rules capital letters represent variables and lower case letters constants and bound variables . 
 1  
 1  
as previously noted  rippling terminates because wavefronts in the rewrite rules must match those in the rewritten term and these are only moved in some well-founded direction. we may therefore rewrite with the associativity of + in both directions. consider proving 

if we difference unify the left hand side of this equation with the right  there are 1 annotated answers corresponding to the 1 ways of selecting any 1 constants from the 1 terms and 1 ways of selecting any one. in general  we prefer only those with minimal amounts of annotation. furthermore  as wave-rules only exist to ripple these minimal annotations  rippling would not find proofs for the others. picking minimal annotations  formally defined in ¡ì1  narrows the choice to 1: 

both of these will lead to proofs by rippling  the first giving a left associative normal form  the second giving a right . in what follows we concentrate on the first. the left hand side of this equation is completely rippled-out: no more wave-rules need  or can  be applied since the wave-fronts are already outermost. the right hand side ripples with  1  yielding 

and now both terms are rippled-out. though rippling is done  we have not succeeded in proving the terms equal since the wave-fronts themselves differ. 
   one might conclude that rippling has not accomplished anything but that would be false. it has reduced the  inner difference  between these terms: each now contain a copy of the previous skeleton a+ b intact. difference unifying   a + b  + c  + d against  a + b  +  c + d  reveals this. there are 1 annotations in total  but only 1 are minimal  and only one of these can be rippled: 

we have made progress since these terms have a larger skeleton. as before the left hand side is rippled-out; rippling on the right with  1  yields the left hand side  so we are done. this example illustrates a general phenomenon: iterating difference unification and rippling successively decreases the difference between two terms. 
¡¡this combination can be very effective. in associative reasoning each iteration of difference unification and 
	basin and walsh 	1 
rippling increases the skeleton and hence terminates successfully. of course  exhaustive application of one of the associativity rules would also suffice  but there are advantages in using difference unification and rippling. to begin with  one needn't completely normalize terms  rippling proceeds only as far as is required to reduce the difference. moreover  as both left and right associativity may be used  fewer rewrite steps may be required. more significantly  there are theories where we need both and where normalization would therefore loop. the combination of difference unification and rippling is often an effective heuristic in theories where rewrite based procedures do not exist; the next example  aside from being more general  illustrate this. 
1 	series 
difference unification and rippling have proved also very useful in summing series. consider  for example  the problem of finding a closed form sum for 

using the standard result  such results are computed automatically in  wnb1   
		 1  
we encode the problem of finding a closed form sum as the task of proving a theorem of the form  

where the existential witness s is restricted to be in closed form. to prove this theorem  we first eliminate the existential quantifier. the standard form method  wnb1  then difference unifies the dequantified goal with  1  giving the minimal annotations 

where c and d are constant with respect to j. note that  1  could not be used in a procedure based on exhaustive rewriting since  like associativity when used in both directions  it would loop. 
¡¡the standard form method first applies wave-rule  1  to the goal dividing its wave-front into two  

we therefore re-difference unify goal and hypothesis to give  as with the associativity example  a larger skeleton  

rippling  though unable to move the differences up completely  has reduced the inner difference. indeed  the difference has been so reduced that we can now substitute the standard result into the goal  


1 	automated reasoning 

the standard form method now difference unifies against the standard result for the sum of the first n integers  and ripples with  1  to complete the proof. 
	1 	o t h e r applications 
we have explored a number of other applications of difference unification that  for lack of space  we cannot develop here. for example  in  bw1a; bbh1  we show how difference unification can be used to guide rewriting in so called proof by consistency techniques. other researchers have also explored applications of these ideas. hutter has recently reported on applying associative commutative difference unification and rippling to solve sams lemma in the i n k a system  ch1j. 
	1 	specification 
to specify difference unification we must be more precise about the representation of annotations. as in  bw1  annotations are represented in a normal form in which 

	basin and walsh 	1 


figure 1: dunify : transformation rules for difference unifying s and t 

   these rules have been implemented in prolog. the following table gives 1 out of the 1 results of difference unifying   x + y   + z with x +  y + z . note that for readability we have merged adjacent wavefronts in the  box and hole  presentation. 

the first three annotations are strongly minimal and give the only wave-rules  oriented appropriately . the fourth  fifth and sixth annotations are neither weakly nor strongly minimal. the last two annotations are weakly but not strongly minimal. this once again demonstrates that difference unification is not unitary  even when restricted to strong or weak minimality. 
   the following is a sample execution trace of the first result. it results from applying the rules: h i d e l   decompose  delete  h i d e r   and delete. 

1 	left-first search 
the transformation rules  when exhaustively and nondeterministically applied  generate all possible difference unifications  not just those that are weakly or strongly minimal. this is both time consuming and almost always unnecessary. we have therefore implemented a search algorithm  i.e.  a meta-interpreter  for traversing the space defined by these rules so that we are guaranteed to encounter just the weakly or strongly minimal difference 
1 	automated reasoning 
unifications. in the strongly minimal case  potentially an exponential amount of search is saved. 
we first describe the structure of the search space. 
 nodes correspond to the quadruples giving the current state. arcs to the left result from applying one of the unification rules: delete  decompose  i m i t a t e l   i m i t a t e r   e l 1 m i n a t e l   and e l i m i n a t e r . arcs to the right result from applying a hiding rule: hid el and h i d e r . the key to returning minimal difference unifications is observing that a non-minimal difference unification uses more applications of the hiding rules than a minimal one  though it may use a greater  lesser or equal number of unification rules. thus  in searching the tree we want to minimize right arcs since each adds more annotation. we call a search algorithm which does this left-first search. at the n + 1-th ply of the search we explore all those nodes whose path back to the root includes n right arcs. this search strategy returns minimal cost solutions where hiding rules  right-rules  have  unit  cost and other rules  left-rules  having no cost. we have implemented a meta-interpreter that performs this search as follows. given a set of nodes tv  left* n  returns the set of nodes reachable from the nodes in n by taking any number of left arcs. the function right n  returns the set of nodes reachable from the nodes in n by taking one right arc. finally solutions{n  returns any answers in the set of nodes n. figure 1 gives the algorithm and illustrates the order in which nodes in a binary tree are explored under left-first search. for strongly minimal difference unifications  this algorithm returns the first set of answers and stops. for weakly minimal difference unifications  we must save the answers generated  and continues to search comparing new answers for weak minimality against previous ones. unfortunately  to return all the weakly minimal difference unifications we must search the whole tree. the advantage of left-first search is that we can immediately tell whether an answer is weakly minimal. 
1 	properties 
let us introduce some notation that will be used to prove properties of difference unification and the dunify rule 
set. we write   to indicate that there is a derivation d  that is  a possibly empty sequence of dunify rule applications  which 


figure 1: algorithm and search tree 
in turn follows from our restrictions on the deletion and elimination rule; they guarantee that every term position in pos b  and pos t  eventually appears in some equation in the derivation d. since elements of a  are a subset of pos s  corresponding to addresses of function arguments in s  and likewise for at  appropriate hiding rule can always be applied. 
¡¡the soundness and completeness arguments only rely on the underlying unification algorithm being sound  complete  and  decompositional  in the sense that every position in the original terms eventually appears in the course of the derivation. hence  if we replace the underlying unification algorithm with something stronger  e.g.  incorporating equations that preserve these properties for some equational theory  then again we will have a sound and complete algorithm with respect to that theory. we suspect that there are many natural applications of equational difference unification  e.g.  the previously mentioned work of hutter. 
theorem 1  termination  the dunify rule set always terminates. 
proof  sketch : given input s and i  use a lexicographic ordering on the triple  i  v  f  were / is |pos s | + |pos  ti - /'  v is the number of imitation steps performed in a sequence of rule applications  v is the number of distinct variables in the  current  equation set  and f is the number of function symbols  including 
constants  in the  current  equation set. 
	1 	complexity 
dunify has been given as a set of rules. if they are applied non-deterministically  it is easy to see that it can take exponential time to find a solution to a problem as we may  using the hide and imitate rules  consider all the ways of hiding function symbols.1 a term of size n  n function symbols  has o n  interior  neither constants or variables  function symbols that can be hidden in 1n  different ways; hence  naive execution can be exponential. it is natural to ask whether this the best that we can do  and which are the tractible cases. in asking such questions we must distinguish between the 
¡¡¡¡1 also note that unification algorithms which explicitly represent substitutions are not efficient. this can  however  be avoided by using a rule-based approach such as  jk1l  at the cost of rules with rather more complicated sideconditions. 
	basin and walsh 	1 

problem of generating all solutions and that of generating a solution or knowing if one exists. the first problem is easily seen to require exponential size even in the very restricted of case of ground difference matching. 
t h e o r e m 1 there are difference matching problems requiring exponential time. 

   problems generating exponential numbers of solutions are exceptional as they involve unusual amounts of repeated structure. in general  there are far fewer matches and unifiers; so it is interesting to investigate the complexity of returning a single solution  or determining if one exists. the first problem is polynomial time solvable for ground terms. 
t h e o r e m 1 given terms s and t we can determine if s difference matches t  s may be annotated with skeleton t  or s difference unifies with t in polynomial time. 
p r o o f  sketch : in  ns1  an algorithm based on dynamic programming is given for solving the homomorphic embedding problem of one ground term into another in polynomial time. this problem is the same problem as ground difference matching. it is easy to modify this idea to provide an algorithm for ground difference unification. furthermore  these algorithms can be easily modified to return sets of answers as well as indicating if answers exist  bw1a . . 
   as a side note  observe that while the above ground difference unification algorithm can be easily modified to yield minimal answers  there is a trivial linear time algorithm for determining difference unifiability although it does not give minimal answers. that is  s and t will difference unify iff they share at least one constant  of arity 1 . in the non-ground case  s and t are difference unifiable iff they share one constant or if either contains a variable. in this respect  difference unification is  perhaps surprisingly  easier than difference matching. 
   in general  difference unification and all its subproblems are trivially in np since we can guess annotations and then unify or match resulting skeletons in polynomial time. in the nonground case  when variables are added determining the existence of a solution is np hard. 
t h e o r e m 1 difference unifying s and t  with annotation on only one side is np hard. 
the proof is given in  bw1a  and uses a reduction from 1sat similar to that used in the proof of the np hardness of set-matching given in  kn1 . 
1 	conclusions 
in  rob1   j.a. robinson presented a simple account of unification in terms of difference reduction. he observed: 
    unifiers remove differences ... we repeatedly reduce the difference between the two given expressions by applying to them an arbitrary reduction of the dif-
ference and accumulate the product of these reductions. 
1 	automated reasoning 
this process eventually halts when the difference ts no longer negotiable  via an assignment f at which point the outcome depends on whether the difference is empty or nonempty.  
   in this light  our research can be seen as a direct extension of robinson's notion of difference reduction: we reduce differences not just by variable assignment  but also by term structure annotation. what makes our extended notion of unification tenable  indeed attractive  is that this annotation is precisely what is required for rippling to remove this difference. 
