
constraint optimization underlies many problems in ai. we present a novel algorithm for finite domain constraint optimization that generalizes branch-and-bound search by reasoning about sets of assignments rather than individual assignments. because in many practical cases  sets of assignments can be represented implicitly and compactly using symbolic techniques such as decision diagrams  the set-based algorithm can compute bounds faster than explicitly searching over individual assignments  while memory explosion can be avoided by limiting the size of the sets. varying the size of the sets yields a family of algorithms that includes known search and inference algorithms as special cases. furthermore  experiments on random problems indicate that the approach can lead to significant performance improvements.
1 introduction
many problems in ai  such as planning  diagnosis  and autonomous control  can be formulated as finite domain constraint optimization problems  schiex et al.  1 . thus  the ability to solve large instances of optimization problems efficiently is key for tackling practical applications.
¡¡depth-first branch-and-bound finds optimal solutions by searching through the space of possible assignments. to prune parts of the search tree  it computes a lower bound on the value of the current partial assignment  and compares it with the value of the best solution found so far as an upper bound. while branch-and-bound is memory-efficient  it can lead to impractical run-time  because the size of the search tree can grow exponentially as its depth increases.
¡¡an alternative approach is to infer optimal solutions by repeatedly combining constraints together. this approach is search-free and thus does not suffer from the run-time complexity of backtracking; however  its exponential memory requirements can render this approach infeasible as well.
¡¡in practical cases  however  constraints often exhibit a structure that can be exploited in order to reduce the memory requirements. decomposition  gottlob et al.  1  can exploit structural properties such as low induced width in order to break down the set of variables and constraints into smaller subproblems. likewise  symbolic encoding using decision diagrams  bryant  1  can exploit regularities within sets of assignments  shared prefixes and postfixes  to collapse them into a much smaller representation. however  while these techniques can push the border on the size of the problems that can be handled  they still do not avoid the fundamental problem of memory explosion.
¡¡the idea presented in this paper is to extend branch-andbound search to incorporate both decomposition and symbolic encoding. in particular  our algorithm simultaneously maintains sets of assignments  and thus sets of bounds  instead of single assignments. because a set can  in many cases  be represented and manipulated efficiently using an implicit  symbolic representation  such as a decision diagram   the setbased search can compute bounds faster than by explicitly searching over the individual assignments  while memory explosion can be avoided by limiting the size of the sets. in our approach  similar to domain splitting  the size of the sets is controlled by partitions defined for the domain of each variable. by varying the granularity of the domain partitions  a family of tree-based algorithms is obtained that includes a recently introduced search algorithm called btd  branch-andbound on tree decompositions   terrioux and jegou  1¡ä   and dynamic programming  kask et al.  1  as limiting cases. we show that a trade-off exists between these two extremes  and thus for many practical cases  it is advantageous to pick an intermediate point along our spectrum.
¡¡the paper is organized as follows. after an introduction to the valued constraint satisfaction problem framework  schiex et al.  1   we present a way to exploit structure in the constraints using tree decomposition and a data-structure for symbolic encoding known as algebraic decision diagrams  adds   bahar et al.  1 . we then describe the set-based extension of the branch-and-bound algorithm  and show how it generalizes existing algorithms. finally  preliminary experiments on random problems illustrate the trade-off between search and inference and the benefit of a hybrid strategy.
1 constraint optimization problems
definition 1  constraint optimization problem  a constraint optimization problem  cop  consists of a tuple  x d f  with variables x = {x1  ...  xn}  finite domains d = {d1  ...  dn}  constraints f = {f1  ...  fm}  and a valuation structure  e ¡Ü ¨’ ¡Í   . the constraints fj ¡Ê f are functions fj : d1¡Á...¡Ádn ¡ú e mapping assignments to x to values in e. e is totally ordered by ¡Ü with a minimum element ¡Í ¡Ê e and a maximum element   ¡Ê e  and ¨’ is an associative  commutative  and monotonic operation with identity element ¡Í and absorbing element  .
¡¡the set of valuations e expresses different levels of constraint violation  such that ¡Í means satisfaction and   means unacceptable violation. the operation ¨’ is used to combine  aggregate  several valuations. a constraint is hard  if all its valuations are either ¡Í or  . for notational convenience  we denote by xi ¡û v both the assignment of value v ¡Ê di to variable xi  and also the hard constraint corresponding to this assignment  its valuation is ¡Í if the value of xi is v  and    otherwise . likewise  we regard elements of e as values  but also as special cases of constraints  constant functions .
definition 1  combination and projection  let f g ¡Ê f be two constraints. let t ¡Ê d1 ¡Á...¡Ádn  and let t¡ýy denote the restriction of t to a subset y   x of the variables. then 
1. the combination of f and g  denoted f ¨’ g  is the constraint that maps each t to the value f t  ¨’ g t ;
1. the projection of f onto a set of variables y   denoted f  y   is the constraint that maps each t to the value min{f t1  f t1  ... f tk }  where t1 t1 ... tk are all the assignments for which ti ¡ýy = t ¡ýy . given a cop and a subset z   x of variables of interest  a solution is an assignment t with value .
in particular  for z =    the solution is the value ¦Á  of an assignment with minimum constraint violation  that is  ¦Á  =
.
¡¡for example  the problem of diagnosing the full adder circuit in fig. 1 can be framed as a cop with variables x = {u v w y a1 a1 e1 e1 o1}. variables u to y describe boolean signals and have domain {1}. variables a1 to o1 describe the mode of each gate  which can either be g  good   s1  shorted to input 1   s1  shorted to input 1   or u  unknown failure . the cop has five constraints fa1  fa1  fe1  fe1  fo1  one for each gate in the circuit. each constraint expresses that if the gate is g then it correctly performs its boolean function; and if it is s1  s1  then it is broken such that its output equals its first  second  input; and if it is u then it is broken in an unknown way and no assumption is made about its behavior. the valuation structure captures the likelihood of being in a mode  and is   1  ¡Ý ¡¤ 1   with ¡¤ being multiplication over the real numbers . we assume or-gates have a .1 probability of being g  a .1 probability of being s1  s1   and a .1 probability of being u; both and-gates and xorgates have a .1 probability of being g  a .1 probability of being s1  s1   and a .1 probability of being u. the value of the best solution then corresponds to the most likely fault in the circuit. for the example  ¦Á  is .1  corresponding to a stuck-at-first-input  s1  fault of or-gate 1.
¡¡we introduce four more operators that we will use later to compare constraints and to turn them into hard constraints. the minimum operation  denoted min f g   returns the constraint whose valuation is the minimum of f t  and g t :
 	if f t    g t  otherwise

figure 1: full adder circuit consisting of two and gates  one or gate  and two xor gates. input and output values are observed as indicated.
the sinking operation  denoted sink f g  returns the constraint that forbids t if f t  ¡Ý g t :
 t 	if f t    g t  otherwise
the lifting operation  denoted lift f   turns a constraint into a hard constraint that allows t if f t     . finally  the complement of a hard constraint f  denoted cmpl f   is the constraint whose valuation is   if f t  = ¡Í  and ¡Í  otherwise.
1 structure in constraints
our approach is based on exploiting independence properties of the constraint functions f  such that they can be represented more compactly  abstractly  than explicitly listing all assignments to x. in this section  we characterize these properties  which are often present in practical problems.
¡¡to start with  in many situations the valuation of a constraint will depend only on a subset of the variables. for instance  for the constraint fa1  its valuation depends only on a1  w  and y. formally  the support of a constraint f is the subset of variables that it depends upon:
definition 1  support  the support of a constraint f  denoted sup f   is the variable set {xi ¡Ê x |  v1 v1 ¡Ê di s.t.  f ¨’  xi ¡û v1    x {xi}1= f ¨’  xi ¡û v1    x {xi}}. for the example  sup fa1  = {a1 w y}  sup fa1  = {a1 u v}  sup fe1  = {e1 u y}  sup fe1  = {e1 u}  and sup fo1  = {o1 v w}. the support structure of a constraint problem can be abstractly represented through a hypergraph h that associates a node with each variable xi  and a hyperedge with the variables sup fj  of each constraint fj. fig. 1 shows the hypergraph for the example.
¡¡while the notion of support captures the independence of a function's value from variables outside the support  there can still exist independence within the support. for instance  in the constraint fo1  if o1 = s1 and v = 1  then the value is .1 regardless of the value of w; if o1 = u  then the value is .1 regardless of the values for w and y  etc. more generally  a
¡¡property that we call weak support can be exploited: if the relationship between assignments and a function's value can be described more compactly than explicitly listing all the assignments to the support  then it is more efficient to solve problems on that symbolic level.
1 symbolic encoding using decision diagrams
in the following  we present a way to recognize support and weak support of functions  namely through symbolic encoding in the form of decision diagrams.
¡¡a decision diagram represents a function over boolean variables to a set of values. binary decision diagrams  bdds   bryant  1  represent functions with values 1 or 1; algebraic decision diagrams  adds   bahar et al.  1  represent functions to any set of values. a decision diagram is a rooted  directed  acyclic graph  where each internal node corresponds to a boolean variable  and each leaf node corresponds to a value of the function. internal nodes have two children n1  n1  and are recursively interpreted as the function f = if xi then f1 else f1  where xi is the boolean variable corresponding to the node  and f1 and f1 interpret the sub-diagrams with root nodes n1 and n1  respectively.
¡¡the power of decision diagrams derives from their reduction rules and canonicity of representation. a decision diagram can be ordered by imposing a variable ordering x1   x1   ...   xn  such that for all paths from the root to the leaves  the sequence of variables encountered obeys the ordering. ordered decision diagrams can be reduced by iteratively applying two graph reduction rules  which collapse assignments by sharing common prefixes and postfixes  to share a common postfix  the function value must be the same : the node deletion rule eliminates nodes from the diagram whose children are equal  n1 = n1   and the node sharing rule eliminates one of two nodes that are root nodes of isomorphic subdiagrams. a reduced  ordered decision diagram is a canonical representation of its function  bryant  1  and contains only variables from the support of the function. it is easy to extend the technique to non-binary variables by mapping each non-binary variable xi to a block of dlog1 | di |e boolean variables that encode the domain values logarithmically. figure 1 shows a reduced  ordered add representing the function fo1. operations on functions  such as projection and combination  can be directly performed on this representation. the complexity of the operations depends on the size of the diagram  number of nodes and arcs   rather than on the number of possible assignments; due to the sharing of common substructures  the number of nodes and arcs can be orders of magnitude smaller than the number of possible assignments. while no compaction is achieved in the worst case  for certain types of constraints it can be shown that the size of the decision diagram grows only logarithmically with the number of assignments  bryant  1 .
1 set-based branch-and-bound with tree decompositions
in this section  we describe how the independence properties of functions described in the previous section  support  weak support  can be exploited in the framework of branchand-bound search. we describe an algorithm that uses a tree decomposition of the hypergraph h to exploit the support of functions  and set-based search to exploit the weak support of functions. thus  the algorithm benefits from compact representations of the functions  while memory explosion is avoided through depth-first search.

figure 1: constraint fo1 for the example in fig. 1 and its add  using two binary variables o1  o1 to encode o1  and variable ordering o1  o1  v  w. assignments and paths with value 1 are not shown.

figure 1: hypergraph  left  and a tree decomposition  right  for the example in fig. 1. the tree shows the labels ¦Ö and ¦Ë for each node.
1 tree decomposition
tree decomposition  gottlob et al.  1; kask et al.  1  is a way to exploit structural properties of h to decompose the original problem into independent subproblems   clusters  : definition 1  tree decomposition  a tree decomposition for a problem  x d f  is a triple  t ¦Ö ¦Ë   where t =  v e  is a rooted tree  and ¦Ö ¦Ë are labeling functions that associate with each node  cluster  vi ¡Ê v two sets ¦Ö vi    x and ¦Ë vi    f  such that
1. for each fj ¡Ê f  there exists exactly one vi such that fj ¡Ê ¦Ë vi . for this vi  var fj    ¦Ö vi   covering condition ;
1. for each xi ¡Ê x  the set {vj ¡Ê v | xi ¡Ê ¦Ö vj } of vertices labeled with xi induces a connected subtree of t  connectedness condition .
in addition  we demand that the constraints appear as close to the root of the tree as possible  that is 
1. if var fj    ¦Ö vi  and var fj   1 ¦Ö vk  with vk the parent of vi  then fj ¡Ê ¦Ë vi .
¡¡figure 1 shows a tree decomposition for the example. the separator of a node  denoted sep vi   is the set of variables that vi shares with its parent node vj: sep vi  = ¦Ö vi ¡É¦Ö vj . for convenience  we define sep vroot  =  . intuitively  sep vi  is the set of variables that connects the subproblem rooted at vi with the rest of the problem:
definition 1  subproblem  for a cop and a tree decomposition  t ¦Ö ¦Ë   the subproblem rooted at vi is the cop that consists of the constraints and variables in vi and any descendant vk of vi in t  with variables of interest sep vi .
¡¡the subproblem rooted at vroot is identical to the problem of finding ¦Á  for the original cop. the benefit of a tree decomposition is that each subproblem needs to be solved only once  possibly involving re-using its solutions ; the optimal solutions can be obtained from optimal solutions to the subproblems using dynamic programming. thus  the complexity of constraint solving is reduced to being exponential in the size of the largest cluster only.
¡¡in order to exploit the decomposition during search  the variables must be assigned in an order that is compatible with the tree  namely by first assigning the variables in a cluster before assigning the variables in the rest of the subproblems rooted in the cluster. this is called a compatible order in  jegou and terrioux  1¡ä  . in  terrioux and jegou  1¡ä    jegou and terrioux present an algorithm called btd  back-¡ä tracking with tree decompositions  that exploits tree decompositions in branch-and-bound search. btd assigns variables along a compatible order  beginning with the variables in ¦Ö vroot . inside a cluster vi  it proceeds like classical branchand-bound  taking into account only the constraints ¦Ë vi  of this cluster. once all variables in the cluster have been assigned  btd considers its children  if there are any . assume vj is a child of vi. btd first checks if the restriction of the current assignment to the variables in sep vj  has previously been computed as a solution to the subproblem rooted at vj. if so  the value of this solution  called a  good   is retrieved and combined with the value of the current assignment  thus preventing btd from solving the same subproblem again  called a  forward jump  in the search . otherwise  btd solves the subproblem rooted at vj for the current assignment to sep vj  and the current upper bound  and records the solution as a new good. its value is combined with the value of the current assignment  and if the result is below the upper bound  btd proceeds with the next child of vi.
1 set-based search
in the following  we generalize btd from single assignments  and thus single bounds  to sets of assignment  and thus sets of bounds   in order to exploit symbolic representations of functions.
¡¡the method that we use to extend the search from single assignments to sets of assignments is to replace the step of assigning a value to a variable by the more general step of restricting a variable to a subset of its domain. this generalization is similar to domain splitting; however  whereas domain splitting might further split up the subsets at subsequent levels of the search tree  we consider the case where each variable occurs only once in each path of the search tree. that is  we assume that for each variable xi  a static  predefined partition of its domain into subsets is given:
definition 1  domain partition  a partition of a finite domain di is a set pi of disjoint subsets of di whose union iss di  that is  pj¡Épk =   for pj pk ¡Ê pi  j 1= k  and p¡Êpi p = di.
¡¡there are two limiting cases: partitions consisting of singleton sets  that is  |pi| = |di|  and partitions consisting of a single set containing all domain values  that is  |pi| = 1. again for notational convenience  we denote by xi ¡Ê p the restriction of a variable xi to the values in a partition element p  and a constraint over variable xi  its valuation is ¡Í if the value of xi is in p  and    otherwise .
¡¡the set-based algorithm proceeds by assigning partition elements p to variables xi  and computing lower bounds by combining the constraints all of whose variables have been assigned. since a partition element can contain more than one domain value  the result is in general a function  set of assignments  rather than a single assignment. thus  we need to generalize the basic test of the branch-and-bound algorithm - comparing a lower bound with an upper bound - to comparing two functions:
proposition 1 given a cop with variables of interest z   x  let fu be a function with sup fu   z   and let fa be a set of assignments to y   x  i.e.  fa is a function with sup fa   y  . then for an assignment t to y   its extension t1 to all variables x can improve on fu  that is  fu t    if sink fa  z fu  z  t  =1  .
¡¡hence  the sinking operation generalizes the comparison of a lower bound to an upper bound by  filtering out  assignments that cannot improve on a bounding function fu.
¡¡algorithm 1 shows the pseudo-code for the resulting algorithm sbbtd  set-based branch-and-bound with tree decomposition . sbbtd is given a constraint fa  corresponding to a set of current assignments and their values   a cluster vi with a set of variables yvi that remain to be assigned  and an upper bound function fu whose support is a subset of the variables sep vi   fu is a constant in the case where vi = vroot . sbbtd returns a constraint corresponding to the extension of assignments fa to solutions of the subproblem rooted at vi
¡¡ again  the result is a constant in the case where vi = vroot . the valuation of this constraint is the value of best solution of the subproblem rooted at vi  or a value greater than or equal to fu t   if this best value is greater than or equal to fu t . sbbtd uses two functions gvi  rvi to record the goods  solutions to the subproblem rooted at vi  for each vi. gvi is a soft constraint that contains the actual goods  while rvi is a hard constraint that contains the information whether an assignment has been recorded as a good or not  the use of two functions is necessary because a good can have any value in e  thus function gvi alone cannot give sufficient information whether the good has been stored or not . that is  an assignment t is recorded as a good for the separator if rvi t  =    and not recorded if rvi t  = ¡Í; in case the good is recorded  its value is gvi t . initially  rvi = gvi = ¡Í.
¡¡sbbtd starts by filtering out the assignments whose value exceeds the bounding function  line 1 . inside a cluster  lines 1   sbbtd operates like branch-and-bound  except that it restricts variables to subsets of their domains  partition elements  instead of single values. once all variables in the cluster have been assigned  sbbtd turns to its children  lines 1 . sbbtd chooses a child vj and first computes the subset of assignments that are not previously recorded as goods of sep vj   line 1 . if there are any assignments sbbtd fa vi yvi fu 
1: fa ¡û sink fa fu  1: if yvi =   then
1: f ¡û children vi  1: while f 1=   and fa 1=   do
1:
1:	¡û	vj
1:	fa1 ¡û rvj ¨’ fa
1:	if fa1=   then
1:	ha ¡û lift fa1   sep v  
1:	ea¡û sbbtd  a	u sep vj  
1:	gv ¡û gv ¨’  ea ¨’ ha 
1:	compl ha 
1:	end if
1:
1:
1:	end while
1: return fa  sep vi  1: else
1:	choose xi ¡Ê yvi
1:	s ¡û pi
1:	i ¡û {f ¡Ê¦Ë vi : xi ¡Ê sup f  sup f  sup fa ¡Èxi}
1:	while s 1=   and fa 1=   do
1:	choose p ¡Ê s 1:	s1¡û¡ûsfa ¨’p  xi ¡Ê p lf¡Êi f
1:	fa
1:	fu ¡û min fu sbbtd 
1:	end while
1:	return fu
1: end if
algorithm 1: set-based branch-and-bound with tree decompositions
not recorded as goods  sbbtd solves the subproblem rooted at vj for these assignments  line 1   and records the solutions as new goods  lines 1 and 1 . it updates the values of the current assignments fa  lower bounds   line 1   and compares it with the current upper bounds  line 1 . it continues with the next child  if any  or returns the solutions to the subproblem. the initial call to the algorithm is sbbtd ¡Í vroot ¦Ö vroot    .
¡¡since the formulation of the algorithm is independent of how the domain partitions are defined  fig. 1 actually defines a spectrum of algorithms that is parameterized by the domain partitions pi for each variable. the limiting cases of the spectrum are |pi| = |di| and |pi| = 1  corresponding to finest and coarsest granularity of the domain partitions  respectively. in the first case  the set of assignments fa actually consists of a single assignment with value smaller than    and thus alg. 1
¡¡becomes identical to branch-and-bound on tree decompositions  btd . in the second case  the restrictions xi ¡Ê p yield constraints identical to ¡Í  and thus the search tree degenerates to a list. hence  in this case the algorithm is backtrackfree and becomes identical to dynamic programming on the tree  called cluster-tree elimination  cte  in  kask et al.  1  . for the cases in between  that is  1   |pi|   |di|  hybrids of search and dynamic programming are obtained.
theorem 1 for a cop  x d f  with a tree decomposition  t ¦Ö ¦Ë  and any domain partitions p1 p1 ... pn for variables x1 x1 ... xn  the algorithm sbbtd is sound and complete  that is  sbbtd ¡Í vroot ¦Ö vroot     = ¦Á .
¡¡for instance  consider the full adder example with the domain partitions pu  pv = {{1} {1}}  pw  py = {{1}}  and pa1  ...  po1 = {{g} {s1 s1} {u}}. that is  the search simultaneously explores the values {1} for w and y and the values {s1 s1} for the mode variables. sbbtd starts by assigning the variables {u v w y a1 a1} in the cluster v1  which gives two assignments  hu v w y a1 a1i = h1 1 g gi and h1 1 g gi  both with value .1. sbbtd next considers a child of v1  for instance  v1. since there are no goods recorded for this cluster so far  the solutions are computed for this subproblem for the assignments hu yi = h1i and h1i. the value of these solutions are .1  corresponding to a s1 failure of xor-gate 1  and .1  respectively. these solutions are recorded and combined with the two assignments  which now have the values .1 and .1  respectively. next  the solutions for the subproblem v1 are computed simultaneously for the assignments hv wi = h1i and h1i. the values are .1 and .1  corresponding to a s1 failure of the or-gate   respectively. after combining these solutions with the two assignments in v1  their value becomes .1 and .1  respectively. since there are no children left  sbbtd updates the bound for the best solution found to .1. this bound prunes all subsequent assignments to variables in v1 except hu v w y a1 a1i = h1 1 g gi and h1 1 g gi. since the assignments hu yi = h1i and h1i for the subproblem v1 lead to values worse than the bound  .1 is returned as optimal solution. in comparison  observe that btd  obtained as a specialization of sbbtd for the case |pi| = |di|  suffers from the problem that it would explicitly iterate through all possible combinations of values for w and y until encountering the best assignment  which is obtained for hw yi = h1i ; in contrast  sbbtd handles those combinations implicitly. dynamic programming  obtained as a specialization of sbbtd for |pi| = 1  suffers from the problem that it would consider more assignments than necessary  for example  it would compute the value for assignments involving ha1 a1i = hu ui  which is very low because it corresponds to a double fault .
1 trade-off between search and symbolic inference
sbbtd unifies search with good recording  btd  and dynamic programming  cte . in fact  the goods that the btd algorithm computes can be understood as partial construction of the messages sent between clusters by the dynamic programming algorithm cte  kask et al.  1 . thus  the two limiting cases can be understood as lazy and eager forms of dynamic programming  respectively: btd computes solutions to subproblems only as far as required to compute the optimal solution  whereas cte computes them completely.
¡¡it has been previously shown  jegou and terrioux  1¡ä   that btd  i.e.  lazy dynamic programming  outperforms cte  i.e.  eager dynamic programming . this is because search on single assignments exploits the upper bounds as rigorously as possible  and therefore the least number of assignments will be explored. however  this argument is based on counting assignments and holds only if assignments are represented explicitly. the picture changes when using techniques such as adds that can manipulate sets of assignments implicitly. hence  a tension is created between making the partition elements in sbbtd smaller or larger: in the former case  the advantage is that as few assignments are explored as possible  but the disadvantage is that less possibilities exist for exploiting commonalities between assignments. in the latter case  the disadvantage is that more assignments might be explored  but the advantage is that assignments can be abstracted into a more compact description and handled implicitly. thus in many practical cases  the optimal granularity will lie in an intermediate point  1 ¡Ü |pi|   |di|  along the spectrum; sbbtd allows us to adapt to this trade-off.
1 implementation and experiments
we implemented sbbtd using the cudd  colorado university decision diagram  package  somenzi  1   which provides a library of routines for manipulating adds.
¡¡we evaluated the performance of this prototype on random  binary max-csp problems. max-csp is a constraint optimization problem where the tuples of a constraint have cost 1 if the tuple is allowed  and cost 1 if the tuple is not allowed; the optimal solution corresponds to an assignment that violates a minimum number of constraints. for each instance  the support of the constraints was determined in order to derive the hypergraph  a graph in this case . then  a tree decomposition of the hypergraph was computed using the min-fill heuristics. we choose random domain partitions  whose granularity we varied by setting a certain percentage p of  random  variables to the partition |pi| = 1  and the other variables to the partition |pi| = |di|. we ran the experiments on a pentium 1 windows pc with 1 gb of ram; due space restrictions we give only summarized results here.
¡¡consistent with results in  jegou and terrioux  1¡ä    we found the number of assignments explored for p=1%  btd  to be in most cases several times smaller than the number of assignments explored for p=1%  dynamic programming . e.g.  in an example class with n=1 variables  c=1 constraints  domain size k=1 and tightness t=1  the mean number of goods recorded for p=1% was 1 to 1  whereas for p=1% it was 1 to 1 1. however  the add representation of constraints typically achieved a compaction of around one to two orders of magnitude  consistent with observations in  hoey et al.  1  . therefore  and also because larger partition elements reduce the number of recursive calls  sbbtd ran faster for larger values of p in almost all cases. e.g.  for n=1  k=1  c=1 and t=1  the mean runtime for p=1% was around 1 sec  but around 1 to 1 sec for p=1%. given that for p=1% the computation required up to one order of magnitude more memory than p=1%  selecting an intermediate granularity  1%   p   1%  allowed significant runtime improvements over btd within still acceptable memory bounds. we are currently working on structured examples  like in  jegou¡ä and terrioux  1   and real-world examples.
1 conclusion
we presented an algorithm for solving soft constraint problems by generalizing branch-and-bound to search on sets of assignments and perform inference  dynamic programming  within those sets of assignments. this hybrid approach can exploit regularities in the constraints  while it can avoid memory explosion by controlling the size of the sets. in contrast to work in  hoey et al.  1; jensen et al.  1   our approach is more general in that it addresses valued constraint satisfaction problems  schiex et al.  1   and incorporates a decomposition of the problem into several subproblems. future work includes ways to automatically determine domain partitions  appropriate points in the spectrum   and augmenting the algorithm with symbolic versions of constraint propagation techniques  cooper and schiex  1  in order to further improve the bounds.
