 
we discuss the relationship between probabilistic logic and cms. given a set of logical sentences and their probabilities of being true  the outcome of a probabilistic logic system consists of lower and upper bounds on the probability of an additional sentence to be true. these bounds are computed using a linear programming formulation. in -cms systems  the outcome is defined by the probabilities of the support and the plausibility  with the assumptions being independent  after a first phase which consists of computing the prime implicants depending only on the variables of the assumptions. we propose to reformulate a cms system without independence conditions on the assumptions  using the linear programming framework of probabilistic logic  and show how to exploit its particular structure to solve it efficiently. when an independence condition is imposed on the assumptions the two systems give different results. comparisons are made on small problems using the assumption-based evidential language program  abel  of  anrig et a/.  1  and the psat program of  jaumard et a/.  1 . 
1 	introduction 
many different models have been proposed for reasoning under uncertainty in expert systems. among those based on the use of logic and probability theory which require a moderate amount of input data  two important families are the probabilistic clause maintenance systems  ttcms   reiter and de kleer  1; dekleer and williams  
1   and the probabilistic logic models  nilsson  1; jaumard et ol.  1; hansen et a/.  1 . while these families have been developed separately  they have much in common  with however the difference that models of the former family usually suppose independence of their assumptions  while those of the latter do not. in this 
automated reasoning 
paper  we explore -cms systems  with and without independence of the assumptions  from the probabilistic logic viewpoint. the main results are the following:  i  when relaxing the independence condition  two formulations can be proposed for -cms systems;  ii  the second formulation suggests an algorithm which exploits the particular structure of -cms and is  on large instances  1 times faster than the column generation algorithm for probabilistic logic of  jaumard et a/.  1  applied to the first formulation;  iii  with the independence condition  probability intervals of an additional proposition obtained by  cms may overlap with those of the corresponding probabilistic logic model  which suggests that 
cms systems do not exploit the available information to its fullest degree. 
　the paper is organized as follows: probabilistic logic models and cms systems are briefly reviewed in the next two sections. the two probabilistic logic models for 
cms systems are presented in section 1. algorithms are discussed in section 1 and computational results in section 1. brief conclusions are drawn in the last section. 
1 	probabilistic logic 
nilsson  nilsson  1  has presented a semantical generalization of propositional logic in which the truth values of sentences are probability values  probabilistic logic  also called probabilistic satisfiability or psat for short . 
　　let x denote a set of propositional variables and s a set of propositional 
sentences over x defined with the usual operators  dis-
junction    conjunction   and -.  negation . a literal is a propositional variable  or its negation 
　　　　　　propositional sentences are assumed to be written using a dnf  disjunctive normal form  expression in this paragraph. 
　　let be a valuation for 1  where is equal to 1 if has value true  and to 1 otherwise  is a possible world if there exists a truth assignment over x which leads to w over s and it is an impossible world otherwise. observe that two different truth assignments on x may lead to the same possible world. let w denote the set of possible worlds and set to | w   note that 

denotes the probability of sentence 
　　the probability distribution p is consistent if it satis* fies the set of logical sentences together with their probabilities  i.e.  if for each sentence the sum of 's over all truth assignment  that satisfy 
equals 
　for a given set s of sentences  let be an matrix such that  is equal to 1 if is true for   and equal to 1 otherwise. this leads to the following linear programming formulation of the psat problem  in decision form : 
 i  
where 1 is a unit row vector. the problem psat thus reduces to determining whether there exists or not a vector p satisfying  1 . observe that  psat  is completely determined by the pair 
　let us assume that the psat problem defined by  1  is consistent. let sm+1 denote an additional logical sentence  with an unknown probability  the optimization form of psat  also known as probabilistic en-
tailmenty see  nilsson  1    is to determine the range 
1 	numerical solution of psat 
the linear program which expresses the psat problem in its decision or optimization form has an exponential number of variables in the size of the input; for this reason  in the sequel we will speak of generalized linear programming  glp for short  formulation. so writing explicitly psat already requires exponential time. this led nilsson  nilsson  1  to suggest looking for heuristic solution methods only. 
　such a view is overly pessimistic since  although writing large psat problems explicitly is impossible  they can be solved quite efficiently by keeping them implicit. this can be done using the so-called column generation technique  lasdon  1 . it extends the revised simplex method  in which only a small number of columns are kept explicitly. this technique makes use of a master problem which implies an objective and constraints re-
lated to the probabilities of the possible worlds  and a subproblem which determines the entering column for the master problem. this last subproblem depends on the structure of the original problem and has quite often a combinatorial nature. for more details see  jaumard et al.y 1 . 
1 	cms and cms models 
the assumption-based truth maintenance systems  or 
atms for short   de kleer  1  and later the cms 
 clause maintenance systems   reiter and de kleer  1  can be viewed as symbolic algebra systems for producing a set of statements  boolean expressions  in which one can believe. a brief description of the cms is given below; details can be found in  reiter and de kleer  1 . 
　　given a set of propositional variables x  a cms consists of a set of assumptions supposed to be such that a x and a set of propositional sentences h  also called justifications  see  de kleer  1j  such that the  are clauses. propositional sentences are assumed to be written using a cnf  conjunctive normal form  expression in this paragraph. therefore  a clause is a finite disjunction of literals with no literal repeated  also represented as a set of literals. 
with respect to h iff no proper subset of with respect to h. the cms 
is a database management system which  given a set h of propositional sentences computes a minimal support clause   for a clause  summarizes a list of sets of nonredundant assumptions  in terms of a boolean formula   each of which is sufficient to support a proof of 
   the  for a clause is related with a prime implicant for h. this relationship is given as follows  reiter and de kleer  1 :  is a minimal support clause with respect to h iff there is a prime implicant 
for h such that and conversely  if is a prime implicant for h such that then is a minimal support clause for with respect to h. 
1 	cms algorithms 
the prime implicants can be used to implement cmss 
 reiter and de kleer  1 . the prime implicants of a set of clauses can be computed by repeatedly resolving pairs of clauses  adding the resulting resolvents to the set and removing subsumed clauses. this method is known to be a brute-force approach and performs far more resolution steps than necessary. the running time of this algorithm depends on the number and expense of the subsumption checks required. de kleer  de kleer  1  describes an improved algorithm for generating the prime implicants of a set of clauses. 
1 	adding numerical uncertainties 
from a logical viewpoint  the  that the atms/cms attaches to a clause yield only three possible truth values for  believed  disbelieved  and unknown. this 
	hansen. jaumard  and 	parreira 	1 

three-value logic cannot rate the degree of imcertainty associated with unknown clauses  and thus may lead to a stalemate whenever a decision is to be made whose outcome depends critically on the truth of these propositions. for this and others reasons  several attempts have been made to augment atms/cms with a numerical measure of uncertainty. several authors use probability theory to deal with uncertainty associated with assumptions for atms  de kleer and williams  de kleer and williams  1  and liu et al.  liu a/.  1   or cms  kohlas et al.  kohlas and haenni  1  . in all extensions the probabilities assigned to assumptions must be independent  see  hansen et al.  1  for details  in order to calculate the degree of belief. 
　　the quantitative judgment of belief can be measured by the degree of support and plausibility. the degree of support of h  dsp for short  is the probability of arguments  in favor of it. similarly  the degree of plausibility  dpl for short  of is 1 minus the probability of arguments against it. 
　as next shown  cms without independence condition can be reformulated using the linear programming expression of the psat problem. 
1 using psat linear programming expression to reformulate a cms model 
consider the psat problem 	defined as follows: 
s = a 	h where 	and 
	where 	is a probability 
m-vector associated with the set a of assumptions and 1 is a unit r-vector  all the probabilities are equal to 1 for the set h of clauses . note that  with 
 the clause h with unknown probability is associated with y the set of literals of 
clause 
first formulation  f1  
the  cms problem can be expressed using the glp 
formulation of the psat problem; master problem: 
min/max 
subject to:  1   1  
 1   1  
 1  
subproblem: 
min/max 	 1  
where with the constraints  1 - 1   respectively. 
　this reformulation results in a psat problem with a subproblem corresponding to an unconstrained nonlinear program in 1 variables. 
automated reasoning 
　note that the set of prepositional sentences of if has a specific structure  in that its probabilities are all equal to 1  i.e  these propositiona! sentences are always true. exploring this structure leads to a second formulation. 
second formulation  fa  
there is a natural partitioning of the constraints of the glp defined by formulation f1 observe that satisfying the constraint  1  is equivalent to satisfying the equation: 

i.e.  to solving a satisfiability problem  sat . 
　hence  constraints  1  can be transferred to the subproblem  which then leads to consider in the master problem only the solutions of  1  which satisfy  1    1    1  and minimize or maximize  1 . 
　we thus obtain the following glp reformulation. master problem: 
 1  
 1  
 1   1  subproblem: min/max 
 1  
　the subproblem is now a linear program in the 1n 1 variables   as the  are either variables with linear constraints. 
   each column of  1  corresponds to a possible world  or equivalently a subset of assumptions with 
true/false values  which may imply  imply 
 or neither. in the first two cases there is one corresponding column in  1 - ll   and in the latter two. when minimizing  columns which have  1 will have probability 1 if there are twin columns with  will correspond to the sum of 
probabilities of those clauses which imply  i.e.  to the degree of support of when maximizing columns which have 1 will have prob-
abilities 1 if there are twin columns with = 1. so will correspond to 1 minus the sum of probabilities of those clauses which imply i.e.  to the degree of plausibility of 
1 	solution method 
the method is an iterative one  in fact  the revised simplex algorithm  chvatal  1   where at each iteration  we determine the column with the minimum  maximum  reduced cost by solving  1  in the case of  ie  

		 1  
where the u1 and ui are the current dual variables associated with the tautology so and with the propositional sentences  respectively. by associating the logical values true with 1 and false with 1 in each logical proposition  one can rewrite  1  as: 

　　this optimization problem can be reformulated using arithmetic expressions of the propositional variables of x. this can easily be done with the convention 1 = true and 1 = false and the relations 
where the left-
hand side variables are logical ones  and the right-hand side variables are integer ones. the choice of the entering column is thus reduced to a problem of minimizing  maximizing  an unconstrained nonlinear function in 1 variables  pnl-1 . in formulation f1 the subproblem is a constrained linear program in 1 variables  cpl1 . 
1 	basic algorithm 
we assume that the optimization problem is a minimization one. algorithm 1 provides a description of the column generation method for formulation f  or f1. 
　phase-1 is not detailed as it proceeds in a similar way than phase-1  i.e.  through step 1 to step 1. 
1 	solution of the subproblems 
again assume that the optimization problem is a minimization one. at each iteration a column with a negative reduced cost must be found by a heuristic or an exact algorithm. exact solution of the subproblem is not necessary at each iteration to guarantee convergence. as long as a negative reduced cost is found by the heuristic an iteration of the revised simplex algorithm may be done. if a feasible solution is obtained in that way  the decision version of the satisfiability problem is solved  but finding none when choosing the entering column in a heuristic way cannot guarantee that none exists. so  when no more negative reduced cost is obtained by the heuristic it is necessary to turn to an exact algorithm to prove that there is no feasible solution for the decision version of psat  nor feasible solution giving a better bound than the incumbent one for the optimization version. we use a steepest ascent mildest descent  samd  or 
tabu search  ts  heuristic   hansen and jaumard  1; glover and laguna  1   for pnl-1  and a variant of tabu search for cpl-1 with constraints to find an approximately optimal solution. we also use a method based on linearization for pnl-1  and branch-andbound for cpl-1  to find an exact optimal solution. 
algorithm 1 column generation method 
step 1. using phase-l of the simplex algorithm 
 see  e.g.  chvatal  1  for details   build an initial matrix  associated with a feasible solution. 
step 1. if there is no such matrix bo then the problem is inconsistent: stop. 
step 1. solve the master problem to compute the dual variables  phase-1 of the simplex algorithm . 
step 1. solve the subproblem to compute a column with negative reduced cost ct using a heuristic; 
step 1. if  then add the corresponding column to the master problem  reoptimize it  
and go to step 1. 
step 1. solve the subproblem to compute the column with the most negative reduced cost using an exact algorithm. 
step 1. if  then add the corresponding column to the master problem  reoptimize it  
and go to step 1. 
step 1. stop: 	the optimal solution has been reached. 
pnl-1 without constraints 
the tabu search  ts  heuristic proceeds to a local optimum by moving at each iteration from one feasible solution to another in its neighborhood  here the vectors at hamming distance 1 from the current one . we then pick the solution in the neighborhood that produces the best improvement in the objective function. if there is no improving solution  a local optimum was reached assuming we use aspiration  see page 1 in  glover and laguna  1   then we choose that one which degrades the objective function least. in order to avoid returning to the local optimum just visited  or cycling  the reverse move is forbidden for a given number of iterations  sizemaxtabu . 
　　the steps of ts are presented in algorithm 1. the parameters  denote the remaining number of iterations during which a local change in direction is forbidden. when a change in an ascent direction is done  is set at the value tabu. that value is chosen by random selection among integers in the range  1  sizemaxtabu . the stopping condition may be  e.g.  maximum computing time allowed  maximum number of iterations  or maximum number of iterations between two improvements. 
　the linearization method works by replacing in a standard way each product of variables by a new 1 variable and adding constraints to ensure that the values agree in 1 variables. 
　the size of the resulting linear 1 variables increases rapidly with  and the number of nonzero dual variables 
	hansen  jaumard  and parreira 	1 


cpl-1 with constraints 
heuristic solution of cpl-1 is again done by a samd or ts algorithm. the idea behind this algorithm is to allow infeasibility. however it must be limited  therefore for each sequence of iterations a move is allowed only if the resulting number of unsatisfied clauses  or violated constraints  is smaller than a given threshold unsatmax. after a number of iterations we verify if the current solution is feasible. in the affirmative we reduce the value of unsatmax by  and another sequence of iterations is performed. in the negative the value of unsatmax is increased by a  we apply a transformation to get a feasible solution and another sequence of iterations is performed. the overall algorithm has a maximum number of rep iterations. steps of the ts-constrained heuristic are presented on algorithm 1. 
　the constrained linear 1 program  1  has the form of a combiped set covering and set partitioning problem. exact solution is based on the algorithm of  fisher and kedia  1 . the main feature of this algorithm is the use of dual variables in the linear programming relaxation to provide lower bounds for a branch-and-bound algorithm. 
1 	computational experiments 
the algorithms for cms/psat described in the previous sections have been coded in c and tested on a ultra-1 sun sparc computer. the resulting program uses the cplex 1 package for linear programming. the problems for cms/psat were randomly generated in the following way:  i  the numbers of assumptions   of justifications  which here are clauses   of variables  assumptions and propositional symbols  are parameters;  ii  the clauses contain at most 1 literals. there is an uniform distribution of clauses with 1  1  1 and 1 literals as well as of uncomplemented and complemented variables. probabilities  a  corresponding to feasible problems were obtained by generating randomly 
1 	automated reasoning 

max 1n  boolean vectors  constructing the corresponding possible worlds  associating with them positive numbers summing up to 1  i.e.  probabilities for these worlds to occur   and then summing for each clause the probabilities of the worlds in which it is true. 
　results of the comparison between the two cms/psat models are given in table 1 and 1  which detail problem sizes  total cpu time  number of columns generated  cpu time for the tabu search and the exact algorithms for the subproblems. each line corresponds to averages over five problems. note than the number of propositions  in the first formulation is equal to the number of assumptions  propositions in the master problem  plus the number of justifications  considered only in the subprobiems  in the second formulation. clearly the second formulation is by far superior to the first one: computation times for the larger instances are 1 times smaller. 
　if an independence condition is imposed on the assumptions  only much smaller instances of cms are solvable in reasonable time. if columns corresponding to feasible worlds are considered explicitly  each has a positive probability and their number increases exponentially. this contrast with the linear programming model of psat  where the number of columns with positive probability in a basic  and hence in an optimal  solution is at most equal to the number of lines. using boolean simplifications we may reduce somewhat the computational burden but it often remains too high to solve large instances. 
	intervals 	cms/psat 	and 


table 1: formulation-1 

table 1: formulation-1 

 dap  dpi  for -cms with independence condition  obtained with the abel program  anrig et al  1   are given in table 1. it appears that in some cases the intervals of cms with the independence conditions overlap in part with those of  cms/psat instead of being included in them  as one would have expected. this indicates -cms does not exploit the available information to its fullest degree. reasons why this is so will be explored in future work. 

table 1: comparison of bounds 
1 	conclusions 
-cms systems can be expressed in two ways as a psat problem  when the independence condition on the assumptions is removed. then the lower and upper bounds on the probability of the additional propositional sentence coincide with its support and plausibility. the second formulation  which keeps the justifications implicit  or transfer them to the subproblem when using column generation as solution method   is much more efficient than the first  direct one. if the independence condition is kept in -cms  solution becomes more cumbersome and probability intervals for the objective function clause provided by both methods may overlap. 
acknowledgments 
research of the authors was supported by drev-
valcartier contract. work of the first and second authors was supported by fcar grants 1-eq-1 and 1-er-1. work of the first has also been supported by nserc grant to hec and nserc grant gp1. work of the second author was also supported by nserc grants gp1 and eqp1. work of the third author has also been supported by 
cnpq  conselho nacional de desevolvimento cientifico e tecnowgico   brazil  grant 1-1. 
