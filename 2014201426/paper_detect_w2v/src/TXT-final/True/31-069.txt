 
the primary goal of inductive learning is to generalize well - that is  induce a function that accurately produces the correct output for future inputs. hansen and salamon showed that  under certain assumptions  combining the predictions of several separately trained neural networks will improve generalization. one of their key assumptions is that the individual networks should be independent in the errors they produce. in the standard way of performing backpropagation this assumption may be violated  because the standard procedure is to initialize network weights in the region of weight space near the origin. this means that backpropagation's gradient-descent search may only reach a small subset of the possible local minima. in this paper we present an approach to initializing neural networks that uses competitive learning to intelligently create networks that are originally located far from the origin of weight space  thereby potentially increasing the set of reachable local minima. we report experiments on two real-world datasets where combinations of networks initialized with our method generalize better than combinations of networks initialized the traditional way. 
1 	introduction 
the main goal of classification learning is generalization - being able to induce a concept that accurately 
classifies future examples. the difficulty with achieving good generalization is that a learner cannot measure generalization directly; instead  the learner relies on its inductive bias to hopefully produce an accurate classifier. a number of schemes have been introduced to address this ubiquitous problem  ranging from treepruning in decision trees  quinlan  1  to the use of complexity terms in neural networks  hinton  1 . in this paper we present a way to address the generalization problem for neural networks trained by backpropagation  rumelhart et ai  1 . our solution employs 
　*'this research was partially supported by onr grant n1-1 and nsf grant iri-1. 
1 	c1nnecti1nist models 
the previously explored approach  drucker et ai  1; hansen and salamon  1; lincoln and skrzypek  1; rogova  1  of training a set of networks rather uaan a single network and then combining the results. the novelty of our approach lies in the type of networks we combine to produce our composite classifier. 
　when using backpropagation  one typically minimizes a cost function. this function is a measure of the errors made by the learner  and perhaps other terms  as discussed below. for example  one straightforward cost function is the sum of squared errors between the predicted and target outputs for the training data. backpropagation learns by making changes to the network that reduce the total cost. 
　however  minimizing the cost function does not guarantee optimal generalization. generalization can be harmed by a number of factors: the learner may have an inappropriate network topology for the problem; the parameters of the learning algorithm  such as the learning rate  may be inappropriate; there may be too few examples to learn the concept; and the learner may  overt!t  its model to correctly classify noisy data. many methods have been introduced to solve these problems. some researchers introduce penalty terms into the cost function that favor generalization  hinton  1 . others  avoid  overfitting using stopping criteria like patience  fahlman and lebiere  1  or by employing validation sets  lang et a/.  1 . some research has focused on choosing an appropriate network by growing  fahlman and lebiere  1  or shrinking  le cun et a/.  1  a network topology  or by exploring a number of topologies  opitz and shavlik  1j. combining multiple networks1 has the advantage of achieving good generalization without having to do a great deal of empirical exploration or complex coding. the obvious disadvantage is the time spent training multiple networks  but this disadvantage can be mitigated  because it is trivial to parallelize the training  since each network can be trained separately. 
　in section 1 we discuss hansen and salamon's  model of combining the predictions of multiple classifiers. a key aspect of their work is that to increase generalization  the mistakes made by the networks combined 
　　1 we will use the phrase combining multiple networks as a shorthand to mean combining the predictions made by multiple neural networks. 
                   weight space figure 1: consider a cost function described over a simple weight space. assuming the initial value of the weight parameter falls between the two dashed lines  the only local minima that can be reached by gradient descent are those marked with crosses  +   even though many other local minima may exist. 
must be independent. the problem  of course  is how to achieve  independent  networks. in order to achieve independence in networks  one would expect to have to greatly vary a number of aspects of the networks including  but not limited to  the set of training patterns  the topology of the networks  the learning parameters of the networks  and the method for initializing the networks. but we have investigated a method that empirically produces good results for combining networks that only requires the user to vary the method of initializing the networks. we do not mean to claim that the resulting networks are truly independent  merely that the networks initialized as we suggest  are less interdependent that networks initialized in the normal manner  and therefore more effective when used in combination. 
　our idea is to initialize the parameters   i.e.  weights and biases  of a neural network over a much larger range of values than normal. we do this to cause backpropagation to seek local minima not normally encountered using standard initialization  see figure 1 . 
　we explored a number of means to achieve our goal of a diverse set of starting points in weight space; the best one is a method employing competitive learning  rumelhart and zipser  1  to produce class prototypes that are used as hidden units in a network in a method similar to moody and darken's  1; 1 . in section 1 we outline competitive learning  and in the following section we discuss how to use it to initialize neural networks. section 1 shows experiments we performed on two real-world data sets  demonstrating the advantages of our approach. we then discuss future research directions  related work  and our conclusions. 
1 	combining multiple networks 
the basic idea in combining neural networks is to train a number of networks  and then somehow use the collection to increase generalization. figure 1 shows a framework for combining multiple networks. 
　the choice of a function for combining predictions is important  kearns and seung  1 . examples of combination functions include voting schemes  hansen and salamon  1   simple averages  lincoln and skrzypek  1   weighted average schemes  perrone and cooper  1; rogova  1   and schemes for training combiners  rost and sander  1; wolpert  1; zhang et a/.  1 . we chose as our method for combining networks the scheme of simply averaging the values of the corresponding output units. results from portfolio theory suggest this method provides a good solution with minimal extra work  mani  1 . 

　hansen and salamon  explored the value of combining multiple networks. they demonstrated that under certain assumptions  generalization will increase as more networks are combined. for each pattern where the average error rate is less than 1% for the possible trained networks  hansen and salamon demonstrate that in the limit the expected error on that pattern can be reduced to zero. of course  since not all patterns will necessarily share this characteristic  e.g.  outliers may be predicted at more than 1% error   the error rate over all the patterns cannot necessarily be reduced to zero. but if we assume a significant percentage of the patterns are predicted with less than 1% average error  gains in generalization will be achieved. a key assumption of hansen and salamon's analysis is that the networks combined should be independent in their production of errors. 
　typically  the weights of a neural network are randomly initialized with small values. the problem with this approach is that this tends to confine the exploration of the network to a single area of weight space  figure 1 . given similar training sets  this means that multiple networks may often find the same local minima. in order to produce networks that are less interdependent in their predictions  we investigated methods that avoided this bias. in particular  we focused on changing the standard means of initializing network weights to produce networks that have large initial weights. 
　our first approach was the obvious solution use a much larger random range for generating initial network weights. this works well in terms of producing large weights  but the resulting networks suffer from the flatspot problem  fahlman  1  - backpropagation is unable to refine these networks since the activation values of the hidden and output units tend to be very close to 1 or l.'1 this occurs because the net input values for a 
　network unit will often be highly positive or negative. 
　in our second approach we tried to randomly pick examples from the training data to act as  prototypes.  we then created a hidden unit for each prototype with large positive weights for each of the  on  features of the prototype. this solution also suffered from the flatspot problem  since in a large input space only a small number of examples will share a large set of features with another example and  hence  the hidden units are typically inactive. using what we learned from this ap-
   1 error is multiplied by actwatwn l - activation  when backpropagating  assuming a logistic activation function and a sum-of-squared-errors cost function. for units with activation near 1 or 1  this means that little error is propagated. 
1 


1 	c1nnecti1nist models 

for netinput in equation 1. for example  if we want our hidden unit to have an average activation value a of 1 when it is  on  we would need netinput = 1. let us assume we have determined the average netinput values neton and net1ff  which are the required netinput values for our desired average activation values. 
　next we create a hidden unit that has weights copied from the competitive learning seed. we use this hidden unit to calculate the average net input for the examples that are part of that subclass  and similarly the average net input for examples that are not part of the subclass  call these values avginclass and avgother - we then calculate a multiplier m for the weights and a bias b for the unit so that the average net input for the examples in the subclass will sum to net1u  and to nei1ff for those examples not in the subclass. to do this we solve for m and b in these equations: 
m avginciass + b = neton  1  m avg1ther + b - net1ff  1  
we multiply the hidden unit's weights by m and set its bias to b  making the unit a detector of its subclass. we repeat this process for each subclass of each category  producing a network ready for backpropagation. 
　recall that our main goal is to have a set of initial networks that are widely dispersed in weight space. the variability of our networks comes from two main sources:  i  we randomly choose the j seeds and  ii  the competitive-learning algorithm randomly sequences through the training examples.  in addition  as explained above  we randomly select hidden-to-output weights from small uniform ranges.  due to computertime limitations  we held the number of seeds constant in our experiments. varying the number of seeds would increase the variability  and is a topic for future work. 
1 	experiments 
to judge the value of combining neural networks  we contrast four approaches: 
  single network - train a single network. this approach is meant to represent methods that do not use multiple neural networks. 
* minimal train error train k networks  selecting the network that does the  best  on the training data. this is an obvious approach to using multiple networks - select the network that does best on the training data on the assumption that the same network will be the best on the test data. 
  oracle - train a' networks  selecting  using an oracle  the network that generalizes best. this approach cannot be applied in practice because there is generally no oracle that can indicate how general a solution is  but this  approach  will provide a good baseline  since it might appear on the surface that this is the best one can do. 
  combination - train a' networks and then combine their predictions. 
we consider two ways of initializing the networks being trained:  a  the standard approach of randomly selecting weights and biases from a small interval centered on zero;  b  our approach that uses competitive learning. 
1 test domains 
our two test domains are a set of handwritten digits from shen  and the protein secondary-structure data from qian and sejnowski . the first data set contains 1x1 digitized numerals. the problem is to recognize the digit  1  in the 1 binary image. the second data set has 1 subsequences of 1 amino acids  each amino acid takes 1 bits to represent  so there are 1 input units . the output for this problem is one of three categories: whether the central amino acid is part of a helix  sheet  or coil. 
1 methodology 
we train our networks using a cost function that is the squared-error between the correct and predicted outputs. to mitigate overfitting  for the digit-recognition data we added a sum-of-weight-magnitudes complexity term to the cost function  which is equivalent to using weight decay  hinton  1    while for the protein-folding data we used validation sets  lang et ai  1   tests with weight decay produced poor results compared to the standard results for this data set . 
　however  we did not use the cost function when evaluating the trained networks. instead  as is typical  we interpret the output unit with the highest activation as the predicted class  and measure testset error by comparing the predicted class to the correct class.  we also use this methodology to select the minimal-error classifier.  
　to measure generalization we performed five 1-fold cross-validation tests on each data set. in 1-fold crossvalidation  the data is randomly divided into 1 groups. we then create 1  possibly composite  classifiers for the data - each classifier uses a different one of the 1 groups as test data  and the other nine groups as training data.  note that we learn only from the training data; the test data is set aside during learning.  we then calculate the testset error for the 1-folds and average over the five runs. for the single-network results our classifier is  naturally  a single network. for the minimal-error classifier we train 1 networks and then choose the network that achieves the lowest error on the training set as our classifier. the oracle-based classifier uses the same 1 networks  but it  cheats  by applying the networks to the test data and then using the network that achieves the lowest error on the test data. for the combination results we average the outputs of the 1 networks to obtain a single prediction. 
　to initialize the networks for our competitive-learning approach  we run competitive learning for each of the different categories of outputs. for the digit data  we use competitive learning to create five subclasses for each type of digit. thus there are 1 hidden units  five subclasses for each of 1 digits  in the networks. this number was suggested by other empirical tests on this data set  cherkauer  personal communication . for the protein-folding data we used 1 hidden units  which qian and sejnowski  concluded was an effective number. we used competitive learning to produce 1 helix subclasses  1 sheet subclasses and 1 coil subclasses  these numbers reflect the approximate distribution of the data among the three categories of outputs . 
1 


1 	results 
our results appear in tables 1 and 1. for each of our tests we report four pairs of numbers: one for the standard backpropagation method of initialization  standard  and one for our method of initialization  competitive . for each data set  we always used networks with the same number of hidden units. the testset error rates reported correspond to the four approaches listed above: using a single network;1 choosing  from the 1 networks  the network that is most accurate on the training data; choosing the network among the 1 that is most accurate on the testset; and using  for each example  the mean prediction of the 1 networks. 
　for both data sets the best result was achieved by our combination of networks initialized using competitive learning  even though the individual networks did not necessarily perform well. the reduction in error for our combination of networks using competitive learning  combination/competitive  compared to the standard approach of training a single standard neural network  single-network/standard  is statistically significant at the p   1 level  i.e.  with 1% confidence  for both sets of data. apparently the networks initialized with competitive learning are more independent in the errors  since in combination they lead to decreases in testset error. an interesting point to note is that the combination results for our approach are better than the oracle results - even though the oracle may seem to be ideal. 
　as a baseline for comparison  note that the best reported error rate for the digit-recognition task is 1%  using decision lists  shen  1 . for this set of proteinfolding data  the best reported error rates are 1% using standard neural networks  qian and sejnowski  1   1% using a knowledge-based neural network  maclin and shavlik  1   and 1% using a case-based reasoning algorithm  and a somewhat larger data format   leng et al  1 . our results are better than all but the case-based reasoning results  which also used a different input encoding . 
　in figure 1 we report error as a function of the number of networks combined. as one might expect  the error shows a sharp drop when combining the first few netwe report the average error rate of the 1 networks. 
1 	c1nnecti1nist models 

figure 1: error as a function of the number of networks combined using the standard initialization method and initialization using competitive learning. 
works and then a gradual decrease. one general conclusion is that combining the predictions of several neural networks is a wise decision; doing so is algorithmically simple and can lead to sizable reductions in testset error compared to the traditional approach of using one trained network. this reduction holds even if one does not employ our approach to initializing networks. 
1 	future and related work 
we plan to study a number of other methods for creating independent networks.1 other methods we would like to try include varying the network architecture  the number of hidden units   using different training sets  and varying other training parameters  such as the learning rate . we also intend to study the question of how to determine the optimal number of networks to use in a combination. finally  we plan to design a scheme for filtering out networks some means to recognize networks that are likely to hurt performance. 
　a number of areas of research are related to the work we presented in this paper. combining predictions has a 
　long history in a number of fields  for an overview in the area of forecasting see granger  . in the field of neural networks  a number of researchers have looked at the advantages of combining multiple predictions. lincoln and skrzypek  and hansen and salamon  both explore the advantages of combining groups of networks in a simple way. many researchers  ghosh et a/.  1; hashem et a/.  1; perrone and cooper  1; rogova  1; wolpert  1  have studied the problem of combining predictions in a more robust way  taking 
   1 the main difficulty in pursuing these other experiments is cpu time; our protein folding experiments required us to train 1 networks  1 random repeats of 1 networks for each of 1 cross-validation folds   and each of these networks takes a little more than 1 cpu day of training. 

into account the confidence of the prediction. another solution to this problem is to use a learning system  such as neural networks  to learn how to combine the results of multiple predictions. zhang et al.  and rost and sander  use this method. jacobs et al  have taken the approach of combining multiple networks one step further  in that they attempt to evolve a set of subnetworks such that each subnetwork is good at prediction for a different region of input space. 
　a related approach to our method of choosing various starting points in weight space is to vary the training process to produce networks that are independent and therefore useful for combination. examples of this approach include reilly et al.'s multi-resolution architectures   schapire's  and drucker et al.'s  boosting algorithms  hampshire and waibel's  use of different objective functions  baxt's  method of training networks on different tasks  and perrone's  tree-structured neural networks. 
　our method of combining competitive  unsupervised  and backpropagation  supervised  learning is similar to a number of other approaches  hecht-nielsen  1; huang and lippmann  1; moody and darken  1 . the main difference between our work and this previous research is that we use a hybrid unsupervised/supervised network as a method for producing networks that are very effective when used in combination  while the others focused on producing a better single network. 
　although we were not aware of the close relationship when we developed our algorithm  our approach is similar to moody and darken s . however  our goals were different from theirs: we wanted to produce networks with large initial weights  while their focus was on partitioning the input space. our method differs from moody and darken's in that we employ standard sigmoidal units rather than gaussian units  and after our initialization phase we use supervised  backpropagation  learning throughout the network  rather than just between the hidden and output layer. our work is also closely related to nguyen and widrow's  which initializes a set of hidden units to each be responsible for a different region of input space; the main difference is that in our work we use competitive learning and our examples to select these regions rather than trying to select them randomly. 
　our work also relates to hybrid systems that mix levels of unsupervised and supervised learning in neural networks  hecht-nielsen  1; huang and lippmann  1 . one difference in our work is that we perform our unsupervised learning among the categories separately. we also transform the results from competitive learning using our weight multiplier - producing large initial weights. finally  we install the results of competitive learning into a standard network  so that we can use backpropagation to adjust the resulting subclasses. 
1 	conclusions 
a fundamental goal for inductive learners is to generalize well - that is  produce classifiers that accurately predict future examples. we present a straightforward approach for improving generalization in which we combine the predictions of several separately trained neural networks. to be productively combined  each individual network should represent solutions whose errors are largely independent of those of the other networks. our key idea is to use competitive learning to initialize our networks. using competitive learning allows us to create initial networks that lie far from the origin in weight space  yet do not suffer from the  flat-spot  problem that can greatly slow backpropagation training; thus  we are capable of reaching a wider variety of the local minima in this space than are reachable by the standard network initialization method. 
　the first step in our network-initialization algorithm is to use competitive learning to cluster the input patterns for each category into subclasses of that category. in our second step  we create a neural network where each subclass is recognized by one hidden unit. finally  we perform backpropagation to refine the resulting network. we repeat this process a number of times to create several networks that in combination generalize well  according to our experiments on two real-world testbeds. 
　while we are not the first to make the point that the  train-multiple-classifiers  approach is useful  our experiments do provide additional evidence of the merit of this simple technique for improving generalization. in addition  we present a novel algorithm that improves one important aspect of this task  namely the initialization of the set of networks to be trained. 
