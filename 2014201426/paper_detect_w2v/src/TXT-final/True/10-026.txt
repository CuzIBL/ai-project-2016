 
       a method is presented for constructing maximal consistent tntepretations of error!ul data. the method appears applicable to many tasks  speech understanding  natural language understanding;  vision  medical diagnosis  requiring partial-matching of errorful data against complex  hierarchically defined patterns. the data is represented as symbolic structures 
 word sequences  line segment configurations  disease symptoms . errors consist of missing data  unrecognized words  occluded lines  undetected symptoms  and extra  possibly inconsistent  data 
 incorrectly 	recognized 	words  	visual 	noise  
spurious symptoms . 	data 	interpretations correspond to 	substructures 	of 	a 	hierarchy of predef ined concepts. 	constraints 	on 	consistent conceptual hierarchy. correctly 
fragments speech 	structures 	embedded 	the 
　an imp1erne nta t ion of the me t hod has interpreted errorful sets of sentence recognized by the hearsay-ii understanding system. the implementation has also correctly interpreted typed-in ungrammatical sentences. detailed examples i l l u s t r a t e operation of the method on real data. 
1duct1n 
	the 	application 	of 	al 	methods 	to 	complex 
domains   e . g .   spe ec h   vis ion   medical d i agn os is   has expanded the dimensions of data interpretation to incorporate some novel phenomena. two of these phenomena are data error and hierarchically defined data patterns. 
       many complex domains are characterized by errorful data. errors such as insertion  deletion  substitution  and repetition of inf orina t ion incrcase as the uncertainty of source data transduction and interpretation i n cr eases. d a t a ma y be mut vially i nco n s i s t en t in that two or more piece: s of information cannot be explained consistently  tolerating error and inconsis t enc i es in t he data requires robust methods that can not only find the best interpretation but are able to distinguish the inconsistent and errorful data from the consistent data. 
       another aspect of data interpretation in complex domains is that interpretations represent complex  hierarchically defined concepts  ideas  rules  patterns  rather than simple  independent concepts  features . often the concepts used in interpretations can be placed in a hierarchy where each concept is defined in terms  of its subconcepts. this structure of concepts is called a conceptual hierarchy. a collection oi data can then be interpreted by the highest concept in the hierarchy supported  validated  by the data. the interpretation of the data is defined by the concept's descendants  subconcepts  subsubconcepts  e t c .   and the data which supports them. these descendants form a substructure of the conceptual hierarchy. 
　　　the general data interpretation problem can now be restated as a search for the concept in the conceptual hierarchy that explains  is supported by  the most data. the data supporting the structure underlying this maximal concept can be described as the maximal consistent subset of data. 
	in 	this 	paper 	we 	define 	conceptual 
	this 	work was 	supported in part by 	the defense 
advanced research projects agency under contract no. f1-o1 and monitored by the air force office of s c i e n t i f i c research. in addition  the f i r s t author was p a r t i a l l y supported by a national research council of canada postgraduate scholarship and the second author was p a r t i a l l y supported by a national science foundation graduate fellowship. hierarchies and maximal consistent interpretations. we then describe a method for interpreting data in such an environment  i . e .   finding maximal consistent interpretations in a 
conceptual hierarchy. examples i l l u s t r a t i n g the method are shown. f i n a l l y   we show the actual application of the method to the problem of interpreting errorful sentence fragments recognized by the hearsay-ii speech understanding system 
 erman  1 . 
1. a real example 
　　　the ma tch ing problem used as an example throughout this paper is taken from the hearsay-ii speech understanding system. when hearsay-ii is unable to completely recogniz e a spoken sentence  utterance   it generat'* s a set of sentence fragments  hayes-rotn et ai   1c  which must be interpreted by the semantic- interpretation module  named sgi ant. the generat ed fragments can be both errorful a nd mutually inconsistent  example 1 . 1   . a senten ce fragment is a chunk of consistent data in that it consists of a grammatically plausible sequence of recognized words. hearsay-ii mechanisms effective in identifying such chunks are not suite d to combining them into an overall consistent int erpretation of tlie utterance. 
example 1. 1 
1:  1    what has herbert  1  
1:  1  paper about pattern matching   1  
1:  1  in learning or pattern matching j 	 1  
1:  1  	  who 	 1  
correct 	sentence: 
 1   who has written about pattern matching   1  
　　　　example 1 shows four sentence fragments generated when hearsay-ii was unable to recognize the sentence   who has written about pattern matching   . the square brackets denote the start and finish of the spoken utterance. the numbers enclosed in angle brackets specify  in centiseconds  how long after the start of the utterance each fragment begins and ends. fragment 1 correctly matches the i n i t i a l portion of the spoken sentence. fragments 1 contain substitution errors. fragments 1 and 1 are mutually inconsistent in that they provide different interpretations of the the overlapping time period  1 . the fragment pairs 1. 1  1 & 1. and 1 & 1 are inconsistent for the same reason. also  fragment i specifics a what question whereas fragment 1 specifies a who question. thus fragments 1 and 1 are semant leal ly inconsistent  irregard less of their times. each   fragment is semant ically described by a hierarchically structured collection of concepts. figure 1 shows a portion of the conceptual hierarchy used by the semant module in hearsay-ii. figure 1 shows the hierarchical description of the correct sentence. 
       the problem of interpreting these fragments i l l u s t r a t e s the phenomena of data error and hierarchically-structured interpretations. the method used for solving this problem appears applicable to a significant class of problems exhibiting these two phenomena. 
1. 	conceptual ht ferarc.hies 
　　　a conceptual hierarchy can be represented by a directed graph of concepts. this graph is treestructured in that it has a root at the to top and leaf nodes at the bottom; however cycles are permitted. the sons of a node define the subconcepts that compose the father  the root of the graph defines the highest level  most general  interpretation of a l l the concepts beneath i t . 
	a 	given 	interpretation 	task 	has 	a 	set of 

natural 	language-1: 	fox 
1 

prespecified patterns  modelling possible datagenerating events  e.g.  utterances  scenes  diseases . each pattern has its own underlying hierarchy. these hierarchies are collapsed into a single hierarchy  for computational purposes  by adding a new root concept. the sons of the root concept are called the primary concepts of the hierarchy. the primary concepts are the roots of the original disjoint hierarchies. a collection of data is interpreted by choosing one or more primary concepts matched by the data. 
　　　　whether a primary concept can be considered to be matched by the data depends on which  if any  of its subconcepts have been matched and on the relationship between the primary concept and its subconcepts. a concept that requires all. its subconcepts  sons  to be matched as a necessary condition for itself to be matched is a conjunctive concept. the subconcepts are related to the conjunctive concept by the constituent  ispart-of  relationship. a concept requiring any non-empty subset of its subconcepts to be matched is union concept. the subconcepts are related to the union concept by the optional constituent  isoptional-part-of  relationship. a concept which requires one of its subconcepts to be matched is a dis timet iye concept. the subconcepts are related to the disjunctive concept by the taxonomic  1s-a  relationship. other  more complex relationships can be defined on the subconcepts of a concept by defining parameterized constraints on the data supporting trie subconcepts. figure 1 shows part of the conceptual hierarchy used to describe the types of sentences expected by the hearsay -ii speech understanding system. the method used to match sentence fragments to concepts is parameterless but successful nonetheless. this 
met nod is described in section 1. 
　　　　based on the above definitions  a maximal consistent interpretation of the data is defined as the primary concept and the subtree underlying it that is matched by a maximal consistent subset of the data. a maximal consistent subset contains the greatest amount of domain information  measured by some function  that is mutually consistent. if the subconcepts of a concept are mutually consistent  it follows that the domain information that supports  matches  these subconcepts is mutually consistent  with an important qualification. this qualification is necessary because two or more competing  mutually inconsistent  pieces of domain data may support the same concept. a consistent interpretation must choose only one of these pieces of data to support the concept. since there is a choice of which data to incorporate in the interpretation  there are many possible interpretations derivable from the data supporting the subtree. these interpretations can be ordered by the function that measures the quantity of data incorporated in  explained by  an interpretation. thus once concept matching has been carried out  any subtree within the conceptual hierarchy defines consistent data sets. furthermore  the distinction between conjunctive  union  and disjunctive concepts allows us to identify which information is missing in a particular interpretation. missing information corresponds to unsupported sons of partially supported conjunctive concepts. 
　　data consistency must be defined relative to a 
　　　　particular application. a set of data is considered consistent if it satisfies some set of application-specific constraints. some of these constraints can be incorporated in the structure of the conceptual hierarchy; a given hierarchy implicitly defines a class of permissible data combinations. for example  the data configurations supporting the sons of a node are mutually consistent if the node is conjunctive but not if it is disjunctive. other constraints can be incorporated in the chunking process which enerates configurations of data. data chunks ncorporate information about data consistency insofar as the data in a chunk is mutually consistent  and subconfigurations of the chunk are consistent with the chunk itself. this information is incomplete in that it doesn't specify whether different chunks are mutually consistent. finally  constraints not incorporated in the hierarchy or the chunking process must be satisfied by special tests on appropriate properties of the data supporting a potential interpretation. one such constraint in the hearsay-1 example is temporal consistency between the various data fragments supporting the interpretation of an utterance. fragments which assign different transcriptions to the same time interval are mutually inconsistent. 
　　　　the measure of an interpretation must also be defined relative to a particular application. the measuring function should reflect the differing credibility of alternative interpretations. several factors affect this credibility. one of them is the amount of data satisfactorily explained by a given interpretation. an interpretation which accounts tor a large subset of the data may be more credible than an interpretation which accounts for only a small subset. another factor affecting the credibility of an interpretation is the cogency of its conceptual structure. for example  an interpretation with many missing pieces 
 unsupported sons of conjunctive nodes  may be less credible than an interpretation with no missing pieces. an extensive interpretation  supported by many concepts  may be more credible than a limited interpretation  involving very few concepts . a third factor is the individual credibility of the data chunks supporting the interpretation. the number of consistency constraints satisfied by a chunk increases with its size. it these constraints are reasonably rigorous  larger chunks may be more credible than smaller chunks. thus the credib 1 i ty of a particular daturn may be sensi ti veto the context  chunk  in which it occurs. the more accurately these various credibility factors are represented in the iunction which rates alternative interpretations  the more often the maximal  highest-rated  consistent interpretation will in fact be correct. 
1* matchtnc and 	fntkhph f.tt mp. 
　　　　a s p r e v i o u s l y d e s c r i b e d   t h e c o n c e p t u a l h i e r a r c h y i s a g r a p h whose nodes a r e c o n c e p t s . we a l l o w e a c h node to a c t as a r e p o s i t o r y o f i n f o r m a t i o n d u r i n g t h e m a t c h i n g and i n t e r p r e t a t i o n . f i n d i n g t h e maximal c o n s i s t e n t i n t e r p r e t a t i o n i s a t h r e e p a r t p r o c e s s . 
　　　　the 	f i r s t 	phase 	m a t c h e s 	trie 	c o n c e p t s 	a g a i n s t t h e 	d a t a . 	w e 	assume 	t h a t 	t h e 	i n i t i a l 	p a r t 	o f 	t h i s p r o c e s s 	i s 	p e r f o r m e d 	b y 	some 	mechanism 	w h i c h s t r u c t u r e s 	t h e 	d a t a 	b y 	i d e n t i f y i n g 	c h u n k s   	i . e .   l o c a l 	c o n f i g u r a t i o n s 	o f 	m u t u a l l y 	c o n s i s t e n t 	d a t a . i n 	t h e 	c u r r e n t 	e x a m p l e   	t h i s 	mechanism 	i s 	hkarsayi i   	and 	t h e 	c h u n k s 	a r e 	s e n t e n c e 	f r a g m e n t s . 	t h i s m a t c h 	may 	b e 	f u l l 	o r 	p a r t i a l 	i n 	t h a t 	c o n j u n c t i v e c o n c e p t s 	may 	b e 	c o m p l e t e l y 	o r 	p a r t i a l l y 	m a t c h e d . when a 	c o n c e p t 	i s 	s u c c e s s f u l l y 	m a t c h e d   	t h e 	d o m a i n i n f o r m a t i o n 	m a t c h i n g 	t h e 	c o n c e p t 	i s 	s t o r e d 	a t 	t h e c o r r e s p o n d i n g 	n o d e . 	t h i s 	i n f o r m a t i o n 	i s 	s a i d 	t o d i r e c t l y 	s u p p o r t 	t h e 	c o n c e p t . 
　　　　the s e c o i f d p h a s e i n t e g r a t e s t h e c h u n k s b y f i n d i n g c o n c e p t s w h i c h e x p l a i n c o m b i n a t i o n s o f 
　　　　c h u n k s . t h i s i s a c c o m p l i s h e d b y   n o t c h i n g   e a c h m a t c h e d c o n c e p t a n d a l l i t s a n c e s t o r s   i . e .   i n c r e a s i n g t h e i r c r e d i b i l i t y s c o r e s a c c o r d i n g t o t h e amount o f d a t a s u p p o r t i n g t h e m a t c h e d c o n c e p t . the n o t c h i n g p r o c e s s a s s i g n s a m e t r i c o f how w e l l e a c h c o n c e p t i s s u p p o r t e d b y d a t a . v a r i o u s m e t r i c s a r e p o s s i b l e . t h e m e t r i c u s e d i n t h i s p a p e r i s d e f i n e d a s f o l l o w s . the s c o r e o f a d i s j u n c t i v e c o n c e p t i s t h e s i z e o f t h e l a r g e s t chunk d i r e c t l y s u p p o r t i n g t h e c o n c e p t p l u s t h e s c o r e o f t h e 
　　　　c o n c e p t ' s h i g h e s t - r a t e d s o n . the s c o r e o f a 
　　　　c o n j u n c t i v e o r u n i o n c o n c e p t i s t h e sum o f t h e 
　　　　s i z e s o f t h e c h u n k s s u p p o r t i n g i t d i r e c t l y   p l u s t h e sum o f t h e s c o r e s o f i t s s o n s . the s c o r e o f a n u n s u p p o r t e d c o n c e p t i s z e r o . s c o r i n g i s c o m p u t e d b y a o n e - p a s s n o t c h i n g p r o c e s s w h i c h p r o p a g a t e s s c o r e s b o t t o m - u p s t a r t i n g a t t h e l e a v e s o r t h e 
　　　　h i e r a r c h y . the n o t c h i n g p r o c e s s can be v i e w e d as a 
　　　　f l o w o f s u p p o r t f r o m t h e d a t a t h r o u g h t h e 
　　　　c o n c e p t u a l h i e r a r c h y . 
　　　　the 	l a s t 	p h a s e 	s e l e c t s 	a 	c o n s i s t e n t i n t e r p r e t a t i o n 	b y 	w a l k i n g 	t o p - d o w n 	t h o u g h 	t h e h i e r a r c h y 	s t a r t i n g 	a t 	t h e 	r o o t 	c o n c e p t   	and i n c o r p o r a t i n g 	t h e 	v i s i t e d 	c o n c e p t s 	i n t o 	t h e 
i n t e r p r e t a t i o n . 	the 	m a x i m a l l y 	s u p p o r t e d 	s u b t r e e 
i n 	t h e h i e r a r c h y 	i s 	f o u n d 	b y 	i n t e r r o g a t i n g 	t h e 
s c o r e 	o f 	each 	c o n c e p t . 	when 	t h e w a l k 	e n c o u n t e r s 	a 
d i s j u n c t i v e 	c o n c e p t   	o n l y 	i t s 	h i g h e s t - s c o r e d 	son 
i s 	i n c o r p o r a t e d 	i n 	t h e 	i n t e r p r e t a t i o n 	a n d 

natural 	lan ua e-1: 	fox 
1 

subsequently v i s i t e d   since the sons of a d i s j u n c t i v e concep t are m u t u a x c l u s i v e . when a 
con j unct ive or un i on concept is encountered  a l l of i ts sons wi th non zero scores are included in the i n t e r p r e t a t i o n and subsequently v i s i t e d   since they are mutually consi s t e n t . unsupported  zero-scored  sons of conjunctive ve concepts in the i n t e r p r e t a t i o n i d e n t i f y missin g data.  more complex r e l a t i o n s h i p s bet ween concepts and t h e i r sons wouid allow mo re complex deductions.  the subtree produced in t l i s fashion represents an i n t e r p r e t a t i o n supported by a maximal consistent subse t ot the data. this consistent subset can be read ly i d e n t i f i e d since the subtree points to the data that supports i t . 
       the nature of the i n t e r p r e t a t i o n generated depends on wheth er the root of the conceptual hierarchy is dis unctive or union. 1 the root is d i s j u n c t i v e   only on  of the primary concepts is incorporated in th e i n t e r p r e t a t i o n . this property is useful when the purpose of ma tch ing ls to cllass i f y an event according to which s i n g l e concept best models i t . if the root is union  the i n t e r e t a t i o n c an i n t e g r a t e m u l t i p l e primary concepts in order to explain the data. this ca pa b i 1 i t y i s us e f u l in domains such as medical diagnosis where the primary concepts model d i f f e r e n t events  diseases  which can occur s imult aneously. 
1. 	a detailed example 
       semant s rati telling domain is composed of e r r o r f u l   sometimes mutually i n c o n s i s t e n t sentence fragments  chunks . a p o r t i o n of the conceptual hierarchy is shown in figure 1 . 1 . 
	trie 	i n i t i a l process of matching the 	domain 
 fragments  to the concepts  i . e .   i n t e r p r e t i n g i n d i v i d u a l chunks  is done by p a r s i n g . a parser c a l l e d pparse  erman  1   taken from the hearsay-1 syntax and semantics module  hayes-roth  mostow  and fox  1 / / ; hayes-roth et a l   1a   is used to parse each sentence fragment. pparse generalizes e x i s t i n g parsing techniques to parse connected subsequences of sentences generated by the grammar. such a sequence may cross the boundaries of the grammatical nierarchy in that it may not be grammatically d e r i v a b l e from any s i n g l e nont e r m i n a l . pparse produces a l l d e r i v a t i o n trees f o r each fragment.  an ambiguous fragment has more than one d e r i v a t i o n t r e e .   the grammar used by pparse is a semantic grammar  hayes-roth  mostow  and fox  1  in which some of the nonterminals have associated semantic meanings. these n o n - t e r m i n a l s   c a l l e d semantic nodes  correspond to matched concepts in the h i e r a r c h y . in the present grammar  a semantic node has the same name as the corresponding concept. thus the d e r i v a t i o n tree f o r a sentence fragment points d i r e c t l y to the concepts it matches. 
　　　the matching process can be described as f o l l o w s : 
   1  the data is chunked by hearsay-!.i i n t o possibly overlapping sentence fragments. 
   1  the process of single-chunk i n t e r p r e t a t i o n determines how each chunk f i t s i n t o the conceptual h i e r a r c h y : 
	1a  	eacn fragment is parsed by pparse. 
　　　　1b  for each semantic node in the parse  the corresponding concept in the nierarchy is found  and a pointer to the semantic node is placed at the concept. thus one can r e t r i e v e the word sequence s  supporting any given concept. 
   j  the concept and i t s ancestors are notched by the number of words underlying the semantic node in the parse of the fragment. the d e t a i i s of the notching metric have already been discussed  section 1   . 
       figure 1 shows the parse trees f o r the fragments  papers about pattern matching  and  artificial intelligence . nonterminals are d i s t i n g u i s h e d by the  s  p r e f i x . only the c i r c l e d nodes are matched i n t o the conceptual h i e r a r c h y : $topic because it is semantically meaningful and $mention!topics because it is the root node of a parse. when the root node of a d e r i v a t i o n tree is not a semantic node  it matches the concept s  corresponding to i t s nearest semantically meaningful ancestor s  in the grammar. in t h i s example  the nearest such ancestors of the root node  mention!topics are $query!topic and $query!topic!author. 
       figure 1 shows the matching of the topic concept by the stopic node.  note that concept names are not p r e f i x e d by   $     . the score of the 
$topic node is 1 because the sub-fragment  pattern matching  underlying it is two words long. this score c o n t r i b u t e s to the scores of a l l the ancestors of topic in the conceptual h i e r a r c h y . 
       figure 1 shows the matching of the querylt1c and query'topic!author concepts by the smention!topics node. the score for t h i s node is 1  since $mentionitopics is supported by the 1-word sequence papers about pattern matching. a l l concepts supported by the smention!topics node are accordingly notched by 1. figure 1 shows the matching of the topic concept by  the stopic node supported by the fragment  artificial intelligence. the topic concept and a l l i t s ancestors are notched by 1. note that while the fragment parse trees contain more than one $topic node  the conceptual hierarchy contains a s i n g l e canonical topic node. 
　　　the c o n s t r u c t i o n of the maximal consistent  i n t e r p r e t a t i o n s t a r t s at the root of the hierarchy. at a d i s j u n c t i v e concept semant chooses the highest-scored son to be in the i n t e r p r e t a t i o n . in figure 1 the highest-scored primary concept is request and is therefore chosen instead of prune. semant next looks at the sons of the 
request concept  which is also d i s j u n c t i v e . the query concept is chosen since it is the h i g h e s t scored son of request. the highest-scored sons of query are queryitoplc and query!topic!author 
 both are supported by smention1pics . either one can be chosen to be part of the i n t e r p r e t a t i o n . when semant readies the topic concept  it must choose which supporting data to incorporate in the i n t e r p r e t a t i o n . since semant has traversed a concept supported by the node .smention! topics in order to reach the topic concept  tlie choice of topic is c a r r i e d out in the context of the smention 1pics. hence pattern matching is chosen since it is part of that context   i . e .   is part of the fragment supporting smention!topics . figure 1 depicts a r e s u l t i n g i n t e r p r e t a t i o n and i t s corresponding support.  note that choosing the concept 
query!topic!author instead of query1pic y i e l d s an equally well-supported i n t e r p r e t a t i o n .   
       figure 1 shows the matching of fragments generated when hearsay-ii was unable to recognize the sentence  let's restrict our attention to papers since nineteen seventy four . the fragments  to papers since nineteen seventy 
four  and  let's restrict our attention to  are mutually consistent while the fragment  design in the arts  is not consistent w i t h e i t h e r of the other two fragments according to the s t r u c t u r e of the conceptual h i e r a r c h y . the l i g u r e shows the state of the conceptual hierarchy a f t e r notching has taken place. the maximal consistent i n t e r p r e t a t i o n generated is shown in figure 1. this i n t e r p r e t a t i o n is the same as that of the correct sentence. thus the i n c o n s i s t e n t information is ignored and the two consistent fragments are semantically combined to form a maximal consistent i n t e r p r e t a t i o n of the u t t e r a n c e . 
       semant can use contextual information to discard the i n c o r r e c t p o r t i o n of a p a r t i a l l y correct fragment. this c a p a b i l i t y is most c l e a r l y i l l u s t r a t e d by a h y p o t h e t i c a l problem. suppose 
hearsay-ii 	f a i l s to 	recognize the 	utterance 	did 
reddy write any articles about learning  but generates the fragments  did reddy write any articles about  and  interested in learning.  
figure 1 shows how these fragments are matched i n t o the conceptual h i e r a r c h y . the f i r s t fragment supports author and query!author!toplc. the second fragment supports topic and selection. the enerated i n t e r p r e t a t i o n is shown in figure 1. t incorporates the highest-scored primary concept 
request  	in 	preference 	to 	the 	lower-scored 
selection. 	the 	incorporated 	conjunctive concept 
query!topic!author is supported by both 	author and 
natural 	language-1: 	fox 
1 topic. since these two concepts are mutually c o n s i s t e n t   they are both included in the i n t e r p r e t a t i o n   even though they are supported by d i f f e r e n t fragments. consequently the i n t e r p r e t a t i o n incorporates the correct word  learning  from the second fragment  but discards the i n c o r r e c t sub-fragment  interested i n     since the selection concept is not part of the i n t e r p r e t a t i o n . 
　　　another f e a t u r e i d e n t i f y which data 
receding example ragment   published of semant is i t s a b i l i t y to is missing. suppose in the 
hearsay-il 	generates 	the 
in 	ijcai  	instead 	of 	the fragment 	 interested in 	learning.  	figure 	1 shows 	the 	matching of 	the 	generated fragments. this example d i f f e r s from the preceding example in that the second fragment contains no information consistent w i t h the f i r s t . the maximal consistent i n t e r p r e t a t i o n   shown in figure 1 . 1   is supported only by the f i r s t fragment. it incorporates the conjunctive concept query!topic!author  whose son topic is unsupported. thus semant can predict that the missing data  unrecognized p o r t i o n of the utterance  includes data which would support topic. such a semantic p r e d i c t i o n could be used to guide f u r t h e r e f f o r t s by hearsay-ii to recognize the utterance  hayes-roth et a l   1b; hayes-roth  mostow  and fox  1 . a l t e r n a t i v e l y   it could be used as grounds f o r asking the user to repeat the topic  hayes-roth  g i l l   and mostow  1 . 
1. complications 
       the problem of f i n d i n g a maximal consistent i n t e r p r e t a t i o n of the data is complicated by a c o n f l i c t between maximality and consistency. maximality is defined in terms of a scoring metric on concept support. a correct metric f u n c t i o n w i l l score the nodes in such a way that a simple t o p down walk that s e l e c t s the h i g h e s t - r a t e d son of every d i s j u n c t i v e node w i l l in fact generate the maximal consistent i n t e r p r e t a t i o n . i d e a l l y   the scoring process should require a s i n g l e bottom-up pass which v i s i t s each node at most once. 
       u n f o r t u n a t e l y   the c o n t e x t - s e n s i t i v e nature of consistency may preclude the r e a l i z a t i o n of t h i s i d e a l . the i n c o r p o r a t i o n of a chunk of data as support f o r a h i g h - l e v e l concept in an i n t e r p r e t a t i o n creates a commitment to incorporate subparts of that data chunk as support f o r lowerl e v e l concepts. this idea is i l l u s t r a t e d in figure 1 . 1 . the n i g h - l e v e l d i s j u n c t i v e concept query is supported by the 1-word fragment  chunk   do any articles mention learning   and has score 1. query has two sons: query!topic  which is supported by the 1-word sub-fragment  mention learning   and query!source  which is supported by the 1-word fragment  in ij cat. proceedings.  accordingly  query!topic has score 1 and query!source has score 
1. consider the behavior of a top-down walk which s e l e c t s the h i g h e s t - r a t e d son of every d i s j u n c t i v e node. such an a l g o r i t h m incorporates the fragment supporting query i n t o the i n t e r p r e t a t i o n   thereby morally committing i t s e l f to incorporate the subfragment supporting query!topic. the a l g o r i t h m then v i o l a t e s i t s commitment by s e l e c t i n g query!source over the lower-scored query'topic and consequently generates the i n c o n s i s t e n t i n t e r p r e t a t i o n shown in figure 1. the correct maximal consistent i n t e r p r e t a t i o n   shown in figure 1  is constructed by f u l f i l l i n g t h i s commitment. 
　　　what e x a c t l y is the problem here  the i n c l u s i o n of a chunk of data as support f o r a concept in an i n t e r p r e t a t i o n creates a commitment to include concepts supported by subchunks of that data. in s h o r t   the s e l e c t i o n of support f o r a 
　　　concept is c o n t e x t - s e n s i t i v e   since it depends on the data chosen to support the concept's ancestors in the conceptual h i e r a r c h y . however  the scores assigned by a one-pass bottom-up notching a l g o r i t h m are c o n t e x t - f r e e . consequently they do not always select the c o r r e c t  maximal c o n s i s t e n t   i n t e r p r e t a t i o n . as the preceding example i l l u s t r a t e s . we see several possible approaches to solving t h i s problem. 
　　　the f i r s t approach compensates f o r d e f i c i e n c i e s of the c o n t e x t - f r e e scoring f u n c t i o n by i n t r o d u c i n g some search in the top-down s e l e c t i o n of an i n t e r p r e t a t i o n . if i n c o r p o r a t i n g the highest-scored son of a d i s j u n c t i v e node leads to an inconsistent i n t e r p r e t a t i o n   the next-highest node can be t r i e d . 
　　　the second approach uses a c o n t e x t - s e n s i t i v e scoring scheme so tnat a non-backtracking top-down walk w i l l work c o r r e c t l y . one way to do t h i s is to notch concepts using a bottom-up process  but under c e r t a i n circumstances to reevaluate descendants of a concept in the context of i t s supporting data. note that the c o n t e x t - f r e e score of a concept is an upper bound on the size of the largest consistent set of data supporting that concept. the a p p l i c a t i o n of a d d i t i o n a l c o n s t r a i n t s such as context can only decrease the size of t h i s s e t . thus one i n d i c a t i o n that a node may need to be reevaluated in context is a f a i l u r e to support it 
w i t h a data set as large as i t s score. 
	these 	approaches have 	a common 	defect: 	the 
 maximal c o n s i s t e n t i n t e r p r e t a t i o n s   they generate may f a i l to s a t i s f y c e r t a i n consistency c o n s t r a i n t s not represented in the s t r u c t u r e of tne conceptual hierarchy. for example  a consistent i n t e r p r e t a t i o n of a spoken utterance cannot be supported by two c o n f l i c t i n g data fragments  word sequences  spanning the same temporal i n t e r v a l of the u t t e r a n c e . s i m i l a r l y   a consistent i n t e r p r e t a t i o n of a scene cannot assign two c o n f l i c t i n g l a b e l s to the same r e g i o n . 
representation of such c o n s t r a i n t s in the conceptual hierarchy appears to require the propagation of temporal or s p a t i a l information through the hierarchy and the parameterization of node r e l a t i o n s   c u r r e n t l y and  xor  union  to t e s t such i n f o r m a t i o n f o r consistency. 
　　　the t h i r d approach  c u r r e n t l y under development  uses a parameterized conceptual hierarchy. after data support is attached to appropriate  nodes in the h i e r a r c h y    notch tokens  are propagated up from the leaves of the h i e r a r c h y . each token represents a p a r t i c u l a r set of data supporting   i n s t a n t i a t i n g   a concept. a token is propagated upward from a node by passing copies of it to the node's parents. when tokens are passed to a conjunctive or union node from several of i t s subconcept nodes  a new token is formed representing the combined data supporting the concept. i f t h i s data i s mutually i n c o n s i s t e n t   i t is s p l i t i n t o maximal consistent subsets  each represented by a new token. 
       such parameterized conceptual h i e r a r c h i e s provide stronger domain models by i n c o r p o r a t i n g a d d i t i o n a l consistency c o n s t r a i n t s . however  experience w i t h such ' parameterized h i e r a r c h i e s shows that they involve more computation than do unparameterized h i e r a r c h i e s   since the various instances  tokens  of each concept   d i s t i n g u i s h e d by t h e i r d i f f e r e n t parameter values  must  be processed   e . g .   scored  separately  hayes-roth and mostow  1;  mostow and hayes-roth  1 . thus it may be desirable to develop a h y b r i d matching scheme that tests as many c o n s t r a i n t s as possible in a parameterless conceptual hierarchy and only tests r e s i d u a l c o n s t r a i n t s afterwards. in t h i s f o u r t h approach  the parameter1ess hierarchy functions as a weak model of the domain. the matching process e f f i c i e n t l y f i l t e r s the data  generating maximal i n t e r p r e t a t i o n s s a t i s f y i n g a l l the c o n s t r a i n t s embedded in the hierarchy. if such an i n t e r p r e t a t i o n f a i l s to s a t i s f y tne residual c o n s t r a i n t s   the matcher f i n d s the next h i g h e s t scored i n t e r p r e t a t i o n . this process continues u n t i l a n i n t e r p r e t a t i o n s a t i s f y i n g a l l c o n s t r a i n t s is found. this is the desired maximal consistent i n t e r p r e t a t i o n . 
fit discussion 
       several points about the presented method should be emphasized. 
1 	importance of chunking 
       chunking c o n t r i butes to the success of our method in several ways. the chunking process i d e n t i f i e s semanticaily meaningful c o n f i g u r a t i o n s of data  i . e .   c o n f i g u r a t i o n s corresponding to  substructures of  known concepts. this s t r u c t u r i n g of the data is e s s e n t i a l to the c o n s t r u c t i o n of a coherent i n t e r p r e t a t i o n . chunking provides information about data consistency i n s o f a r as the data in a chunk is mutually c o n s i s t e n t . this information is incorporated in the process of c o n s t r u c t i n g an 
i n t e r p r e t a t i o n . chunking also provides information about the contextual c r e d i b i l i t y of data insofar as the data in a chunk is mutually confirmatory. this i n f o r m a t i o n   represented by varying chunk s i z e   is incorporated in the scoring metric and helps d i s c r i m i n a t e between a l t e r n a t i v e i n t e r p r e t a t i o n s . 
tl1-importance of hierarchy 
　　　another important aspect of the method is i t s use of h i e r a r c h i c a l s t r u c t u r e to embed c o n s t r a i n t s on data consistency. mutual e x c l u s i o n . mutual necessity  and mutual consistency of sudconcepts are modelled r e s p e c t i v e l y by d i s j u n c t i v e   c o n j u n c t i v e   and union nodes. any subgraph of the 

natural 	lanj :uap;e-1: 	fox 1 

hierarchy in which no disjunctive node lias more than one son constitut.es a consistent  possibly incomplete  conceptual structure. the data supporting such a structure consequently s a t i s f i e s many constraints on data consistency. 
       the hierarchical structure also permits the i d e n t i f i c a t i o n of missing data. mutual necessity of concept constituents is represented by conjunctive nodes. unsupported sons of conjunctive concepts incorporated in an interpretation therefore represent missing constituents. 
       the parameter less nature of the conceptual hierarchy precludes the embedding of certain types of constraints. in the speech understanding example  since temporal information is not propagated through the hierarchy  temporal constraints such as adjacency  ordering  and nonoverlap are not represented jn the hierarchy. in the vision domain  since location information is not propagated through the hierarchy  spatial constraints such as allignment  adjacency  proximity  ordering  and non-overlap are not represented. this reduction of constraint allows semantically consistent chunks to be incorporated in an interpretation even if they don't conform to a stronger  more constrained  model of the domain. this aspect of the representation permits increased f l e x i b i l i t y in the matching process  in that the constraints on the integration ot multiple chunks into an interpretation are weaker than the constraints on the local integration of data into individual chunks. furthermore  the simplicity of the representation should make the matching process faster than methods which represent consistency constraints as tests on propagated parametric information. the disadvantage of the simpler representation is its greater potential for constructing inconsistent interpretations. 
ft.i.1. rower oj lht; method 
　　　the presented method interprets sets oi hierarchically structured  possibly mutually inconsistent chunks of data. although it exploits information incorporated in the chunk structure  the method is not restricted to accepting or rejecting chunks in an all-or-none fashion; the method can discard part of a chunk in order to construct a consistent interpretation which incorporates the remainder of the chunk. the constructed interpretation corresponds to a highly partia1-matched substructure of the conceptual hierarchy. unsupported constituents of the substructure identify missing data. 
1-ja applications ojlliie current 	implementation 
　　semant was originally developed to interpret sentences and sentence fragments recognized by hearsay-1i  hayes-roth et a 1b . in addition to this task  semant has been applied to the interpretation of ungrammatica1 sentences. a sentence is chunked into its maximal grammatical subsequences  which are input to semant as fragments. semant then integrates the fragments 
programs p e r f o r m i n g r e a l - w o r l d t a s k s . such programs w i l l have t o h a n d l e u n c e r t a i n   i n c o n s i s t e n t data c o r r e s p o n d i n g only a p p r o x i n u i t e l y to known c o n c e p t s . the p r o b l e m of i d e n t i f y i n g c o n s i s t e n t s u b s e t s of data and i n t e g r a t i n g  them i n t o a h i e r a r c h i c a l l y o r g a n i z e d c o n c e p t u a l knowledge base can a c c o r d i n g l y be e x p e c t e d to assume i n c r e a s i n g i m p o r t a n c e . 
erma 	l . u .   	1 / 1   	overview 	oi 	the 	hearsay 
	speech 	u n d e r s t a n d i n g 	r e s e a r c h . 	computer 
	science 	research 	review 	 1 1 - 1 1     	computer 
	science 	d e p a r t m e n t   	c a r n e g i e - m e l l o n 
 u n i v e r s i t y . p i t t s b u r g h   pa. n  l . i       1 1. a f u n c t i o n a l d e s c r i p t i o n of th j hearsay-ll speech u n d e r s t a n d i n g system  p r o c . 1 1 ieee i n t e r . conf. on a c o u s t i c s   speech and s i g n a l p r o c e s s i n g   t o a p p e a r   . 
have s-roth k. f l/. d.erman  m.s. fox  and d . j . mostow  i 1a  s y n t a c t i c p r o c e s s i n g i n h e a r s a y - i i   speech u n d e r s t a n d i n g systems: 
	summary 	of 	r e s u l t s 	of 	t h e 	f i v e - y e a r 	research 
	e f f o r t   	depa r t me nt 	o f 	compu t e r 
	s c i e n c e   	c a r n e g i e - m e l l o n 	u n i v e r s i t y   
p i t t s b u r g h . 
haye s-pvoth f .   m.s. 	fox  c . g i l l   	and 	i . j . 	mos tow   
1b  semantics and p r a g m a t i c s in the heaksay-1i speech u n d e r s t a n d i n g system. 
	speech 	u n d e r s t a n d i n g systems: 	summary 	ot 
	r e s u l t s 	o f 	t h e 	f i v e - y e a r 	research 	e f f o r t   
depart me nt o f compu t e r sc i e n c e   c a r n e g i e - m e l l o n u n i v e r s i t y   p i t t s b u r g h . 
have s - r o t h   f .   v. l e s s e r   d . j . mostow  and l . d . erman  1c  p o l i c i e s f o r r a t i n g h y p o t h e s e s   h a l t i n g   and s e l e c t i n g a s o l u t i o n in t h e hearsay-ll speech u n d e r s t a n d i n g s y s t e m     speech u n d e r s t a n d i n g systems: summary of r e s u l t s of the f i v e year research e f f o r t   department of computer s c i e n c e   c a r n e g i e - m e l l o n u n i v e r s i t y   p i t t s b u r g h . 
haye s - r o t h f .   and d . j . mostow  1  an a u t o m a t i c a l l y c o m p i l a b l e r e c o g n i t i o n network f o r s t r u c t u r e d p a t t e r n s . p r o c e e d i n g s o f the f o u r t h i n t e r n a t i o n a l j o i n t c o n f e r e n c e on a r t i f i c i a l i n t e l l i g e n c e . cambridge: m i t . 
haye s - r o t h f .   g . g i l l   and d . j . mostow  1    d i s c o u r s e a n a l y s i s & task performance in the hearsay-ii speech u n d e r s t a n d i n g s y s t e m   
  speech u n d e r s t a n d i n g systems: summary of r e s u l t s o f the f i v e - y e a r research e f f o r t   department. of computer s c i e n c e   c a r n e g i e m e l l o n u n i v e r s i t y   p i t t s b u r g h . 
hay  s-rot h 	k.  	d . j . 	mos tow  	and m.s. 	fox  	1  
	u n d e r s t a n d i n g 	speech 	in 	the 
to a p p e a r : n a t u r a l language computers  l . bole   e d .     v e r l a g . 
mos t ow 	d . j .   	and 	f. 	h a y e s - r o t h   
	waterman and 	f. 	hayes-roth hearsay-ii system  communication with 
b e r l i n : 	s p r i n g e r -
1  	a p r o d u c t i o n c k
	  e d s .     	p a t t e r n 	d i r e c t e d 	i n f e r e n c e 	systems. 	new 	y o r k : 
	academic 	p r e s s   	  i n 	p r e s s   . 

into 	an 	interpretation 	of 	the 	sentence. 	this 
method 	has 	been 	used 	to 	correctly 	interpret sentences containing errors of 	insertion  deletion  substitution  r e p e t i t i o n   and re-ordering. 
1  conclusions 
       we have designed and implemented a method for identifying and interpreting maximal consistent subsets of data in hierarchically modelled domains characterized by data error and inconsistency. the implementation has correctly interpreted spoken sentence fragments recognized by the hearsay-ll speech understanding system. it has also been used successfully to interpret typed-in ungraminatical sentences. 
	the 	method appears 	applicable to 	many tasks 
  e . g .   speech understanding  natural language understanding  scene analysis  medical analysis  requiring matching of error! ul data against complex  hierarchically describable structures. when missing data or tne inherent nature of the task causes the structures to be incompletely instantiated  partial-matching ot these structures provides consistent  meaningful interpretations of the data. 
       the continuing progress of ai beyond toy problems will be by intelligent 
	natural 	lan ua e  1: fox 
1 




