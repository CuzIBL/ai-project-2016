 
　in this paper**  we attempt to quantify what is meant by the terms  degenerate view'*  and its relatives   characteristic view    visual event   and  general viewing position . we propose that the definition of degeneracy is itself degenerate  taking on differing meanings at different times. we claim  at least for the case of polyhedra  that one can only speak of a two-dimensional stimulus as being degenerate with respect to a given heuristic for inverting the image function. additionally  we show that given the finite viewing resolution of a two-dimensional retina  in practice the concept of a characteristic view is often not characteristic of real imagery. even precisely defined general viewing positions are sensitive to camera acuity: any viewpoint ceases to be characteristic at some resolution  and non-characteristic views are not vanishingly improbable. we provide initial quantitative estimates on these probabilities for some simple cases  and relate them to a minimal disambiguation distance. it follows that an aspect graph is less a discrete graph  and more properly a partitioning of the surface of the viewing sphere into  fuzzy  regions of non-zero area: an aspect map. this viewpoint is more in keeping with recent and proposed work on optimal viewing strategies. 
1 introduction 
　robotic vision systems must both obtain images and analyze them. however  a primary characteristic of many realistic imaging situations is that the data acquisition is much less costly than the subsequent data analysis. in such domains it is therefore reasonable to dedicate significant computational effort towards the task of calculating an optimal viewing point for the next image capture. defining and obtaining this optimum is necessarily probabilistic; it must incorporate an understanding of the limits of resolution of the camera  and of the limits of resolution of the placing agent the overall goal is to obtain maximal information from a sequence of inexact images in inexact placements  while minimizing some work function which expresses the relative costs of image acquisition and image analysis. such calculations necessarily place a heavy premium on avoiding what are often referred to as  degenerate views . 
　nevertheless  it is not apparent what makes a view degenerate  how such a view is recognized or forecast  or even whether such 
views are rare or commonplace. thus  the first concern of this paper is to define and quantify the meaning of the term  degenerate   and to show the varying imaging contexts in which it can arise. secondly  we suggest a representation useful for calculating the likelihood of such views  whatever their definition ; it takes the form of mappings over the viewing sphere. this representation extends existing work on aspect graphs by explicitly 
　*thii research was supported in part by arpa grant #n1-c-1  by a nsf presidential young investigator award  and by faculty development awards from at&t  ford motor co.  and digital equipment corporation. 
　** a more detailed version of this paper  including a survey of multiple viewpoint representations  as well as complete references and appendices  may be found in  render and freudensteln 1  
incorporating the known limits of visual acuity. it also leads directly to methods of associating with each view a probability of its being attained  and the placement cost of attaining such a view. 
1 degenerate viewpoints in theory 
　if it is to be useful  a representation for the views of a three dimensional object or object assembly must give some insight into those viewing positions which are less helpful in resolving ambiguities of object structure  position  or orientation. we present two common views of what such degeneracy is  show that they are deficient  and redefine them in ways that are more quantifiable. 
1 slight movements giving drastic changes  
　perhaps the simplest example of ambiguity is the case of a headon view of a cube  which is ideally imaged as a square. such an image has often been noted as giving no information as to the three-dimensionality of the object  and has therefore been described as a degenerate image  see for example   kanade 1; sabbah 1   . degeneracy in this context  however  refers to the fact that a  slight  change in the viewpoint which generated the image would cause a  drastic  change in the image  sometimes called an  image event  . 
　this definition  and related descriptions of what makes a viewing position general or an image characteristic  chakravarty 1   is inadequate in two ways: 
1. it is vague with respect to the meanings of  slight  and  drastic . 
1. it does not encompass all the phenomena that would seem to be properly described as examples of degeneracy. 
　what changes drastically in the cube-as-square image can be characterized in many ways: the number of regions change  the topology of the image regions is altered  apparent symmetries are modified  and  if lines are labeled in the huffman-clowes manner  the junctions are relabelled  cf.  lavin 1; thorpe and shafer 1  . still other derived properties of the image change  too. more generally  depending on the means of analysis  this view of the cube would be called degenerate if a slight change in viewpoint would alter the  quality  of the ensemble of extracted image features used in shape analysis. a rigorous definition of this  quality  change must then include the requirement that a qualitative change is one that ultimately affects the derivation of those object's  semantic  properties  such as identity  scale  rotation  coloring  etc.  considered important by the system. 
　the drastic change is therefore a drastic change in interpretation  not in image. therefore the perception of a drastic change can vary from system to system. for example  if the system distinguishes cubes from spheres by detecting the presence or absence of long straight lines  the cube-as-square cannot be 
	kender and freudenstein 	1 
　
considered degenerate.  and  in net  if the cube is the only model in the system at all  no view is ever degenerate.  
　what is hiding behind mis implicit definition of  drastic  is the interpretation equivalence relation; a drastic change is a change of interpretation equivalence classes. however  since in many systems the interpretation classes are inherited from the feature equivalence classes  commonly the drastic change has been attributed to image characteristics alone. 
　similarly  the notion of  slight movement  is imprecise. what is usually implicit in such definition is that there is at least one 
direction in which an arbitrarily small movement of the camera causes the drastic change.  usually the direction is on a line perpendicular to an image edge . the meaning of  arbitrarily small  only appears to make sense when taken in the sense of mathematical analysis. that is  the drastic change must occur for positive movements of magnitude less than some epsilon  in the direction of degeneracy. 
　such a definition would imply that degeneracy can be qualified as a matter of varying degree  although this is apparently never stated. that is  what can vary from degeneracy to degeneracy is the number of possible   qualitative   drastic changes  and the relative number of directions in which such resolutions  or nonresolutions  occur. for example  the cube-as-square image can resolve itself into an image with either two or three regions  with die two region image possible only for four discrete directions of camera movement all other directions resolve it into an image with three regions  even if some of those regions are vanishingly thin. further  some  degenerate  views sometimes do not resolve at all. for example  the cube imaged as two rectangles remainstwo rectangles for two discrete directions of movement  resolving itself into three regions under movement in all other directions. the space of allowable degeneracies is apparently very large  and perhaps can be quantified in absolute terms as some measure defined on the ways in which the view fails to resolve into something more  characteristic . 
　the converse of the common  small gives drastic  definition is perhaps easier to implement this converse definition it stated as follows: an image is seen from a  general viewpoint  if there is some positive epsilon for which camera movements in any direction can be taken without effect on resulting semantic analysis. here  too  the definition is based ultimately on system performance; an image can be degenerate to one system but not another. note that this definition of degeneracy need not directly appeal to any cansideration of there dimensional models. 
and the  necessarily  heuristic procedures of the system for inverting the image projection. again  this is a system performance definition  and an image s degree of degeneracy would change as system parameters change. 
　it would appear that this definition must be probabilistic. it is not hard to conceive of objects or object assemblies in which multiple viewpoints give identical images  but for which the resolution into a single interpretation takes varying strategic paths depending on the differing image features that can appear in the second view.  take as an example a cube with a single distinguished face  viewed initially so that only one nondistinguished face is visible.  the likelihood of taking each path can be quantified: the most inclusive measure of an image's degeneracy would be then be its probability-labeled search tree. various measure* based on the full tree  one of which is  of course  is expected depth  could also serve as s measure of degeneracy. under this definition  tree breadth has no strong role: a degenerate image can resolve itself into hundreds of images  but as long as each new image was interpretable. the original image is no less degenerate than the pyramid viewed from below. 
　it is interesting to note a paradoxical consequence of this systems' view of degeneracy. as a system's power increases due to the availability of more sophisticated shape analyzing tools  such as when shape from skewed symmetry is used widh shape from shadins   more types of ambiguity are possible. each method brings with it a weakness. the implication is that vision systems with multiple sources of knowledge must know when to ignore a source undergoing degeneracy. this meta-knowledge can be explicidy coded  or implicitly handled by means of a flexible enough representation that permits  don't know much  as a valid answer. 
1 specific imaging degeneracies 
　considering now only images of polyhedral objects  it is possible to eive a catalogue of image degeneracies. each is based on a specific heuristic for inverting the three-dimension to twodimension image function. the list is partial  and omits some heuristics that are even more fundamental  such as the generally assumed heuristic rules that lines in the image have been caused by lines in three-space.  in this last case  this would imply that any planar curve imaged from within its plane would often be considered as degenerate  if the system were unable to interpret it as other than a linear object  
　
1 unlikely views  
　even this definition of t degenerate viewpoint it incomplete; basically it lays that generality is a form of stability. many stable viewpoints ought to be considered degenerate  at least in the sense that that they are less likely to allow a system to instantiate a proper model than other viewpoints. 
consider a pyramid with a square base and arbitrary height 
 customarily  it has equilateral triangles for its sides  but we relax mat restriction.  imaged from many viewpoints from below  its image appears to be a type of rhomboid: a tilting square. none of these viewpoints is degenerate according to he stability definition above  since a slight cnange in viewpoint does not cause a drastic change in the image; it merely tilts the rhomboid in fact  there is a 
great deal of viewpoint freedom  and many views appear to yield the same semantic result: a partly instantiated pyramid with height information largely missing  what is most disturbing about such views is that they are potentially the most common. for a very flat pyramid  such rhomboids appear from nearly half of all viewing directions. 
　yet it seems plausible to suggest that these particular views be considered at least partially degenerate; in contrast to some other views  these images give little information about how to instantiate the pyramid's height  they do place weak upper limits on the height: the peak is constrained to heights that keep it invisible.  further  if our model base were more complete  we would not be able to distinguish such a view from among similar views of a triangular wedge with square base  or any similarly tapering polyhedron with a square base  despite the stability of our vantage point thus  we may wish to include in our definition of degeneracy those viewpoints from which  relatively little  threedimensional information may be obtained  regardless of stability. 
　operationally  this aspect of degeneracy can be quantified as the expected number of additional views necessary to disambiguate the object; degeneratet view is therefore one that is relatively unifororative and will requite mote linages. this number clearly depends on the complexity of the model data base  the intelligence of the system procedures for determining the  best  next view  
1 	perception 
1 vertices imaged in the plane of scene edges 
　apparently the major source of  degenerate views  in the blocb world  see figure 1   so-called coincidental alignments occur when the image of a vertex appears to fall on the image of an edge. they confound the basic imaging assumption that three or more lines coincident in the image are coincident in the scene. if the scene is analyzed using labelling  the labelling will fail. the image is then degenerate because another image is required. in 
	figure 1 	＊ 	in 
classical ''degenerate  view 
theory  such coincidental alignments have probability zero  since the camera must lie on a specific plane  or more precisely  in the infinite intersection of two co-planar half-planes . 
1 parallel scene lines imaged in their o w n plane 
this is one of the degeneracies observed with the cube  see 
figure 1 . it violates the heuristic that colinear in the image implies colinear in the scene  a heuristic often not used. hence  it is system-sensitive. in theory  it also has probability zero  although the camera placement is somewhat more free than in the case of vertex-on-edge. 
1 coincident scene lines imaged in their own plane 
　this is a special case violation of linear in the image implies linear in space. again  this is system dependent and has probability of zero.  figure 1 illustrates one example of this degeneracy while viewing a pyramid.  
1 perfect symmetry 
　this is an interesting extreme case  and one apparently avoided by professional photographers as it appears to flatten relief  we provide a straightforward example of perfect symmetry in figure 1 . it is apparently based on the heuristic that symmetry in the image implies symmetry in the scene perpendicular to the line of sight. analogous to what happens when a cube is imaged as two congruent rectangles  it is often degenerate since perfectly symmetric images lack the cues to depth that broken  skewed  symmetries provide. it has a probability of zero of occurring ideally  although the camera now has the freedom to move in at least one entire plane. 

figure 1 
perfect symmetry  view of a cube  
1 the effect of finite resolution 
　the various viewing points for our camera may be modeled as points on a viewing sphere at whose center lies the object of interest therefore  in the ideal case of the cube with infinite resolution under orthography  or  for that matter  under perspective  there are precisely six viewing directions from which we see exactly one face of the cube and no more. similarly  a family of three mutually orthogonal great circles which intersect at these six points determine the set of directions from which we would see exactly two faces of the cube. anywhere else on the sphere we see three faces  see figure 1 . a point on the sphere chosen at random will be a viewpoint imaging three faces with probability 1. 
　of course  any real system will have only finite resolution. how this resolution is measured  and how repeatable it is  can vary depending on application. for the cube  resolution appears to be the ability to separate two nearly concurrent parallel lines into their separate sources.  under perspective  the parallel lines would only be nearly parallel.  assuming this resoivability of parallels is independent of the line segment lengths  admittedly  this is somewhat unrealistic   then the zero probabilities of degeneracy become finite. on the viewing sphere  the great circles have become bands  and the points of single face viewing have become spherical squares  see figure 1 . their relative areas  and hence the probability of degeneracy  are straightforward to compute in terms of camera acuity. the less accurate the camera  or the farther it is away  or the smaller the object  the larger the likelihood 
that a viewpoint is degenerate. in the extreme  the bands merge  and no viewpoint sees a  characteristic  view: the images are infinitely degenerate. 
　the edges of the bands  however  cannot be sharp. although the bands partition the surface of the viewing sphere  their borders represent those viewing directions at which parallel lines are first  seen as two lines. given camera inaccuracy and noise  this transition to resoivability cannot be sudden. depending on the camera and the accuracy of the algorithms processing its data  repeatability may best be representee! by a fuzzy boundary. thus instead of each point on the sphere having a label  it has a vector of  label  likelihood  pairs. each degeneracy region  then  fades away in likelihood as it extends farther from its ideal point or great circle. the actual computation of the shape of this probability 

figure 1 
cube  at center of the 
  viewing sphere   

cube at center of the viewing sphere  
degeneracies delineated 
density depends on the image heuristic used for image function inversion  as well as some measure of camera and software precision. nevertheless  the relative size of the integral of probability over the partition can give an accurate estimate of the likelihood that a particular view  degenerate or not  will be visible after a random camera placement 
1 comments 
　in a sense these aspect maps are property spheres  where the property is a type of degeneracy. computing them demands substantial computational time and storage  besl and jain 1 ; both would benefit from a hierarchic  trixel-like approach. note that since the sphere it topologicaly equivalent to the extended plane  all such maps can be drawn as planar graphs  werman  baugher  and gualtieri 1 .  see figure 1  where the  standard aspect graph has been augmented to show all possible transitions out of degenerate views  as alluded to in  castore 1  * . 
1 minimal disambiguation distance 
　transitions between the various regions of the sphere represent what  koenderink and van doorn 1  term a  visual event . only such a transition is capable of yielding qualitatively new information. thus these transitions clearly represent a useful change of viewpoint  which would be worth paying for in terms of 
traveling distance. 	  
　for the purposes of minimizing the distance traveled in obtaining further images  it will be useful to quantify the minimal distance we must travel on our viewing sphere  to ensure that we will experience a visual event if we reach a characteristic view from which an image has not yet been obtained  then we will maximize the probability mat any degeneracy will be 
　　# **m particular  we have added  without ton of plannarity  the direct transitions between regions where 1 face it visible  and regions where 1 faces am visible. we noticed that in their excellent survey on 1d object recpgnition.   beil and jaim 1  p. 1  did not show such transitions in their aspect graph of a cube  nor did their analogues appear in the aspect graph of a tetrahedron  presented by koenderink and van doom. for an intersting discussion of the relevance of such transition! to robotic vision  see the remarks of n. badler in  castore 1  
	kender and freudensteln 	1 
　

figure 1 
    planar  aspect graph for cube  including 1-face to 1-face transitions 
disambiguated by the new information. in the case of our viewing sphere of a cube  this would mean ensuring that a 1-faced image is obtained. 
   using the assumptions of orthographic projection  we can easily quantify this minimum distance  for the geometric proof  see  kender and freudenstein 1  . for a fixed viewing-sphere radius of resolution n  i.e. n is an absolute number equal to the number of pixels our object will occupy in the image   the distance we must travel along the viewing sphere is equal to the product of the length of the radius and the arcs in of  1/n  radians. 
　in other words  we can quantify the minimal disambiguation angle as theta  where 

1 relative probabilities for the cube 
　we might  in a given situation  wish to know the probability of reaching a particular class of viewpoint  given a random decision as to  where to go next.  for the case of the cube  we can obtain the probabilities of 1  1  and 1-faced views  by using spherical geometry to calculate the relative surface areas on the viewing sphere of the 1 regions described above and depicted in figure 1  square  rectangular  and triangular patches . 
　an analysis of the cube shows that these probabilities are generally a function of system resolution : systems capable of higher resolution will generally be less likely to yield ''uncharacteristic'' views  as one would expect. 
　our results  the complete derivations of which are presented in  kender and freudenstein 1   are as follows: 

1 closing observations and future research 
　calculating the number of necessary views and the effort to obtain them is a formidable task. in some senses it resembles the design of part feeders  natarajan 1 : that is. given an unknown position on the viewing sphere  determine what series of camera movements would inevitably lead to a distinguished configuration  namely  the acquisition of all relevant semantic information about an object or object assembly. even assuming one knows perfectly where one is on the viewing sphere  the determination of even the distance to the nearest visual event is complex  given its 
1 	perception 
probabilistic nature. circumstances are easy to construct  for example  when the object is too small  where it is actually impossible. 
　the aspect map can be augmented with other information. it can incorporate probabilities such as the likelihood of a given gravity-induced preferred orientation  or it can be convolved with a placement uncertainty spread function. the spread function can be variable  itself incorporating such information as the robotic work space or other constraints on placement motion. a search for the optimal next view could then also minimize camera placement error and also  by related methods  camera placement costs. 
   such algorithms would be particularly valuable if ways exist to formally combine the aspect maps of individual objects to create the aspect map of an object assembly. thus  from a few primitives and a little knowledge of the robotic placer and its workspace  a single representation could direct active sensing. whether or not such a representation is ultimately practical  it has nevertheless been helpful in elucidating the meanings of  general viewing position and ''degenerate view . 
