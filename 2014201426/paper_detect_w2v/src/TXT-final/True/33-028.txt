learning  complex  structural descriptions from examples 
regine loisel  yves kodratoff 
g.r.1 du c.n.r.s.  institut de programmation  tour 	1 
	1 place jussieu 	1 paris cedex 1 france 

summary 
we present a formalization of an intuitively sound strategy for learning a description from examples : within a partition examples are grouped according to greatest resemblances and examples not in the same subset show a maximum of differences. 
i. introduction 
winston  has demonstrated the importance of the near-miss concept in a context of learning descriptions from examples. his methodology is practical 
when a few simple scenes are dealt with. we have extended it to include numerous complex examples. 
　　　the definition of the near miss concept  1  1  w i l l be summarized in section 1. 
　　　a problem arises from the fact that a large number of near-misses can be obtained which do not convey the same type of information. our experience shows that at least three types of near-misses must be introduced : highly ambiguous  ambiguous and discriminant near-misses  each conveying a d i f f e rent type of information. a second problem concerns the building of a structural description when 
several examples of several concepts are given  i.e. there are so many possible descriptions that a choice must be made of the most suitable as a recognition device. this leads us to define  promising  partitions of a set of examples. given a set of examples  the description w i l l be a tree recursively constructed by the rule : divide the set into its most promising partitions. an example of our methodology is given below. this example is actually too simple for the system and must be considered only as an i l l u s t r a t i o n of the definitions we propose. 

each labelled stroke is one element part of the example. 
the f i r s t step consists of defining the reference stroke : e.g  that which is most centrally located  or that which contains other element  or possibly that which is directly above the central stroke. 
this choice is very important as the whole process depends on i t   but an explanation of the reasons underlying the choice is not within the scope of this paper. 
once a reference or  most important  stroke has been chosen  i t s relationships with the other strokes are computed using rules very similar to those usually used in formal descriptions   1   1 . for example  in  man  m the relationship between 1 and 
1 is expressed by : 1 1 -1  meaning that  
a  1 and 1 are tangent  b  1 and 1 are not inside each other  c  1 and 1 have their centers on the same vertical axis  d  1 is directly below 1. here 1 is the f i r s t stroke   1 1 -1  is the relationship between 1 and 1 is the second stroke. the only important point about this description is that it is already a generalization of the description since  for example  relationships between 1 and 1 
w i l l never be looked for. 
we thus obtain a l i s t of sublists which is a description of these three examples  this has to be accepted by the reader  : 

1. near-misses 
given that m1 b1 and tl are considered as reference strokes of the 1 concepts  the definition of a near-miss is : 
if two sublists of two different examples refer to a stroke of the same importance and if the relationships match except for one and only one of their elements  then the conjunction of the two relationships is a near-miss between the two examples. for example  considering the l i s t s of m and t  the sublists  1 1 -1  and  1 1 -1  constitute a near-miss : central  1 1 -1 1 -1   since they both refer to the central stroke and their relationship matches except for one of its 
values. 
let el and e1 be two examples. let r1 a relationship of e1 which constitutes a near-miss with a relationship r1 of e1. 
a near-miss is highly ambiguous when rl also belongs to e1 and r1 also belongs to el. 
for example  central  is highly ambiguous . 

1 

example : av { m j b }

- discrimination power of 	ei relative to 	a : 
s. ei    av. ei + number of examples of a separable from ei/ iai 
example : s   j t t   - 1 
1. relationships between two disjoint sets of examples a and b : 
definitions are those of section 1 except that a l l examples of b must be summed over  for each ei belonging to b. 
1. most promising partition of a set 1. partition of a set a by a near-miss n : n is defined by the relationships rl and r1. let x be the subset of a which contains a l l the examples to which rl or  non-exclusive or  r1 belong. let x' be the subset a-x. 
the partition  x x'  is the partition of 	a 	by 	n. 
1. conclusion 
comments on the intuitive meaning of the most promising partition : while ambiguous and d i s c r i minant near-misses both emphasize differences and resemblances between two examples  their respective proportions of information relative to resemblance vs. information relative to differences are not the same. therefore  ambiguous and discriminant near-
misses do not convey the same type of information. the role of the above defined indexes is to express this difference-resemblance play among examples. this means that our structural description w i l l be built as follows. we f i r s t try to find discriminable sets  and their associated near-misses . when we have several discriminable partitions  we choose among them by minimizing the ambiguity between the two subsets of the partition. if a choice s t i l l remains  we maximize the ambiguity of each of the subsets. the last test simply tells which one has the greatest number of elements verifying the given near-miss. 
this means that we want to keep together examples which are discriminable as long as possible. 

1 

in fact  we describe our work as a formalization of this sound strategy. 
bibliocraphie 
1. t.g. dietterich  r.s. mlchalski learning and generalization of characteristic descriptions : evaluation c r i t e r i a and compara-
tive review of selected methods proc ijcai 1 tokyo 1 pp 1 
1. n.s. fu 
syntactic methods in pattern recognition. academic press  1a  
1. y. kodratoff 
non statistical learning to analyse scenes by the use of the  near-miss  concept. 
proc 1th ijcpr kyoto  1  pp 1 
1. p.h. winston 
learning structural descriptions from examples ph. d. thesis mit 1 . 
note added in proof. 
using a quite different description than the above one  but using the same near-miss definition and our  most promising partition  concept  we very recently built an efficient recognition tree for a very d i f ferent problem  namely the carcinogenic power of big chejnical molecules. 
1 
