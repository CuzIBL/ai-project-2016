predicting the length of solutions to problems 
	j.r. 	quinlan 
basser department of computer science 
	university of sydney  	australia 

introduction 
　　　this papier is concerned with a class of problems whose solutions are in a sense l i n e a r . several formalisms have been used to describe such problems   1   1   1   1   1   1     but the central ideal can be s i m p l i f i e d and summarised as follows 
the universe is a network consisting of a set 
s={s  } of objects connected by a set e of edges. 
a problem is the task of f i n d i n g a path from one 
object s. 	to another object s . . 	a solution con-
1 
s i s t s then of a sequence of objects 
　　　several systems have been developed for di scovering solutions to these problems. they have one feature in common with most algorithms in a r t i f i c i a l i n t e l l i g e n c e   namely: at any stage in the search for a s o l u t i o n   a choice must be made among several possible next actions. this choice is known to be c r u c i a l   for if it is made f e l i c i tously a solution may be found quickly  whereas a great deal of time may otherwise be spent f r u i t l e s s l y . many successful systems incorporate rel a t i v e l y complex mechanisms to make t h i s choice  1 1  but these mechanisms often seem to be bound inexorably each to i t s own system  and thus cannot be transferred to new systems. 
　　　this s i t u a t i o n was relieved by analysis   1   1   i n d i c a t i n g that the a b i l i t y to make a good choice comes down to  in our simple formalism  the a b i l i t y to predict the lengths of solutions to problems before they are solved. this is a p a r t i c u l a r l y useful approach because the length of a s o l u t i o n to a problem does not depend on the way that the s o l u t i o n was found  and so the choice-making function can be divorced from the algorithm proper. i n p a r t i c u l a r i t i s possible 
to study the p r e d i c t i o n task in i s o l a t i o n   so long as the implications of the eventual r e union of a l l the components are borne in mind. 
　　　the following section develops a general p r e d i c t i o n scheme that could be adapted to any system for handling t h i s type of problem. 	this is followed by an examination of i t s performance 
on a substantial number of problems. 
a general scheme 
　　　the underlying structure of the scheme is s t r a i g h t f o r w a r d . suppose we have a set of problems whose solution length is known  and an unsolved problem whose solution length we wish to estimate. the approach taken is to p r e d i c t t h a t the unsolved problem w i l l have the same s o l u t i o n length as the 'most s i m i l a r ' solved problem. to determine the most s i m i l a r solved problem  we w i l l map a l l the problems i n t o points in some space and f i n d the point closest to the unsolved problem. the main part of the scheme is concerned with s e t t i n g up the mapping in such a way that points in the space which are close together do tend to have s i m i l a r solution lengths. note that the converse is not t r u e : we do not require that a l l points with s i m i l a r s o l u t i o n lengths l i e close together. for instance  the points with a given solution length may form several d i s t i n c t clusters throughout the space. 
　　　a few preliminary remarks must be made. a problem may have many solutions of various lengths  so ' t h e ' length w i l l be taken to be the shortest. a l t e r n a t i v e l y a problem may have no s o l u t i o n   in which case we take the length to be a large number. f i n a l l y   while a s o l u t i o n length is c l e a r l y an integer  we w i l l allow an estimate to be a real number such as 1  which may be i n t e r preted as 'closer to 1 than to 1 ' . 
1 
　　　the f i r s t step w i l l be to look at the d i f ferences between a pair of objects. we are a f t e r some means of describing the changes that must be wrought on the f i r s t to make it i d e n t i c a l to the second. clearly t h i s description w i l l depend on the nature of the objects and cannot be defined in general terms. we thus postulate the e x i s t ence of a difference function 

which  given a pair of objects  produces a vector of q non-negative real numbers. section 1 describes two such functions that may serve as i l l u s -
t r a t i o n s . 
　　　now 1 maps a pair of objects i n t o rq  and a problem consists of f i n d i n g a path between a p a i r of objects s  and s .   say. it might seem that alone w i l l s u f f i c e to map problems i n t o a suitable space. however  r e c a l l that we w i l l need to f i n d 
　　　the closest point to an unsolved problem  so we w i l l need to use distance in the space. the 
various components 	of  might measure quite 
d i f f e r e n t things  with the r e s u l t that using alone might render distances in the space meaningless. consider the analogy of mapping people i n t o r 1 by taking t h e i r height in feet and t h e i r weight in pounds. suppose we have two i n d i v i d u a l s who map to  1 1  and  1 1 . a t h i r d individual  1 1  would then be closer to the former than the l a t t e r ! to ensure that distances are meaningful  then  our mapping must have the property that the coordinates of a point are measured in the same u n i t s . 
　　　since the length of a problem's s o l u t i o n w i l l also c l e a r l y depend on the edges e connecting objects  it would seem desirable to bring them i n t o the mapping somehow. now each edge e 
connects two objects s 	and s   say. 	we can form x 	y 
a picture  of the difference between the objects connected by edge e. if we could form such a picture for each edge and average them  the result would be a vector 

where di is the average value of the i t h component of the difference between pairs of objects connected by an edge. i n t u i t i v e l y   d is a picture of the difference created by moving along a ' t y p i c a l * edge. each component of  is non-negative  so d. w i l l be non-negative. moreover  d. w i l l be zero only if the i t h component of the difference between a l l p a i r s of objects connected by edges is zero  in which event the i t h component of the difference function could well be scrapped . but f o r most problems of i n t e r e s t s and e are very large or even i n f i n i t e   so d cannot be computed as above. here we make use of the fact that the scheme is to be embedded in a problem-solving system. it is most u n l i k e l y that a problemsolver would be set up to tackle a single problem in some universe; even if it were  it would solve some subproblems in the course of i t s search for a s o l u t i o n . we can assume  then  that a number of problems with i d e n t i c a l or very s i m i l a r s and e have been solved. the vector d can be approxi-
mated by averaging  not over a l l edges e  
but over those edges used in solutions to the 
previous problems. 
again  a problem is solved when a path is 

then xk. is the kth component of the difference that w i l l arise as we move from s. to s   . aqain  
d is the corresponding component of the d i f f e r ence that arises in moving along a t y p i c a l edge. the r a t i o xk/dk. is then the number of t y p i c a l edges that we would expect to move along in g e t t i n g from s. to s j  . if we form 

then zk is a crude estimate  derived from the k t h component of the difference f u n c t i o n   of the length of the solution to the problem. each component of z is c l e a r l y measured in the same u n i t s   so mapping problems to t h e i r z descriptions in r q 
w i l l r e s u l t in meaningful distances in the space. 
　　　at f i r s t glance  it seems that we have changed the task of p r e d i c t i n g the length of s o l u tions i n t o a c l a s s i c a l pattern recognition problem   1   in which the z's are the d e s c r i p t i o n vectors and the classes are the solution lengths. this unfortunately is not so. since the p i c t u r e of a problem is incomplete  it is quite possible to envisage two problems w i t h the same p i c t u r e 
　　　but d i f f e r e n t solution lengths. secondly  we have 
1 

allowed the p r e d i c t i o n function to take real values so the number of classes would become i n f i n i t e . as a matter of peripheral i n t e r e s t   when the f i r s t set of data from the next section was set up as a pattern recognition problem using a c l u s t e r i n g algorithm   1     the results were poor. 
       s t i l l   the approach taken is a variant of a f a m i l i a r pattern recognition technique. each z is c l e a r l y a point in q-space  so we imagine a set { p . } of prototype points embedded in t h i s space. each prototype p o i n t p. has associated with it a frequency fj. and a class sum c   both of which are integers. as usual we operate in two modes  c l a s s i f y i n g and t r a i n i n g . for c l a s s i f i c a t i o n we are given to description z of a problem; we f i n d the prototype point p. nearest to z and predict the s o l u t i o n length as the r a t i o 
c . / f . . in t r a i n i n g we have a description of a 
problem with known s o l u t i o n length n. if there already exists a prototype point p j that is very 

	  i i   	changing i t s frequency and class sum; 
           f. becomes f +1 and c. becomes c.+n. if no prototype point is very close to z  we enter the l a t t e r as a new prototype point s e t t i n g f . to 1 and c. to n. 
　　　one matter remains to be dealt w i t h . if the p r e d i c t o r is to be useful in practice it cannot be allowed to acquire prototype points without l i m i t . there must be some mechanism for reducing t h e i r number so that the performance of the pred i c t o r is degraded as l i t t l e as possible. this implies that some means of generalizing a subset of the prototype points is required  in the vein of samuel's generalization of checker positions   1   . a simple process is defined that reduces by one the number of prototype points. b a s i c a l l y   it looks for two neighbouring points with s i m i l a r class sum/frequency r a t i o s and r e places them by an average p o i n t . 
　　　we say two prototype points p. and p. are adjacent if the distance between them is less than the distance from e i t h e r to any other proto-

the procedure then consists of examining each p a i r of adjacent points and merging that pair for which the above cost is minimal. each application of the procedure reduces the number of prototype points by one. section 1 reports on the degradat i o n of p r e d i c t i o n performance as the number of prototype points is reduced. 
　　　early in t h i s section we postulated a funct i o n 1 f o r producing a vector description of the changes that would have to be made to one object in order to make it i d e n t i c a l to a second. this function eventually yielded a description z of a problem in q-space. the scheme proceeded under the assumption that two problems w i t h points l y i n g near each other w i l l tend to have s o l u t i o n s of s i m i l a r length. in other words  we required 1 to provide a meaningful description so that t h i s s p a t i a l property comes about. now f o r some problem areas w i t h b u i l t - i n s p a t i a l connotations  such as transportation problems  it is not d i f f i c u l t to formulate such a 1. but what about the rest  the next section examines two universes  one f i n i t e and one i n f i n i t e . in each case it is possible to develop a simple 1 so that the p r e d i c t i o n scheme gives useful r e s u l t s . hopefully these successes indicate a general a p p l i c a b i l i t y 
of the scheme. 
testing the scheme 
1 　　　in the f i r s t universe objects are binary trees  a representation recognized as being both common and general   1     the universe is i n f i n i t e   so objects and edges cannot be stated e x p l i c i t l y . edge information is given by r e w r i t i n g r u l e s   
each of the form  where  are 
objects. the meaning of such a rule is as follows: if s is an object containing an instance of then s. can be r e w r i t t e n as the object s. formed by replacing the instance of  with a corresponding instance of s . for example  consider the object  a+b +c and the rule x+y := y+x. the object is an instance of x+y  and so can be r e w r i t t e n as the corresponding instance of y+x  namely c+ a+b . but a+b is also an instance of x+y  so the o r i g i n a l object could also be r e w r i t t e n by t h i s rule as  b+a +c. an edge connects s. to s j if and only if s. can be r e w r i t t e n as s   . 
since s is i n f i n i t e   each r e w r i t i n g rule normally defines an i n f i n i t e number of edges. 
       two sets of problems were established. the f i r s t  set a  contained 1 problems r e l a t i n g to the manipulation of algebraic expressions i n v o l v ing + and -. the number of r e w r i t i n g rules varied from 1 to 1  s o l u t i o n lengths from 1 to 1. the second  set s  of 1 problems was concerned w i t h establishing the equivalence of programs using a formal language to describe flowcharts   1   . the number of rules ranged from 1 to 1  solution lengths from 1 to 1. sample problems and solutions for sets a and s appear in   1   1   . a number of problems from both sets have been presented to human problem-solvers who found them 
n o n - t r i v i a l . 
　　　a moderate amount of experimentation was needed to f i n d a suitable 1  largely because the early attempts were too s o p h i s t i c a t e d   . it was decided to use only syntactic information  i . e .   to disregard e n t i r e l y the meanings of objects represented as trees. further it was decided to ignore the difference between operators and operands. six operations for manipulating binary trees were formulated  as 
any changes to a binary tree can be described using these operations. the function 1 produces a vector of 1 elements  one f o r each of the 
operations. 	the kth element of 	is 
simply the number of times t h a t the kth operation above was used in changing sj to sj . the uniqueness of the vector was ensured by a number of a r b i t r a r y r e s t r i c t i o n s   such as only using the 
operations  when the move operations by themselves were inadequate. for example  con-
sider the two objects 
is completely independent of the r e w r i t i n g rules available to solve a problem; there is no 
idea of  providing a model of how to get from s to sj. the same  was thus used f o r both sets of problems. the ' t y p i c a l ' edge d i f f e r e n c e d for each problem was computed from the s o l u tions to previous problems in i t s set. 
　　　the second universe was that of the 1puzzle. an object consists of a 1 arrangement of t i l e s bearing the d i g i t s 1 to 1 and a blank t i l e . an edge exists between two objects if the second arises from the f i r s t by interchanging the blank t i l e with one of i t s neighbours. in t h i s problem domain both s and e are f i n i t e   though large  s contains about 1 o b j e c t s   . 


1 

　　　the basic measure of the p r e d i c t o r ' s performance on a problem was taken to be the absolute e r r o r   i . e .   the magnitude of the difference between the actual and predicted s o l u t i o n lengths.  this follows the approach to errors in h e u r i s t i c functions in   1   .   for a set of problems the performance measure was the average absolute e r r o r on the s e t . the p r e d i c t o r could be considered useful in so far as it o u t s t r i p s the obvious random procedure of selecting an a r b i t r a r y length from those a c t u a l l y occurring in the set. this random procedure has an expected average absolute 
e r r o r 	of 
1 on set a  selecting a length from 1 to 1  
1 on set s   d i t t o from 1 to 1  
1 on set p   d i t t o from 1 to 1 . 
       the f i r s t experiment was designed to t e s t the scheme in an environment s i m i l a r to that which would be encountered in p r a c t i c e . each set was f i r s t shuffled so that the o r i g i n a l order of the problems would have no bearing on the outcome. each problem in a set was f i r s t tested  the absolute error found  and then the problem used to t r a i n the system. each problem was thus tested with the p r e d i c t o r having the benefit only of experience from previous problems in the s e t . 
three average absolute errors were computed: for the f i r s t 1 of the problems  f o r the l a s t 1  and f o r the whole s e t . this experiment was performed with 1 d i f f e r e n t shuffles of each set. 
　　　the r e s u l t s obtained appear in table 1. this shows that the performance on the whole set was b e t t e r than the random procedure in a l l cases  but p a r t i c u l a r l y so f o r sets a and p. there is also a clear improvement on the l a s t 1 in a l l sets. considering the numbers of problems and s h u f f l e s   t h i s improvement can only be ascribed to the experience obtained on previous   d i f f e r e n t   
problems. 
	table 	i 
a l t e r n a t i n g test and t r a i n : average absolute errors on 1 shuffles and mean. the values shown for each set are for the f i r s t two-thirds of the problems  the l a s t t h i r d   and the whole set. 
　　　the second experiment was drawn up to i n v e s t i gate the p r e d i c t o r ' s performance on the sets of problems a f t e r t r a i n i n g   and to see how it was affected by reduction of the number of prototype p o i n t s . the prototype points developed in the f i r s t experiment were retained and each problem again presented f o r c l a s s i f i c a t i o n . the number of prototype points was then reduced by repeated merging and each problem again fed to the p r e d i c t o r . this reduction process was performed 
several times. 
       the r e s u l t s appear in table i i . it is c l e a r   f i r s t o f a l l   that the p r e d i c t o r i s doing very w e l l with i t s f u l l complement o f prototype p o i n t s . secondly  it is possible to merge quite a large number of prototype points before the performance of the p r e d i c t o r is seriously degraded; even 
1 

allowing only 1  the p r e d i c t o r s t i l l does passably. this suggests that the scheme should s t i l l be useful if a r e s t r i c t e d amount of space was a v a i l a b l e to hold prototype p o i n t s . 

　　　on the basis of i t s performance on the sets of problems in the previous s e c t i o n   it seems f a i r to say that the scheme gives useful r e s u l t s   even with an unsophisticated 1 f u n c t i o n . it is being included as part of a problem-solver in the process of development. s t i l l   many improvements are possible. 
　　　in section 1 we went to some lengths to ensure that the various components of the z descript i o n of a problem were measured in the same units. as a r e s u l t   distances were equivalent in a l l dimensions of the problem description space. t h s does not allow f o r the p o s s i b i l i t y that small changes in one component could be more s i g n i f i c a n t than large changes in another. a more f l e x i b l e d e f i n i t i o n would allow distances in d i f f e r e n t dimensions to be weighted d i f f e r e n t l y . experiments have been conducted along these lines using s t a t i s t i c s such as the variance of d. from problem to problem in a set. the r e s u l t was a small but noticeable improvement. 
　　　certain aspects of the scheme may not be appropriate if the number of t r a i n i n g points were to run i n t o the thousands. 	in p a r t i c u l a r . it may be desirable to impose some s o r t of ageing process on prototype points and on the solutions used to give a p i c t u r e of the ' t y p i c a l ' edge. these measures would be designed to make the system more responsive to i t s recent h i s t o r y rather than i t s t o t a l h i s t o r y in some problem 
domain. 
       f i n a l l y   	there s t i l l remains the nuisance of designing an appropriate 	. 	this may not be as annoying as it appears. 	for the universe of binary trees we used only s t r u c t u r a l information on o b j e c t s   so the same 1 was appropriate f o r two quite d i f f e r e n t problem domains. 	a r e l a t i v e l y small number of structures is used to represent objects in a r t i f i c i a l i n t e l l i g e n c e   so a few 1's may s u f f i c e to handle a large number of problem domains. 	the ideal system  of course  would specify a loose framework f o r 1 and allow the function i t s e l f to be induced from experience  along the lines of a feature e x t r a c t i o n exercise. i n t r i g u i n g as t h i s sounds  it may turn out to be 
pinning one's hopes on a deus ex machina. 
