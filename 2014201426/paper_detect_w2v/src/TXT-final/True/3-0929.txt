
the paper reports on new algorithms for solving partially observable games. whereas existing algorithms apply and-or search to a tree of blackbox belief states  our  incremental  versions treat uncertainty as a new search dimension  examining the physical states within a belief state to construct solution trees incrementally. on a newly created database of checkmate problems for kriegspiel  a partially observable form of chess   incrementalization yields speedups of two or more orders of magnitude on hard instances.
1 introduction
 classical  games  such as chess and backgammon  are fully observable. partially observable games  despite their greater similarity to the real world  have received less attention in ai. the overall computational task in such games can be divided conceptually into two parts. first  state estimation is the process of generating and updating the belief state-a representation of the possible states of the world  given the observations to date. second  move selection is the process of choosing a move given the belief state.
　partially observable games are intrinsically more complicated than their fully observable counterparts. at any given point  the set of logically possible states may be very large  rendering both state estimation and move selection intractable. furthermore  move selection must consider one's own information state  gathering information is helpful  and the opponent's information state  revealing information is harmful . finally  game-theoretically optimal strategies are randomized because restricting oneself to deterministic strategies provides additional information to the opponent. the paper by koller and pfeffer  provides an excellent introduction to these issues.
　in this paper  we focus on a particular subproblem: deciding whether a guaranteed win exists-i.e.  a strategy that guarantees the optimal payoff within some finite depth  regardless of the true state  for any play by the opponent. this is simpler than the general problem  for two reasons. first  the state estimate need represent only the logically possible states  without considering their probabilities. second  we have the following:
theorem 1 a guaranteed win exists from some initial belief state iff it exists against an opponent with full observation.
　this follows from the fact that an opponent  by simply choosing moves at random  has a nonzero probability of duplicating any finite behavior of an optimal opponent with full observation. thus  the logical possibility that the solver can guarantee a win within some bounded depth depends only upon the solver's own information about the true state. this implies that neither the opponent's information state nor randomized strategies need be considered. we will see shortly that the theorem does not apply to certain other strategies  which win with probability 1 but are not guaranteed.
　despite these restrictions  the problem is quite general. indeed  it is isomorphic to that of finding guaranteed plans in nondeterministic  partially observable environments. our particular focus in this paper is on kriegspiel  a variant of chess in which the opponent's pieces are completely invisible. as the game progresses  partial information is supplied by a referee who has access to both players' positions. the players  white1 and black  both hear every referee announcement. there is no universally accepted set of rules; we adopt the following:
  white may propose to the referee any move that would be a legal chess move on a board containing just white's pieces; white may also propose any pawn capture.
  if the proposed move is illegal on the board containing both white and black pieces  the referee announces  illegal. 1 white may then try another move.
  if the move is legal  it is made. announcements are:
- if a piece is captured on square x:  capture on x.  - if black is now in check:  check by d   where d is one or two of the following directions  from the perspective of black's king : knight  rank  file  long diagonal  and short diagonal.
- if black has no legal moves:  checkmate  if black is in check and  stalemate  otherwise.
  finally:  black to move. 
 examples of play are given in section 1. in addition  more details are available online at our kriegspiel website  www.cs.berkeley.edu/ jawolfe/kriegspiel/. 
　one important aspect of kriegspiel and many other partially observable games and planning domains is the  tryuntil-feasible  property-a player may attempt any number of actions until a legal one is found. because the order of attempts matters  a move choice is actually a plan to try a given sequence of potentially legal moves. hence  the branching factor per actual move is the number of such sequences  which can be superexponential in the number of potentially legal moves. we will see that try-until-feasible domains admit certain simplifications that mitigate this branching factor.
　kriegspiel is very challenging for humans. even for experts   announced  checkmates are extremely rare except for so-called material wins-such as kqr-vs.-k-when one side is reduced to just a king and the other has sufficient  safe  material to force a win. checkmate is usually  accidental  in the sense that one player mates the other without knowing it in advance.
　several research groups have studied the kriegspiel checkmate problem. ferguson  exhibited a randomized strategy for the kbn-vs.-k endgame that wins with probability 1; the lone black king can escape checkmate only by guessing white's moves correctly infinitely often. subsequently   he derived a strategy for the kbb-vs.-k endgame that wins with probability 1   for any   1. in our terminology  these mates are not guaranteed  and they do not work if the opponent can see the board. additional materialwin strategies  all deterministic  have been developed  ciancarini et al.  1; bolognesi and ciancarini  1; 1 .
　as we explain in section 1  algorithms for finding a checkmate in kriegspiel involve searching an and-or tree whose nodes correspond to belief states. this idea is common enough in the ai literature on partially observable planning search  see  for example  chapters 1 and 1 of  russell and norvig  1  . it was proposed for kriegspiel  and applied to the analogous partially observable variant of shogi  japanese chess   by sakuta and iida; results for several search algorithms are summarized in sakuta's phd thesis . bolognesi and ciancarini  add heuristic measures of  progress  to guide the tree search  but consider only positions in which the opponent has a lone king. in all of these papers  the initial belief state is determined externally.
　the search algorithm developed by ginsberg  for  partially observable  bridge play works by sampling the initial complete deal and then solving each deal as a fully observable game. this approach gives a substantial speedup over solving the true game tree  but never acts to gather or hide information  which is essential for domains such as kriegspiel . the only previous kriegspiel-playing agent we know of  developed by parker et al.   uses this approach. it keeps track of a sample of its true belief state  and at each point selects the move that would be best if the remainder of the game were played as fully observable chess.
　solving kriegspiel is an instance of nondeterministic partially observable planning  and could therefore be carried out by symbolic techniques such as the ordered binary decision diagram  obdd  methods developed by bertoli et al.  or by quantified boolean formulae  qbf  solvers. unfortunately  the computational penalty for generating chess moves by symbolic inference methods appears to be around four orders of magnitude  selman  personal communication .
　this paper's contributions are as follows. section 1 addresses the problem of state estimation; for the purposes of this paper  we focus on exact estimation using straightforward methods. section 1 describes a simple but complete kriegspiel player  combining both state estimation and move selection  and explains how self-play was used to generate the first database of kriegspiel checkmate problems with observation histories.
　section 1 develops the basic and-or tree structure for solving kriegspiel-like games  allowing for possibly-illegal moves. section 1 defines two baseline algorithms-versions of depth-first search  dfs  and proof-number search  pns - for solving such trees  and then presents some basic improvements for these algorithms and analyzes their performance on our checkmate database.
　section 1 develops a new family of incremental search algorithms that treat uncertainty as a new search dimension in addition to depth and breadth  incrementally proving belief states by adding a single constituent  physical state  to a solution at each step. this leads to a further speedup of one or more orders of magnitude. finally  section 1 shows how state estimation and incremental checkmate search may be interleaved.
1 state estimation
if we are to find a guaranteed win for white  state estimation must identify the  logical  belief state-the set of all physical states  configurations for white and black pieces  that are consistent with white's history of moves and observations. a naive algorithm for exact state estimation looks like this:
  the initial belief state is a singleton  because black's pieces start the game in their normal positions.
  for each white move attempt  apply the move to every physical state and remove those states that are inconsistent with the subsequent percept.
  for each black turn 
- for each sequence of k  illegal  percepts for the unobserved black move attempts  remove any physical state for which there are fewer than k distinct illegal moves.
- replace each remaining physical state by the set of updated states corresponding to all black moves that are legal and yield the given percept when made in that state.
- remove duplicate states using a transposition table.
　in kriegspiel  the belief state can grow very large-1 states or more-so this algorithm is not always practical. we have found  however  that with certain aggressive styles of play  the belief state remains no larger than a few thousand states throughout the game.
　the naive algorithm given above can be viewed as a breadth-first expansion of a physical-state tree with branching at black's moves and pruning by percepts. an alternative method  which we adopt  performs a depth-first search of the tree instead. this has the advantage of generating a stream of consistent current states with only a moderate amount of effort per state. furthermore  if the set of states found so far does not admit a checkmate  then the whole belief state does not admit a checkmate and both state estimation and move selection can be terminated early  see section 1 .
　a randomized depth-first search can generate a randomly selected sample of consistent states that can be used for approximate decision making. we explore approximate state estimation in a subsequent paper; for now  we assume that the exact belief state is available to the checkmate algorithm.
1 a kriegspiel checkmate database
in order to evaluate checkmate-finding algorithms for kriegspiel  we require a database of test positions. prior to this work  no such database existed.1 our first database consists of white's move and percept histories for 1 kriegspiel games  up to the point where a 1-ply checkmate might exist for white.1 of these are actual mate instances; the other 1 are near-miss instances  which  almost  admit a guaranteed checkmate within 1 ply. for each near-miss instance  there is a checkmate plan that works in at least half of the possible physical states  but not in all of them.
　this database was created by analyzing games between two different kriegspiel programs. the first program  playing white  performs exact state estimation and makes a complex static approximation to 1-ply lookahead; it plays well but can be defeated easily by a skilled human.1 the second program  playing black  is much weaker: it computes a limited subset of its true belief state and attempts moves that are most likely to be captures and checks first. whenever white's belief state has 1 black positions or fewer  we determine if the belief state describes a mate or near-miss instance. if so  the move and percept history for the game-in-progress is saved. games in which white's belief state grows above 1 positions are excluded. with these two programs  white's belief state generally remains fairly small  and about half the games played result in problem instances.1
　obviously  the checkmate problems we generate by this method have belief states that never exceed 1 physical states throughout the move history and have at most 1 physical states in the final position  the average is 1 . furthermore  the solution is at most 1-ply  but may include branches with illegal move attempts in addition to 1 actual moves.
　by simply re-analyzing our 1-ply near-miss problems at 1ply  we have also constructed a more difficult database of 1-ply mate instances and 1-ply near-miss instances. both databases are available at our website  url in section 1 .
　as better state estimation  search  and evaluation methods are developed  it will be possible to construct more difficult problems that better reflect the kinds of positions reached in expert play. nonetheless  our problems are far from trivial; for example  we will see that on 1% of the 1-ply near-miss instances  basic depth-first search requires more than 1
cpu seconds to determine that no mate exists  within 1 ply .
1 guaranteed kriegspiel checkmates
thanks to theorem 1  our search problem involves a tree whose nodes correspond to white's belief states. figure 1 shows a simple example: a miniature  1  1-ply kriegspiel checkmate. in the root belief-state node  1  there are three

figure 1: a minimal and-or proof tree for a 1 kriegspiel 1ply checkmate problem. the grayed moves in the black-to-move section are hidden from white.
possible physical states  which differ in the locations and types of black's pieces  white will always know the number of remaining black pieces . the figure depicts a minimal proof tree for the problem instance  with other possible moves by white omitted; it describes the following strategy:
1. white attempts move qa1 from belief state 1. if the right-most state  1.c  is the true state  white wins.
1. otherwise  qa1 was illegal and white now attemptsmove qa1 from belief state 1.
 a  if the subsequent percept is  capture on a1   black
has two legal moves: nb1 and nc1.
i. if black makes nb1  the referee announces capture on b1  and white mates with qb1.
ii. if black makes nc1  the referee announces knight check  and white mates with qc1.
 b  if the subsequent percept is  capture on a1 & short diagonal  check   black has only one legal move: kc1. white mates with qb1.
in general  belief-state and-or trees consist of three types of nodes:
  or-nodes: in figure 1  or-nodes appear in the white
to move sections  e.g.  nodes 1  1  1 . an or-node represents a choice between possible moves for white  and is proven iff at least one of its children is proven. its children are and-nodes  each containing the results of applying a single move in every possible physical state.
  expand-nodes: expand-nodes appear in the black to move sections  representing black's moves  e.g.  nodes 1  1 . since black's moves are invisible to white  each expand-node has only a single child  an andnode containing the union  eliminating duplicates  of the legal successors of its possible physical states. an expand-node is proven iff its only child is proven.
  and-nodes: and-nodes are the thin nodes that appear at every other level in the tree  e.g.  nodes 1  1  1 . physical states within and-nodes are abbreviated as circles. an and-node represents the arrival of a percept from the referee  and can be terminal or non-terminal:
- if every physical state in an and-node is a terminal win for white  the node is terminal with value true. if any physical state is a terminal draw or loss for white  the node is terminal with value false.
- otherwise  the and-node is nonterminal  and has children that form a partition of its nonterminal physical states  percepts do not change the underlying physical states-see  e.g.  nodes 1 and 1 .
thus  an and-node is proven iff all of its belief-statetree children and its terminal physical states are proven.
　in kriegspiel  the referee makes an announcement after each move attempt. thus  kriegspiel belief-state trees have and-nodes at every other level. the intervening nodes alternate between expand-nodes  black moves  and sequences of or-nodes  white move attempts .1 because one turn for white may involve several move attempts  white's entire turn has a worst-case branching factor equal to the factorial of the number of possible moves.
1 searching belief-state and-or trees
this section describes two common algorithms-depth-first search and proof-number search-for searching belief-state and-or trees. like other existing algorithms  both solve a belief-state tree as an ordinary and-or tree with blackbox belief-state nodes. after introducing the algorithms  we evaluate their performance on our 1-ply checkmate database  with and without some basic improvements.
1 dfs and pns
the pseudocode for dfs  depth-first search  is shown in figure 1 dfs operates using the expand method  which constructs and evaluates the children of a belief-state node  as described in section 1 ; as an example  figure 1 shows
expand's or-node instance. to use dfs  we simply initialize an or-node with the root belief state and remaining depth  and pass it to solve-top. in figure 1  the numbers beside the nodes indicate an order in which dfs might expand them when searching the tree.
function solve-top b  returns true or false inputs: b  a belief-state node
expand b  return solve b 

method solve b an or-node  returns true or false while children b  is not empty do if solve-top first children b    then return true pop children b   return false

method solve b an expand-node  returns true or false return solve-top child b  

method solve b an and-node  returns true or false if terminal b  then return value b  while children b  is not empty do if not solve-top first children b    then return false pop children b   return truefigure 1: the dfs algorithm.
method expand b an or-node  for each m in moves first states b    do b＞ ○ a new and-node with terminal b＞ = false 
value b＞ = true  depth b＞ = depth b  
children b＞ = an empty list  and
　　　states b＞ = map successor * m  states b   for each s in states b＞  do if s is a win for white then remove s from states b＞  else if s is terminal or depth b = 1 then b＞ ○false; break
if b＞ =1 false then
push b＞ children b   if states b＞  is empty then
terminal b＞ ○true; breakfigure 1: the or-node instance of the expand method  which constructs and evaluates the children of b.
　pns  proof-number search  is a best-first search algorithm for and-or trees  and is commonly believed to be superior to dfs. at each step pns expands a  most-proving  node  which can make the largest contribution to proving or disproving the entire tree. a most-proving node is defined as any node that is a member of both a minimal proof set and a minimal disproof set of the tree  where a minimal proof/disproof set is a minimal-cardinality set of unexpanded nodes that  if proved/disproved  would be sufficient to prove/disprove the root. every tree has at least one most-proving node; if there are multiple most-proving nodes  the pns algorithm chooses one arbitrarily  allis  1 .1
1 analysis and improvements
figure 1 shows the solving ability of our search algorithms on the 1 problems in our 1-ply database  for readability  we show only a subset of the algorithms tested . we will

figure 1: performance of search algorithms on our 1-ply kriegspiel checkmate database. top: mate instances; bottom: near-miss instances. the y-axes show the fraction of problems solvable within a given amount of cpu time  in lisp  on a 1 mhz machine . the algorithms are ranked in decreasing order of efficiency.
introduce the dbu  dub  and ipns algorithms later  in section 1. performance on our 1-ply database  not shown  is qualitatively similar  but does not allow for accurate discrimination between our improved algorithms.
　basic dfs is by far the slowest of the algorithms tested  primarily because of the factorial branching factor for white  which subsequent algorithms avoid  to a large extent ; basic pns is much faster. notice that the near-miss instances are generally more difficult to solve than the mate instances.
heuristic ordering
when searching a belief-state and-or tree using a blackbox algorithm such as dfs  there are two possible opportunities for heuristic ordering: white moves at or-nodes  and percepts at and-nodes. in this paper we focus on the underlying search algorithms; we do not investigate heuristic orderings for the white moves  and test only a simple but effective ordering for the percepts.
　at and-nodes  the legal children  children in which the last move was legal  are generally much cheaper for dfs to explore than the illegal child  since they have lower remaining depth. this suggests a simple heuristic: investigate the legal children first. as shown in figure 1  l-dfs  legal-first dfs  is considerably faster than dfs. on the other hand  lpns  not shown  performs almost identically to pns  which naturally allocates its efforts efficiently .
　future work may investigate the effects of ordering the white moves  e.g.  information-gathering and likely checking moves first  and the legal percepts  e.g.  checks and captures first for black and last for white .
pruning
because a proof of guaranteed checkmate is a single branching plan that must succeed in every physical state of a belief state  we can make the following observation:
theorem 1 if a belief state does not admit a guaranteed checkmate  no superset of that belief state admits a guaranteed checkmate.
　a straightforward implementation of the expand method  e.g.  figure 1  constructs all elements of a belief state before evaluating any of them. theorem 1 suggests a more efficient strategy: evaluate each physical state as soon as it is constructed. if a terminal physical state with value false  or a nonterminal physical state at the depth limit  is found  the construction of the belief state can be halted early. in the best case  this reduces the effective search depth by one level  since only a single element of each belief state at the depth limit will be constructed . as shown in figure 1  indicated by e- for  early termination    this simple idea is the most effective of the improvements we consider in this section.
　theorem 1 also suggests another pruning  which is specific to try-until-feasible trees. consider the situation in which white is in belief state b  attempts a possibly-legal move  and is told that the move is illegal. white's new belief state b＞   b. theorem 1 implies that if b＞ does not admit a guaranteed checkmate  then neither does b. in other words  when the illegal child of an and-node is disproved  this is sufficient to disprove the and-node's parent or-node as well. for example  if node 1 in figure 1 were disproved  that would show not only that trying qa1 first fails to ensure checkmate  but also that no other white move from node 1 gives checkmate. clearly  this is a useful pruning rule.
　we call this pruning greedy  since when combined with the legal-first heuristic it allows white's turns to be solved without backtracking  by adding moves to the plan iff they lead to checkmate when legal. because a move plan cannot include repetitions  a greedy algorithm such as gl-dfs  greedy legal-first dfs  has a worst-case branching factor per white's turn that is only quadratic in the number of possible moves. however  figure 1 shows that gl-dfs only slightly outperforms l-dfs. this is because the pruning only applies when there are moves that lead to checkmate if legal but not if illegal.
　perhaps surprisingly  our experiments show that a g-dfs algorithm performs better when it tries the illegal child first instead  even though the resulting algorithm is not actually greedy ; this algorithm  shown as gx-dfs in figure 1  outperforms even pns. the power of gx-dfs stems from its ability to test a subset of its belief state using possibly-legal moves  and terminate early if it disproves the subset.
　we did not implement a  g-pns  algorithm  because the greedy pruning could force pns to choose between the goals of proving and disproving the root  it always does both simultaneously . future work may explore this issue further.

figure 1: left: a simple belief-state tree for a planning domain with nondeterministic transitions. a  b  and e are moves; c and d are percepts. right: for each incremental algorithm  the order in which it would expand the nonterminal physical states in the tree.
1 incremental belief-state and-or search
as we saw in the previous section  early termination via interleaved belief-state construction and evaluation can lead to large improvements in performance. this section develops this incremental idea into a novel framework for beliefstate and-or tree search  which treats uncertainty as a new search dimension in addition to depth and breadth. after introducing this framework  we present results and theoretical analysis for our new algorithms.
1 introduction
ordinary and-or trees have two dimensions: depth and breadth. this leads to two  directional  search algorithms  depth- and breadth-first search  as well as numerous  bestfirst  algorithms  e.g.  pns . in addition to depth and breadth  belief-state and-or trees have uncertainty over physical states. by recognizing uncertainty as a new possible dimension for search  we can construct a new class of directional belief-state and-or search algorithms  as well as new bestfirst algorithms that balance all three factors efficiently.
　in this paper  of the possible incremental directional algorithms  we consider only the three that put depth before breadth  which we will call udb  dbu  and dub. figure 1 shows a simple belief-state tree for a domain with nondeterministic transitions  as well as the order that each of these algorithms would expand the physical states in the tree. the first algorithm  udb  uncertainty-then-depth-then-breadth   is in fact just the e-dfs algorithm discussed in section 1. in the figure  the difference between udb and the other new algorithms should be immediately apparent; whereas udb expands all physical states at a node before moving to the next node  the other algorithms begin by exploring the first physical-state tree in a depth-first manner. thus  unlike existing algorithms  dbu and dub can construct minimal disproofs that consider only a single element of each belief state. in the tree  the difference between dbu and dub first arises when selecting the seventh node for expansion. after establishing a proof on a single physical-state branch  i.e.  non-branching path from the root to a leaf   dbu gives precedence to verifying the proof on the current physical-state tree  whereas dub gives precedence to verifying it on the current belief-state branch. thus  all three algorithms con-
function solve-top b  returns true or false inputs: b  a belief-state node
while states b  is not empty do
incremental-expand b pop states b    if not solve b  then return false
return true

method solve b an and-node  returns true or false if terminal b  then return value b  return   b＞ （ children b   solve-top b＞ figure 1: the dbu algorithm  which builds upon dfs .
struct proofs by  looking inside  the belief state; they differ in that udb incrementally constructs belief-state nodes  whereas dub incrementally constructs branches and dbu incrementally constructs entire proof trees.
　at each point  dbu expands the deepest unexpanded physical state within the current proof tree. dub does the same  except limited to a single belief-state branch at a time. thus  in a pure or-tree with no percept branching  dub and dbu act identically. this brings us to an important point: the breadth that our b refers to is only the breadth of a proof  the and-branching  percepts .
　whereas the algorithms differ significantly with respect to establishing disproofs  when exploring a proof tree such as the right branch of figure 1  all three algorithms expand the same physical states  just in a different order. since udb and dub both put breadth last  they explore the same sequence of belief-state branches  with different orderings for physical states within each branch. likewise  dub and dbu explore the same first physical-state branch.
　in addition to these directional algorithms  we have implemented a best-first ipns  incremental pns  algorithm that operates on a single physical state at a time. this algorithm uses the above tree model  allowing and-nodes to store unexpanded physical states. by simply redefining a mostproving node as a physical state that  if expanded  could contribute most to the proof/disproof of the entire tree  the proofnumber idea naturally generalizes over uncertainty as well as depth and breadth. among other things  this allows ipns to naturally consider the relative ease of proving and disproving its belief-state nodes based on their sizes  an ability which other researchers have attempted to artificially introduce into a pns-type algorithm  sakuta  1 .
1 implementations
our implementation of dbu  shown in figure 1  uses a new
incremental-expand method that expands a single physical state rather than an entire belief state at a time  its ornode instance is shown in figure 1  for comparison with figure 1 . when dbu's solve-top encounters uncertainty  it first constructs a proof for a single state  and then extends the proof to cover additional states one-at-a-time. to support such incremental proofs  dfs's solve instance for andnodes must also be modified to save proved children  rather than popping them; this allows dbu to continually refine a single proof tree that works in all physical states examined so far.
　our implementation of dub uses two sets of recursive methods. the inner recursion is exactly that of dbu  ex-
function outer-top b  returns true or false inputs: b  a belief-state node return  solve-top b  and outer b  

method outer b an or-node  returns true or false loop do if outer first children b    then return true pop children b  
if not solve b  then return false

method outer b an expand-node  returns true or false return outer child b  

method outer b an and-node  returns true or false if terminal b  then return value b  loop do if not outer first children b    then return false pop children b   /* percept branching here */
if children b  is empty then return true if not solve b  then return falsemethod solve b an and-node  returns true or false if terminal b  then return value b 
return solve-top first children b    /* not here */figure 1: the dub algorithm  which builds upon dbu 
method incremental-expand b an or-node  s a state  if children b  is empty then /* create b's children */ for each m in moves s  do b＞ ○ a new and-node with terminal b＞ = true 
           value b＞ = true  depth b＞ = depth b   children b＞ = an empty list  move b＞ = m  and states b＞ = an empty list push b＞ children b   for each b＞ in children b  do /* integrate s's children */
	＞	＞
s ○ successor s move b    if s＞ is terminal or depth b = 1 then if s＞ is not terminal or s＞ is not a win for white then remove b＞ from children b 
else push s＞ states b＞  ; terminal b＞ ○falsefigure 1: the or-node instance of the incremental-expand method  which constructs and evaluates the children of s  integrating them into the children of b  which are also constructed if necessary .
cept that the solve method for and-nodes is modified to test only the first percept encountered  rather than all possible percepts ; one might call this modified recursion simply du. it either returns false  indicating a certain disproof  or true  representing a partial proof of a single belief-state-tree branch. the outer recursion  consisting of outer-top and outer  uses the inner recursion to construct a partial proof and then verify this proof on other percepts  deepest-first .
　when implementing dub or dbu in a try-until-feasible domain  a new issue arises: potential white moves that are always illegal are useless  but inflate the branching factor substantially; thus  it is crucial to avoid them during search. this is trivial for an uncertainty-first algorithm  since alwaysillegal moves can be filtered out during move generation. however  an incremental algorithm cannot use this method  because in general only a single physical state will be available when constructing a belief-state node. to avoid the large penalty associated with always-illegal moves  our actual implementations of dub and dbu use the legal-first heuristic and skip the move in question  saving it for a later attempt  if it is not legal in any states examined so far.
　with incremental search  there are also new opportunities for heuristic orderings that we have not yet investigated. for one  the physical states within a belief state can be ordered  e.g.  best for black first . one might also consider dynamic move orderings  using physical-state and/or belief-state transposition tables to cache proving moves; this could be especially effective in combination with iterative deepening.
1 results
in figure 1  we see that the directional incremental algorithms have significantly higher solving ability than their nonincremental counterparts. the true depth-first algorithms  ldub and l-dbu  perform at a similar level  outpacing ludb  le-dfs  by a large margin. again  greedy pruning has a small but significant effect: gl-dbu has the highest solving ability of the algorithms tested  solving 1 of 1-ply problems within the 1-second time limit.1
　in the figure  we see that ipns is by far the most effective of our algorithms in solving the mate instances  but falls behind the true depth-first algorithms on the near-miss instances. this discrepancy can be explained by the depth limit  which strongly violates a basic assumption of ipns: that the expected amount of work to disprove a physical state is constant throughout the tree. thus  we expect that the discrepancy would disappear after adapting ipns to the depth limit  or when searching without one.
1 analysis
in this section  we conduct a brief analysis of the time and space complexity of our new algorithms. no directional algorithm is best in general; for specific classes of belief-state trees  however  clear differences do arise between the algorithms. in the following analysis  we focus on disproofs  since the algorithms generate the same trees for proofs   and ignore illegal moves and transpositions.
　recall that in any tree with all terminal leaves at the depth limit  dfs dominates bfs in the sense that for every fixed branch ordering  the set of nodes expanded by dfs will be a subset of the set of nodes expanded by bfs. we can make an analogous claim comparing the operation of dub and udb:
theorem 1 in a tree with all false leaves at the depth limit  for any fixed branch ordering  the set of physical states expanded by dub will be a subset of the set of physical states expanded by udb.
　in this class of trees  udb and dub visit the same set of belief-state nodes with the same order of first visit. however  dub does depth-first rather than uncertainty-first searches of each belief-state-tree branch  allowing it to find the false leaves faster. theorem 1 nearly holds for our problem database  because shallow false leaves arise only from stalemates and black checkmates  which are relatively rare in the positions we create.
　using a simple tree model  we can also approximate the best-case speedup and worst-case memory requirements for our new algorithms. consider a belief-state tree rooted at an or-node of size u1  with depth d and fixed branching factors mw  mb  pw  and pb for the white and black moves and percepts. in this tree  examine an arbitrary expand-node 1ply from the depth limit with size u＞  and define u=u＞  mb. if the belief-state tree has no terminal nodes  then the following table shows how many physical states each directional algorithm must construct to disprove the expand-node  not including elements of the expand-node itself :
dub & dbu1+mw　since a majority of the tree's physical states will be located within 1-ply of the depth limit  we can approximate the overall performance of our search algorithms by the number of physical states they construct within its deepest 1-ply. furthermore  because all four algorithms visit the same set of belief-state nodes in trees without terminal nodes  by setting u＞ to the average belief-state size of visited expand-nodes 1-ply from the depth limit  we can interpret the values in the above table as approximately proportional to run times. thus  in the best case  dub and dbu are faster by roughly a factor of the average belief-state size in the tree. this is consistent with our observed speedup: in our 1-ply database  the average value of u  as defined above  is approximately 1.
　under the above tree model  with the additional stipulation that physical states be evenly distributed among percepts  the worst-case asymptotic memory requirements for efficient implementations of the algorithms are as follows:
dfs  udb  & dub　udb and dub store only a proving branch plus physical states for other possible percepts  whereas dbu must store a proof tree and ipns must store the entire belief-state tree. because of ipns's large memory requirements  one might attempt to construct a depth-first variant of the algorithm  analogous to recent work on ordinary pns  sakuta  1 .
1 interleaved state estimation and search
the depth-first method for state estimation described in section 1 can be interleaved with the dbu checkmate-finding algorithm described in section 1. as each new state is found by the state estimation algorithm  it is integrated into the current proof tree. this process continues until a disproof is found  early termination  or the entire belief state has been proven.
　computation times for  interleaved  vs.  sequential  methods  using gl-dbu  applied to each 1-ply database instance are shown in figure 1. as expected  interleaving can provide substantial time savings on near-miss instances by eliminating the need for full state estimation  but has no effect on the solving of mate instances.
1 conclusions and further work
we have proposed a new family of statewise-incremental solvers for belief-state and-or trees  and have shown them

figure 1: results for interleaved state estimation and search.
to yield large performance improvements on a database of kriegspiel checkmate problems. future work will enhance our complete kriegspiel player with belief-state transposition tables  as explored by sakuta   and improved methods for approximate state estimation and nonterminal evaluation  as well as evaluate further applications of incremental beliefstate search. in particular  we plan to investigate dynamic move orderings and iterative deepening  further analyze the combination of incremental search and approximate state estimation  and apply incremental search to existing methods for general play. one might also consider incrementalization of partially observable planners and of qbf solvers more generally.
