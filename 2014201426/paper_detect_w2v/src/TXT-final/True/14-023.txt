 
the structural properties of optic flow fields are used to develop constraints on the motion of image features over time. for several restricted cases of motion  these constraints greatly simplify the determination of inter-frame motion and the inference of environmental information. these structural properties are briefly reviewed. procedures are presented for computing  and making environmental inferences from  optic flow produced when camera motion is known  translational  or restricted to a plane. some applications are discussed. 
	i. 	introduction 
　　optic flow is the f i e l d of v e l o c i t y vectors generated on an imaging surface by the moving projections of environmental points. the analysis of flow f i e l d s provides useful environmental and movement control information without 
 top-down   semantic knowledge and often by simple computations   1   . there are  however  s i g n i f i c a n t problems with computing optic flow from real world image sequences  notably how techniques for environmental inference can be applied to computed flow f i e l d s which are noisy and imprecise and how to seperate p a r t i c u l a r image transformations  such as l i g h t source and occlusion e f f e c t s   from image 
motion which corresponds to optic flow. 
　　in t h i s paper we consider r e s t r i c t e d cases of motion for which the processing of optic flow  from real world image sequences  is robust. these cases occurr frequently in important s i t u a t i o n s . the s t r u c t u r a l properties of flow f i e l d s are reviewed and used to develop constraints on the motion of image features overtime. for several r e s t r i c t e d cases of motion  these constraints greatly s i m p l i f y the determination of optic flow and the inference of environmental information. 
　　f i n a l l y   in processing image sequences  a flow f i e l d is generally approximated by the displacements of features between successive images. while there are s i g n i f i c a n t differences between a flow f i e l d and a displacement f i e l d   in t h i s communication they are referred to interchangeably. 
 this research was supported by nih grant no. r1 ns1 com and nsf grant mcs1. 
	ii optic 	flow 	field 	structure 
	a. 	translational/rotational components 
	the motion of 	features 	in 	successive 	images  
image i  and image i+1   produced by a camera moving r e l a t i v e to a stationary environment can be described by 1 parameters   1   1   : two   t 1   i     t 1   i     for the unit vector describing the d i r e c t i o n of t r a n s l a t i o n with respect to the camera coordinate system; two   r 1   i     r     i     for the unit vector 
describing the axis of r o t a t i o n with respect to the camera coordinate system; and one  r1 i   for the extent of r o t a t i o n about the axis of r o t a t i o n . 
　　for a planar r e t i n a   the t r a n s l a t i o n a l flowpaths are straight l i n e s which intersect at a point called the focus of expansion/contract ion or foe for short. the positioned of the foe is determined by the intersection of the r e t i n a l surface with the t r a n s l a t i o n a l a x i s . the d i r e c t i o n of motion along a flowpath  either towards or away from the foe  r e f l e c t s whether the corresponding environmental point is becoming more or less d i s t a n t . the environmental depth of a point is a simple function of i t s position and displacement along a t r a n s l a t i o n a l flowpath  
d * z' 
	z 	= 	
d' 
where d is the distance of an image point from the foe at i; d' is the displacement of the image point from i to i + 1 ; z' is the environmental displacement of the point r e l a t i v e to the observer along the z axis from i to i + 1 ; and z is the environmental depth at time i. 
　　rotational flowpaths  for planar r e t i n a s   are conic sections. the important fact about r o t a t i o n a l flow is that it is not a function of environmental depth. that i s   the parameters r1 i   r1 i   r1 i  are s u f f i c i e n t to determine the notion of a point  due to camera r o t a t i o n   from image i  to image i+1 . 
1 

b. recovery 	of 	camera 	motion 
　　the1e properties enable the recovery of the camera motion parameters from a displacement f i e l d . given such a f i e l d   one technique   1   1   involves searching through the bounded space of r o t a t i o n a l parameters  r1 i   r1 i   r1 d  to determine image displacements  due to r o t a t i o n   which  when subtracted from the established displacements  
y i e l d t r a n s l a t i o n a l components which nearly intersect at a point corresponding to a foe. 
　　the inference of these parameters is s i m p l i f i e d when environmental motion is constrained. amoung such constraints are r e s t r i c t i o n s on the positions 
of the t r a n s l a t i o n a l and r o t a t i o n a l axes  t h e i r r e l a t i v e o r i e n t a t i o n and motion overtime. such constraints r e s t r i c t the motion of image p o i n t s   s i m p l i f y i n g the determination of image motion. 
some basic cases are presented below. 　　these displacements can be determined in several ways. since image motion is constrained to a known l i n e   temporal-spatial gradient a n a l y s i s   1   1    based upon approximating the product d l   s   / d t   d s / d l   s     where i s  is the i n t e n s i t y at position s along a l i n e   w i l l provide solutions  provided c e r t a i n requirements concerning image smoothness and the extent of motion hold. another general technique is determining the optimal match for an image subarea from the rotated image i  along a flowpath with respect to image i+1 . such a window need only be a id array of interpolated i n t e n s i t y values along a portion of a flowpath. figure 1 shows a flow f i e l d produced by camera motion with 
respect to some i n d u s t r i a l parts using such a feature. edge-based descriptors  such as zero-crossings  region boundaries  and i n t e n s i t y iso-contours can also be matched e a s i l y . i i i . 	cases of camera motion 
a. known camera motion 
processing known camera motion  when all 1 parameters and the extent of the tran1latlonal displacement are given  involves applying the rotation specified by r1 i   r1 i . r1 i  to image i  and to determine the position of the tran1lational axis between the rotated image i  and image i+1 . the inference of environmental depth then involves finding the 1 dimensional displacements along the tran1lational flowpaths for 
image points   f i g . 	1 . 
　　given a computed depth map and known camera motion  the positions and displacements of image points in later images can be predicted. differences between predicted and the determined positions can be used to refine the i n i t i a l l y computed depth map or supply evidence for some other type of image transformation or independently moving object. 
b. translational motion 
　processing 	translational 	motion 	requires determining a foe. 	the techniques for known motion are then applicable. 	some techniques for this 	are 1  	searching 	through 	t1 i   	t1 i  for a foe and corresponding flowpaths along 	which 	the 	strength and 	number 	of 	matches 	of extracted features are maximized; 	1  determining the 	foe 	from 	computed image 	displacements. 	for 	a perfect displacement f i e l d   	this 	is 	given 	by 	finding 	a 	common intersection. 	given 	an 	errorful 	displacement f i e l d   approximations 	to 	such 	a 	point 	must 	be found  	using  	for 	example  	least squares error. additionally  if the direction of translation stays fixed 	over 	several 	images  	then 	using 	the straightness of the flow paths as a constraint 	can f i l t e r 	out bad matches; 	1  using a measure of the consistency of the environmental inferences with 	a 
prior surface models to guide foe search. 
1 
iv. applications 
	in figure 1 is shown a 	determined 	foe 	from 	a 

portion of a messy flow field. a least squares intersection is determined for strong matches and used to initialize a more refined search. it is difficult to infer the foe when it is positioned far from the actual image and computed matches tend to be parallel. 

　　when motion is constrained to a known plane p  the axis of rotation  r1 i   r1 i   is determined and the position of the foe is constrained to a 
　　line l  determined by the intersection of the image surface with a plane  parallel to pf and containing the focal point. processing involves finding  for a computed displacement f i e l d   a value for the extent of rotation r1 i  which yields translational components whose intersections with l form a tight cluster corresponding to a foe. 
　　this is done by searching through the bounded set of values for r1 i   the extent of rotation between successive images is generally limited . the scatter of the intersections of the translational components along l can be used as an error measure. if several displacement vectors are used  the intersections of the translational components can be histogramed along l and a value for r1 i  selected which produces a strong  sharp peak. 
a. robot control 
　　an industrial robot generally exists in an environment where known or restricted motions occur. potential uses of motion processing involve image sequences produced from a stationary camera positioned with respect to a moving conveyor belt or one directly attached to a robot arm. i have recently begun the analysis of image sequences produced in this latter case. there is much useful information for collision determination  controlling grasping  and object recognition. there are also considerable technological problems  notably the necessary speeds of processing and the load and bulk of attached cameras. 
　　the load and bulk problems may be resolvable through the use of optic fiber transduction elements. in figure 1  several such elements are shown attached to an idealized cartesian arm. this particular arrangment shows some of the appealing properties of such arms and the use of multiple optic sensors: an encompassing view of the workspace and a direct decomposition of image motion into translational and rotational components by the placement of the sensors. 

b. motion knowledge 	source 	for 	visions 
these techniques are being applied towards the development of a motion knowledge source for the umass visions system  1 . the restrictions of constrained camera motion  with respect to stationary outdoor house scenes are significantly weaker than the semantic constraints currently used to control image interpetation by the visions system. 

1 

acknowledgements 
i would very much l i k e to acknowledge a wide range of support from the umass visions group  and in p a r t i c u l a r   ed riseman  al hanson and ralf kohler. and thanks especially to dr. nelson corby and his associates from the i n t e l l i g e n t machine systems group at the general electric corporate research and development center in schenectady  new york for the use of t h e i r cart arm  cameras  s k i l l   and patience. 
