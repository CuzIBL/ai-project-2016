
in several domains of spatial reasoning  such as medical image interpretation  spatial relations between structures play a crucial role since they are less prone to variability than intrinsic properties of structures. moreover  they constitute an important part of available knowledge. we show in this paper how this knowledge can be appropriately represented by graphs and fuzzy models of spatial relations  which are integrated in a reasoning process to guide the recognition of individual structures in images. however pathological cases may deviate substantially from generic knowledge. we propose a method to adapt the knowledge representation to take into account the influence of the pathologies on the spatial organization of a set of structures  based on learning procedures. we also propose to adapt the reasoning process  using graph based propagation and updating.
1 introduction
several domains  such as anatomy  can benefit from a strongly structured knowledge  that can be expressed for instance by an ontology. this knowledge is of great help for interpreting particular cases or instantiations  e.g. individual anatomy . as a typical application  we consider in this paper the problem of knowledge-based recognition of anatomical structures in 1d brain images. the available knowledge includes generic descriptions of structures  and their spatial organization  in particular their spatial relations  usually formulated in natural language or formalized in medical ontologies. this knowledge involves complex textual descriptions  which are difficult to translate into an operational model assisting image segmentation and recognition algorithms. towards this aim  we propose to model this type of anatomical knowledge using graphs  as a natural representation of both objects and relations and a powerful reasoning tool  section 1 . spatial reasoning in medical image interpretation strongly relies on spatial relations  that are less subject to inter-individual variability than properties of anatomical structures such as size or shape  as described in section 1. a generic graph model is used in a reasoning process guiding the recognition of anatomical structures in brain magnetic resonance images and is then instantiated in order to account for specificities of the patient. however  specific cases can exhibit significant deviations from the generic model. this is typically the case in medical applications when pathologies  such as brain tumors  may appear as additional objects in the images  which are not represented in the generic model. another contribution of this paper  detailed in sections 1 and 1  is the adaptation of the reasoning process to deal with specific cases  according to both generic knowledge about pathologies and their potential impact on normal structures  and specific patient's information derived from the images. we propose to learn the variability of the spatial relations in the presence of a tumor by using a database of pathological cases  section 1 . the adaptation of the reasoning procedure relies on knowledge about the pathologies  throughthe exploitationof a brain tumor ontology  the learning results and a graph based propagation process which consists in updating the graph structure and attributes based on image segmentation results  section 1 .
¡¡the proposed approach  illustrated in figure 1  contributes to fill the gap between two widely addressed problems: segmentation and recognition of objects in images on the one hand  and knowledge representation on the other hand. recently  few approaches for ai based image interpretation have been developed exploiting knowledge and generic information  crevier and lepage  1   in particular structural knowledge represented with graphs  to drive specific recognition procedures  see e.g.  mangin et al.  1; deruyver et al.  1; colliot et al.  1  among others . however  these methods mainly deal with normal cases  and cannot be applied directly to pathological cases. noticeably  very little work uses ontology-based approaches for automatic image interpretation  while they are more developed for image retrieval  smeulders et al.  1 . unfortunately  no modeling approach of spatial relations in the image domain has been proposed  and segmentation tasks are not addressed. this paper proposes an original method towards these aims.
1 generic knowledge representation

figure 1: overview of our framework  illustrating the ontological  graph-based representations  learning and updating procedures. the schematic representation of the generic anatomy is from  hasboun  1 .in several domains  scene interpretation benefits from knowledge about its structural organization and its context. this is typically the case in medical image interpretation. as an example  we consider the case of brain imaging. the brain is usually described as a hierarchical organization. each level of the hierarchy is composed of a set of objects  at a given level of granularity. these objects are organized in space in a roughly persistent way. this hierarchical and spatial organization is an important component of linguistic descriptions of anatomical knowledge  bowden and martin  1; hasboun  1 . recent developments in the ontology community have shown that ontologies can efficiently encode generic and shared knowledge of a domain. for instance  the foundational model of anatomy  fma   rosse and mejino  1  provides an ontology of the canonical anatomy of the human body.
¡¡based on both linguistic and ontological descriptions  we propose to model the spatial organization of the brain as an hypergraph. each vertex represents an anatomical structure  while edges or hyperedgescarry information about the spatial relations between the vertices they link. the choice of hypergraphs is motivated by the importance of complex relations of cardinality higher than two  such as  between . moreover this type of structural representation is appropriate for modelbased recognition.
¡¡model-based recognition requires a second level of knowledge representation  related to the semantics of the spatial relations in images. fuzzy representations are appropriate in order to model the intrinsic imprecision of several relations  such as  close to    behind   etc.   the potential variability  even if it is reduced in normal cases  and the necessary flexibility for spatial reasoning  bloch  1 . two types of questions are raised when dealing with spatial relations:  i  given two objects  possibly fuzzy   assess the degree to which a relation is satisfied;  ii  given one reference object  define the area of space in which a relation to this reference is satisfied  to some degree . in this paper  we deal mainly with the second question  see section 1 . therefore we rely on spatial representations of the spatial relations: a fuzzy set in the spatial domain defines a region in which a relation to a given object is satisfied. the membership degree of each point to this fuzzy set corresponds to the satisfaction degree of the relation at this point  bloch  1 . an example is illustrated in figure 1.

figure 1: left: a fuzzy reference object. right: fuzzy region representing the relation  to the left of  the reference object. membership degrees vary from 1  black  to 1  white .
¡¡we now describe the modeling of the main relations that we use: adjacency  distances and directional relative positions.
¡¡a distance relation can be defined as a fuzzy interval f of trapezoidal shape on r+  as illustrated in figure 1. a fuzzy subset ¦Ìd of the image space s can then be derived by combining f with a distance map da to the reference object a:
	 x ¡Ê s  ¦Ìd x  = f da x   	 1 
where da x  = infy¡Êa d x y .

	n1	n1	n1 n1
figure 1: fuzzy interval representing a distance relation. for instance the relation  close to  can be modeled by choosing n1 = n1 = 1.
¡¡directional relations are represented using the  fuzzy landscape approach   bloch  1 . a morphological dilation ¦Ä¦Í¦Á by a fuzzy structuring element ¦Í¦Á representing the semantics of the relation  in direction ¦Á  is applied to the reference object a: ¦Ì¦Á = ¦Ä¦Í¦Á a   where ¦Í¦Á is defined  for x in s given in polar coordinates  ¦Ñ ¦È   as:
	¦Í¦Á x  = g |¦È   ¦Á|  	 1 
where g is a decreasing function from  1 ¦Ð  to  1   and |¦È   ¦Á| is defined modulo ¦Ð. this definition extends to 1d by using two angles to define a direction. the example in figure 1 has been obtained using this definition.
¡¡adjacency is a relation that is highly sensitive to the segmentation of the objects and whether it is satisfied or not may depend on one point only. therefore we choose a more flexible definition of adjacency  interpreted as  very close to . it can then be defined as a function of the distance between two sets  leading to a degree of adjacency instead of a boolean value:
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¦Ìadj a b  = h d a b    1  where d a b  denotes the minimal distance between points of a and b: d a b  = infx¡Êa y¡Êb d x y   and h is a decreasing function of d  from r+ into  1 . we assume that
a ¡É b =  .
¡¡in all these definitions  the satisfaction degree of a relation depends on a function  f  g or h  which is chosen as a trapezoidal shape function for the sake of simplicity. a learning step  presented in section 1  defines the parameters of these functions based on a set of segmented images.
1 spatial reasoning for model-based recognition
for the sake of completeness  we summarize in this section previous work on structure recognition using spatial relations and graph based knowledge representations. details can be found in  colliot et al.  1 . the approach is progressive  in the sense that objects are recognized sequentially and their recognition makes use of knowledge about their relations with respect to other objects. this knowledge is read in the graph representing generic knowledge. the graph also drives the order in which objects are searched. relations with respect to previously obtained objects have generally different natures and have to be combined in a fusion procedure  at two different levels. first  fusion of spatial relations occurs in the spatial domain  using spatial representations of relations. the result of this fusion allows to build a fuzzy region of interest in which the search of a new object will take place  in a process similar to focalization of attention. in a sequential procedure  the amount of available spatial relations increases with the number of processed objects. therefore  the recognition of the most difficult structures  usually treated in the last steps  will be focused in a more restricted area. another fusion level occurs during the final decision step  i.e. segmentation and recognition of a structure. for this purpose  it was suggested in  colliot et al.  1  to introduce relations in the evolution scheme of a deformable model  in which they are combined with other types of numerical information  usually edge and regularity constraints. this approach leads to very good results in normal cases.
1 how to deal with specific cases
the method presented so far is not well adapted to cases that greatly differ from the generic model. particularly  in medical images  the presence of a tumor may induce not only an important alteration of the iconic and morphometric characteristics of its surrounding structures but also a modification of the structural information. we propose a pathologydependent paradigm based on the segmentation of the pathology and on the use of the extracted information to adapt both the generic graph representation and the reasoning process to specific cases. in this paradigm  ontologies and fuzzy models convey important information to deal with complex situations. in this section  we address the following question: given a pathology  which spatial relations do remain stable  and to which extent 
1 a brain tumor ontology
in addition to canonical anatomy  image interpretation in diseased cases can benefit from knowledge on pathologies. for example  brain tumor classification systems are highly used in clinical neurology to drive the selection of a therapeutical treatment. brain tumors are classified according to their location  the type of the tissue involved  their degree of malignancy and other factors. the main brain tumor classification system is the who grading system  smirniotopoulos  1  which classifies brain tumors according to histological features and radiologic-pathologic considerations. differential diagnosis of brain tumor based on the location of the tumor was also proposed1. in this paper  we propose a brain tumor ontology which encodes these different kinds of knowledge. named tumors  e.g. gliomas  astrocytoma  are hierarchically organized according to the type of the tissue involved in the tumor. then for each type of tumors  the ontology describes their possible locations  their spatial behavior  i.e. infiltrating vs. circumscribed   their composition  i.e. solid  cystic  necrotic  with surrounding edema   their modality-based visual appearance and their grade in the who grading system  as shown in figure 1.

figure 1: overview of a subpart of the brain tumor ontology.
¡¡this ontology was developed in the framework of prote¡äg¡äe1and can be obtained on demand. we show in the next sections how to use this ontology.
1 learning spatial relation stability in presence of pathologies
the presence of a pathology can affect the generic structural information in several ways:  1  a spatial relation between two anatomical structures can be invalidated;  1  a spatial relation between two anatomical structures can be validated but with more variability;  1  new relations between anatomical structures and pathological structures can be added; and  1  an anatomical structure can be destroyed by the pathology.
¡¡these modifications depend on the type of the relations  on their stability  on the precision or vagueness of the available knowledge. intuitively  topological relations imply less unstability than metric ones. the nature of the deformation itself  i.e. the nature of the tumor in our case: infiltrating  destroying...  has also an impact on the stability of the spatial relations.
¡¡however  these considerations remain intuitive and do not lead to definite conclusions on the nature of the impact. therefore  we propose to learn the stability of the spatial relations in the presence of tumoral pathologies on a set of examples.
learning database
the database is constituted of 1 healthy mri and 1 pathological mri where the main anatomical structures were manually segmented. the healthy cases are the images of the widely used ibsr database1  real clinical data . the pathological cases include intracranial brain tumors belonging to n different classes. we focus our study on the stability of spatial relations between internal brain structures  namely: ventricles  caudate nuclei  thalami and putamen  which is a clinically relevant choice  according to medical experts' opinion.
¡¡the first step concerns the structuration and clustering of the database according to the brain tumor ontology. a key point is the representativity of the database according to predominant spatial behaviors of brain tumors  i.e. their tendency to spread  to destroy  necrotic or not   to stem  cystic tumor  edema presence  and their location.
learning procedure
from this database  the parameters involved in the construction of the fuzzy representations of spatial relations  for functions f  g  h in particular  are learned. let us first introduce some notations and definitions: k =  kn kp1 ...kpn  is the learning database with kn the set of healthy instances and kpi i ¡Ê 1...n  the set of pathological instances of class i. let c be an instance of k  an image   oc the set of segmented objects in c and r a spatial relation. we denote by ¦Ìnr the fuzzy subset in the image space corresponding to the relation r for a healthy case  and by the fuzzy subset in the image space corresponding to the relation r for a pathological case of class i.
¡¡a leave-one-out procedure is used to learn  for a given spatial relation r  the parameters of its fuzzy formulation ¦Ìr. since ¦Ìr is defined in the spatial domain  we can directly compare ¦Ìr and the target objects. the parameters are optimized so as to maximize the inclusion of the target object in ¦Ìr  i.e. the object has to fulfill the relation with the highest possible degree . for all c ¡Ê kk  k ¡Ê {n p1 ...pn}   ac bc  ¡Ê oc  we compute the fuzzy set with respect to ac  and for a given inclusion measure i  we compute. the fuzzy set optimizing this criterion is denoted by ¦Ìcr.
¡¡in order to learn functions f  g and h  equations 1  1 and 1   the minimum or maximum of the values  distances  angles...  are computed for all instances  from which the function parameters are then determined. let us detail the example of the relation  close to . the training consists in the computation of the maximum distance from a point x of the target object bc to the reference object ac:
	.	 1 
then the mean mk and standard deviation ¦Òk of the values {dcmax}c¡Êkk are computed. the fuzzy interval f is then defined as a fuzzy subset of r+  with kernel  1 mk  and support  1 mk +1¦Òk . this allows taking into account the variability of the parameters in the training set. an example is illustrated in figure 1.
¡¡a similar approach is applied for adjacency and directional relations.
stability assessment
the stability of the spatial relations can now be assessed by comparing the learned parameters for specific cases and for healthy ones. a suitable choice for such a comparison is a mmeasure of resemblance  according to the classification proposed in  bouchon-meunier et al.  1 .
¡¡we use a set-theoretic derived m-measure of resemblance defined as the cardinality of the intersection of two fuzzy sets

figure 1: learning the relation  close to  between putamen and caudate nucleus ¦Ìd on normal cases and on pathological cases for a class pi  here high grade gliomas that shift the putamen away from the caudate nucleus .
  normalized by the cardinality of their union:

where d denotes the definition domain of the fuzzy sets. this choice is motivated by the properties of this measure  reflexive  symmetrical  increases with the overlapping between the two fuzzy sets  decreases with their difference .
¡¡this resemblance measure is applied on the fuzzy sets learned for each type of spatial relations  as the ones illustrated in figure 1  in this case d is the distance space  i.e.
r+ .
results
in this section  we show some results for an instance of a pathological class  here  high grade glioma  which are spread and destroying . for each spatial relation  we compute the fuzzy resemblance between the learned fuzzy sets in the pathological class and in the healthy one as explained before.
caudateventriclethalamusputamencaudate111ventricle111thalamus111putamen111table 1: degree of resemblance between the fuzzy representations of the the adjacency relation for the healthy class and for a pathological class pi  high grade gliomas .
caudateventriclethalamusputamencaudate111ventricle111thalamus111putamen111table 1: degree of resemblance for the relation  close to  .
¡¡table 1 shows that the adjacency relation exhibits high resemblance values for structures that have a high degree of adjacency  such as caudate nuclei and ventricles  i.e. the adjacency relations between two structures in a healthy case are similar as those in a pathological case   which confirm our assumption that the adjacency remains stable even in pathological configurations. the spatial relation  close to  is more prone to unstability  in particular for structures that are more affected by the tumor. in the considered pathological class  the tumor has a strong impact on the putamen for instance. table 1 shows that the distance relations between the putamen and other structures have a high variability between healthy cases and pathological ones  i.e. low resemblance values . these results are in agreement which visual observations on the images  as illustrated in figure 1. note that the learning process in not symmetrical in ac and bc and depends on the reference object  equation 1   which explains that the tables are not symmetrical.
tumor

figure 1: a normal case and a pathological one. the caudate nuclei and the ventricles are adjacent in both cases  hence a high resemblance value for this relation . the putamen is deformed in the pathologicalcase  thus modifyingits distance to the caudate nuclei  which explains the low value of the resemblance in table 1.
1 knowledge and reasoning adaptation for specific cases
in this section  we propose an original approach to reason on specific cases based on three steps:  1  detection and segmentation of the tumor from the specific image as described in  khotanlou et al.  1 ;  1  adaptation of the generic model to the specific case. the idea is to exploit the ontology  enhanced by the learning results  and then add tumor information extracted from images in the graph. due to the variability of individual cases  this knowledge is only a guide for the recognition of image structures. the real specificity of the processed case is computed by a graph based propagation segmentation process which evaluates the tumor impact on surrounding structures;  1  updating of the database using this new processed case.
1 generic knowledge adaptation
the knowledge adaptation process depends on the available knowledge. if we have expert knowledge about the processed case  such as the diagnosis associated with the pathological image  then it can be used to extract its characteristics from the brain tumor ontology and then use the learned relations corresponding to its class in the segmentation process. if we do not have any information about the current case  we can use image matching procedures through a similarity measure to find the best matching class in the database.
¡¡the knowledge adaptation process is based on the modification of the generic graph: we first segment the brain tumor  add a tumor node in the graph and localize it in the brain  based on segmentation results; we then modify edge attributes with the learned spatial relation parameters for the class of this particular tumor.
1 a graph based propagation process
the aim of the graph based process is to quantify the real impact of the pathology on surrounding structures by using a progressive model based recognition approach as described in section 1. the model used is the one which results from the knowledge adaptation step described in the previous section. starting from a reference structure  usually the lateral ventricle   we propagate the tumor impact in the graph until a behavior which is similar to the healthy case is reached  i.e. until structures which are not affected by the tumor.
¡¡the knowledge is read in the graph representing the specific learned knowledge for this class. the graph drives the order in which objects are searched but contrary to the generic case  the choice of the structure to segment is also driven by the stability of the learned relations. more precisely  starting from a previously recognized object ac  all objects bcj linked with an edge to ac are potential candidates for the next object to be found. the choice of one of these is based on the maximum of resemblance. usually several relations are shared by ac and bcj. the maximum is then defined based on a lexicographic order on the relations: 1. adjacency  1. direction  1. distance. then we segment the corresponding structure in a similar way as in section 1. the only difference is that each relation is taken into account with a weight given by the resemblance degree. at last we update segmented structure properties and relations with known structures in the specific graph by edge and node attribute modifications. the process stops when the computedattributes do not widely deviate from the generic model  hence no more updating is required .
¡¡an illustrative example of segmentation results obtained using the proposed approach on a pathological case is shown in figure 1. on this example  once the tumor is segmented  the procedure leads to sucessful segmentation of ventricles  caudate nuclei  thalamus and putamen  in this order . note that these results would have been very difficult to obtain based on the generic knowledge only.

figure 1: an axial slice of a 1d mri  with segmented tumor and some anatomical structures.
1 conclusion
this paper is a contribution to ai based methods for image interpretation. an important feature of the proposed approach is the adaptation of genericknowledgeto specific cases taking into account information extracted from individual images  as illustrated in the domain of pathological brain imaging. the method combines in an original way graph representations  fuzzy models of spatial relations  learning procedures and graph propagation. further work aims at developing the last step  which consists in updating the database with the new processed cases. this includes adapting the shape of the membership functions as in the learning step. evaluation of the proposed models and the whole approach by medical experts will also be performed.
acknowledgments
this work has been partly supported by grants from re¡ägion ile-de-france  get and anr.
