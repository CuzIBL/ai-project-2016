
biological movement control and planning is based upon motor primitives. in our approach  we presume that each motor primitive takes responsibility for controlling a small sub-block of motion  containing coherent muscle activation outputs. a central timing controller cues these subroutines of movement  creating complete movement strategies that are built up by overlaying primitives  thus creating synergies of muscle activation. this partitioning allows the movement to be defined by a sparse code representing the timing of primitive activations. this paper shows that it is possible to use a factorial hidden markov model to infer primitives in handwriting data. the variation in the handwriting data can to a large extent be explained by timing variation in the triggering of the primitives. once an appropriate set of primitives has been inferred  the characters can be represented as a set of timings of primitive activations  along with variances  giving a very compact representation of the character. the model is naturally partitioned into a low level primitive output stage  and a top-down primitive timing stage. this partitioning gives us an insight into behaviours such as scribbling  and what is learnt in order to write a new character.
1 introduction
biological systems are strongly superior to current robotic movement control systems  despite having very noisy sensors  and unpredictable muscles. therefore  the amount and nature of pre-planning in biological movement is extremely interesting. strong evidence exists to suggest that biological motor control systems are modularised  with motor primitives first being conclusively found in frogs  bizzi et al.  1; d'avella and bizzi  1; d'avella et al.  1   where stimulation of a single spinal motor afferent triggered a complete sweeping movement of the frog's leg. for a review of modularisation of motor control in the spine  see  bizzi et al.  1 .
¡¡evidence suggests that once a particular subsection of movement has commenced  it cannot be unexpectedly switched off. rather  to quickly modify a movement trajectory  the movement primitives are superimposed  kargo and giszter  1 .
¡¡a primitive in the handwriting domain will be a short time extended block of pen motion  brought about by a corresponding block of muscle activations. these blocks are superimposed upon each other to create coherent movement in this case  a character.
¡¡to reliably model natural handwriting  we introduce a fully generative model  allowing proper modelling of handwriting variation and adaptation irrespective of the character drawn. if the handwriting output is made up of primitive type subblocks then the generative model must represent these primitives  to allow it to efficiently model the internal handwriting encoding.
¡¡in section 1  we introduce our generative handwriting model based on primitives in terms of a factorial hidden markov model. section 1 covers the generalisation over the timing of primitives to create a timing model. in section 1 we present some typical samples  and the results of using this model  and finally the discussion is in section 1.
1 model
a generative handwriting model must be capable of reproducing the class of characters upon which it has been trained. assuming that all motor commands are made up of motor primitives  handwriting must therefore contain projections of these primitives. assuming also that motor primitives are fixed  or adaptable over long time scales  any short term adaptability and learning must come from the timing and selection of different primitives.
¡¡assuming the individual primitives are independent of each other  and are linearly superimposed  a controller to select primitive onset timing is necessary  similar in nature to a piano model  where key pressing controls the onset of time extended clips of sound that the listener hears as a superimposed waveform.
1 a deterministic piano model
to formalise this model in a generative way  the output of the system y at time t is defined as
	  	 1 

figure 1: graphical representation of a factorial hidden markov model  showing the independence of the separate markov chains. although the observable output is dependent upon the state of the entire system  the internal states evolve with no interdependencies. stm denotes the hidden state vector at time t  in factor m.
where wm t  are the primitives  and ¦Ómn represents the time of the nth activation of primitive m  and ¦Ámn defines the activation strengths of the primitives. in this definition  m enumerates the primitives  whilst n enumerates the occurrence of the primitive within the sample window  at time ¦Ómn.
¡¡similar models have been used for modelling real piano operation such as  cemgil et al.  1   where the transfer from piano roll to sound uses note onset  and damping onset as key timing information for the reproduction of sound. also  karklin and lewicki  1  present a generative model of speech waveforms  where their 'sparse shiftable kernel representation' is similar in nature to the piano model presented here.
¡¡the data samples of handwritten characters are not segmented or keyed to a common start point  apart from the pen touching the paper. as this is not a reliable keying time for primitive activation  a flexible model must be used to infer the primitives  which will not only infer the shape of the primitives  but their timing onsets. we take the idea of the piano model as a basis  but model it probabilistically using a factorial hidden markov model  fhmm .
1 factorial hidden markov model
a graphical model of the fhmm can be seen in figure 1. at each time step  the observable output yt  a vector of dimension d  is dependent on m hidden variables st 1  .. stm. the output is a multivariate gaussian  such that
	yt ¡« n ¦Ìt c   	 1 
where c is a d ¡Á d parameter matrix of output covariance  and
		 1 
is the d-dimensional output mean at time t. wm is a d ¡Ák parameter matrix giving the output means for each factor m  such that the output mean ¦Ìt is a linear combination of its columns weighted with the hidden state activations.
¡¡each of the m hidden variables can be in k different states. in equation  1  this is encoded in the k-dimensional state vector stm using a 1-in-k code  i.e.  st im = 1 if the m-th factor is in state i and zero otherwise. this allows us to write expectations of the hidden states as  which is also the probability distribution over the individual states stm. each latent factor is a markov chain defined by the state transition probabilities and the initial state distribution as

where ¦Ðm is a k-dimensional parameter vector giving the initial hidden state distribution  and pm is a k¡Ák parameter matrix denoting the state transition probabilities. as can be seen in figure 1  each factor is independent. this means that the joint probability distribution can be factorised as

 1 

¡¡given the fully parameterised modelling framework  learning of the parameters can be done using an expectationmaximisation  em  method. the structured variational approximation was chosen for the e-step inference. for more details on the various arguments for and against this choice  refer to  ghahramani and jordan  1   which provides details about the fhmm model  and the learning procedure.
¡¡the em method is an iterative algorithm  in which the estep infers the expectations of the hidden states given a set of parameters  then the m-step updates the parameters to their maximum-likelihood values  given the inferred hidden state distributions. in our case  the e-step fits the primitives to the data  inferring the primitive onset timings for each sample. the m-step infers the shapes of the primitives. some constraints were imposed upon the parameters  so that the primitives progressed monotonically along their states  and that the rest state for all primitives  gave a zero output contribution.
¡¡the fhmm can reconstruct the data by using a set of maximally statistically independent primitives  and the appropriate hidden state values. due to the constraints imposed upon the hidden state transitions  these state values can be reduced to a set of primitive activation timings  or spikes. without this spike timing information  the primitive model can still be run separately  as can be seen in figure 1  which can be thought of as primitive babbling. to reconstruct a character  the primitives need to be coordinated  and activated at the appropriate times. this is achieved by introducing a separate part of the model  the centralised timing controller.
1 timing model
the centralised timing controller must be capable of reproducing spiking characteristics that in some areas of the character are variable  and others less so  both in time of spike  and existence of spike. in other words  some primitives are necessary  occurring in every character sample in roughly  but not exactly the same place. others occur occasionally in a reproduction  but not in every case. crucially  on a short time scale  there is heavy dependency between spikes  whereas on the long term  they are simply dependent upon the character being drawn.
¡¡we have chosen a stochastic integrate and fire  if  model for the generation of spikes  as this model has a local temporal dependency characteristic  and also allows variance in the total number of spikes in a sample.
integrate and fire the integrate and fire  if  model originates from simplified models of biological neurons. it treats the neuron as a leaky capacitor  upon which a charge is built up by the inputs  over time. once the voltage across the capacitor reaches a noisy threshold level  the neuron fires  producing a spike at its output  and discharging the capacitor. this means that  due to the leak term  over a long time scale  the inputs at different times are independent  however  on a short time scale  they are not  as it is the short-term running sum of the inputs that causes the neuron to fire. this is desirable for the primitive model  because the timing of a necessary primitive can be variable in the character samples  however  the if neuron will still fire as long as it receives enough inputs during its temporal memory window.
¡¡the most straight forward model using if neurons is to attribute one if neuron to one primitive. the inputs to the neurons will then determine the timing of the primitives and thus the character that is written. for a particular primitive  m  the probability of a spike at time t  p ¦Ëmt   is given by:
	p ¦Ëmt |¦Ëmt 1 = 1  = p ¦Ëtm 1  + itm   ltm 	 1 
	p ¦Ëmt |¦Ëtm 1 = 1  = itm   lmt  	 1 
		 1 
where itm are the input excitations  and lm is a leak term proportional to the accumulated probability. therefore  given a common set of primitives  a character is defined by its temporal excitation matrix  itm  which parameterises the if model. this matrix is learnt from the spiking statistics of the character training set  as seen below.
¡¡during the e-step for the fhmm  the hidden state distribution p stm  is inferred. as the transition matrix is constrained so that the primitives progress monotonically through their states  the information in p stm  can be summarised as the onset probabilities of the different primitives   which are the rows of p stm  for state 1  the first state in each primitive. for a set of primitives that fit the data well  these probabilities are close to zero or one  and form a very sparse matrix containing spikes representing primitive activation appropriate to reconstruct a single character sample from the data set. it is effectively an average over the samples of these spiking matrices that is needed to parameterise the if model  as itm. for ease of notation  let be the posterior onset probability at time t of the mth primitive for the n data sample.
¡¡to allow for differences in the start point time  and average speed of each character sample  two parameters are associated with each data sample  a temporal offset ¦Ätn and a linear temporal stretching factor ¦Äln. these parameters are optimised so that the ¦Ót nm matrices for the nth sample best fit the average itm matrix that is constructed by taking linear interpolations.
	.	 1 
more precisely  we optimize the temporal offset and strechting by iteratively finding ¦Ätn and ¦Äln via gradient ascent that maximize the objective function
	.	 1 
¡¡this finds an itm matrix that best reflects an average primitive onset probability matrix  where t has a separate linear shifting and stretching factor associated with it for each character sample  n. this is used to parameterise the if model  which generates the spike timing information needed to run the fhmm generatively.
1 implementation
handwriting data were gathered using an intuos 1 wacom digitisation tablet http://www.wacom.com/ productinfo/1.cfm. this provided 1 dimensional data at 1hz. the dimensions of the data were x-position  y-position  pen tip pressure  pen tilt angle  and pen orientation  1  . the normalised first differential of the data was used  so that the data mean was close to zero  providing the requirements for the zero state assumption in the model constraints  see section 1 . only 1 dimensions of the data were used  x-position  y-position  and pressure  as the signal to noise ratio of the other two was too low to provide usful data. the data collected were separated into samples  or characters  for processing purposes  and then the parameters were fitted to the data using our algorithm. we generated datasets of the characters 'g'  'm'  'a'  'b'  'c' and 'd'. the 'g' character set was the largest character set  and can be found at http://homepages.inf.ed.ac.uk/s1/ data/mixoutg.mat. the character sets 'g' and 'm' were chosen to explore the differences in primitives inferred from two contrasting characters  see figure 1. the characters 'a'  'b'  'c' and 'd' were chosen to explore the sharing of primitives between different characters  and the ability to create distinct reconstructions  as seen in figure 1.
data setsize'g'1'm'1'abcd'1 results
a typical subset of primitives learnt via the fhmm from data of g-characters are shown in figure 1 demonstrating the variation in shape and length on the paper of the primitives when reconstructed on their own. in this example  1 primitives of length 1 were used to model a data set of 1 characters  of average length 1. the average error of the reconstruction in velocity space for the data was  1 1 1 . using these primitives  the fhmm model can reconstruct the original character as shown in figure 1 using the posterior timings that are inferred from the data in the e-step of


	 a 	 b 
figure 1: two examples of character reconstructions  using timing information derived from the e-step inference. in both  a  and  b   the timing information is shown on the left  and the reproduction of the sample on the right  with the onset of each primitive marked with an arrow. in  a   1 primitives of length 1 time steps were used to model the 'g' dataset  of over 1 characters. in  b   1 primitives of length 1 were used to model the 'm' dataset  of over 1 characters.

	 1	 1	 1	 1	 1	1.1	 1	 1	 1	1.1.1.1.1.1.1.1
	 a 	 b 
figure 1: two samples generated using primitives without specific timing information  neither the posterior timing nor a learnt timing model .  a  was generated using primitives inferred from the 'g' dataset   b  was generated using primitives from the 'm' dataset. starting point of both reconstructions is  1 .


figure 1: a sample of 1 primitives used for the reconstruction in figure 1 a . the axis values refer to some normalised distance on paper  as the primitives are shown as a reconstruction in pen-space  rather than the raw data  which is in 1-dimensional velocity space. as the data was normalised ignoring the physical size of the pixels  it would be meaningless to provide units for the axes. thickness corresponds to pen pressure. refer to section 1 for an explanation.
the primitive extraction stage. the timing information  seen on the left of the figures is a representation of the posterior probabilities of onset of the primitives whilst reconstructing the data set. these probabilities are inferred during the e-step  and reveal the expected hidden state values of the fhmm. furthermore  given a sufficient set of common primitives to model the data reliably  these probabilities can be represented as spike timings  which provide a very compact encoding of the character. this timing information can also be modelled using a timing model  as investigated in section 1. here  no timing model was used or learnt. without such a timing model and without the hidden state posterior extracted from the data  one can still run the primitive model generatively  ignoring any precise timing information  and sampling the model states from the priors  without calculating the posterior distributions. the result is a random superposition of primitives producing a scribbling form of output such as shown in figure 1. here it can be seen that the primitives  even without precise timing information controlling their activation  still generate samples that capture an aspect of the training set from which they were extracted. allowing the temporal shifting and stretching as described in section 1  produces a distribution over spiking patterns  itm as can be seen in figure 1 for the 'g'-dataset. sampling from this distribution using our integrate and fire approach as described above  produces samples that reliably model the variation of the data set  as can be seen in figure 1. clearly  these are all examples of a character 'g'  however  the pen trajectory is vastly different in each example  reflecting the variance in the original data set. inferring primitives from a range of characters is also possible. figure 1 shows 1 different characters all drawn using the same primitives. despite the variation in the characters of a particular alphabet  the actual hand movements when controlling the pen are very similar  so it should come as no surprise that it is possible to use the same primi-

figure 1: a graphical representation of the distribution of spikes as m given by it for a 'g' character set.

	1	1	 1	 1	1.1	1	1	 1.1	 1	 1	1.1.1
figure 1: four samples generated from the full generative model as given by the learnt primitives  the fhmm  and the timing model
                                                                 m parameterized by the spike distribution it  shown in figure 1 .
	primitive timing data	pen space reconstruction	primitive timing data	pen space reconstruction

1 1  1  1  1  1 1 1 1  1  1 1.1 time /sample no.	time /sample no.
figure 1: four characters that have been reproduced using the same set of primitives  learnt from a mixed character set.
tives to reconstruct different characters. the variation in the characters must therefore be accounted for by the different timings of the primitives.
1 discussion
using the fhmm framework to infer motor primitive representations in handwriting data gives us primitives that can be active at any point  that are statistically independent  and are not limited to any particular section of character  or any subset of characters.
¡¡the spike timing distribution that can be seen in figure 1 may also be expressed in terms of a mixture of gaussians  where the mean of a gaussian conveys the average timing of a particular spike that is necessary to reproduce a character. this would be a more compact encoding for a character  although it would restrict the spike timing model to have the same number of spikes for a particular primitive in all samples. the stochastic integrate and fire model allows variance in the number of spikes  and includes the short term time dependency that is necessary to produce meaningful spike timings  however  the parameterisation matrix is much larger than would be the case for a mixture of gaussians.
¡¡without the timing model  the primitives can still produce output  by running the fhmm model generatively  and sampling the hidden states at each time step  from the prior distribution conditioned on the previous time step. this produces an output sample that is similar to scribbling or doodling. perhaps when we are absent-mindedly doodling  it is a disconnection of the timing control part of our motor system from the muscle output  or primitive section that produces these scribbles. intuitively  we are putting a pen in our hand  and telling ourselves to write  but not dictating what exactly.
¡¡in this model  given a common set of primitives used to control the complete set of possible movements  it is clearly the timing model that is dictating what class of movement is required. the spikes are the internal encoding of the movement class. using the spike timing representation of when the primitives are triggered  allows a very compact representation for a character. as a common set of primitives is capable of reconstructing several different characters  the spike encoding can therefore be divisive in differentiating one character from another  and may therefore be useful for efficient character recognition. the compact code would also be useful for data storage and transmission  in much the same way as the ascii code allows efficient transmission of printed characters  a spike encoding could efficiently transmit handwritten ones. this distributed model provides a framework both for learning new character sets  and experimentation with primitive shapes. it is possible that primitive shape is a personal attribute  which may account for different handwriting styles. if this is so  then an efficient mapping from one style to another may be possible. this hypothesis requires further research  by examining the primitives inferred from different people's handwriting samples. another hypothesis may be that different people have a different number or average length of primitive  maybe this could account for more 'messy' styles of handwriting.
¡¡given a common set of primitives  the spike timings encode the movement  but this does not address learning new movements. when we learn to write for instance  we must either learn new primitives  or adapt old ones  or perhaps some movements are simply not learnable or rather cannot be encoded by a sparse spike representation. the adaptation of primitives  and their association with learning new motor skills would be a very interesting area to explore  with the help of this model.
