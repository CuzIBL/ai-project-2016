* 
　　　most automated graphics generation systems employ either a constructive or a parametric graphics synthesis approach. constructive graphics synthesis is a deductive approach that builds visual presentations from scratch by gluing together the most basic visual variables. conversely  parametric graphics synthesis defines a set of parametrized visual models and interprets the information to be presented through instantiation of the selected model. to increase efficiency  we have combined parametric and constructive approaches in a system called improvise. in this paper  we focus on the parametric aspect of our approach. we present a comprehensive  general  and extensible formalism to represent a visual lexicon for use in automated graphics generation. a visual lexicon is a collection of parametrized primitive visual objects that serve as building blocks for constructing more complex visual presentations. we also illustrate how this representation can be effectively employed to aid the selection and instantiation of a visual lexical item in the graphics generation process. examples are given from improvise to demonstrate the representation and use of this visual lexicon. 
1 introduction 
　　automated graphics generation is a computationally complex task. most research systems that have been developed to explore it use one of two approaches: parametric graphics synthesis and constructive graphics synthesis. 
　　parametric graphics synthesis defines a set of parametrized visual models. it analyzes the data attributes  maps the data attributes onto the parameters of the models  and instantiates the visual parameters of the selected model to interpret the data  e.g.   robertson  1  . in contrast  constructive graphics synthesis does not predefine a set of visual models. 
t this research is supported in part by darpa contract daal1-k1  the columbia university center for advanced technology in high performance computing and communications in healthcare  funded by the new york state science and technology foundation   the columbia 
center for telecommunications research under nsf grant ecd-1 and onr contract n1-1 -1. instead  it reasons about visual design principles  e.g.   mackinlay  1   and attempts to compose visual presentations from scratch by gluing together the most basic visual variables  bertin  1  to form a coherent whole. 
　　we are developing a system called improvise  illustrative metaphor production in reactive object-oriented visual environments  that can automatically generate visual presentations using a combination of parametric and constructive approaches. unlike most of the constructive systems  e.g.   mackinlay  1; roth and mattis  1    improvise constructs a wide variety of visual presentations  including 1d static graphs and 1d animations  to convey heterogeneous information  zhou and feiner  1 . improvise begins by sketching abstract plans from scratch to create partially specified visual presentations. these vague descriptions are progressively replaced by more complete descriptions  zhou and feiner  1 . in a top-down fashion  a complex visual presentation is recursively built by using primitive visual objects that can be handled by a rendering component. we refer to a collection of the primitive visual objects as a visual lexicon. each primitive visual object in the lexicon is called a visual word or a visual lexical item. 
　　a visual word can be any type of visual form  ranging from a 1d static text string to a video clip. rather than list all the possible primitives and their combinations or construct them from scratch  we abstract and parametrize the basic visual forms. we have developed a comprehensive  general  and extensible formalism to represent a visual word. much like a lexical component in natural language' generation systems  gates et al.  1; elhadad et al.  1   the representation is not only comprehensive enough to capture the syntactic  semantic and pragmatic features of each word  but is also compact enough for the visual words to be easily manipulated by the design process. furthermore  the formalism is general enough to support a wide range of visual forms  including 1d graphical models  images  and video. the representation can also be easily extended to accommodate new visual forms. 
　　based on the lexical representation  we have formulated a set of constraints to guide the selection and instantiation of a visual word. those constraints come from a wide variety of sources including: syntax  e.g.  only certain visual words can be used in a composition   semantics  e.g.  only certain visual words can be used to fulfill a particular information-

1 	natural-language processing and graphical presentation 

seeking goal   and pragmatics  e.g.  available resources  such as a type of display  require certain types of visual words . 
　　in the rest of the paper  we first briefly discuss several parametric graphics synthesis systems in section 1. then we present our representation formalism for the visual lexicon in section 1. based on the representation  we postulate a set of constraints that guide the selection and instantiation of a visual word. finally  in section 1 we present our conclusions and discuss possible future work. 
1 related work 
　　the foundation of parametric graphics synthesis is a set of parametrized visual models. through careful examination  the mapping between the visual attributes of the models and the data properties can be established in a formal and systematic manner. most systems that employ a parametricapproach are quite similar but have minor differences in the methodologies they use to map data onto their visual models. nevertheless  systems can be differentiated by the richness and flexibility of their parametrized visual models  as well as their capabilities to compose various models into a coherent presentation. 
　　bharat  gnanamgari  1  was developed at university of pennsylvania to generate 1d displays for quantitative information: pie graphs  bar graphs  and line graphs. it maps numeric data to one of these graphs determined by the data characteristics. once a graph type is selected  it is instantiated based on the data properties and its syntactic parameters. 
	robertson's 	natural 	scene 	paradigm 	 nsp  
 robertson  1  maps data variables to various features of a 1d realistic natural scene  such as surface condition  surface height  and density based on data characteristics. he postulates a set of mapping rules to correlate the properties of the natural scene  the data characteristics  and the user's interpretation goals. nsp focuses on representing scientific or statistical data sets  it does not address how to represent qualitative  i.e.  non-quantitative  information. 
　　vista  senay and ignatius  1  is a knowledge-based visualization system that suggests various visual techniques for a given data set and also allows the user to modify the design interactively. compared to other parametric systems  vista offers a much richer set of visual techniques that can effectively express a wide range of scientific data. furthermore  it employs a sophisticated compositional design approach to design a composite visual display. vista partitions a large data set into simple sets of data  selects unused primitive visualization techniques to represent each small data set  and assembles all selected primitive visualization techniques together. like nsp  vista also emphasizes scientific visualization and does not address visual techniques for representing qualitative information. 
1 visual lexicon representation and usage 
     since most parametric synthesis systems have focused on presenting quantitative information  their representation formalisms usually are not comprehensive or general enough to handle heterogeneous information. moreover  most of their parametrized visual models are characterized by their syntactic features: the semantics and pragmatics of the models are cither ignored or simplified. however  to effectively synthesize visual presentations  we need a comprehensive representation of each model that captures its syntactic  semantic  and pragmatic features. the representation formalism should also be general and extensible. in our case  each visual word in the lexicon corresponds to such a model. to meet these criteria of comprehensiveness  generality  and extensibility  we have adopted an object-oriented paradigm to represent a visual word. 
1 representation 
a visual word is always associated with a single domain 

object. however  each domain object can be represented by one or more visual words. in a visual lexicon  we say that a domain object has multiple senses. for example  an instance of object patient could be displayed as one of the senses shown in figure 1. each sense  i.e.  visual word  has its syntax  semantics and pragmatics in the context of graphic design. in addition  a graphical expression  called a lexeme  
is also stored. 
object pattern 
　　　to map an object onto a visual word  we first need to know the object pattern including the type  attributes  and other object characteristics  zhou and feiner  1 . as shown in figure 1  variable  patient stands for an instance of patient. more complex patterns can also be represented through pattern description keywords. currently  we have implemented two keywords: type and attribute. type speci-
fies the domain of the object  while attribute restricts the 
objects to a subset that satisfies the specified attributive constraints. for example  to represent any patient whose age must be greater than 1  we use: 
    object-pattern   patient  type patient   attribute    ;age 1     note that the name of each attribute is preceded by a  : . 
syntax 
　　syntax describes the structure or pattern of a visual word. in particular  category  subcategory  and media 
together specify the syntactic features  figure 1 . 
　　category provides the type of a visual word based on the visual hierarchy described in  zhou and feiner  1   while subcategory further classifies the type information. for example  a visual word is an instance of a visual-structure. more specifically  it is in the table-chart subcategory. although we could go even deeper to further distinguish the visual word types  we have found a two-level hierarchy to be adequate thus far. 
　　improvise is designed to deal with a wide variety of visual presentation forms  i.e.  visual media formats . we allow four media formats: graphical model  graphical file  image  and movie. 
　　a graphical model describes a visual object in a particular graphics language. in graphical model mode  all graphi-
cal expressions are explicitly written out as a lexeme. however  in graphical file mode the lexeme refers to the name of a file that contains all the graphical expressions. for example  a human model might be expressed in inventor 
 wernecke  1j file format in graphical model mode as: 
human{ 
head  ...  
body{ 
chest  ...  
waist {...}...} 
} 
alternatively  this description can be kept in a file named  human.iv  in graphical file mode. image mode signifies that the current visual object is an image file. optionally  it can be followed by an argument to indicate the image format as shown in sense1 of figure 1. the last media category  movie  indicates the current visual object is a video clip. similar to image  it can also be further qualified by appending a type argument  e.g.  mpeg1 . 
　　the advantage of providing media information is to simplify the process of handling multiple media formats and 
to make the system more general and extensible. 
usually  we specify a set of abstract visual operations 
 e.g.  scale  and move  at a high level without worrying about the implementation details for different media. at a lower level  based on the provided media information  the abstract operations are realized by media-specific proce-
dures. hiding the details of abstract visual operations makes it easier to extend the system. consider the abstract visual operation scale. scale transforms the modeling matrix for a graphical model  which can change the dimensions of an image. to support a new media format  we only need to write a set of procedures to perform the scale operation for the new medium without affecting the rest of the knowledge 
base. 
semantics 
　　while syntax focuses on describing the structure or pattern of a visual word  semantics abstracts the meaning of the syntactic features  summarizes the thematic roles of a visual word  and identifies the scope of its role. figure 1 shows the 
semantic features for the patient-entry. 
　　semantic sense specifies the abstraction of syntactic features of a visual word  while semantic role indicates what a visual word is capable of when it participates in a visual presentation. moreover  semantic scope elaborates how well a # text 	# simple body model 
 sensel 	 sense1 
	 semantics 	 semantics 
	 role identify  	 role locate  # complex body model 	# image 
 sense1 	 sense1 
 semantics 	 semantics 
	 role locate  	 role identify  	 scope naming  	 scope spatialposition  	 scope 	spatialposition  	 scope appearance  
	 sense label    	 sense symbol    	 sense symbol    	 sense portrait    
figure 1. semantics for patient entry #text # simple body model 	# complex body model # image  sensel  sense1 	 sense1  sense1  syntax  syntax 	 syntax  syntax  category visual-unity  	 category visual-unity  	 category visual-unity   category visual-unity   subcategory text  	 subcategory 1d-shape  	 subcategory 1d-shape   media image tiff     media graphical-model    	 media graphical-file    	 media graphical-file    
figure 1. syntax for patient entry 1 	natural-language processing and graphical presentation 
# text # simple body model 	# complex body model # image  sense1  sense1 	 sense1  aense1  pragmatics  pragmatics 	 pragmatics  pragmatics  domalnlnfo ...  	 domaininfo...  	 domaininfo 	...   domaininfo...   hardware 	 hardware 	 hardware  hardware  platform sgi i pc  
 cpu r1 i pentium...  	 platform sgi i pc  	 platform sgi   platform sgi i pc   graphics extreme i...  	 display color i grayscale   	 display color i grayscale    display color i grayscale       display color i grayscale    performance fast  ...  	 performance fast  ...  	 performance medium  ...   performance medium  ...  figure 1. pragmatics for patient entry 

visual word can perform in the specified role. in figure 1  sensel is a label that can only identify the patient by naming  but sense1 is a portrait that can identify the physical appearance of the patient. 
pragmatics 
　　in language or image understanding  pragmatic features usually refer to the roles or influences that the language or image possesses to help the user understand distinguishing features and appropriate contexts  e.g.   goldsmith  1  . to facilitate visual design  we have extended the connotation of the pragmatic features of a visual word. not only do we include word features that are directly related to the characteristics of the user and context  such as the user's identity  expectations  and application type  but we also cover factors that describe the relationships between the word and the design or execution environment  such as the hardware requirements  e.g.  display type  of the word. since modeling users and system environments is a complex task itself  we concentrate on a few types of information that are particularly useful. they are domain information  hardware requirements  and performance estimation. figure 1 lists the pragmatics of each word in patient-entry  with domain information omitted since they all share the same one: 
 domalnlnfo 
 apptype medical  
 audiencetype nurse i doctor   
　　the pragmatics features of sensel in figure 1 can be read as: the text representation of a patient's name is suitable for both nurses or doctors in a medical application. moreover  this text can be rendered on a sgi or pc with color or grayscale display. the rendering speed of such a text string is fast  e.g.  under a millisecond . 
　　although the pragmatic features involve domain-specific information  we can consolidate all domain-specific information by expressing it in a disjunctive form. for example  if we want to use the patient-entry for both medical and military logistics applications  we can write:  domalnlnfo 
 infol  apptype medical  
 audiencetype nurse i doctor   
 info1  apptype logistics  
 audiencetype medic i doctor    
lexeme 
　　in a visual lexicon  each lexeme is a graphical representation of a visual word. each type of representation {graphical model  graphical file  image  and movie  is actually a parametrized template. for example  the lexeme of sense1 in patient-entry is: 
 lexeme  visual-unity  geometry  text1 
 string  get-name  patient       
this says that the visual word is an instance of visualunity with a geometry of 1d text  which in turn requires that the string be the name of a patient. embedding procedures in the representation can be very useful. it eases information encoding by abstracting the common features of a visual word and expressing them in a procedural format. suppose that every patient's picture is stored as an image in the knowledge base  and is named by the patient's id number with a suffix  tif'. instead of explicitly listing all the patients and the file names of their pictures in the visual lexicon  we can use a single expression: 
      lexeme  image  filename  string-cat  get-id  patient   .tif      this states that the file name can be constructed by concatenating the patient's id and the suffix  .tif  
     to be consistent with the constructive theme of improvise  the visual lexicon stores only visual words that represent atomic objects. visual representations for composite objects are built from scratch by piecing together their component representations. 
1 usage 
　　improvise's visual lexicon is first searched to select a visual word for a given object and then the parameters of the selected visual word are instantiated. 
visual lexicon selection 
　　as described above  only atomic objects can be directly matched against the object-pattern specified in a visual lexicon entry. for example  suppose the task is to display patient jones's demographics information to a nurse in a medical application. in our case   demographics  is a composite object whose component objects include name  age  and gender. the system iteratively refines the abstract plan for accomplishing the task and reaches the point where it must decide how to represent the  age  object. at this point  the system needs to match the object description  i.e.  jonesage  against each object-pattern in the lexicon. the pattern matching is conducted by unifying the object description with an object-pattern. if the unification is successful  then all the visual words for the specific object-pattern become candidates  of which one will be selected to represent the object. in this example  the two unified entries are: 
	object: 	 jones-age  type physical-attribute   

pattern-1:   attribute  type attribute   
　　note that the two matched types are not necessarily the same. but physical-attribute is indeed a subclass of attribute. for generality  matching by inheritance is allowed. if an object description matches more than one object-pattern  the system always chooses the most specific one. the lower the object type is positioned in the domain ontology hierarchy  the more specific the object type is. moreover  the more attributive constraints an object pattern has  the more specific the pattern is. naturally  the more specific object pattern inherits the lexemes that are defined for more general object patterns. suppose there is another object-pattern: 
pattern-1:   attribute  type physical-attribute   
in this case  pattern-1 is used instead of pattern-1 and patter1 also inherits all lexeme expressions defined in pattern-1. moreover  through unification  the variable specified in the object-pattern is bound to the matched object. thus  variable  attribute is bound to object jones-age. 
　　the task of the selection stage is to single out the most appropriate candidate. many factors can affect the decision. we have established a set of syntactic  semantic  and pragmatic constraints to aid the selection. 
syntactic constraints. syntax governs the pattern formation in a synthesis process  marks  1 . syntactic features specified at different visual presentation levels are used to filter out undesired patterns to keep them from participating in higher-level patterns. figure 1 was automatically generated by improvise to present a patient's information summary to a nurse. the top-level visual description for the entire display is a structure-diagram  lohse et al.  1   which is a subtype of visual-structure. the syntax of a structure-diagram requires that its core component be a 
visual-unity that is not in the text subcategory. in this case  the core component could be one of the patient's visual representations shown in figure 1. 
　　based on the descriptions in figure 1  all visual words satisfy the syntactic constraint except sense  which is a text.  the patient name in figure 1 is not generated through defining the core component  but as part of the demographics information.  however  there are still multiple candidates 

figure 1. improvise's presentation for a nurse 
that need to be ruled out. 
semantic constraints. while syntactic constraints guarantee that visual representations have valid structures  semantic constraints can be used to ensure that the syntactically valid structures are also perceptually correct. semantic constraints can come from different aspects. one type arises from information-seeking goals  casner  1 . these constraints are evaluated by matching the semantic requirements to the role or scope description of the visual word. some visual words can play some roles to a certain extent to meet the goals while others cannot. in the example of figure 1  the task actually requires locating positions on the patient's body so that other information can be arranged around the body. by this criterion  only two choices remain: sense1 and sense}  since only these two can locate body positions. 
　　another type of constraint is specified by high-level visual preferences. these constraints usually require that the selected visual word have a certain visual sense  e.g.  be a symbol instead of a portrait   which in turn defines the potential usability of the visual word  arens et al.  1 . for example  a symbolic 1d graphical model can be viewed from different angles  while a portrait image cannot. in our case  the core component of the structure-diagram is required to be a symbol. fortunately  since both sense1 and sense1 satisfy the requirements  there is no conflict. 
　　in case all semantic constraints can be satisfied but result in a conflict set  we order the constraints by decreasing importance: first information-seeking goals  then visual preferences. this order in turn determines the importance ranking of the semantic features of a visual word: role  scope  and sense. in other words  when semantic constraints help determine visual word selection  a visual word should be weighted first to see whether it can fill the role to achieve the information-seeking goals  as measured by the scope of its role. while not posing any threat for achieving any information-seeking goals  sense can be considered last to see whether the user's or application's visual preference can be met. 
pragmatic constraints. pragmatic constraints can be used to further filter out some of the undesired candidates. like other constraints  pragmatic constraints also arise from a wide variety of sources. we have formulated several types of constraints that are most important to our applications. they come from the following aspects: application situation  including presentation type  targeted audience  and location   available hardware  criticality  and timing. continuing with our patient example  a set of system pragmatic constraints is specified as: 
 appsituation 
 type summary  
 audience nurse  
　　　 location cardiac-icu    hardware  platform pc  
 display medium.resolution & color   
 timing shortjtime  
 criticality critical  
　　more specifically  the system needs to present the patient's summary to a cardiac icu nurse in a short time. 

1 	natural-language processing and graphical presentation 

the presentation will run on a pc with a medium-resolution color display. recall that the candidates left  after screening by both syntactic and semantic constraints  are sense! and sense1. based on figure 1  sense! is eventually chosen over sense1 since sense! meets both timing and hardware constraints. this filtering process is done by checking the list of pragmatic features  e.g.  performance  of each candidate against the pragmatic constraints  e.g.  timing . based on the success of the match  the candidate set is further pruned. 
　　as in ordering different semantic constraints  we also rank those pragmatic constraints based on their importance: 
application situation  criticality  timing  and hardware. 
　　unlike other graphics generation systems  improvise does not require a specific order of constraint satisfaction  e.g.  satisfying pragmatic constraints before syntactic constraints  in its design process. instead  improvise allows the constraints to float with the design process  elhadad et al.  1  and solves them when the time is right. if there is enough evidence to indicate that a constraint is satisfiable  then improvise asserts this fact by taking appropriate actions  e.g.  eliminating unwanted candidates . otherwise  improvise defers its decision until more information is available. 
thus  improvise operates in a least-commitment manner 
 cohen and feigenbaum  1j and avoids unnecessary backtracking over arbitrary decisions. 
visual lexicon instantiation 
　　after a visual word is selected  it will be instantiated once there is enough information to supply parameter values. like selection process  the instantiation also adopts a leastcommitment algorithm: no instantiation is made unless there is enough information. 
　　instantiation involves two steps. the first step is to replace the object variable specified in the object-pattern. this is straightforward: the object variable is replaced  wherever it appears  with the name of the object with which the variable is unified. for example  if variable  patient is bound to patient jones  an expression such as  get-name  patient  will be replaced by  get-name jones . the second step deals with the parameters in a lexeme. for conciseness and efficiency  only key information is explicitly expressed in a lexeme. for example  if text is chosen to represent patient jones's name  the lexeme in the visual word specifies: 
 text1  string  get-name jones    
however  this is inadequate for realizing the name: additional information  such as text font or text color  needs to be supplied. certainly  default values can be provided as part of the knowledge base  as they are in improvise   but default values are not always the desired ones. moreover  different visual words have a different set of parameters and the number of parameters can be large  e.g.  1 to 1 . instead of explicitly expressing all parameters for each word in the visual lexicon  a set of variables is automatically generated to represent those parameters once a word is selected. in our example  the expression is actually expanded as: 
 text1 
 string  get-name jones   
 font font-1  
 color  color-1  
 justification  justify-1   
　　instantiating each variable in this extended format is a challenging task because effectiveness and consistency must be taken into account. effectiveness constraints from various sources restrict the variable to certain values. for example  if the system runs on a very slow platform  it would probably be better to display a 1d graphical model as a wireframe instead of with shaded polygons. thus  the parameter drawmode for this particular graphical model might take value wireframe instead of solid. 
　　unlike most text generation systems that try to use paraphrasing to avoid repetitions  most graphics generation systems try to maintain design consistency by reusing the same visual cues whenever possible  zhou and feiner  1 . unless there is a good reason to do otherwise  similar objects should appear alike in the course of visual presentation. using variables in visual word descriptions eases this task. for example  if a consistency rule asserts that all text objects that represent a patient's name should appear in the same font and color  then all the variables representing font and color in the text can be co-referred  e.g.   font-1 is  font-1  and vice versa . in other words  if any one of them is instantiated  all co-referred variables are instantiated at the same time to the same value. 
　　there are other factors that also need to be taken into account in instantiation; for example  instantiating one variable could affect the instantiation of another. assuming that the current background color is instantiated to blue  then perceptual rules demand that the text color should not be instantiated to red. 
1 conclusions and future work 
　　we have implemented a system that combines a constructive graphics synthesis approach with a parametric graphics synthesis approach. in this paper  we have presented the core component of our parametric approach. a visual lexicon is used to generate visual descriptions for atomic domain objects during synthesis. we have described a comprehensive  general  and extensible formalism to represent the lexical entries. figure 1 summarizes all possible values that are used to describe the syntax and semantics of a visual word. however it is worth noting that some of the values are correlated; for example  if syntactic category takes visual-unity as its value  then its subcategory can never be a table-chart. theoretically  we could encode complex visual representations such as time-chart in a visual word. to retain the flexibility and extensibility of constructive graphics synthesis  we usually construct complex visual presentations from scratch while keeping already-made simple visual representations in the visual lexicon. furthermore  we have formulated a set of constraints to guide the selection and instantiation of the visual lexical items in parametric synthesis. 
　　we believe that this hybrid takes advantage of both parametric and constructive approaches to make graphics generation more powerful  efficient  and flexible. as in a constructive approach  the system is inherently flexible and extensible. as in a parametric approach  we gain efficiency 

syntactic descriptions semantic descriptions slots 
category 
subcate- gory 
medium value description slots 
sense 
role 
s c o p e value description 
label 
list 
plot 
symbol 
portrait 
cluster 
identify 
locate 
distinguish 
proposition 
spatial-relation 
concept-function visual-structure 
table-chart time-chart 
bar-graph line-graph pie-graph 
graphics-model 
graphics-file visual-unity 
image 
video 
text 
1d-shape 
1d-shape 
graphics-model 
graphics-file 
image 
 tiff i rgb i gif i pict  video 
 mpeg1 i sgi i qtime  figure 1. syntactic and semantic descriptions of a visual word 

by providing a reduced search space and facilitate knowledge encoding through reuse of visual words. 
　　several areas could be further improved to make the approach more systematic and comprehensive. one is to use a good computational model  e.g.  a probability model  to describe various constraints more accurately. as most of the constraint values are expressed qualitatively in discrete values  e.g.  short and long describe the timing information   a better model can be used to provide more precise quantitative measurements. probabilistic reasoning  russell and norvig  1  could also be incorporated to aid the generation process and model constraints. last  but not least  the capabilities of each visual word need to be further studied to allow a more comprehensive understanding of various visual forms. 
