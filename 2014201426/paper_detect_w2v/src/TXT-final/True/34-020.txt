 
　　　this paper describes a context mechanism for a natural language understanding system. since no sentence is ever perceived outside some context  it is reasonable to inquire into the nature of context as it affects the interpretation of sentence meaning at a deep conceptual level. a theory  called conceptual oyerl ays  is described. this theory  1  defines c t1   . . .   t i     the context established by the meaningful sequence of thouqhts t1 tj:  1  defines i tj+ 1   c t1  ... t j       the high-level interpretation of ti+i in the context established by t i   . . .   t i ; and  1  specifies an effective algorithm and data structure for computing i t k  for arbitrary thought t in context k. in particular  a prototype lisp system  ex-spectre-1  which solves simple cases of i t1. c t1   is described. the system is based on an expectancy/fulfillment paradigm. expectancies are spontaneously activated by a patterndirected invocation technique. each expectancy implicitly references large chunks of common sense algorithms. a collection of such implicitly activated algorithms constitutes context  and the interpretive process is one of identifying future input as steps in these algorithms. context switching and uses of i t k  in a language comprehension system are discussed. 
introduction 
　　　the goal of this research is to synthesize a domain-independent theory of how context  specifically expectancy  influences perception and interpretation of natural language meaning stimuli. i want here to examine the specific problem of interpreting actions in context  and to describe a general theoretical approach to its solution  because i believe many of the issues of this specific problem overlap with the issues of most other problems of context. 
　　　the statement of the task of interpreting actions in context can be formulated as follows: given a  meaningful  sequence  t1 tj   of syntactically  referentially and conceptually unambiguous sentences  actually  the sequence of thoughts underlying them  expressed in some meaning formalism    assign a meaning interpre-
 * there w i l l be many interesting interrelationships between the present theory and the processes by which meaning is extracted from realworld sentences and perceptions which contain syntactic  referential and conceptual ambiguities. the assumption made here that sentences are unambiguous helps separate the influence of context from the influences of the various other processes. 
tation to the 1st similarly unambiguous sentence 1n a way which elucidates its relationship 
to the context  or situation  established by 
t  tj. 
　　　this task engages four issues:  1  what is a reasonable definition of c t  ...   t j     the context established by t  ti   1  what is a meaningful definition of i t k   the interpretation of sentence t in context k   1  what is the role of inference in the contextual interpretive process  and at what point and to what 
richness are inferences made    1  how do contexts begin  switch  end and interact  this paper concentrates on  1  and  1   describing a method and a prototype system  ex-spectre-l  for obtaining i t1 c t-|    where t1 describes some volitional action by an actor who is acting in the context established by t1. 

1 it is f e l t that the specific mechanisms underlying these four varieties of binary and ternary interaction w i l l prove to be characteristic of many other context-related mechanisms. at the time of w r i t i n g   ex-spectre-l has met the f i r s t and second goals for restricted examples. 
background 
　　　the present theory of conceptual overlays 1s the next step 1n the development of the model of memory and inference described in  r1  and  r1   which proposed that a spontaneous  nongoal-directed substratum of language-independent inference is requisite to even the simplest forms of language comprehension. as w i l l be evident  the present theory of overlays is in accord with the philosophy verbalized by abel son in  a1  and by minsky in  ml  that perceptions and events can be interpreted only within r e l atively large  themes   abelson  or  frameworks   minsky . the theory also relates to the idea of a  demon   used by charniak in  ci   and ties in closely with the goals of schmidt's model of personal causation  s1   which deals with some of the same issues from the point of view of social psychology. 
conceptual overlays 
　　　for the sake of concreteness  acknowledging the potential loss of generality  it w i l l be useful to thread the discussion through the details of one particular example. at least this w i l l connote the main ideas of the theory. the example w i l l be the one used earlier: 
	t1: 	pete stole jake's cattle. 
t1: jake saddled his  jake's  horse. 
the goal 1n this example w i l l be to explain how jake s saddling his horse might relate to pete's act of theft. the theoretical setting 1s a conceptual memory of the sort described in  rl  and  r1   which receives as its input meaning graphs which have been constructed from input sentences by an autonomous parser of the sort described by riesbeck in  r1   and which contains the lowlevel inference reflex mentioned above. in order to communicate some representation-independent ideas  most problems of meaning representation 
w i l l be unabashedly ignored by using englishlike notation. it is assumed that a suitably expressive system of representation  such as schank's conceptual dependency  s1   is used throughout. 
　　　to begin with  we would expect reasonable interpretations of this example to follow the lines:  jake is going after pete to get his cattle back   or  jake is going into town to see the sheriff.  these interpretations relate to this specific t1. of course  there could have been a limitless range of other t 1 's in place of this particular one:  jake sat down and wept   jake took out his r i f l e     'jake smirke-j    pete was arrested next day    jake lingered over his morning coffee in deep thought    pete celebrated   and so forth. the important test of the theory is that it be able to relate these as well. the requirement of the theory is therefore that it provide a format wherein general expectancies can be maintained  providing enough impl i c i t slots so that very diverse subsequent i n put can f i t later. hence the term  overlay  has been used to suggest a superimposable piece of cellulose with boxes drawn on it which say:   i f you see such-and-so occur  here is where it f i t s into the laroer scneme of things at the moment.  action overlays 
　　　entities called action overlays are the vehicles for storing and organizing bundles of expectancies. an action overlay  a  is a data structure consisting of five components:  1  a set of interceptors  1a   1  a universe of potential expectancies   ea   1  an expectancy selector function  sa   1  a set of overlay switchers   wa  and  1  a set of termination handlers! ha. fig. 1 shows an action overlay which relates to acts of theft. fig. 1 is the corresponding lisp data structure in use by ex-spectre-1.  recall that  in principle  the english-liko notation now in use w i l l eventually be replaced by a formal system.  
interceptors 
　　　the set of interceptors  1a  specifies conceptual patterns which can trigger the action overlay. a  of which they are a part. as each new input  t  arrives in the system  either from the sentence analyzer directly  or as an inference from the inference component of the overlay system   the interceptors of every inactive action overlay in the system are compared to t. if at least one interceptor is satisfied  the overlay becomes active. the process of action overlay activation in ex-spectre-1 is therefore a pattern-directed invocation scheme. 
　　　there w i l l be quite a large number of action overlays in a full-scale system  each dealing with some relatively narrow situation and 
its related expectancies. because of t h i s   and since situation descriptions w i l l frequently overlap  more than one action overlay w i l l generally be found applicable to a given input  meaning that several situations are in progress simultaneously. as w i l l be seen  multiple overlays exert their influence concurrently on subsequent inputs. 
　　　in the overlay of fig. 1  only one interceotor has been included. when the input 
 pete steal cattle from jake  
arrives  this overlay is activated in ex-spectre 
1. activation begins by binding x to pete  y to cattle  z to jake  and h to the entire pattern for later reference in the selector function. 
potential expectancies 
　　　ea  the universe of potential expectancies  is a set of  what next  describers which enumerates at a high descriptive level the universe of activities which might possible follow the triggering input without  violating the s p i r i t   of the overlay  and hence cause a switch to another action overlay . the information in fig. 1 associated with the feature universe comprises the set of potential expectancies for this theft overlay. by  violates the s p i r i t   i mean some subsequent activity which would cause the comprehender to be surprised - something which somehow deviates from what is normally expected after a theft. 
1 
　　　to suggest that the range of possible  what next  activities can be captured by a relatively small  enumerable set of expectancies might seem unrealistic. i do not selieve it is. to be sure  there is an i n f i n i t e ange of  what nexts  which is surely impossible to anticipate directly. but the obvious phenomenon of comprehension is that  given any one of the i n f i n i t e l y many subsequent events which might occur or be described next  we are usually able to say in retrospect  yes  that f i t s here in what i was vaguely expecting  and here's how: . . .   so rather than cope with d e t a i l   an expectancy should simply specify the kinds of activities reasonably expected to follow. algorithmic knowledge can 
f i l l out the details  as will be shown. an expectancy simply serves to carve off a manageable chunk of relevant world knowledge from what would otherwise be an enormous  unrestricted potpourri of  what nexts . 
expectancy selector function 
　　　the universe of expectancies simply enumerates potentials; not all members of ea w i l l be equally applicable across all situations  and within a given situation  that i s   the particulars of who stole what from whom   some elements of ea w i l l be more salient than others. consider acts of theft of the form  x steal y from z . 
1 

within this paradigm there are many specific fac tors which can assist in the prediction of the relevance of each potential expectancy in ea. for example  if z already knows x's identity  then his future activities should not be expected to include the determination of x's identity. likewise  such factors as x and z's relationship  student-teacher  husband-wife  jailer-inmate  neighbor-neighbor  etc.   1's belief about x's motivation for the theft  if ascertainable   and the relative value of y to z  will all be good clues for deriding  say  whether z can be expected to attempt a physical get-back of y from x or a psychological retaliation against x  or both. if some sort of retaliation seems in order some notions of degree and kind will be of importance - jake is less likely to stick his tongue out at pete than to break down his fence! fig. 1 contains a partial list of relevant factors for the theft overlay which might be reasonable to include in a larger system. ex-pectre-1 contains only a subset of these tests  as shown in fig. 1. 
     the tests of fig. 1 are made by the expectancy selector function  sa. sa is currently implemented as a  ternary transition network   serving as a discrimination network.  ternary  refers to the characteristic that each node in the net branches three ways:  yes    no  and  don't know . nodes in the net are memory queries and each arc has associated with it a set of saliency setters - assignment statements which specify estimations of the saliency of various elements of ea when the arc is followed. all saliency estimations are preset to 1 out of 1; the net changes only those for which definite clues are present one way or another. 
　　　sa is intended to model the phenomenon wherein a human comprehender seems to acquire some very cursory  rough gestalt of the situat i o n   or in other words  which expectancies in ea are salient and which are not. sa therefore imposes only a rough ordering on ea so that those elements presumed most salient can receive 
more attention in subsequent partof searching to be described. an  incorrect  judgement of saliency w i l l in principle never preclude comprehension; it w i l l simply increase the processing time required to discover relationships lat*v on  and perhaps cause an inability to prefer one interpretation over another in a case where there are several competing interpretations. in a sample run  ex-spectre-1 produced the saliency vector indicated by the dashed lines in fig. 1 for the theft example. 
the expectancy cloud 
　　　having been roughly assessed for saliency  all members of ea are thrown into a central expectancy cloud  ec. each expectancy in ec is backlinked to its contributing overlay  since the cloud w i l l generally contain expectancies from numerous concurrent overlays  and since final interpretations w i l l need to reference the contributina overlay. 
　　　a person is never f u l l y aware at each moment exactly what his expectancies are. apparentl y   an expectancy is a subliminal thing. the cloud  ec  therefore  although explicit and composed of discrete and isolatable expectancies  is intended to model a component in the human which is not part of his immediate awareness from moment to moment  but which in retrospect generally seems to have contained most of the necessary information for contextual interpretation. 
　　　the expectancies in this cloud define the context at each moment in the model. 
stepwise indexed algorithms 
　　　an active expectancy in ec describes some activity which is anticipated to have some chance of occurring at some future point. such an activity can be characterized by a commonsense algorithm  or set of algorithms  where an algorithm is some temporally sequenced  hierarchical collection of subgoals  or steps. as one penertates deeper into the hierarchy  steps become more specific and the alternatives more numerous. as a basic data structure  the and/or graph provides an effective declarative  as opposed to procedural  method of specifying commonsense algorithms.  see  nl  for instance .* 
　　　since an expectancy is an anticipated acti v i t y   and since activities can be represented 
 since the time of first submittal of this paper  a new formalism for representing commonsense algorithms has heen developed and partially implemented. the new formalism renlaces the and/or graph  which lacks the structural constraints needed for representing general commonsense algorithms. see  r1 . 
1 

by algorithms  each expectancy in ec is in fact no more than a pointer to one or more commonsense algorithms; hence each expectancy implici t l y references al assible steps in those algorithms. if a subsequent input  t  can be identified as a step in the algorithms referenced by some expectancy in ec  this identification will relate t to the current context  k  represented by ec  thereby providing an interpretation  i{t k . this relating of an input as a step in some activity which has been anticipated via an action overlay is the central idea of the theory. 
     the collection of commonsense algorithms  the algorithm base  used for the contextual interpretation process is the very same collection of algorithms the comprehender would use in actually getting about in the world  first-hand problem solving . this is a crucial point in my opinion  since it directly brings the world model to bear on the process of comprehending lanquage. 
     however  the interpretive task is the inverse of the executory task; rather than  trans-
late a goal into some plan of action   the task 
1 

is  ascribe a aoal to some observed plan of action   or more specifically  'characterize some observed action as a step in tne attainment of some inferred goal.  because of this difference in use  the data structure used in ex-spectre-1 for storinq commonsense algorithms is an augmented and/or graph which i have called a stepwise indexed algorithm  sia . in an sia  each specific step in the alaorithm is represented by  1  a pointer to a step schema  and  1  r e l evant binding information relating the instance of the schema to the schema. for instance  instead of writing  p goto drugstore  as a step in some algorithm for getting rid of a headache  this goto step  as well as all other goto steps in the entire algorithm base  1s represented by a pointer to the step schema  x goto y   with the appropriate bindings  ir. this case  x:p and y:drugstore. in addition  each step in the sia is  father-linked  to its parent step. this w i l l permit traversing an sia bottom-up  from a step to higher level qoals of which it is a part. 
　　　each step schema is back!inked to each of its occurrences in the algorithm base through its occurrence set. this provides an index into the algorithm base to all points where the schema is referenced. for the  x goto y  schema  this occurrence set would probably be quite large in a full-scale system. hence  finer distinctions among the various types of goto  as one example   based on the specific conceptual features of x and y  would probably have to be made by the indexinq scheme to improve on the search efficiency of the partof function  about to be described. 
　　　fiq. 1 shows the sia and related sted schema for oart of a physical get-back goal  referenced by one of the expectancies in the cattle theft example. 
partof searching upward through sia's 
　　　sia's and step schemas are nut to use as follows. in addition to beinn scanned by the interceptors of all inactive action overlays  each input to the overlay system is matched to some step schema. if the input is unambiguous  and if a suitably formal system of representational primitives is used to represent the meaning of each input  then at most one schema w i l l match each input. in the cattle theft example   jake saddled his horse   represented in ex-spectre-1 as  jake put saddle on horse   matches the step schema  x put y on z . this schema represents the more general concept of an actor putting some object on top of another. 
　　　having matched the input to some schema  the task then becomes one of locating occurrences of that schema in some active expectancy in ec by upward searches from each of the schema's occurrences in the algorithm base. this operation is performed in ex-spectre-1 by calling the function  partof  step    algori thm   for  step  =  x put y on z  and  algorithm  varying over the members of ec  in the order of highest saliency f i r s t . identifications of the schema in some 
member  e  of the cloud define upward paths from the schema to e through sia's. such a path  from a step to an expectancy  is defined to be the 

　　　fig. 1 shows by dotted lines one path of length 1 which ex-spectre-1 discovers as an interpretation of  jake saddled his horse  in c  pete stole jake's c a t t l e     ; jake is going directly after pete to get his cattle back. another interpretation not shown  but which is also discovered  is in the  jake w i l l inform the sheriff  expectancy: jake is going to see the sheriff. 
　　　as a point of engineering  the motivation for searching upward through sia's  from the step schema to the element of ec   rather than downward  from the members of ec to all possible step schema  has to do with the phenomenon that the typical commonsense algorithm tends to become quite specific after just a few levels. that i s   even though the top few levels of an expectancy describe general subgoals  the lower levels beqin quickly to deal with the particular details of the objects and people involved. put another way  the i n f i n i t y of detail in a commonsense algorithm is a phenomenon of breadth rather than depth. because of t h i s   if the occurrence set indexing is refined enough  the number of relevant occurrences of a schema referenced by a particular input can be made quite small. this means that the branching factor in an upward search w i l l be small in comparison with the branching factor coming downward from the expectancy to the step. to i l l u s t r a t e   even though the f u l l occurrence set for the schema  x goto y 
might be large  the subset of occurrences indexed by the particular form  x goto store  would only be 1 or 1 in number  e.g. it occurs in an algorithm for buying something  or returning something  and perhaps one or two others . 
	multiple 	interpretations 
　　　in any given context c t1   . . .  t j     there w i l l generally be several competing interpretations. a human comprehender seems usually to be able to prefer one over the rest. although it is too early in the research to prescribe exactly how such a preference should be made by the 
model  two obvious factors are  1  saliencies of expectancies and  1  interpretation~path length. that i s   a f i t of a step into an expectancy of high saliency should be preferred over a f i t of that step into one of low saliency. in conjunction with t h i s   it would seem reasonable to prefer shorter interpretation paths over longer  more remote ones. in fact  in a full-scale system  it would probably be necessary to have partof give up its scanning after  say  1 levels of some sia; after that point  even if some interpretation could be found  it would almost certainly be obscure. 
　　　related to these ideas is the conjecture that sequences of purposively-constructed communication  say as found in children's stories  are organized so that the average contextual i n terpretation path length w i l l be relatively constant across a l l cultures  relative to a t y p i cal algorithm base within each culture. perhaps the constant is 1  perhaps 1; it would be interesting to ascertain whether or not such a metric 

exists  and if so  to discover its range. that is  on the average  how far do we have to search to connect each thought in with the context  too short and we become red  too long and we become lost. 
uses of i t k  
　　　an interpretation is a useful thing in itself. however  once an interpretation path is discovered  two other context-related operations become possible. first  all steps  to the left  of the identified step  s  in algorithm a those steps which must logically have preceded s in a - can be generated as inferences. that is  if we know that jake has already saddled his horse  and this has been interpreted as part of a physical get-back  then jake must already know who and what x and y were  have decided on some plan of action  perhaps qotten his gun  and gone to the barn. such inferences relate to the 

class of conceptual inference termed  enablement inference  in the model of  rl . 
　　　the second use is that the original highlevel expectancy in ec can be replaced by the set of remaining subgoals in a - those  to the right  of s in a. at that point  the system has begun to  track  a particular algorithm  and can descend from general to more specific expectancies which are the subgoals remaining to be f u l f i l l e d in the original expectancy. this narrowing of expectancies is perhaps a rough approximation of the way expectancies evolve from the general to the specific during the course of a human's comprehension of a story or sequence of events. 
overlay switchers 
　　　in a system which relies upon expectancy as its primary mechanism  it seems to be as important to specify negative expectancies as well as positive ones. that i s   to make explicit what classes of behavior would be  anomalous  in the current context  and to specify what the system should do when it detects an anomaly. 
　　　the switchers  wa  specify these negative expectancies by making explicit a set of patterns which are overtly anomalous in the context the overlay represents. these patterns become active at the time a is i n i t i a l l y activated  and serve as interceptors for subsequent input which  violates the s p i r i t   of the overlay. associated with 
each negative expectancy is a pointer to another overlay to which the system should switch in case that negative expectancy is realized. 
　　　in the prototype system  there are just two switchers for the theft overlay; one of them is:  z be happy : 1verlay1  where 1verlay1 represents the bundle of expectancies relevant to classes of practical jokes. at the time of w r i t i n g   this negative expectancy can intercept anomalous input and prepare to switch  but no switching actually occurs yet. details of how accumulated information can be transfered from one overlay to another have not been considered yet. 
related issues 
　　　there is not room here to discuss all the related topics and questions raised by the conceptual overlay approach to context. for a f u l ler discussion  the reader is referred to the unedited version of this paper and to the new formalism for commonsense algorithms  r1   both available upon request. 
conclusions 
　　　while the task of interpreting actions in context is only one aspect of  the context problem   its applicability is broad; even thouoh much of what we perceive is static information about the world  it usually relates  via r e l atively low-level inference  to some action or another. in this sense  nearly everything relates one way or another to algorithmic knowledge. and within this domain  one basic mechanism is as applicable to understamling why the president summoned the tape-erasing technician as it is to understanding why mary wanted the car keys when she was hungry. 
　　　specific conclusions are not yet in order. however  a general conclusion to be drawn is that algorithms play a central role in the interpretation of volitional actions in context. since algorithms presumably account for a large portion of a person's belief system  the theory is actually one of how interpretation of perceptions is influenced by beliefs. although the issues discussed have of necessity been limited in scope  i believe that the basic idea w i l l prove to be fundamental to most other context phenomena. 
　　　current plans are to continue the development of ex-spectre along the lines of the new commonsense algorithm formalism. then  after seven more prototype version numbers  it w i l l be time to rename the system! 
acknowledgments 
　　　my thanks to dave levy and bob abelson  who taught me about cattle thefts last summer. 
