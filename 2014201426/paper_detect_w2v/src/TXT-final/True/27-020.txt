 
we present new strategies for  probably approximately correct   par  learning that use fewer training examples than previous approaches the idea is to observe training exam pies one-at-a-time and decide  on-line  when to return a hypothesis  rather than collect a large fixed-size training sample this yields sequen tial learning procedures that par-learn by observing a small random number of examples we provide theoretical bounds on the expected training sample size of our procedure - but establish its efficiency primarily by a scries of experiments which show sequential learning ac tually uses many times fewer training examples in practice these results demonstrate that paclearning can be far more efficiently achieved in practice than previously thought 
1 	introduction 
we consider the standard problem of learning an accurate classifier from examples given a target classification scheme x   -  y defined on a domain x  we are interested in observing a sequence of training examples { tl c x1      xt c xt    and producing a hypothesis h x -  y that agrees with c on as much of the domain as possible here we adopt the standard batch training protocol  where after a finite number of training examples the learner must produce a hypothesis h which is then tested ad infinitum on subsequent training examples 
　in practice  domain objects can be represented in many different ways  e g   boolean or real-valued vectors  or structured descriptions like strings  graphs terms  etc   and so too can hypotheses  e g   decision trees  
neural networks  nearest neighbor classifiers  etc   how ever  regardless of the specific representation used  the central question is always how best to extrapolate the classifications of a few domain objects to an accurate classification scheme over the entire domain 
motivation classification learning is by far the most studied in machine learning research the immense interest in this problem arises from the fact that classification itself is an important subtask in many applications - in fact  comprising the central function of 
russell greiner 
siemens corporate research princeton  n j 1  usa greineroscr siemens com 
most expert systems  clancey 1  the importance of /earning in this context is that w  often lack the requisite knowledge needed to specify an appropriate 
classifier  and yet have access lo many correctly classified examples in such situations  we can attempt to exploit the wealth of available data to overcome inadequate prior knowledge and hence use learning as an effective classifier synthesis tool in fact there are numerous examples where learning systems 
have produced classifiers that outperform the best available  hand-coded' systems  c q    le   un et al   1  
weiss and kulikowski  1  
　although empirical research tends to examine the performance properties of particular hypothesis guessing strategies on specific domains  the underlying goal of classification learning research is to uncover whatever general principles might underly the effective extrapolation of training object classifications to entire domains however it has often been observed that there really is no such thing as a genera  purpose extrapolation strat egy  schaffer 1  - a particular strategy performs well on a specific application only by fortuitous predisposition il just happens to 'guess right on unseen domain 
objects  whether by prior knowledge or luck lo guaranttt success one must supply prior constraints 
　the current trend towards theoretical analysis in machine learning represents a fundamental shift in emphasis away from discovering  universal  extrapolation strate gies towards explicitly acknowledging the role played by prior constraints in yielding successful extrapolat ion the role of a theoretical analysis is not to prescribe prior knowledge/constraints hut to determine the best that can be achieved given whatever is known beforehand 
1 	pac-learning theory 
the most influential analysis of classification learning is the theory of 'probably approximately correct   par  learnmg introduced by valiant  rather than spec ulate about the mechanisms that might underly gen 
eral purpose  classification learning valiant's idea was to characterize those situations where successful learning could be provably achieved  and where it is demonstrably impossible 
problem pac-learning theory adopts an  i i d random examples  model of the learning situation  which assumes domain objects are independently generated by 
	schuurmans and greiner 	1 

a fixed distribution px and labelled according to a fixed target concept c under this model  the er ror of a hypothesis with respect to c and px is given by here we consider the 
difficulty of meeting the so-called pac criterion producing a hypothesis h with error at most e  with probability at least 1 - s  for specified accuracy and reliability parameters e and 1 of course  the difficulty of achieving this criterion depends on how much we know about c and pk beforehand pac-learning theory adopts a model of prior knowledge where we assume the target concept c belongs to some known class c but nothing is known about the domain distribution px given this model  we naturally consider what  can be achieved in the  worst case distribution-free' sense 

   for example  we might be interested in solving the problem   where domain objects are described by 1 real-valued attributes  the target concept is known to be some linearhalfspacc of jr.1  and we wish to produce a hypothesis with 1% error with probability at least 1% our goal is to solve these learning problems as efficiently as possible - i. e.  using a minimum of data and computational resources the primary focus of this paper is on improving the data-efficiency of pac-learncr1  rather than their computational- efficiency 
results some of the most important technical results of pac-learning theory concern the data resources needed to solve pac-learning problems intuitively  it should take more training examples to pac-learn a complex concept class than a simple one  since it is harder to disambiguate possible targel concepts from a complex class the question is how can one measure the representational complexity of a concept class c so as to precisely determine the number of training examples needed to pac learn it turns out that just such a measure is provided by the vapnik-chtrvonenhs  vc  dimension of c   ehrenfeucht et al  have shown that  for any concept class c with vc c  - d the minimum number of training examples needed by any learner to learn c is at least 
furthermore there is a simple fixed-sample-size learning procedure  f  that always meets this lower bound tc within constant and log factors and hence learns with near-optimal data-efficiency see figure 1 in particular  blumer et al  have shown that for any1 con-
　　the vcdimension measures how  fine grained  c is by the maximum number of domain objects c can independently label  vapnik and chervonenlas  1l  this in an abstract combinatorial measure which applies to arbitrary domains and concept classes moreover  it often gives intuitive results 
 eg  the class of halfspace concepts on  is defined by n +1  free parameters  and also has a vcdimension of n -+- 1  
c must satisfy certain  benign  measurabibty constraints 
 blumer  et al  1   which we will assume throughout 
learning 
procedure 
collect   training examples sufficient to eliminate all e-bad concepts from c with prob at least 
return any 	that correctly classifies every example 
	figure 1 	procedure f 
cept class random training examples are sufficient to ensure f par learns c  where  this result has since been improved by shawe-taylor ft al  to 
'	o	v	e	r	a	l	l	 	t	h	e	s	e 
arepowerful results as they characterize the necessary and sufficient training sample sizes needed to pac-learn any concept class c in terms of a ' tight  linear function 
of its vc dimension 
1 	issue 
however  despite these impressive results  pac-learning theory has arguably had little direct impact on the actual practice of machine learning why  beyond criticisms of certain modelling assumptions  e g noise-free examples bivalent classifications  which actually have been addressed the pac-framework  cf  haussler  1    the most prevalent criticism of pac-learning theory is that the actual numbers of training examples it demands are far too large to be practical 
e x a m p l e consider the problem mentioned earlier noting that 
vc c  = 1  we can simply use  to determine a sufficient sample size for procedure f but here we find demands 1 training examples'  even the improved demands 1 examples in this rase   this seems like an outrageous number given the apparently modest parameter settings moreover  these results compare poorly to the empirical  rule of thumb  that for a concept class defined by to free parameters  roughly training examples are needed to achieve an er-
ror of e  baum and haussler  1  applied here  demands only 1 training examples - an order of magnitude fewer than   of course  this rule of thumb comes with no guarantees  but it does give an indication of how many training examples practitioners would deem  reasonable  for this problem   furthermore  r e orders o f magnitude larger than the best known lower bound  which demands only 1 training examples in this case' see table 1 in section 1 for a direct comparison 
   this shows that  although the theoretical upper and lower bounds are tight up to constant and log factors  they give results that are orders of magnitude apart in practice this has drastic consequences for the applicability of the theory  since in practice it is often training data  not computation time  that is the critical resource / e   cutting the training sample size in half would be a significant improvement in most applications  even if this came with a slight increase in overall computation time 
　the apparent inefficiency of pac learning has lead to much speculation about the sources of difficulty the 

predominant  folk wisdom  is that the large sample sizes follow from the worst case nature of the parguarantees  haussler  1  - that is  the worst case bounds are inherently unreasonable because they must lake into account  pathological  domain distributions and target concepts which force large training sample sizes  moreover  the argument continues these pathological situations do not arise in ' typical' applications  in fact  this belief motivates much research that makes distributional assumptions in order to improve dataefficiency  e g    benedek and itai  1 aha  et al 1  barllett and williamson  1l  however  notice that this line of reasoning is actually quite weak first of all  no-one can demonstrate that these  pathological' situations really exist  for this would be tantamount to improving the lower bound tehkv  secondly  it is clear from the previous example that the current bounds are loose  and can likely be substantially improved t g 
tstab a-nd tehkv differ by roughly a factor of 1 in approach in this paper we investigate an alternative view perhaps the simplistic  collect find  learning procedure f is not particularly data-efficient this raises the obvious question of whether alternative learning strategies might be more data-efficient than f here we investigate sequential learning procedures that observe training examples one-at-a-time and autonomously deride  online' when to stop training and return a hypothesis the idea is that we should be able to detect situations where an accurate hypothesis can be reliably returned even before the sufficient sample si1c bounds have been reached  c g   we might detect that c has been reduced to a single possible target  the hope is that  in this way  we can significantly reduce the number of training examples  observed  while still meeting the exact same pac-criterion as before namely  that an e-accurate hypothesis be returned with probability at least for any target concept and distribution px an underlying assumption here is that we are willing to incur a slight computational penalty to obtain a significant improvement in data-efficiency this is motivated by the fact that training data is usually the most critical resource in practical learning applications 
　the remainder of this paper develops a few simple sequential learning procedures that  i  are correct pat learners   n  are provably data-efficient  and  iii  use many ttmes fewer training examples in empirical case 
studies 
1 	sequential pac-learning 
a sequential /earner l consists of a stopping rule that maps training sequences to stopping times  and a hypothesizer hl  that maps finite training sequences to hypotheses our basic strategy for constructing sequential pac-learners is to take an arbitrary consistent hypothesizer h for c  which produces hypotheses that correctly classify every observed training example  collect h's hypotheses and test these against subsequent training examples until one proves to have sufficiently small error the main challenge is finding an appropriate stopping rule that guarantees the pac-cntenon  while observing as few training examples as possible 

figure 1 procedure r 
　note that in general a sequential learner observes a random rather than fixed number of training examples thus to compare the data-efficiency of our approach with previous techniques we must comparr a distribu tion of sample sizes to a fixed number there are a number of ways one could do this but we focus on what is arguably the most natural measure comparing the av erage  i e expected  training sample size of a sequential learner with the fixed sample size demanded by previous approaches in solve the same pac-learning problem 
obvious approach perhaps the rnost obvious strat egy for sequential pac learning is based on the ide a of repeated significance testing- test a series of hypotheses generated b  h until one  orrettly classifies a sufficient number of consecutive training examples see procedure r in figure 1 although this is a plaubible approach  which  in fact  works well in prat ticc  it is hard lo prove reasonable bounds on r s expected sample si1  the problem ii that r r jecls  good enough hypotheses with high probability and yet takes a long time to do so  i c   r rejer ts hypotheses of error f with prob bilily 1 - but this takes | expected time  lhus  if h produces a series of ' borderline  hypotheses r will take a long time to terminate  expected time about which is hot very good  fortunately there is a better  approach 
better approach here we introduce a novel learning procedure s  figure i   which is also based on repeated significance testing but avoids the apparent inefficiency of r s survival testing approach s is based on two ideas first instead of throwing away h s hypotheses after a single mistake  s saves hypotheses and continues testing them until one proves to have small error second  s identifies accurate hypotheses by using a se quential probability ratio test  sprt   wald  1  to test each candidate  on-line   in parallel   frigure 1 thus  s never rejects a potentially acceptable hypothesis  and quickly identifies any sufficiently accurate candidate 
　procedure s is a correct pac learner in the exac t same sense as f the key property of s is that its call to sprt eventually accepts any  good hypothesis with proba bility 1  wpl   but only accepts an e-bad hypothesis h  with probability at most  this implies that s even tually halts wpl  and returns an c-good hypothesis with 
　　1  variants of procc dure r have been proposed by many authors in the past  liniual tt al 1  oblow  1   primarily to achieve  nonuniform  pac-learning however  the goals of nonuniform pac-leaming fundamentally differ from what we are trying to accomplish here  see footnote 1  
	schuurmans and greiner 	1 

figure 1 procedure s 
probability at least   for any target concept and domain distribution px  thug  achieving the exact same worst case pac-guarantees as f  1 this property also allows us to prove a reasonable upper bound on the average number of training examples s observes for any target concept cec and domain distribution px 
theorem 1 for  and any  well behaved  concept class c with vc c'  = d using a consistent hy pothesizer h for c and any constant k  i  procedure s observes an average training sample size of at most 
although this is a crude bound  it is interesting to note that it scales the same as moreover  this bound actually beats for small values of s  schuurmans  1j however  as shown below s actually performs much better in practice than any bounds we can prove about its performance since this is not a possibility for fixed-sample-sized approaches  we expect s to perform much better t h a n a n d in practical applications 
　before demonstrating s's advantage in empirical tests  we first note that there are inherent limits to the data-
efficiency even of sequential learning 
theorem 1 for sufficiently small c and 1  and any con cept class c wtth    v    - -  - any learner that al ways observes  for any fixed c ♀ c and yx  an average training sample size less than 
cannot meet the pac 	x 
notice that this lower bound scales the same as in terms of   and vc c  - which shows that no new concept classes become pac-learnable merely by considering a sequential over fixed-sample-size approach 
1
　　provided  details omitted  proofs of all results mentioned in this paper  and more  are outlined in  schuurmans and greiner  1  complete details appear in 
 schuurmans  1  
learning 
figure 1 procedure sprt 
1 	empirical efficiency 
although the theoretical advantage we can demonstrate for s is only slight  we expect s to perform much better m practice than any bounds we can prove about its perfor mance this is because s's actual data-efficiency in any particular case study is determined by the specific case at hand  and not by the worst case situation  or  worse yet  what we can prove about the worst case situation  in fact  in empirical studies  s proves to be far more efficient than any bounds we can prove about its per formance  and many times more efficient than tbehv  or tstab this is easily demonstrated by a simple example 
with the fol 
　　　　　　training objects were generated according to a uniform distribution on  -1  l  n and labelled by a fixed target halfspace  defined by a  diagonal  hyper plane passing through the origin 1  with norm directed towards the constant k was set to 1  so thai and we supplied s with a hypothesizer h 
that finds consistent halfspace concepts 1  we ran procedure s 1 times for n = 1 and obtained the results shown in table 1 notice that s's average training sample size of 1 is about 1 times smaller than tstab   1 times smaller than   and only about 1 timet  larger t h a n i t is important to emphasize that s obtains these empirical sample size improvements while maintaining the exact same worst case pac-guarantees as before  that an c-accurate hypothesis is returned with probability at least these results are in fact representative over the entire range of parameter settings s's empirical advantage actually improves for increased problem dimension n  figure 1   and is maintained at higher accuracy and reliability levels  schuurmans  1  overall  s appears to be pac-learning with near-practical data-efficiency in this example 
　interestingly  s also outperforms the simplistic procedure r on this problem figure 1 shows that  r performs nearly as well as s on easy problems  low dimension  accuracy  reliability   but s's advantage grows significantly as these parameters are scaled up 
   'specifically  we used the bfgs secant optimization procedure  dennis and schnabel  1  with a  relaxation  objective function  duda and hart  1  

explanations these results demonstrate a clear advantage for sequential over fixed-sample-size learning we solve the exact same pac-learning problem using far fewer training examples in this case of course these preceding results are anecdotal  and it is tempting to explain away the advantage as a mere artifact of the specific experimental setup however  we have found that these experimental results are  in fact  quite robust 
　first  the previous experiment only tested a single domain distribution  uniform   which could happen to be a particularly  easy  one for s to counter this claim  we repeated the experiment with various domain distribu tions to see if any could seriously affect s's performance in particular we considered three different transformations of the uniform -1   distribution spherical  nonlinear compression towards origin   pyramidal  compression from opposite corners towards hyperplane  and accretive  translation towards discrete points m { - 1 n  surprisingly  none of these transformations had any noticeable effect on s's performance  sc huurmans  1   as demonstrrted in figure 1 for the pyramidal case 
　a second reason for s's advantage might be that the specific target concept  diagonal halfspace  is a particularly  easy  one for s - i f   h could somehow be biased to guess similar hypotheses however this is easily shown not to be the case we repeated the original experiment on 1 different target halfspaces each successively closer to  axis-parallel  and found that none of these made any appreciable difference  figure 1 
　third  it could be the case that the class of halfspaces  oncepts happens to be 'easy  among classes with comparable vodimension this turns out to be partly true we have been able to construct alternative concept classes which force s to observe slightly more training examples  see figure 1 however  we have yet to devise any roncept class  with the same    dimension  that ran even double s's original performance on halfspaces in fact  s's performance often imprnvts for different concept classes  particularly finite ones  overall  it appears that halfspaces is not a remarkably hard or easy class for a given vcdimension 
another explanation of s s advantage over f is that 
tstab might possibly be a gross overestimate of the true worst case situation  which seems likely given the gap between tstab and tshav  of course  this means that any current advantage enjoyed by s could potentially be overcome by future improvements to tstab - but notice that we can enjoy s s improved performance immediately  without having to wait for theoreticians to improve the bounds  ensuring the correctness of f re-
quires one to prove some bound is sufficient this is not a requirement for procedure s since its correctness is completely decoupled from its. efficiency   
　a final explanation of s s advantage is that sequential learning might be inherently more efficient than fixed sample-size learning clearly since the sequential approach generalizes the fixed-sample-size approach  it can be no worse than f the question is how substantial an advantage can be obtained in principle  this is left largely unanswered by our empirical results and remains an interesting open topic for future research 

after 1 trials  procedure s used 



figure 1 scaling in input dimension n number of training examples observed for  rn halfspaces  t = 1 1 = 1 os  with n = 1 1 1  1  results of 1 runs each   

	schuurmans and greiner 	1 

advantages despite the empirical nature of these re suits  sequential learning holds many clear advantages over fixed-sample-size learning for solving pac-learning problems first  the sequential approach decouples the actual data-efficiency of a pac-learner from the precise bounds we can prove about its performance a pnon thus  the actual data-efficiency of a sequential learner depends on the specifir case at hand  not on what w  can prove about the worst case situation consequent!} the sequential approach automatically takes advantage of beneficial situations like 'easy  target concepts and domain distributions  oblow  1   or a ' good  hypoth csizer that makes lucky guesses -- without the system designer having to explicitly notice that these beneficial situations exist a pnon ' more importantly the true worst case data-efficiency of sequential learning depends on the true worst case convergence properties of the con cept class  not on the particular bounds we happen to be able to prove at the time  i e   if bad concepts are eliminated sooner than proven bounds  then s automatically stops sooner  so in effect we are able to exploit the optimal worst case bounds right now  even though we are unable to prove exactly what tbey are 
computation wc also note that procedure s only introduces reasonable computational overhead over procedure f and in fact is often more computational efficient than rr although  at first glance  s appears to be extremely space-inefficient this rarely amounts to a significant expense in practical applications the point is that  in practice  it is the task of finding consistent hypotheses  calling h  that takes most of the work - storing hypotheses once  found  updating statistics  etc   
does not require much overhead in comparison conse quently  r is often slower than s  even though it uses less space  simply because r lends to call h more often 
	1 	additional results 
special cases we have obtained even stronger results in slightly restricted settings  schuurmans and gremer 1  for example  a variant of procedure s can serve as a sequential ' mistake bounded to pac  conversion procedure that is provably more efficient than litlle 
stone's fixed-sample-size procedure  littlestone  1   and which uses 1 dmes fewer training examples in empirical tests  we also obtain stronger improvements for the case of distribution specific pac-learmng  where we assume the learner knows px  but not the target concept 
 notice that a sequential approach is still possible in this case  and  in fact a variant of procedure s 
can pac-learn concept spaces | using 1 times fewer 
training examples than the best known fixed-sample-size procedure developed in  benedek and itai  1  
	range of applicability 	beyond improving data-
efficiency  sequential learning is also applicable to a much wider range of pac-learning problems than fixed-samplesize learning for example. procedure s can be direclly applied to  nearest neighbor  and  decision-tree  hy pothesizers  like cart  breiman  et al  1   which implicitly consider concept classes of infinite vcdimen sion no fixed-sample-size bound can ever be sufficient 
learning 

in these cases  and yet procedure s can be applied to pac learn these classes  as is   the only catch is that we can no longer place a uniform upper bound on s s expected training sample size 1 
1 	conclusion 
research directions there are numerous directions for future research first  since our empirical results address  artificial  learning problems  it would be interesting to test these procedures on real world' data sets  e g   as contained in the uci repository of machine learning databases  to verify that the same empirical advantages can be realized there another important re search direction is to extend our techniques lo deal with classification noise which remains the main barrier between the results presented here and real applications finally  one can also consider a slightly different learning sconano which perhaps has more practical applications than pac-learning rather than first fixing the accuracy and reliability parameters and then determining suffinent sample size it is much more natural to take a fixed sample size  fix a reliability parameter and produce an estimate of the accuracy achieved by the learner's final hypothesis in this regard we are currently investigat mg a variant of procedure s which produces hypotheses with small  but reliable1  error estimates 
contributions we have described a novr 1 pac-learning pro edurc  s  that uses far fewer training examples than previous approaches procedure s is  in effect generic test  procedure  hat can pac-learn arbitrary ran  ept rlasses c  with finite vc dimension   provided only that we can supply a hypothesizer h that produces consistent concepts from c this procedure introduces little computational overhead and yet substantially reduces the number of training examples needed to pac learn in practice - as demonstrated in numerous case studies where s used many times fewer training examples than the previous best known approaches while still maintaining the exact same worst case pac guarantees 
　in a way these results exploit the empirical advantage demonstrated by practical learning algorithms over the theoretical bounds  to improve the efficiency of paclearmng overall  our results show how pac learning can be far more efficiently achieved in practice than previously thought - countering the claim that pac learning can never be feasibly achieved in real applications 
a c k n o w l e d g m e n t s 
thanks to steven shapiro for his help with the implementations 
　　1  it is important not lo confuse the idea of sequential with nonuniform pac-learning  lima  et al 1  oblow  
1  although nonuniform pac learning procedures also use ' on-bne  stopping rules very similar to r they do not share the same theoretical advantages shown for s sequen tial pac-learning  seeks to obtain a uniform improvement in data efficiency for all cases permitted by our prior knowledge whereas nonuniform pac learning sacrifices data-efficiency in some situations to obtain an improvement in others these two concerns are in fact orthogonal 
