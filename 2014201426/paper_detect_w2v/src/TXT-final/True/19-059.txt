. 
     duce is a machine learning system which suggests highlevel domain features to the user  or oracle  on the basis of a set of example object descriptions. six transformation operators are used to successively compress the given examples by generalisation and feature construction. in this paper duce is illustrated by way of its construction of a simple animal taxonomy and a hierarchical parity checker. however  duce's main achievement has been the restructuring of a substantial expert system for deciding whether positions within the chess endgame of king-and-pawn-on-a1 v. king-androok  kpa1kr  are won-for-while or not. the new concepts suggested by duce for the chess expert system hierarchy were found to be meaningful by the chess expert ivan dratko. an existing manually created kpa1kr solution  which was the basis of a recent phd. thesis  is compared to the structure interactively created by duce. 
1. introduction. 
     it is well recognised  feigenbaum 1  that acquisition of expert knowledge is the major  bottleneck  in expert system development. however  michalski and chilausky  1  and later quinlan  1  have shown that this bottleneck can be considerably eased by generalising low-level data to form high-level rules. shapiro  1  extended this methodology to deal effectively with extensive bodies of knowledge by employing structured programming techniques. thus the expert structures the knowledge in a topdown fashion manually  and then provides examples which can be used to inductively generate each module in the hierarchy separately. using this technique  shapiro and kopec created knowledge structures for correctly deciding a forced win for while in any position within the chess endgames of king-and-pawn v. king  kpk  and king-and-pawn-on-a1 v. king-and-rook  kpa1kr . doth solutions were completely verified by exhaustive computation. however  using an information theoretic approach shapiro showed that around 1% of the endgame knowledge was provided by the expert in the creation of the knowledge structure. thus almost all the work was still being done by the expert rather than by the machine. in an attempt to overcome this structuring bottleneck paterson  1  tried to use the statistical clustering algorithm cluster  michalski and stepp 1  to automatically restructure the knowledge for the simpler of the two endgames  kpk. paterson's results were not promising  with the machine's suggested hierarchy not having any significance to domain experts. 
     in the context of machine learning  michalski  1  has called the problem of originating terms constructive induction. cluster  michalski and stepp 1   perhaps the best known constructive induction algorithm  uses a statistical clustering technique to group objects into conceptual clusters. each object is initially described in terms of a vector of primitive attribute values. objects are grouped using a heuristic inter-object distance metric. rendell  1   and fu and buchanan  1  describe alternative similarity-based approaches to creating taxonomic hierarchies which 
* thii paper describes wort which wasunded in part by the british 
 government's alvey logic database demonstrator. research facilities were provided by he taring institute  glasgow. uk. computational facalities for the prepsrstion of this paper were provided by interact rad corporation  victoria  bc  canada. 
work on much the same basis as cluster. 
1. transformation-based induction. 
     in duce the approach to constructive induction differs considerably from that of michalski and stepp  1   rendell  1   and fu and buchanan  1   and can be more easily compared to the deductive transformational programming techniques of burstall and darlington  1 . durstall and darlington  and later dershowitz  1   suggest that deductive program synthesis can be carried out by gradual truth-preserving transformations of a program specification. at first sight  these techniques seem not to be applicable to inductive inference  which by definition progresses by performing non-truth-preserving generalisations of the supplied training set. however  if each inductive transformation is tested against an oracle which ensures the validity of any transformation  any such inductive transformation is as legal and safe as its deductive counterparts. this use of an oracle is closely related to sammut and banerji's  1  method of learning concepts by asking questions indeed  one of the generalisation operators described in the next section is directly due to sammut and banerji. 
     constructive induction carries out transformations which introduce new terms into the learner's vocabulary. though such transformations can be truth-preserving  they are not what might be called semantics-preserving. thus the primary concern in constructive induction should not be  how can new terms be introduced into the vocabulary ' but rather  how can meaningful new terms be introduced '. again by using an oracle to either name or reject machine-suggested concepts  the difficult philosophical problems involved in defining the word meaningful can be sidestepped. given a meaningful and valid training set  every transformation of which is both meaningful and valid  by agreement of the oracle   the resultant rule set will be meaningful and valid. 

	muggleton 	1 


1 	knowledge acquisition 

truncation  'the truncation operator  like dichotomisalion is intended for use with rule sets containing positive and negative examples of the same concept. however  truncation generalises by dropping conditions. a set of rules which all contain the same head  such as 
this operator generalises in a similar manner to that of the 
aq learning algorithms  michalski and chilausky  1 . its use is restricted by the precondition that the resultant rule  1/1  must not clash  i.e. be inconsistent  with any other rule within the rule base. of all the operators truncation is the only one which reduces the number of rules. all other operators compact the rules by shortening the average rule length. 
     for any stale of a rule base  there arc many possible operator applications. any subset of rules within the rule base r is a candidate for the application of one of the 1 operators. thus the searchspace for the  best  operator application is of size 1  the size of the power set of r. what is meant by a  good  operator application  since each of the operators can reduce the number of symbols in the rule base  duce searches for the application which produces the largest symbol reduction  i.e. occam's razor is applied. if each rule is taken as having a symbol size equal to the number of conjunctive terms in the rule body plus one  for the rule head   then for each operator there exists an equation which can be used to predict the exact symbol reduction for any operator. let r' be a subset of the rule base r and /' be a common subset of all the bodies of rules within r'. in the following equations voperator is the symbol reduction produced when the operator is applied to r'. the total number of symbols within the rule set r' is written as total  r' . the symbol reduction equations arc 
¡¡¡¡note that v1p can take a zero or negative value  in which case there is no symbol reduction. searching for the best operator application is clearly intractable. moreover  there is no guarantee that such an operator application  once found  would be acceptable to the oracle. in ducc the next operator application is chosen using a best first search through the power set of the symbols in the rule base r. let a subset of symbols /' be found among the bodies of the rule set r' where r' is the largest subset of r containing /'. the operator application apply{op  /'  r'   using operator op  is only suggested to the oracle when some /' has been found for which v1p is locally maximal. any rejection of an operator application by the oracle leads to continued search. transformations arc carried out itcralivcly until no further operations can reduce the rule base size further. at termination  by nature of the operators  almost all symbols occur within a restricted number of rules. 'thus  although the termination condition requires searching the entire remaining space the search space has shrunk to manageable proportions. since only operations which reduce the number of symbols arc applied termination is guaranteed. 
     this section illustrates the behaviour of ducc when creating a simple animal taxonomy. figure 1 shows the set of example animal descriptions given to ducc. in english the first example says 
	muggleton 	1 

a blackbird has a beak  is black  has two legs  a tail and wings. 
 blockhead the blackbird is an instance of the  blackbird  concept. 
	note 	the 	inclusion 	of 	the 	instance 	set 
 blockhead the blackbird  within the role. this can be used as a powerful tool for illustrating the meaning of new rules and concepts. figure 1 shows user interaction for this example set. user input is shown in bold type. when asked to induce  duce searches for an operation and suggests an application of the truncation operator which will save 1 symbols. the operation is valid if and only if everything having four legs is an elephant. the user can either answer affirmatively   y    negatively   n   or ask for illustrative examples   i  . if duce is asked for illustrative examples it lists the instances adultclcpliant and babyelcphant. the suggestion although consistent with the limited universe of the examples  is too general  and is rejected. puce continues its search and finds a 
slightly less advantageous truncation  which would save 1 symbols. the new suggestion  that anything with four legs and no wings is an elephant is similarly rejected. there is no particular mechanism for specialising over-generalised hypotheses. this is merely a byproduct of the search mechanism. on the third attempt  duce ques-
tions whether everything that has four legs and a trunk is an elephant. since this is affirmed  duce replaces all elephant rules by the new more general rule and returns to the  !-  prompt. 
     the second generalisation  concerning man is accepted first lime around  producing a saving of 1 symbols. in the third interaction ducc finds that using the interconstruction operator  one symbol can. be saved by defining a new concept for all things which have two legs and no wings. the user can either reject this new concept   n    ask for illustrative examples   i    or give a name for the concept  the name  primate  is given to the concept. duce goes on to suggest another new concept for all things which have a beak  two legs  a tail and wings. this concept is named  bird . when asked to search for another operator application ducc comes back with the message   no applicable transformation   meaning that none of the operators reduce the rule base. the time between each prompt in this 
example is in the order of one second. 
     figure 1 shows the result of the transformations. not only is the rule base more compact but also the new concepts have made the rules more conceptually transparent. for example  a blackbird is simply defined as a bird which is black. note that the illustrative 
examples arc propagated to all new rules. 
1. even-parity. 
     according to minsky and papert  1  the  parity  function is unlcarnable by single-layer perceptions  the even-parity problem is that of recognising whether strings of binary digits contain an 
even number of l's. recent techniques using multi-layered perceptron networks  rumclhart and mcclelland 1  have been shown lo be capable of learning parity effectively. however  in the paradigm of explicit rule formation  algorithms such as 1  quinlan 1  and aq1  michalski and chilausky 1  turn out to be rather inadequate when used to learn such functions. it has been shown  muggleton 1  that whereas single-level concept represen-
tations of parity have a description complexity which is necessarily non-polynomially dependent on the number of attributes  multi-level descriptions can be built whose size is only linearly dependent on the number of primitive attributes. efficient multi-concept solutions inevitably rely on a divide-and-conqucr approach. thus the decision 
of the top-level concept is based on the combination of values of lower-level predicates. each lower-level predicate has a domain which depends on a restricted subset of the total set of problem attri-
butes. 
     figure 1 depicts examples of 1-variable even-parity. the variables  or primitive attributes  are numbered vl to v1  and each it bound to a value from the set {f t}  rather than {1} . in the first example  the variables have even-parky  since all eight have the value t  i.e. an even number of variables arc bound to t. the  eg  part of the example shows a string of this form. figure 1 shows the session in which duce transforms the training set of figure 1 into the partial  hierarchical solution of figure 1. the responses arc based on 
1 	knowledge acquisition 


a standard solution in which the variables arc recursively broken into two equal sized sets at each level. the total set of variables have even-parity if and only if both subsets have even-parity  or both have odd-parity  'the first three concept suggestions do not follow this scheme  and arc rejected. the fourth is recognised as  the second-half of the variables have even parity   sev . 'the user then affirmatively answers questions concerning the application of the absorption operator  the next suggested concept is named ffev or  first-half of the first-half of the variables are even . given the original eight examples  ducc's solution is generalised to cover 1 of the 1 possible instances. if presented initially with the complete instance set  duce tends towards a solution consisting of an 1-ievel deep hierarchy in which levels are used to count the number of variables set to t. 
1. recreation of the kl'a1kr structure. 
     both the animal taxonomy and parity problem have highly restricted domains. the real test of duce's capabilities has been the attempt to restructure shapiro and kopec's expert system  shapiro 
1  for deciding whether positions within the chess endgame of king-and-pawn-on-a1 v. king-and rook  kpa1kr  are won-forwhite or not. the domain contains around 1 positions shapiro generated a database of all positions  labelling each with its minimax backup value of forced win-for-white or not. a set of 1 primitive board features were calculated for each position. since many positions had the same feature vector and won-for-white value  the number of distinct examples was reduced to 1. with this number of examples duce's search-space for applying the first operation is 1  see section 1   or approximately 1. nilsson 
 1  states that the complete game tree for chess has approxi-
1
mately 1 nodes; even that well-known hard problem has a considerably smaller search space than that attempted here. 
     for the purposes of the experiment  shapiro provided a randomly chosen board position for each example. thus the initial rule base given to ducc consisted of examples of the form 
¡¡ wonforwhtte featurel a feature1 a .. feature1  eg  position  two chess experts  ivan dratko and tim niblett  helped in giving oracle answers to questions asked by ducc. the rule base started with 1 symbols. 'the first suggestion reduced 1 of these  a reduction of around 1%. after three questions  around 
1% of the rule base had been reduced. after 1 transformations  the rule base had been reduced to 1 rules  and contained a total of 1 symbols. at this point there were still applicable operations  but symbol reductions had been reduced to the low hundreds. 
     in questions 1 and 1  in which new concepts were introduced  the size of the common set of symbols  int was too large for a comprehensible rule description. it is here that the illustrative board positions were indispensible. for this experiment  a domaindependent graphics front-end was built into ducc  which gave the user the ability to peruse a large number of board positions representing the concept and counter-concept without this graphical device  new concepts could not have been recognised and named as it was  concepts were named with confidence within the presentation of 1 to 1 board positions. it was rarely necessary to reject new concepts and generalisations suggested by ducc in the kpa1kr experiment. 
     figure 1 shows the structure created manually by shapiro and kopec  which took an estimated 1 man months of effort. figure 1 shows ducc's solution. ducc carried out the 1 oracle agreed transformations during a single working day. the computation time between each question was in the order of a minute. it should be noted that where shapiro and kopec have used nine hierarchically arranged concepts  duce has used thirteen. ducc's solution also contains 1 rules and 1 symbols where shapiro and kopec's manually created solution contains the equivalent of around 1 productions and around 1 symbols. although ducc's solution could have been made more compact by applying more transformations or by generating decision trees for each concept using 1  it seems unlikely to the author that this would have resulted in a solution which was as compact as that of shapiro and kopec. 
     by virtue of the operators used by ducc  the kpa1kr solution is guaranteed correct by construction. 
1. discussion. 
     duce in a program which  with the aid of a human oracle discovers useful new concepts. am  lenat 1   an early concept discovery program  was criticised  ritchie and hanna 1  for the obscurity of the techniques involved. unlike am  duce uses a simple and explicit set of six operators to create and refine concepts. in 
	muggleton 	1 

addition the meaning-giving agent  implicitly present within any machine learning system  is explicitly represented as the oracle within ducc. 
     extensive search is used to decrease the number of questions asked by ducc of the oracle. however  in what circumstances is the use of an oracle either justified or feasible  in this respect it is worth noting that on the basis of a meagre number of empirical studies the ratio of oracle rejections to acceptances seems to be inversely related to the percentage of examples provided from the domain. in the parity problem  where duce was supplied with a sparse set of examples  a large number of rejections were necessary  figure 1 . in the more complex kpa1kr chess domain  duce was given an exhaustive set of examples  and required almost no rejections from the oracle. thus it might be expected that in domains in which a moderate amount of example material is available the oracle would need to reject a moderate number of proposals. further research is necessary to show the truth of this hypothesis. 
     duce works with statements in prepositional logic. one way of extending the present work would be to attempt using similar techniques within other representations. danerji  1  is presently looking at the problem of constructive induction within first-order calculus. the author believes that techniques akin to those used in ducc could be profitably employed in learning hierarchically definable context free grammars. 
acknowledgements. 
     i would like to thank donald michie for suggesting the application of duce to the kpa1kr problem. thanks are also due to alcn shapiro for supplying the chess example database  ivan bratko and tim niblctt for acting as chess oracles  pete mowforth for suggesting the name  duce  and michael bain  dave haussler  claude sammut and wray buntine for helpful discussion. 
