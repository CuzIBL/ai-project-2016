 
most of the basic problems in computer vision  as formulated  admit infinitely many solutions. but vision is full of redundancy and there are several sources of information that if combined can provide unique solutions for a problem. furthermore  even if a problem as formulated has a unique solution  in most cases it is unstable. combining information sources in this case leads to robust solutions. in this paper  we combine shading and motion to uniquely recover the light source direction and the shape of the object in view  and we describe how one could combine information sources present in the image in order to achieve uniqueness and robustness of low level visual computations. 
1. prolegomena 
     several problems in human or machine vision  as formulated  admit infinitely many solutions  because the available constraints that relate image properties to the unknown parameters are not enough to guarantee uniqueness. one approach to the solution of these problems is to regularixe them by requiring that the desired parameters satisfy some criteria  basically smoothness . poggio et al.   l       have very successfully shown that several problems in early vision may be  solved  by standard regularization techniques. 
     another approach to the solution of ill-posed problems would be to look for more information sources in order to augment the number of physical constraints and achieve uniqueness of the parameters to be computed. for example  we can combine shading with retinal motion to compute the illuminant source and the shape of the object in view  combine shading with stereo  stereo with motion  texture with contour  and so on  in order to compute three-dimensional scene properties. the results of such an approach are summarized in table 1 for reference. in the ellipses  top  are the different image cues  we take the liberty of calling stereo or motion a cue . by. a cue we mean a source of information  either coming from the image s  or from the particular set-up or condition of the visual system  stereo  motion . in the squares are the results 
that can be obtained  in terms of propositions  when information is combined from two or more cues. two or more different cues are combined with arcs which lead to small circles containing pluses. then  an arc leads from the  plus  to a square containing the result obtained from this combination. 
a part of this work wss done when the author was with the university of rochester  ny  under an ibm predoctoral fellowship. the work was completed at the center for automation research of the university of maryland under grant daab1-k-f1 of the defence advanced research projects agencyand the u.s. army night vision and electro-optics laboratory. the comments of professors a. rosenfeld  c. brown  d. ballard  j. feldman and l. davis are highly appreciated. 
1 	perception 
the interested reader is referred to . in this paper we study only the combination of shading and motion for the computation of the lighting direction and shape. 
1. process of image formation 
     the ability to obtain three-dimensional shape from two dimensional intensity images is an important part of vision. the human visual system in particular is able to use shading cues to infer changes in surface orientation fairly accurately  with or without the aid of texture or surface markings. the direction of illumination is required to be known in order to obtain accurate three-dimensional surface shape from two dimensional shading because changes in image intensity are primarily a function of changes in surface orientation relative to the illuminant  for many of the surfaces in our visual environment. for the purposes of this paper we use the following simple and universally accepted model. assuming orthographic projection  if is the surface normal at a point on the imaged surface  t is the illuminant direction  and  is the flux emitted towards the surface  and we assume a lambertian reflectance function for the surface  the image intensity function is given by  where p is the albedo of the surface  a constant depending on the surface  and     denotes the vector inner product. 
1. motivation and previous work 
     most of the work in shape from shading assumes that the albedo of the surface in view and the illuminant direction are known a priori. the only work done on illuminant direction determination is due to pentland   brooks and horn   brown and ballard  1   and lee and rosenfeld . 
     it is easy to prove that the illuminant direction cannot be recovered from only one intensity image of a lambertian surface without other assumptions. in the sequel  we prove that from two intensity images  moving object or moving observer   with the correspondence between them established  we can uniquely recover the illuminant direction  and thence the shape. in this paper we do not deal with the computation of correspondence  retinal motion . we assume that it has been obtained by some method such as those described in the recent literature. see  1  for detailed references. 
1. technical prerequisites 
     in this section we develop two technical results  one concerning the relationship among shape  intensity  displacements  and the lighting direction  and the other concerning the parameters of a small motion  small rotation  of the shape. we begin with the following theorem. 
theorem it suppose that two views  under rigid motion  of the same lambertian  locally planar surface are given; let i1 


	alolmonos 	1 

for all 1 for 
{get n quadratic equations in b. check if they have a common solution. if yes  output 
     we have implemented the above algorithm and it works successfully for synthetic images. due to lack of space we do not describe them. the interested reader is referred to 
1. computing shape f r o m shading and motion 
     this section discusses the problem of uniquely determining shape from shading and motion. before we proceed  we need some technical preliminaries. 1. the m o t i o n constraint 
proof: 	see  1|. 
1. how to utilise the constraints 
     now we show how to utilize the constraints to recover the three-dimensional shape of the object in view  using shading and motion. it is assumed that the illuminant direction has already been computed using the algorithm described in the previous sections. up to now  we have developed two constraints on shape that also involve the displacements and the illuminant direction. the motion/illumination constraint is a conic in p and q with coefficients that depend on the relative intensities  the displacements  and the illuminant direction  eq. 1 . the motion constraint is again a conic in p and q  with coefficients that depend on the displacement vectors finally  the image irradiance equation  1  
which determines the intensity  at a point of the image as a function of the shape n of the world point whose image is the point  the illuminant direction and the albedo of the surface  is another constraint on p and q that is also a conic. in the sequel we will call the above constraint the image irradiance constraint. it is worth summarizing at this point that we have at our disposal three constraints on the shape p q of a point whose image is the point  each of these constraints is a conic in gradient space. figure 1 gives a geometrical description of the constraints. 
1. c o m p u t i n g shape w h e n the albedo is k n o w n 
     when the albedo is known  we have at our disposal three constraints at every image point for the computation of shape: 
1 	perception 
the motion/illumination 	the motion constraint  say ance constraint  say each of degree two  and their system  barring degeneracy  will have at most one solution. 
   the solution can be easily found by solving the system of equations but if the input is noisy  since this method is local  i.e. shape is computed at every point separately  we might get results corrupted by noise. to avoid this  we adopt an iterative technique  at the expense of assuming that the surface in view is smooth. we prove  however  that our method will converge to a unique solution. we assume that we know the shape at the occluding boundaries. because of the fact that gradient space is unbounded  we use stereographic shape coordinates  . in this case  all possible orientations are contained in a disc of represents an orientation at the occlud-
by 
motion /illumination constraint  for straint and for t = 1 the image/irradiance constraint. the reason why g1 is a function of x and y as well  where x y are the image coordinates  is that the coefficients in for are functions of position in the image plane. 
	trying to find a solution that satisfies 	for 
i = 1  1  1 and is smooth  we wish to minimize the functional 

where d is the unit square region in the  plane  where the image appears  with mesh size m; the surface in view is assumed to have derivatives that are square integrable; and is a constant  regularization  that weights the relative importance of the constraints and smoothness. we follow a standard numerical analysis technique  widely used in the area of partial differential equations  we discretize e by using difference operators instead of differential ones and summations instead of integrals. 
the desired surface is the one that minimizes 
i 
is parallel to the image plane 
we have assumed for simplicity and 
without loss of generality that the boundary is square. the analysis for a nonsquare boundary is very involved  using finite element methodology   and it will not be presented here. 
we can prove that if we choose 
	l. 	-* 
then 	t h e r e exists at most one solution for the minimization problem. 
1.1. learning the regularised algorithm 
     in the previous section we gave an algorithm for computing shape  using the actual constraints and the smoothness of the surface in view. the results depend on the choice of the parameter  and even though any choice of  in an interval will result in a convergent algorithm  it does not mean that the solutions we will get will reflect the reality  physical plausibility . to achieve this  we would have to train the system with examples  so that the best is chosen. a method that can be used for this is the cross-validation technique . another can be found in 
1. computing shape when the albedo is not known see |1 . 
1. implementation and experiments 
     due to lack of space we do not describe our experimental results. the interested reader is refered to . 
1. conclusions and future directions 
     we have presented a theory of how to compute the illuminant direction and shape uniquely from shading and retinal motion. our input consists of two intensity images in a dynamic sequence  with the correspondence between the two frames established. in the past  only the work of grimson  has combined shading with another source of information  in particular stereo. 
     it is clear from the preceding sections that a similar theory can be developed when very general  i.e. not only 
lambertian  reflectance maps are used. it is one of our future oals to extend our theory to reflectance maps that model the lumination due to the sun and sky. 
