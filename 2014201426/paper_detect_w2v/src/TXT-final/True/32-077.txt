 
this paper studies the role of two mechanisms memory and balance - to exploit the arms race resulting from predator-prey interactions when solving a given problem. memory ensures that individuals are not only well adapted to the current members of the opposite population but also to earlier generations of opponents. a balanced  co evolution  on the other hand  adapts the speed of evolution  i.e. the reproduction rate  to the performance of a population. it leads to a steady progress in both populations. indirectly  a balanced  co evolution avoids a premature loss of genetic diversity. this in turn  diminishes the need for a long memory span. the current paper shows how both mechanisms can be incorporated in coevolutionary genetic algorithms  cgas . empirical results support the importance of  and interaction between  both mechanisms. 
1 introduction 
in nature  organisms undergo selective pressures from other organisms - belonging to the same or to other species. predator-prey interactions are a common example of selective pressure between organisms. these interactions are characterized by an inverse fitness interaction: success on one side is felt by the other side as failure to which must be responded in order to maintain one's chances of survival. this typically results in an arms race in which the complexity of both predator and prey increases stepwise. it is a challenge to integrate this mechanism into an evolutionary algorithm in order to further improve its performance. 
　　paredis  provides an overview of the use of coevolution for computational purposes starting from the early days of computing. here  only work directly relevant to the issues of the current paper is discussed. hillis  co-
evolved networks for sorting lists of sixteen numbers. such a sorting network consists of comparisons between two numbers  and the possibility of swapping both numbers . the goal was to find a network  which correctly sorts all possible lists of sixteen numbers  with as few comparisons as possible. hillis used two populations. the first popula-
1 	search 
tion consisted of sorting networks. the individuals in the second population were sets of test-lists. these lists contain numbers to be sorted. both populations were geographically distributed over a grid with each location containing one set of test-lists and one sorting network. at each generation a sorting network was tested on the set of test-lists at the same location. the fitness of a sorting network was defined as the percentage of correctly sorted test-lists. the fitness of the set of test-lists  on the other hand  was equal to the percentage of test-lists incorrectly sorted by the network. this is similar to the inverse fitness interaction between predator and prey. 
　　hillis has shown that - in comparison with traditional non-coevolutionary single population gas - better sorting networks can be obtained. inspired by this work  paredis  1a  introduced a coevolutionary genetic algorithm  cga  which uses a partial but continuous fitness evaluation resulting from encounters between individuals belonging to different species. the first cga was used to train a neural network  nn  on a classification task. next  an abstract class of problems which can be solved by cgas was defined: so-called test-solution problems  paredis 1 . this large class of problems in artificial intelligence and computer science in general  involves the search for a solution which satisfies a given set of tests. 
　　a cga uses two populations to solve test-solution problems. one contains the tests which a solution should satisfy. the other consists of potential solutions to the problem. cgas have been applied to various other test-solution problems  such as: constraint satisfaction  paredis 1b   process control  paredis  1   path planning  paredis and westra  1   and the evolution of cellular automata  ca  for density classification  paredis  1 . the main purpose of the applications described above is to help us understand  explore  and illustrate the operation of cgas. recently  researchers have been using cgas in realworld applications such as object motion estimation from video images  dixon et al  1  and time tabling for an emergency service  kragelund  1 . 
　　some cga applications used a test population whose contents remained fixed over time  kragelund  1; paredis  1a; 1b . in others  both populations fully evolved  dixon et a/.  1; paredis  1; 1; paredis 

and westra  1 . in the latter case  there is pressure on both populations to improve  i.e. the solutions  try  to correctly satisfy as many individuals as possible in the test population. at the same time the tests  try  to make life hard for the solutions. it is not in their  interest  that the problem be solved. especially if there is no solution satisfying all possible tests then the tests might keep the solutions under constant attack. even if there exists a solution satisfying all tests  it might be virtually unreachable given the revolutionary dynamics. this might be caused by the high degree of epistasis in the linkages between both populations. due to such linkages a small change to the individuals in one population might require extensive changes in the other population. this was exactly what happened in the ca application  paredis  1 : the tests were able to keep ahead of the solutions by  jumping  back and forth between two regions - in close proximity of each other - in the space of all tests. after each such jump of the test population  extensive changes to the  genes  of the solutions  i.e. cas  were required in order to satisfy the tests. paredis  provides a simple diversity preserving scheme which prevents the tests from keeping ahead of the solutions. in fact  it achieves this by randomly inserting and deleting individuals from the test population. it also suggests other mechanisms  such as fitness sharing or the use of different reproduction rates in both populations. the latter approach is investigated here. the goal is to obtain a good balance such that there is a steady progress in both populations. this is to avoid the tests from  out-evolving  the solutions and to ensure that there is sufficient variation in the fitness of the members of a population. the latter is necessary to guide  co evolution. 
　　the use of fitness sharing to preserve diversity in a competitive revolutionary context has been investigated by a number of researchers. the othello application of smith and gray  is probably one of the earliest. rosin and belew  combine competitive fitness sharing and shared sampling. the latter ensures that representative opponents are selected for the  competition duels . juille and pollack   1  proposed another way to ensure population diversity: in a classification application  a solution receives a larger reward when it correctly classifies a test which is classified correctly by none  or only a few  of the other solutions. more recently  rosin  has identified the causes why revolutionary progress can come to a halt: the loss of important niches  revolutionary cycles  or a lack of balance. he observed that  even with fitness sharing  solutions might  forget  how to compete against old extinct types of individuals which might be difficult to rediscover. for this reason he introduces a  hall of fame   containing the best individuals of previous generations which are used for testing new individuals. this introduces some kind of memory in the system. in order to keep the progress in both population balanced  rosin  introduces a  phantom parasite  which provides a niche for  interesting  individuals. 
　　the final goal of a cga solving a test-solution problem is to find a solution which satisfies all possible tests. 
any other  victory  of the solution population is only a pyrrhic victory. a solution population whose members satisfy all members in the test-population  but who do not satisfy tests which are unlikely to make their way in the testpopulation  is useless. this is another reason why it is important to preserve the genetic diversity of the test population for long enough a period. 
　　the structure of this paper is as follows. the next section describes the use of cgas for test-solution problems in more detail. section three describes how to obtain a balanced coevolution within a cga and how the memory can be increased. the fifth section evaluates the impact of these mechanisms when solving multimodal problems described in section four. finally  the paper closes with a discussion and conclusions. 
1 cgas for test-solution problems 
as a first step in applying cgas to test-solution problems  both initial populations are filled with randomly generated individuals. their fitness is calculated by pairing them up with 1 randomly selected members of the other population. in order to calculate the fitness of an initial solution  one counts the number of tests it satisfies. similarly  the fitness of a test is the number of solutions  out of a randomly chosen set of twenty solutions  which violate the test. as a matter of fact  each individual - test or solution has a history which stores the fitness feedback - or pay-offresulting from such an encounter. a solution receives a payoff of one if it satisfies the test. otherwise it receives a zero. the opposite is true for tests: they get a pay-off of one if the solution encountered does not satisfy a test. the fitness of an individual is equal to the sum of the pay-offs in its history. it is also good to note that the populations are sorted on fitness: the fitter the individual the higher its rank in the population. 
　　the pseudo-code below describes the basic cycle the cga executes after the initial populations are generated. first  1 encounters are executed in which a test and solution are paired up. the selection of these individuals is biased towards highly ranked individuals  i.e. the fitter individuals are more likely to be selected. in a cga  the most fit individual is 1 times more likely to be selected than the individual with median fitness. next  the actual encounter happens during which it is tested whether the solution satisfies the test it encounters. the result of the encounter is one if it does. otherwise it is zero. this result is also the pay-off received by the solution. the test receives the  inverse  pay-off. the function toggle in the basic cycle implements this inverse fitness interaction between tests and solutions. it changes a one into a zero and vice versa. again  each individual stores the pay-off it receives in its history. at the same time  the pay-off that the individual received least recently is removed from the history. this guarantees that the history will always contain the 1 most recently received pay-offs. this update of the history of an individual  is followed by an update of the fitness of the individual: it is set equal 
	paredis 	1 

to the sum of the pay-offs in its history. because both populations are kept sorted on fitness  an individual might move up and down in its population as a result of the update of its fitness. 
　　after the execution of the encounters  one offspring is generated in each population. this happens as follows. first  two parents are selected from the population  again with the same bias towards fitter individuals as explained above. next   1-point reduced surrogate  crossover and  adaptive  mutation are used in order to generate the child from the bit-string of each of its parents. then the fitness of the child is calculated as the sum of the pay-off received from encounters with 1 selected individuals from the other population. if this fitness is higher than the minimum fitness in the population to which its parents belong then the child is inserted at the appropriate rank location in this population. at the same time  the individual with the minimum fitness is removed. in this way  both populations remain sorted on fitness. 

a couple of remarks are in place here. first  note that in order to avoid unreliable pay-off from possible mediocre offspring  the encounters with new offspring do only result in pay-off for the child  not for the individuals it is encountering. 
　　second  the partial but continuous fitness feedback resulting from the encounters is called life-time fitness evaluation  ltfe . two parameters are associated with it. the first is the size of the histories. the second is the number of encounters per cycle. in all previous cga applications  both parameters are set - quite arbitrarily - to 1. except when mentioned explicitly  this will be the case here too. 
1 increasing the memory and keeping the balance 
this paper investigates whether an increase of the memory of the individuals prevents the two species  solutions and tests  from performing a cyclical dance of changes without really improving their quality. by increasing the memory  individuals which learn new things at the expense of things learned earlier are penalized. the balancing mechanism proposed here is devised to prevent the tests from outperform-
1 	search 
ing too much the solutions. it also ensures that as the solu-
tions get better  more effort is put into finding tests which are not satisfied by the solutions. 
1 memory 
the steady-state character of the cga together with the continuous nature of ltfe provides memory to the individuals. an individual's fitness reflects its performance against members of the opposite population over a period of time. the variant proposed here accumulates the pay-offs received during the entire lifetime of an individual. in this case  the fitness is defined as the number of times a pay-off of one is received divided by the total number of encounters the individual was involved in. this alternative for ltfe is called lifelong fitness evaluation  llfe . with llfe  the fitness of an individual reflects its performance against the members of the opposite population it encountered during its entire lifetime. in this way  there is a selective advantage for individuals to also  beat  members of less recent generations of the opposite population. hence  in comparison with ltfe  llfe increases the memory of the individuals. 
1 	balance 
the need for a balanced evolution immediately raises two questions: 1  how can the cga recognise that the evolution is getting unbalanced  1  once an imbalance is recognised  how can the balance be restored  
　　the answer to the first question is relatively simple: if both populations evolve in a balanced manner then they will receive roughly the same amount of pay-off during the encounters. conversely  the evolution is getting more imbalanced as the pay-off received by both populations is more unequal. 
　　now  the second question can be addressed. what should be done when one population gets considerably more pay-off than the other  somehow the weaker population has to be given a helping hand. its efforts to counter the increasing opposition should be increased. this is done by allowing different reproduction rates in both populations. in the standard cga  two offspring are generated per cycle  one in each population. now  only one offspring will be generated per cycle. the percentage of successes in the last twenty encounters is used to stochastically determine which population evolves. if none of the 1 encounters is successful then the tests may well be too good  i.e. difficult  for the solutions currently in the solution population. hence  the probability that the solution-population evolves  i.e. two parents are selected from it  and if their offspring is fit enough  it is inserted in the solution population  is equal to one. as the percentage of successes increases this probability linearly decreases  see figure 1 . it becomes zero when all encounters are successful. in this case  the probability that the test population reproduces is equal to one. 


figure 1. in order to determine which population reproduces  a real number is uniformly drawn from the interval  1   if this number is smaller than the probability of reproducing a solution then the solution population evolves else the test population evolves. 
1 testing the cga on the p-model 
de jong et al   introduce a simple multimodal problem generator which allows to perform controlled experiments testing the mechanisms described above. as a first step  a set of p random bit-strings of length n is generated. these represent the location of p peaks in a n-dimensional boolean hypercube. the strength1 of an individual is equal to the proportion of bits the string has in common with the nearest peak. when p is equal to one  a single peaked strength-landscape is obtained. for larger p  the modality  as well as the degree of epistasis  increases. 
　　the p-model allows us to test the mechanisms introduced before on problems with different degrees of difficulty. an additional advantage of the p-model - in comparison with  for example  the nk-model  kaufman  1  - is that the optimal value of strength is known: it is one. furthermore  for different p  the variance in strength is not significantly reduced. 
　　in our experiments  the p-model is used as follows. each population  test and solution  has its own set of optima which might be different in location as well as number  i.e. they can have a different value of p. during an encounter  the individual with the highest strength gets a payoff of one  the other receives zero pay-off. these pay-offs are used to calculate the fitness as described in section 1. as was the case for test-solution problems  the pay-offs are restricted to two values  zero and one  instead of just being equal to the respective strengths. this to facilitate the generalization of the conclusions drawn from the experiments described here to test-solution problems in general. note that when the individuals involved in an encounter have the same strength  the solution gets the pay-off of one and the test gets zero pay-off. this to ensure that there exists a solution which beats all tests. ideally  the cga should find this 
individual which has a strength of one. 
1 empirical results 
just as was the case in earlier cga applications  both populations contain 1 individuals. also the same genetic operators are used: reduced surrogate two-point crossover and adaptive mutation. furthermore  n is set equal to 1. in the experiment described here  the degree of epistasis of the test strength landscape is higher than that of the solution landscape. due to space restrictions two other experiments  in which the solution strength landscape has the highest p  or where both populations have the same p value are not reported here. these two additional experiments confirm the conclusions drawn from the experiment discussed here. 
   in the current paper  the performance of 1 cga variants is compared. the name of each variant consists of a triplet. the first part indicates whether ltfe or llfe is used to calculate the fitness of the solutions. the second part represents the type of fitness calculation used for the test population. the third part is either labelled 'trad  or  bal . the former indicates that the traditional  unbalanced  algorithm - as described in section 1 - is used  the latter uses the balanced algorithm. l-t-bal  for example  refers to the balanced variant which uses lifelong fitness evaluation  llfe  for the solution population  and lifetime fitness evaluation  ltfe  for the test population. 
   in order to allow for a fair comparison  all variants generate 1 offspring. this means that the variants with a balanced evolution execute 1 cycles  whereas the  unbalanced  variants - which produce two offspring per cycle execute 1 cycles. in order to ensure that all variants use the same amount of computing time and fitness feedback  the balanced variants perform 1 encounters per cycle instead of 1. 
   the experiment repeats the following steps 1 times. first  a solution strength landscape  p= 1  and a test strength landscape  p= 1  are generated. next  each variant is run on these landscapes. finally  the strength of the highest ranking solution individual of each variant is compared. table 1 summarizes the results obtained. the first column of this table shows how often a given variant produces a highest ranking solution with a strength greater  or equal  than the strength of the highest ranking solution individuals of the other variants. the second column indicates how often it was the second best  etc. table 1 shows  for example  that for 1 out of 1 runs the highest ranking solution individual of t-t-bal has the highest strength. note that the total of all numbers in the first column of the table is above 1. this is because the highest ranking solution of several variants might have the same strength. 
   a couple of observations can be made from the table. first of all  the upper left quadrant of the table  four leftmost columns of the four top rows  and the bottom right quadrant contain small numbers. the large numbers are located mainly in the two other quadrants. or  in other words  the balanced cgas consistently outperform the traditional cgas in which each population evolves at the same rate. 
the balanced variant without llfe  t-t-bal  performs 
	paredis 	1 

best. it is not only 1 times the best of the eight variants. in 1  1 + 1  out of 1 runs it finds the best or second best strength. hence  this indicates that llfe does not bring any improvement  on the contrary. 
1st 1nd 1rd 1rth |1th |1th 1th 1th t-t-trad 1 1 1 1 1 1 1 1 l-t-trad 1 1 1 1 1 1 1 1 t-l-trad 1 1 1 1 1 1 1 1 l-l-trad 1 1 1 1 1 1 1 1 t-t-bal 1 1 1 1 1 1 1 1 l-t-bal 1 1 1 1 1 1 1 1 t-l-bal 1 1 1 1 1 1 1 1 l-l-bal 1 1 1 1 1 1 1 1 table 1: ranking of the strength of the highest ranking solution after 1 runs  see text  
the same picture emerges from table 1 which compares the variants on the basis of the highest solution strength encountered during the entire run. again  the balanced variants outperform the unbalanced ones considerably. once more  t-t-bal is the winner. 
1st  1nd 1rd 1rth 1th 1th 1th 1th t-t-trad 1 1 1 1 1 1 1 1 l-t-trad 1 1 1 
1 1 1 1 1 1t-l-trad 1 1 1 1 1 1 1 1 l-l-trad 1 1 1 1 1 1 1 1t-t-bal 1 1 1 1 1 1 1 1 l-t-bal 1 1 1 1 1 1 1 1t-l-bal 1 1 1 1 1 1 1 1 l-l-bal 1 1 1 1 1 1 1 1 	  	t 	. 	i 	* 	* 
table 1: ranking of the highest solution strength generated during 1 runs  see text  
a third observation is that  at the end of the run of each balanced variant  the solution population always contains at least one individual with the largest strength encountered during the entire run. for  t-t-trad  l-t-trad  t-ltrad  and l-l-trad  on the other hand  this is only true for 1  1  1  and 1 out of 1 runs  respectively. moreover  at the end of a run with a balanced cga  this individual with the highest strength can often be found at 
the top of the solution population. for t-t-bal  l-tbal  t-l-bal  and l-l-bal this is the case in 1  1  1 and 1 out of 1 runs  respectively. this is considerably lower for t-t-trad  1   l-t-trad  1   t-l-trad  1   and l-l-trad  1 . this increased ability of the balanced variants to keep the best individual at the top of the popula-
1 	search 
tion  explains why the difference between the balanced and unbalanced variants is most outspoken in table 1. 
　　finally  let us define a population with a highest fitness smaller or equal to 1 as an extinct population. in none of the 1 runs  a balanced cga variant produced an extinct  test or solution  population. this in contrast with the unbalanced variants. as a matter of fact  extinctions only occurred in populations which used ltfe. out of 1 runs  the solution population of t-t-trad and t-l-trad became extinct 1 and 1 times respectively. extinction of test populations occurred 1 and 1 times. the former when t-t-trad was used. the latter when l-t-trad was used. 
clearly  such extinctions must be avoided because uniform low fitness values do not provide enough information to 
guide coevolution. 
1 conclusions and discussion 
as described in the introduction  other researchers have used fitness sharing to preserve genetic diversity in a revolutionary environment. the balanced cga deals with the direct cause of the loss of diversity: selection. when selection is too severe  the population rapidly converges to a  sub optimum. in a cga  selection occurs through competition between new offspring and individuals already in the population. the balancing mechanism proposed here makes the reproduction rate  and hence the amount of selection  dependent on the success of the population. in this way  the algorithm avoids that the better population  out-evolves  the weaker one. in fact  once an imbalance occurs  the weaker population is allowed to catch up: more search effort is spent on it. this at the expense of the stronger population whose progress - and convergence - is slowed down. 
　　the experiments show that a balanced coevolution results in an increased performance. two reasons can be identified for this success. a first one was already given in the previous paragraph: balanced coevolution maintains genetic diversity. in this way  individuals are confronted with a diverse opposition. secondly  the balancing mechanism  together with the inverse fitness interaction between both populations  ensures that the fitness variance between members of a population is maximal. this because when each population receives about the same amount of pay-off then each population receives roughly as many zero pay-offs as ones. this results in fitness variance which  in its turn  guides  co evolution. in addition to this  the balanced variants maintain the best solutions found  in  the top of  the population. 
　　in the experiments above an increase in memory did not result in increased performance. there is not yet a satisfying explanation for this. possibly the steady-state nature of a cga and the partial and continuous fitness feedback of ltfe provide more than enough memory. note that although ltfe does not take into account pay-offs received more than 1 encounters ago  the very survival of an old individual indicates that it has been able to withstand numerous opponents. alternatively  the type of problems used here might preclude the need for memory. in fact  as indi-

viduals climb the strength-landscape  the set of opponents which beat them monotonically decreases. hence  there is no risk of  forgetting  to beat opponents which were beaten by previous  inferior  individuals. the experiments do  however  suggest a possible relationship between memory and balance: in the absence of a balancing mechanism only populations using llfe could avoid  extinctions . hence  balance does seem to decrease the need for memory. 
　　it is good to look whether nature also  uses  a balancing mechanism. when a predator species becomes too successful then more prey is killed. in the short term  the population size of the prey decreases while that of the predators increases. this puts a natural brake on the growth of the predator species because food  i.e. prey  becomes more and more scarce1. similarly  too effective prey will  on one hand  lead to a rapid increase of the prey population size  which  in its turn  provides a larger food resource for the predators. on the other hand  the predator population size decreases  i.e. the selective pressure to improve increases. hence  in nature  fluctuations in population size keep 
 co evolution in balance. this in contrast with the fixed population sizes in cgas which do not allow for real extinctions of test or solution species. hence  an alternative balancing mechanism is introduced here which adapts the selective pressures through a change of reproduction rates. 
   recently  olsson  1  introduced a balancing mechanism which lets a population evolve until it contains an individual  a  champion   beating all the individuals in the other population. next  the other population evolves until it finds an individual beating all members of the first population. this process is then repeated but at each stage all the previous champions as well as the current members of the opposite population should be beaten. such a mechanism could be introduced in a balanced cga by marking champions. these marked individuals should always remain in the population. 
　　although experiments with different degrees of epistasis support the conclusions given here  other cga applications arc needed to confirm their generality. other balancing mechanisms  for example based on the  difference in  fitness of the individuals instead of on the number of successes during the encounters  might further improve performance. 
