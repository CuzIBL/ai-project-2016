 
the oldest known game tree search algorithm alpha-beta is still the most popular one. all other algorithms in this area fall short of alpha-beta in one or more of the following three desired characteristics - high pruning power  low storage requirement and low execution time. this paper discusses how revisit of nodes can be used effectively in game tree search. a few strategies of introducing revisits in game tree search are presented. it is demonstrated that for any shape and ordering of the game tree to be searched  there always exists one strategy that  on an average  consistently evaluates less number of terminals than alpha-beta in comparable memory and time. 
1. introduction 
in artificial intelligence  game tree search has ever been an active area of interest over years  a number of schemes have been proposed for searching game trees  each having its own advantages and disadvantages. interestingly  the oldest known game tree search algorithm  alpha-beta  is still the most popular one. to judge the effectiveness of any game tree search algorithm  we need to consider three different characteristics of the algorithm - its pruning power  its storage requirement and its execution time. alpha-beta is a recursive depth-first procedure and needs little memory; it is simple to implement and executes rather fast other game tree search algorithms like sss*  stockman  1   scout  pearl  1  and their variations fall short of alpha-beta in one or other respect 
   sss* is best-first and iterative  and consumes a large amount of storage space. although the pruning power of sss* is greater than that of alpha-beta  the improvement is more than offset by its excessive memory and overhead requirements. recently  two recursive variations of sss*  viz.  recsss*   bhattacharya and bagchi  1   and recdual*   reinefeld and ridinger  1   have been proposed. empirical evidence   reinefeld and ridinger  1   shows that both of them dominate alpha-beta so far as terminal nodes examined are concerned  and for any game tree  one of them is always faster than alpha-beta. however  the storage requirement of either is even higher than that of sss*. the cautious test-before-evaluate strategy of scout  pearl  1  is an extension of the alpha-beta algorithm. the evaluation phase is essentially alpha-beta  and the testing phase prior to it is an additional layer on top of alpha-beta  which enhances the pruning power of the evaluation phase. apart from providing an alternative to alpha-beta  scout is important since it introduced the concept of revisits in game tree search. while in alpha-beta and sss* a terminal node in the game tree can be examined atmost once  scout allows revisit of its nodes - once during the testing phase and then  if required  again during the evaluation phase. 
   the purpose of this paper is to show how revisits can be used effectively to examine less number of terminals than alpha-beta in comparable time using affordable amount of storage space. the base algorithm in which different strategies for revisits have been experimented is rather a new algorithm called quickgame. this algorithm was obtained as a special case of the generalized game tree search algorithm gengame  bhattacharya and bagchi  1 . quickgame uses a mix of depth-first and best-first strategies to search the game tree and  for a uniform game tree of depth d and branching degree b  requires about  b * d /1 units of storage space. when run on random trees  on an average  quickgame examines less number of terminals than alpha-beta   bhattacharya and bagchi  1  . 
   however  in practice  the game tree to be searched is very often strongly ordered  i.e.  for any non-terminal node in the game tree the probability that the leftmost child will prove to be optimal for the node is very high. quickgame has the drawback that when run on such strongly ordered game trees  it examines  on an average  many more terminals than alpha-beta. in this paper  we introduce the concept of revisiting a node in the algorithm quickgame. we demonstrate that for any shape and any ordering - random or strong - of the game trees to be searched  there exists at least one version of quickgame which  on an average  examines less number of terminals than alpha-beta in comparable memory and time. 
   we first take a quick look at the algorithm quickgame and its relevant characteristics in section 1. section 1 improves upon quickgame by allowing revisit of nodes and 
	bhattacharya 	1 
discusses the various ways in which revisits can be done. section 1 details our experimental results comparing performances of alpha-beta  quickgamc and its variations on game trees with both random and strong orderings. section 1 concludes the paper. 
throughout the paper the root node s of the game tree 
t to be searched is assumed  without loss of generality  to be a max node. we use d to denote the length of the longest path in t  and b to denote the maximum number of sons that a non-terminal node in t can have  called the branching degree. t is a uniform  b  d  tree if every nonterminal node has exactly b sons  and if every path from s to a terminal node has length d; otherwise it is non-uniform. individual nodes are named using a dewey radix-b code 
 pearl  1   in which the root node is represented by the empty sequence  and the b*   b sons of a non-terminal node x in t as x.i  1   i   b' a static evaluation function v .  scores each terminal node from max's point of view. for any non-terminal node x in t  let tx  be the minimax value of the subtree rooted at x. when x is a terminal node  tx  = v x . 
1. a quick look at quickgame 
in sss*  a global list of nodes called open is maintained  which  at any instant during execution  contains one representative node from each solution tree of the game tree t. the high pruning efficiency of sss* is explained by the fact that all solution trees in t are in contention at every instant but in the process  the size of the global open list rises to b d/1 units of storage space for a  b  d  uniform tree. alpha-beta evaluates more terminals because it does not keep all solution trees in simultaneous contention  but compares in a depth-first scan the current solution tree with the best one found so far. in quickgame  we intend to go for a compromise. quickgame is a recursive procedure that gets invoked only at non-terminal max nodes and at tenninal nodes. below any non-terminal max node p  the subtree rooted at p is split up into as many subtrees as the number of sons of p  and all the solution trees of these subtrees are kept in simultaneous contention. 
   let t be a uniform  b  d  game tree rooted at a max node s. for ease of understanding d can be taken to be even  but quickgame runs just as smoothly on uniform trees of odd depth and on non-uniform trees. let p be a non-terminal max node in t. if quickgame gets invoked at p  it is passed three parameters: the node p  and the two bounds  alpha and beta. the bounds play a role comparable to that in alpha-beta : alpha  the lower bound  is the highest currently known value of all max ancestors of p  while beta  the upper bound  is the lowest currently known value of all min ancestors of p. at the root node s  alpha = and beta = . when quickgame returns from the call at node p  the correct minimax value at p has been found  provided that the 
value lies within the alpha and beta bounds specified in the call. in order to find the best solution tree rooted at p  quickgame uses a local open list of b entries; an entry for a node x in open has two fields  the dewey code for x  and 
1 	automated reasoning 
the current value h x  of x. the node p is expanded  and the b grandsons p.i.1   i   b  enter open  with their h-values initialized to beta p . it is as if the set of solution trees rooted at p is split up into b disjoint subsets  with each subset having a representative in the local open of p. for a node x in the local open  h x  is an upper bound on the minimax value of the subtree rooted at x. quickgame is now recursively invoked on the highest-valued node among these grandsons  ties being resolved in favour of nodes having lexicographically smaller codes. 
   suppose p.i.y is currently the highest-valued node in the local open of p  where 1   i   b and 1   y   b. this node being the representative of the currently most promising subset of solution trees  we explore below p.i.y by invoking quickgame on the node. if p.i.y is terminal  the call returns the minimum over the upper bound on p.i.y and the static evaluation score v p.i.y ; otherwise the call returns the minimax value at p.i.y. on return  if p.i.y is not the rightmost among its brothers we replace p.i.y with its immediate right brother p.i.y+1 which belongs to the same set of solution trees to which p.i.y belongs  p.i.y+1 is the next node to be explored in this set of solution trees if this set is still the most promising one. since p.i is a min node  the minimax value of p.i.y acts as an upper bound on the minimax value of p.i.y+1 and is assigned to h p.i.y+l . alternatively  if p.i.y is rightmost among its brothers  i.e.  y = b-1   when the call on p.i.y returns  we have examined all those solution trees of the subtree rooted at p sharing the common min node p.i. hence the value returned by the call acts as a lower bound on the minimax value of the max node p. so no replacement is made when y is b-1; h p.i.y  in such situation reflects the value of one completely explored solution tree of the subtree rooted at p. the algorithm now selects the current highest-valued node from open  and the entire cycle is repeated  until the node that gets selected has the form p.i.b-1  and quickgame has already been called at this node at some earlier instant in such a situation  since h p.i.b-l  is highest among nodes in open and is the value of a solution tree of the subtree rooted at p  h p.i.b-l  defines the minimax value of p  and the call returns from p to the grandfather of p. since calls are made only at max nodes or terminals  and each call at a non-terminal node involves the use of a local open of b entries  the total storage requirement for all the open lists taken together is about  b * d /1 units. the algorithm is invoked by calling quickgame s  -1 . example 1 : let the 1 = 1 numbers in table 1  see section 1  correspond to the static evaluation scores of the terminal nodes in left-to-right order of a uniform  1  game tree with a max node as root quickgame evaluates 1 of the 1 terminal nodes in the time sequence indicated below the scores. alpha-beta  on the other hand  evaluates 1 of the nodes; owing to its depth-first nature  the terminals get visited in left-to-right order. 
   it is possible to construct examples where quickgame evaluates more terminals than alpha-beta. 
for the  1  1  uniform tree of  knuth and moore  1   
alpha-beta makes 1 terminal node evaluations and quickgame evaluates 1 terminals. 
   thus quickgame must be making some cutoffs not made by alpha-beta  and example 1 verifies this. but example 1 shows that on occasions alpha-beta makes some cutoffs not made by quickgame. 
   the cutoffs made by alpha-beta are of two types  shallow and deep  see  pearl  1  . when a node p1 causes a shallow cutoff below a node p1  the dewey code of p1 must be lexicographically smaller than the code of p1. instead of shallow cutoffs  quickgame makes what may be called generalized shallow cutoffs   bhattacharya and bagchi  1  . these are just like ordinary shallow cutoffs  except that a node q1 can get cutoff either by a node p1 with a code that is lexicographically smaller or by a node p1 with a code that is lexicographically greater. this added generality is a consequence of the use of local opens. it can be shown that for any game tree  all shallow cutoffs made by alpha-beta are also made by quickgame. quickgame can also influence deep cutoffs. but the number of nodes undergoing deep cutoff in quickgame is much less than the corresponding number in alpha-beta. 
   in table 1  the 1th terminal from the left has undergone generalized shallow cutoff while the 1th and the 1th terminals have undergone deep cutoffs in quickgame. in table 1  the two terminal nodes evaluated by quickgame but not by alpha-beta have undergone deep cutoffs in 
alpha-beta. in both tables  all shallow cutoffs made by alpha-beta have also been made by quickgame. 
1. introducing revisits in quickgame 
empirical results demonstrate   bhattacharya and bagchi  1   that quickgame  on an average  evaluates fewer terminals than alpha-beta when run on random trees. but when game trees are strongly ordered  alpha-beta is a much better choice over quickgame. in actual games  the trees generated very often tend to be strongly ordered  and hence alpha-beta will be preferred. is there any way of improving upon quickgame so as to dominate over alpha-beta even in case of strongly ordered trees   
   the dominance of alpha-beta over quickgame in case of strongly ordered game trees can be explained in terms of deep cutoffs. the more strongly ordered the game tree t is  the higher is the probability that the optimal solution tree lies towards the left of t. when run on t  alpha-beta in its strict left-to-right scan of the game tree will encounter the optimal solution tree very quickly  examine all the terminals of it  and the value of the optimal solution tree thus obtained will influence deep cutoffs while scanning the rest of the game tree. stronger the ordering of the game tree  more pronounced is the effect of deep cutoff while running alphabeta on it. quickgame  on the other hand  tries to equitably distribute its search effort among disjoint sets of solution trees  and  in the process  delays complete evaluation of any particular solution tree. as a result  when quickgame is being called on a non-terminal max node p  the alpha bound passed as a parameter is a very poor lower bound on the minimax value of the node p  and hence fewer deep cutoffs occur below p. 
   in short  to make quickgame competitive to alpha-beta for strongly ordered game trees  we have to improve upon its capability to influence deep cutoffs and this can be achieved only by providing improved lower bound while calling quickgame on a non-terminal max node. let p be a non-terminal max node in a  1  d  uniform game tree t and let quickgame be called on p with alpha bound  lb and beta bound  ub. grandsons p.1  and p. 1 will enter open each with an h-value of ub. quickgame will be recursively called on p.1 with bounds lb and ub  and let the call return 
the minimax value o f u b which now becomes the b-value of the replacing node p.1. the next node to be selected from open will be p. 1 and quickgame  p. 1  lb  ub  will be called. it may be noted that when running alpha-beta on the subtree rooted at p  node p. 1 will be called with lower bound  t p.o and upper bound  ub. what happens in quickgame if  instead of lb  we pass h p.1  =  as the alpha bound while calling on p. 1   clearly  since p.o is a min node  hence deep cutoffs below the node p.1 will be even more pronounced than the deep cutoffs influenced by alpha-beta when called on the same node. quickgame  p.1  h p.1   ub  will continue its search until either the minimax value of p.1 has been found out in which case t p.1  and the value returned will be minimum at some point of time during execution the largest h-value 
	bhattacharya 	1 


1 	automated reasoning 

remark 1 : lb  at any instant during the execution of the algorithm  holds the value of the lower bound to be passed in the next call. initially  since all h-values in open are equal  viz.  beta  lb is set to alpha  the lower bound on p. remark 1 : if open k  has not been solved by the call  the node is left in open as it is with its h-value   lb defining a tighter upper bound on the minimax value of open k . remark 1 : tie in the selection of the highest-valued node is resolved in favour of node having lexicographically smaller code. 
remark 1 : the function selectlowerbound determines the lower bound according to one of the strategies described above. depending on the strategy used we get algorithm qg1 or qg1 or qg1. 
example 1 : let us run qg1  qg1 and qg1 on the  1  1  game trees of examples 1 and 1 in that order  tables 1 and 1 respectively . it may be noted here that when the branching degree is 1  most of the times all the three strategies - lowest to the left  lowest among all and second highest - will find the same lower bound. in table 1  all the versions of qg examine the same sequence of terminals as quickgame. in table 1  all the versions of qg examine the same set of terminals as alpha-beta but in a different order. in the  1  1  uniform tree of  knuth and moore  1   both og1 and qg1 examine 1 terminals and qg1 examines 1 terminals compared to 1 terminals and 1 terminals examined by alpha-beta and quickgame respectively. 
   it may be noted that the storage requirement of each of these algorithms is identical to that of quickgame  i e.  b * d/1 units for a uniform  b  d  tree. 
1. experimental results 
the performances of the algorithms alpha-beta  quickgame  qg1  qg1 and qg1 have been compared experimentally on a 1-based vectra 1vl machine. for each  b  d  pair  1 random uniform trees and 1 strongly ordered uniform game trees were generated. a node ordering tells us  for any node x.i in a game tree  the probability that x.i determines the minimax value of x. in a random ordering  all x.i's have equal probabilities. the strongly ordered trees were generated following the suggestion of richard korf . this technique of generating game trees first appeared in  fuller et al.  1 . the scheme is as follows : assign random independent values to the edges of the tree. the static value of a node is computed as the sum of the edge costs from the root to that node. fully expand each node  and then order the children of the node by their static values - increasing order for the children of min nodes  and decreasing order for the children of max nodes.  it makes no sense to fully expand nodes one level above the terminal nodes . following korf s suggestion  the strongly ordered trees have been generated by doing full expansion with sorting all the way down to one level above the terminal nodes. to allow comparisons of different algorithms on the same tree  whenever we needed a random value to be assigned to an edge  we have made use of the static value of the parent node and the tree number  between 1 and 1  to determine the seed for initializing the random number generator. 
   the ordering of the trees thus generated have been found to be marginally stronger than the strongly ordered trees of marsland et al. . for example  when run on one hundred  1  strongly ordered uniform trees generated using both the methods  korf s and marsland's   the average number of terminals examined by alpha-beta is 1 on korf trees and 1 on marsland trees. note that the number of terminals examined is 1 percent of the total number of terminals in the case of korf trees. 
   table 1 compares the number of terminals evaluated and the time taken in seconds by each of the five algorithms. for each  b  d  pair  the number of terminals examined by an algorithm was averaged over 1 uniform trees and rounded off to the nearest integer. for qg1  qg1 and qg1  the terminal count shown is the total number of terminals examined  including revisits. the second column of the table gives the value of b d/1  + b d/1  - 1  the minimum number of terminals that any minimax algorithm has to examine. 
   it may be noted that in our implementation  no time is spent in 'evaluating' a terminal and substantial amount of time is spent in generating the tree in a pre-specified order. this  in turn  implies that in our experiments if an algorithm 
a examines less number of terminals than some other algorithm b in comparable time  one can expect algorithm a to run faster than algorithm b in actual game playing situations. this is because in actual games  terminal evaluation takes significant time and the tree is quite naturally generated in a strongly ordered manner. 
   on the basis of the experimental results given in table 1  the following observations are in order: 
a  on random trees  the performance of quickgame is the best among all the algorithms in terms of average number of terminals examined  execution time  and number of times it examines fewer terminals than alpha-beta. in other words  in actual games  quickgame is expected to run faster than alpha-beta if the tree generated is known to be random. on strong trees  the performance of quickgame is worst among the algorithms. 
b  on strongly ordered trees  the average total number of terminals  including revisits  examined by the algorithm qg1 is consistently less than that of alpha-beta. recall that in qg1 the lower bound passed is the second highest h-value to the left of the selected node in the local open. as expected  on random trees  performance of qg1 is worst among quickgame and its variations due to too many revisits. 
c  the average execution time of qg1  when run on strongly ordered trees  is marginally worse than that of alpha-beta. it may be noted that  since our implementation requires no time to evaluate a terminal  the timings reflect only the overheads of the algorithms. thus the 
	bhattacharya 	1 



overhead of qg1 is marginally higher than that of alpha-beta. 
d  as argued in section 1  no node pruned by alpha-beta will be examined by qg1  although qg1 may need to revisit some of the nodes. in actual games  the time for evaluating a terminal during revisit can be saved by keeping track of the already evaluated terminals in a hashed table. hence  compared to alpha-beta  the total time that would be saved in terminal evaluation by qg1  when embedded in game playing programs  is expected to be more than what is reflected by the difference between the average number of terminals examined by the two algorithms. 
e  considering the observations in  b    c  and  d  above  it is reasonable to expect that in actual games where  i  no special effort is required to generate the tree in strongly ordered manner and  ii  evaluation of a 
terminal takes substantial time  qg1 will run faster than alpha-beta. 
f  between qg1 and qg1  performance of qg1  lower bound passed is the lowest h-value to the left of the selected node  is consistently better than that of qg1  lower bound passed is the lowest among all h-values in local open . on random trees  both qg1 and qg1 perform worse than quickgamc but better than both alpha-beta and qg1. on strongly ordered trees  both qg1 and qg1 perform worse than qg1 and better than quickgamc we conjecture that for some ordering between random and strong  these algorithms will perform better than both quickgame and qg1. 
1. conclusion 
in this paper different strategies for allowing revisits in game tree search have been discussed. it has been shown that on random trees  the algorithm quickgame  which does not allow revisit of a node  outperforms alpha-beta in comparable time and memory. on strongly ordered trees  qg1  which is an extension over quickgame and allows revisits in a specific manner  is a close competitor of alphabeta. the other strategies discussed may prove useful for orderings in between random and strong. 
   we expect that the algorithms discussed will stimulate further research in using revisit of nodes effectively in game tree search. 
