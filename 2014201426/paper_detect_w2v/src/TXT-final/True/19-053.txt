 
we analyze the logical form of the domain knowledge that grounds analogical inferences and generalizations from a single instance. the form of the assumptions which justify analogies is given schematically as the  determination rule   so called because it expresses the relation of one set of variables determining the values of another set. the determination relation is a logical generalization of the different types of dependency relations denned in database theory. specifically  we define determination as a relation between schemata of first order logic that have two kinds of free variables:  1  object variables and  1  what we call  polar  variables  which hold the place of truth values. determination rules facilitate sound rule inference and valid conclusions projected by analogy from single instances  without implying what the conclusion should be prior to an inspection of the instance. they also provide a way to specify what information is sufficiently relevant to decide a question  prior to knowledge of the answer to the question.1 
1 	introduction to the problem 
in this paper we consider the conditions under which propositions inferred by analogy are true or sound. as such  we are concerned with normative criteria for analogical transfer rather than a descriptive or heuristic theory. the goal is to provide a reliable  programmable strategy that will enable a system to draw conclusions by analogy only when it should. 
　reasoning by analogy may be defined as the process of inferring that a conclusion property q holds of a particular situation or object t  the target  from the fact that t shares a property or set of properties p with another situation/object s  the source  that has property q. the set of common properties p is the similarity between s 
　　1 this research was made possible in part by a grant from the system development foundation to the center for the study of language and information  and in part by the office of naval research under contracts n1-c-1 and n1-k-1. the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies  either expressed or implied  of the office of naval research or the united states government. this research was done while the second author was a student in the computer science department at stanford university  supported by a nato studentship from the uk science and engineering research council. the first author is presently also affiliated with the psychology department at stanford university. 
1 	knowledge acquisition 
stuart j. russell 
computer science division 
university of california 
berkeley  ca 1  usa 
and t  and the conclusion property q is projected from 1 onto t. the process may be summarized schematically as follows: 
p s  a q s  
p t  q t . 
　this form of argument is nondeductive  in that its conclusion does not follow syntactically just from its premises. instances of this argument form vary greatly in cogency. bob's car and john's car share the property of being 1 mustang glx v1 hatchbacks  but we could not infer that bob's car is painted red just  because john's car is painted red. the fact that john's car is worth about $1 is  however  a good indication that bob's car is worth about $1. in the former example  the inference is not compelling; in the latter it is very probable  but the premises are true in both examples. clearly the plausibility of the conclusion depends on information that is not provided in the premises. so the justification aspect of the logical problem of analogy  which has been much studied in the field of philosophy  see  e.g.          may be denned as follows: 
the justification problem: 
find a criterion which  if satisfied by any particular analogical inference  sufficiently establishes the truth of that inference. 
specifically  we take this to be the task of specifying background knowledge that  when added to the premises of the analogy  makes the conclusion follow soundly. 
　it might be noticed that the analogy process defined above can be broken down into a two-step argument as follows:  1  from the first premise p s  a q 1   conclude the generalization v.tp .x  =  q x   and  1  instantiate the generalization to t and apply modus ponens to get the conclusion q{t . in this process  only the first step is nondeductive  so it looks as if the problem of justifying the analogy has been reduced to the problem of justifying a single-instance inductive generalization. the traditional criteria for evaluating the cogency of enumerative induction  however  tell us only that the inference increases in plausibility as the number of instances confirming the generalization increases  without counter-examples  and is dependent on the conclusion property being  projectible   see  . if this is the only criterion applied to analogical inferences  then all projectible conclusions by analogy without counter-examples should be equally plausible  which is not the case. for example  if inspection of a red robin reveals that its legs are longer than its beak  a projection of this conclusion onto unseen red robins is plausible  but projecting that the scratch on the first bird's beak will be observed on a second red robin is implausible. a person who has looked closely at the beak of only one red robin will have no counter-examples to either conclusion  and both conclusion properties are projectible  so the difference in cogency must be accounted for by some other criterion. the problem of analogy is thus distinct from the problem of enumerative induction because the former requires a stronger criterion for plausibility. 
　one approach to the analogy problem has been to regard the conclusion as plausible in proportion to the amount of similarity that exists between the target and the source  see  . heuristic variants of this have been popular in research on analogy in ai  see  e.g.  and  . such similarity-based methods  although intuitively appealing  suffer from some serious drawbacks. consider again the problem of inferring properties of an unseen red robin from those of one already studied: the amount of similarity is fixed  namely that both things are red robins  but we are much happier to infer that the bodily proportions will be the same in both cases than to infer that the unseen robin will also have a scratched beak. in other words  the amount of similarity is clearly an insufficient guide to the plausibility of an analogical inference. recognizing this  researchers studying analogy have adverted to relevance as an important condition on the relation between the similarity and the conclusion     . 
　to be a useful criterion  the condition of the similarity p being relevant to the conclusion q needs to be weaker than the rule  fx p x  =  q x   for otherwise the conclusion in plausible analogies would always follow just by application of the rule to the target. inspection of the source would then be redundant. so a solution to the logical problem of analogy must  in addition to providing a justification for the conclusion  also ensure that the information provided by the source instance is used in the inference. we therefore have the following: 
the non-redundancy problem: 
the background knowledge that justifies an analogy or single-instance generalization should be insufficient to imply the conclusion given information only about the target. the source instance should provide information not otherwise contained in the database. 
this condition rules out trivial solutions to the justification problem. in particular  though the additional premise vx p x  =  q x  is sufficient for the truth of the inference  it does not solve the non-redundancy problem and is therefore inadequate as a general solution to the logical problem of analogy. to return to the example of bob's and john's cars  the non-redundancy requirement stipulates that it should not be possible  merely from knowing that john's car is a 1 mustang glx v1 hatchback and some rules for calculating current value  to conclude that the value of john's car is about $1-for then it would be unnecessary to invoke the information that bob's car is worth that amount. the role of the source analogue  or instance  would in that case be just to point to a conclusion which could then be verified independently by applying general knowledge directly to john's car. the non-redundancy requirement assumes  by contrast  that the information provided by the source instance is not implicit in other knowledge. this requirement is important if reasoning from instances is to provide us with any conclusions that could not be inferred otherwise. 
　this seems like an opportune place to draw a distinction between this work and that of many others researching analogy. there has been a good deal of fruitful work on different methods for learning by analogy                in which the logical problem is of secondary importance to the empirical usefulness of the methods for particular domains. similarity measures  for instance  can prove to be a successful guide to analogizing when precise relevance information is unavailable   . however  when studying any form of inference  it behooves the researcher to at least consider what the basis of the inference process might be; for the most part such consideration has been lacking  with the result that analogy systems have yet to demonstrate any wide applicability or reliable performance. our project is to provide an underlying justification for the plausibility of analogy from a logical perspective  and in so doing to provide a way to specify background knowledge that is sufficient for drawing reliable analogical inferences. the approach is intended to complement  rather than to compete with  more heuristic  methods. 
1 	determination rules as a solution 
if we think about the example of the two cars  bob's and john's   it seems clear that  while we may not know what the value of a 1 mustang glx v1 hatchback is prior to knowing the value of bob's car  we do know that the fact that a car is a mustang glx v1 hatchback is sufficient to determine its value. abstractly  we know that either all objects with property p also have property q  or that none do: 

having this assumption in a background theory is sufficient to guarantee the truth of the conclusion q t  from p s a p t aq s  while at the same time requiring an inspection of the source s to rule out one of the disjuncts. it is therefore a solution to both the justification problem and the non-redundancy problem. 
　as a way of describing the relation between p and q in the above disjunction  we might say that p decides whether q is true for any situation x. of course  one 
	davies and russell 	1 

might notice that the background knowledge we bring to the car example is more general in form. specifically  we have knowledge of what is called in database theory a  dependency  relation     that the make  model  design  engine  condition  and year of a car determine its current value. abstractly  a functional dependency is defined as follows   : 

in this case  we say that a function  or set of functions  f functionally determines the value of function s  g because the value assignment for f is associated with a unique value assignment for g. we may know this to be true without knowing exactly which value for g goes with a particular value for f. a taxonomy of the forms for the relation ''f x  determines g :r   has been worked out by researchers in database theory  in which such dependencies are used as integrity constraints   . if the example of bob's and john's cars  cars and carj respectively  from above is written in functional terms  as follows: 

then knowing that the make  model  design  engine  condition  and year determine value thus makes the conclusion valid. in our generalized logical definition of determination  see the section on  representation and semantics    the forms  *  and  **  are subsumed as special cases of a single relation  p determines q   written as 
   assertions of the form  p determines q  are actually quite common in ordinary language. when we say  the irs decides whether you get a tax refund   or  what school you attend determines what courses are available   or  quoting a recent television advertisement   it's when you start to save that decides where in the world you can retire to   we are expressing an invariant relation more complicated than a purely implicational rule. at the same time  we are expressing weaker information than is contained in the statement that p implies q. if p implies q then p determines q  but the reverse is not true  so traditional implication falls out as a special case of determination. that the knowledge of a determination rule is what underlies preferred analogical inferences seems relatively transparent once the problem is set up as we have done. we therefore find it surprising that only recently has the possibility of valid reasoning by analogy been recognized  in   and the logical form of its justification been worked out in a way that solves the non-redundancy propblem  in  . most research on analogy and generalization seems to have assumed that an instance can provide at most inductive support for a rule. our work suggests that rule formation and analogical projection are better viewed as being guided by higher level domain knowledge about what sorts of generalizations can be inferred from 
1 	knowledge acquisition 
an instance. this perspective seems consistent with more recent ai techniques for doing induction and analogy  e.g.    which view such inferences as requiring specific knowledge about relevance rather than just an ability to evaluate similarity. we have concentrated on making the relevance criterion deductive. 
1 	representation and semantics 
to define the general logical form for determination in predicate logic  we need a representation that covers  1  determination of the truth value or polarity of an expression  as in example cases of the form  p x  decides whether or not   formula  *  from previous section    1  functional determination rules like  **  above  and  1  other cases in which one expression in first order logic determines another. rules of the first form require us to extend the notion of a first order predicate schema in the following way. because the truth value of a first order formula cannot be a defined function within the language  we introduce the concept of a polar variable  which can be placed at the beginning of an expression to denote that its truth value is not being specified by the expression. for example  the notation ~ can be read  whether or not p x '  and it can appear on either side of the determination relation sign  in a determination rule  as in 

this would be read  ''p  x  and whether or not p1 x  together jointly determine whether or not q x   where i  and i1 are polar variables. 
　the determination relation cannot be formulated as a connective  i.e.  a relation between propositions or closed formulas. instead  it should be thought of as a relation between predicate schemata  or open formulas with polar variables. for a first order language l  the set of predicate schemata for the language may be characterized as follows. if 1 is a sentence  closed formula or wff  of l  then the following operations may be applied  in order  to 1 to generate a predicate schema: 
1. polar variables may be placed in front of any wffs that are contained as strings in 1  
1. any object variables in s may be unbound  made free  by removing quantification for any part of 1  and 
1. any object constants in s may be replaced by object variables. 
all of and only the expressions generated by these rules are schemata of l. 
　to motivate the definition of determination  let us turn to some example pairs of schemata for which the determination relation holds. as an example of the use of polar variables  consider the rule that  being a student athlete  one's school  year  sport  and whether one is female determine who one's coach is and whether or not one has to do sit-ups. this can be represented as follows: 

example 1: 

as a second example  to illustrate that the component schemata may contain quantified variables  consider the rule that  not having any deductions  having all your income from a corporate employer  and one's income determine one's tax rate: 
example 1: 

　in each of the above examples  the free variables in the component schemata may be divided  relative to the determination rule  into a case set x of those that appear free in both the determinant  left-hand side  and the resultant  right-hand side   a predictor set y of those that appear only in the determinant schema  and a response set z  of those that appear only in the resultant.1. these sets are uniquely defined for each determination rule. in particular  for example 1 they are 
; and for example 
. in general  for a predicate schema free variables x and y  and a predicate schema x with free variables x  shared with   and z  unshared   whether the determination relation holds is defined as follows: 
the definition of determination: 

　in interpreting this formula  quantified polar variables range over the unary boolean operators  negation and affirmation  as their domain of constants  and the standard tarskian semantics is applied in evaluating truth in the usual way  see  . this definition covers the full range of determination rules expressible in first order logic  and is therefore more expressive than the set of rules restricted to dependencies between frame slots  given a fixed vocabulary of constants. nonetheless  one way to view a predicate schema is as a frame  with slots corresponding to the free variables. 
1 	use in reasoning 
much of the work in machine learning  from the early days when shakey was learning macro-operators for action    to more recent work on chunking    and explanation-based generalization     has involved getting systems to learn and represent explicitly rules and relations between concepts that could have been derived from the start. in shakey's case  for example  the planning algorithm and knowledge about operators in strips were a sufficient apparatus for deriving a plan to achieve a given goal. to say that shakey  learned  a specific sequence of actions for achieving the goal means only that the plan was not derived until the goal first arose. likewise  in ebg  explaining why the training example is an instance of a concept requires knowing beforehand that the instance embodies a set of conditions sufficient for the concept to apply  and chunking  despite its power to simplify knowledge at the appropriate level  does not in the logician's terms add knowledge to the system. by defining determination rules prior to the acquisition of case data  we can enable the system to generalize appropriately without making the rules it will generate implicit from the start. 
　determination rules are the kind of knowledge that programmers of an intelligent system often have. we may not know very many specific rules about which coaches instruct which teams  but we still know that the latter determines the former  and this knowledge has the potential to generate an infinite number of more fine-grained rules. in addition to enhancing the power of intelligent systems  the logical formulation of analogical inference enables it to be used reliably in the logic programming and expert system contexts. a logic programming implementation is described in the next section. determination rules may be useful in knowledge engineering for two reasons: 
1. in many domains a strong  implicational  theory may not be available  whereas determination rules can be provided  and the system can gain expertise through the acquisition of examples from which it can reason by analogy. 
1. even when a strong theory is available  its complete elucidation may be difficult  and it may be easier to elicit knowledge using questions of the form  what are the factors which go into making decisions about q  i.e.  to extract determination rules. 
　the use of determination rules appears to be a natural stage in the process of knowledge acquisition  occurring prior to the acquisition of a strong predictive theory; for example  we have as yet no theory that can even come close to predicting the vocabulary  grammar and usage of an entire language simply from facts about the nation it belongs to  but we still have the corresponding determination rule that one's nationality determines one's native language  with a few exceptions. we have been building a list of different categories of determinative knowledge. here are some examples of processes in which determination rules are found: 
  physical processes: initial conditions determine outcome; boundary conditions determine steady-state values for whole system; biological ancestry determines gross physical structure;' developmental environment determines fine structure of behavior; strucdavies and russell 1 
ture determines function; function determines structure  less strongly ; disease determines symptoms; symptoms determine disease  less well ; diet  exercise and genes determine weight; etc. 
t processes performed by  rational agents : case description determines legal outcome; upbringing and education determine political leaning; social class and location determine buying patterns; nationality determines language; zip code determines state; address determines newspaper delivery time; etc. 
  processes in formal systems: program input deter-mines program output; program specification determines program; etc. 
  the system's own problem-solving processes: all the problem solving abilities the system has  be they planning  search  inference  programming or whatever  can be analyzed into an input p and an output q. constructive processes  such as planning and design  which have enormous search spaces  are particularly amenable to reasoning by analogy.   begins to address these issues  implicitly using the determination rule that  exact  problem specification determines solution; the key issue to be resolved before such work can succeed is to identify the various abstracted levels of description for problems and solutions which will allow use of less specific determination rules that do not require exact matching of specifications.  
1 i m p l e m e n t a t i o n i n a l o g i c p r o g r a m m i n g s y s t e m 
determination-based analogical reasoning can be implemented directly as an extension to a logic programming system  such as genesereth's mrs system  see  . the programmer simply adds whatever determination rules are available to the database and the system will use them whenever possible to perform analogical reasoning. 
　given a query x t  z   the basic procedure for solving it by analogy is as follows: 

1. backchain on an applicable implication rule. 
1. analogize using an applicable determination rule. 
　to solve goal x t z  using determination rule x  x z   we simply add the following conjunctive goal to the agenda: 

the subgoals of this can be solved recursively by the same three alternative methods  thus achieving the procedure given above. 
　an example may be helpful here. suppose we have the goal of finding out what language jack speaks  i.e.  nativelanguage  jack  z . we have the following background information: 

and among our determination rules we have that nationality determines native language  except for swiss   as well as other such rules  for instance that nationality and whether or not one has dual citizenship determines whether or not one needs a visa to enter the united states and how long one may stay: 


1 	knowledge acquisition 

using the first of these determination rules  the system generates the new goal: 

which is solved after a few simple deduction steps  with jill as the source s. one may observe that the more  similar  source giuseppe is ignored  and that the irrelevant facts about jack and jill are not examined. when the facts satisfying the various subgoals of the analogy are not explicitly available in the database  the system will of course attempt solutions by further reasoning  either analogical or implicational. for example  if nationalitv jill uk  

were replaced by birthplace jill  london   then the analogy could still succeed if a rule relating birthplace and nationality were available. thus we have a natural  goaldirected reformulation which reveals implicit similarities in an efficient manner. 
　in comparison to the more traditional  heuristic approaches to analogy  the use of determination rules has significant efficiency advantages in addition to its other properties. winston    and greiner    point out the enormous complexity of matching the target against all possible sources in all possible ways to find out the most similar source; as we observed in the implementation example  finding the determination rule first enables us to pick out the relevant target facts and use those to index directly to an appropriate source  thus overcoming the matching problem. we also render irrelevant the problem of finding a suitable similarity metric  and transform the reformulation problem  which arises when a change of representation might reveal a previously hidden similarity  from an open-ended nightmare of forward inference into a relatively controlled  goal-directed process. 
　the ability of determination-based analogical reasoning to avoid unnecessary matching makes it a reasonable alternative to traditional rule-based logic systems. for some problems  analogy is more efficient than using a corresponding set of implication rules. a determination rule  and a set of instances replace a set of 
implication rules: 

where n can be arbitrarily large. furthermore  since it must test the premises of every rule that could imply a goal until it finds the right one  a backward chaining system requires a lengthy search that can be avoided by using a determination rule. 
　a common form of reasoning that displays this behavior is taxonomic inheritance  for which we might use a rule such as 

to conclude the current resale value of one of our cars. with 1 models in our database  this would take us 1 backchains on average. replacing the implication rules with a determination rule isa x  y    value ln 1  x z  and a collection of prototypical instances  exactly analogous to the typicalelephant frames in semantic nets  we can solve our goal in four backchaining steps. 
　another example is that of diagnostic reasoning  in which the  simplified  traditional approach uses a collection of rules of the form: 

1 	c o n c l u s i o n 
there are a number of problems related to analogy that we have not solved. what we have is a method for generating correct generalizations and analogical inferences  given correct determination rules. at the same time  our work has created new problems: a reasonable next step is to work out how determination rules can themselves be acquired. some early thought on the determination rule acquisition problem points to four basic methods: 
1. deduce a determination rule from other known facts  for an example  see  . 
1. induce a determination rule from instances  essentially calculate the empirical degree of determination 

1. induce a determination rule from a collection of specific rules. 
1. generalize from a collection of more specific determination rules. 
　because we have a formal definition for determination  inductive acquisition of determination rules is conceptually straightforward  if pragmatically troublesome. acquisition experiments on a broad knowledge base are currently under way using the cyc system   . we are also building determination-based expert systems by induction from examples in the domains of market forecasting and mechanical device diagnosis from acoustic emission. the results so far seem very promising. 
　a full understanding of the human processes of analogical inference and generalization will surely require further investigations into how we measure similarity  how situations and rules are encoded and retrieved  and what heuristics are used in projecting conclusions when a valid argument cannot be made. but it seems that logic can tell us quite a lot about analogy  by giving us a standard for evaluating the truth of its conclusions  a general form for its justification  and a language for distinguishing it from other forms of inference. at the same time  we have found a consideration of the logical problem to be of practical benefit  for reasoning by analogy using determinative knowledge appears to give a system the ability to learn reliably new rules that would otherwise need to be programmed. 
1 	a c k n o w l e d g m e n t s 
we would like to thank our advisors  john perry  mike 
genesereth  and doug lenat  as well as doug edwards  bryn ekroot  russ greiner  benjamin grosof  david helraan  jerry hobbs  dikran karagueuzian  kurt konolige  stan rosenschein  devika subramanian  dirk ruiz  amos 
tversky  paul rosenbloom  and j. o. urmson for fruitful discussions  constructive criticism and moral support. 
	davles and russell 	1 
r e f e r e n c e s 
 burstein  m. h. a model of incremental analogical reasoning and debugging. in proceedings of the national conference on artficial intelligence  1  pp. 1. 
 carbonell  j. g. a computational model of analogical problem solving. in proceedings of the seventh international joint conference on artificial intelligence  1  pp. 1. 
 carbonell  j. g. derivational analogy and its role in problem solving. in proceedings of the national conference on artificial intelligence  1  pp. 1. 
 carbonell  j. g. derivational analogy. in michalski  r. s.  carbonell  j. g.  and mitchell  t. m.  editors  machine learning ii  morgan kaufmann  1. 
 carnap  r. logical foundations of probability. university of chicago press  1. 
 davies  t. analogy. undergraduate honors thesis  stanford university  1. issued as informal note 
no. in-csli-1  center for the study of language and information  stanford university  1. 
 davies  t. r. a normative theory of generalization and reasoning by analogy. to appear in helman  david h.  editor  analogical reasoning: perspectives of artificial intelligence  cognitive science  and philosophy  d. reidel  forthcoming. 
 gallier  j. h. logic for computer science: foundations of automatic theorem proving. harper and row  1. 
 genesereth  m. r. and nilsson  n. j. logical foundations of artificial intelligence. morgan kaufmann  in press. 
 gentner  d. structure mapping: a theoretical framework for analogy. cognitive science  1-1  1. 
 goodman  n. fact  fiction  and forecast. harvard university press  1. 
 greiner  r. learning by understanding analogies. ph.d. thesis  stanford university  1. issued as 
technical report no. stan-cs-1  department of computer science  stanford university  1. 
 hesse  m. models and analogies in science. notre dame university press  1. 
 holland  j.  holyoak  k.  nisbett  r.  and thagard  p. induction: processes of inference  learning  and discovery. mit press  1. 
 kedar-cabelli  s. purpose-directed analogy. in the seventh annual conference of the cognitive science society  1  pp. 1. 
1 	knowledge acquisition 
 leblanc  h. a rationale for analogical inference. philosophical studies  1-1  1. 
 lenat  d. cyc: using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks. the ai magazine  1-1  1. 
 is  marciszewski  w. dictionary of logic as applied in the study of language. martinus nijhoff publishers  1. 
 mill  j. s. a system  of logic. harper and brothers publishers  1. 
 mitchell  t. m.  keller  r. m.  and kedar-cabelli  s. t. explanation-based generalization: a unifying view. machine learning  1   1. 
 nilsson  n. j. shakey the robot technical note 1  artificial intelligence center  sri international  menlo park  ca  1. 
 rosenbloom  p. s.  and newell  a. the chunking of goal hierarchies: a generalized model of practice. in michalski  r. s.  carbonell  j. g.  and mitchell  t. m.  editors  machine learning ii  morgan kaufmann  1. 
 russell  s. j. the compleat guide to mrs. technical report no. stan-cs-1  department of computer science  stanford university  1. 
 russell  s. j. a quantitative analysis of analogy by similarity. in proceedings of the national conference on artificial intelligence  1  pp. 1. 
 russell  s. j. analogical and inductive reasoning. ph.d. thesis  stanford university  1. 
 russell  s. j.  and grosof  b. n. a declarative approach to bias in concept learning. in proceedings of the national conference on artificial intelligence  1. 
 shaw  w. h. and ashley  l. r. analogy and inference. dialogue: canadian journal of philosophy  1-1  1. 
 ullman  j. d. principles* of database systems. computer science press  1. 
 vardi  m. y. the implication and finite implication problems for typed template dependencies. technical report no. stan-cs-1  department of computer science  stanford university  1. 
 weitzenfeld  j. s. valid reasoning by analogy. philosophy of science  1-1  1. 
 wilson  p. r. on the argument by analogy. philosophy of science  1-1  1. 
 winston  p. h. learning and reasoning by analogy. communications of the acm  1-1  1. 
　　　1 readers familiar with statistical modeling might notice that the terms for these sets of variables are borrowed from regression analysis. for a discussion of the statistical analogue of determination  and its relations to regression and classification  see  
   ---------------

   ------------------------------------------------------------

---------------

------------------------------------------------------------

