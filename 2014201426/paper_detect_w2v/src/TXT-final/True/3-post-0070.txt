
we present an efficient dynamic programming algorithm for synchronous parsing of sentence pairs from a parallel corpus with a given word alignment. unless there is a large proportion of words without a correspondence in the other language  the worstcase complexity is significantly reduced over standard synchronous parsing. the theoretical complexity results are corroborated by a quantitative experimental evaluation.
our longer-term goal is to induce monolingual grammars from a parallel corpus  exploiting implicit information about syntactic structure obtained from correspondence patterns.1here we providean importantprerequisiteforparallel corpusbased grammar induction: an efficient algorithm for synchronous parsing  given a particular word alignment  e.g.  the most likely option from a statistical alignment .
synchronous grammars. we assume a straightforwardextension of context-free grammars  compare the transduction grammars of  lewis ii and stearns  1  :  1  the terminal and non-terminal categories are pairs of symbols  or nil ;  1  the sequence of daughters can differ for the two languages; we use a compact rule notation with a numerical ranking for the linear precedence in each language. the general form of a rule is n1/m1 ¡ú n1:i1/m1:j1 ...nk:ik/mk:jk  where nl ml are nil or a  non- terminal symbol for language l1 and l1  respectively  and il jl are natural numbers for the rank in the sequence for l1 and l1  for nil categories a special rank 1 is assumed . compare fig. 1 for a sample analysis of the german/english sentence pair wir mussen¡§ deshalb die agrarpolitik prufen¡§ /so we must look at the agricultural policy. we assume a normal form in which the right-hand side is ordered by the rank in l1 the formalism goes along with the continuity assumption that every complete constituent is continuous in both languages.1
synchronous parsing. our dynamic programming algorithm can be viewed as a variant of earley parsing and generation  which again can be described by inference rules. for instance  the central completion step in earley parsing can be described by the rule1
 1  hx ¡ú ¦Á   y ¦Â  i j i  hy ¡ú ¦Ã    j k i

hx ¡ú ¦Á y   ¦Â  i k i
¡¡the input in synchronous parsing is not a one-dimensional string  but a pair of sentences  i.e.  a two-dimensional array of possible word pairs  or a multidimensional array if we are looking at a multilingual corpus . the natural way of generalizing context-free parsing to synchronous grammars is thus to use string indices in both dimensions. so we get inference rules like the following  there is another one in which the i1/j1 and j1/k1 indices are swapped between the two items above the line :
 1  hx1/x1 ¡ú ¦Á   y1:r1/y1:r1 ¦Â  i1 j1 j1 k1 i  hy1/y1 ¡ú ¦Ã    j1 k1 i1 j1 i

hx1/x1 ¡ú ¦Á y1:r1/y1:r1   ¦Â  i1 k1 i1 k1 i
¡¡since each inference rule contains six free variables over string positions  i1 j1 k1 i1 j1 k1   we get a parsing complexity of order o n1  for unlexicalized grammars  where n is the number of words in the longer of the two strings from l1 and l1   wu  1; melamed  1 .
correspondence-guided parsing. as an alternative to standard  rectangular indexing  we propose an asymmetric approach: one of the languages  l1  provides the  primary index  - the string span in l1 like in monolingual parsing. as a secondary index  l1 contributes a chart-generationstyle bit vector of the words covered  which is mainly used to guide parsing - i.e.  certain options are eliminated. a complete sample index for mussen¡§ /must in fig. 1 would be h 1  i. completion can be formulated as inference rule  1 .1 condition  iii  excludes discontinuity in passive chart items  i.e.  complete constituents; active items  i.e.  partial constituents  may well contain discontinuities.
 1  hx1/x1 ¡ú ¦Á   y1:r1/y1:r1 ¦Â h i j  vii  where hy1/y1 ¡ú ¦Ã   h j k  wii

hx1/x1 ¡ú ¦Á y1:r1/y1:r1   ¦Â h i k  uii
 i  j 1= k;	 ii  or v w  = u;
 iii  w is continuous  i.e.  it contains maximally one subsequence of 1's .s/s
np:1/np:1
pron:1/pron:1
	wir/we	mu¡§ssen/must	deshalb/so	nil/at	die/the	nil/agricultural agrarpolitik/policy	pru¡§fen/look
figure 1: sample analysis for a synchronous grammarparsing is successful if an item with index h 1 n  1i can be found for the start category pair  where n is the length of the
l1-string .
¡¡words in l1 with no correspondent in l1  let's call them  l1-nil s for short  can in principle appear between any two words of l1. therefore they are represented with a  variable  empty l1-string span like for instance in h i i  i. but note that due to the continuity assumption  the distribution of the l1-nils is constrained by the other words in l1  as exploited in the inference rule:
 1  hx1/x1 ¡ú ¦Á   nil:1/y1:r1 ¦Â h i j   vii  where hnil/y1 ¡ú ¦Ã   h j j  wii

hx1/x1 ¡ú ¦Á nil:1/y1:r1   ¦Â h i j  uii
 i  w is adjacent to v  i.e.  unioning vectors w and v does not lead to more 1-separated 1-sequences than v contains already ;  ii  or v w  = u.
the rule has the effect of finalizing a cross-linguistic constituent after all the parts that have correspondents in both languages have been found.
complexity. we assume that the two-dimensional chart is initialized with the correspondences following from a word alignment. hence  for each terminal that is non-empty in l1  both components of the index are known. when two items with known secondaryindices are combinedwith  1   the new secondary index can be determined with minimal expense. thus  for sentence pairs without any l1-nils  the worst-case complexity for synchronous parsing is identical to the monolingual case of context-freeparsing  i.e.  o n1  . the average parsing expense in the absence of l1-nils is even lower than in monolingual parsing: certain hypotheses for complete constituents are excluded because the secondary index reveals a discontinuity.
¡¡the complexity is increased by the presence of l1-nils  since with them the secondary index can no longer be uniquely determined. however  with the adjacency condition   i  in rule  1    the number of possible variants in the secondary index is a function of the number of l1-nils. say there are m l1-nils. in each application of rule  1  we pick a vectorv  with a variable forthe leftmost andrightmostl1-nil element. by adjacency  either the leftmost or rightmost one marks the boundary for adding the additional l1-nil element nil/y1 - hence we need only one new variable for the newly shifted boundary among the l1-nils. so  in addition to the n1 expense of parsing non-nil words  we get an expense of m1 for parsing the l1-nils  and end up in o n1 . since typically the number of correspondent-less words is significantly lower than the total number of words  these results are encouraging for medium-to-large-scalegrammar learning experiments.1
empirical evaluation. to validate empirically that the average parsing complexity for the proposed correspondenceguided synchronous parsing approach  cgsp  for sentences without or with few l1-nils is lower than for standard monolingual parsing  we did a prototype implementation of the algorithm and ran a comparison. a synchronous grammar was extracted  and smoothed  from a manually aligned german/english section of the europarl corpus. the results are shown as the black line  for the cgsp approach on sentences without l1-nils  and dark gray line  for monolingual parsing  in  1 . the diagram shows the average parsing time for sentence pairs of various lengths. note that cgsp takes clearly less time.
 1  synchronous parsing with a growing number of l1-nils

 1  also shows comparative results for parsing performance on sentences that do contain l1-nils  curves for 1  1 and 1 l1-nils are shown . here too  the theoretical results are corroborated that with a limited number of l1-nils  the cgsp is still efficient.
¡¡we also simulated a synchronous parser which does not take advantage of a given word alignment. for sentences of length 1  this parser took an average time of 1 seconds  largely independent of the presence/absence of l1-nils .
