 
given a set of numbers  the two-way partitioning problem is to divide them into two subsets  so that the sum of the numbers in each subset are as nearly equal as possible. the problem is np-complete  and is contained in many scheduling applications. based on a polynomial-time heuristic due to karmarkar and karp  we present a new algorithm  called complete karmarkar karp  ckk   that optimally solves the general number-partitioning problem. ckk significantly outperforms the best previously-known algorithms for this problem. by restricting the numbers to twelve significant digits  we can optimally solve two-way partitioning problems of arbitrary size in practice. ckk first returns the karmarkar-karp solution  then continues to find better solutions as time allows. almost five orders of magnitude improvement in solution quality is obtained within a minute of running time. rather than building a single solution one element at a time  ckk constructs subsolutions  and combines them in all possible ways. ckk is directly applicable to the 1 knapsack problem  since it can be reduced to number partitioning. this general approach may also be applicable to other np-hard problems as well. 
1 	introduction and overview 
consider the following very simple scheduling problem. we are given two identical machines  a set of jobs  and the time required to process each job on either machine. assign each job to one of the machines  in order to complete all the jobs in the shortest elapsed time. in other words  divide the job processing times into two subsets  so that the sum of the times in each subset are as nearly equal as possible. this is the two-way number partitioning problem  and is np-complete l . the generalization to k-way partitioning with k machines is straightforward  with the cost function being the difference between the largest and smallest subset sums. this basic problem is likely to occur as a subproblem in many practical scheduling applications. 
　for example  consider the set of numbers  1  1  1  1  1 . if we divide it into the two subsets  1  and  1 1   the sum of each subset is 1  and the difference of the subset sums is zero. in addition to being optimal  this is also a perfect partition. note that if the sum of all the numbers is odd  a perfect partition will have a subset difference of one. 
　we first present previous work on this problem  including a polynomial-time greedy heuristic  and an exponential-time algorithm to find optimal solutions. we also present an elegant polynomial-time approximation algorithm due to karmarkar and karp  called set differencing  or the kk heuristic  which dramatically outperforms the greedy heuristic. the main contribution of this paper is to extend the kk heuristic to a complete algorithm  which we call complete karmarkar karp  ckk . the first solution returned by ckk is the 
kk solution  and as the algorithm continues to run it finds better solutions  until it eventually finds and verifies an optimal solution. 
　we present experimental results comparing ckk to the standard algorithm for finding optimal solutions. ckk appears to be asymptotically faster than the standard algorithm  and provides orders of magnitude improvement when perfect partitions exist. due to the existence of perfect partitions  it is possible in practice to optimally partition arbitrarily large sets of numbers  if the number of significant digits in each number is limited. this limit is about twelve decimal digits for twoway partitioning. this is not a limitation in practice  since no physical quantities are known with more than twelve digits of precision. for example  this would represent an accuracy of one second in over 1 years. we have performed the same experiments for three-way partitioning  with very similar results  except that the precision limit for optimally partitioning large sets is only six decimal digits. 
　ckk is the best existing algorithm for number partitioning  outperforming even stochastic approaches. it also can be directly applied to the 1 knapsack problem  which can be reduced to number partitioning. instead of incrementally building a single partition  ckk constructs a large number of subpartitions  and combines them together in all possible ways. we believe that this general strategy may be applicable to other np-complete problems as well. 
1 previous work 
1 greedy heuristic 
the obvious greedy heuristic for this problem is to first sort the numbers in decreasing order  and arbitrarily place the largest number in one of two subsets. each remaining number is then placed in the subset with the smaller total sum thus far  until all numbers are assigned. 
　for example  given the sorted numbers  1 1 1   the greedy algorithm would proceed through the following states  where the numbers outside the list are the current subset sums: 1 1 1   1 1 1   1 1   1 1   1    for a final subset difference of 1. note that the greedy algorithm does not find the optimal solution in this case. the above notation maintains both subset sums  but to find the value of the final difference  we only need the difference of the two subset sums. thus we can rewrite the above trace as: 1 1 1   1 1   1 1   1   1  . in practice  however  we would keep track of the actual subsets as well. 
　this algorithm requires 1 n log n  time to sort the n numbers  and then o n  time to assign them  for an overall time complexity of 1 n log n . 
1 set differencing  karmarkar-karp  
the set differencing method of karmarkar and karp  also known as the kk heuristic  is another polynomialtime approximation algorithm. it also begins by sorting the numbers in decreasing order. in our example  the two largest numbers are 1 and 1. the algorithm commits to placing these two numbers in different subsets  while deferring the decision about which subset each will go in. for example  if we place the 1 in the left subset  and the 1 in the right subset  this is equivalent to placing their difference of 1 in the left subset  since we can subtract 1 from both subsets without affecting the final difference. similarly  placing the 1 in the right subset and the 1 in the left subset is equivalent to placing 1 in the right subset. the algorithm removes the two largest numbers  computes their difference of 1  and then treats the 1 just like any other number  inserting it in sorted order in the remaining list of numbers. the algorithm continues removing the two largest numbers  replacing them by their difference in the sorted list  until there is only one number left. this number represents the value of the final subset difference. 
　for example  given the sorted numbers  1 1 1   the 1 and 1 are replaced by their difference of 1  which is inserted in the remaining list  resulting in  1 1 . next  the 1 and 1 are replaced by their difference of 1  yielding  1 1 . the 1 and 1 are replaced by their difference of 1  giving  1   and finally the difference of these last two numbers is the final subset difference of 1. the kk heuristic also fails to find the optimal partition in this case  but does better than the greedy heuristic. 
　while the above algorithm computes the final difference of the subset sums  computing the actual partition is slightly more involved. the algorithm builds a tree  initially with one node for each original number  and no edges. each differencing operation adds an edge between two numbers  to signify that they must go in different subsets. the resulting graph forms a spanning tree of the original nodes  which is then two-colored to determine the actual subsets  with all the numbers of one color going in one subset. 
　for example  figure 1 shows the final tree for the example above. first  replacing 1 and 1 by their difference creates an edge between them. the larger of the two  node 1  represents their difference of 1. next  replacing 1 and 1 by their difference adds an edge between them  with node 1 representing their difference of 1. if we then take the difference of 1  and the 1 from the difference between 1 and 1  we add an edge between 1 and 1  since node 1 represents the difference of 1. since 1 is larger than 1  node 1 represents their difference of 1. finally  an edge is added between node 1 and node 1  which represents the remaining value of 1. 

　in general  the resulting graph forms a spanning tree of the original nodes  since all the numbers must eventually be combined  and n - 1 edges are created  one for each differencing operation. we then color the nodes of the graph with two colors  so that no adjacent nodes receive the same color  to get the final partition itself. to twocolor a tree  color one node arbitrarily  treating this node as the root  and then color all the nodes at a given depth from the root the same color  alternating colors with each level. two-coloring the above graph results in the subsets  1  1   and  1   whose subset sums are 1 and 1  respectively  for a final partition difference of 1. 
　the running time of this algorithm is o nlogn  to sort the tv numbers  1 n  ogn  for the differencing  since each difference must be inserted into the sorted order  and finally o n  to two-color the graph  for an overall time complexity of 1 n log n . 
　the kk heuristic finds much better solutions on average than the greedy heuristic. figure 1 shows comparative data for the two algorithms  partitioning random integers uniformly distributed from 1 to 1 billion. the horizontal axis is the number of values in the original set  and the vertical axis is the difference of the final subset sums  on a logarithmic scale. each data point is an average of 1 random problem instances. as the number of values increases  the final difference found by the kk heuristic is orders of magnitude smaller than for the greedy heuristic. we also show the optimal solution quality  which is orders of magnitude better than even the kk solution in this range. the optimal solution data points are averages of only 1 problem instances each. with 1 or more numbers of this size  a perfect partition difference of zero or one was found in every case. if we extend the graph further to the right  at about 1 numbers the kk line joins the optimal line  finding a perfect partition almost every time. the greedy line  however remains almost flat  requiring a. thousand numbers to drop another order of magnitude in solution quality. 
the explanation for the difference between the qual-
k1rf 

ity of the greedy and kk solutions is quite simple. the difference of the final partition is on the order of the size of the last number to be assigned. for the greedy heuristic  this is the size of the smallest original number. this explains the small improvement with increasing numbers of values  since the more values we start with  the smaller the smallest of them is likely to be. for n numbers uniformly distributed between 1 and 1  the greedy method produces a final difference of 1 /n . for the kk method  however  repeated differencing operations dramatically reduce the size of the remaining numbers. the more numbers we start with  the more differencing operations  and hence the smaller the size of the last numbers. karmarkar and karp have shown that the value of the final difference is 1 l/nalo*n   for some constant a . 
1 	finding optimal solutions 
both algorithms above run in 1 n log n  time  but only find approximate solutions. if we want an optimal solution  the obvious algorithm is to search a binary tree  where at each node the left branch assigns the next unassigned number to one subset  and the right branch assigns it to the other subset. we keep track of the best final difference found during the search  and return it as the result  along with the actual subsets if desired. 
　the time complexity of this algorithm is 1n   since we have to search a binary tree of depth n  and its space complexity is 1 n   since we can search the tree depthfirst. there are two ways of pruning this tree  however. if we reach a node where the difference between the current subset sums is greater than or equal to the sum of all the remaining unassigned numbers  the best we can do is to assign all the remaining numbers to the smaller subset. for example  consider the state 1 1 1   which results from assigning the 1 and 1 to the same subset. since the sum of 1  1  and 1 is no greater than the current subset difference of 1  the best we can do is to put all the remaining numbers in the other subset. since this pruning doesn't depend on the best solution found so far  the size of the tree is independent of the order in which it is searched. 
　if we reach a terminal node whose subset difference is zero or 1  representing a perfect partition  then we can terminate the search. the above example illustrates this  since once we assign the remaining numbers to the other subset  the resulting complete partition has a difference of zero. if a perfect partition exists  then the search order matters  since the sooner we find a perfect partition  the sooner we can quit. the obvious way to order the search is to sort the numbers in decreasing order  and always put the next number in the smaller subset  before putting it in the larger subset. this algorithm produces the greedy solution first  and continues to search for better solutions  until an optimal solution is eventually found and verified. 
　several additional optimizations deserve mention. one is that the first number should only be assigned to one subset  cutting the search space in half. the second is that whenever the current subset sums are equal  the next number should only be assigned to one subset  cutting the remaining subtree in half. the first optimization is in fact a special case of the second  but in practice only this special case yields significant performance improvements. finally  when only one unassigned number remains  it should be assigned only to the smaller subset. figure 1 shows the resulting binary tree for the numbers  1 1 1   where the number in front of the set is the difference between the current subset sums  and the numbers below the leaf nodes represent the corresponding final partition differences. 
1 	pseudopolynomial-time algorithm 
there is also another rather different algorithm for finding optimal solutions. this is a dynamic programming approach which assumes that the original numbers are integers  or can be mapped to integers  such as a set of rational numbers. it requires an array whose size is half the sum of all the numbers. the algorithm enumerates all possible subset sums  as opposed to all possible subsets  to determine the achievable subset sum closest to half the total sum. unfortunately  the space complexity of this algorithm makes it impractical for numbers of even moderate size. 
1 	complete karmarkar-karp 
similar to the extension of the greedy heuristic to a complete algorithm  the main contribution of this paper is to extend the kk heuristic to a complete algorithm. while the idea is extremely simple  it doesn't appear in karmarkar and karp's original paper  and apparently escaped a number of other researchers who worked on the problem subsequently  1; 1; 1 . 
　at each cycle  the kk heuristic commits to placing the two largest numbers in different subsets  by replac-

when a perfect partition does exist. in that case  for the same reason that the kk heuristic produces better 

ing them with their difference. the only other option is to place them in the same subset. this is done by replacing them by their sum. the resulting algorithm  which we call complete karrnarkar-karp  ckk   also searches a binary tree  where each node replaces the two largest numbers. the left branch replaces them by their difference  while the right branch replaces them by their sum. the difference is inserted in sorted order in the remaining list  while the sum is simply appended to the head of the list  since it will always be the largest element. thus  the first solution found by ckk is the kk solution  but as it continues to run it finds better solutions  until an optimal solution is eventually found and verified. 
　in the worst case  the time complexity is still 1n . however  the same pruning rules apply as in the standard algorithm  with the largest element of the set playing the role of the current subset difference. in other words  a branch is terminated when the largest element is greater than or equal to the sum of all the remaining elements. figure 1 shows the resulting binary tree for the numbers 
 1 1 1 . note that the tree in figure 1 is smaller than that in figure 1  even though both find optimal solutions to the same problem instance. 
　there are two reasons why ckk is more efficient than the standard complete algorithm  depending on whether or not a perfect partition exists. if there is no perfect partition  then both algorithms must search the whole tree. this is illustrated by the left subtrees in figure 1 and figure 1  where both algorithms place the 1 and 1 in different subsets. this state is represented by 1 1  in figure 1  where 1 is the current subset difference  and by  1  1 1  in figure 1b. the distinction between these two representations is that in the latter case  the difference of 1 is treated like any other number  and inserted at the end of the sorted order  instead of having the special status of the current subset difference. thus  at the next level of the tree  represented by nodes  1 1  and  1 1  in figure 1  the largest number is greater than the sum of the remaining numbers  and these branches can be pruned. in the standard algorithm  however  the two children of the left subtree  1 1  and 1 1  in figure 1  do not have this property  and have to be expanded further. thus  ckk allows more pruning than the standard algorithm. 
the second reason that ckk is more efficient occurs solutions than the greedy heuristic  the ckk algorithm finds better solutions sooner  including the perfect solution. this allows it to terminate the search much earlier than the standard algorithm  on average. 
1 	experimental results 
to demonstrate these effects  we implemented both the standard complete algorithm and the ckk algorithm  which both find optimal solutions. the results for twoway partitioning are shown in figure 1. we chose random numbers uniformly distributed from 1 to 1 billion  which have ten significant decimal digits. each data point is the average of 1 random problem instances. to make the algorithms more efficient  the ckk algorithm directly computes the optimal partition when there are four numbers left  since the kk heuristic is optimal in that case. the equivalent stopping point for the standard algorithm is when there are three unassigned numbers remaining  with the current subset difference playing the role of the fourth number. the horizontal axis shows the number of values partitioned  with data points for sets of size 1  1  1  ...  1  1. the vertical axis shows the number of nodes generated by the two algorithms. the descending line shows the average optimal partition difference on the vertical axis  fortuitously representable on the scale. 
　both algorithms were coded in c  and generate approximately 1 million nodes per minute on a sun sparc 1. thus  the whole vertical axis represents about an hour of computation. while ckk would seem to require more time per node to insert the computed difference in the remaining list  this amounts to only a constant factor  since most of the nodes in the tree are near the bottom  where the lists are very short. this constant is made up for by the fact that when there are only four numbers remaining  the final partition difference can be computed more efficiently by ckk  since they are in sorted order. for the standard algorithm  the last subset difference is not in sorted order with respect to the remaining three numbers. 
　there are clearly two different regions of this graph  depending on how many values are partitioned. with less than 1 numbers  no perfect partitions were found  while with 1 or more numbers  a perfect partition was found in every case. the optimal solution quality aver-
korf 

ages .1 beyond 1 numbers  since there are roughly equal numbers of final differences of zero and one. 
　figure 1 shows that ckk outperforms the standard algorithm over the entire range. without a perfect partition  there is a small asymptotic improvement. the ratio of the number of nodes generated by the standard algorithm compared to ckk grows linearly with the number of values partitioned. this suggests that ckk is asymptotically more efficient than the standard algorithm. 
　the performance improvement is much more dramatic when a perfect partition exists. in that case  ckk finds the perfect partition much sooner than the standard algorithm  and hence terminates the search earlier. as the problem size increases  the running time of the standard algorithm drops gradually  but the running time of ckk drops precipitously  resulting in orders of magnitude improvement. we have run ckk on 1-digit problems up to size 1  and the trend seen in figure 1 continues  bottoming out at about 1 milliseconds to partition 1 numbers. at that point  the kk solution is almost always optimal  and the running time is dominated by the 1 n log n  time to find this first solution. 
　the data in figure 1 is for numbers with ten decimal digits of precision  to allow running many trials with different numbers of values. arbitrary-size single problem instances with up to twelve digits of precision can be solved in practice  however. since no physical quantities are known with higher precision  any two-way partitioning problems that arise in practice can be optimally solved  regardless of problem size. while all our experiments were run on uniformly distributed values  we believe that the same results will apply to other naturally occurring distributions as well. 
　most of the work on number partitioning  however  has focussed on problems without perfect partitions. to generate large such problem instances  numbers with up to 1 decimal digits have been used. as long as there is no perfect partition  the performance of both ckk and the standard algorithm is largely independent of the precision of the numbers being partitioned  except for a constant based on whether singleprecision  double-precision  or multiple-precision arithmetic is used. the data above was collected with doubleprecision arithmetic. to optimally partition 1-digit double-precision numbers with ckk requires an average of about 1 hours and 1 minutes  while the standard algorithm requires an average of 1 hours and 1 minutes. 
　for larger problems with very high precision  we must settle for approximate solutions. in that case  we can run ckk for as long as time allows  and return the best solution found. the first solution found is the kk solution  and as the algorithm continues to run  it finds better solutions. this technique is very effective  since much of the improvement in solution quality occurs early in the run. figure 1 shows the improvement as a function of running time for partitioning 1-digit numbers. the horizontal axis is the number of nodes generated on a logarithmic scale  and the vertical axis is the ratio of the initial kk solution to the best solution found for a given number of node generations  also on a logarithmic scale. the entire horizontal scale represents less than a minute of real time  and shows almost five orders of magnitude improvement  relative to the original kk solution. almost three orders of magnitude improvement is obtained within a second of running time. 


1 multi-way partitioning 
so far  we have discussed partitioning a set of numbers into two subsets. here we briefly discuss the generalization of all these techniques to partitioning into multiple subsets  omitting the details due to space limitations. the general task is to partition a set of numbers into k mutually exclusive and collectively exhaustive subsets  so that the difference between the largest subset sum and the smallest subset sum is minimized. 
1 greedy and standard algorithms 
the generalizations of the greedy heuristic and the standard optimal algorithm to k-way partitioning are straightforward. we sort the numbers in decreasing order  and maintain k different subsets. for the greedy heuristic  we always place the next number in the subset with the smallest sum so far. the complete algorithm places each number in each different subset  in increasing order of their subset sums  searching a k-ary tree. by never placing a number in more than one empty subset  we avoid generating duplicate partitions that differ only by a permutation of the subsets  and produce all nk/k! distinct k-way partitions of n elements. we prune the tree when the sum of the remaining elements is small compared to the differences between the current subset sums. we only have to maintain a' - 1 subset sums  since we can always subtract the smallest subset sum from each of the others without affecting the final difference. a perfect partition has a difference of zero if the sum of the original numbers is divisible by k  and a difference of one otherwise. 
1 karmarkar-karp heuristic 
karmarkar and karp generalize their set differencing method to k-way partitioning as follows. every element represents a partial partition  with potentially k subset sums. the initial numbers each represent a partial partition with the number itself in the largest subset  and the remaining subset sums equal to zero. for example  a three-way partition of the set  1 1 1  would initially be represented by the subpartitions   1 1    1 1    1 1    1 1    1 1    which are sorted in decreasing order. then the two largest numbers are combined into a single subpartition by putting them in different subsets  resulting in the list   1  1    1 1    1 1    1 1  . since the combined subpartition still has the largest subset sum  the next smaller subpartition   1 1   is combined with it by placing the 1 in the smallest subset  resulting in the subpartition  1 1 . since we are only interested in the difference between the largest and the smallest subset sums  we subtract the smallest sum  1  from each of the subsets  yielding the subpartition  1 1 . this subpartition is then inserted into the remaining sorted list in decreasing order by largest subset sum  resulting in   1 1  1 1  1 1  . again  the two largest are combined  yielding   1  1  1  1  . finally  these last two subpartitions are merged by combining the largest subset sum with the smallest  the smallest subset sum with the largest  and the two medium subset sums together  yielding  1 1 . subtracting the smallest from all the subset sums results in the final subpartition of  1 1   which has a difference of 1  and is optimal in this case. while we have shown all three subset sums for clarity  our actual implementation only maintains the two non-zero values for each subpartition. additional bookkeeping is required to recover the partition itself. 
1 complete karmarkar-karp algorithm 
the ckk algorithm also generalizes to multi-way partitioning. as in the case of two-way partitioning  instead of combining subpartitions in only one way  to make the algorithm complete we must combine them together in all possible ways. again consider three-way partitioning. a particular subpartition represents a commitment to keep the elements in the different subsets separate. there are three cases to consider in combining a pair of subpartitions. in the first case  both subpartitions have only a single non-zero subset sum  say  x  1  1  and  a  1  1 . we can combine these in two different ways  resulting in  a'  a  1  or  x + a  1  1 . in the second case  one subpartition has a single non-zero subset sum and the other has two non-zero subset sums  say  a' y  1  and  a  1  1 . in this case we can combine them in three different ways  resulting in the subpartitions  x y  a    a'  y + a  1   and  x + a  y  1 . finally  both subpartitions can have two non-zero subset sums  say  a'  y  1  and  a b 1 . in this case  there are or six different ways to combine them:  x y + b a    x y + a b    x + b y a    a' + b  y + a 1    x + a y b   and  a+ a  y + 1 . in each case  the combined subpartitions are searched in increasing order of largest subset sums  so that the first solution found is the kk solution. the resulting search tree has depth tv  and nodes with branching factor two  three  and six. the number of leaf nodes  however  is no greater than that in the standard tree. this is proven by showing that each of the three groups of combinations above is mutually exclusive and collectively exhaustive  and hence each distinct partition is represented by exactly one leaf node. 
　pruning works by comparing the subset sums in the largest subpartition to the sum of all values in the remaining subpartitions. a complete partition with difference zero or one is optimal  and terminates the search. 
　we implemented the above algorithms for three-way partitioning  obtaining similar results to those for twoway partitioning. namely  there is a small asymptotic improvement when no perfect partition exists  and orders of magnitude improvement with perfect partitions. 
　while the constant factors for ckk and the standard algorithm are roughly the same for two-way partitioning  the three-way version of ckk is more complex. as a result  ckk runs about 1% slower per node generation than the standard algorithm  on three-way partitioning problems. while this reduces the absolute performance of ckk  it appears to be asymptotically more efficient than the standard algorithm  and runs faster in practice. in order to run large numbers of three-way partitioning problems of different sizes  we used numbers with five significant decimal digits. single instances of arbitrary size with six digits of precision can be solved in practice  however. three-way partitioning is computa-
k1rf 
tionally more difficult than two-way  and partitioning into more subsets is likely to be harder still  since the number of distinct k-way partitions is 1 kn/n  . 
1 stochastic approaches 
there have been at least three studies applying stochastic algorithms to number partitioning  none of which can guarantee optimal solutions. johnson et al. applied simulated annealing to the problem  but found that it was not competitive with the karmarkar-karp heuristic solution. ruml et al. applied various stochastic algorithms to some novel encodings of the problem  but their best results outperform the kk solution by only three orders of magnitude  compared to the five orders of magnitude ckk achieves in a minute. jones and beltramo applied genetic algorithms to the problem  but don't mention the karmarkar-karp heuristic. their technique fails to find an optimal solution to the single problem instance they ran  while the kk solution to this instance is optimal. 
1/1 knapsack problem 
given a set of integers  and a constant c  the 1 knapsack problem asks if there exists a subset of the integers whose sum is exactly c. we can reduce this problem to the two-way partition problem  and hence apply ckk to the 1 knapsack problem as well. let s be the sum of all the integers. assume that c   1  and otherwise use s - c for c. add a new integer d such that  1 + d /1 = c  or d = 1c - s. if this augmented set can be perfectly partitioned with a difference of zero  then the subset of the perfect partition that does not contain d is a subset of the original numbers whose sum is exactly c  and hence a solution to the 1 knapsack problem. conversely  if this augmented set cannot be perfectly partitioned  then there is no subset of the original numbers that sum to exactly c  and hence no solution to the 1 knapsack problem. 
1 summary and conclusions 
the main contribution of this paper is to extend a very effective polynomial-time approximation algorithm due to karmarkar and karp  to a complete algorithm  ckk . the first solution it finds is the kk solution  and as it continues to run it finds better solutions  until it eventually finds and verifies an optimal solution. for problems without perfect partitions  ckk appears to be asymptotically more efficient than the standard optimal algorithm. when a perfect partition exists  ckk outperforms the standard algorithm by orders of magnitude. we showed results for two-way partitioning  and have obtained similar results for three-way partitioning. in practice  two-way partitioning problems of arbitrary size can be solved if the numbers are restricted to no more than twelve significant digits of precision  while arbitrary-sized three-way partitioning problems can be optimally solved with six significant digits. for large problems with very high precision  ckk can be run as long as time is available  returning the best solution found when time runs out. ckk outperforms every algorithm we could find in the literature. 
　what contribution does this work make beyond the specific problem of number partitioning  first  ckk is directly applicable to the 1 knapsack problem  and may apply to other related problems as well. secondly  it presents an example of an approach that may be effective on other combinatorial problems. namely  we took a good polynomial-time approximation algorithm  and made it complete  so that the first solution found is the approximation  and then better solutions are found as long as the algorithm continues to run  eventually finding an optimal solution. thirdly  it represents an example of another approach that may be more broadly applicable. most algorithms for combinatorial problems construct a solution to a problem incrementally  adding one element at a time to a single partial solution. this is the case with the standard algorithm for number partitioning. the ckk algorithm  on the other hand  constructs a large number of partial solutions  and combines them together in all possible ways. in this case  this latter strategy is much more effective  and may be for other problems as well. 
1 acknowledgements 
thanks to wheeler ruml for introducing me to number partitioning  and to the karmarkar-karp heuristic. thanks to wheeler  ken boese  alex fukunaga  and 
andrew kahng for helpful discussions concerning this research  and to pierre hasenfratz for comments on an earlier draft. this work was supported by nsf grant iri-1  and a grant from rockwell international. 
