 
　this paper introduces a hybrid learning methodology that integrates genetic algorithms  gas  and decision tree learning  id1  in order to evolve optimal subsets of discriminatory features for robust pattern classification. a ga is used to search the space of all possible subsets of a large set of candidate discrimination features. for a given feature subset  id1 is invoked to produce a 
　decision tree. the classification performance of the decision tree on unseen data is used as a measure of fitness for the given feature set  which  in turn  is used by the ga to evolve better feature sets. this ga-id1 process iterates until a feature subset is found with satisfactory classification performance. experimental results are presented which illustrate the feasibility of our approach on difficult problems involving recognizing visual concepts in satellite and facial image data. the results also show improved classification performance and reduced description complexity when compared against standard methods for feature selection. 
1 introduction 
pattern classification  a difficult but fundamental task in ai  depends heavily on the particular choice of features used by the classifier. one usually starts with a given set of features and then attempts to derive an optimal subset of features leading to high classification performance. a standard approach involves ranking the features of a candidate feature set according to some criteria involving 1nd order statistics  anova  and/or information theory based measures such as  infomax   and then deleting lower ranked features. ranking by itself is usually not enough because the criteria used do not measure the effectiveness of the features selected on the actual classification task itself  nor do they capture possible nonlinear interactions among the features. 
　this paper provides specific answers to the problems raised above and describes a hybrid learning approach for optimal feature selection and the derivation of robust pattern classifiers. our novel approach  which includes a genetic algorithm  ga  and a tree induction system  id1   minimizes the number of features used for classification while simultaneously achieving 
k. dejong and h. wechsler department of computer science 
george mason university fairfax  va 1 
improved classifications rates. a ga is used to search the space of all possible subsets of a large set of candidate discrimination features. for a given feature subset  id1 is invoked to produce a decision tree. the classification performance of the decision tree on unseen data is used as a measure of fitness for the given feature set  which  in turn  is used by the ga to evolve better feature sets. this ga-id1 process iterates until a feature subset is found with satisfactory classification performance. experimental results are presented which illustrate the feasibility of our approach on difficult problems involving recognizing visual concepts in satellite and facial image data. the results also show improved classification performance and reduced description complexity when compared against standard methods for feature selection. 
1 background 
any object or pattern that has to be recognized and/or classified must possess a number of discriminatory properties or features. the first step in any recognition process  performed either by a machine or by a human being  is to choose candidate discriminatory features and evaluate them for their usefulness. feature selection in pattern recognition involves the derivation of salient features from the raw input data in order to reduce the amount of data used for classification and simultaneously provide enhanced discriminatory power. the number of features needed to successfully perform a given classification task depends on the discriminatory qualities of the selected features. 
　the selection of an appropriate set of features is one of the most difficult tasks in the design of pattern classification system. at the lowest level  the raw feature data is not nice clean symbolic data like  green   but rather noisy sensor data  e.g.  spectral properties  the characteristics of which are complex and irregular. in addition  there is considerable interaction among low level features which must be identified and exploited. however  the typical number of possible features is so large as to prohibit any systematic exploration of all but a few possible interaction types  e.g.  pairwise interactions . large feature sets with noisy numerical data also provide considerable difficulty for traditional symbolic inductive learning systems. the running time of the learning system and the accuracy and complexity of the output rapidly 
	baiaetal 	1 

fall below an acceptable level. 
the rationale behind our approach is the belief  michalski  
1  that further advances in pattern analysis and classification require the integration of various learning processes in a modular fashion. learning systems that employ several strategies can potentially offer significant advantages over single-strategy systems. since the type of input and acquired knowledge are more flexible  such hybrid systems can be applied to a wider range of problems. examples of such integration include combinations of genetic algorithms and neural networks  gruau and whitley  1  and genetic algorithms and rule-based systems  bala et al  1   vafaie and de jong  1 . 
　the integration of genetic algorithms and inductive decision tree learning for optimal feature selection and pattern classification is a novel application of such an approach and is the topic of this paper. we have selected id1-like induction algorithms  which use entropy as an information measure during tree derivation. this same entropy underlies also the infomax principle - maximum information preservation between successive processing layers. self-organization in perceptual networks and the development of receptive fields has been shown to be driven by such a principle. specifically  linsker 1  has reported that a perceptual system develops to recognize relevant features of its environment using the infomax principle. 
　the integration of genetic algorithms and decision tree learning advocated in this paper is also part of a broader issue being actively explored  namely  that evolution and learning can work synergistically  hinton and nowlan  1 . the ability to learn can be shown to ease the burden on evolution. evolution  genotype learning  only has to get close to the goal;  phenotype  learning can then fine tune the behavior  muhlenbein and kinderman  1 . although darwinian theory does not allow for the inheritance of acquired characteristics  lamarckian evolution   learning  acquired behaviors  can still influence the course of evolution. the baldwin effect where local search is employed to change the fitness of strings  but the acquired improvements do not change the genetic encoding of the individual is under active study  whitley et al  1 . one can gain a further perspective on the lamarckian hypothesis by moving up from the individual chromosome  agent  to ecosystems  species  and addressing cultural evolution as well  wechsler  1 . 
1 	ga-id1 hybrid learning 
the basic idea of our hybrid system is to use gas to efficiently explore the space of all possible subsets of a given feature set in order to find feature subsets which are of low order and high discriminatory power. in order to achieve this goal  we felt that fitness evaluation had to involve direct measures of size and classification performance  rather than measures such as the ranking methods discussed in the previous section. the speed of id1 suggested the feasibility of the approach shown in figure 1. 
　an initial set of features is provided together with a training set of the measured feature vectors extracted from raw data corresponding to examples of concepts for which the decision tree is to be induced. the genetic algorithm  ga  is used to explore the space of all subsets of the given feature set where preference is given to those features sets which achieve better classification performance using smaller dimensionality feature sets. each of the selected feature subsets is evaluated  its fitness measured  by testing the decision tree produced by id1  quinlan  1 . the above process is iterated along evolutionary lines and the best feature subset found is then recommended to be used in the actual design of the pattern classification system. 
　in order for a ga to efficiently search such large spaces  one must give careful thought to both the representation chosen and the evaluation function. in this case  there is a very natural representation of the space of all possible subsets of a feature set  namely  a fixed-length binary string representation in which the value of the ith gene {1} indicates whether or not the fth feature from the overall feature set is included in the specified feature subset. thus  each individual in a ga population consists of fixed-length binary string representing some subset of the given feature set. the advantage of this representation is that a standard and well understood ga can be used without any modification. 
　each member of the current ga population represents a competing feature subset that must be evaluated to provide fitness feedback to the evolutionary process. this is achieved by invoking id1 with the specified feature subset and a set of 


1 	genetic algorithms 

training data  reduced to include only the feature values of the specified features . the decision tree produced by id1 is then 1 experimental results tested for classification accuracy on a set of unseen evaluation data. its accuracy together with the size of the feature subset is an initial set of experiments has been performed to assess the used as the ga fitness measure. performance of the hybrid ga-id1 learning system. subsets of 
optimal features for recognizing visual concepts in satellite and 
　our belief is that such a hybrid learning system will identify facial image data have been learned and compared against significantly better feature subsets than those produced by standard methods for feature selection. the error rates on existing methods for two reasons. first  we are exploiting the unseen image data and the tree description complexity power of gas to efficiently explore the non-linear interactions 
                                                measured as the number of nodes  have been used as the basis of a given set of features. second  by using id1 in the for comparison. evaluation loop  we have an efficient mechanism for directly 
measuring classification accuracy. in order to apply cross validation of the learning process  the learning data was randomly shuffled to generate two sets in order to test our ideas we have implemented a prototype 
　　　　　　　　　　　　　　　　　　　　　　　　 figure 1 . in each set 1% of examples were used for version of the system. for the ga component  we used inducing decision trees and the other 1% for evaluation of the without modification genesis  grefenstette  1   a learned description. ten experiments were performed on each standard ga implementation. similarly  we used without set in order to find the best average performance. the set that modification c1  a standard implementation of id1 produced the best result  i.e. the lowest error rate  was selected 
 quinlan  1   to build up the decision trees for the as the training set. the tree generated during the best run of evaluation procedure. for both components  standard default that set  one of ten runs  is applied to the unseen test data. parameter settings from the literature were used. for the ga 
                                                 results obtained by the ga-id1 system have been compared module  this resulted in a constant population size of 1  a with two other sets of results. the first one was obtained by crossover rate 1 and a mutation rate 1 for c1  the using all features  1 for the satellite date and 1 for facial pruning confidence level was set to default 1%. 
data . to generate the second result a set with features reduced to the same number as the one produced by the ga-id1 experiment was used. this reduction was achieved by an independent ranking of each feature using an information theory based entropy measure  infomax  to estimate which features are the most discriminatory. features that lead to the greatest reduction in the estimated measure of the training 
examples are chosen. the exact criterion is to choose that feature vector x with values  that 
minimizes the expression 
over n classes  where x+ is the number of examples in a given class with values  is the number of negative examples  all the examples not belonging to this class  with the value 
1 experiments with the satellite data 
the satellite image database consists of the multi-spectral values of pixels in 1 neighborhoods  and the classification associated with the central pixel in each neighborhood. the aim is to predict this classification  given the multi-spectral values. in the sample database used in experiments  the class 
of a pixel is coded as a number. 
　one frame of landsat mss imagery consists of four digital images of the same scene in different spectral bands. two of these are the visible region  corresponding approximately to green and red regions of the visible spectrum  and two are in the  near  infra-red. each pixel is a 1-bit binary word  with 1 corresponding to black and 1 to white. the spatial resolution of a pixel is about 1m x 1m. each image contains 1 x 1 such pixels. 

　the original data for the database used in our experiments was generated from data purchased from nasa by the australian center for remote sensing. one frame of imagery consists of four digital images of the same scene in different spectral bands. two of these are in the visible region  corresponding approximately to green and red regions of the visible spectrum  and two are in the  near  infra-red. each pixel is a 1-bit binary word  with 1 corresponding to black and 1 to white. each example of data corresponds to a 1 square neighborhood of pixels completely contained within the 1 sub-area and it contains the pixel values in the four spectral bands  converted to ascii  of each of the 1 pixels in the 1 neighborhood and a number indicating the classification label of the central pixel. tables 1 and 1 characterize the data. figure 1 shows average performances on the evaluation sets over 1 runs using the ga-id1 system. table 1 shows the results of the ga-id1 experiment together with the corresponding performances for  i  the set with all the 
features and  ii  the set with features reduced to the number obtained in the ga-id1 experiment and ranked using the  entropy  infomax measure. 
1 experiments with face data 
the ability to detect salient facial features is an important component of any face recognition system. among the many facial features available it appears that the eyes play the most important role in both face recognition and social interaction. 
　detecting the eyes serves first of all an important role in face normalization and thus facilitates further localization of facial landmarks. it is eye detection that allows one to focus 
attention on salient facial configurations  to filter out structural noise  and to achieve eventual face recognition. for these purposes  we applied the hybrid learning system to 
accomplish feature selection on eye detection problem. 
　1 eye  1 nose and 1 other facial region examples are made available as learning and 1 eyes  1 nose and 1 other facial region examples are used as test data in our experiments. the original eye image  nose image or the image of other regions has resolution 1 by 1  column by row  pixels  which is cut from human face images  1 pixels . 1 features are produced for each example. the configuration of those features follows the rules listed in table 1  while table 1 gives the characteristics of the face data. 
　figure 1 shows average performance on the evaluation sets over 1 runs using the ga-id1 system. table 1 shows the results of the ga-id1 experiment together with the corresponding performance for  i  the set with all the features and  ii  the set with features reduced to the number obtained in the ga-id1 experiment and ranked using the  entropy  infomax measure. 
　figure 1 represents graphically a comparison of various results obtained in experiments. both for the satellite and face data an improvement of recognition rate  lower error rate  has been observed for sets with features reduced by the ga-id1 
1 	genetic algorithms 

bala et al 1 

1 	conclusions 
this paper introduced a hybrid learning methodology that integrates genetic algorithms  gas  and decision tree learning  id1  for evolving optimal subsets of discriminatory features for robust pattern classification. experimental results have been presented which illustrate the feasibility of our approach on difficult problems involving recognizing visual concepts in satellite and facial image data. the results have also shown significant improvements in classification performance and reduced description complexity when compared against standard methods for feature selection. 
　clearly more work needs to be done. although these two data sets are quite complex in comparison with symbolic machine learning data sets  they are still modest from an image processing point of view. we are currently involved in refining the system described here as we test it on larger and more complex problems. 
　an interesting extension to be explored is the possibility of additional feedback from id1 concerning the evaluation of a feature set. currently only classification accuracy is returned. however  mere is potentially exploitable information with respect to which features were actually used to build the decision tree and their relative positions in the tree. 
acknowledgments 
the army research laboratory  arl  has partially supported j. huang and h. wechsler under the daal1-r-1 grant on 'face recognition'. we would like to thank eric bloedorn and ali hadjarian for useful comments on experiments  and to bob henery for explanations on satellite data. 
