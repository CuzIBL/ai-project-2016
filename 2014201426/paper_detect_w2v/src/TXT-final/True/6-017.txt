 
increasing dialogue efficiency in case-based reasoning  cbr  must be balanced against the risk of commitment to a sub-optimal solution. focusing on incremental query elicitation in recommender systems  we examine the limitations of naive strategies such as terminating the dialogue when the similarity of any case reaches a predefined threshold. we also identify necessary and sufficient conditions for recommendation dialogues to be terminated without loss of solution quality. finally  we evaluate a number of attribute-selection strategies in terms of dialogue efficiency given the requirement that there must be no loss of solution quality. 
1 introduction 
in conversational case-based reasoning  ccbr   a query is incrementally elicited in an interactive dialogue with the user  aha et al  1 . attribute-selection strategies that aim to minimize the length of such dialogues have recently attracted much research interest  doyle and cunningham  1; kohlmaier et al  1; mcsherry  1; schmitt et al  1 . potential benefits include avoiding frustration for the user  reducing network traffic in e-commerce domains  and simplifying explanations of how conclusions were reached  breslow and aha  1; doyle and cunningham  1 . while our focus in this paper is on incremental query elicitation in recommender systems  it is worth noting that the ability to solve problems by asking a small number of questions has been a major factor in the success of helpdesk applications of cbr  aha et al  1; watson  1 . 
   an advantage of information gain  quinlan  1  as a basis for attribute selection is that it tends to produce small 
decision trees  thus helping to reduce the length of problemsolving dialogues  doyle and cunningham  1; 
mcsherry  1 . however  concerns about its suitability in e-commerce domains include the fact that no use is made of the system's similarity knowledge  kohlmaier et al  1; schmitt et al  1 . any importance weights associated with the case attributes are also ignored. as a result  it is possible for a case to be recommended simply because no other case has the preferred value for an attribute of low importance  even if its values for other attributes are unacceptable to the user. 
   kohlmaier et al  propose a similarity-based approach to attribute selection in which the best attribute is the one that maximizes the expected variance of the similarities of candidate cases. in domains in which cases are indexed by different features  another alternative to information gain is to rank questions in decreasing order of their frequency in the most similar cases  aha et al  1 . 
   to address the trade-off between dialogue efficiency and solution quality  a cbr system must also be capable of recognizing when the dialogue can be terminated while minimizing the risk of commitment to a sub-optimal solution. existing approaches include terminating the dialogue when the similarity of any case reaches a predefined threshold  or the achievable information gain is less than a predefined level  or the set of candidate cases has been reduced to a manageable size  aha et al  1; doyle and cunningham  1; kohlmaier et al  1 . 
   however  a limitation of these approaches is that there is no guarantee that a better solution would not be found if the dialogue were allowed to continue. whether it is possible to identify more reliable criteria for termination of problemsolving dialogues is an issue that has received little attention  if any  in cbr research. 
   in section 1  we examine the trade-off between dialogue efficiency and solution quality in recommender systems. in section 1  we present empirical techniques for identifying cases that can never emerge as the  best  case and can thus be eliminated. in section 1  we identify necessary and sufficient conditions for the dialogue to be terminated without loss of solution quality. in section 1  we evaluate a number of attribute-selection strategies in terms of dialogue efficiency given the requirement that there must be no loss of solution quality. our conclusions are presented in section 1. 
   

1 	case-based reasoning 
   
when the similarity of any case reaches a predefined threshold. 
   we use a leave-one-out approach in which each case is temporarily removed from the case library and used to represent the preferences of the user in a simulated recommendation dialogue. we measure dialogue length as the percentage of the 1 possible questions the user is asked before the dialogue is terminated. average dialogue length  precision and recall over all simulated dialogues are shown in figure 1 for similarity thresholds in the range from 1 to 1. in this case library  there is never more than a single case in the retrieval set for the full-length query that provides the baseline for our evaluation of retrieval performance. it follows that for each threshold  recall is the percentage of dialogues in which this  best  case is recommended. 
figure 1. trade-off between dialogue efficiency and solution quality with termination based on a predefined threshold. 
¡¡the similarity threshold of 1 can be seen to have reduced average dialogue length by almost 1%. this equates to about 1 out of 1 questions  on average  being asked before a recommendation is made. however  the trade-off is a reduction of more than 1% in both precision and recall. this means that the best case is recommended in less than 1% of dialogues. as precision is less than recall for the 1 threshold  there arc also occasions when the system recommends the best case along with one or more other cases that are equally similar to the final query. it is also worth noting that even a threshold of 1  though providing a reduction in dialogue length of 1%  docs not ensure that the best case is always recommended. 
1 when can the dialogue be safely terminated  
the potentially damaging effects of similarity thresholds on solution quality highlight the need for more reliable criteria for terminating ccbr dialogues. an incomplete query q gives perfect precision and recall if and only if rs q  = rs q*   but the problem is that q* is unknown. one can imagine an approach to ccbr that relics on exhaustive search to determine when the dialogue can be safely terminated; that is  in the certain knowledge that there can be no loss of precision or recall. the dialogue would be terminated only if all possible completions q* of the current query q yielded the same retrieval set as q. however  this approach is unfeasible in practice as the number of possible completions of a given query is often very large. 
   in section 1  we identify criteria for safely terminating the dialogue that require minimal computational effort in comparison with exhaustive search. the approach is based on the concept of case dominance that we now introduce. 
the importance of case dominance can easily be seen. 
any case that is dominated with respect to the current query can be eliminated as it can never emerge as the best case regardless of the preferences of the user with respect to the remaining attributes. in the following section  we present empirical techniques for identifying dominated cases that can easily be applied in practice. 
1 identifying dominated cases 
 we now present 1 alternative criteria for identifying cases that are dominated with respect to an incomplete query. we will refer to the dominance criteria identified in theorems 1  1 and 1 as dc1  dc1 and dc1 respectively. dc1 and dc1 are sufficient but not necessary conditions for a given case to be dominated by another case  while dc1 is both a necessary and a sufficient condition. dc1 and dc1 have the advantage of not relying on the triangle inequality  but only dc1 is guaranteed to detect all dominance relationships. 
   a limitation of dc1 is that it fails to recognize that the similarity of the more similar case c  is a moving target for the less similar case c1  and that the latter may be dominated even if it can equal or exceed the current similarity of c1. for example  if c  and c1 have the same values for one of the remaining attributes  then any increase in similarity gained by c1 with respect to this attribute is also gained by c . our second dominance criterion  dc1  ignores attributes for which c1 and c1 have the same values  thus making it less susceptible to this problem. 
   

1 	case-based reasoning 
   
   the cost of testing condition  a  of theorem 1 increases only linearly with the size of the retrieval set. at first sight  condition  b  may seem expensive to test  particularly in the early stages of query elicitation when |rs q| may be large. however  it can be seen from lemma 1 that if  a  is true and 
c1 is any case selected from rs q   then  b  is true if and 
   it is worth noting that failure of the underlying similarity measure to respect the triangle inequality does not affect the ability of a ccbr algorithm that uses the termination criteria presented in theorem 1 to provide perfect precision and recall. however  the use of dc1  which does not rely on the triangle inequality  as the dominance criterion is likely to affect retrieval performance in terms of dialogue efficiency. in the rest of this paper  we assume that the underlying similarity measure is regular  thus permitting the use of dc1 in the identification of dominance relationships. 
1 attribute-selection strategies 
we now examine the effects on dialogue efficiency of four approaches to attribute selection in ccbr algorithms that use the termination criteria we have shown to be essential to ensure perfect precision and recall. two of our algorithms are goal driven in that attribute selection is based on the ccbr1: select attributes in random order 
ccbr1: select attributes in order of decreasing importance 
ccbr1: select the attribute that maximizes the similarity variance of cases not currently dominated by the target case 
ccbr1: select the attribute that maximizes the number of cases dominated by the target case 
   attribute selection in ccbr1 is adapted from the approach proposed by kohlmaier et al. . however  an expected similarity variance over all values of each attribute is not computed in our approach. instead  the impact on similarity variance of each attribute is evaluated only for its value in the target case; this greatly reduces the computational effort involved in attribute selection. 
¡¡our experimental method is designed to compare average dialogue length for each attribute-selection strategy with the optimal dialogue length that can be achieved by any ccbr algorithm that always gives perfect precision and recall. any such algorithm  like the algorithms in our evaluation  must use the termination criteria identified in theorem 1. as in our previous experiments  each case is temporarily removed from the case library and used to represent the preferences of the user. to determine the optimal dialogue length for a left-out case  we simulate all possible dialogues based on that case; that is  with the available attributes selected in every possible order. the optimal dialogue length is the minimum number of questions asked over all such dialogues. for each left-out case  we also record the dialogue length for each of our attribute-selection strategies. 
   for each strategy  figure 1 shows the maximum  minimum  and average number of questions asked over all simulated dialogues. similar statistics are shown for the optimal dialogues determined as described above. ccbr1 gave the best performance  reducing the number of questions asked by up to 1% and by 1% on average relative to a full-length query. its average dialogue length of 1 is only 1% higher than the lowest possible average that can be achieved by any ccbr algorithm that guarantees perfect precision and recall. 
   attribute selection based on similarity variance  ccbr1  also performed well on this case library  with an average dialogue length of 1 compared with 1 for the random strategy  ccbr1 . with an average dialogue length of 1  selecting attributes in order of decreasing importance  ccbr1  was also more effective in reducing average dialogue length than the random strategy. 

   the case library used in our final experiment  www.aicbr.org  contains over 1 holidays and their descriptions in terms of 1 attributes such as price  region  duration  and season. the experimental setup is the same as in our previous experiment except that we do not attempt to determine the optimal length of each dialogue. the results are shown in figure 1. once again  ccbr1 gave the best performance  reducing dialog length by up to 1% and by 1% on average. on this occasion ccbr1  though reducing average dialogue length more effectively than ccbr1  was outperformed by ccbr1. 
target case. in spite of its low computational cost  linear in the size of the case library  this strategy gave close to optimal performance on the pc case library. it was also more effective in reducing average dialogue length than the other strategies evaluated on the travel case library  a standard benchmark containing over 1 cases. 
   a feature of cbr recommender systems on which the techniques presented in this paper depend is that each outcome class  a unique product or service  is represented by a single case  mcsherry  1 . investigation of criteria for safe termination of problem-solving dialogues in other areas of cbr is an important objective for further research. 
