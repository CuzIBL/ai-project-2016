 
this paper describes how a competitive tree learning algorithm can be derived from first principles. the algorithm approximates the bayesian decision theoretic solution to the learning task. comparative experiments with the algorithm and the several mature ai and statistical families of tree learning algorithms currently in use show the derived bayesian algorithm is consistently as good or better  although sometimes at computational cost. using the same strategy  we can design algorithms for many other supervised and model learning tasks given just a probabilistic representation for the kind of knowledge to be learned. as an illustration  a second learning algorithm is derived for learning bayesian networks from data. implications to incremental learning and the use of multiple models are also discussed. 
1 	introduction 
systems for learning classification trees  quinlan  1; 
cestnik et al  1  are common in machine learning  statistics and pattern recognition. despite these successes  the study presented here is not motivated by a view that tree classifiers are inherently superior to other learning systems  see for instance  the argument against so-called universal learning algorithms in  buntine  1b  . rather  this study is motivated by the view that tree learning is an ideal benchmark problem for studying learning theories. the problem is used here to gain insight into generic problems in empirical learning  and to explore a general strategy for designing learning algorithms. 
   first  current tree learning methods are mature in that many modifications have been suggested in recent years  but little real gain has been made1. there are now many different tree learning methods and none clearly superior  mingers  1   the systems have stood the test of time 
'research institute for advanced computer science 
1
　　 except  perhaps  in the area of learning strictly logical rules where recent techniques learn new terms; but the focus of this paper is primarily learning noisy or uncertain concepts  where gains have been more incremental. 
1 	learning and knowledge acquisition 
and are now widely used for benchmarking and comparative studies. if an algorithm design strategy yields a superior tree learning algorithm despite this tough competition  it is likely the strategy will be successful on other learning tasks. 
　second  tree learning is a common meeting ground for the different areas of inquiry outside of ai that have learning theories of some form or another such as classical statistics  breiman et a/.  1  and minimum encoding approaches  rissanen  1 . this provides a rare opportunity to contrast these different learning theories theoretically as well as empirically. comparative studies conducted to date in ai have provided little understanding about generic principles of algorithm design  partly because comparisons have been made of algorithms that use different knowledge representations  and comparisons have largely ignored the theoretical principles on which the algorithms were based. 
   finally  classification trees have been the framework in which a number of discoveries have been made in machine learning: the overfitting problem  related to the accuracy-complexity tradeoff and ockham's razor   incremental algorithms  schlimmer and granger jr.  1   and interactive induction  shapiro  1 . the learning problem tree systems tackle is difficult enough to be considered  unlearnable   yet simple enough so not requiring the specialized machinery to learn relations or do constructive induction. in this spirit  this study presents a number of additional discoveries about problems generic to empirical learning. 
   this paper reviews the bayesian development of a system for learning tree classifiers  from the theoretical basis  through the hacking required to make the system work  to comparative results with other systems. the development is presented as a generic algorithm design strategy in the second section  and the results discussed in the third section. more detail of the statistical aspects of the system can be found in  buntine  1a; buntine  1c . because of the large number of different trials and data sets that were used  full detail of the results are reported elsewhere  buntine  1c . 
　this paper also discusses some insights that have come out of this study: an emerging trend in machine learning towards the use of multiple models  kwok and carter  1; gams  1; jacobs et a/.  1   a generic method to overcome the problem of repeated restructuring in 
incremental learning  crawford  1   and a better understanding of learning theories and their role in helping us design learning algorithms. these are discussed in the fourth section. 
　we can now design algorithms for many other supervised and model learning tasks given just a probabilistic representation for the kind of knowledge to be learned. as an illustration  a method is outlined in the fifth section for learning bayesian networks  lauritzen and spiegelhalter  1/  a common representation in medical expert systems. this is a model learning task. the design strategy can also be applied to other learning tasks such as probabilistic rule systems  n-gram models  such as bigram and trigram models  used in speech recognition and natural language  and the function-finding task that is the basis of scientific discovery algorithms. the strategy has also been applied to analyse the training of feed-forward neural networks  buntine and weigend  1   where popular heuristic procedures for cost functions and network pruning were found to conform well to corresponding methods developed from bayesian first principles. 
1 	the algorithm design strategy 
the algorithm design strategy presented here is based on approximating bayesian decision theory. the justification for bayesian decision theory comes from fundamental principles of how uncertain reasoning should be done  berger  1 . the theory applies widely in inference and plausible reasoning and its use is continually expanding in ai. but there is not a single  bayesian learning algorithm   as some people mistakenly believe when they learn about bayesian classifiers  tou and gonzalez  1 . rather  bayesian decision theory presents computational guidelines on how learning should be done for many different learning problems  including for instance  improving an approximate theory using data. 
   the basic tenet of bayesian decision theory is that if we do not know something with reasonable certainty  then we should look at some reasonable and mutually exclusive alternatives and weigh them up  to help us make a  representative  decision. a reasonable alternative is one we currently have high subjective belief in. i will first explain how this applies to trees  buntine  1a   to introduce the notation. this is done for the two-class problem with discrete tests at nodes  but easily extends to the multi-class problem  and adjustments for realvalued tests at nodes exist  buntine  1c  sec.1.1 . the formulation is sufficiently general so that it could just as well be applied to other models such as probabilistic rules  bayesian networks  or one of many other knowledge representations that have a probabilistic interpretation. 
　class probability trees have a vector of class probabilities at their leaves  breiman et a/.  1   and they represent a conditional probability distribution of class value conditioned on example value. a particular class probability tree can be represented by its discrete component t  the tree structure given by the shape of the tree and the tests at the leaves  and its continuous component 1  the leaf class probabilities. this gives the conditional probability distribution  which is the likelihood function for the class probability tree specified by t and 1 for the training example  c'  x' . 
　suppose we are given a training sample of examples x and their classes c  together with a new example x' whose class we wish to predict. if the goal is to minimize errors in prediction  other utility functions can be handled similarly   decision theory says we should choose the class c' to maximize the posterior class probability 
 using the tree model  this is the posterior average of the class probabilities predicted for d from all possible class probability trees: 

formula  1  simply says to average the class predictions made for each tree structure  where   the posterior probability of the tree structure t  is the weight used in the averaging process. in this formula  is the prior on the space of class probability trees  and  the likelihood of the training sample. 
　the algorithm design strategy is based on designing a heuristic procedure to find a single structure or set of structures that can be used to approximate formula  1 . this is described by the following 1 steps  and table 1 gives the results of the analysis. 
　1. precisely define the form of knowledge to be learned by representing it in terms of a parameterized likelihood function  a particular parameterization is referred to as a model which has a structural  discrete  and a continuous component as described for trees. 
　1. develop a prior over the structural and continuous components of the model. the form of the prior should be flexible enough so that it can be changed from application to application. in  buntine  1a/  a range of priors are presented for trees. one is given in the table. the prior on the tree structures  is not given but could  for instance  be assumed uniform. the prior on the continuous component is a product of symmetric beta distributions over the probabilities 1. the function b{n m  given there is the beta function found in many mathematical handbooks. 

　1. given a training sample sample  determine a 
　suitably efficient way of computing or approximating the posterior of the structural component of the model. see  buntine and weigend  1  for an approximation in the more complex domain of feed-forward neural networks. 
	buntine 	1 


table 1: bayesian analysis of learning class probability trees 

　1. devise a heuristic search procedure for searching the space of structures to find structures with high posterior. a simple one-ply lookahead procedure can be tried  which corresponds to the standard tree growing algorithm  quinlan  1   although two-ply or threeply versions could also be tried. start with the trivial structure  the empty tree. then consider extending the structure by a single ply  which for trees means growing a single node by adding a test with leaves at the outcomes of the test. a heuristic measure to evaluate the quality of the new growth is given in the table. to prevent overflow/underflow  this measure has to be calculated in log-space. the measure behaves similarly to quinlan's information gain heuristic  but has some correction terms for multivalued attributes and small samples. this heuristic can also be used as a stopping rule  cestnik et a/.  1 . 
　1. given a training sample sample and a structure t  determine a formula or approximation for the posterior expected values of the parameters 1  as required for formula  1 . 
　1. devise a procedure for approximating the summation of formula  1  by a small set of high posterior structures. several suggestions are given below. this is currently an active area of research. 
　minimum encoding approaches  rissanen  1; wallace and freeman  1  to supervised learning and the so-called  most probable model   bayesian  approach are first-order approximations to formula  1   because they attempt to find a single high posterior structure. step 1 in the design strategy above is the main improvement suggested here  because it suggests how to improve on this. 
1 	learning and knowledge acquisition 
there are three techniques for performing step 1. 
these correspond to different ways of estimating the sum in formula  1 : 
smoothing: the sum can be computed in closed form if it is restricted to the set of tree structures obtained by pruning a large tree structure in all possible ways. a linear time algorithm is given in  buntine  1c  
lemma 1.1 . this is called smoothing because it is equivalent to smoothing out the class probabilities at the leaf of a tree by averaging them with some class probabilities from interior nodes of the tree. 
averaging: the sum can be approximated by searching for and storing many dominant terms  i.e. many high posterior trees structures. we can build multiple tree structures  and combine them together efficiently in an and-or representation called option trees. growing option trees and then applying a similar summation process to smoothing is called tree averaging. 
multiple models: the sum can be approximated by using importance sampling and monte carlo estimation. that is  a few tree structures are generated in approximate proportion with their posterior  this is done using the tree growing heuristic  buntine  1a    and their class probability vectors uniformly averaged. 
1 	experimental results 
reimplementation1 of cart  breiman et a/.  1   c1 
 quinlan  1   and a generic minimum encoding ap-

proach were compared with the bayesian approaches1. the algorithms were applied to 1 different data sets with a range of characteristics. these included quintan's hypothyroid and xd1 data  quinlan  1   the cart digital led problem  breiman et al.  1   three medical domains made available by bratko's induction group  cestnik et a/.  1   and a variety of other data sets from the irvine machine learning database such as  glass    voting records    hepatitus   and  mushrooms.  data sets where divided into training/test pairs  a classifier was built on the training sample and the accuracy  predicted accuracy  and mean square error estimated on the test sample. this was done for 1 random trials of the training/test pair  and for 1 different training set sizes  and significance of difference between two algorithms was checked using the paired t-test. 
　of the algorithms tried  a generic minimum encoding approach   re- cart   re- c1  bayesian smoothing and bayesian averaging  the averaging approach using a uniform prior on tree structures was the only approach that consistently produced the best predictions. in most cases it was pairwise significantly better than all other non-bayesian approaches at the 1% level. bayesian averaging with a two-ply lookahead during growing yielded improvement in predictive accuracy averaged over 1 trials as often as high as 1%  sometimes more. with a 
　one-ply lookahead  the improvement is not as dramatic but still significant. one has to be cautious in interpreting this result  however  because option trees are more than just a single decision tree  they effectively involve an extension of the model space. also the growing of option trees sometimes involved extra orders of magnitude in time and space. although this only occurred for small samples  or where trees were inappropriate for the learning problem  like xd1 which is a dnf concept poorly expressed using a tree . certainly the bayesian approaches are competitive  and they appear to be superior for smaller samples. 
　for many of the data sets  it was appropriate to select a prior that had stronger preference towards smaller trees. when this was done  bayesian smoothing of a single tree gave good predictions  often as good as the bayesian averaging with one-step lookahead. this is useful because we would not always wish to go to the computational expense of bayesian averaging  or we may require just a single tree for explanatory purposes. 
　a second point of comparison of the algorithms is the parameters available when driving the algorithms. cart and c1 have default settings for their parameters. with cart  heavy pruning can be achieved using the 1-se rule rather than the 1-se rule. the number of partitions to use in cross validation cost complexity pruning can also be changed  but the effect of this is unclear  especially since leaving-one-out cross validation cost complexity pruning gives poor predictive accuracy. the minimum encoding approaches are  according to the purist  free of parameters. however  these approaches often strongly overprune  so quinlan and rivest  quin-
1
    the tree algorithms were written in c and integrated with an experiment control package. the entire suite is available from the author. 
ian and rivest  1  introduce a parameter that allows lighter pruning. so all approaches bayesian and non-bayesian have parameters that allow more or less pruning. these can be set depending on the amount of structure believed to exist in the data. in the fuller bayesian approach with option trees and bayesian averaging  choices available also allow greater search during growing and fuller elaboration of the available optional trees. these parameters have the useful property that predictive accuracy  or some other utility measure  and computational expense are on average monotonic in the value of the parameter. the parameter setting allows improved predictive accuracy at computational expense. 
1 	discussion 
1 	multiple models 
machine learning research  as with classical statistics and minimum encoding methods  has been largely concerned to date with trying to find the best single tree  the best non-redundant rule set  or the best relational rule explaining the data. 
　several researchers have now reported being able to significantly improve learning performance by instead working with multiple models. this is an approximate method for doing the averaging presented in section 1  and is different from the technique of combining independent sources of knowledge multiplicatively  using the probability formula for independence  the basis of  idiot  bayes classifiers . 
kwok and carter used a heuristic approximation to 
bayesian decision theory  kwok and carter  1 ; they built multiple decision trees and when processing a new example  processed it with each tree individually and averaged the multiple class predictions. gams discussed the notion of  redundant knowledge   gams  1   where he weighs up the predictions of several overlapping rules when classifying a new example. jacobs et al. present another approach that does adaptive mixing of multiple feed-forward networks  jacobs et a/.  1 . a survey of some related theoretical work in  aggregrating learning strategies  and  weighted majority  is given in  haussler et a/.  1 . 
　suggested modifications to learning algorithms rarely perform consistently better  see for instance  mingers  1  . the most striking thing about the use of multiple models is that it does appear to give consistently better performance  and can often be implemented as a control module on top of an existing algorithm. 
1 	incremental learning algorithms 
incremental learning applies when new training examples are continually being supplied and we wish to update our current hypothesises  given the few additional examples. the contrasting approach is batch learning where examples are supplied in one batch. the major approach for developing an incremental algorithm is to modify a batch learning algorithm. this has the advantage that the long sequence of theoretical and empirical work that led to the development of the algorithm is not wasted. some algorithms  however  are designed to be 
	buntine 	1 
incremental from the beginning  gennari et a/.  1 . these algorithms can suffer from order-sensitivity  langley and mckusick  1   which is an incremental manifestation of the overfitting problem  a problem which is largely solved for batch algorithms. 
　there are two broad cases where a batch algorithm can be easily converted to an incremental algorithm. in the first case  bayesian classifiers and many classical statistical methods are naturally incremental because they are calculated from simple summary statistics such as means and variances that are readily updated with additional data. these summary statistics are an example of sufficient statistics  discussed in most advanced statistical texts. in the second case  perceptrons  most neural net methods  autoclass  cheeseman et al.  1   and many classical statistical clustering algorithms use iterative convergence methods. these are not naturally incremental  because their performance is generally poor with only one iteration of the training sample. but because of their iterative nature  they can be easily modified to form incremental versions. for instance  one could add the new training data to the next iteration. 
　some batch algorithms do not lend themselves naturally to incremental versions. in these cases  as done with trees  schlimmer and granger jr.  1   the batch learning algorithm is differentiated. that is  an incremental algorithm is designed that attempts to do the least amount of work to modify a tree given new data so that it looks as if the tree was constructed from the entire training sample using the corresponding batch algorithm. crawford reports this leads to the problem of repeated restructuring  crawford  1 . this occurs in trees when some subtree is repeatedly restructured during incremental updating due to vacillation in what is currently considered the  best  test at the root of the subtree. this occurs particularly with learning noisy concepts  earlier incremental studies looked at logical concepts . the bayesian methods offer a generic remedy for this problem. essentially  we only restructure if we strongly believe the new substructure will be better  rather than immediately restructuring the moment some new substructure seems slightly better. the logarithm of the lookahead measure given in table 1 returns a measure whose units are in log-odds. so one can easily implement an algorithm that only changes the current test at a node if there is another test that has a good log-odds  e.g.   1  of being better. this would prevent vacillation  and experiments show it does not unduly effect predictive accuracy. 
1 	comparisons of learning theories 
a basic tool of learning theory in pattern recognition and computational learning theory is uniform convergence. if a sample size is large enough  uniform convergence theory provides bounds on the predictive performance of classifiers learned by minimizing empirical error  vapnik  1 . in practice when sample sizes are not large enough  one needs to make a tradeoff between the complexity of the hypothesis chosen and the accuracy of the fit to the data. here  uniform convergence methods give less guide  only asymptotic  i.e. large sample  1 learning and knowledge acquisition 
theory regarding their performance  see  for instance  the principle of structural risk minimization in  vapnik  1  . these techniques have no theoretical justification that they will provide good average-case performance on smaller samples. some experimental comparisons are given in  buntine  1c . learning theoreticians are now using bayesian methods  haussler et al.  1  to analyse the smaller sample case  as suggested earlier by buntine  buntine  1 . 
　statisticians overcome these overfitting problems with a variety of resampling techniques  as applied to trees  see  breiman et a/.  1; crawford  1   that have good intuition and performance  but again only have asymptotic theory. the tree experiments  using crossvalidation  show these techniques work well  however they can overprune  so do not have the consistency of the full bayesian approach when sample sizes are smaller. they are quick to code in many cases and hence offer a viable alternative. 
　only bayesian decision theory is able to claim that it is the most rational alternative in the information poor environment of learning from smaller samples  berger  1 . minimum encoding approaches  rissanen  1  are sometimes touted as alternatives  however they are  mathematically  an interpretation of the bayesian  most probable model  approach  which itself is an approximation to bayesian decision theory  wallace and freeman  1; buntine  1c . experiments support this approximation view  and also indicate the minimum encoding approximation can degrade significantly as the sample size decreases. this happens because the encoding methods do not consider multiple models  as suggested here. 
　in bayesian theory  priors are viewed as assumptions that are essential when making inference from limited information such as a small training sample. uniform convergence theory constrains samples so they are large enough to make the effect of the prior assumptions negligible  buntine  1c  lemma 1.1 . according to bayesian theory  methods applied to smaller samples have implicitly built in particular assumptions which correspond to a choice of prior. breiman et a/.'s cost complexity pruning with cross validation and the 1se rule  for instance  favors smaller trees. and the various minimum encoding approaches  rissanen  1; quinlan and rivest  1  have a very strong preference towards smaller trees. bayesian methods differ in that they make these unavoidable prior assumptions explicit  allowing them to be specified by the user  or providing fairly objective assumptions as a fall-back. 
1 	learning bayesian networks 
to illustrate the algorithm strategy again  i will outline the development of an algorithm for learning bayesian networks. this yields a one-step lookahead heuristic search algorithm  with smoothing on the final structure. the algorithm is analogous to the tree algorithms just presented. a similar method has been independently developed and implemented by herskovits and cooper and they report good experimental results  cooper and herskovits  1 . the different approach of geiger et al is concerned with learning networks from known depen-

dency information  geiger et al  1   for instance  as extracted from a large sample  so is not relevant to the problem of learning from a smaller sample when dependency information is uncertain. 
　bayesian networks in their simplest formulation specify dependence properties between variables by using a directed acyclic graph. they describe probabilistic models useful for non-directed classification. figure 1 shows 

figure 1: bayesian network for a simple system 
a simple bayesian network. the set of variables that have outgoing arcs to a variable are called the parents of the variable. these parents specify the network structure. each variable also has an associated conditional probability table which gives probabilities for different values of the variable given values of its parent variables. for instance for the graph in the figure  we need values 
for - the parent struc-
ture and the conditional probabilities specify the model  as given by the likelihood function in table 1. for ease of presentation  the learning algorithm presented here assumes variables are binary; this can be easily extended to multivalued or to real-valued variables. 
　the following notation is used. a bayesian network consists of a set of binary discrete variables where each variable has a set of parent variables iix. assume variables take the values 1 or 1. for instance  for the graph in the figure   the set of values for the cartesian product of variables in iix is v iix . the number of examples in the training sample 
sample with assuming every example in sample has variable values fully specified. the conditional probabilities for variables are given by the probabilities as specified in the likelihood function in table 1. 
　the learning algorithm is developed analogously to the tree learning algorithm. the corresponding results of the bayesian analysis are given in table 1. the network model has a structural component ii  the parent function  and a continuous component 1  the conditional probabilities. the prior on the continuous component is similar to the tree prior. a form for pr ii  is not given in the table; it could be chosen to be uniform  or take some other simple form. a one-step lookahead heuristic search procedure for growing a high posterior structure can be developed analogous to the tree case. start with the trivial structure where no variables have parents  and repeatedly add a new parent to maximize the posterior at each stage. notice the adding of parents also has to be constrained so that the resultant graph has no cycles. a suitable heuristic measure for lookahead is given in the table. this gives the increase in posterior due to making y a parent of x. notice the lookahead values calculated for a variable x remain unchanged if a new parent has just been added to another variable x'. this means at each cycle when choosing the next best parent to add  little recalculation needs to be done. 
acknowledgement s 
thanks to ross quinlan especially  also padhraic smyth  
peter cheeseman and robin hanson. university of strathclyde and turing institute provided some support. 
