learning technique and 
the stochastic approximation method 
f r i d r i c h sloboda and jaroslav fogel i n s t i t u t e for engineering cybernetics 
slovak academy of sciences bratislava 
dubravska cesta  czechoslovakia 

summary 
in the paper is presented a new method for accelerating the convergence of the 
stochastic approximation method.which can be used as a mathematical technique to solve some learning problems. 
	1. 	introduction 
one of the main aims of contemporary theory of adaptive learning and self-learning systems is the u n i f i c a t i o n of the problems of adaptation learning and self-lear-
ning from one point of v i e w   i . e . t h e determination of the appropriate mathemat i c a l technique which would be able to solve as large a class of problems as possible.theoretically it seems that the theory of stochastic approximation could solve t h i s problem1 . 
       in the learning problem of d i v i d i n g input s i t u a t i o n s into n classes it is poss i b l e in a deterministic case to consider the l e a r n i n g - i s is known1 -as an approximation of the function which divides two d i s j o i n t classes.let t h i s decision funct i o n be w r i t t e n as 
		1  
where x is an 1-dimensional vector and y is a quantity showing the class to which a pattern belongs.in the stochastic formulation of the problem where the condit i o n of d i s j o i n t classes is not required  y can be taken as the p r o b a b i l i t y that x belongs to one class and 1-y is the prob a b i l i t y that x belongs to another class. the function f in equation  1 can be approximated by the f i n i t e expansion 

where is an n-dimensional vector of c o e f f i c i e n t s    p 1 ib an n-dimensional vector of linear independent functions and t stands for transposition.let p  be an unknown p r o b a b i l i t y density function of the observed vector  x a measure of the approximation of i t  through c1  can be provided by the mean value of any s t r i c t ly convex function/  with argument f♀u;-ftf  * 
then we can write the measure of the ap-

where i is the space of a l l observed vectors a .the best approximation corresponds to such a choice of vector  that t a; attains i t s minimum.this problem can 
be solved by the stochastic approximation method where the influence of noise can also be considered. 
　　　the p r a c t i c a l use of the stochastic approximation method as a mathematical technique for l e a r n i n g   s e l f - l e a r n i n g   and adaptation depends on the speed of convergence of the methods used.this paper deals with t h i s problem.from the pract i c a l point of view the solution of extremumsearching problems has great s i g nificance .the stochastic approximation methods as methods of sequential i t e r a tions in the case of extremum-searching problems exploit various forms of the i t e r a t i v e gradient method.asymptotic behaviour and the speed of convergence were observed by many authors for various modifications of t h i s method.a common feature of a l l these algorithms of gra-
dient methods an a l l these modifications did not however change.this is a way in which information is gained during the i t e r a t i v e process.the way of gaining i n formation the structure of the informat i o n and i t s interconnection provide the basic clue to the construction of the new algorithms and are also the c r i t e r i o n of q u a l i t y . i f there is not s u f f i c i e n t information to make the next step in the i t e r a t i v e scheme then additional information must be gained by experimental interim steps.from t h i s point of view those a l gorithms are important which do not need experimental steps before the next step can be made.the s t a b i l i t y of used algorithms against noise depends d i r e c t l y on the structure of gained information and i t s interconnection.not every algorithm 
which solves the problem in the determin i s t i c case is stable against noise. many control processes can be described only through the mathematical models possessing some uncertainties in the form of a set of random variables with unknown p r o b a b i l i s t i c descriptions. 

-1-

　　　in t h i s paper we describe an algorithm which has the above mentioned prop e r t i e s ; i.e. it does not use experimental steps and information is gained by steps during the i t e r a t i v e process and it s o l ves the extremum-searching problem in the presence of noise. 
1. 	stochastic approximation methods  
the f i r s t methods of stochastic approximation were the algorithms of robbins and monro*   b l u m *  kiefer and wolfowitz l for finding the zero point of the func-
t i o n or the extremum of the one-dimensional function in the presence of noise. a generalization for multidimensional functions was made l a t e r by blum* and these r e s u l t s were u n i f i e d by dvoretzky'  
whose r e s u l t s we s h a l l use.as the speed of convergence of the method given by robbins and monro depends on the type of f u n c t i o n   o f t e n t h i s speed is not satisfact o r y from the p r a c t i c a l point of view. 
　　　we s h a l l use the two following ways of accelerating the convergence .let * l  be a fixed but unknown function which has a unique rootx= .let 1 is a random var i a b l e with d i s t r i b u t i o n function w vt  1 which depends on the real parameter ♀   the robbins-monro procedure is defined for searching the zero point of regresion function 

expression 1 y*cvvi  retains i t s s ignore  then the value of o in the algorithm does not decrease /as it does in the algorithm of robbins and monro/ 1 but remains unchanged u n t i l the f i r s t change of signum.on the condition that a*  is a nonincreasing sequence kesten shows the convergence of t h i s algorithm w i t h p r o b a b i l i t y one.the advantage of t h i s algorithm l i e s in the fact t h a t   u n t i l the i t e r a t i v e process reaches the domain of i t s extremum the algorithm retains a greater value of step and so decreases the influence of noise  as t h i s is i n d i r e c t l y dependent on the value of the step  i.e. the greater the value of the step the smaller the influence of the random component.kesten examined the p o s s i b i l i t y of also u t i l i z i n g this idea 
also for the algorithm of kieffer-wolfowitz 
 a  
in order to find the extremum of the r e gression function.kesten shows the convergence of t h i s algorithm only with an additional strong condition for sequence c . instead o f the o r i g i n a l condition c o f the condition c+* coast  is essential .and so  in t h i s case *  in general does not have to converge to the point in which the regression function achieves i t s e x t r e mum.this leads to two opposing demands: 
	on 	one hand the condition of con-
vergence i t s e l f   i . e . t h a t the value of should be as low as possible;on the other hand the question of the speed of convergence  because  the greater the value of the smaller the influence of noise. obviously  t h i s is v a l i d only so long as the algorithm does not achieve i t s e x t r e mum domain.the idea behind these algorithms for extremum-searching of the k-dimensional function is the way of determination of the gradient.up to now used standard method for searching the gradient is a s t a t i c one and the gradient is determined using the experimental steps.in the case of stochastic approximation the symmetric gradient is the most suitable and t h i s needs 1k experimental steps for the determination of d i r e c t i o n of the g r a d i e n t . f u r t h e r   i t w i l l be given the algorithm which creates a sequential process during which the gradient is searched without using the experimental step1.this sequential multidimensional search algorithm creates a sequential process of k onedimensional search algorithms.this algorithm does not have the above drawbacks and i t s speed of convergence is better than the speed of convergence of the above-mentioned modificat i o n s . 

-1-






ge value are used far from the extremum; and the nearer the extremum the smaller the step becomes*the fact that t h i s method does not use the experimental steps 
means t h a t   i n t h i s case the convergence is accelerated and the method gives considerable better results than other methods .the method was used in pattern r e cognition for d i s j o i n t classes. 
1. v.dupac  	 1 kiefer-wolfowitzove approximacni metode  cas.pest.mat. 
1/ pp.1 
1. a.dvoretzky   on stochastic approximation proc.of the third berkeley 
symposium on math.statistics and probability vol.1 berkeley 1 pp.1 

 f i g . l . the multidimesional search algorithm bibliography: 
1. h.robbins s.monro   a stochastic approximation method  a.m.s.1/ pp.1 
1. j . k i f e r   j . w o l f o w i t z   	 stochastic e s t i mation of the maximum of a regression function a.m.s. 1 /1/  pp.1 
1. j.r.blum  	 approximation methods which convergence with p r o b a b i l i t y one  a.m.s. 1 /1/ pp.1 
1. j.r.blum   multidimensional stochastic approximation methods  a.m.s. 
1 /1/ pp.1 
1. v.fabian  	 stochastic approximation methods  cech.mat.zurn. 1/ n o . l   
/1/ pp.1 
1. h.kesten   accelerated stochastic approximation  a.m.s. 1/ pp.1 
1. d.j.wilde   optimum seeking methods   prentice hall 1 
1. z.cypkin  	 adaptation learning and 
s e l f - l e a r n i n g in control systems  
third congress of ifac london 
1 
1 . f.rosenblatt   principles of neurodynamics perception and the theory of brain mechanisms  spartan books  washington d.c.1 
1. aizerman braverman ro1onoer   veroiatnostnaia zadaca ob obucenii 
automatov raspoznavaniu klasov i metod potencialnych funkcii .automatika i telemechanika moskva  
t.1 no.1 
1. z.cypkin   a vse ze suscestvuet li t e o r i a sinteza optimalnych adaptivnych sistem  automatika i telemechanika  no.l 1 moskva 
1. i.stratonovic  	 suscestvuet 	t e o r i a sinteza optimalnych adaptivnych  samoobucaiuscichsa samonastraivavaiuscichsd sistem  automatika 	i telemechanika no.1 moskva 
1. e.d.avedian  	 k odnoj m o d i f i k a c i i algoritma robbinsa i monro  automatika 	i telemechanika no.1 

-1-

-1-
