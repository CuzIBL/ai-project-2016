 
　　　a method is presented for matching two scene descriptions  each of which consists of a set of measured feature vectors with estimated uncertainties. the two scenes differ by a transformation that depends on a few unknown parameters. the method performs a search by sequentially matching features of one scene to those of the other scene  solving for the transformation parameters by means of a generalized least-squares adjustment  computing the probabilities of these matches by means of bayes* theorem  and using these probabilities to prune the search. an example is given using scene descriptions of the martian surface in which the features are rocks approximated by ellipsoids. 
introduction 
　　　a common problem in vision is that of matching. this may involve ma telling one two-dimensional image to another  matching a three-dimensional object to its two-dimensional projection  or matching two three-dimensional descriptions of the same scene. for want of a better term  the entities to be matched will be called  scenes . in general  the two scones may be related in various complicated ways. for example  there may be  rubber sheet  distortion   l     there may be independent changes in different parts of the scene as in the stereo matching problem   or there may be arbitrary changes in the different portions of a complicated object as in matching to a generic model . however  in this paper the problem is restricted to the case in which the relationship between the scenes to be matched can be expressed by a few parameters  each of which has a global effect. restricting the problem in this way allows the use of robust  efficient techniques that would not be applicable in the more general case. 
　　　it is further assumed here that the matching will be done by using local features that have been detected in each scene  that the a priori 
*the work described in this paper was started at 
stanford university and was completed at the jet 
propulsion laboratory  california institute of technology  under contract with the national aeronautics and space administration. correspondence between features in the two scenes is unknown  that each feature is described by a vector of measured feature parameter values  and that for each feature the probability distribution of its measured feature vector values is known. although in principle any probability density function of errors in the feature vector could be used  the following treatment is restricted to the special case in which the error distribution is determined by its covariance matrix. the possibility exists that a feature detected in one scene 
w i l l not be detected in the other  and this possibility is covered by estimates of probability of detection based on experience. 
　　　for example  consider the matching of two aerial photographs which differ by an unknown translation  rotation  and scale factor. in this case four parameters determine the transformation. the features might be local landmarks whose twodimensional position and orientation have been measured  in which case each feature vector would have three components. another example might be recognizing in a two-dimensional image the projection of a known three-dimensional object. six parameters determine the position and orientation of the object. the features might be markings  corners  or edges that are known in the object model but must be found in the image. 
　　　for a third example  consider an object finder  1  1  which produces a description of a threedimensional scene in terms of objects represented by ellipsoids. thus each feature vector consists of the nine parameters that define the ellipsoid. suppose that the same area has been viewed from two different locations by a roving vehicle. there w i l l be a partially unknown translation and perhaps rotation  requiring six parameters in general  between tne coordinate systems cf the resulting two scene descriptions  caused by errors in the 
navigation system of the vehicle. it is desired to match these two descriptions in order to correct the navigation data.  this special case is discussed further elsewhere   and an example of its use is presented later in this paper.  
　　　by using the probability distributions of the feature vectors  it is possible to find the optimum matching of the scene in an efficient way that does not consider all possible matches of individual features and yet does not overlook matches 

1 

that nave an appreciable chance of turning out to be correct. in t h i s regard the method to be presented can be considered to be an improvement over the method of price  and the suggestion of milgram and bjorklund   1   . it also has some overlap with the method of fischler and elschlager  l    l y i n g somewhere between t h e i r dynamic programming 
method and t h e i r linear embedding algorithm.  in t h e i r terminology  a   s p r i n g   would connect each feature to some constant point in the scene for the problem stated above. this is not the kind of s i t u a t i o n for which t h e i r method was designed to 
work w e l l .   
     it is assumed below that the matching of features is one-to-one  with perhaps some features l e f t unmatched  and that a l l features are of the same type  so that a feature in one scene can be 
matched to any feature in the other scene . however  the mathematics can be generalized to the case where several features in one scene can be matched to the same feature in the other scene and 
to the case where there are d i f f e r e n t types of features that cannot be matched to each other  with perhaps a d i f f e r e n t size of feature vector for each type . 
notation 
　　　matrix notation w i l l be used.  hohn  provides a good text on matrix algebra.  for any mat r i x a  i t s transpose is denoted by at  i t s i n -
verse by a 1  and i t s determinant by det a . vectors  of any size  are represented by column mat r i c e s . the covariance matrix of any vector x is defined in the usual way to be 
 ♀     x - ♀ x    x-1*x  t   where ♀ is the mathematical expectation operator. a p a r t i a l d e r i v a t i v e matrix of a vector y w i t h respect to a vector x is defined so that the rows correspond to elements of y and the columns correspond to elements of x. 
the two given scene descriptions are called 
scene a  composed of features a l   a1  etc.  and scene b  composed of features b l   b1  e t c .   . for each feature of each scene the following are given  w i t h subscripts to denote p a r t i c u l a r features: 
x = measured feature vector. 
h = covariance matrix of x. 
b   p r o b a b i l i t y that the feature w i l l be present in a matching scene. 
r = a p r i o r i p r o b a b i l i t y density of feature vector for t y p i c a l scenes  evaluated at x but not otherwise using measured data. 
  i t is necessary that the dimensionality of scene b be at least as great as that of scene a  so that any feature in scene b can be uniquely projected into scene a if the transformation is known.  
the following global quantities are given: 
p1 - a p r i o r i p r o b a b i l i t y that the two scenes match  that i s   represent the same phys i c a l scene  . 
g1 - a p r i o r i estimate of vector of parameters used in the transformation from scene b to scene a. 

optimum match 
　　　the method to be used involves producing tent a t i v e matches of the features in one scene to those in the other and for each match m computing the a p r i o r i p r o b a b i l i t y ttm  computing the transformation vector gm  and comparing the residuals of the f i t to the given feature vector d i s t r i b u tions to evaluate the p r o b a b i l i t y density pm. then 

1 

bayes' theorem is used to compute the a posteriori probability pm the m for which pm is near unity  if any  can be assumed to be the correct match  and the corresponding gm can be used for g. 
     thus the a posteriori probability of m is computed by means of bayes' theorem as follows: 
	 1  
since p1iim is the a priori probability of the scene matching according to m  l-p 1 is the probab i l i t y of the scenes not matching  and pm and p1 respectively are the probability densities that the observed results  feature vectors  would follow from these events.   i t would appear that a l l combinations of feature matches would have to be used in this computation  but a way of avoiding this 
will be described in the next section.  it remains to describe the computation of     pm and p . 
	m' m 	o 
　　　the ttm quantities needed in  1  can be found by the following reasoning. the probability that feature ai w i l l be matched to some feature in scene b is b a l   the probability that it will be unmatched is l-b a i   and similarly for bbj and  this is only approximately correct here because of the fact that the parameters being adjusted affect the weights through rj in  1 .  	thus  

if f is nonlinear  the above process may need to be iterated.  g' would be g1 on the f i r s t itera-
tion but later would be gm from the previous itera-
tion.   
	bj	thus the 	duals are 
             1 is for the case in which feature ai is unit includes the a priori distribution of scene a features only  to be consistent with the 
　　　the solution for the g parameters for a particular matching is computed as follows. 	an approximation to g  denoted by g'  is used to compute the partial derivative matrices p and r of 
the transformation f g' xb  as defined in the 
notation section.  note that p and r are implicit functions of g' and xb  in general.  then for this 
approximation a discrepancy vector u and its covariance matrix t for each matching of feature ai with feature bj is computed as follows: discrepancies being computed in scene a coordinates according to  1 .  strictly speaking  p j j 
for matched features should include the effects of the a priori distribution also. however  since the 
a priori distribution is usually much wider than that given by t  this usually would have l i t t l e effect.  then  the probability density for the complete match is the product of a l l of the p i j values in this combination times the probability density function of the a priori parameter values  as 		follows: 
the solution for the parameters can be obtained by a generalized least-squares  minimum-variance  adjustment according to the general method described in  or in appendix a of   which produces the maximum-likelihood solution if the errors have the normal  gaussian distribution. 
1      the above solution can be used to obtain pm for use in  1   provided that the distribution of the measurement errors is known. first the resi-


priori parameter values are included in the summation by letting u1 = c1 - c'. therefore   1  is equivalent to the following when the errors have the normal distribution: 
	 1  
　　　in order to be consistent with the above  the a priori probability density of the feature vectors is computed using scene a features only  as follows: 　　　because  when a t e n t a t i v e match is made  it is not known which features in scene b w i l l remain 
unmatched  there is no obvious way to use a l l of 
the information in  1 . 	instead  Π m is computed by the following recursive method for the purposes of the search  where i now denotes a sequential 
	 1a  	numbering of scene a features in the order in 
ai 
which they are selected for matching: 
　　the criterion used for pruning ideally should not use a constant probability threshold  but 
should take into account the fact that  if a large 
search procedure number of nodes have small probability each but 
sum to a large probability  there is a good chance 
with a large number of features  it would be that one of them w i l l turn out to be part of the 
impractical to use a l l combinations in  1  and  1x correct solution. an appropriate method would be 
however  because of the exponential function in to sort by probability a l l of the nodes at a given 
 1  or  1   most of the pm values  and hence level in the search and to reject a l l of the nodes 
pm values  w i l l be n e g l i g i b l y small  and these with smallest probabilities that sum to less than 
terms can be ignored. the problem is to determine some threshold. a simpler  and more tolerant  me-
which combinations w i l l produce s i g n i f i c a n t magnithod is to reject any node whose probability times 
tude in p m without having to compute them a l l . 
the number oi nodes at this level is less than the threshold. 
　　　the approach used is to select the features in scene a one at a time and t e n t a t i v e l y to match 
1 these to unmatched features in scene b. the a posteriori probability of each of these partial m combinations is computed  and those with negligibly small probability are not pursued further. in this way a search tree is built up  branching out as different features in scene b  including no feature  are matched to the current feature in scene a at each level. the features in scene a can be ordered according to a criterion based on their feature vectors so that those most likely to be unambiguously matched are matched f i r s t . some kind of best-first search could be used  but in order to take advantage of bayes' theorem in computing the probabilities for pruning the search  a breadth-first search is used instead. 

　　　as the bottom level of the search tree is reached  not a l l of the available information w i l l have been used in computing Πm by the above method. thus Πm from  1  at the bottom level w i l l act as an upper limit to the value that would have been obtained from  1 . this effect causes less pruning to occur than the optimum computation would produce  but it should not result in the rejection of good solutions. 
　　　at each level of the search  the complete parameter computation according to  1  through  1  can be computed  including the iterations. however  the result from the parent node in the previous level of the search tree can be used as the i n i t i a l approximation at this node  so that fewer iterations  perhaps only one  would be needed at each level. 
　　　also  under some conditions the variation in the elements of pj with respect to g can be ignored.  this is likely to occur if g1 is accurate.  in such a case the summations involving pj.. in  1  and  1  can be computed recursively by adding the terms for a new  a i  b j   combination to the total accumulated at the parent node  thus saving time  or a kalman recursive estimation technique  also called sequential adjustment  could be used with slight additional time savings . in such a case  time can be saved also in the computation of 
pm if  1  is used  by recursively accumulating 
	t 	-1 
the sum of u 	t 	u 	and the product of 
 1π a det  tij   as new combinations are added. c' in  1  would then be constant  perhaps equal to g1 . if g1 is not accurate  it may be necessary to postpone the use of the recursive method until enough features have been matched to determine g well.  an alternate method of recursively computing pm is described in .  
　　　in order to save time in the search phase  it may be desirable to use less than the full information that is available. for example  the feature vector can be collapsed to a vector with fewer components that capture most of the information useful in discrimination and adjustment. this would result in slightly less effective pruning  but the time saved in computing each node may more than make up for this. the approximations of this type that can be made depend upon the application. some are discussed for one case in . 
　　　in any case  the solution at the bottom level can be used as an i n i t i a l approximation for one or more iterations with the f u l l computation described in the previous section  using those combinations that have not been pruned because of small probability. 
example 
     as mentioned in the introduction  one possible application for the method described in this paper is the matching of scene descriptions produced by the object finder described in  and  a   such an example w i l l now be presented. 
　　　a stereo pair of pictures  each about 1＜ by 1＜  taken by the viking lander 1 on the surface of mars was used as the input to processing  consisting of stereo depth mapping  a ground finder  and the object finder. figures 1 and 1 show the results when height thresholds of 1 centimeters and 1 centimeters  respectively  were used in the object finder. these figures show the ellipsoidal objects  approximating the rocks  projected into the left picture.  the large rock in the center is about 1 meters from the cameras and is about 1 meters long.  each ellipsoid represents a feature to be used in the matching process. arbitrarily assigned feature numbers are shown in the figures. it can be seen that more objects were detected in figure 1 than in figure 1 and that for those objects detected in both cases the ellipsoids are slightly different. thus two different descriptions of the same scene are available for illustrating the operation of the matcher.  the poor f i t to the upper right rock was caused by the fact that the background behind it was outside of the right picture  as explained in . the white blob is an artifact of the picture-taking process.  
　　　although the object finder produces nine parameters to define each ellipsoid  only three parameters were used here in the matching for simplicity  consisting of the two components of horizontal position and the size. these three parameters formed the feature vector x  and the corresponding three-by-three covariance matrix = was derived from the nine-by-nine covariance matrix produced by the object finder. as a further simplification  the covarlances of size with position were ignored. the vector g of parameters to be adjusted consisted of the two components of horizontal translation  rotation in the horizontal plane  and scale factor. translation was completely free to be adjusted  in effect the a priori values had infinite standard deviation   the a priori value for rotation was zero with a standard deviation of 1＜  and the a priori value of scale lactor was unity with a standard deviation of 1. the b values  representing the probability of detection of a feature  were made a function the ellipsoid size  varying from zero for zero size up to 1 for a very large object. p1 was set to 1. this information 
was used in a version of the matching algorithm implemented for this application and described in det a i l in   the probability threshold for pruning 
was 1  divided by the number of nodes at this level to obtain an absolute threshold .  this is quite tolerant; in practice a larger threshold may be desirable to reduce the search.  some preliminary crude pruning is included in this implementation. if the discrepancies from  1  are so large 
compared to the covariance matrix from  a   1 -hat it is obvious that this node w i l l be pruned  the further computations for this combination are omitted and thus this node does not appear in figures 1 and a. no final adjustment at the bottom level of the search tree was done. 
     figure 1 shows the results of using the data in figure 1 as scene a and the data in figure 1 
as scene b. the search tree is shown. the numbers at the left followed by colons are the feature numbers in scene a. the other numbers on 

1 


1 

the same line are the feature numbers in scene b for the features being matched to this feature in scene a. zero means that this feature in scene a is left unmatched. the numbers just below the scene b feature numbers represent the a posteriori probabilities computed for this match so far. to save space the. negative of the common logarithm of the probability  truncated to an integer  is shown. below the search tree the final results are shown for the most probable match  with computed standard deviations. note that the probability is close to 1  whereas the a priori probability was only 1 this illustrates the fact that  when the features contain enough information to determine the match well  the a priori probabilities have l i t t l e effect  as long as they are reasonable. also 
note that the standard deviation of the scale factor is not much less than the input value of 1  
which means that the solution was not able to add much information about the scale factor.  since the two scenes were both from the same actual scene and same camera position  the true values of translation and rotation are zero  and the true value of scale factor is unity.  
     figure 1 similarly shows the results of doing the match with the scenes interchanged  so that figure 1 now represents scene a and figure 1 represents scene b. even though the search tree is quite different  the final results are almost the same.  the two final results would agree even better if a complete solution were done at the bottom level of the search tree  since the same features were matched.  of course  since the scenes have been interchanged  the translation and rotation have changed sign and the scale factor has been inverted. 
　　　in this example  only the two horizontal translation parameters were free to be adjusted by large amounts. therefore  after the first level  the search tree stopped growing rapidly  because one feature match in two dimensions suffices to determine two translation parameters. if the a priori values of rotation and scale factor had been very uncertain also  the rapid growth would have continued to the second level  because two 
a unmatched  indicated by zeros for feature numbers in scene b . as more objects are left erroneously unmatched  the probability of these combinations becomes quite small at the lower levels of the tree  and they eventually are pruned. 
