 
supervised classification problems have received considerable attention from the machine learning community. we propose a novel genetic algorithm based prototype learning system  please  for this class of problems. given a set of prototypes for each of the possible classes  the class of an input instance is determined by the prototype nearest to this instance. we assume ordinal attributes and prototypes are represented as sets of feature-value pairs. a genetic algorithm is used to evolve the number of prototypes per class and their positions on the input space as determined by corresponding feature-value pairs. comparisons with c1 on a set of artificial problems of controlled complexity demonstrate the effectiveness of the proposed system. 
1 	introduction 
the induction of concept classification methods has received widespread attention both in the cognitive sciences and in the machine learning communities. this is to be expected because the development and use of concepts is a key characteristic of intelligent behavior. a study of the acquisition of conceptual knowledge involves an analysis of the representation of this knowledge  as well as the process of drawing inductive inferences using these representations. 
　a number of symbolic and subsymbolic systems have been proposed to solve the problem of inductively acquiring concept classification knowledge from a set of pre-classified instances. some of the more influential symbolic systems include id1  quinlan  1   version spaces  mitchell  1   and cobweb  fisher  1 . the most widely used subsymbolic systems for concept learning are based either on neural networks  rumelhart et ai  1  or on genetic algorithms  gas   dejong  1; holland  1 . some of the more frequently used representations in symbolic concept learning systems use logic expressions and programs  decision trees and lists  hierarchical clusters  and rules. representations used in subsymbolic systems include networks of simple computational units connected by weighted links and bit strings. 
　in addition to these mainstream machine learning approaches  there exists a significant body of work on statistical induction schemes  breiman et ai  1; cheeseman et ai  1 . other researchers have been motivated by the findings of cognitive psychologists  schaffer  1; smith and medin  1  and are using exemplar-based classification schemes  aha et ai  1; kruschke  1; stanfill and waltz  1 . these methods store the set of training instances and classify a new instance by some voting scheme using a given number of nearest stored examples. the exemplar-based approach  also called the nearest neighbor classification algorithm  vosniadou and ortony  1   is attractive because of its simple representation  and because it can be used to explain a number of human cognitive phenomena  schaffer  1; smith and medin  1 . hybrid ga-nearest neighbor algorithms have been developed to learn weights associated with individual attributes  kelly and davis  1   used in calculating distance of new instance from the stored instances  and to store only a subset of the set of training instances  cherkauer  1 . 
　the other form of concept representation that has been commonly posited by cognitive scientists as a theory of human concept learning is that of prototypes  reed  1; smith  1 . a prototype is a collection of salient features of a concept. an instance can be classified using prototypes by finding the prototype with which it shares most of its features  and then using the class of that prototype. the exemplar based models of concept classification are more flexible than prototype models  but cannot account for some general aspects of ordinary concepts. smith  smith  1  concludes that for ordinary concepts like birds  we use prototypes rather than storing exemplars; for complex concepts like students in my class  however  exemplars can be used to construct prototypes or to directly classify instances. in addition  the prototype models produce much more compact concept descriptions compared to exemplarbased models  and hence require much less computational effort to classify new instances. the on-line computation of prototypes  however  has been recognized as a difficult computational problem  hintzman  1; kahneman and miller  1 . 
　in this paper  we use a genetic algorithm  holland  1  to evolve prototypes from pre-classified instances. 
we believe that in addition to possessing psychological 
	sen and knight 	1 
plausibility  prototype models can be used to build effective classification techniques for supervised classification problems. to test this hypotheses  we have defined a set of classification problems involving two classes and two real-valued features. the constructed problems are of varying complexity as measured by the number of prototypes per category required for correct classification. we compare our system with the c1 system  quinlan  1  on these data sets. 
　the rest of the paper is organized as follows: section 1 discusses alternate representations for prototype based classification and introduces our representation; section 1 describes the ga used to evolve these prototypes; section 1 describes the classification problem set used to evaluate our system; section 1 compares experimental results of our system with the c1 system  and section 1 presents the shortcomings of the current system and future research directions to address these problems. 
1 	representation 
the standard approach to representing prototypes consists of using the descriptions of individual instances of a given class and then abstracting the more frequent properties of these instances  kahneman and miller  1 . a prototype is often represented in a slot-filler structure containing default attribute values  relationships between attributes  and weights on attributes. in these representations  prototypes are often linked in hierarchies. other possible representations for prototypes include production systems  holland et a/.  1  and connectionist networks. 
　in general  only one prototype is constructed per class1. the similarity of an input instance to a prototype is calculated from their respective attribute values using a  contrast rule : attributes not having common values are weighted and subtracted from the weighted sum of the attributes having common values. this method of classification explains typicality effects seen in most natural concepts  e.g.  some birds are more easily recognized as bird than others . 
　using a single prototype per class  however  is not sufficient to learn linearly non-separable categories. since most practical classification problems are likely to be linearly non-separable  we allow multiple prototypes per class. the classification problems used in this paper are defined on real-valued attributes. hence  the calculation of the similarity metric and the representation of prototypes are modified to suit these domains. our representation of prototypes is identical to that of exemplars  that is a prototype is represented as a list of feature values together with its associated class. the similarity metric used is the euclidean distance between the input instance and the prototype in the space defined by the features. 
　　1actually  it is widely believed that an ordinary concept definition consist of a prototype constructed from perceptually salient and easy to compute features and a core made up of more accurate but less accessible features  smith et al  1 . 
1 	genetic algorithms 

　note that our prototype model is similar to the exemplar model in the nearest neighbor calculation. the difference is that the prototypes are  in general  distinct from any examples seen by the system  and the number of prototypes per class is restricted to a small number  1 in this paper . our model is similar to some prototype models which calculate similarity from a distance measure in some underlying psychological space rather than measuring it by common and distinctive properties  shepard  1 . 
1 genetic algorithms for learning prototypes 
genetic-based machine learning  gbml  systems are rule-based systems which can be used to determine the class membership of input instances from a set of attributes. a gbml system matches the set of attributes corresponding to an instance against a set of rules to determine the class membership of the instance. these domain-independent classification mechanisms are particularly useful in problem domains for which there is no known precise model to determine the class  or for which determining a precise model is impractical. 
　there are two principal schools of thought in designing gbml systems  dejong  1 . the first school of researchers proposes to use genetic algorithms to evolve individual rules  a collection of which comprises the classification expertise of the system. this approach to building classifier systems was originally proposed by john holland at the university of michigan  and hence is referred to as the michigan approach  holland  1 . the other school of thought has been popularized by ken de jong and steve smith  smith  1  from the university of pittsburgh  and is therefore referred to as the pitt approach to building classifier systems. in this approach  genetic algorithms are used to evolve structures  each of which represent a complete set of rules for classification. each structure in the population in the pitt approach corresponds to the entire set of rules in the michigan approach. 
　the pitt approach seems to be better suited for batch-mode learning  where all training instances are available before learning is initiated  and for static domains. the michigan approach is more flexible to handle incremental-mode learning  training instances arrive over time  and dynamically changing domains. we have chosen the pitt approach in this paper to take advantage of the availability of all training data before learning is initiated. the only difference with the pitt approach is that a structure consists of a set of prototypes instead of a set of rules. 

1 population structures 
each population structure consists of one or more prototypes belonging to each of the possible classes in the domain. each prototype is represented as a set of feature values as described in section 1. prototypes belonging to the same class are placed adjacent to each other. prototypes belonging to different classes are separated by a special marker   let us denote the jth feature value of the ith prototype belonging to the kth population structure by pij. then given a problem with two classes and two features  the kth structure in the population with two prototypes belonging to the first class and three prototypes belonging to the second class is represented as: 

　traditional gas use bit-string representations for population structures  goldberg  1 . our choice of real valued representation has recently received increasing attention in the ga community  goldberg  1  and has been effectively used for supervised concept classification problems  kelly and davis  1; corcoran and sen  1 . 
1 operators for structure manipulation 
genetic algorithms are a class of adaptive techniques that were motivated by the effectiveness of natural evolution in developing organisms well-suited to a variety of environmental conditions. a majority of the structure manipulation operators in gas are highly abstract versions of operators found in natural genetics. 
　gas operate on a population of structures  evolving more well-adapted structures to the given environment over successive generations. each structure is evaluated in the domain to give it a fitness measure. we formulate the prototype learning problem as a function minimization problem  where we are searching for structures that reduce the number of misclassifications on the training set. the number of misclassifications produced by a structure is used as a measure of its fitness. we formulate the prototype learning problem as a function minimization problem  where we are searching for structures that reduce the number of misclassifications on the training set. 
　after all the structures in the population are evaluated  a new generation is formed by inserting new structures into the population according to their fitness values  causing the poorer performing structures to be eliminated  some get copied over multiple times depending on their relative fitness . for this selection process we use a rank-based method which has been claimed to be superior to the traditional fitness proportionate selection scheme  whitley  1 . 
　mutation is used to replace the current value of one feature of a prototype by a randomly generated number in the domain of the feature. thus mutation allows for a drastic change in the position of a prototype along one of the dimensions in the input space  each dimension corresponds to one attribute of the problem . mutation takes place infrequently. the probability of mutation is set by a parameter 
　a creep operator is used to displace the current position of a prototype on the input space by a small amount. the creep operator is applied with a probability pcreep and changes the values of all the features of a prototype by a small percentage  1  of their current values1. 
　a two point crossover operator is used to swap subparts of two structures. the crossover points can fall anywhere within a structure. when two parents are selected for crossover  two crossover points are first randomly selected on one of the parents . now  two points are chosen on the other parent which match up semantically with the previously chosen points on the first parent. for example  if a crossover point on the first parent is in between prototypes belonging to category x  the corresponding crossover point in the the second parent should also fall between prototypes for category x. similarly  if the crossover point in the first parent falls between the second and third features of a prototype belonging to category y  the corresponding crossover point in the the second parent should also fall between the second and third features of a prototype belonging to category v. after crossover points are selected in both parents  the portions of the chromosomes in between these points are swapped between the parents to produce two offsprings. any crossover that results in chromosomes with empty categories or with a number of prototypes for a category exceeding the maximum limit  is disallowed. the following example demonstrates a valid twopoint crossover as described above  crossover points are marked by the symbol   : 

1 	problem set 
in order to evaluate our proposed system  please  we designed a set of problems of varying complexity. these problems were defined on two continuous attributes  x and y  each having a range of  1 . so  the input space is a square of unit area. we formulated four different problems by labeling different regions of this unit square with one of two possible categories  1 or 1. the area of the region allocated to each of the categories is equal in area for all the problems. these regions were chosen so that the classification problem can be solved with a specific number of appropriately positioned prototypes for each category. different problems require different number of prototypes per category. the minimum number of prototypes required per category to solve the classification problem is used as a measure of the complexity of the problem. given a particular problem  we randomly generated a set of points from the input space and then labeled each point with the category associated with the region containing that point. these sets of points were then divided into training and testing sets. 
   1  in our experiments  we found faster convergence when all the feature values were changed by the creep operator rather than changing only one feature at a time. 
	sen and knight 	1 

　we present the problems used in the experiments in this paper in figure 1. the problems are labeled as n/m  where n and m stand for the minimum number of prototypes in the two categories required to accurately solve the classification problem. the darkened regions in each of the figures are associated with category 1  and the rest of the square is associated with category 1. the prototypes required to solve the problem are labeled '-' and '+' for categories 1 and 1 respectively. we should clarify that the presented problems are not unique instances of n/m problems; their choice was motivated by considerations of the ease of exposition. the following describes each of the problems in more detail: 
1 problem: the unit square is divided by a diagonal into two right-angled triangles  and each assigned to one category. this is the simplest problem in the problem set  and can be solved by using only two prototypes  one each for the two categories. the two prototypes must be placed on a perpendicular bisector of the dividing diagonal and should be at the same distance from the diagonal. the prototypes should also be correctly labeled  i.e.  the prototype in the region assigned to category 1 should be labeled by a '+' and the prototype in the region assigned to category 1 should be labeled by a '-'  we will assume this is the case when describing the other problems . such an orientation of the proto-
1 	genetic algorithms 
types means that any point in the upper triangle will be closer to the prototype in that triangle and hence classified correctly. the interesting thing to note here is that the above solution description allows for an infinite number of minimal solutions1 to the problem  infinite number of perpendicular bisectors of the diagonal  infinite number of pairs of points on any of these bisectors that are equidistant from the diagonal . one such solution is showed in the figure1. 
1 problem: in the particular 1 problem chosen for experimentation  a single diagonal strip associated with category 1 separates two triangular regions assigned to category 1. once again  prototypes placed on any straight line perpendicular to the two diagonal lines can solve the classification problem perfectly. as a result  there are infinitely many minimal solutions to this classification problem with the prototype representation we have chosen. one such placement of prototypes is shown in the figure. 
1 problem: the presented problem consists of a triangular region associated with category 1  and the rest of the unit square associated with category 1. 
　1  minimal solutions refer to solutions that require the minimal number of prototypes for each category. 
　1 the placement of the prototypes in the figures are only approximately correct. 

in contrast to the above problems  there is a unique minimal solution to this problem. this solution is found by first drawing perpendicular bisectors of the three sides of the triangle and placing the '-' prototype at the intersection of these three bisectors. the three ' + ' prototypes are then placed at points outside the triangles obtained by reflecting the position of the '-' prototype about each of the three sides of the triangle. 
1 problem: the presented problem consists of a square embedded within the unit square and with vertices placed on the midpoints of the sides of the unit square. the embedded square is associated with category 1 and the rest of the unit square is associated with category 1. once again  there exists a unique minimal solution to this problem. this solution is obtained by placing the  -' prototype at the center of the square  and the four ' + ' prototypes at the four vertices of the unit square. 
　the problem set  therefore  consists of problems of varying complexity  both in terms of the minimal number of prototypes required per category to solve the clas-
sification problems  as well as in terms of the number of minimal solutions existing for the problems. 
1 	experimental results 
in this section  we present results from experiments conducted to solve the previously mentioned classification problems using both please and cm.1. we have used the cross validation error estimation technique  breiman el a/.  1  for evaluating the performance of the algo-
rithms on the problem set. for each of the problems  1 points were randomly generated from the input space and classified according to the region from which it was drawn. we used a five-fold cross validation  generating five different training/testing set splits. in each such split  1 input instances were used for training  and the remaining 1 were used for testing. the constraint imposed on training/test split was that both the categories were equally represented in the training and test sets. additionally  within a category  all the regions were also equally represented. results obtained with the c1 system are averaged over these five training/testing set splits for each of the problems. our please system uses genetic algorithms for learning prototypes  and the performance of the latter depends on the random initial population. as such  the please system was run on each training/testing split with 1 different random initializations. the results of please on each problem  therefore  is averaged over 1 runs. 
　the parameters used for the please system in these experiments are as follows: population size = 1  number of generations = 1  pmut = 1  pcreep - 1  s = 1  selection bias = 1  maximum number of prototypes per category = 1. table 1 contains the average and standard deviations of the percentage error rates of c1 and please on each of the four problems in the problem set. 
　the main observations from these results are as follows: 
  please was consistently able to discover a set of prototypes that achieved near-perfect classification accuracy. 
  the error rates for please and c1 increased slightly with more complex problems. 
  though c1 performed slightly better on training instances in the some of the problems  these differences were not statistically significant. on the other hand  a two-sample t procedure shows that with at least 1% confidence level it can be stated that please produced lower error rates on the test instances than c1. the other notable difference between c1 and please was their relative performance on the training and test cases. training and test set errors were much more consistent in please than in c1. in fact  for the c1 system  test errors were approximately 1 to 1 times higher than errors on training instances. since test set performance is more important in supervised classification problems  please seems to be able to better represent the underlying target concept. 
　we now analyze the kind of solutions please generates for the given problem set. table 1 presents the average number of prototypes used by the best solutions generated by please for each of the four problems. the numbers show that the solutions produced use more prototypes than required by the minimal solutions to corresponding problems. on analyzing individual solutions  we found that some of the solutions indeed were minimal  but in general  more prototypes were used. the decision trees produced by c1 for these problems contained  on the average  1  1  1  and 1 nodes for the 1  1  1  and 1 problems respectively. hence  the data compression obtained with the please system is significantly better compared to that obtained with c1. 
　we will use a typical solution for the 1 problem to analyze both the nature of the solutions generated by please  and the classification errors made by such a solution. figure 1 presents the 1 data points for the 1 problem and also a typical solution produced by please together with the training and test set misclassifications of that solution. for the sake of clarity we have also drawn the lines outlining the embedded square for this problem. we find that the solution produced by please contains several prototypes for category 1  all clustered around the center of the unit square. the minimal solution contains just one prototype at the center. similarly  there are two prototypes belonging to category 1 placed close to each other at the left corner of the unit square. these two observations suggest the use of a prototype merging operator that will replace two prototypes by a new one in between them  if the distance between the two prototypes is less than a preset threshold. the placement of the prototypes in the solution generated by please is found to approximate  the prototype locations in the minimal solution. this close approximation to the unique minimal solution produces very low classification errors  1 on the training set and 1 on the test set. 
on analyzing the misclassifications produced we find 
	sen and knight 	1 


table 1: average number of prototypes learned by please for the two categories for each of the problem types. 
no  blatant  errors  i.e.  all errors are located close to the boundary of separation between the categories. the other solutions that we have analyzed show similar trends in both the prototypes developed and the errors produced. 
1 	conclusions 
the choice of prototypes as a representation of target classes and the use of genetic algorithms to learn appropriate prototypes for given classes has been shown to be an effective means for addressing supervised classification problems. in particular  we have provided a novel way of successfully addressing the difficult problem of on-line computation of prototypes from training data  hintzman  1; kahneman and miller  1 . 
　this paper contains an experimental evaluation of our proposed classification system  please  on a set of real-valued classification problems of varying complexity. please produces near-perfect solutions to these problems and performs better than the well-known c1 system on these problems. in a further study with an extended set of problems  knight and sen  1   we have found the please system performs favorably compared to simple exemplar-based classification mechanism like the nearest neighbor algorithm. 
　the system as it stands today can be improved in a number of ways. we envision the following experiments with and extensions to the current system: 
  developing a representation for both structured and nominal attributes in addition to the ordinal attributes that are used currently. 
* evaluating please for noisy immunity. 
  using prototypes with a subset of attributes  necessary to handle domains with large number of irrelevant attributes ; this goes back to the more tra-
1 	genetic algorithms 
ditional view of prototypes  kahneman and miller  1 . 
  collapsing two prototypes into a single prototype if they are closer to each other than a given threshold. 
  using the inversion operator in gas  to allow swap-ping of prototypes between any two classes in a chromosome. 
  a prototype add  delete  operator that randomly selects a class in the chromosome and then adds  deletes  a prototype to  from  that class. the prototype to be added may be constructed by averaging feature values of a subset of the instances in the training set of that class that have been rnisclassified by this chromosome. a prototype may also be deleted if it did not classify any instance. 
* seeding of the population by chromosomes constructed from possibly useful prototypes; these prototypes can be formed by averaging feature values over a certain number of instances of a class that are randomly selected from the training set. 
we also plan to develop a prototype-based michiganstyle classifier system. 
