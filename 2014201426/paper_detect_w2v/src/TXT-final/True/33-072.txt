 	ii 	belief models 

　　　identifying deception in stories requires an understanding of the beliefs of the characters. a model must include both beliefs about facts and beliefs about other characters. this paper presents a method for representing such belief structures. arbitrary levels of embedded beliefs are represented by cvclic structures with shared common beliefs. with these structures we show how different instances of deception can be recognised with a single deception template. we w i l l illustrate these concepts by applying them to several example stories. 
i introduction 
when eve caused mankind to be ejected from the 
garden  the world became a place where truth could no longer be taken for granted. not only has deception played a c r i t i c a l part in history  but it is central in the development of fictional stories as well. 
　　　for a clear understanding of most stories  an understanding of deception is essential. we must understand how people can have differing beliefs  how they can successfully lie to each other  and why they lie to each other. 
　　　deception ia d i f f i c u l t to understand because it deals with beliefs rather than with factual information. most of the research done in language understanding has dealt with unquestionable facts  physical actions  attributes of objects  and so on . however  to understand deception  we must model the beliefs of characters. some work has been done on modeling simple beliefs   1   ; however  characters must also have models of other characters  beliefs in order to deceive. 
　　　in this paper  we w i l l present a single method for modeling both characters  own beliefs and their beliefs about other characters. we w i l l then show how stories containing deception can be analyzed using these models. 
　　　in this section  we introduce the belief models that are used throughout the paper. here  we w i l l use them to model a simple situation with no deception: 
maggie t e l l s andy that she was once married. 
example 1. 
in order to model this situation  we must make some inferences about what people believe after they say or hear something. these default rules of conversation  are crucial to the construction of the belief structures. after reading the sentence in example 1  we can make the following inferences: 
maggie was married. 
maggie believes she was married. 
andy believes maggie was married. 
maggie believes andy believes maggie was married. andy believes maggie believes she was married. 
these are default inferences; some may not be made if conflicting information is already known. 
　　　notice that the last two inferences contain nested beliefs  that i s   beliefs about other beliefs. we could continue the l i s t of possible inferences indefinitely by making each inference more nested than the previous one. the belief structures appear to be i n f i n i t e l y recursive. how 
many levels of nested beliefs should we model  for example  why not infer  andy believes maggie believes andy believes maggie was married   in a notation similar to the one in bruce and newman 
 1   we can infer andy and maggie's beliefs  a and m  respectively  and their beliefs about each other's beliefs  am and ma . however  people have d i f f i c u l t y understanding deeper beliefs such as the complex one shown above in quotes  which would be written as ama. as we shall see in later examples  it is sometimes necessary to model these recursive beliefs in order to detect deception. 
　　　in example 1  models a and ama can be viewed as being the same belief model. this simply means that andy thinks maggie has modeled him correctly; that i s   andy thinks that his beliefs are identical to maggie's model of his beliefs. to the reader of 
1 

this one-sentence story  his view of a and ama are not merely equivalent  they are the same belief model. for this simple case of mutual beliefs  if we realize that am - m and ma - a  then we can create a cyclic structure which captures a l l the information that would appear in the i n f i n i t e l y recursive model. 

figure 1. 
　　　figure 1 illustrates this cyclic model. here  the two belief models are the large boxes with numbers in the upper-left corner. the numbers are illustrative purposes and are not part of the 
representation. each model contains a l i s t of facts  only married in this case  and possibly one or more nested models. these models are the smaller boxes that contain only a single number. this single number is meant to illustrate that this is not a new model  but is merely a reference  in the lisp implementation  a pointer  to the existing model with the same number. in other words  in the static structure shown in figure 1  there are only two belief models. 
　　　for the sake of clarity within our figures  we have abbreviated individual facts. for example  the fact that maggie was married is written as married. actually  each fact in the model would be a knowledge representation such as conceptual dependency . 
　　　the structure in figure 1 is one of mutual belief  1j. this is the default belief structure when information is transferred from one person to another. it occurs only when neither person has conflicting knowledge about the subject. 
iii simple deception 
　　　suppose that whan we were reading example 1  we knew that maggie had never been married. the story would effectively have been: 
maggie has never been married. 
she tells andy that she was once married. 
example 1. 
figure 1 shows the belief models for this modified story. the same inference rules have been used to construct this model as we used in example 1. however  not a l l of the default inferences appliedto the model. for example  maggie does not believe that she was ever married  even though she t e l l s andy she was. however  using the same default rule 
  i f someone says something  he believes i t     andy constructs a model of maggie that contains the fact that she was married. andy's beliefs about maggie's beliefs now differ from maggie's actual beliefs  am does not equal m . 
　　　showing that am does not equal m only yields that an inconsistency in the belief structure exists. a l i e is an intentional act. there is deception in this example because maggie knows she has lied to andy. maggie believes that andy has an incorrect model of her; mam does not equal m. the belief boxes corresponding to mam and m are labeled 1 and 1  respectively. notice that they differ about the 'married' fact. 


　　　this example is the pattern which we w i l l hereafter refer to as the deception template. it includes two main ideas; f i r s t   the intentionality of the deception  mam not equal to m  and secondly  the actual success of the deception  am not equal to m . we w i l l show that this pattern f i t s a l l examples of deception. new input. the transition from box 1 to box 1 shows that the reader held an incorrect view of maggie. maggie has not changed her beliefs; the reader has changed his mind about what maggie's beliefs have always been. at this point  the reader has admitted to himself that he was wrong about what maggie believed. therefore he has  in 	the 	language 	of 	  	supplanted 	his 	model 	of 
	maggie. 	the ' s '  supplant  on the arrow indicates 
iv psychological justification of the model. changed this. 	notice in 	exactly the same way that the reader's that 	andy's 	model 	of 	maggie 	has 

　　　although the need for some type of nested structure in a belief model is very clear  understanding stories that contain many levels of beliefs can become very d i f f i c u l t . for example  when one tries to analyse the beliefs of another  one can imagine himself as the other person. this involves replacing his top level beliefs with the beliefs he holds about the other person. this process of  getting into someone else's head  is part of the reason why people have d i f f i c u l t y in understanding stories with many levels of beliefs. with these stories  this replacement of top level beliefs occurs several times. 
　　　in example 1  a  aha  and amama describe several applications of this replacement process. however  in terms of the physical structure of the model  these belief boxes are the same model. in spite of this  we are unable to answer questions about amama. this is because even though the structural nesting of amama is only 1 levels deep  its dynamic nesting level   i . e .   the number times the above process is used  is 1 levels deep. our representation allows the dynamic nesting level to increase without bound. however  we believe that this is a very complex process  and for each person  the maximum depth in the model at which the process can take place is the determining factor in their a b i l i t y to recognize deception. 
v modeling the reader 
　　　the previous model was implicitly that of a reader of the story. if we make this fact explicit in our model  we can see that the author can deceive the reader in precisely the same way that story characters deceive one another. 
consider the following story fragment: 
maggie tells. andy she was married. 
maggie t e l l s andy she lied about being married. 
example 1. 
notice the representation  figure 1  now includes an outermost model of the reader of the story. like example 1  this story contains an instance of deception. however  in example 1  the reader knew that maggie was lying a l l along. in this example  the reader is as surprised as andy by maggie's confession. 
　　　two new items of notation are introduced in figure 1. the two types of arrows  s-arrows and u-arrows  indicate a belief change as a result of has. this is because they were both deceived by maggie in the same way. thus  the reader's model is not the only one that can be supplanted; characters' models can be supplanted  too. 

	f i g u r e 	1. 
　　　the transition from box 1 to box 1 indicates that the reader has altered his beliefs about andy. the reader was never wrong; he has merely recorded the fact that andy has changed his mind. this is indicated by the ' u '  update  on the arrow. andy's old belief  that maggie was married  remains in the current model  box 1 . 
　　　to summarise  when a belief model is changed because a character was modeled incorrectly  it is supplanted; when a belief model is changed to reflect that a character changed his mind  it is updated. 
　　　we w i l l now explain how the simple deception template described earlier allows us to detect the presence of deception in this more complicated model. at the end of the f i r s t sentence  there is 

1 

a state of mutual belief. in figure 1  this is the cyclic structure involving boxes 1 and 1  this is the same as figure 1 . at the end of the second sentence there as is also a state of mutual belief. this is the structure involving boxes 1 and 1. there appears  at f i r s t glance  to be no deception in the model. but notice the  supplant  history in box 1. at the end of the second sentence the reader realizes that he was wrong about the apparent mutual belief that existed after the f i r s t sentence. the deception template matches the structure involving boxes 1  1  and 1. these boxes represent the reader's revised view of the state of affairs after the f i r s t sentence. it was the second sentence that gave the reader a clue about 
what had actually happened. 
　　　let us briefly clarify how boxes 1  1  and 1 indicate that maggie has deceived andy. in box 1  maggie has a reference to box 1. she believes that at time 1 andy believed box 1. the left side of the supplant in box 1 refers to a belief held at time 1. box 1 contains 'married' while maggie has always believed 'single'  from box 1 . 
	this is an example 	of 	discovered 	deception. 
before the discovery  at time 1  there is a state of mutual belief. after the deception is discovered  there is a state of mutual belief  but also a realization that the previous state was not one of mutual belief. 
	vi 	double deception 
　　　double deception  occurs when a person allows another to think that a lie has been successful. an example w i l l c l a r i f y : 
maggie tells andy she was once married. 
maggie tells andy she lied about being married. andy says he knew it a l l along. 
example 1. 


1 

　　　the f i r s t two sentences are the same as those in example 1. in the third sentence andy admits that he knew of maggie's deception a i l along. in figure 1  this if represented in the reader's model by the transition from box 1 to box 1. the reader has replaced the relatively complicated structure in box 1  that andy believed one thing and then changed his mind  with the simple view in box 1  that he knew a i l along . 
　　　maggie changes her model of andy in precisely the same way. this is because the reader and maggie are both surprised by andy's revelation in the third sentence. this illustrates how our model can capture the common elements of the superficially different activities of deceiving the reader and deceiving a character. 
vii detecting deception 
　　　because deception can occur at certain times in the story and be noticed at other times  we now describe the use of what we call the  time  slot of each belief. the time slot is used to differentiate between similar beliefs held by the same person at different times. when a belief is  created  we place a number in the time slot corresponding to the number of the sentence from 
which the belief was inferred. 
　　　at any point in the story  we can ask questions relating to the supplant/update histories of our model. we may ask   when did a deception occur in the past   and  when did you f i r s t find out about i t     in example 1  the reader is aware of the deception at the time that it happens. in example 1  the reader finds out later  at time 1  about a deception that occured at time 1. the reader's use of the belief histories that are modeled within each character allows him to answer these questions. the reader may also use his own belief histories to examine what he believed in the past. 
	v i i i 	reader-author deception 
　　　if we want to study how a story with deception is written  we can create models of the author and the reader. each model has a hypothetical model of the other. as the reader reads the story  he constructs a view of the author in exactly the same way as he models characters in the story. the reader uses essentially the same default inference rules when dealing with the author. however  there are some differences. for example  we know of no case in fictional stories where the author lies directly to the reader. instead  the author achieves this effect by having a character l i e   thereby lying to the reader indirectly  as in example 1  or by setting up a situation with strong inferences that later are found to be incorrect. it is interesting to note that in other forms of written material where fewer restrictions apply  such as propaganda and campaign literature  the author may deliberately lie to the reader. 
ix limitations of the inferencing mechanism 
　　　we i n i t i a l l y introduced  in section 1  the inference rules that were necessary to construct a l l of the given deception examples. this static set of rules may not apply in a l l conditions. for example  when one suspects that another is dishonest  his inference rules may drastically change. that i s   if one believes he is being deceived  he may believe something different from what he hears. if he is being told the truth then he may misconstrue the good intent of the speaker based on his own erroneous inference. 
　　　later  when we try to understand more complicated stories  it w i l l be necessary for each person to have reasons for each of his beliefs. we propose to add what we call 'why' tags to each belief. these tags indicate the reasons for the belief. a tentative l i s t of reasons for a belief includes personally experiencing i t   being told about i t   and inferring i t . these tags w i l l aid in tracing bad sources of information and correcting bad inferences. 
　　　there is a specific form of deception which has not been considered here. this is when the deceiver take1 advantage of the fact that a person can be led to draw incorrect inferences when he is presented with correct but incomplete data. in this case  the why-tag on the fact of the deception indicates that the incorrect information was inferred and not told by anyone. an area of future research is to make a program answer questions about how a particular character was deceived. this w i l l involve extensive use of the why tags and is beyond the scope of this paper. 
x implementation of the theory 
1 　　　a program is presently being written in uci mlisp to implement the theory presented here. it is divided into 1 separate parts. the f i r s t part w i l l use applications of the inference rules to transform the i n i t i a l input  in conceptual dependency  into the internal representation. this transformation process has been partially described in this paper; however  it has not yet been implemented. the second process consists of recognizing the deception using the deception template. it could also be used as the basis for a question-answering system. this portion of the system is in the implementation stages  as well. the third and only completed portion of the system was used to print the deception diagrams in this paper from the proposed internal belief representation which was explicitly input by hand.  
　　　the main goal of our representation has been to adhere to a reasonable theory of memory 
organisation. the f i r s t problem solved is that of nested beliefs and mutually nested beliefs. by 
using references to belief boxes 	in 	creating 	the 
 
cyclic structures  we have economized on the number of beliefs. we create a fixed-sized model which appears to be dynamic when referenced. 
 
　　　another goal of our representation involves storing knowledge about the past. in  we see 
that a history of inferences is needed in order 	to 
 
understand the intermediate inferences of characters in a story at any arbitrary time. our representation also exhibits this necessary capability we have shown how time dependent granger  r.  when expectation f a i l s : towards a self-correcting inference system.  proceedings of the first national conference on a r t i f i c i a l intelligence. stanford  ca  
1. 
meehan  j. 	the 	metanoval: writing stories by 
computer. ph.d. thesis. computer science department  yale university  1. 
 minsky  m. semantic informative processing massachusetts institute of technology  1. 
perrault  c. and cohen  p.  planning speech acts   ai-memo 1  department of computer science  university of toronto  1 

	 	schank r. 	conceptual 	information processing 
information 	is 	 remembered  in our representation 
　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　north holland  amsterdam  1. and how questions concerning such information can be answered.  schank  r. and abelson r. scripts. plans. 
　　　our belief representation is evolving. goals. and understanding. lawrence erlbaum presently it is used only to detect deception. we associates  hillsdale  n.j  1. 
believe that it w i l l be useful in interacting with a planning mechanism. the effects of changing beliefs on plan-creation and goal-setting are 
widespread. it is our goal to design a belief structure that w i l l satisfy the interaction requirements of a planning mechanism so that we can achieve a better understanding of the underlying 
reasons for deception. 
acknowledgements 
　　　we would like to thank rick granger for his helpful guidance in this research  jim meehan for useful information on belief systems  and stephen willson for his participation in the early stages of this research. 
