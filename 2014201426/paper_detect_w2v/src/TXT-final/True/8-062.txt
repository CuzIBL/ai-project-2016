 
a computer model of some classes of verbal behaviour is described. the general characteristic of the classes is that the subjects emit discrete verbal units but not continuous discourse. the concept of a word store is defined as a stochast i c information r e t r i e v a l system  imple-
mented in the form of a network of stochastically interacting nodes. the word store is assumed to be a p a r a l l e l processor which operates in conjunction with a s e r i a l processor in the human organism. the application of the model to word association  response sequences  learning processes  and satiation effects is discussed. the main data structure and functions of the computer program are described with some examples given in the pop-1 programming language. it is shown that the word store model f i t s q u a l i t a t i v e l y many of the phenomena in verbal 
behaviour  and an example of a quantita-
tive comparison is shown. 
descriptors 
words  memory organisation  r e t r i e v a l   association  verbal behaviour  computer model  stochastic  network. 
introduction 
this paper gives a b r i e f description of a set of computer programs which constitute a model of human behaviour in certain experimental situations l i k e word associat i o n   free r e c a l l of word l i s t s   paired associate learning  and others. the general characteristic of a l l these experimental settings is that the subject is required to select and emit discrete verbal u n i t s   but not continuous discourse. 
　　　in spite of the great deal of a c t i v i t y in the f i e l d of verbal behaviour  there is a surprising lack of general theories which could account for the phenomena in a systematic manner. the model described in this paper is a tentative step in this d i r e c t i o n . various aspects of this model have been discussed in a number of other p a p e r s 1 ' 1 . l k 1 l 1 and some of these w i l l be summarised very b r i e f l y here. the main emphasis w i l l be on the behaviour and p o t e n t i a l i t i e s of the computer simulation. 
　　　some ideas about the ne ed for paral l e l processing in cognitive processes have also been discussed by reitman1  and his approach is close to that of the present paper. feigenbaum' s epam model provides an example for a ra ther d i f f e r ent approach to the computer simulation of verbal behaviour. 1 final ly  quillian1 is working on another more elaborate computer model for semantic memory which is again rather relevant to many of the ideas in this paper. 
formulation of the model 
the general assumption is made at the outset that humans possess both serial  central-processor like  and parallel information processing resources  and that these are j o i n t l y u t i l i s e d in highlevel psychological processes. in order to deal with verbal behaviour it is postulated that the relevant parallel processor  which w i l l be called the word store  is functionally a stochastic information r e t r i e v a l system. structura l l y it is a network containing representations of words and links between them. each word  representation  can have a varying level of a c t i v i t y . the links can transmit a c t i v i t y from one word to another. 
　　　this transmission is assumed to be stochastic in nature and is described by specifying the probability that a unit a c t i v i t y in word   w i l l produce a certain d i s t r i b u t i o n of a c t i v i t i e s over the words in the system. it is argued in kiss  1 however  that in normal behaviour the interest is in the mean values of these transmissions which are  due to the distributed manner in which the links are implemented in the organism  rather stable and can be treated in a deterministic manner. 
　　　each word is also capable of storing the cumulative sum of a c t i v i t i e s received over an interval of time. this sum w i l l be referred to as the cumulative a c t i v i t y of a word. it is assumed that this a c t i v i t y either persists i n d e f i n i t e l y   or decays according to some  possibly exponential  function. 
the word store can now be looked at 

-1-

as a sequential machine whose state is defined by a vector specifying the current cumulative levels of activities of the 
words. the system can make transitions in the absence of external influences  free transitions  due to the operation of the transmission links. external interference with the activities can also change the state of the system. the fine behaviour of the word store can be described by the machinery of stochastic multidimensional branching processes.1 the average behaviour  on the other hand  can be treated by a graph theoretical approach  in particular by using signal flow graphs.1 
　　　the interaction between the word store and the serial processor is defined as follows. at any instant a word can become available to the serial processor   can enter consciousness   with a certain probability. this probability is the ratio of the cumulative activity in that word to the sum of a l l such activities in the word store. this is in accord with some well-known theories of choice behaviour  e.g. luce1 . 
　　　in summary  the two essential components of the word retrieval process are the evolution of the word store in time through transitions from some starting state  and a  decision stage  in which a random choice is made according to the relative levels of cumulative activity. 
verbal behaviour and the 
word store model 
word association 
the word association experiment is perhaps the most uncluttered form of verbal behaviour. in its simplest form the subject is minimally constrained by giving a stimulus word  and any response is acceptable. nevertheless  when the frequencies of response words are tabulated for samples of subjects  surprising regularities emerge. the frequency distribution has a characteristic shape  shown to be of the zipf type by skinner.1 response latency depends on response probability as a smooth monotonic decreasing function  thought to be logarithmic.1 the distribution of latencies is close to the lognormal.1 the absolute probability of a word in the language correlates highly with its average associative probability.1 the rank of a word in the distribution is positively correlated with the number of other words in the response l i s t which also e l i c i t that word as a response.1 
　　　this is a very incomplete l i s t . numerous other findings are summarised ir a recent book by cramer.1 those listed above are most closely related to the model and hopefully comprise a fairly representative selection of phenomena to be explained. let us outline briefly how the word store model accounts for them. 
　　　one particularly attractive way of conceptualising the operation of the model is to think of it as a signal flow graph. this is a linear directed graph in which the nodes are words and the arcs are the transmission links. every node adds the incoming signals and transmits the result along the outgoing arcs. the values of the arcs are the transmittances connecting one node to another. by us in a basic set of elementary transformations which deal with series  parallel  star  and self-loop connections of arcs  one ca calculate the total transmittance between any node pair of a network.1 if the values of the outgoing arcs are normalise so that they sum to one  the representation of a markov chain is obtained. the 
n-step transition probabilities  and the sums of n-step transition probabilities u to some limit correspond respectively to the activity transmitted from one node to another at the ntn transition of the system  and to the cumulative activity transmitted during the n transitions. for simplicity  it is assumed here that the word store operates in discrete time: the states of all nodes are updated simul taneously during each transition. 
　　　it is possible to assess the values of the arcs in this flow graph by means o the word association experiment  but this is not simple.1 the problem is that th empirical associative probabilities are not the one-step transition probabilities of the markov chain described above. bu it is possible to obtain approximations from this data. 
　　　the word association process can now be described as follows. some activity is injected into the node corresponding to the stimulus word in the network. th word store then goes through several tran sitions. during each of these the nodes sum the incoming transmissions and transmit the sum to other nodes to which they are connected. at some stage  which depends on the experimental conditions  a choice is made among the words in such 
way that the probability of choosing any one word is determined by the relative activity of that word. 

-1 

       if this model is used for the simulation of the word association behaviour of a sample of subjects  a number of qualitative and quantitative conclusions can be reached. if the assumption is made that the transition rate is the same 
for all subjects  then the response latency w i l l depend on the number of transitions made by the word store. if 
we also assume that the network structure is the same for all subjects  clearly an over-simplification   then associative response probability corresponds to the total transmittance between a node pair  taking into account all possible pathways up to some limiting length. then the monotonic decreasing function relating latency to probability  described by woodworth and schlosberg1 follows from the model  since activity will build up more quickly at the nodes which have a strong total transmittance leading to them from the stimulus node. 
       the response probability distribution has been obtained by simulation and is compared with some independent empirical data in figure 1. the agreement is close in spite of the approximations involved in deriving the network data  described in more detail1 . the latency distribution cannot be accounted for by the model unless further assumptions are made about the stopping point of the branching process. it seems reasonable to assume that the process stops when some threshold conditions are reached in the activity levels. the various possibilities have not been explored as yet in detail. it is worth pointing out that williams1 has shown that for a one-dimensional branching process the first-passage time distribution is very close to lognormal. 
       the result obtained by pollio1 about the relationship between response rank and the number of other items in the response l i s t eliciting the word is obvious from the model: the more numerous the pathways between stimulus and response  the larger the total transmittance and hence the response probability. 
       finally  we reproduce here table 1 from kiss1 to show the comparison between simulation and empirical data. the column marked ps shows the simulated probabilities  and the columns marked pm1 and pm1 show the probabilities obtained from 1 subjects at minnesota in 1 and 1 respectively. a star in the pm1 column means that the probability is not known  only the fact that the word does occur  this is due to the peculiarities of the tabulation in the minnesota data  see palermo and jenkins1 . it can be seen that 1 per cent of the words retrieved by the model are in the minnesota data. the correlation between the simulation and the minnesota data is r=1. this simulation involved letting the word store run through three transitions. similar comparisons have been made when the stimulus consists of three words  for example moth bird fly.1 the difference here is that a starting state is set up in which several words have nonzero activities. the correlation between the empirical and simulated probabilities was r=1. 
response sequences 
       in many experiments the subject is required to emit a sequence of responses. responses which are acceptable can be specified in a number of ways. bousfield and sedgewick1 asked subjects to generate members of some class  like four-legged animals  names of cities  etc. less restrictively  the subject may be asked to generate a continuous sequence of word associations to a stimulus word. one may also consider the free recall of a word l i s t as a highly restricted case of this process. 
       how does the word store model cope with this situation  it is assumed that there are two components  carried out by the parallel and serial processors respectively. the parallel processor is generating candidate items which are then tested for acceptability by the serial processor.1 the parallel processor generates the candidates by adjusting the probabilities with which words become available to the serial processor  in the manner described in the previous section. particular questions which arise here are the setting up of a starting state for the system  and the feedback to the system from the testing and emission of candidates. 
       the characteristic results of the bousfield and sedgewick1 experiments and of the continued association experiments are that if the cumulative number of responses given is plotted as a function of time then the average curve is well described by an equation of the form n=c l-e-mt . when the fine structure of individual curves is examined  however  one finds that the responses occur in bursts  triggered by a member of some sub-class  like domestic animals  etc. a related phenomenon occurs in the free recall of word lists where the items show a positional clustering even when the presentation order of the l i s t is random. 
in attempting a computer simulation 

-1-

of such sequential phenomena the assumpt i o n was made that the emission of a response by the subject has the same feedback effect as the presentation of a stimulus  possibly with an attenuation parameter r e f l e c t i n g the   a t t e n t i o n   paid to the event. s i m i l a r l y   the testing of an item by the s e r i a l processor is assumed to have a feedback e f f e c t   even if the item is rejected as unsuitable. once these assumptions are made  the same program could be used here as for the generation of single associative responses. it was necessary to add only a few t r i v i a l executive routines in order to generate continued associative sequences. 
       in the simplest case the feedback effect was set equal to the stimulus effect and a feedback i n j e c t i o n of a c t i v i t y was made whenever a candidate item was tested  irrespective of the outcome. the only test in this case was for previous occurrence: if the item was new it was emitted  if not it was rejected. the average curve for 1 runs is shown in figure 1. it is quite clearly of the kind usually observed in these experiments . 
　　　more impressive was however the clear-cut occurrence of temporal clustering effects in the individual sequences. an example is shown in figure 1. notice that the clusters seem semantically coherent  and that this effect did not require the introduction of 'conceptual organising factors' into the production process advocated by some investigators  see  for example  cofer1 . no detailed exploration of the effects of the parameters has been done at the time of w r i t -
ing this paper. 
learning processes 
　　　no model of verbal behaviour could be complete without the incorporation of learning mechanisms. in this section we s h a l l show q u a l i t a t i v e l y that the word store model can cover tnem in a natural manner. the detailed exploration of these f a c i l i t i e s is in progress. 
　　　there is a vast variety of experimental paradigms for verbal learning. lack of space precludes any extensive discussion of the f i n d i n g s   so that again a set of i n t e r e s t i n g examples w i l l be taken: paired-associate learning  see  for example  goss and nodine1   mediated transfer of learning1 and semantic gene r a l i s a t i o n  see  for example  feather1 . 
　　　let us s t a r t with an exploration of possible l o c i for learning effects in the word store model. the most obvious 
p o s s i b i l i t y is the adjustment of the network structure and of the l i n k values. as far as the adjustment of l i n k values is concerned  the scheme closely resembles the perceptron mechanisms.1 it should 
be noted however that the choice of output  monitoring  nodes also contributes to the adaptive c a p a b i l i t i e s . it seems l i k e l y that a h i e r a r c h i c a l system of monitoring nodes w i l l be necessary in order to r e f l e c t the current state of the system. 
　　　these proposals result in a d i s t r i buted storage of the effects of learning. the scheme which is being explored at present is as follows. in a pairedassociate learning s i t u a t i o n the stimulus node is activated  then the system is allowed to run for a number of t r a n s i t i o n s . this results in an a c t i v i t y 
pattern over a certain area of the network. the nodes with the highest a c t i v i t y levels are selected  down to some threshold l e v e l . it is now ascertained whether these nodes are connected d i r e c t l y to the desired response node or not. if a connection e x i s t s   it is reinforced; if it does not  then a new connection is b u i l t . 
　　　clearly  a number of alternative schemes are possible and the eventual choice w i l l have to depend on detailed comparisons with empirical data. it is f e l t   however  that the model has a q u a l i t a t i v e   f i t   . for example  a w e l l known effect in paired-associate learning is that ease of learning increases with increasing m values of the responses. the m value is usually defined as the number of associations a subject can give to a word in a specified time i n t e r v a l . in terms of the word store model m w i l l be a function of the network connectivity in the neighbourhood of the word in quest i o n .  to obtain more precise results one should r e a l l y work with some grapht h e o r e t i c a l l y defined  sink  or  source  property of a node.  it i n t u i t i v e l y follows that  given the learning scheme described above  ease of learning w i l l increase if there are many existing path-
ways leading to the response term. 
　　　similar remarks can be made about mediated transfer  where the effects of existing associative connections on the transfer of learning manifest themselves. a c r i t i c i s m which can be directed towards most of these experiments is that they f a i l to recognise the fact that the associative connections are embedded in a network  so that many a l t e r n a t i v e pathways are operating simultaneously. this may be one reason why the exploration of a number of mediation paradigms1 leads to unclear r e s u l t s . 

-1-

　　　semantic generalisation  where a conditioned response is observed to generalise from one word to others which have similar meanings  is a natural property of the word store model if one observes that semantically related items form  strongly  connected clusters in the network.1 according to the learning scheme described  the associations are b u i l t in a d i s t r i b u ted fashion between some areas of the net-
work and the response; hence if semantic clusters e x i s t   semantic generalisation 
would follow. 
　　　the p o s s i b i l i t y of introducing i n h i b i t o r y links has not been mentioned so f a r . physiologically this is a very plausible mechanism. although the computer model was o r i g i n a l l y designed to work with excitatory links only  it was found that both negative links and negative a c t i v i t y values can be dealt with 
without changing the program. i n h i b i t i o n w i l l almost certainly be needed to ensure s e l e c t i v i t y of response and to prevent undesired generalisation. 
satiation 	effects 
　　　we shall close this section of the paper with a b r i e f discussion of s a t i a t i o n e f f e c t s . when a word is repeated or i n spected for a prolonged period of time  the subject usually reports that the word loses or changes i t s meaning. if after such treatment a word association test is made  then the number of uncommon or irrelevant associations obtained increases. 
　　　in the word store model repeated presentation of a stimulus has the effect that a c t i v i t y w i l l spread into more distant regions and hence more distant  uncommon and irrelevant  responses become l i k e l y . since the cumulative a c t i v i t y in the network is normalised  the eventual l i m i t i n g s i t u a t i o n is a more or less f l a t d i s t r i b u t i o n over a large area. the subjective changes in meaning seem to imply that there is an awareness of the overall state of the network in the subject and that the correct cognition of meaning depends on the presence of a characterist i c pattern of a c t i v i t i e s . this is the 
way in which connotative meaning can be 
represented in the word store model. 
the computer programs 
the pop- 1 programming language 
　　　the programs simulating the word store model are a l l w r i t t e n in pop-1. this is an on-line conversational programming language in use at the department of 
machine intelligence and perception at 
edinburgh university.1 	it is a powerful and sophisticated language for nonnumerical computation with a variety of data structures  including words  l i s t s   records  s t r i p s   and arrays; and with powerful f a c i l i t i e s for manipulating functions. the author was previously programming in ipl-v and found pop-1 a considerable advance  even apart from i t s conversational a v a i l a b i l i t y . 
     the features which this author found most useful are the combination of lisptype l i s t processing functions and the a b i l i t y to make assignments; the stack on which the arguments and results of functions are placed; the a b i l i t y to manipulate functions as data; records; good readability of programs; and automatic store management  garbage collection  . 
data structure of the model 
     the main data structure is held in a variable called memory. it is a l i s t of records. each record represents a word  a node in the network  and consists of six components. the components can be accessed by means of the standard updaterselector doublet functions of pop-1. the names of these are: name  which handles a character s t r i n g  the word which is represented by the node ; a l i s t   which handles the l i s t of links emerging from the node  and t h e i r values  strengths ; a c t i v i t y   which handles the numerical value of the current a c t i v i t y of the node; sjumact  which handles the cumulative a c t i v i t y ; and newact  which handles the a c t i v i t y received by the node during the current t r a n s i t i o n of the system. one further component of the record is used in addressing the disc store with large networks. 
     the component a l i s t is a l i s t of p a i r s . the f i r s t element of the pair is a pointer to a node  and the second is the numerical value. if the network is large  only the records are kept in core store and the alist1s are stored on disc. before each updating cycle  see figure 1  the a l i s t ' s of the nodes which have a nonzero a c t i v i t y are brought into core store  and a l l other a l i s t ' s   if any  are erased. in this way only the currently active nodes have association l i s t s attached to them and core store demands are kept low. 
main functions of the model 
     the central function is the main updating cycle of the network  called cycle. this function works through the memory l i s t and for each node it m u l t i plies the a c t i v i t y of the node with the 

＊1-

strengths of the links on the a l i s t . and adds the result to the contents of the newact's of the nodes to which the links go-
　　　to illustrate the flavour of the language  we give in figure 1 the function itself  exactly as typed on a teletype  apart from the underlining which is included here for readibility. the underlined words are syntax words and cannot be used as identifiers. the standard functions lid and tl select the head  lisp car  and t a i l  ttsp cdr  of a l i s t . the horizontal arrow is the assignment sign. apart from the usual bracketed functional notation  a.limited form of inverse polish notation is available by means of the dot operator. for example  m.tlstl m  takes the t a i l of the l i s t m. most of the other features 
shoulcl be self-evident. 
     when the end of the memory l i s t is reached  the function transfer is called. 
it adds the contents of newact to sumact  updating the cumulative activity   transfers the newact into the activity  and clears the newact  for each node. 
　　　the two functions  cycle and transfer  together define a transition of the system. most of the other functions are executive routines  generating one or another kind of behaviour  or u t i l i t y routines for building  modifying  reading and printing network structures. 
　　　as an example  the routine asequence  used for the generation of continued associations  operates as follows. 
request a stimulus from the console. 
clear the activities and cumulative activities. 
set the activity of the stimulus to 
1. 
set the time counter to 1  and init i a lis e a response l i s t . 
1. drive the memory through 1 transi-tions. 
normalise the cumulative activities to 1 over the memory. 
make a random choice weighted by the cumulative activities. 
look up the selected response on the response l i s t : - i f it is on the l i s t   go to 1; 
- i f it is not  then put it on the l i s t   print the name of the response  followed by the time count; 
1. clear the activities. set the activity of the response to 
1. 
increment the time count  print a newline  goto 1. 
　　　the main function for modifying the network is associate  which takes the names of two nodes as arguments and build a link with a specified value between them. if the link already exists  the old value is replaced by the new one. if one or both of the nodes are new  then fresh nodes are created and the new names are assigned to them. the link is then inserted normally. 
　　　a useful function in the learning processes is alink  which is a doublet for accessing or updating the value of a link between two specified nodes. in pop-1 a doublet is a function which can occur either as the source or the destina tion of an assignment. thus  alink  x y +z selects the value of the link between the nodes x and y and places it into z  while zaline x y  updates the value of the link between x and y to be  z. the updater part of the function alink w i l l also create a new link if it does not yet exist. 
