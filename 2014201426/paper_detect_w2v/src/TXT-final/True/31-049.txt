 
adding knowledge to a knowledge-based system is not monotonically beneficial. we discuss and experimentally validate this observation in the context of cabins  a system that learns control knowledge for iterative repair in ill-structured optimization problems. in cabins  situation-dependent user's decisions that guide the repair process are captured in cases together with contextual problem information. during iterative revision in cabins  cases are exploited for both selection of repair actions and evaluation of repair results. in this paper  we experimentally demonstrated that unfiltered learned knowledge can degrade problem solving performance. we developed and experimentally evaluated the effectiveness of a set of knowledge filtering strategies that are designed to increase problem solving efficiency of the intractable iterative optimization process without sacrificing solution quality. these knowledge filtering strategies utilize progressive case base retrievals and failure information to  1  validate the effectiveness of selected repair actions and  1  give-up further repair if the likelihood of success is low. the filtering strategies were experimentally evaluated in the context of job-shop scheduling  a well known ill-structured 
problem. 
1 	introduction 
recently  there has been increased interest in the issue of the utility of knowledge in knowledge-based systems. several studies  markovitch and scott  1; minton  1  have defied the traditional belief that increasing a problem solver's knowledge is a monotonically beneficial process. utility of knowledge depends on the difference between its cost  e.g. cost of knowledge acquisition  storage  matching  and its benefits  e.g. increased problem solving efficiency  increased solution quality . operational definitions of utility of a knowledge item in the literature  e.g.  minton  1   state that it is the difference between the cost of solving a problem with * previously at matsushita electric industrial co. ltd. 
the knowledge item and solving it without it. machine learning systems can acquire greater amounts of knowledge than is possible to be hand-coded for them by their developers. because less intelligence is involved in the automated knowledge acquisition by machine learning systems  the acquired knowledge may be of low quality  e.g. it could be incorrect  irrelevant or redundant . hence it is very important for machine learning systems to consider the quality of the knowledge they employ and develop heuristic strategies to eliminate harmful knowledge  i.e. knowledge whose elimination from consideration would improve problem solving performance.  markovitch and scott  1  has termed such strategies information filters because they filter out harmful knowledge from being used in problem solving. examples of information filters include discarding of least useful board positions in the checkers player  samuel  1   selecting only misclassified instances in id1  quinlan  1   and estimating the utility of newly acquired control rules and deleting those unlikely to be useful in prodigy 
 minton  1  
　to ascertain the utility of information filtering  it has to be shown that learned unfiltered knowledge is harmful in the sense that its addition to a system's knowledge base deteriorates system performance along some evaluation criterion. in this paper  we experimentally show non-beneficial effects of unfiltered learned knowledge in a system called cabins and study the effectiveness of three filtering strategies designed to fix the problem. cabins is a case-based system that learns control knowledge through user interaction and utilizes it for solution improvement through iterative repair in job shop scheduling  an ill-structured domain  miyashita and sycara  1 . the information filtering idea can be applied in a cbr system in various ways. one way could be to eliminate cases from the case base   forgetting   kolodner  1  . another way would be to prune out parts of the case base from consideration during problem solving. traditionally  this is done in cbr systems by using some sort of similarity metric. by ad-
justing the similarity metric a larger or smaller number of cases are allowed to pass this filter and be considered during problem solving. alternatively  instead of adjusting the similarity metric  various filtering tests could be applied to selectively narrow down retrieved knowledge from the cases. a fourth method could be filtering out 
	miyashita and sycara 	1 
information retrieved from cases  for example filtering out failure information. yet a fifth method could be to use retrieved knowledge to extract new indices for subsequent retrieval thus using successive retrievals as filters. the filtering strategies we have developed involve progressive information filtering using a combination of successive retrievals and tests and utilizing success and failure information stored in cases. 
　the use of failure information in cbr systems is not new. for example  chef  hammond  1  assumes the existence of a model-based simulator for evaluating a derived plan and detecting failure and uses handcrafted domain rules for selecting repair actions. work by  kambhampati and hendler  1  aims to speedup system performance through learning and case-based reuse of control rules in planning  where a correct satisficing plan is sought and a strong domain model is assumed. the contribution of our work is to experimentally study failure-based information filtering strategies in case-based control knowledge learning for an optimization task in a domain without a strong domain model cabins was evaluated in the task of schedule optimization in the job shop scheduling domain. our experimental results  presented in section 1 show that progressive filtering is superior to flat filtering in that it enables cabins to increase both solution quality and search efficiency. in particular  cabins uses its past failure experiences in progressive filtering to  1  validate use of a selected repair action  and  1  interrupt a repair that is unlikely to produce useful results. given our encouraging experimental results  we believe that our filtering strategies can be used as a domain-independent refinement of k-nearest neighborhood retrieval for control knowledge learning tasks. 
1 the task domain 
scheduling assigns a set of tasks over time to a set of resources with finite capacity. one of the most difficult scheduling problem classes is job shop scheduling. job shop scheduling is a well-known np-complete problem  french  1 . in job shop scheduling  each task  heretofore called a job or an order  consists of a set of activities to be scheduled according to a partial activity ordering. the dominant constraints in job shop scheduling are: temporal precedence constraints that specify the relative sequencing of activities within a job and resource capacity constraints that restrict the number of activities that can be assigned to a resource during overlapping time intervals. the activity precedence constraints along with a job's release date and due date restrict the 
set of acceptable start times for each activity. the capacity constraints restrict the number of activities that can use a resource at any particular point in time and create conflicts among activities that are competing for the use of the same resource at overlapping time intervals. the goal of a scheduling system is to produce schedules that respect temporal relations and resource capacity constraints  and optimize a set of objectives  such as minimize tardiness  maximize resource utilization etc. 
　the tight interactions between temporal precedence and capacity constraints give rise to many nonlinear effects during search for an optimal schedule. it is in general impossible to have a strong domain model that could help estimate the effects of system decisions on optimization objectives. the use of heuristics and study of experimental results is the typically used method for job shop schedule optimization  french  1 . 
1 cabins overview 
in order to make the information filtering aspect comprehensible  we give here a brief and of necessity incomplete overview of cabins. for more details on cabins implementation  operation and other experimental results that describe different cabins capabilities  the reader is referred to  miyashita and sycara  1 . 
　cabins incrementally revises a complete but suboptimal schedule to improve its quality. revision con-
sists in identifying and moving activities in the schedule . to move activities  cabins uses a number of repair operators  called repair tactics that it possesses. in the current implementation  cabins has 1 repair tactics  e.g.  jumpjeft  which moves an activity as much to the left on the timeline as possible without violating precedence constraints . because of the tight constraint interactions  a revision in one part of the schedule may cause constraint violations in other parts. it is generally impossible to predict in advance either the extent of the constraint violations resulting from a repair action  or the nature of the conflicts because of interacting influences of constraint propagations. therefore  a repair operator must be selected  applied and its repair outcome must be evaluated in terms of the resulting effects on scheduling objectives. 
　thus  at each decision point  cabins must make three control decisions: which activity to move  which repair operator to apply and how to evaluate the repair result so as to eventually optimize overall schedule quality according to scheduling objectives. each of these decisions is very difficult for the following reasons. a schedule typically contains many jobs  each of which contains many activities. there is no a priori knowledge as to the order of activity moves that will give the best result. moreover  we have found no distinguishing features of an activity per se that would allow satisfactory matching with previous similar activities. therefore  cabins orders the jobs randomly and within each job repairs activities from the first to the last  miyashita and sycara  1 . since activities get moved during repair  an activity may be repaired  moved  multiple times during a problem solving session. selecting a repair operator to apply is also very difficult. unlike traditional planning operators  the repair operators in cabins have no well defined preconditions or postconditions. hence learning operator selection is fraught with all the difficulties of learning control rules in traditional planning plus the additional complexity of not knowing the operator preand post-conditions. cbr enables cabins to learn a control model of repair operator selection. finally  evaluation of the result of applying a repair operator is also very difficult  since the optimization objectives are often context and user dependent and reflect state-dependent tradeoffs that are difficult to describe in a simple man-

ner. cabins learns through cbr what combinations of effects of application of a particular repair action constitutes an acceptable or unacceptable repair outcome. 
　in each repair iteration  cabins focuses on one activity at a time  the focalactivity  and tries to repair it. a case in cabins describes the application of a particular modification to a focalactivity. a case in cabins comprises 1 types of the features: global features  local features and repair history. the global features reflect an abstract characterization of potential repair flexibility for the whole schedule. associated with the focal activity are local features that we have identified and which potentially are predictive of the effectiveness of applying a particular repair tactic. because of the illstructuredness of job shop scheduling  local and global features are heuristic approximations that reflect problem space characteristics. 
　the repair history records the sequence of applications of successive repair actions  the repair outcome and the effects. repair effect values describe the impact of the application of a repair action on scheduling objectives. a repair outcome is the evaluation assigned to the set of effects of a repair action and takes values in the set  'acceptable'  'unacceptable' . typically the outcome reflects tradeoffs among different objectives. an outcome is 'acceptable'  i.e. a success  if the user accepts the tradeoffs involved in the set of effects for the current application of a repair action. otherwise  it is 'unacceptable'  a failure. the effect salience is assigned by the user when the outcome is 'unacceptable'  and it indicates the significance of the effect to the repair outcome. the user's judgment as to balancing favorable and unfavorable effects related to a particular objective constitute the explanations of the repair outcome. 
　once enough cases have been gathered through user interactive schedule repair  cabins repairs sub-optimal schedules without further user interaction. cabins repairs the schedules by  1  sorting jobs in a random order   1  focusing on a focalactivity to be repaired in each repair cycle   1  invoking cbr with global and local features as indices to decide the most appropriate repair tactic to be used for each focalactivity   1  invoking cbr using the repair effect features  type  value and salience  as indices to evaluate the repair result  and  1  when the repair result is deemed a failure  deciding whether to give up or which repair tactic to use next. the similarity metric that cabins uses is a k-nearest neighborhood method. 
1 	experimental design 
to test whether learned unfiltered knowledge is beneficial or not  we used controlled experimentation on a benchmark suite of job shop scheduling problems. these problems are variations of the problems we have used to test other aspects of cabins  miyashita and sycara  1 . the benchmark problems have the following structure: each problem has 1 orders of 1 activities each. six groups of 1 problems each were randomly generated by considering three different values of the range parameter  and two values of the bottleneck configuration. 
　a cross-validation evaluation method was used. each problem set of each problem class was divided into two groups with the same size  i.e.  each group contains 1 problems . currently we have collected about 1 cases for each group of training sets. these cases were then used for case-based repair of the test problems in the other group. the above process was repeated by interchanging the training sets. 
　in the experiments reported here  we used the sum of tardiness and inventory costs as an explicit cost function to reflect optimization criteria1. we built a greedy hillclimb rule-based optimizer  rbr  that goes through a trial-and-error repair process to optimize a schedule by minimizing the cost function. rbr was implemented to try what seems a best repair action first based on heuristic evaluation of its possible repair effects and go through all the available repair actions before giving up further repair. for each repair  the repair effects were calculated and  on this basis  since rbr had a pre-defined cost function  it could evaluate repair results precisely. rbr was used as the experimental baseline where no learning of control knowledge takes place. rbr was also used as a case base builder for cabins. each time rbr repaired an activity  the repair decisions made by rbr such as repair action selection and repair result evaluation were recorded in a case. in this set of experiments  rbr was used to create a case base with 1 cases. 
naturally  a cost function  though known to rbr  is not known to cabins and is only implicitly and indirectly reflected in an extensional way in the case base. 
　in our experiments  the number of repair tactic applications was used as a metric of search efficiency for a number of reasons:  1  tactic application involves constraint propagation and calculation of repair effects  thus being the most computationally expensive process in schedule repair   1  the number of tactic applications is a machine independent measure  as opposed to for example  cpu time  and  1  the number of tactic applications directly reflects the number of search states examined. reduction of the number of tactic applications improves the efficiency of iterative schedule revision process. 

　in table 1  unfiltered  indicates the performance of cabins  which retrieves similar successful repair experiences and applies the repair tactic that was dominant in the most similar success cases. if the tactic is evaluated as unacceptable  in the unfiltered condition  cabins automatically tries another repair tactic used in the next most similar cases. 
　table 1 shows that unfiltered learned knowledge is indeed harmful in terms of problem solving efficiency al-
　1such a cost function is widely accepted in practical scheduling environments. 
	miyashita and sycara 	1 

though it produces solutions of similar quality as compared to the base condition of rbr. this result means that the cost of utilizing the learned knowledge is excessive. we think that this is due to the unfiltered repair's greediness and stubbornness. greediness makes unfiltered repair applies the tactic from the most similar success case no matter how small the similarity. stubbornness makes the unfiltered repair insists on trying to repair the current focal activity without giving up if the likelihood of a successful repair seems small. 
1 information filtering 
to decrease the number of tactic applications without sacrificing solution quality  filtering strategies must be found that retrieve more relevant tactics and better estimate the likelihood of successful outcome before application of a selected tactic. we hypothesized that incorporating failure information in filters would alleviate nonbeneficial effects of potentially harmful learned knowledge by lowering the cost of excessive number of tactic applications. so we focused on designing filters that would enable cabins to  1  learn to avoid repeating similar previous failures  and  1  learn to avoid wasting lots of efforts in trying to solve too difficult problems. 
　to analyze the correctness of the above hypothesis  the following three filtering strategies were experimentally implemented in cabins: validated filtering  interruptive filtering and hybrid filtering. these filtering methods were tested using the same problems  cost function and case bases used for the experiment in section 1. 
1 	validated filtering 
the validated filtering method allows cabins to apply a repair action only after it has been validated as possibly effective for repairing the current problem. validation techniques have been used in case-based reasoning systems  e.g.  hammond  1; simoudis and miller  1  . for example  in cascade and coast  simoudis and 
miller  1   a validation process extracts from the case base only those cases that appear to be closely relevant to the current problem using a validation model of the domain which consists of knowledge of interrelations among diagnostic tests and knowledge about individual diagnostic tests and their expected values in previous cases that would match a current problem. 
　the above systems utilized established models based on deep understanding of their domain for validation. domain models act as filters that allow only validated information to be used in problem solving. however  in ill-structured domains like job shop scheduling  neither causal model nor validation model of the domain are readily available. in the job shop scheduling problem  non-linearity of objectives and tight interactions of constraints make it hard to predict the effects of a local optimization decision on global optimality  thus making the analysis of the domain structure required to build a causal model and a validation model extremely difficult. therefore  cabins must validate the potential effectiveness of a retrieved repair tactic without such models. to compensate for lack of these models  cabins 

figure 1: validation filtering process in cabins 
　fig. 1 shows the schematic diagram of the validation filtering process in cabins. first  using global and local features as indices  candidate cases are retrieved from success cases that store successful repair episodes in a case base. then  another cbr retrieval is done from 
failure cases using as additional indices the repair tactics indicated in the already retrieved successful cases. this retrieval results in a set of rejecting cases. the candidate repair tactics found in rejecting cases with low credibility  i.e. low similarity to the current problem   are then allowed to be used since they have been validated to be possibly effective  i.e. not likely to fail . 
　the repair tactic selection procedure using validated filtering is as follows: 
1. select k 1 nearest cases of the current problem that succeeded in repair using global and local case features as indices  these are labelled  candidate cases  in fig. 1 . 
1. among the candidate cases  obtain the sum of case similarity 1 to the current problem for each of the repair tactics which was successfully appiled in the cases. 
1. sort the repair tactics of step 1 in decreasing order of the corresponding value of the similarity sums. 
1. until no repair tactic remains in the sorted queue  do the followings: 
 a  pick up the next repair tactic in the sorted repair tactics queue. 
 b  using as indices  global and local features and the picked-up repair tactic  select k nearest cases of the current problem  in which an application of the picked-up tactic resulted in failure   rejecting cases  in fig. 1 . 
 c  sum up the similarity of the selected k  rejecting cases . 
 d  if the sum is smaller than a pre-defined threshold value  return the tactic as a validated tactic. 
1. return  give.up  as a repair tactic  i.e. give up trying to repair the current activity. 
1 in our experiments  we heuristically decided k as 1. 
1 for details of the similarity calculation  see  sycara and miyashita  1 . 

　the validated filtering procedure allows only validated tactics to be considered for repair application. cabins judges the likelihood that a selected repair tactic will fail in the current problem from the past failure experiences of the same tactic. if cabins judges that a tactic is not likely to fail in the current problem  i.e. the sum of similarity of rejecting cases associated with the tactic is less than some threshold   cabins considers the repair tactic as validated. 
　since in difficult problems such as schedule repair  failures usually outnumber successes  if the value of the threshold  in step 1 d  of the above procedure  is defined as moderately high  overly pessimistic results could be produced  i.e. cabins seldom validates a tactic . to avoid this  a threshold value was set as 1. since the value of k was 1 in the experiments  validation rejection was less likely to occur. 
1 	interruptive filtering 
in validated filtering  cabins gives up repairing a particular activity either when there are no validated tactics  or when all validated tactics have resulted in failure  i.e. an unacceptable repair outcome . the interruptive filtering method allows cabins to shift its repair attention to another activity when repair of the current activity is estimated too difficult. cabins gives up a further repair when it determines that it would be a waste of time. if there are enough failure cases in the past similar situations to the current one  cabins gives up repairing the current activity  and switches its attention to another. 

figure 1: interruptive filtering process in cabins 
　fig. 1 shows the schematic diagram of the interruptive filtering process in cabins. in the process  cases that match the current problem are retrieved from failure cases  the retrieved cases are called interrupting cases in fig. 1 . if the interrupting cases have high credibility  i.e. high similarity to the current problem   the process of retrieving candidate cases to use in repairing the current focal .activity is not allowed to proceed and the problem solver seeks another activity to repair. 
　the repair tactic selection procedure using interruptive filtering in cabins is as follows: 
1. using global and local features as indices  retrieve k nearest cases of the current problem from failure cases  i.e.   interrupting cases  in fig. 1 . 
1. sum up the similarity of the selected k  interrupting cases . 
1. if the sum exceeds a pre-defined threshold value  return  give up  as a repair tactic  i.e. give up repairing the current focalactivity. 
otherwise  select k nearest cases of the current problem using global and local features as indices from successful cases  these are the  candidate cases  in fig. 1 and they are the same as the  candidate cases  in fig. 1 for a given focalactivity . 
1. among the candidate cases  obtain the sum of case similarity to the current problem for each of the repair tactics which was successfully appiled in the cases. 
1. sort the repair tactics of the previous step in decreasing order of the corresponding value of the similarity sums. 
1. return the first repair tactic in the sorted repair tactic queue as the selected repair tactic. 
　in the above procedure  cabins judges the likelihood that a current problem cannot be repaired from failure experiences in past similar problems. if cabins judges that the current problem is not likely to be repaired  i.e. the number of failures of similar past problems is high enough   cabins gives up repairing the current problem. if cabins decides that the current problem is not too difficult  it proceeds to repair it selecting repair tactics from success cases without tactic validation. as was discussed in the validated filtering method  in difficult problems such as schedule repair  failures usually outnumber successes and if the value of the threshold  in step 1 of the above procedure  is defined moderately high  overly pessimistic results could be produced  i.e. cabins suggests giving up too often . to avoid this  a value of the threshold was set as 1. 
　the ways failure cases are used in validated and interruptive filtering seem to be independent and compatible with each other. each filtering strategy filters different knowledge at different stages of repair action retrieval and evaluation. hence  the two strategies can be combined in a serial fashion to form a hybrid filtering strategy. 
1 	hybrid filtering 
in hybrid filtering  cabins first decides whether to give up repairing the current focalactivity using  interrupting cases   as in interruptive filtering . if it is decided that repair of the current focalactivity should proceed  cabins uses validated filtering to validate the selected tactics that will be tried in the repair. 
　the repair tactic selection procedure using hybrid filtering in cabins is as follows: 
1. using global and local features as indices  retrieve k nearest cases of the current problem from failure cases  i.e.  interrupting cases  in fig. 1 . 
1. sum up the similarity of the selected k  interrupting cases . 
1. if the sum exceeds a pre-defined threshold value  return  give.up  as a repair tactic  i.e. give up repairing the current focalactivity. 
	miyashita and sycara 	1 


　table 1 shows performance comparison among the unfiltered condition  rbr  and the three filtering strategies. the results in the table show that cabins with validated filtering improved its efficiency about 1% as compared with the unfiltered condition without unduly sacrificing schedule quality. cabins with validated filtering was even faster than rbr. table 1 also shows that cabins with interruptive filtering improved its efficiency about 1% as compared with unfiltered condition while maintaining high schedule quality. 
　from the results in the table  it is also shown that cabins with the hybrid repair improved its efficiency about 1% compared with the unfiltered condition without reducing schedule quality. the results also suggest that cabins with hybrid filtering produced high quality schedules more efficiently than rbr. 
　to analyze the effects of combining two repair methods in the hybrid repair  the number of tactic application using validated filtering and using interruptive filtering were compared with that of hybrid filtering. by hypothesis testing  it was found that cabins with hybrid filtering should be more efficient than cabins with interruptive repair or cabins with validated repair. therefore  by combining the validated repair and the interruptive repair  a synergistic effect emerges in improving the efficiency of the repair process. 
　although experimental results show that the three information filtering strategies were effective in reducing the number of tactic applications in cabins  it could be argued that knowledge filtering will also consume computational resources. cpu time is a generally accepted metric of overall problem solving cost. the averaged cpu time results in table 1 show a pattern similar to the one observed for number of tactic applications  i.e.  validated repair  interruptive repair and hybrid repair consume less cpu time than unfiltered repair  in our experiments. these results are encouraging. 
1 	conclusions 
we discussed the phenomenon of non-beneficial effects  in terms of degradation of the performance of a problem solver  of learned knowledge. we showed the existence of this phenomenon in the context of case-based learning of control knowledge. this knowledge is used to to guide revision-based optimization in an ill-structured domain  
job shop scheduling. to alleviate the non-beneficial effects of learned knowledge  we designed and experimentally demonstrated the effectiveness of three knowledge filtering strategies. these strategies  validated filtering  interruptive filtering and hybrid filtering employ a combination of successive case retrievals and in particular exploit failure information found in cases in order to  1  validate learned control actions  or  1  avoid wasting effort in attempting repairs where the likelihood of success is low. our experimental results show that the knowledge filtering strategies were effective in increasing the efficiency of problem solving without compromising solution quality. we are currently exploring automated adaptation of the filtering control parameters  value of k and of the threshold . 
　　　　　　　　　　　　　　　　　　　　　1 references 
 french  1  simon french. sequencing and scheduling: an introduction to the mathematics of the jobshop. ellis horwood  london  1. 
 hammond  1  kristian j. hammond. case-based planning : viewing planning as a memory task. academic press  new york  ny  1. 
 kambhampati and hendler  1  subbarao kambhampati and james a. hendler. a validationstructure-based theory of plan modification and reuse. artificial intelligence  1-1 :1  1. 
 kolodner  1  janet kolodner. case-based reasoning. morgan kaufmann  san mateo  ca  1. 
 markovitch and scott  1  shaul markovitch and paul d. scott. information filtering: selection mechanisms in learning systems. machine learning  1-1. 
 minton  1  s. minton. learning effective search control knowledge: an explanation-based approach. kluwer academic publishers  boston  ma  1. 
 miyashita and sycara  1  kazuo miyashita and katia sycara. cabins: a framework of knowledge acquisition and iterative revision for schedule improvement and reactive repair. artificial intelligence  1. to appear. 
 quinlan  1  j. ross quinlan. induction of decision trees. machine learning  1 :1  1. 
 samuel  1  a. l. samuel. some studies in machine learning using the game of checkers. ibm journal  1-1. 
 simoudis and miller  1  e. simoudisand j.s. miller. the application of cbr to help desk applications. in 
proceedings of the case-based reasoning workshop  pages 1. darpa  1. 
 sycara and miyashita  1  katia sycara and kazuo miyashita. case-based acquisition of user p