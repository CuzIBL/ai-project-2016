 
results are presented for a new method to identify images of moving objects in a sequence of scene images  e.g. from a tv-camera observing a street intersection. the reported approach exploits the assumption that systematic greyvalue differences based on second order statistics - between consecutive frames are due to images of moving objects. no knowledge is assumed about size  shape  or texture for images of stationary or non-stationary scene components. 
1. introduction 
if a component of a scene is displaced relative to the stationary scene part from moment to moment without significantly changing its internal structure then it appears as a natural abstraction to consider the systematically displaced component to represent a moving object. a sequence of images may  therefore  be evaluated under the assumption that systematic displacements of some image components from frame to frame can be taken as a strong hint to look for the image of a moving object. this assumption opens a way to extract object representations from a sequence of image frames without detailed knowledge about size  shape or textural appearance of the object or the stationary part of the scene. during investigations of this possibility cnagel 1b  nagel 1  it became necessary to quickly and reliably identify non-stationary image components in a sequence of images  e.g. tv-frames from a tv-camera observing a street intersection 
with cars and pedestrians or a conveyor belt with industrial parts. 
we want to suggest an approach which seems to offer a reliable basis for separating non-stationary from stationary image components. 
1. comparison of digitized images based on second order statistics 
a complete digitized tv-frame comprises of 1 lines with 1 pixels each at our installation. the area consisting of four neighbouring pixels for six consecutive lines is defined as a 'geo-pixel'. for each geo-pixel the mean greyvalue m and the corresponding variance s is calculated and stored. since the greyvalues are digitized to eight bits and - due to computational reasons - not the mean 
 *  on leave from electronics & electrical communication engineering department  indian institute of 
technology  kharagpur 1  india 
and variance but the sum of greyvalues and squared greyvalues are preserved for each geo-pixel  the amount of storage required for each geo-pixel is given by 1 bits for the greylevel sum and 1 bits for the sum of the squared greylevels. since these sums will have to be accumulated for several frames  even more bits have to be reserved. by suitable packing  these data f i t - for each geopixel - into two 1 bit words of our decsystem-1. we thus require 1x1 = 1 words of core for an entire tv-frame in geo-pixel format. 
for every tv-frame in'the sequence  each geo-pixel is compared to data previously observed at the some geo-pixel coordinates by means of the follow-

m and s  denote the mean greyvalue and its variance for the measurements accumulated at this geo-pixel position. this expression is formed in analogy to one given by yakimovsky 1 to determine whether two neighbouring test areas can be thought of being measurements from identical or from differing normal distributions for preylevels. here  the measurements are not taken from two neighbouring areas of the same tv-frame but rather from the same area of two neighbouring tv-frames - an idea which comes quite natural when working with the yakimovsky algorithm cyakimovsky 1  nagel 1 on sequences of tv-frames cnagel 1. 
if the likelihood ratio turns out to be smaller than a threshold t  in our experiments chosen within the range 1 to 1  then the two sets of measure-
ments for this geo-pixel position are considered to be drawn from the same normal greylevel distribution. on this basis  the sum of greylevels as well as the sum of squared greylevels for this geo-pixel from frame n+1 are added to the corresponding  already accumulated sums for the geo-pixel at the same coordinates and the count of contributing pixels for this geo-pixel is increased by 1. this corresponds to taking repeated measurements and averaging them to obtain a better estimate for the grey value of this geo-pixel. 
if  however  the likelihood ratio equals or exceeds the chosen threshold t  it is decided to attribute the measurements for this geo-pixel in frame n+1 to a different normal greylevel distribution than the one from which the hitherto accumulated measurements for the same geo-pixel coordinates were obtained. in this case the sums of greylevels and squared greylevels are entered together with the frame number and the geo-pixel location into a list 

vision-1: jain 1 

of  yet unconnected  see later  'not matched' geopixels which is ordered according 
- first to line numbers  
- for each line according to column numbers  
- for each column number according to frame numbers. 
figure 1 shows two pictures of a tv-frame sequence from a street intersection scene. figure 1 shows the numbers of geo-pixels at each of the 1 geo-pixel positions which are in the 'not matched' or 'failing match' list when seven subsequent frames are compared in the described manner. one can easily see areas with a high density of 'not matched' geo-pixels. with the exception of the vertical band at the left which is due to hardware trouble  line jitter compounded by some other effect   one can attribute the high density 'not matched' areas to moving objects: the bright car crossing the intersection  a pedestrian to the lower left and a car at the lower center coming to a stop. 
if the failing match of a geo-pixel is due to genuine motion of the corresponding object then the next frame should also not match at the same geopixel position. this consideration is used to build a filtering process by which the accidentally failing matches can be removed to some extent 
with a local operation. 
as soon as a failing match is observed at a geopixel position in frame n+1  this position is flagged. if comparison of the geo-pixel from frame n+1 with the data accumulated at the same coordinates in the geo-pixel matrix up to frame n yields a failing match  too  then both failing matches are definitely accepted. this situation is henceforth denoted as a mismatch. moreover  this geo-pixel position continues to be flagged until a match will be observed for i t . if the geo-pixel from frame n+1 matches to the data accumulated up to and including frame n then the failing match at this position in frame n+1 is dropped. the corresponding greyvalue and squared greyvalue data from frame n+1 are not incorporated into the accumulated measurements  whereas those of frame n+1 are incorporated. the 'failing match' flag is removed for this geo-pixel position. figure 1 presents the definite mismatches obtained by comparing the same tv-frames that resulted in figure 1. most of the noise has disappeared. 
based on these results  two alternative approaches have been devised to extract non-stationary image components. 
1. clustering of mismatched geo-pixels 
if a mismatch for a geo-pixel position could really be attributed to definite changes in greylevels for this position due to motion of an object in the scene then sooner or later mismatches must be observed in neighbouring geo-pixels. therefore  a candidate for a non-stationary image component is formed for every 1-connected group of mismatched geo-pixels which 
- contains at least one geo-pixel for which the number of mismatches exceeds a certain fraction of the number of tv-frames compared  this fraction is currently taken to vary between 1 % and 
1 % : a so-called 'strong mismatch'-  
- contains at least one additional mismatched geopixel which is 1-connected to a 'strong mismatch'. 
additional mismatches may be 1-connected to a 
'strong mismatch' either directly or indirectly through other mismatches. it is considered sufficient to look for all 1-connected mismatches since even for oblique motion relative to the tv-raster enough neighbouring geo-pixels should eventually show a mismatch to establish 1-connection between them. 
figure 1 presents the candidates for non-stationary image components extracted from the data represented in figure 1. 
up to this point the algorithm contains only three parameters: the threshold t for the likelihood ratio  the number n of frames after which the list of mismatched geo-pixels is searched for non-stationary component candidates  and the fraction of n which is required for a strong mismatch. one could consider the minimum number of 1-connected mismatches in a cluster as another parameter which for some pictures might be set higher than 1 as it is done here. now an additional step is introduced 
which provides the setup to repeat the steps discussed so far. 
an enclosing rectangle for each non-stationary image component candidate is determined. one pair of rectangle sides is taken to be parallel to the scanline. the coordinates of the rectangle edges are remembered for a later estimate of the velocity vector to be attributed to the non-stationary component candidate. after these preparations the next n frames are compared to the geo-pixel matrix. whenever a mismatch occurs at a geo-pixel position 
1-connected to a candidate as enclosed within the  latest  rectangle  then this mismatch is considered to belong to the candidate to which it is uconnected  note that a mismatch requires at least two subsequent 'non-matches' and that it must be 1-connected to a candidate for the non-stationary image component itself  not to the rectangle enclosing i t   . if a mismatch cannot be 1-connected to an already existing non-stationary component candidate  it is introduced in a separate list of 'yet unconnected' mismatches. in this way even mismatches due to very slow motions will eventually be recognized after sufficient frames have been compared. 
whenever another series of n frames has been treated in this manner  the enclosing rectangles about the newly added mismatches of already existing non-stationary component candidates are determined. then the left and right edges of such a newly enclosing rectangle are compared with those of the preceding enclosing rectangle of the same candidate. the larger of the two edge displacements for each candidate will determine an estimate of the image displacement velocity for this candidate 

vision-1: jain 1 

along the horizontal axis. the smaller displacement velocity is attributed to residual mismatches in the trailing part of the non-stationary image component candidate. to take this hypothesis into account  the trailing fraction of the newly determined enclosing rectangle equal in extension to the displacement difference between leading and trailing edge of the enclosing rectangle during the last n frames is released.  note that this implies assuming a constant extension of the nonstationary image component candidate along the apparent direction of motion.  as a consequence  all entries for these geo-pixel positions are cleared since it has just been decided that the non-stationary image component moved away from there and uncovered the background. new estimates of the background can be accumulated in these geo-pixel positions during subsequent frames. the same approach is taken with respect to the vertical displacement. before handling the next n frames  the list of 'yet unconnected' mismatches is searched for additional non-stationary image component candidates; all remaining isolated mismatches are then thrown away. 
this algorithm has been tested on four image sequences from different street scenes  each containing 1 tv-frames. the threshold t had to be va-
ried between 1 and 1 to yield optimal results for these image sequences. the number n of frames in one subseries has always been choosen to be 1 and the fraction of it establishing a strong mismatch was best taken to be 1 %  1 out of 1 frames . 
in order to obtain good results for all four image sequences with the same threshold value  the match criterion of paragraph 1 has been modified by replacing all variances s with max s  1  - note that the nominator of the match criterion represents the square of the variance for greyvalues from all pixels involved in this test. 
about 1 seconds cpu-time of a dec ki-1 processor are required to test already prepared geo-pixel data of one tv-frame for a match with previously accumulated data. if one starts directly from the raw digitizings  about 1 seconds per frame are required. after each subseries of n frames an additional 1 seconds cpu-time are required to process the mismatches found in this subseries  about 1 per frame depending upon the threshold value . 
the final extraction of moving object descriptions from non-stationary image components may proceed according to the methods discussed in nagel 1b and nagel 1. 
1. exploiting a monotony characteristic of the mismatch count 
based on the mismatches established by the algorithm of paragraph 1 an alternative approach to the one described in paragraph 1 has been devised. this alternative may either be used to complement the one described in the preceding paragraph or to yield another estimate for the image of a moving object  thus allowing a consistency check on the estijnation of the image of the moving object. 
the differencing operation described in section 1 results in clear indication of those regions of the frames where changes are taking place. this operation offers one very attractive property which may be exploited for extracting the image component potentially due to a moving object. let us consider an idealized situation to understand this property: an object with homogeneous greyvalue is moving parallel to the image plane of the tv-camera against a homogenous background. at the rear end of the object some part of the background which was covered by the object in the previous frame is uncovered and at the front end some uncovered part of the background is covered by the moving object. this results in mismatched geo-pixels. assuming the reference frame to be represented as 1th frame  after the 1st frame there will be 1 entry for each 'not matched' geo-pixel corresponding to these regions. the 'not matched' geo-pixels may be thought of as representing a difference picture. 
after the second frame  the regions of the difference picture which were having is become 1s and the new regions due to the uncovering and covering of background will have is. after the. 1rd frame  1s become 1s  is become 1s and newly created regions receive is. if the object motion is unidirectional  this process continues until the object image has 
moved over the distance equivalent to its projection along the direction of motion in the image plane of the tv-camera. this phenomenon is depicted in figure & for the comparison of 1 frames. hence if one observes neighbouring entries in the difference picture corresponding to this idealized situation  the entries are found to be monotonic in nature. the above discussion is valid for the motion having a velocity component perpendicular to the line of sight of the camera. if the velocity component in the image plane of the tv-camera is zero then mismatches for a motion along the line 
of sight of the camera will be due to size changes for the projected image of the moving object. however  this case is not considered in the present implementation. 
in real world pictures the situation is not  unfortunately  so straightforward. because of the inho-
mogeneous objects and inhomogeneous background  some noise is introduced in the difference picture. still it should be expected that for the most part these entries  assuming the noise not to be very high  in high noise situation even the human beings make mistakes  will confirm monotonicity. accordingly  for an object having a velocity component perpendicular to the axis of the camera there should be two more or less monotonic regions - provided this object is completely contained in the field of view  is not occluded  and does not show vanishing contrast with respect to the stationary scene part that is currently occluded by this object. 
vision-1: jain 1 the monotonicity of the entries will also indicate the direction of the motion: the object will be moving in the direction in which the entries are decreasing. on knowing the direction of the motion it is immediately known which region corresponds to the rear end of the object and which to the front of the object. it should be noted that the mismatch region at the rear end of the object is formed due to uncovering of the background while the mismatch region at the front end is formed due to covering of the background by the object. 
hence the mismatch regions in the nth frame correspond to the background component and the object component  respectively. these two regions may be utilized to estimate a representation of the nonstationary image component. 
in the present algorithm we extract the properties of the background  presently only greylevel  and then build up the non-stationary component by considering that all the pixels in the area fixed by the two regions of the difference picture which are differing from the background by an appreciable amount represent the object. this algorithm is applied to the tv-sequence' of the traffic scene. the result obtained from frame 1 is shown in figure 1. a simple filtering of noise is achieved bv removing all the 1-connected regions of size less than 1. the regions of the non-stationary component having different greylevels are printed using different characters in the filtered non-stationary components shown in figure 1. it should be noted that in this example the car and its shadow are considered to be the same nonstationary image component because they are moving together  although they have very different greyvalues . 
once these non-stationary image components are extracted  estimation of their velocity components presents no problem. moreover  the representation of the non-stationary image component candidates may be compared with the representation of the corresponding candidates in subsequent frames. any pixels which do not appear in a large fraction of candidates will be discarded from the representation of the non-stationary image component. additional domain independent knowledge may subsequently be applied to support the hypothesis that the non-stationary image component can indeed be taken as a representation for the projected image of a moving object in the scene. however  such techniques exceed the scope of this contribution. 
1. conclusion 
the experiences with yakimovsky's algorithm show that a segmentation of greylevel pictures based on the above mentioned second order statistics likelihood ratio seems to be a very robust method cnagel 1al. further experiments are necessary to verify whether application of the same approach to the comparison of consecutive frames turns out to be robust  too. 
the method proposed by potter 1 seems to present difficulties if applied to real world scenes. chow and aggarwal 1 work with objects showing a high contrast against background so that noise problems do not bother them. part of the results reported by chien and jones 1 refer equally to experiments with well controlled contrast. their work on realtime tracking of cars in a street scene is primarily concerned with finding and following prominent greyvalue features rather than extracting a description of a moving object from the tv-frame sequence as in our work. limb and murphy 1 developed a method for the detection of a non-stationary image component in the context of bandwidth compression of tv-signals  they essentially rely upon a threshold for the greyvalue difference between successive frames to find a non-stationary image component. they do not attempt to isolate and extract the image of a moving object. further references to the literature may be found in nagel 1b and nagel 1. 
it is obvious that the combinations of the algorithms proposed here with evaluation of segmentation results for individual images may yield additional information as to what regions are likely to belong to the image of a moving object. especially in the case where the leading and trailing edges characterized by mismatches can be connected within each frame by  a group of  regions with constant greyvalue'characteristics  strong support would be obtained to consider these  group of  regions as a representation for a moving object. 
it might be worthwile to point out that no special emphasis is placed by this approach on the first frame. although it provides the starting estimates for each geo-pixel characteristic  these are either reenforced by accumulation of data from compatible geo-pixels in later frames - indicating that this geo-pixel belongs to a stationary image component - or new estimates are started once the non-stationary component has disappeared from this area of the image. 
it should be noted that the approach suggested here will allow to determine automatically a window within each image around a suspected moving object candidate. in addition  it can be used to derive the frame number difference between two frames within which the non-stationary image component has been displaced by more than its own extension along the direction of motion. therefore  a direct comparison of these two frames will contrast the non-stationary image component against parts of the stationary image component in the other frame  thus enabling a simple extraction. the automatic determination of a  conservative  window around the non-stationary image component and the appropriate frame number difference are the essential parameters for the method described in nagel 1b where these parameters s t i l l had to be estimated by a human operator and supplied as input values. therefore  the current contribution can be seen as giving additional support to the approach described in nagel 1b. it should be emphasized that the approach described here must be seen as one part in an entire system for analysis of image sequences  as e.g. in the envisaged dersign of a system for the analysis of tv-frame sequences outlined in nagel 1. 

v ! s ! o n - 1 : jain 
1 

1  