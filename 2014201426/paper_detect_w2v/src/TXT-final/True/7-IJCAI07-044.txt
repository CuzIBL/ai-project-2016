
in this paper we propose a framework for decentralized model-based diagnosis of complex systems modeled with qualitative constraints and whose models are distributed among their subsystems.
we assume that local diagnosers are associated with subsystems and are coordinated by a supervisor which acts as the diagnoser for the complex system. the local diagnosers and the supervisor communicate via a standard interface and share a common modeling ontology. in this diagnostic architecture  connections between subsystems only need to be known at runtime  thus allowing for dynamic  re configuration of the system.
the approach is designed to compute partial hypotheses in order to avoid unnecessary queries to local diagnosers.
1 introduction
developing diagnostic software for complex systems is a challenging task especially when a system is composed of many subsystems coming from different suppliers  a very common situation in industry . decomposition has been recognized as an important leverage to manage architectural complexity of the systems to be diagnosed. most of the approaches  however  focus on hierarchical decomposition  genesereth  1; mozetic  1   while decentralization has been explored less frequently  see e.g.  pencole뫣 and cordier  1  . on the other hand  new problems have to be faced when independently manufactured subsystems are assembled. each subsystem may come with its own  possibly embedded  diagnostic software whose details should not be disclosed to the customers. a diagnostic software for a complex system has thus to take into account all its subsystems and their diagnosers. the structure of the system and the paths of interaction of the subsystems may be defined statically  or they may change dynamically  e.g. due to redundant design  and for software systems like web services.
모in this paper we propose a decentralized supervised approach to diagnosis. we assume that a system is formed by subsystems each one having its local diagnoser  while a supervisor is associated with the overall system  with the aim of coordinating local diagnosers and producing global diagnoses. the approach computes a set of partial diagnoses  de kleer et al.  1  that represents all the consistency-based diagnoses; it is designed to avoid commitment on parts of the model that are unnecessary to explain the observations. in this way local diagnosers are not queried on global hypotheses where their contribution is irrelevant.
모the paper is organized as follows: in the next section we describe the decentralized architecture we propose. section 1 introduces the type of models used for diagnosis and a running example. then  we discuss how the decentralized diagnostic process is carried out in our approach  section 1  and analyze its complexity  section 1 . we finally conclude with a discussion on related work.
1 architecture
we propose a supervised diagnostic architecture where:
  a local diagnoser is associated with each subsystem. the model of the subsystem is private.
  a supervisorof the diagnostic process is associated with the system. it coordinates the work of the diagnosers optimizing their invocations during a diagnostic session. in the definition we consider the general case where:
 i  the supervisor needs no a-priori knowledge about the subsystems and their paths of interaction  they can be reconstructed at run time   and local diagnosers do not necessarily know each other. this ensures that subsystems can be added/removed/replaced independently of each other at any time.
 ii  each local diagnoser must implement a given communication interface with the supervisor  which is reasonable in an assembler-supplier relationship .
 iii  it should be possible to have a hierarchical architecture of supervisors corresponding to a hierarchical decomposition of the system.
모the architecture defines a communication interface between the local diagnosers and the supervisor. they must share a modeling ontology even though this allows each local diagnoser to use its own modeling language and assumptions  provided that it is able to map it over the common one during communications.
모local diagnosers are awakened by the subsystem they are in charge of whenever an anomaly  fault  is detected. they may explain the fault locally or may put the blame on an input received from another subsystem. they communicate to the supervisor their explanations  without disclosing the details of the possible local failure s  . the supervisor may invoke the local diagnoser of the blamed subsystem asking it to generate explanations. the supervisor may also ask a local diagnoser to check some predictions.
1 models
in this section we discuss the modeling ontology used in the interface. first of all  as it is common in model-based diagnosis  we consider component-oriented models  where each componenthas one correct behaviorand possibly one or more faulty behaviors. each behavior of a component is modeled as a relation over a set of variables.
모we consider qualitative models where all variables have a finite  discrete domain  thus representing either a discretization of the corresponding physical quantity  or an abstraction over some of its properties. this implies that the model of a component c is a finite relation including a mode variable c.m  that ranges over the set of behavior modes {ok ab1 ... abn} of the component itself.
모in the example in this paper we will use deviation models  malik and struss  1  where each physical quantity q represented in the model has a corresponding variable 붟q representing a qualitative abstraction of the deviation of q with respect to its expected value; in particular  the sign abstraction {  1 +}  expressing whether q is lower than  equal to  or higher than its expected value.
모in this paper we only deal with atemporal diagnosis  assuming that the models abstract away the temporal information  which is of course restrictive  brusoni et al.  1 .
모as a running example we use a simplified part of an aircraft system  namely the part concerned with the landing gear. figure 1 represents a high-level view of the system in terms of subsystems. the ones pictured with a dashed line do not directly take part in the example  but are shown for the sake of completeness.
모the hydraulic extraction system  hes  creates a pressure that mechanically pushes the landing gear  thereby extracting it. the hes is also connected to some leds on the cockpit  that show whether the subsystem is powered up or not. in order to create the pressure  the hes takes power from two sources. the main source is the power transmission from the aircraft engine  which actually powers up the main pump of the hes. a secondary source  used to transmit the pilot command from the cockpit  and to light up leds  is the independent power supply  which produces a low-amperage dc current.
1 decentralized diagnostic process
in this section we will describe how the diagnostic process is carried out. as we have already mentioned  a supervisor coordinates the activities of several local diagnosers

figure 1: the landing gear section of an aircraft system
{ld1 ... ldn}. in order to obtain a loosely coupled integration  the supervisor assumes that each ldi is stateless  that is  every invocation of a local diagnoser is independent of the others. the interaction is thus defined by:
  an interface that each local diagnoser must implement  discussed in section 1. the role of each local diagnosers consists in generating hypotheses consistent with the model of its subsystem and the corresponding observations.
  an algorithm for the supervisor that computes diagnoses by coordinating the local diagnosers through the above interface  as explained in section 1. the role of the supervisor is to propagate hypotheses to the neighbors of a local diagnoser.
1 the extend interface
we assume that each local diagnoser ldi reasons on a model mi of its subsystem si. from the point of view of the supervisor and its interactions with local diagnosers  each model mi is a relation over a set of variables where:
  mode variables  denoted by si.m  express the behavior mode of components in si;
  input/output variables express values of quantities that si exchanges with other subsystems.
  there may be additional internal  private  variables.
모the interface between the supervisor and the local diagnosers is made of a single operation called extend that the supervisor invokes on the local diagnosers. moreover  upon an abnormal observation  local diagnosers autonomously execute extend and send the results to the supervisor.
모the goal of extend is to explain and/or verify the consistency of observations and/or hypotheses made by other local diagnosers. thus  the input to extend when invoked on ldi is a set of hypotheses on the values of input/output variables of mi. such hypotheses are represented as a set of partial assignments over the variables of interest.
모in the particular case where extend is autonomously executed by a local diagnoser upon receiving an abnormal observation from its subsystem  the set of hypotheses contains only the empty assignment  i.e. the one with empty domain . for each hypothesis 붸 received in input  ldi must first check whether 붸 is consistent with the local diagnostic model mi and the local observations 뷎i. the extension that ldi should perform may be interpreted as follows  in causal terms : backwards  to verify whether the hypothesis needs further assumptions to be supported within mi and 뷎i; forwards  to see whether the hypothesis has consequences on other subsystems  which can be used to discard or confirm it.

figure 1: a closer view to the hydraulic extraction system
모let us consider as an example the hydraulic extension system  figure 1  and suppose the local diagnoser ldhes  associated to the hes  receives in input an assignment that assigns the value     to its output data variable hes.붟e  representing the mechanical extraction of the landing gear. this value means that the landing gear did not extract when expected. ldhes may then see that  with respect to the local model  one of the following must have happened:
  an internal component has failed  for example the pump is stuck or the pipe is leaking.
  one of the two inputs of the pump is wrong  for example the pump is not powered or it has not received the command.
모this means that the partial assignment hes.붟e =   can be extended in four ways: by assigning hes.m = stuck  or hes.m = leaking  or hes.붟v =    or hes.붟c =  .
모what is important regarding extensions is that they should include everything that can be said under a given hypothesis  but nothing that could be said also without it. in other words  we are interested in knowingwhether a given assignmentconstrains other variables more than the model alone does. the following definition captures and formalizes this notion.
definition 1 let mi be a local model with local observations 뷎i  and let 붺 be an assignment. we say that 붺 is admissible with respect to mi and 뷎i if:
i. 붺 is an extension of 뷎i;
ii. 붺 is consistent with mi;
iii. if mi 붺 is the model obtained by constraining mi with 붺  its restriction to variables not assigned in 붺 is equivalent to the restriction of mi itself to the same variables:
mi 붺|var mi  dom 붺  뫖 mi|var mi  dom 붺 .
thus  for each assignment 붸 received in input  the ex-
tend operation of a local diagnoser ldi returns a set of assignments e붸 that contains all minimal admissible extensions of 붸 with respect to mi and 뷎i  restricted to input  output and mode variables of mi. notice that  whenever 붸 is inconsistent with the observations or the model  e붸 is empty.
모minimal admissibility avoids unnecessary commitments on values of variables that are not concretely constrained by the current hypothesis.
모in order to illustrate these definitions  let us consider a  simplified  model mp of the pump p alone. the model includes four variables: p.m represents the behavior mode  p.붟v the power supply to the pump  p.붟c the command that turns on the pump  and p.붟f the flow coming out from the pump. the extensional representation of mp is:
	p.m p.붟c p.붟v p.붟f	p.m p.붟c p.붟v p.붟f
ok11stuck1 ok1++stuck1+1 +  ok1  stuck1  ok+1+stuck+1 +  ok+++stuck++1 +  ok+ 1 +  stuck+ 1 +  ok 1 stuck 1 ok +1 +  stuck +1 +  ok   stuck   모suppose extend is called on mp alone  having in input an assignment 붸 such that dom 붸  = {p.붟f} and 붸 p.붟f  =  . it can be verified that 붸 itself is not admissible  while the minimal admissible extensions of 붸 wrt mp are:
p.m p.붟c p.붟v p.붟f
붺1stuck 붺1  붺1  모붺1  붺1 and 붺1 express the three possible explanations for 붟f =  : either the pump is stuck  or it is not powered  or it did not receive the command. for each of the three assignments  unassigned variables are those whose value is irrelevant to the explanation.
1 the supervisor algorithm
the supervisoris started by a local diagnoserlds that sends to it the results of an extend operation executed as a consequence of an abnormal observation.
모during its computation  the supervisor records the following information:
  a set h of assignments  representing current hypotheses;
  for each assignment 붸 and for each variable x 뫍 dom 붸   a modified bit mdf 붸 x  .
모moreover  we assume that given an input or output variable x that has been mentioned by one of the local diagnosers  the supervisor is able to determine the variable s  conn1 x  ... connk x  connected to it. we do not make any assumption on whether this information is known a priori by the supervisor  or it is retrieved dynamically  or it is provided by the local diagnoser itself.
모the supervisor initializes its data structures with the results of the initial extend operation that has awakened it:
  h contains all the assignments that were sent by lds as the result of extend;
  for each 붸 뫍 h  and for each x 뫍 dom 붸   the supervisor extends 붸 to conn  x  connk x  by assigning 붸 connj x   =. then the supervisor sets mdf 붸 connj x    = 1.
모modified bits are used by the supervisor to understand whether it should invoke a local diagnoser or not  according to the following:
rule r. if a subsystem si has a variable x with mdf 붸 x   = 1 for some 붸  then ldi is a candidate for invocation and 붸 should be passed on to extend.
모after initializing data structures  the supervisor loops over the following four steps:
step 1: select the next ldi to invoke. the supervisor selects one of the local diagnosers ldi for which there is at least one assignment 붸 meeting rule r. if there is none  the loop terminates.
step 1: invoke extend. if ldi has never been invoked before in this diagnostic process  then the input to extend is the set of all assignments in h  restricted to variables of mi. otherwise the input consists only of those assignments 붸 that meet rule r.
step 1: update h. the supervisor receives the output of extend from ldi. for each 붸 in input  extend has returned a  possibly empty  set of extensions e붸 = {붺1 ... 붺k}. then 붸 is replaced in h by the set of assignments {붹1 ... 붹k} where 붹j is obtained by:
  combining 붸 with each 붺j 뫍 e붸;
  extending the result of this combination to connected variables  so that for each x 뫍 dom 붺  representing an input/output variable  붹j conn x   = 붹j x .
this implies that rejected assignments  having no extensions  are removed from h. this step and the following take place in exactly the same way if the extend operation was not invoked by the supervisor  but rather autonomously executed by a local diagnoser upon receiving an alarm. this is treated as an extension of the empty assignment  thus applicable to all 붸 in h.
step 1: update the mdf bits. for each assignment 붹j added in step 1 mdf bits are set as follows:
 i  for each variable x not belonging to mi such that x 뫍 domdom 붸   mdf 붹j x   is set to 1.
 ii  for each variable x belonging to mi such that x 뫍 dom 붹j   mdf 붹j x   is set to 1.
 iii  for any other variable x 뫍 dom 붹j   x 뫍 dom 붸  and mdf 붹j x   = mdf 붸 x  .
모notice that the diagnostic process terminates: new requests for extend are generated only if assignments are properly extended  but assignments cannot be extended indefinitely. we can prove the following:
theorem 1 let m denote the global model  and let 뷎 denote the set of observations obtained during the diagnostic process. at the end of the supervisor loop  the set h of partial assignments has the following properties:
i. each partial assignment 붸 뫍 h is admissible with respect to m and 뷎;
ii. the set of extensions is complete wrt m and 뷎  that is  for each total assignment 붺 consistent with m and 뷎  there exists 붸 뫍 h such that 붺 is an extension of 붸.
모the proof of this theorem relies on the following property of admissible extensions:
proposition 1 let m1 and m1 denote two interacting models  with observables 뷎1 and 뷎1  and let 붸 be a partial assignment over  where  denotes the composition of the two models . if 붸 is admissible both wrt m1 뷎1 and wrt m1 뷎1 then it is admissible wrt.
모we need now to establish a relation between h and consistency-based diagnoses. let us first extract diagnostic information from assignments in h:
definition 1 let 붸 be an assignment in h at the end of the diagnostic process. the diagnostic information 붟 붸  associated with 붸 is its restriction to mode variables.
as a consequence of theorem 1 we have:
proposition 1 the set {붟 붸  | 붸 뫍 h} is a complete set of partial diagnoses  de kleer et al.  1  wrt the model m and observations 뷎  meaning that every total mode assignment completing a 붟 붸  is a consistency-based diagnosis for m and 뷎  and every consistency-baseddiagnosis is a completion of some 붟 붸 .
corollary 1 let d be the set of diagnoses obtained by completing all 붟 붸  with ok assignments. the set of minimal diagnoses in d coincides with the set of minimal consistencybased diagnoses for m and 뷎.
모notice that in the supervisor algorithm the role of mode variables is rather peculiar. since these variables are local to a given system  the supervisor never communicates their value to a local diagnoser different than the one originating them. thus  they are not needed for cross-consistencychecks. there are two main reasons why we need the supervisor to be aware of them:
  they providethe connection between two different invocations on the same local diagnoser; by having the supervisor record them and send them back on subsequent calls  we allow the local diagnosers to be stateless.
  the supervisorneeds them to compute globallyminimal diagnoses.
notice however that  for both of these goals  the values of mode variables need not be explicit: local diagnosers may associate to each fault mode a coded id and use it as a value for mode variables. in this way  information on what has happened inside a subsystem can remain private.
모let us sketch a scenario of execution of the supervisor algorithm for the system in figure 1. suppose that ldlg notices that the landing gear did not extract and blames it on the hydraulic extraction system. then the supervisor asks ldhes for an explanation  and receives back four extensions. in two of them  the hes takes responsibility for the problem  either the pump is stuck or the pipe is leaking . in the other two  it blames respectively the power transmission  input 붟v   and the dc power  input 붟c .
모the local diagnoser of the power transmission is then asked to explain the blame; it has an observation confirming that its input 붟t is ok  thus it can explain it only as an internal failure. then the local diagnoser of the dc power is asked to explain its blame. also the dc power can explain it only as an internal failure  but it also states that this type of error would produce a problem also on its other output 붟x. at this point ldhes is invoked again to verify the consequences of this prediction  and it states that a problem on 붟x would produce a similar problem on 붟y . the local diagnoser of the leds subsystem discards this possibility thanks to its local observations; thus the causes of the failure can only be in the hydraulic extraction system or in the power transmission.
1 hierarchies of supervisors
in this section we discuss the problem of having a multilayered hierarchical structure of diagnosers. as we will see in section 1  this has also a relevant impact on complexity issues.
모let us consider a supervisor s at an intermediate level of the hierarchy  in charge of a portion m of the global model m  with observations 뷎. when s is invoked from a higherlevel supervisor s  its loop starts with data structures initialized as follows:
  h contains all the assignments that s asked to extend;
  for each 붸 뫍 h  and for each x 뫍 dom sets mdf 붸 x   = 1.
모in general  at the end of its loop  s does not compute all minimal admissible extensions of the initial assignments in
. in fact  theorem 1 guarantees that all the returned extensions are admissible  and that for each input assignment a complete set of extensions is returned  but not that such extensions are also minimal.
모it is however possible to give a sufficient condition which guarantees minimality. moreover  this provides a way to estimate the distance that returned extensions have from minimality. intuitively  minimality cannot be guaranteed when the context where a subsystem is operating  i.e.  the other subsystems it is connected to  limits its possible behaviors wrt those described in its model.
모more formally  let us consider a supervisor s with n local diagnosers: the model m is thus partitioned in m1 ... mn each owned by a different ldi. let m|var mi  denote the projection of m over variables in mi. if  for every i = 1 ... n  mi 뫖 m|var mi   then the supervisor actually computes minimal admissible extensions. the more mi is larger than m|var mi   the farther the returned extensions may be from minimality.
the operation computed by a supervisor s with model
m and observations 뷎 is then  in the general case  a re-
laxedextend that  for each input assignment 붸  returns a complete set of admissible extensions of 붸 wrt m and 뷎.
모replacing extend with relaxedextend has no effect on the correctness of the algorithm  since theorem 1 does not exploit the assumption that the extensions returned by local diagnosers are minimal:
proposition 1 if all local diagnosers involved in a diagnostic process implement the relaxedextend operation  then the supervisor coordinating them implements relaxedextend as well.
모thus  a multi-layered hierarchy of supervisors is possible  although choosing to treat a subsystem with multiple local diagnosers  rather than as a whole  can result in non-minimal admissible extensions.
모not having minimal extensions has impact on at least three aspects of the diagnostic process. first  the contents of the exchanged messages and of the hypotheses set h may be larger. second  some local diagnoser could be invoked even if the information it can provide is irrelevant to the diagnostic process. third  as we will see in the next section  relaxedextend has a lower complexity than extend. this trade-off must be taken into account when selecting a diagnostic architecture.
1 complexity
in this section we discuss the complexity of the proposed algorithm. diagnosis is np-complete  therefore we cannot expect anything better.
모in our approach  the core of the diagnostic process is the supervisor loop. this task can is composed by two activities: invocations of local diagnosers and merging of the results. the latter depends on the size of the results themselves; we need however to recall that the supervisor builds a set of partial assignments  which in the worst case is exponential in the number of variables k. thus the merging activity is in the worst case exponential in k. as to local diagnoser invocations  each of them is invoked at most once for each interface variable in its model. if we denote by ki the number of variables in model mi  and by k i 뫞 ki the number of interface variables in mi  then we can express the complexity of the supervisor as:
o ek + o k icld ki  
where cld ki  denotes the complexity of a local diagnoser invocation over a model with ki variables.
모let us now consider the extend operation performed by local diagnosers. given a model m  and an input assignment 붸  the task of finding an admissible extension for 붸 in m is essentially a satisfiability problem: it suffices to find a total assignment satisfying m붸. thus  this task is exponential in the number of involved variables.
모unfortunately  finding minimal admissible extensions is harder: it is np-hard  and belongs to npnp  although it does not appear to be complete for this class .
모however  analyzing the complexity expression above  we see that  if the model can be split in subsystems with an upper bound on the number of variables in each of them  then ki can be treated as a constant  and the complexity of the overall algorithm goes back to o ek .
모in component-oriented systems and models this decomposition is straightforward: components are usually reasonably sized  and the complexity of systems depends on the number of components rather than on the complexity of individual components. this suggests that the best way to tackle the complexity of extend is to increase the number of local diagnosers and decrease the size of models in their care. in this case  the multi-layered architecture in section 1 can be profitable. in particular  if the split models can be obtained by projecting the global model  as it is the case when the split is due to efficiency reasons and not to subsystem privacy   there is no loss in the quality of the results  while the complexity of the algorithm is lower.
1 conclusions
in this paper we discuss a supervised decentralized approach to diagnosis that allows to loosely couplemultiple diagnosers  in order to deal with systems consisting of several subsystems  whose models cannot be composed.
모the goal of the paper is to show that we can effectively perform the diagnostic task and define intelligent strategies for the supervisor  even if it is not aware of the internal aspects of local diagnosers  the local diagnosers do not know each other  and their paths of interaction dynamically change.
모the approach proposed in this paper builds on  ardissono et al.  1   which deals with diagnosis of web services. in particular  the definition of the extend interface is borrowed from  ardissono et al.  1   while the supervisor algorithm is generalized in order to loosen the assumptions while not losing diagnostic coverage. moreover  the properties of this algorithm are proved and its complexity analyzed.
모the proposed framework was presented for atemporal models  where dynamic features are either absent  or have been abstracted away. the extension to temporal issues in diagnosis  brusoni et al.  1  is subject for future work. dynamic models  possibly including feedback loops  should be dealt with  as well as using temporal information on observations for discrimination  with the additional problem of possible communication delays among diagnosers .
모the approach in  pencole뫣 and cordier  1  has some relevant similarity with that of this paper  from the point of view of diagnostic architecture: a supervisor is in charge of computing global diagnoses exploiting the work of several local diagnosers. however  this work focuses on quite different theoretical and practical problems:
  the system to diagnose is modeled as a discrete-event system;
  the main problem is to avoid composing the whole model  because this would produce a state-space explosion;
  as a consequence  the supervisor is aware of the subsystem models  but cannot compose them: it can only compose local diagnoses to obtain a global one;
  due to the nature of the considered systems  reconstructing global diagnoses is a difficult task  and as such it is one of the main focuses of the paper.
모other papers in the literature deal with completely distributed approaches to diagnosis  where diagnosers communicate with each other and try to reach an agreement  without a supervisor coordinating them. our choice of a supervised approach was motivated by the need of having loosely coupled diagnosers  while a purely distributed approach requires diagnosers to establish diagnostic sessions and exchange a greater amount of information in order to compute diagnoses that are consistent with each other.
모nevertheless  the distributed approach proposed in  roos et al.  1  has some similarity with ours because it is based on the idea of diagnosers explaining blames received from others  or verifying hypotheses made by others. needless to say  the proposed algorithms are completely different  having to deal with a distributed approach. moreover  in order to reduce computational complexity  the authors introduce some fairly restrictive assumptions on the models  e.g. requiring that explanations imply normal observations  or that output values are either completely undetermined or completely determined .
모finally   provan  1  deals with a scenario similar to ours: each diagnoser has a local model and observations  which are not shared with the others. each local diagnoser computes local minimal diagnoses  and then engages in a conversation to reach a globally sound diagnosis. however  being the approach purely distributed  solutions are different. in particular  in order to propose a solution with reduced complexity  the author focuses on systems whose connection graph has a tree-like structure. on the contrary  our approach  thanks to the presence of the supervisor  does not need to make any assumption on system structure.
