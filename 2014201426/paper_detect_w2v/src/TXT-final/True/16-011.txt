 
　　　this paper discusses some of our research into detecting and reconciling c r i t i c a l differences between a user's view of the world and the system's. we feel there is benefit to be gained by separating misconceptions into two main classes: misconce.pt ions about what is the case and misconceptions about what can be the case. we review some i n i t i a l work in both areas and discuss our work in progress. 
1 	introduction 
　　　for the past several years  we have been engaged in research aimed at extending the scope of natural language  nl  interaction with database systems beyond that of factual requests  webber1   one important sub-area is that of detecting and reconciling critical differences between the user's and the system's views of the world. if not done  the result may be that the user is confused  or worse  misled by the information the system is trying to convey. 
　　　our goal is to identify the information a system must have and use in order to detect and rectify various belief disparities  in the context of natural language database  db  question-answering. in this paper we review some earlier work which we now see as user misconceptions about what is the case in the database  as well as discussing more recent work on user misconceptions about what can be the case. 
1 	misconceptions about what is the case 
　　　a user can hold many di fferent kinds of incorrect beliefs about what is the case in the world. one type that has received i n i t i a l computational attention towards its detection and correction consists of misconceptions that something exists which is describable by a particular description. if that description doesn't in fact describe anything  any question concerning additional properties true of such a thing is misguided  based as it is on a 
　　　misconception. for example  consider the question 
1. which 	female 	employees 	work 	in 	the 	shoe department  
for a person to want to know the answer to this question  s/he must believe that there are some employees  that there are some female employees  and that there is a shoe department. any one of these beliefs may be inconsistent with what is known to the system s/he is asking the question of. recognizing and correcting such misconceptions was the aim of the co-op system  kaplan1 . 
　　　the problem with not doing this in responding to 	a 	user's question is the false inferences the user may otherwise draw from the answer. 	if 	the system 	answers 	 none  to the above question  the user may conclude that a l l female 	employees 	work in some other department  that the shoe department 
discriminates against female employees  etc.  even though the answer may actually follow from there being no female employees or no shoe department 
i . e .   from one of his/her   i s   beliefs being wrong. 
　　　now the type of  is -misconception that co-op handles is only one of several that a user might have. for example  s/he may believe that an object has a particular attribute when it just doesn't  example 1  or that one thing depends on another when it doesn't  example 1  -
1. u: what's the maximum age for opening 	a 	keogh account  
s: there is no maximum age: you can open one as long as you have income from self-employraent. 
1. u: what are profit margins as a percentage of sales for each installation  
s: margins don't depend on sales. they are calculated as the difference between unit product cost and l i s t price. 
such misconceptions about objects and the relationships among them is the subject of a new research effort reported on in  mccoy1 . 
1 misconceptions about what can be the case 
　　　in addition to misconceptions about what is actually the case in the world  a user might have misconceptions about what can be the case. there are at least two types of such misconceptions. the f i r s t   given a database of entities and relations  is that some entity or subset of 

entities can participate in a particular relation. as with type constraints and type violations in programming languages  this may not be the case because the entity is the wrong type. i n i t i a l work in this area is reported in  mays 1 . the knowledge needed to recognize such type failures in users' queries consists of entity-relation information  hierarchical  subset-superset  information  as well as partition information as to what subsets of a given set are mutually exclusive. it is the last factor that is critical for distinguishing between a non-deviant request 
like 
which women teach courses  
and a deviant one like 
which undergraduates teach courses  
where the  teach  relation holds between  faculty  and  courses   figure 1 . as figure 1 shows  the entity  people  has two different partitions one between  men  and  women   the other between  faculty  and  student . assuming a relation is always asserted at the most general point in the hierarchy  the configuration means that only faculty can be the first argument to teach  and only courses  the second. since  faculty  and  student  have an empty intersection and  undergraduates  is a subset of  student   the implication is that  teach  cannot hold between  undergraduate  and  course . the same is not true of  women   as  women  and  faculty  can have a non-empty intersection. 
　　　mays' system detects such misconceptions in the course of transforming a parse structure into a database query. at that point it verifies that the given arguments satisfy the constraints specified in the data model. one problem with this method is that it cannot correctly detect 
misconceptions in negative questions like  1 . 
1. which faculty do not teach courses  
1. which courses are not taught by faculty  
the simple check of relation/argument constraints would find both questions acceptable  and both would be translated  including negation  into database queries. yet  1  actually reveals the user's misconception that courses can be taught by people other than faculty.  example  1  reveals no such misconception: faculty do not have to teach courses.  
　　　negation has often been a source of problems for question-answering systems  but in a cleaned-up version of mays' system  we hope to be able to deal correctly with detecting 
misconceptions in negative questions  as well as in positive ones. 
　　　the second type of  can be  misconception involves violating another type of constraint constraints between events and states and their relationship over time. it is possible for a user to be mistaken about what can be true now or what could have been true  or happened  in the past  
b. webber and e. mays 1 
 1  because s/he is unaware of the occurrence  or non-occurrence  of some event or of its consequences or  1  because s/he believes some event has occured when it hasn't. again  if the user's question reveals such a misconception  it should be corrected lest the user draw a false conclusion from the system's answer. the kind of behavior we are aiming for is as follows: 
1. u: is john registered for cse1  
s: no. he can't be registered for it because he has already advance placed i t . 
1. u: is john registered for cse1  
s: no. he can't be registered for it because he hasn't yet taken cse1. 
　　　the knowledge needed to recognize and square away such misconceptions consists of a knowledge of past events  or states of the dbs  - often preserved in back-up files but not accessible to the db system - and of the relationship between past events and what can be true afterwards  including possibly the present. the latter is very much like update constraints used to maintain db consistency. however  in general update constraints are not expressed in a form that admits reasoning about possible change. something more is needed. what we have chosen to use instead is an extension of the propositional branching time temporal logic  benari   as documented in  mays1 mays1. 
　　　our original impetus into this area was a desire to give a db system the ability to take the initiative and offer to monitor for information of which it was currently unaware. for example  
1. u: has john checked in yet  
s: no - shall i let you know when he has  
1. u: has john checked in yet  
s: yes - shall i let you know when the rest of the committee members do  
work on producing monitor offers that are both competent   i . e .   that correspond to a possible future state of the database  and relevant   i . e .   that the user would be interested in  is proceeding concurrently with the work reported on here. we have termed systems which can reason about possible future states of the db  dynamic database systems . 
　　　we do not have the space here to explain in detail the logical system we are using  but see  mays1  . in brief  the system treats the past as a linear sequence of time points up to and including a reference point that  for simplicity  we can call now. the future is treated as a branching structure of time points that go out from  and include  the reference point. a set of complex operators is available to quantify propositions as to the points they are asserted to hold over - e.g.  
agq - proposition q holds at every time of every future 
exq - proposition q holds at the next point in 

1 b. webber and e. mays 
some future 
	pq - proposition q holds at some time 	in 	the 
past etc. 
two classes of axioms describe the relationship between events/states in the past  present and future. the f i r s t class contains logical axiom schemas that apply to temporal assertions in general - e.g.  if prior to now  pq was true 
  i . e .   lpq   then pq is s t i l l true now   i . e .   lpq -  pq . there are also  specialization  axioms relating general and more specific operators -
e.g.  if for a l l times in every future q w i l l be true   i . e .   agq  then  more specifically  q w i l l be true at the next time in every future   i . e .   agq -  axq . 
　　　the second class of axioms are non-logical axioms that describe relationships that hold in the particular domain. here we have taken a university domain of students and courses. let the propositional letter 'a' stand for 'student advance places course' and ' r '   for 'student is registered for course'. then the following non-logical axiom states that a student who has advance placed a course  some time in the past  is not now registered for i t : h ag pa -  ~ r     .  most non-logical axioms are taken to have held and to continue to hold forever. hence the complex operator hag around the implication.  
　　　our problem  given the two registration examples above  1 and 1  to distinguish whether it is accidental that john is not registered for cse1 now  he could be  only he's not  or foreordained  some event has taken place that 
precludes registering or some enabling event has not yet occured  requires the system to suppress its knowledge of john's current status and consider whether it could provably believe the opposite - i . e .   that john is registered now for cse1. if it couldn't  then not only is john not registered for cse1  the system should have identified at least one basis for why he couldn't be. by the above axiom  it is clear that it is not accidental that john isn't registered  because r  being registered for cse1  is inconsistent 
with 	pa 	 having 	advance 	placed 	gse1  
pa -  ~r. this is the knowledge and reasoning on which we are basing the recognition of such  could be  misconceptions. 
1 	conclusion 
we have discussed recent work on detecting and correcting two main classes of use r misconceptions misconceptions about what is the case and 
misconceptions about what could be the case  there is other research which is s trongly relevant to this  in particular recent wo rk by mercer and reiter on using default logic to represent the potential presuppositions of certa in lexical items and syntactic constructions  merce r1 . this is an area of great importance for interactive systems because of the c r i t i c a l consequences of user confusion and misundersta nding. we are continuing our efforts on it and encourage others to do so as well. 
