
successful negotiators look beyond a purely utilitarian view. we propose a new agent architecture that integrates the utilitarian  information  and semantic views allowing the definition of strategies that take these three dimensions into account. information-based agency values the information in dialogues in the context of a communication language based on a structured ontology and on the notion of commitment. this abstraction unifies measures such as trust  reputation  and reliability in a single framework.
1 introduction
in this paper we introduce an agency framework grounded on information-based concepts  mackay  1 . it presents an agent architecture that admits a game-theoretical reading and an information-theoretical reading. and  what is more interesting  permits a connection between these two worlds by considering negotiation as both cooperative  in the sense that all interaction involves the exchange of information  and competitive  in the sense that agents aim at getting the best they can. this approach contrasts with previous work on the design of negotiation strategies that did not take information exchange into account  but focused on the similarity of offers  jennings et al.  1; faratin et al.  1   game theory  rosenschein and zlotkin  1   or first-order logic  kraus  1 .
	we	assume	that	a	multiagent	system
{¦Á ¦Â1 ... ¦Âo ¦Î ¦È1 ... ¦Èt}  contains an agent ¦Á that interacts with negotiating agents  ¦Âi  information providing agents  ¦Èj  and an institutional agent  ¦Î  that represents the institution where we assume the interactions happen  arcos et al.  1 . institutions give a normative context to interactions that simplify matters  e.g an agent can't make an offer  have it accepted  and then renege on it . we will describe a communication language c based on an ontology that will permit us both to structure the dialogues and to structure the processing of the information gathered by agents. agents have an internal language l used to build a probabilistic world model.
¡¡we understand agents as being built on top of two basic functionalities. first  a proactive machinery  that transforms needs into goals and these into plans composed of actions. second  a reactive machinery  that uses the received messages to obtain a new world model by updating the probability distributions in it. agents summarise their world models using a number of measures  e.g. trust  reputation  and reliability  sierra and debenham  1   that can then be used to define strategies for  exchanging information  - in the sense developed here  this is the only thing that an agent can do.
¡¡we introduce the communication language in section 1  the agent architecture in section 1  some summary measures based on the architecture in section 1  and some associated interaction strategies in section 1.
1 the multiagent system
our agent ¦Á has two languages: c is an illocutionary-based language for communication  and l is a language for internal representation. c is described following  and l in section 1.
1 communication language c
the shape of the language that ¦Á uses to represent the information received and the content of its dialogues depends on two fundamental notions. first  when agents interact within an overarching institution they explicitly or implicitly accept the norms that will constrain their behaviour  and accept the established sanctions and penalties whenever norms are violated. second  the dialogues in which ¦Á engages are built around two fundamental actions:  i  passing information  and  ii  exchanging proposals and contracts. a contract ¦Ä =  a b  between agents ¦Á and ¦Â is a pair where a and b represent the activities that agents ¦Á and ¦Â are respectively responsible for. contracts signed by agents and information passed by agents  are similar to norms in the sense that they oblige agents to behave in a particular way  so as to satisfy the conditions of the contract  or to make the world consistent with the information passed. contracts and information can then be thought of as normative statements that restrict an agent's behaviour.
¡¡norms  contracts  and information have an obvious temporal dimension. thus  an agent has to abide by a norm while it is inside an institution  a contract has a validity period  and a piece of information is true only during an interval in time. the set of norms affecting the behaviour of an agent define the context that the agent has to take into account.
¡¡the communication language that ¦Á needs requires two fundamental primitives: commit ¦Á ¦Â    to represent  in    what is the world ¦Á aims at bringing about and that ¦Â has the right to verify  complain about or claim compensation for any deviations from  and done a  to represent the event that a certain action a1 has taken place. in this way  norms  contracts  and information chunks will be represented as instances of commit ¡¤  where ¦Á and ¦Â can be individual agents or institutions  c is: a ::= illoc ¦Á ¦Â   t  | a;a | let context inaend   ::= term | done a  | commit ¦Á    |   ¡Ä   |   ¡Å   |    |  v. v |  v. v
context ::=   | id =   | prolog clause | context;context
where  v is a formula with free variable v  illoc is any appropriate set of illocutionary particles  ';' means sequencing  and context represents either previous agreements  previous illocutions  or code that aligns the ontological differences between the speakers needed to interpret an action a.
¡¡for example  we can represent the following offer:  if you spend a total of more than e1 in my shop during october then i will give you a 1% discount on all goods in november   as:
offer  ¦Á  ¦Â spent ¦Â  ¦Á  october  x  ¡Ä x ¡Ý e1 ¡ú
  y. done inform ¦Î  ¦Á  pay ¦Â  ¦Á  y   november   ¡ú commit ¦Á  ¦Â  discount y 1%   
note the use of the institution agent ¦Î to report the payment.
¡¡in order to define the language introduced above that structures agent dialogues we need an ontology that includes a  minimum  repertoire of elements: a set of concepts  e.g. quantity  quality  material  organised in a is-a hierarchy  e.g. platypus is a mammal  australian-dollar is a currency   and a set of relations over these concepts  e.g. price beer aud  .1 we model ontologies following an algebraic approach  kalfoglou and schorlemmer  1  as:
¡¡an ontology is a tuple o =  c r ¡Ü ¦Ò  where c is a finite set of concept symbols  including basic data types   r is a finite set of relation symbols  ¡Ü is a reflexive  transitive and anti-symmetric relation on c  a partial order   and ¦Ò : r ¡ú c+ is the function assigning to each relation symbol its arity. ¡Ü is a traditional is-a hierarchy  and r contains relations between the concepts in the hierarchy.
¡¡the concepts within an ontology are closer  semantically speaking  depending on how far away are they in the structure defined by the ¡Ü relation. semantic distance plays a fundamental role in strategies for information-based agency. how signed contracts  commit ¡¤  about objects in a particular semantic region  and their execution done ¡¤   affect our decision making process about signing future contracts on nearby semantic regions is crucial to model the common sense that human beings apply in managing trading relationships. a measure  li et al.  1  bases the semantic similarity between two concepts on the path length induced by ¡Ü  more distance in the ¡Ü graph means less semantic similarity   and the depth of the subsumer concept  common ancestor  in the shortest path between the two concepts  the deeper in the hierarchy  the closer the meaning of the concepts . semantic similarity could then be defined as:
                           h sim 
where l is the length  i.e. number of hops  of the shortest path between the concepts  h is the depth of the deepest concept subsuming both concepts  and ¦Ê1 and ¦Ê1 are parameters scaling the contribution of shortest path length and depth respectively.
¡¡given a formula   ¡Ê c in the communication language we define the vocabulary or ontological context of the formula  o     as the set of concepts in the ontology used in it. thus  we extend the previous definition of similarity to sets of concepts in the following way:
	sim   ¦×  =	max	min {sim ci cj }
ci¡Êo    cj¡Êo ¦× 
the following does not depend on this particular definition.
1 agent architecture
agent ¦Á receives all messages expressed in c in an in-box x where they are time-stamped and sourced-stamped. a message ¦Ì from agent ¦Â  or ¦È or ¦Î  is then moved from x to a percept repository yt where it is appended with a subjective belief function rt ¦Á ¦Â ¦Ì  that normally decays with time. ¦Á acts in response to a message that expresses a need. a need may be exogenous such as a need to trade profitably and may be triggered by another agent offering to trade  or endogenous such as ¦Á deciding that it owns more wine than it requires. needs trigger ¦Á's goal/plan proactive reasoning described in section 1  other messages are dealt with by ¦Á's reactive reasoning described in section 1.
1 proactive reasoning
¦Á's goal/plan machinery operates in a climate of changing uncertainty and so typically will pursue multiple sub-goals concurrently. this applies both to negotiations with a potential trading partner  and to interaction with information sources that either may be unreliable or may take an unpredictable time to respond. each plan contains constructors for a world model mt that consists of probability distributions   xi   in first-order probabilistic logic l. mt is then maintained from percepts received using update functions that transform percepts into constraints on mt - described in section 1.
¡¡the distributions in mt are determined by ¦Á's plans that are determined by its needs. if ¦Á is negotiating some contract ¦Ä in satisfaction of need ¦Ö then it may require the distribution pt eval ¦Á ¦Â ¦Ö ¦Ä  = ei  where for a particular ¦Ä  eval ¦Á ¦Â ¦Ö ¦Ä  is an evaluation over some complete and disjoint evaluation space e =  e1 ... en  that may contain hard  possibly utilitarian  values  or fuzzy values such as  reject  and  accept . this distribution assists ¦Á's strategies to decide whether to accept a proposed contract leading to a probability of acceptance pt acc ¦Á ¦Â ¦Ö ¦Ä  . for example  pt eval ¦Á ¦Â ¦Ö ¦Ä  = ei  could be derived from the subjective estimate pt satisfy ¦Á ¦Â ¦Ö ¦Ä  = fj  of the expected extent to which the execution of ¦Ä by ¦Â will satisfy ¦Ö  and an objective estimate pt val ¦Á ¦Â ¦Ä  = gk  of the expected valuation of the execution of ¦Ä possibly in utilitarian terms. this second estimate could be derived by proactive reference to the {¦Èi} for market data. in a negotiation ¦Á's plans may also construct the distribution pt acc ¦Â ¦Á ¦Ä   that estimates the probability that ¦Â would accept ¦Ä - we show in section 1 how ¦Á may derive this estimate from the information in ¦Â's proposals.
¡¡¦Á's plans may construct various other distributions such as: pt trade ¦Á ¦Â o  = ei  that ¦Â is a good person to sign contracts with in context o  and pt confide ¦Á ¦Â o  = fj  that ¦Á can trust ¦Â with confidential information in context o.
¡¡the integrity of percepts decreases in time. ¦Á may have background knowledge concerning the expected integrity of a percept as t ¡ú ¡Þ. such background knowledge is represented as a decay limit distribution. if the background knowledge is incomplete then one possibility is for ¦Á to assume that the decay limit distribution has maximum entropy whilst being consistent with the data. given a distribution  p xi   and a decay limit distribution d xi   p xi  decays by:
           pt+1 xi  = ¦¤i d xi  pt xi    1  where ¦¤i is the decay function for the xi satisfying the property thatbe linear:limt¡ú¡Þ pt xi  =  d¡Á xdi  . for example xi +¦Íi¡Ápt x¦¤i   wherei could
	pt+1 xi  =  1	¦Íi 
¦Íi   1 is the decay rate for the i'th distribution. either the decay function or the decay limit distribution could also be a function of time: ¦¤ti and dt xi .
1 reactive reasoning
in the absence of in-coming messages the integrity of mt decays by eqn. 1. the following procedure updates mt for all percepts expressed in c. suppose that ¦Á receives a message ¦Ì from agent ¦Â at time t. suppose that this message states that something is so with probability z  and suppose that ¦Á attaches an epistemic belief rt ¦Á ¦Â ¦Ì  to ¦Ì - this probability reflects ¦Á's level of personal caution. each of ¦Á's active plans  s  contains constructors for a set of distributions {xi} ¡Ê mt itogether with associated update functions  js ¡¤   such that jsx  ¦Ì  is a set of linear constraints on the posterior distribution for xi. examples of these update functions are given in section 1. denote the prior distribution pt xi  by p   and let be the distribution with minimum relative entropy1 with respect to = argmin that

1
¡¡¡¡given a probability distribution q  the minimum relative entropy distribution subject to a set of j linear constraints
the constraint .
this may be calculated by introducing lagrange multipliers ¦Ë:  . minimising
1} j = 1 ... j is the set of given constraints g  and a solution to  leads eventually to p. entropy-based infer-
ence is a form of bayesian inference that is convenient when the data is sparse  cheeseman and stutz  1  and encapsulates commonsense reasoning  paris  1 .
satisfies the constraints jsxi ¦Ì . then let be the distribution:

and then let:
 is more interesting than
otherwise
a general measure of whether is more interesting than
  where 
 is the kullback-leibler distance between two
probability distributions.
¡¡finally merging eqn. 1 and eqn. 1 we obtain the method for updating a distribution xi on receipt of a message ¦Ì:
	pt+1 xi  = ¦¤i d xi  pt xi ¦Ì   	 1 
this procedure deals with integrity decay  and with two probabilities: first  the probability z in the percept ¦Ì  and second the belief rt ¦Á ¦Â ¦Ì  that ¦Á attached to ¦Ì.
¡¡in a simple multi-issue contract negotiation ¦Á may estimate pt acc ¦Â ¦Á ¦Ä    the probability that ¦Â would accept ¦Ä  by observing ¦Â's responses. using shorthand notation  if ¦Â sends the message offer ¦Ä1  then ¦Á may derive the constraint: jacc ¦Â ¦Á ¦Ä  offer ¦Ä1   = {pt acc ¦Â ¦Á ¦Ä1   = 1}  and if this is a counter offer to a former offer of ¦Á's  ¦Ä1  then: jacc ¦Â ¦Á ¦Ä  offer ¦Ä1   = {pt acc ¦Â ¦Á ¦Ä1   = 1}. in the not-atypical special case of multi-issue bargaining where the agents' preferences over the individual issues only are known and are complementary to each other's  maximum entropy reasoning can be applied to estimate the probability that any multi-issue ¦Ä will be acceptable to ¦Â by enumerating the possible worlds that represent ¦Â's  limit of acceptability   debenham  1 .
1 reliability
rt ¦Á ¦Â ¦Ì  is an epistemic probability that takes account of ¦Á's personal caution. an empirical estimate of rt ¦Á ¦Â ¦Ì  may be obtained by measuring the 'difference' between commitment and enactment. suppose that ¦Ì is received from agent ¦Â at time u and is verified byat some later time t.
denote the prior be the posterior minimum relative entropy distribution subject to the constraints
  and let be that distribution subject to. we now estimate what ru ¦Á ¦Â ¦Ì  should have been in the light of knowing now  at time t  that ¦Ì should have been ¦Ì.
¡¡the idea of eqn. 1  is that rt ¦Á ¦Â ¦Ì  should be such that  on average across - no matter whether or not ¦Ì was used to update the distribution for xi  as determined by the condition in eqn. 1 at time u. the observed reliability for ¦Ì and distribution  on the basis of the verification of ¦Ì with ¦Ì  is the value of k that minimises the kullback-leibler distance:
= argmin
the predicted information in the enactment of ¦Ì with respect to xi is:
		 1 
that is the reduction in uncertainty in xi where h ¡¤  is shannon entropy. eqn. 1 takes account of the value of rt ¦Á ¦Â ¦Ì .
¡¡if x ¦Ì  is the set of distributions that ¦Ì affects  then the observed reliability of ¦Â on the basis of the verification of with ¦Ì is:

if x ¦Ì  are independent the predicted information in ¦Ì is:
		 1 
suppose ¦Á sends message ¦Ì to ¦Â where ¦Ì is ¦Á's private information  then assuming that ¦Â's reasoning apparatus mirrors ¦Á's  ¦Á can estimate it ¦Â ¦Á ¦Ì .
¡¡for each formula   at time t when ¦Ì has been verified with ¦Ì  the observed reliability that ¦Á has for agent ¦Â in   is:
	rt+1 ¦Á ¦Â    = 1	¦Í  ¡Á rt ¦Á ¦Â   +
sim   ¦Ì 
where sim measures the semantic distance between two sections of the ontology as introduced in section 1  and ¦Í is the learning rate. over time  ¦Á notes the context of the various ¦Ì received from ¦Â  and over the various contexts calculates the relative frequency  pt ¦Ì . this leads to an overall expectation of the reliability that agent ¦Á has for agent ¦Â:

1 commitment and enactment
the interaction between agents ¦Á and ¦Â will involve ¦Â making contractual commitments and  perhaps implicitly  committing to the truth of information exchanged. no matter what these commitments are  ¦Á will be interested in any variation between ¦Â's commitment     and what is actually observed  as advised by the institution agent ¦Î   as the enactment   . we denote the relationship between commitment and enactment  pt observe commit     simply as.
¡¡in the absence of in-coming messages the conditional probabilities    should tend to ignorance as represented by the decay limit distribution and eqn. 1. we now show how eqn. 1 may be used to revise as observations are made. let the set of possible enactments be ¦µ =
{ 1  1 ...  m} with prior distribution
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡is received  we estimate the posterior p ¦Ì  =  p ¦Ì i i=1 =      .
¡¡first  if ¦Ì =   k    is observed then ¦Á may use this observation to estimate p  k k as some value d at time t + 1. we estimate the distribution by applying the principle of minimum relative entropy as in eqn. 1 with prior p   and the posterior satisfying the single constraint: .
¡¡second  we consider the effect that the enactment of another commitment ¦Õ  also by agent ¦Â  has on p. this is achieved in two ways  first by appealing to the structure of the ontology using the sim ¡¤  function  and second by introducing a valuation function.
the sim ¡¤  method.	given the observation 
define the vector  t by
sim 
for i = 1 ... m. t is not a probability distribution. the multiplying factor sim  limits the variation of probability to those formulae whose ontological context is not too far away from the observation. the posterior is defined to be the normalisation of
the valuation method. ¦Á may wish to value   in some sense. this value will depend on the future use that ¦Á makes of it. so ¦Á estimates the value of   using a probability distribution  p1 ... pn  over some evaluation space e =  e1 ... en . pi = wi    is the probability that ei is the correct evaluation of the enactment is the evaluation function.
¡¡for a given  k   pt  1| k   ... pt  m| k   is the prior distribution of ¦Á's estimate of what will be observed if ¦Â committed to  k  and's evaluation over e of ¦Â's commitment  k. ¦Á's expected eval-
 has committed to  k
is
for i = 1 ... n. now suppose that ¦Á observes the enactment ¦Õ of another commitment ¦Õ also by agent ¦Â. eg: ¦Á may buy wine and cheese from the same supplier. ¦Á may wish to revise the prior estimate of the expected valuation in the light of the observation  to:
for some function  g - the idea being  for example  that if the commitment  ¦Õ  a contract for cheese was not kept then ¦Á's expectation that the commitment     a contract for wine will not be kept should increase. we estimate the posterior by applying the principle of minimum relative entropy as in eqn. 1 with prior satisfying the n constraints:

j=1 n
this is a set of n linear equations in m unknowns  and so the calculation of the minimum relative entropy distribution may be impossible if n   m. in this case  we take only the m equations for which the change from the prior to the posterior value is greatest. that is  we attempt to select the most significant factors.
1 summary measures
the measures here generalise what are commonly called trust  reliability and reputation measures into a single computational framework. it they are applied to the execution of contracts they become trust measures  to the validation of information they become reliability measures  and to socially transmitted behaviour they become reputation measures.
ideal enactments. consider a distribution of enactments that represent ¦Á's  ideal  in the sense that it is the best that ¦Á could reasonably expect to happen. this distribution will be a function of ¦Á's context with ¦Â denoted by e  and is
. here we measure the relative entropy between this ideal distribution   and the distribution of expected enactments . that is:

where the  1  is an arbitrarily chosen constant being the maximum value that this measure may have. this equation measures one  single commitment  . it makes sense to aggregate these values over a class of commitments  say over those   that are in the context o  that is   ¡Ü o:

where pt¦Â    is a probability distribution over the space of commitments that the next commitment ¦Â will make to ¦Á is  . similarly  for an overall estimate of ¦Â's reputation to ¦Á:

preferred enactments. the previous measure requires that an ideal distribution   has to be specified for each  . here we measure the extent to which the enactment   is preferable to the commitment  . given a predicate prefer c1 c1 e  meaning that ¦Á prefers c1 to c1 in environment e. an evaluation of pt prefer c1 c1 e   may be defined using sim ¡¤  and the evaluation function- but we do not detail it here. then if   ¡Ü o:
 prefer 
and:

certainty in enactment. here we measure the consistency in expected acceptable enactment of commitments  or  the lack of expected uncertainty in those possible enactments that are better than the commitment as specified . if   ¡Ü
let:  prefer for some constant ¦Ê  and:

where is the normalisation of
¦µ+   o ¦Ê  
b  = = 1
 as above we aggregate this measure for those commitments in a particular context o  and measure reputation as before. computational note. the various measures given above involve extensive calculations. for example  eqn. 1 contains  that sums over all possible enactments  . we obtain a more computationally friendly measure by appealling to the structure of the ontology described in section 1  and the right-hand side of eqn. 1 may be approximated to:

 where is the normalisation of for sim   and similarly for . the extent of this calculation is controlled by the parameter ¦Ç. an even tighter restriction may be obtained with: sim   for some ¦×.
1 strategies
an approach to issue-tradeoffs is described in  faratin et al.  1 . that strategy attempts to make an acceptable offer by  walking round  the iso-curve of ¦Á's previous offer  that has  say  an acceptability of c  towards ¦Â's subsequent counter offer. in terms of the machinery described here: argmax{ pt acc ¦Â ¦Á ¦Ä   | pt acc ¦Á ¦Â ¦Ö ¦Ä   ¡Ö c }  1  ¦Ä
in multi-issue negotiation the number of potential contracts that satisfy  or nearly satisfy  a utilitarian strategy such as this will be large - there is considerable scope for refining the choice of response.
¡¡everything that an agent communicates gives away information. so even for purely self-interested agents interaction is a semi-cooperative process. ¦Á's machinery includes measures of expected information gain in messages either sent to  or received from  ¦Â. for example  ¦Á can refine a strategy such as eqn. 1 by replying to a message ¦Ì from ¦Â with ¦Ì that attempts to give ¦Â equitable information gain:
.	this refinement aims to be
fair in sharing ¦Á's private information. unlike the quasiutilitarian measures  both the measure of information gain and the semantic measure  see below  apply to all messages.
   the structure of the ontology is provided by the sim ¡¤  function. given two contracts  containing concepts  respectively  the  nonsymmetric  distance ofis the vector :  where 
   = sup argmin and the function is the supremum of two concepts in the ontology.  quantifies how different and enables ¦Á to  work around  or  move away from  a contract under consideration.
¡¡more generally  suppose that ¦Á has selected a plan s that is attempting to select the 'best' action in some sense. then s will construct a distribution d =  di  ¡Ê mt where di is the probability that zi is the best action that ¦Á can take  and {z1 ... zr} are the available actions. s reduces h d  to an acceptable level before committing itself to act - here ¦Á is an uncertainty minimising agent. s reduces the entropy of mt by acquiring information as we now describe.
¡¡distribution d will typically be defined in terms of other distributions. for example  the 'best' action may be defined in terms of the trustworthiness of ¦Â  section 1   quasi-utilitarian distributions such as those described in section 1  measures of information gain in section 1  and measures of semantic context in section 1. suppose that d is defined in terms of {xi}. the integrity of each xi will develop in time byi eqn. 1. the update functions for xi  jx   identify potential  entropy reducing  information that may perhaps be obtained from the information sources {¦Èi}ti=1. if ¦Á requests information   from ¦Èj that is delivered as   it is managed as described in section 1. that section also showed how nearby observations    may be used to update distributions  so identifying additional information that may reduce entropy.
¡¡let m¦Á¦Ât be the set of time-stamped messages that ¦Á has sent to likewise both at time t. the next action that ¦Á takes in this dialogue will be to send ¦Â a message ¦Ì that is determined by its strategy. ¦Á's strategy is a function f ¡¤  of the following form: ¦Ì =argmaxf it ¦Â ¦Á z  
z
 
|
 pt acc ¦Â ¦Á z  pt ¦Á ¦Â ¦Ö z   | z is a proposal  
it takes account of the acceptability  expected utility  of proposals  the expected information gain in each communication and the semantic relationship between proposals  both as seen by itself and by ¦Â.
1 conclusion
information-based agency integrates in an homogeneous agent architecture the exchange of information and the negotiation of norms and contracts using a rich communication language. these agents' world models are manipulated by the agent's proactive and reactive machinery using ideas from information theory. these agents are aware of the value of the information in every utterance  the semantic relationship between utterances as well as their utilitarian value. summary measures that generalise trust  reliability and reputation illustrate the strength of the architecture. these agents' negotiation strategies are based on three dimensions: informational  rational and semantic.
acknowledgments carles sierra has been supported by the eu funded strep project openknowledge and the spanish mec project webi-1. both authors are supported by the australian arc discovery project 'the curious negotiator'.
