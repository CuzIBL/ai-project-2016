 
　　most of the data on the relative efficiency of different implementations of the alpha-beta algorithm is neither readily available nor in a form suitable for easy comparisons. in the present study four enhancements to the alpha-beta 
algorithm-iterative deepening  aspiration search  memory tables and principal variation search-are compared separately and in various combinations to 
determine the most effective alpha-beta implementation. the rationale for this work is to ensure that new parallel algorithms incorporate the best sequential techniques. rather than relying on si-
mulation or searches of specially constructed trees  a simple chess program was used to provide a uniform basis for comparisons. 
	i 	introduction 
　　perhaps the most complete description of the alpha-beta algorithm is the paper by knuth and moore  in which a negamax implementation is described   l   . that paper also makes a clear 
distinction between those nodes in the game tree where cutoffs may occur  and those which must be fully explored  and so are logical candidates for the application of multiple processors during 
parallel searches. one field where the alpha-beta algorithm is universally applied is that of computer chess. here the problems are so large that a tree of the whole game cannot be built and so an approximate solution is sought  one which involves a succession of searches on fixed depth trees. at a
 terminal node  a leaf  an evaluation function is 
invoked to estimate the value of the subtrees discarded. in chess  non-quiescent moves at the terminal nodes are explored more fully  with special subset searches involving  for example  only moves which check or capture  or their forced responses . 
　　the alpha-beta algorithm owes its efficiency to the employment of two bounds which form a window. typically  a call to the alpha-beta function is of the form: 
　　　v := ab p  alpha  beta  depth ; where p is a pointer to a structure which represents a position  alpha and beta are the lower and upper bounds on the window  and depth is the specified length of search. the number returned by the function is called the minimax value of the tree  and measures the potential success of the next player to move. a skeleton for the alphas-beta function appears in a recent survey paper   where more details about certain alpha-beta refinements appear. previous studies of alpha-beta efficiency have not considered these refinements  or have not been done on a basis which allows for simple comparisons. to provide more consistency  this new quantitative study presents results from a simple working chess program1  and may be compared with those from searches of specially constructed trees . 
	ii 	alpha-beta refinements 
　　an iterative deepening mode  in which a sequence of successively deeper and deeper searches is carried out until some time limit is exceeded  is a simple way of extending the alpha-beta algorithm. a search of depth d ply  moves  is used to dynamically reorder  sort  the choices and thus prepare the way for a faster search to d+l ply than would be possible directly. my aim is to determine exactly how much a shallow search may improve a deeper one  and to compare the results with those for a direct full window search. the methods considered are: 
　　1. simple iteration  in which the move list at the root node of the tree is sorted after each iteration. by this means the candidate best move is tried first during the next iteration. 
　　1. aspiration search  in which the score returned by the best move found so far is used as the centre of a narrow window within which the score for the next iteration is expected to fall. if the value returned is outside the window  the search has failed high or low and must be repeated 
with a window which spans the new range of possible values . 
　　1. minimal window search employs a full window only on the candidate principal variation. all the alternate variations are searched with a zero window  under the assumption that they will fail-low in any case. should one of the moves not fail this way then it becomes the start of a new principal variation and the search is repeated for this move with a window which covers the correct range of possible values. the pvs  principal variation search  implementation of this algorithm 
is based on calphabeta   which in turn is simi-
1: tinkerbelle  k. thompson   a chess program which participated at the us computer chess championship  san diego  november  1. 

1 t. marsland 
lar to scout . the algorithm is presented in figure 1  through a pascal like language extended with a return statement. undefined in the program are functions evaluate  to assess the value of a leaf   and generate  to list the moves for the current position . for simplicity  additional functions make  to actually play the move considered  and undo  to retract the current move  are not included. note that pvs preserves the property of falphabeta   in that for failing searches the bound returned may be better than the alpha limit. this means that the re-search of a new principal variation normally proceeds with a narrower window. more importantly  pvs may be easily extended to draw on the idea that the correct score for a candidate principal variation is not needed until a potential rival arises. this extension to alphabeta searching is based on a technique employed by k. thompson at the first level of the tree search in belle1. note also that zero window searches normally cut off quite quickly. if this is not the case  then a profitable heuristic is to curtail the search and repeat immediately with the appropriate window. 
　　naturally  all of these methods may be improved by the inclusion of transposition and refutation memory tables. 
	i l l 	memory tables 
　　for each initial move in the game tree  the alpha-beta algorithm determines a sequence of moves which is sufficient to cut off the search. these sequences may be stored in a refutation table. after a search to depth d on a tree of constant width w this table will contain w*d entries. thus upon the next iteration there exists a set of move sequences of length d-ply that are to be tried first. the next ply is then added and the search continues. the candidate principal variation is fully searched  but for the alternate 
variations the moves in the refutation table may again be sufficient to cut off the search  and thus save the move generation that would normally occur at each node. the storage overhead is very small  although a small triangular table is also 
needed to identify the refutations . 
　　a transposition table holds not only refutations and the main subvariations  but also has the capacity for including more information. in particular  once a subtree has been searched its transposition table entry will contain not only the length of the search tree and the value of the subtree  but also whether that value represents the true score or an upper/lower bound on the score . a typical transposition table might 
contain 1 entries  each of 1 bytes  for a million-byte total storage overhead. in our implementation  the  position encoding  hash key was 1 bits long  of which 1 bits were used to index into an 1-entry table. various choices for accessing the transposition table are discussed in a 
recent report   for this study only a single probe of the table was made for each position. 
1: belle  the current world champion chess program  developed by k. thompson  bell laboratories. 
	iv 	results 
　　minimax tree searches generally involve significantly more calculation at a leaf than at an interior node. for example  chess programs carry 
out a check and capture analysis in the form of an extended tree search. therefore the following results are based on the number of terminal nodes examined. it is reasonable to assume that the various heuristics in the evaluation function are 
equally effective across all alpha-beta refinements  and so we have a machine-independent measure for future comparisons. 
　　the algorithms were tested on a data set which was used to assess the performance of computer chess programs and human players . that data set contains 1 chess positions  labelled a..x in table 1   but a was deleted from our study since it involved a simple sequence of forcing checks. 
all the remaining positions were searched with 1  1 and 1-ply trees  using a combination of alphabeta refinements  and a 1-ply search was done with the best method. the raw results have been con-
densed into figure 1  which shows the ratio of the number of terminal nodes searched relative to a direct search. in order to see how much improvement is possible in the alpha-beta algorithm  the formula 
   w**|d/1| + w**|d/1i - 1 nodes  where |x| and ixl represent upper/lower integer 
bounds on x  is plotted in figure 1 as the minimum tree size . here the value for w is estimated as the average width of the nodes in the trees being studied. the zig-zag appearance of figure 1 is normal for alpha-beta searches   and .occurs because for an even-ply search a larger fraction of the terminal nodes must be fully evaluated. 
　　from table 1 we see that one of the positions influences the final results strongly. for example  in the case of board w a change occurred in the principal variation  thus the 1-ply search was not a good predictor of the 1-ply result. just how serious this can be is clear from table 1  which shows that for board w all the iterative searches are more expensive than a direct search. this is reinforced in the 1-ply results when  for the case pvs with transposition table  1% of the effort was expended on board w   some effective heuristics for partial re-ordering of the move list between iterations can be developed to correct this problem. even so  iterative searches may be at a disadvantage whenever the principal variation changes. for problems of this type we are 
designing parallel versions of pvs. 
	v 	assessment of sequential methods 
　　these results confirm that iterative deepening is an effective enhancement to the alpha-beta algorithm  provided it is used in conjunction with some form of aspiration or memory table search. for relatively shallow trees  depth   1  there is not much to choose between refutation and transposition memory tables. by its very nature  a transposition table is continually being filled 

with new positions  some of which may destroy entries that have not yet been reused. thus it is not possible to guarantee that all the primary refutations will be retained. this problem can be overcome through the inclusion of a small and easy to maintain refutation table. to support this combination  we observed that for the 1-ply pvs case an average 1 percentage point improvement occurred  while in the 1-ply case a more dramatic 1 percentage point improvement was seen  figure 1. from this second result we conclude that a transposition table of 1 entries is too small for 1ply searches of complex positions  since it becomes seriously overcommitted and cannot perform as well as the simpler refutation table. on the other hand  the true power of a transposition table was not brought out by our data set  since there were only two endgames  boards f and h  table 1 . 
	vi 	conclusions 
　　of the two principal refinements  narrow window aspiration search and use of memory tables  it was found that preservation and use of the refutations from a previous iteration was more important than aspiration searching. this point is clearly illustrated in table 1  where a full window search with refutation table support is superior to a narrow window aspiration search without a memory table. 
　　based on our experiments  as summarized by results presented in figure 1  it is clear that pvs is potentially superior to narrow window aspiration searching  since it avoids the need to determine an acceptable window. note that these results reverse an earlier conclusion for the game of checkers  where calphabeta was described as being  disappointing  and  probably not to be recommended  . thus for two different games contradictory results appear  illustrating not 
t. marsland 1 
only how game-dependent these methods may be  but also the influence of strong move ordering  on the efficiency of tree search algorithms. 
