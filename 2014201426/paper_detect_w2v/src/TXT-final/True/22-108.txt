 
the task of learning from environment is specified. it requires the learner to infer the laws of the environment in terms of its percepts and actions  and use the laws to solve problems. based on research on problem space creation and discrimination learning  this paper reports an approach in which exploration  rule creation and rule learning are coordinated in a single framework. with this approach  the system live creates strips-iike rules by noticing the changes in the environment when actions are taken  and later refines the rules by explaining the failures of their predictions. unlike many other learning systems  since live treats learning and problem solving as interleaved activities  no training instance nor any concept hierarchy is necessary to start learning. furthermore  the approach is capable of discovering hidden features from the environment when normal discrimination process fails to make any progress. 
1 	introduction 
while solving problems in a new environment  as when we learn how to swim  a learning system must explore the environment to correlate its actions with its senses  to induce the laws of the environment  and to create feasible problem representations for problem solving. we refer to this task as learning from environment  and give its specification in table 1. 
    this research was sponsored by the defense advanced research projects agency  dod   arpa order no. 1  amendment 1  monitored by the: 
avionics laboratory 
air force wright aeronautical laboratories aeronautical systems division  afsc  united states air force 
       wright-patterson afb  ohio 1 under contract f1-c-1. 
　the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies  either expressed or implied  of the defense advanced research projects agency or the us government. 
given: 
  actions: effectors executable in the environ-ment; 
  percepts: objects' features or relations observ-able from the environment; 
  constructors: a set of primitive predicates  e.g. =      functions  e.g. +  *  and logical connectives  e.g. a -   and 1 ; 
  environment: a process that provides the ob-servable information and determines the effects of the actions; 
  goal: a state description of the environment; learn: 
  the laws of the environment that predict ac-tions' effects and reach the given goal. 
table 1: the definition of learning form environment 
　for example  consider the tower of hanoi as an environment. suppose that the learner has actions:  pick diskx pegr  and  put diskx pegx   percepts:  on diskx pegx    in-hand diskx   and  size  diskx disky   and constructors: a     and 1. to solve problems  the learner must learn consequences of its actions and the laws of the tower of hanoi. the environment enforces its laws by refusing to carry out illegal actions. the specified learning task has a wide range of complexity. it becomes harder as the learner's actions and percepts become more environment independent and the environment contains larger laws and hidden features. for example  the tower of hanoi problem becomes much harder if  pick diskx pegx  is replaced by more primitive actions like pick    turn-hand 1  and slide-hand d   and  on diskx pegx  is replaced by objects' shape  size  and their locations. 
　this paper will focus on the rule creation and rule learning approach used by a learning system called live that can solve the specified task with primitive percepts  objects' features  and primitive actions  moving a hand . the learned rules are similar to strips's operators  but they are used for both prediction and problem solving  and their prediction does not change the world as strips's add and delete lists. with this approach  live creates new rules by noticing the changes caused by actions  and later refines them by discriminating the 
failures and successes of their prediction. when the discrimination process fails  hidden features will be defined 
	shen and simon 	1 
by searching back in the history. after briefly describing some related work and a survey of the l i v e system  details of live's other components  such as exploring  planning with incomplete rules  integrating plan execution with learning  and constructing qualitative predicates from numerical percepts  will be discussed in another paper  shen  1b    we will discuss the three parts of the rule creation and rule learning method and demonstrate them with examples. 
1 	related work 
there are many approaches to the problem of rule creation and rule learning. the candidate elimination algorithm  mitchell et a/.  1  is well known for learning conjunctive rules with a given concept hierarchy. quinlan's id1  is probably the best example of a system for learning disjunctive rules from many examples when learning and problem solving are separated. for discrimination learning  vere  uses it as counterfactuals  and langley  utilizes it in his sage system and develops a theory. more recently  falkenhainer  uses discrimination as disanalogy  and newell and flynn 
 newell  1  use it to modify incorrect productions in soar. carbonell and gil  also use a similar method in learning by experimentation. 
　with respect to automatic creation of a problem space  hayes and simon  have built a system capable of constructing problem spaces from written english  which is extended by yost and newell  newell  1  in the soar system. however  few attempts have been made to create problem spaces from interactions with an environment  although drescher  did some interesting work on implementing early piagetian learning. as for discovering hidden features  the bacon system  langley et al  1  creates new terms to infer laws from given data.  mitchell et a/.  1  and  utgoff  1  present methods for detecting the insufficiency of a concept description language in problem solving and define new terms.  dietterich and michalski  1  gives a survey on some of the existing constructive induction systems for discovering hidden features in time-independent environments  see section 1   and present their solutions. 
1 	overview of live 
the live system is an extension of the gps problem solving framework with a learning component that creates and learns rules through environmental exploration. each rule consists of three parts: condition  action and prediction  all constructed in terms of the given percepts  actions and constructors. when applied forward  a rule whose condition matches the current environmental state can predict the consequence of the action performed; when applied backward  a rule that predicts the current goal can be used to propose new subgoals as if it were a problem reduction rule or inference rule. live is capable of learning disjunctive rules when constructors include logical connectives  in this case  the form of the conditions and predictions is: 

1 solution planning: find the differences between the goals and the current state; for each difference find a rule  order the differences by their rules; 
1 if the first difference has no rule  propose an exploration plan; 
1 if an exploration plan exists  then select an action from it  else select the first difference with its rule from the solution plan; 
1 if the rule is not executable  then identify new differences  order them by their rules  and insert them in the solution plan  go to 1; 
1 make prediction and execute the action; 
1 if the outcome is expected  then go to 1; if the outcome is surprising  then explain the surprise and revise the rule set; if the current action is from the solution plan  then go to 1; else go to 1. 
table 1: the outline of live's algorithm 
　as we can see in the algorithm outline in table 1  when live is solving problems in a new environment  it will alternate its attention between environment exploration and problem solving because no knowledge is given at the outset. the decision for alternation mainly depends on surprises  situations where an action's consequences violate its prediction. when no rule can be found for solving the problem  live will generate and execute an exploration plan  or a sequence of actions  seeking for surprises to extend the rule set. when new rules are learned  problem solving is resumed and a solution plan may be constructed through means-ends analysis. since the correctness of a solution plan cannot be guaranteed  learning is inevitable at execution time. when a rule's prediction fails during execution  live will revise the rule set and then plan another solution for the problem. 
   to illustrate the rule representation and the algorithm  let us consider again the tower of hanoi environment  and suppose the initial state is  on diskl pegl   on disk1 pegl   on disk1 pegl . since live starts with no rules at all  it does not know how to reach the given goal stale:  on diskl peg1   on disk1 peg1   on disk1 peg1 . so it generates an exploration plan  say  pick up a disk from pegl and then put it down on peg1. ruleo and rulel are created in the exploration. rulel is defined as follows: 

after the exploration  live plans to put disks on peg1 one by one  believing that the order is unimportant. as a result  diskl is successfully put on peg1  but not disk1. after  put disk1 peg1   l i v e is surprised that disk1 is still in the hand. an explanation for the surprise is then found  details will be discussed later   and live splits the above rule into two with the help of the explanation  the 1 quantifier is necessary because the match process 

1 	machine learning 

examines the action and the positive condition before any negative condition  and disky is a free variable here : 


　after these rules are learned  live begins to plan another solution but finds that the current rules cause unresolvable goal interactions: no matter which goal is achieved first  it will be destroyed in order to achieve other goals. at this point  live switches itself from problem solving to exploration  in the hope that new surprises will arise for learning better rules. 
1 	creating new rules through exploration 
live learns from a new environment by correlating its actions with its percepts. at the very beginning  it simply executes its actions and compares the states before and after. when noticing that facts disappear and emerge as actions are taken  the system will build a new rule  using the disappeared facts as conditions  and the emerged facts plus the negation of disappeared facts as predictions. for example  to figure out what  pick diskx pegx  does  live may try  pick diskl pegl   and then find diskl moved from pegl to its hand. ruleo is then built  rulel is built in the same way : 
  
   the main objective for rule creation is to keep the new rule as general as possible. in the example above  the rule is indeed most general because the action happens to make one and only one change. but what if there is no change at all  or there are many changes  in the case of no change  as when a robot hand does put   when nothing is in its hand  the system will build a new rule with equal conditions and predictions made by the facts related to the action. for example  a new rule about the put   will use the position of the hand both as the condition and as the prediction because the hand is the actor. in the example above  if  pick diskl pegl  did not change anything  then  on diskx pegx  will also be the prediction because diskx and pegx appear in the action. in the case of many changes  the system will select necessary relational changes just adequate for specifying the action. for example  suppose that a robot hand is above a stack of disks  disk1  disk1  ...  disk ;   when it turns away all the relations  direction= hand diski  will become false. in this case  live will not include all these relations in the rule but choose one  any one  of them. 
   perhaps a more important question to ask here is what if there are no given relation predicates  and all that can be perceived are objects' features such as shape  size  and location. the answer is to construct new relation predicates by noticing the features that changed  shen  1b   however  we will not discuss this topic further in this paper. 
1 	splitting rules by explaining surprises 
the newly constructed rules  as we saw in the last section  are clearly over-general and incomplete  but they serve as a springboard for further exploration. because of their generality  live will have chances to make mistakes  to be surprised  and hence to increase its knowledge about the environment. 
　incomplete rules can be easily identified in live  because all rules predict and live compares their predictions with the actual outcomes in the environment whenever a rule's action is executed. a surprise occurs when the actual outcomes falsify the predictions  and the rule that made the predictions is the faulty rule. 
　live uses discrimination to revise its rules. it remembers each rule's latest application  which contains the rule index  a state  and the rule's variable bindings. once a rule causes a surprise  live will search for the rule's last application  find the difference  using langley's method   between the state now and the state then  and use the differences found to split the rule into two. 
   for example  suppose the current state is  on diskl peg1   on disk1 pegl   in-hand disk1   size  disk1 diskl   size  disk1 diskl   size  disk1 disk1   and live tries to put disk1 on pegl with the prediction  in-hand disk1  made by rule1 with variable bindings:   disky . disk1   pegx . pegl   diskx . disk1  . after executing  put disk1 pegl   live is surprised because disk1 is now on pegl. to explain the surprise  the system fetches the rule's last application which contains a state:  on diskl peg1   on disk1 pegl   in-hand disk1   size  disk1 diskl   size  disk1 diskl   size  disk1 disk1   and bindings:   disky . diskl   pegx . peg1   diskx . disk1  . comparing these two applications  live finds the difference to be  size  diskx disky  a  on disky pegx   the details are omitted here because readers can find similar examples in  langley  1  . based on the difference  rule1 is then split into two new rules  shown below : one is a variant of the old rule with the condition augmented by the difference; the other is a new rule  whose condition combines the old condition with the negation of the difference  and whose prediction is the surprising consequences  constructed by the same method used in rule creation . note that live keeps both rules after splitting  and this is one of the main distinctions between llve's discrimination process and the one employed by langley   1 ; for if rule1 were thrown away when splitting rulel  as his method does  the good rule1 might never be found. 

	shen and simon 	1 

reason and the rule later becomes too specific  such rules will be wasted and new rules will be re-learned. to prevent learning wasted rules again  live will reject an explanation if the result of splitting is equivalent to some existing rule. second  it seems that even though the order of surprises may cause rules' conditions to be built differently  the rules learned are always useful and effective for live to reach the given goal  as we have found in many running examples. third  if the outcomes include more changes than predicted  no surprise arises  but live will remember those extra changes. in further plan execution  if these changes violate the conditions of the later rules in the plan  live will then insert the changes into the rule's predictions. 
1 	discovering and assimilating hidden features 
previous research in discrimination learning has developed many methods for finding the critical difference between two states  but what if the two states have no difference at all  as when two pairs of green peas look exactly the same but produce different offspring  in this case  we say that the environment has hidden features  something unobservable that yet can discriminate two states that appear identical. 
   live has two ways to discover hidden features  depending on whether an environment is time dependent or not. in a time-independent environment  where states do not depend on the previous actions  live discovers hidden features by applying its constructor functions to the existing features and testing whether the result discriminates the ambiguous states. for example  when predicting whether a balance-beam  siegler  1  will tip or balance  live discovers the invisible  torque  concept by multiplying distance and weight.  this kind of hidden features is normally categorized by the term constructive induction.  in time-dependent environments  where states do depend on the previous actions  live discovers hidden features by searching back in its history to find differences in the states preceding the two indistinguishable states. we will give a detailed description of the discovery of genes in a later section. 
   discovering hidden features is only the first half of the whole story; they have to be assimilated into the system to be useful in the future. in a time-independent environment  since hidden features are defined in terms of observables  the system can simply use the newly defined features as if they are visible because they are computable from the observables. for example  when the concept of torque is discovered by a system that perceives only objects' distances and weights  the concept will simply be added as another object feature. any rule that needs torque to discriminate its condition can use it by computing the value weight*distance. in a timedependent environment  since hidden features determine the observables  two additional things must be done before these features can be used: determine how the hidden features define the observables; and determine how the hidden features are inherited through actions. one strategy is used for both tasks: testing all the construc-
1 	machine learning 
tor functions to find one that is consistent with all the examples collected. we will have more to say about this later when live attempts to discover genes. 
   although live's discovering method has been tested in both time-independent and time-dependent environments and the hidden features to be discovered can be quite complex in principle  previous discovered features can be used to discover new features   it depends heavily on the constructors that are given. for example  if * is not given  no features like torque can be discovered. in the future  we hope live will start with a parsimonious  domain independent set of primitives from which necessary constructors like * can be constructed during the interaction with environment. some early results along this direction have been reported in  shen  1a . 
1 	solving the low-level tower of hanoi 
in this section  we complete the description of how live learns a set of correct and useful rules in the tower of hanoi environment. we call it low-level  because live's innate percepts and actions do not  include high-level concepts and actions that previous studies have used. in this environment  no matter what the initial state is  
live always creates a set of good rules  different rules may be learned in different runs  and reaches the given goal state. in the run we have been talking about so far  it takes live 1 steps  including both actions and proposing subgoals  to solve the problem. we have explained how ruleo through rule1 are created. in the later stage  live meets three more surprises  the first surprise conies when it tries to pick up a disk when another disk is in the hand  which splits ruleo into ruleo and rule1; the second surprise comes when it tries to put a bigger disk on a smaller one  which splits rule1 into rule1 and rule1; the third surprise comes when it tries to pick up a bigger disk underneath a smaller disk  which spilts ruleo into ruleo and rule1. the following is a list of all seven rules learned by live: 



	shen and simon 	1 


1 	conclusion 
in this paper  the problem of learning and problem solving in new environments is specified as a problem of correlating a learner's percepts and actions and inferring the rules from the given environment. a discriminationbased learning method is investigated that creates general rules by noticing the changes in the environment  and then specifies the rules by explaining their failures in prediction. the method has two distinct characteristics. first  when an over-general rule is split  the method will keep both new rules for further development. second  when the discrimination process is unable to find any difference between a success and a failure  the method will define hidden features in terms of existing or historical features. we have been investigating the method in several very different domains and further studies are focusing on applying it to more complex exploration tasks and learning problem solving strategies. 
acknowledgement 
we thank jaime carbonell  tom mitchell  chuck thorp and jeff schlimmer for their valuable comments  and klaus gross for the suggestion of using mendel's discovery as a testing domain. we also appreciate the support from the world modelers project upon which live is originally developed. 
1 	machine learning 
