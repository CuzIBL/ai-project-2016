 
this paper proposes a new approach of neural network based photometric stereo in which all the directions of illumination are close to and is rotationally moved around the viewing direction. adjacent light sources cause a numerically ill-conditioned problem. ill-conditioning is overcome in two ways. first  many more than three images are acquired. second  principal components analysis is used as a linear preprocessing technique to determine a reduced dimensionality subspace for use as input. the approach is empirical and uses the radial basis function  rbf  neural network to do non-parametric functional approximation. one neural network maps image irradiance to surface normal. a second network maps surface normal to image irradiance. the two networks are trained using samples from a calibration sphere. comparison between the actual input and the inversely predicted input is used as a confidence estimate. further  we introduce the illumination planning  which disposes the information of the cast shadow region from the ill-effected light sources for each point on the object using the confidence estimate. then  the best combination of nn units with well-effected light sources for each point are used to get the relevant results. the results on real data are also evaluated. 
1 	introduction 
shape-from-shading  horn  1; 1  is the problem of determining surface shape from the smooth shading present in a single image. photometric stereo  woodham  1  determines surface orientation locally using multiple images of an object surface acquired from a single viewpoint under different conditions of illumination. principles of optics are used as a source of radiometric constraint. 
　recently  theoretical analysis of shape-from-shading and photometric stereo seem to dominate the literature at the expense of practice. theoretical work of-
1 	vision 
ten considers lambertian reflectance alone. regrettably  this convinces many potential implementors that the approach is of little practical value. in  physics-based vision   serious attention now is paid to other reflectance models  healey et al.  1   healey et al  1 . clearly  this is fundamental. but  it has not yet proven effective in practice. 
　in  woodham  1   the non-linear mapping between image irradiance and surface orientation was represented explicitly in a lookup table  lut . this allowed near real-time implementation of three light source photometric stereo on full frame video data at near video frame rates  i.e.  1hz . 
　iwahori has pursued neural network implementations of photometric stereo  iwahori et a/.  1 . using principal components analysis  pca  in conjunction with a neural network for the case of a moving  nearby light source was first reported in  iwahori et al.  1 . not surprisingly  it was observed that  with only small movements of the light source  standard photometric stereo becomes numerically ill-conditioned. for this reason  it seemed difficult to realize implementations based on a single moving light source. in the present version of the work  the moving light source is standardized into a rotational pattern. 
　while  some approaches using the illumination planning to photometric stereo are proposed in  solomon et al.  1  and  solomon et al.  1 . these approaches 
are intended to remove the glossy components from multiple light sources. 
　factors limiting application of photometric stereo include shadows  interreflection and the reality that the available range of illumination directions often is restricted. there are trade-offs. greater difference in the directions of illumination leads to a better conditioned numerical estimation of surface orientation. at the same time  greater difference in the directions of illumination leads to a larger number of surface points that fail to be commonly illuminated and hence fail to support any estimation of surface orientation. this paper proposes a new nn based approach using the illumination planning to remove the cast shadow region as much as possible from the multiple rotational light sources. the illumination planning is used is to determine the best combination of light source for each point on the object to recover the gradient. combination of two distinct nns are used to determine a local confidence. experiments on real data are demonstrated for the illumination planning. 
1 	neural network based photometric stereo 
1 	principle of photometric stereo 
let the object surface be given explicitly by z = f x  y  in a right-handed euclidean 1d scene coordinate system  with the positive z direction pointing to the viewer. image projection is assumed to be orthographic. let a  unit  surface normal vector at any surface point be  n1  n1  n1 . photometric stereo uses multiple images obtained under the identical geometry but with different conditions of illumination. with p light source directions  p images  and hence p equations  are obtained. 
		 1  
where e x y  is the image irradiance and r n1  n1  n1  is the reflectance map  defined using the surface normal   n1  n1  n1   to represent surface orientation. with p   1  the p image irradiance measurements  e1  e1 ...  ep  generally overdetermine the local surface orientation at each point   x y   since surface orientation only has two degrees of freedom. but  if all directions of illumination are nearly collinear  as will be the case here  the problem can be ill-conditioned. 
1 	principal components analysis 
principal components analysis  pca  is a technique from multivariate statistical data analysis. the basic idea is to describe the dispersion of an array of n points in a p-dimensional space via a new set of orthogonal linear coordinates  called the principal components  determined so that the principal components are mutually uncorrelated and so that the sample variances of the n points are ranked in decreasing order of magnitude with respect to these new coordinates. pca is an invertible coordinate transformation that captures no more  or no less  information than was originally present. 
　algebraically  pca involves finding the eigenvalues and eigenvectors of the sample covariance matrix.  a variant of standard pca uses the sample correlation matrix instead . a covariance matrix is symmetric and positive definite so that its eigenvectors form an orthogonal set. the  normalized  eigenvectors define the new set of coordinates axes  i.e.  the principal component axes . since pca does remove correlation from data coordinates  in a p-dimensional space   it does have application to dimensionality reduction  given sample data with significant correlation. dimensionality reduction typically is achieved by simple elimination of lower order principal components. with p directions of illumination that 

1 	rbf networks and ols learning 
neural networks are attractive for non-parametric functional approximation. a radial basis function  rbf  neural network is one choice suitable for many applications. in particular  it has been widely used for strict interpolation in multidimensional spaces. it is argued that rbf neural networks often can be designed in a fraction of the time it takes to train standard feed-forward networks. they are expected to work well when many training vectors are available. 
　rbf networks represent non-linearity via the choice of basis functions. a gaussian isn't the only choice of radial basis function for rbf networks but it is the choice widely used and the one used here. one common learning algorithm for rbf networks is based on first randomly choosing data points as rbf centers and then solving for the optimal weights of the network. performance  however  critically depends on the chosen centers. in practice the centers often are chosen to be an arbitrary selected subset of the data points. 
　the learning procedure adopted here is based on the orthogonal least squares  ols  method. the ols method can be employed as a forward regression procedure to select a suitable set of centers  regressors  from a large set of candidates. at each step of the regression  the increment to the explained variance of the desired output is maximized. it chooses radial basis function 
iwahori.et al. 
centers one by one in a systematic way until an adequate network has been constructed. the algorithm has the property that each selected center maximizes the increment to the explained variance of the desired output while remaining numerically well-conditioned. 
　with this learning procedure  two rbf networks are trained using input/output data from a calibration sphere. here  we use reduced dimensionality data preprocessed by pca as described in section 1. many training vectors are available since data from the calibration sphere are dense and include all possible visible surface normals   each rbf network used consists of two layers   i.e.  a hidden layer of p neurons and an output layer of 1 neurons   as shown in figure 1. 
　the learning procedure builds an rbf neural network one neuron at a time. neurons are added to the network until the sum-squared error falls beneath an error goal  or a maximum number of neurons has been used . in learning  it is important that the so-called spread constant of the radial basis function be large enough that the neurons respond to overlapping regions of the input space  but not so large that all the neurons respond in essentially the same manner. once learning is complete  that which has been learned is represented by the weights connecting each rbf neural network unit. the resulting network generalizes in that it predicts a surface normal    given any triple of input values  
             the resulting network trained using the calibration sphere can then be used to estimate the surface orientation of other test objects. 
the idea is to use the length of the surface normal  
 n  n  n    to define a confidence measure. we have found a better idea to be the simultaneous training of a second network  during calibration  to inversely predict the input   from the estimated output   n1 n1 n1 . comparison between the actual input and the inversely predicted input then serves as a suitable confidence estimate. 
　the architecture for the two step rbf network is shown in figure 1. as mentioned  both component networks are trained during calibration. during training  
1 	vision 
each normal vector input to the inverse network necessarily is a unit normal. if the 1d subspace from the calibration sphere is input to this two step network  the output of the second step  which we call the resynthesized input subspace  should be very similar to the original input. however  if an impossible triple  i.e.  one that could not have arisen from the calibration sphere  is input  we expect the resynthesised input subspace to be quite different since the resynthesized values necessarily correspond to points on the calibration sphere. 
1 	illumination planning 
1 	i m p l e m e n t a t i o n 
nn-based photometric stereo using more than three light sources can be implemented as follows. 

figure 1: process units 
two rbf-nns 
where n1bj is the total pixel number of the test object region. 
　calibration measures reflectance data using an object of known shape. a sphere is a good choice because it is convex  thus eliminating interreflection  because it is easy to dead reckon local surface orientation geometrically from the object silhouette and because it spans all 

possible visible surface normal vectors. details of the calibration procedure used are described elsewhere  woodham  1; iwahori et al  1 . 
　illumination planning is applied by picking up the data that does not give the cast shadow under the multiple light sources for each point on the test object. 
1 	strategy of illumination planning 
three light source photometric stereo necessarily causes cast shadow problem for the complicated curved object and the image irradiance equation cannot be applied for cast shadow region. generally  shadow region is given by two causes: one is the region where the shadows de pends on the geometrical local shape  and the other is the cast shadow which is defined as that another local shape interrupts the illumination and it casts shadow. the former shadow occurs when the angle between the surface normal vector and the light source direction vector becomes greater than 1 degrees  however  actual image irradiances still hold some information to recover the local surface gradient. while  the latter shadow is defined as the cast shadow and it is impossible to use the irradiance values to recover the local surface gradient. 
　the approach uses the rotational multiple light sources more than three  and once recovers the distri button of surface orientation for the test object using all light sources. after this process  one can determine the confidence for each point of the test object from the difference between and 
from the confidence values  the 
method disposes the ill-effected light sources among all light sources and recovers the shape again from only the well-effected light sources to get the relevant results. this is proposed as the strategy of the illumination plan ning based approach. the procedures are given as follows. 
1. recovery from all p-light sources 
all p-light sources  i.e.   are input into the nn-units and obtain nall and e'all. 
1. extraction of cast shadow region 
the object surface regions can be defined as one of  normal reflection region    intersection region    shadows depending on local shape region  and  cast shadow region . this method finds the  cast shadow region  from the threshold process with to the standard derivation of the difference of for each pixel. 

　this process can find  normal reflection region  and  shadows depending on local shape region  under the condition that  while   interreflection region  increases the observed image irradiance and affects to are stable for all light sources and the variance of call becomes small for this interreflection region. 
　only the  cast shadow region  takes the various values for the variance of the difference between 
then  the values of 	a n d b e c o m e high for this 
 cast shadow region . 
　from the above reasons  the appropriate threshold process to aall can find the  cast shadow region . 
1. disposing light source which casts shadow 
for each point of the extracted cast shadow region  new combination group sub of light sources is determined by disposing the light source which casts shadow from the all combination of group all using the difference value of each light source. 
	let  be the difference between 	then 
the light source which has the larger value of has the worse one and should be a prtort disposed as 
light source which casts shadow . 
　since any actually has the positive value for the cast shadow and the range of  is less than it and greater than 1 for the same point  only the light sources for which  are negative and less than   are disposed. 
1. final recovery for each point without light sources which cast shadow 
image irradiance vector e aub from the illumination of the extracted light source group sub is input into the corresponding nn-unit and the shape of cast shadow regions are recovered again. the vectors 
 nsub e'nub  obtained here are used as the final results for the cast shadow region. 
1 	experiments 
1 	configuration 
the light source configurations are shown in figure 1. 
the distance between object and camera was set to be 
1  cm . fifteen light source directions were used  each differing from the z-axis by 1 degrees  i.e.  azimuth angle  for the illumination of eight light sources with smaller radius  while by 1 degrees for that of seven light sources with larger one. 
　two objects are used. one is a pottery sphere  used for calibration purposes  and the other is a pottery rnoon face. both objects are made of the same material with the same reflectance properties. no particular assumptions for the surface reflectance or light source directions are used or needed for the experiments. 
1 	construction of nn-units 
this experiments disposes the worst light sources of one to five in the total fifteen light sources. therefore  the number of nn-units prepared is for 
the combination of 
　the covariance matrix size used to recover the gradient for each point on the test object depends on the the 
iwahori  et al. 

figure 1: configuration of rotational moving light source 
number of light sources used for each point. the learning count for learning each nn-unit was set to be 1. this value is sufficient for the scale and generalization of nn used in the experiment. the values of and was set to be 1 and -1  mean of d   respectively. 
1 	results 
the results of this approach are shown in the figures 
1 to 1. the mean value of the estimated confidence  mean c   was 1 after the illumination planning  while mean c  was 1 before applying the illimination planning. 

	 a  before illumina- 	 b  after illumination 
	tion planning 	planning 
figure 1: needle maps 
　figure 1 shows the needle map obtained before/after the illumination planning  respectively  while figure 1 shows the slope map which linearly encodes the slope angle  e   i.e.  the angle between the surface normal and the vector pointing to the viewer  as a gray value in the range black  e = 1  to white  figure 1 shows 
1 	vision 

 a  before illumina-  b  after illumination tion planning planning 
figure 1: slope maps 

 a  before illumina-  b  after illumination tion planning planning 
figure 1: confidence maps 
the values of the confidence estimate c  encoded as a gray level. bright values correspond to points in the image where confidence in the estimated surface orientation is lowest. as can be seen  after the illumination planning  the confidence estimate is apparently improves for the region affected by cast shadows. figure 1- a  shows how the region was improved by this illumination planning as a gray level. bright values corresponds to the well improved regions. figure 1- b  shows an example of the original input images from the light source l1. 
　figure 1- a  and figure 1- a  shows some local random results around the two eyes  mouth  and arms  but figure 1- b  and figure 1- b  improved the results and removed the disconnected vectors around there. figure 1- b  is also improved in comparison with figure 1- a  for the corresponding regions. numerical evaluation shows the mean value of the confidence estimate  mean c   was improved with the rate of 1% and it is shown that the the regions effected by the cast shadow 


 a  comparison map  b  an original image of moon-face : ll figure 1: reference images 
is extracted and sufficiently recovered in addition to the normal regions  and the approach is entirely robust and practical by introducing pca and neural networks. 
1 	conclusion 
this paper proposes a new neural network based photometric stereo using the illumination planning  as one of the physics based vision approach. the illumination planning determines the cast shadow region and disposes the information of the ill-effected light sources for each point on the object from the output of the neural network. 
　shadows depending on local shape has the information to be used for shape recovery but cast shadow cannot be used for photometric stereo. for the implementation  pca and rbf nn-units are effectively used for the environment. in the illumination planning  the ill-effected region for each point is found from the output of nnunits learned for the calibration sphere images from all light sources. one can know which combination of light source is used to get the relevant result for each point. finally  each combination of nn-units can be applied to recover the surface normal for each point on the test ob-
ject effected by cast shadow. it is valuable to stress that the entire approach is non-parametric  empirical in that no explicit assumptions are made about light source directions or surface reflectance. it is sufficient that the calibration sphere used in training and the subsequent test objects be viewed under the same pattern of illumination and be made of the same material  i.e  have the same reflectance properties.  the experiment shows the approach is useful and can improve the shape recovery. 
　as the future subjects  the application of nn to nonuniform test object  and to the problem of correcting interreflection are remained. 
acknowledgements 
support for the work described in this paper was provided by the artificial intelligence research promotion foundation  japan. support for woodham's research is provided by the institute for robotics and intelligent systems  iris  and by the natural sciences and engineering research council of canada  nserc . 
