now approaches to parsing conjunctions using prolog 
sandiway kong 
robert c. berwick 
artificial intelligence laboratory 
m.i.t. 
   1 technology square cambridge ma 1  u.s.a. 
a b s t r a c t john and mary went to the pictures simple constituent coordination 　　conjunctions are particularly difficult to parse in traditional  phrase-based grammars. this paper shows how a different representation  not based on tree structures  markedly improves the parsing problem for conjunctions. 
it modifies the union of phrase marker model proposed by goodall   where conjunction is considered as the linearization of a three-dimensional union of a non-tree based phrase marker representation. a prolog grammar for con-
junctions using this new approach is given. it is far simpler and more transparent than a recent phrase-based extraposition parser conjunctions by dahl and mc.cord . unlike the dahl and mc.cord or atn sysconj approach  no special trail machinery is needed for conjunction  be-
yond that required for analyzing simple sentences. while of comparable efficiency  the new approach unifies under a the fox and the hound lived in the fox hole and 
                   kennel respectively constituent coordination with the 'respectively' reading 
john and i like to program in prolog and hope 
simple constituent coordination but can have a collective or respectively reading 
john likes but i hate bananas 
non-constituent coordination 
bill designs cars and jack aeroplanes 
gapping with 'respectively' reading 
the fox  the hound and the horse all went to market 
multiple conjuncts 
single analysis a host of related constructions: respectively sentences  right node raising  or gapping. another advantage is that it is also completely reversible  without cuts   and therefore can be used to generate sentences. 
i n t r o d u c t i o n 
　　the problem addressed in this paper is to construct a grammatical device for handling coordination in natural language that is well founded in linguistic theory and yet computationally attractive. the linguistic theory should be powerful enough to describe all of the phenomenon in coordination  but also constrained enough to reject all ungrammatical examples without undue complications. it is difficult to achieve such a fine balance - especially since the term grammatical itself is highly .subjective. some examples of the kinds of phenomenon that must be handled are shown in fig. 1 
       the theory should also be amenable to computer implementation. for example  the representation of the phrase marker should be conducive to both clean process description and efficient implementation of the associated operations as defined in the linguistic theory. 
　　　the goal of the computer implementation is to produce a device that can both generate surface sentences given *john sang loudly and a carol violation of coordination of likes 
*who did peter see and the car  
violation of coordinate structure constraint 
*l will catch peter and john might the car gapping  but component sentences contain unlike auxiliary verbs 
 the president left before noon and at 1. gorbachev 
fig 1: example sentences 
a phrase marker representation and derive a phrase marker representation given a surface sentences. the implementation should be as efficient as possible whilst preserving the essential properties of the linguistic theory. we will present an implementation which is transparent to the grammar and perhaps cleaner & more modular than other systems the execution time of both systems for some sample sentences will be presented. furthermore  the advantages and disadvantages of our device will be discussed in relation to the msc implementation. 
       finally we can show how the simplified device can be extended to deal with the issues of extending the system to handle multiple conjuncts and strengthening the constraints of the system. 
t h e 	r p m 	r e p r e s e n t a t i o n 
　　the phrase marker representation used by the theory described in the next section is essentially that of the reduced phrase marker  rpm  of lasnik & kupin . a reduced phrase marker can be thought of as a set consisting of monostrings and a terminal string satisfying certain predicates. more formally  we have  fig. 1  :-

       this representation of a phrase marker is equivalent to a proper subset of the more common syntactic tree representation. this means that some trees may not be representable by an rpm and all rpms may be re-cast as trees.  for example  trees with shared nodes representing overlapping constituents are not allowed.  an example of a valid rpm is given in fig. 1 :-
sentence: alice saw bill rpm representation. 
{s. alice.saw.bill. np.saw.bill. alice.v.bill. alice. vp.aiice. saw. imp} 
fig 1: an example of rpm representation 
       this rpm representation forms the basis of the linguistic theory described in the next section. the set representation has some desirable advantages over a tree representation in terms of both simplicity of description and implementation of the operations. 
s. fong and r. berwick 1 
g o o d a l p s 	t h e o r y 	o f c o o r d i n a t i o n 
　　goodall's idea in his draft thesis  goodall    was to extend the definition of lasnik and kupin's rpm to cover coordination. the main idea behind this theory is to apply the notion that coordination results from the union of phrase markers to the reduced phrase marker. since rpms are sets  this has the desirable property that the union of rpms would just be the familiar set union operation. for a computer implementation  the set union operation can be realized inexpensively. in contrast  the corresponding op-
eration for trees would necessitate a much less simple and efficient union operation than set union. 
       however  the original definition of the rpm did not envisage the union operation necessary for coordination. the rpm was used to represent 1-dimensional structuie only. but under set union the rpm becomes a representation of 1-dimensional structure. the admissibility predicates deminates and precedes defined on a. set of 
monostrings with a single non-terminal string were inadequate to describe 1-dimensional structure. 
       basically  goodalps original idea was to extend the dominates and precedes predicates to handle rpms under the set union operation. this resulted in the relations e-dominates and e-precedes as shown in fig. 1 :-

figure 1: extruded definitions 
　　　this extended definition  in particular - the notion of equivalence forms the basis of the computational device described in the next section. however since the size of the rpm may be large  a direct implementation of the above definition of equivalence is not computationally feasible. in the actual system  an optimized but equivalent alternative definition is used. 
       although these definitions suffice for most examples of coordination  it is not sufficiently constrained enough to reject some ungrammatical examples. for example  fig. 1 gives the rpm representation of  *john sang loudly and a carol  in terms of the union of the rpms for the two constituent sentences :-

1 s. fong and r. berwick 
{john. sang  loudly  s  
john.vloudlyjohn.vp  
john sang loudly 
john.sang.ap  
imp.sang  loudly} 
{john.sang.a.carol s  
john.v.a.catol john.vp  
john sang a carol 
john. sang. np  
np.sang.a.t.irol} 
 when these two rpms are merged some of the elements of the set do not satisfy lasnik & kupin's original definition - these pairs are :-  
{john.sang.loudly. john sang a.carol} 
{john.v loudly. john v a carol} 
{imp sang loudly. imp sang a carol} 
 none of the above pairs satisfy the e-dominates predicate - but they all satisfy e-prccedes nnd hence the sentence is accepted as an rpm.  
fig.1: an example of union of rpms 
　　　the above example indicates that the extended rpm definition of goodall allows some ungrammatical sentences to slip through. although the device presented in the next section doesn't make direct use of the extended definitions  the notion of equivalence is central to the implementation. the basic system described in the next section does have this deficiency but a less simplistic version described later is more constrained - at the cost of some computational efficiency. 
given a set of sentences and a set of candidates which represent the set of conjoinable pairs for those sentences  linearization will output one or more surface strings according to a fixed proce dure 
given a set of sentences  finding equivalences will produce a set of conjoinable pairs according to the definition of equivalence of the linguistic theory. 
       for generation the second process  finding equivalences  is called first to generate a set of candidates which is then used in the first process  linearization  to generate the surface strings. for parsing  the definitions still hold but the processes are applied in reverse order. 
       to illustrate the procedure for linearization  consider the following example of a set of simple sentences 
 fig. 1  :-
{ john liked ice-cream. mary liked chocolate} set of simple sentences 
{{john. mary}  {ice-cream  chocolate}} set of conjoinable pairs 
fig 1: example of a set of simple sentences 
       consider the plan view of the 1-dimensional representation of the union of the two simple sentences shown in fig- 1 :-

l i n e a r i z a t i o n 	a n d 	e q u i v a l e n c e 
　　although a theory of coordination has been described in the previous sections - in order for the theory to be put into practice  there remain two important questions to be answered 
  how to produce surface strings from a set of sentences to be conjoined  
  how to produce a set of simple sentences  i.e. sentences without conjunctions  from a conjoined surface 
string  
       this section will show that the processes of linearization and finding equivalences provide an answer to both questions. for simplicity in the following discussion  we assume that the number of simple sentences to be con-
joined is two only. 
       the processes of linearization and finding equivalences for generation can be defined as :-

fig 1: example of 1-dimensional structure 
       the procedure of linearization would take the following path shown by the arrows in fig. 1 :-

fig 1: example of linearization 
       following the path shown we obtain the surface string  john and mary liked ice-cream and chocolate . 
       the set of conjoinable pairs is produced by the process of finding equivalences. the definition of equivalence as given in the description of the extended rpm requires the generation of the combined rpm of the constituent sentences. however it can be shown  fong    by considering the constraints imposed by the definitions of equivalence and linearization  that the same set of equivalent terminal strings can be produced just by using the terminal strings of the rpm alone. there are considerable savings of computational resources in not having to compare every element of the set with every other element to generate all possible equivalent strings - which would take 1 n1  time - where n is the cardinality of the set. the corresponding term for the modified definition  given in the next section  is 1 . 
parse and generate 
　　in the previous section the processes of linearization and finding equivalences are described as the two compo-
s. fong and r. berwick 1 
nents necessary for parsing and generating conjoined sentences. we will show how these processes can be combined to produce a parser and a generator. the device used for comparison with dahl & mccord scheme is a simplified version of the device presented in this section. 
       first  difference lists are used to represent strings in the following sections. we can now introduce two predicates linearize and equivalentpairs which correspond to the processes of linearization and finding equivalences respectively  fig. 1  :-
linearize  pairs si el and s1 e1 candidates set gives sentence  
linearize holds when a pair of difference lists 
 {si. el} &  s1. e1}  and a set of candidates  set  are consistent with the string  sentence  as defined by the procedure given in the previous section. 
       the definitions for parsing and generating arc almost logically equivalent. however the sub-goals for parsing are in reverse order to the sub-goals for generating since the prolog interpreter would attempt to solve the 

1 s. fong and r. berwick 
sub-goals in a left to right manner. furthermore  the subset relation rather than set equality is used in the definition for parsing. we can interpret the two definitions as follows  fig. 1  :-
generate holds when sentence is the conjoined sentence resulting from the linearization of the pair of difference lists  si. nil  and  s1. nil  using as candidate pairs for conjoiningf the set of non-redundant pairs of equivalent terminal strings  set . 
parse holds when sentence is the conjoined sentence resulting from the linearization of the pair of difference lists  si. el  and  s1. e1  provided that the set of candidate pairs for con-
joining  subset  is a subset of the set of pairs 
of equivalent terminal strings  set . 
fig 1: logical reading for generate & parse 
       the subset relation is needed for the above definition of parsing because it can be shown  fong    that the process of linearization is more constrained  in terms of the permissible conjoinable pairs  than the process of finding equivalences. 
linearize 
　　we can also fashion a logic specification for the process of linearization in the same manner. in this section we will describe the cases corresponding to each prolog clause necessary in the specification of linearization. however  for simplicity the actual prolog code is not shown here. 
       in the following discussion we assume that the template for predicate linearize has the form  linearize  pairs si el and s1 e1 candidates set gives sentence   shown previously in fig. 1. there are three independent cases to consider during linearization :-
1. the base case. 
if the two difference lists  {si. el} & {s1. e1}  are both empty then the conjoined string  sentence  is also empty. this simply states that if two empty strings are conjoined then the result is also an empty string. 
1. identical leading substrings. the second case occurs when the two  non-empty  difference lists have identical leading non-empty substrings. then the conjoined string is identical to the concatenation of that leading substring with the linearization of the. rest of the two difference lists. for example  consider the linearization of the two fragments  likes mary  and ''likes jill  as shown in fig. 1 {likes mary  likes jill} which can be linearized as :-
{likes x} where x is the linearization of strings {mary. jill} 
fig. 1: example of identical leading substrings 
1. conjoining. 
the last case occurs when the two pairs of  nonempty  difference lists have no common leading substring. here  the conjoined string will be the concatenation of the conjunction of one of the pairs from the candidate set  with the conjoined string resulting from the linearization of the two strings with their respective candidate substrings deleted. for example  consider the linearization of the two sentences  john likes mary  and  bill likes jill  as shown in fig. 1 :-
{john likes mary. bill likes jill} 
given that the selected candidate pair is {john. bill}  the conjoined sentence would be :-
{john and bill x} where x 
is the linearization of strings {likes mary  likes jill} 
fig. 1: example of conjoining substrings 
       there are some implementation details that are different for parsing to generating. however the three cases arc the same for both. 
       we can illustrate the above definition by showing what linearizations the system would produce for an example sentence. consider the sentence  john and bill liked 
mary   fig. 1  :-
{john and bill liked mary} would produce the strings:-
{john and bill liked mary. 
john and bill liked mary} with candidate set {} 
{ john liked mary  bill liked mary} with candidate set { john  bill } 
{john mary. bill liked mary} with candidate set { john. bill liked } 
{john. bill liked mary} with candidate set { john. bill liked mary } 
fig. 1: example of linearizations 
all of the strings are then passed to the predicate 

s. fong and r. berwick 1 


1 s. fong and r. berwick 
c o m p a r i s o n w i t h 	m s g s 
　　the following table  fig. 1  gives the execution times in milliseconds for the parsing of some sample sentences mostly taken from dahl & mccord . both systems were executed using dec-1 prolog. the times shown for the msg interpreter is based on the time taken to parse and build the syntactic tree only - the time for the subsequent transformations was not included. 

fig.1: timmings for some sample sentences 
       from the timings we can conclude that the proposed device is comparable to the msg system in terms of computational efficiency. however  there are some other  idvantages such as :-
  transparency of the grammar - there is no need for phrasal rules such as  s -  s and s . the device also allows non-phrasal conjunction. 
  since no special grammar or particular phrase marker representation is required  any parser can be used the device only requires an accept/reject answer. 
  the specification is not biased with respect to pars-ing or generation. the implementation is reversible allowing it to generate any sentence it can parse and vice versa. 
  modularity of the device. the grammatically of sen-tences with conjunction is determined by the definition of equivalence. for instance  if needed we can filter the equivalent terminals using semantics. 
e x t e n s i o n s t o t h e b a s i c d e v i c e 
　　the device described in the previous section is a simplified version for rough comparison with the msg interpreter. however  the system can easily be generalized to handle multiple conjuncts. the only additional phase required is to generate templates for multiple readings. also  gapping can be handled just by adding clauses to the definition of linearize - which allows a different path from that of fig. 1 to be taken. 
       the simplified device permits some examples of ungrammatical sentences to be parsed as if correct  fig. 1 . the modularity of the system allows us to constrain the definition of equivalence still further. the extended definitions in goodall's draft theory were not included in his thesis  goodall1  presumably because it was not constrained enough. however in his thesis he proposes another definition of grammatically using rpms. this definition can be used to constrain equivalence still further in our system at a loss of some efficiency and generality. for example  the required additional predicate will need to make explicit use of the combined rpm. therefore  a parser will need to produce a rpm representation as its phrase marker. 
a c k n o w l e d g e m e n t s 
   this work describes research done at the artificial intelligence laboratory of the massachusetts institute of technology. support for the laboratory's artificial intelligence research has been provided in part by the advanced research projects agency of the department of defense under office of naval research contract n1-c-1. the first author is also funded by a scholarship from the kennedy memorial trust. 
r e f e r e n c e s 
bowen v.t al: d.l. bowen  ed.   l. byrd  f.c.n. percira  l.m. pereira  d.h.i . warren. decsystem-1 prolog user's manual. university of edinburgh. 1. 
dahl & mecord: v. dahl and m.c. mccord. treating coordination in logie grammars. american .journal of computational linguistics. vol. 1  no. 1  1 . 
font/  : sandiway fong. to appear in s.m. thesis -  specifying coordination in logic    1 
goodall  : grant todd goodall. draft - chapter 1  sections 1. to 1 - coordination. 
goodull 1: grant todd goodall. parallel structures in syntax. ph.d thesis. university of california  san diego  1 . 
lasnik & kupin: ii. lasnik and j. kupin. a restrictive theory of transformational grammar. theoretical linguistics 1  1 . 
