 
　　　　the performance of a new heuristic search algorithm is analyzed in this paper. the algorithm uses a formal representation  semantic representation  that contains enough information to compute the heuristic evaluation function h n   as defined in the context of a*  without requiring a human expert to provide it. the heuristic is computed by solving less constrained subproblems  auxiliary problems  of the given problem. 
the new algorithm is shown to be less efficient than the 
dijkstra algorithm  according to the complexity measure  number of node expansions.  this proves that it is not efficient to compute heuristics for a* by solving auxiliary problems with backtracking. 
basic definitions and auxiliary problems 
a syntactic problem is a 1-tupie 

where: 
n is a set of states  or nodes   called the state-space; e is a set of directed edges; 
w is a set of positive costs  greater than an arbitrary small constant  associated to each edge; i is a distinguished member of n  the initial state; k is a distinguished member of n. the final state. 
　　　　the optimal solution of a problem p is a path in the graph g =  n.e.w  from i to k of minimal cost  where the cost of a path is the sum of the costs of its 
edges. 
a semantic problem is a 1-tuple 

where: 
a is a set of attributes; v is a set of values; 
ii is a set of predicates  called properties  each indicated by  of one argument  whose domain is the set of all possible states; 
a is a set of predicates  called legal conditions  each indicated by  . of two arguments  each one being one of all possible states; i is a distinguished sequence of attribute-value pairs; k is a distinguished sequence of attribute-value pairs. 
　　　　a sequence of attribute-value pairs is called a semantic  or structured  state  or node . a semantic state has a structure: the sequence of attribute-value pairs that constitute its meaning. in the classic   syntactic  framework  instead  a state is just an atomic concept; all the information carried over from the problem domain is contained in the graph. 
the writing of this paper was supported by the air 
force office of scientific research under grant afosr-1. the paper is based on work done at the politecnico di milano  milan  italy. 
　　　　let us now consider how the structure of every semantic state is used to determine the state space and the legal moves in a semantic problem. the candidate states are all possible sequences of attribute-value pairs  indicated by a letter in italics  such as n  ; the state space  n   consists of all the candidate states which satisfy all the properties  the states in n are called legal states ; the candidate moves are ail possible pairs of legal states; the legal moves are all the moves   n1   n1   that satisfy all the legal conditions. therefore  to every semantic problem one can associate a graph called the skeleton of the semantic problem. the structure of the states is lost in passing from a semantic problem to its skeleton. 
　　　　one could solve a semantic problem by solving the problem corresponding to its skeleton with the dijkstra algorithm  but this method does not take any advantage from the extra information contained in the structure of the states. reference  valtorta  1  discusses some ways to exploit this information. one of them  algorithm m  will be discussed below. before introducing it  i present the key notion of auxiliary problem. informally speaking  a problem is auxiliary to another one if it is less constrained. 
a semantic problem 

is an auxiliary problem to 

if 

　　　　the following theorem provides a basis for computing an heuristic evaluation function  h n    as used by a* to focus its search  nilsson. 1   from the information contained in the semantic representation of a computable problem  in this paper 1 follow the convention used in  nilsson  1  in indicating the heuristic estimate with h n  and its exact value with h* n . note that h* i  is the cost of the optimal solution of p.  
         theorem. if p' is auxiliary to p  where the initial state for p' and p is n  then the length of the optimal solution of p' is a possible value for an admissible heuristic estimate h n  for the problem p. the proof is in  guida and somalvico  1 . algorithm m 
　　　　this algorithm is a special case of both algorithm g given in  guida and somalvico  1  and algorithm s in  valtorta  i1 . 

1 m. valtorta 
input: a semantic problem 
output: an optimal solution of p. 
method: solve the problem corresponding to the skeleton of p using a*  where each necessary value of h n  is computed by solving an auxiliary problem to q  using the dijkstra algorithm. q differs from p only in the initial state  which for q is n. 
all the auxiliary problems have the same set of legal conditions-a'. this ensures that the  consistency  condition  niisson  1; nilsson  1  is satisfied for h n  computed by solving the auxiliary problems to q this result is shown to hold in  valtorta  i1 . complexity of algorithm m 
         in this section  1 compare algorithm m to the dijkstra algorithm. it would be senseless to compare m to the a* algorithm  since  to focus its search  a* relies on information  i.e.  h n   that is outside the problem representation formalism used  i.e.  the syntactic graph . 
　　　　i compare these algorithms according to the criterion  number of node expansions   which is discussed and generally accepted in the published literature  nilsson  1; martelli  1 . first recall some results from  martelli  1 . 
         let a  directed  graph g =  n.e.w  be given. let g n  be the length of the path from node i  the initial node  to node n  in graph g  passing through already expanded nodes. 
         fact 1. the dijkstra algorithm will find a shortest path in g by expanding only the nodes  n  that satisfy the following inequality: 
 1  	g n  h* i . 
         fact 1. the a* algorithm will find a shortest path in g by expanding only the nodes  n  that satisfy the following inequality:  1  g n  + h n    h* i  and some of the nodes that satisfy: 
 1  	g n  + h n  = h* i . 
         define the distance from node m to node p in the graph g =  n.e.w  to be the length of the shortest path from m to p in g.  if no path from m to p exists in g  then the distance is conventionally assumed to be infinite.  the following result can be proven: 
main theorem. let a semantic problem 

be given. to solve problem p . algorithm m expands at least every node expanded by the dijkstra algorithm to solve the syntactic problem corresponding to its skeleton. 
         since the dijkstra algorithm never expands the same node twice  it follows as a corollary that algorithm m uses at least the same number of node expansions as the dijkstra algorithm. 
proof of the theorem. 
algorithm m expands nodes in two phases: 
 a  to compute h n ; 
 b  to solve p  with the a* strategy. 
　　　　i shall consider three cases  which exhaust all possibilities  and show that for each case the computation of the estimate plus the solution of the problem using it is more expensive than the solution of the problem by using the dijkstra algorithm  which does not require any estimate to be computed. 
case 1 
　　　　the estimate h n  allows node n to be expanded in phase  b . 
         the computation of the heuristic  in this case  does not allow to save even a single node while using it in phase b. since to compute h n  by solving an auxiliary problem one needs to expand at least a node  in the non trivial case in which n is the final node  when it is obviously not useful to compute the heuristic!   it would have been better not to compute the estimate at all in the first place. 
case 1 
　　　　the estimate h n  is such that n is not expanded because 
 1  	g n  + h n *h* i . 
 note that if  1  is true with      node n will not be expanded for sure; if it is true with  =   it might.  if the only effect of h n  is that node n will not be expanded  the cost of the estimate computation in phase  a   which necessitates at least the expansion of node n itself  offsets at best the saving arising from not expanding n in phase  b . 
case 1 
there are nodes r that are expanded by the 
dijkstra algorithm  but are not expanded by the m algorithm in phase  b  because  in order to be expanded  they should be reached through a node m whose estimate h m  is so large that m is not expanded in phase  b . 
         the nodes r are  at most  the ones for which the following holds: 
 1  d m r    h* i  - g m   
because d m r   the distance from m to r  plus g m   equals g r  which is bounded by h* i  by fact 1. 
　　　　by fact 1  m is not expanded if h m  is at least so large that the following holds: 
 1  h m    h* i  - g m . 
         since h m  is computed  in phase  a   by solving an auxiliary problem to p using the dijkstra algorithm  one must expand  according to fact 1  all the nodes at distance less than h rn  from m on the skeleton of the auxiliary problem. 
but we know that h m  is at least so large that 
 1  holds. therefore  at least the nodes at distance less than h* i  - g m  from m in the auxiliary problem must be expanded. a fortiori  since the distance of i to m in the auxiliary problem is not greater than the distance from i to m in p  at least the nodes at distance less than h* i  - g m  from m in pmust be expanded. 
therefore  the nodes  call them s   expanded 

by the m algorithm in phase  b  satisfy the following inequality: 
 1  d m s    h* i  - g m . 
　　　　by comparing  1  with  1   one concludes that  even in the most favorable case  the set of nodes r which are not expanded in phase  b  because of the computation of the estimate h m  in phase  a  is a subset of the set of the nodes  nodes s   expanded to compute the estimate in phase  b . 
　　　　therefore  even in this last case  it is better not to compute the heuristic at all and solve p by using the dijkstra algorithm directly. 
conclusion 
　　　　in this conclusion  i state two definitions and a 
　　　　theorem  and present an interpretation of the main theorem. 
         given that a shortest-path algorithm is blind if it does not use heuristic information  and it is unidirectional 	if 	it 	expands 	nodes 	at 	increasing distances from the initial node  the following result can be shown to hold: 
         theorem the dijkstra algorithm is the algorithm that uses the least number of node expansions among blind  unidirectional  deterministic algorithms. 
　　　　the proof of this result consists of an  adversary   or  oracle   based argument. assume that another algorithm-b  can find a shortest path from i to k without expanding a node--n  for which the following holds: 
 b  	g n    h* i  
　　　　then  the adversary can find a problem such that there is an edge from node n to node f of such a small cost that the minimum cost path from i to f 
passes through n. 
　　　　this means that the b algorithm does not find the minimum cost solution. 
the above result  together with the main 
theorem  indicates that it is not efficient to compute heuristics by solving auxiliary problems with a trial and error strategy  i.e.  a strategy involving backtracking . 
         recognizing that an auxiliary problem can be solved by means of a method that does not require backtracking seems to be an extremely difficult task  strictly related to the  change of representation  problem  amarel  1   which is considered to be beyond the state of the art.  see  for example  lenat  1  pp. 1 .  even auxiliary problems whose solutions lead to the computation of simple heuristics do not display any apparent structure  as far as their skeleton is concerned; which may lead to their simple solution. an interesting example of this phenomenon is described in  valtorta  1   where the auxiliary problem whose solutions compute the heuristic  number of misplaced tiles  for the eight-tile puzzle is presented. this heuristic is described in  nilsson  1; nilsson  1 . 
m. valtorta 1 
appendix i: related research 
　　　　work on the semantic representation  motivated by the effort to automate the computation of heuristics  was started at the politecnico di milano by marco somalvico and his assistants in the mid-seventies. 
　　　　judea pearl and the late john gashnig have discovered  independently from the milan team  that admissible heuristics for a* can be computed by solving auxiliary problems. judea pearl calls the auxiliary problems  relaxed models.  john gashnig calls them  edge supergraphs   gashnig  1 . gashnig uses the syntactic formalism and he does not propose an algorithm that finds auxiliary problems automatically  using the  semantic  formalism  as algorithm m does. 
　　　　judea pearl and dennis kibler  kibler  1  have postulated the need for changing representation paradigm to solve auxiliary problems efficiently. their postulation is grounded on the negative result discussed in this paper of which i had informed them in personal correspondence. they quote this result explicitly in their reports  pearl  1  p.1; kibler 1  p.1j. 
