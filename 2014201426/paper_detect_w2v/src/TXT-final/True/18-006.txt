 
　　we present an overview of the many control constructs and heuristics used by prolog systems with extra control facilities. two features of computations rules are used to evaluate and classify them. they are detecting failure quickly  where it is unavoidable  and avoiding failures. by examining current systems in this light  we reach conclusions concerning deficiencies in performance  and how they may be overcome. we propose an idealized computation rule which uses a hierarchy of goals and a breadth first component. 
1. introduction 
　　there are now many prolog systems with more control facilities than conventional implementations. the design of these systems has been justified by examples of how programmers can implement efficient algorithms using simple logic.  naish 1b  went a step further and showed how some control can be generated automatically in this paper  a shortened version of  naish 1a   we take a much broader view. we examine many proposed and implemented control primitives and heuristics to identify their strengths and weaknesses. we use the term control rule for these individual components of complete computation rules our attention is restricted to control rules for s'ld resolution. we hope the discussion and conclusions here will contribute to the design of logic programming systems with better control components in the future. 
   the main part of this paper introduces some general properties that we should like computation rules to exhibit. the extent to which each control rule contributes to these properties is discussed and used for a simple classification. finally  an idealized combination of control rules is suggested. first  however  we give some programming examples which will be referred to in the discussion. 
1. program examples 
   the following selection of programming examples from the literature illustrates the kinds of problems that can be solved efficiently by using a flexible control strategy. 

these procedures define the permutation relation on lists. 
 block 1  shows how difficult it is to write a definition of perm which works with either argument bound using conventional prolog. if perm is called with the second argument a variable  the execution of delete should proceed ahead of perm but if the first argument is a variable  perm should proceed ahead of delete. 


   using perm  we can write a program to solve the eight queens problem. the desirable form of control discussed most is for perm and delete to generate the list of queen positions one at a time and for safe and nodiag to test if the new queen position is safe. if the arguments in the initial call to perm are swapped  it is more efficient to delay calls to delete and = = until the end  then do the calls to delete  resuming the instantiated calls to = = at each stage. 

   this program can be used to check whether two trees have the same list of leaf tags the desired form of control is for the two calls to leaves to coroutine. whenever one further instantiates the list of leaf tags  the other should check if the newly added tag is the next tag in the other tree. either call can be the generator at each stage. this program can easily be extended to any number of trees. grandparent g  c  : parent p  c   parent g  p . 
ancestor !*  c  :- parent p  c . ancestor a  i   :--  parent p  i    ancestor a  p . 
   here we define the grandparent and ancestor procedures using parent  which we assume is defined with a collection of facts. grandparent can be used to find the grandparents or grandchildren of a given person. however  it is most efficient to reverse the calls to parent when finding grandchildren. 
   ancestor poses some rather difficult optimization problems. for finding the ancestors of someone  parent should always be called first. calling ancestor first causes an infinite loop. in fact  infinite loops can always occur if someone is their own ancestor. there are even more difficulties using the program for finding descendants. 
 naish 1a  discusses this further  
1. features of computation rules 
 1  the one obvious overriding property that we wish computation rules to exhibit is to minimize the size of the search tree. unfortunately  there are very few cases where we can even find heuristics directly related to the size of the tree. therefore  in the next two paragraphs we introduce heuristics which are reasonably general  but are useful for the design and classification of implementable control rules. 
 1  for goals which can finitely fail  computation rules should select atoms which lead to detecting failure quickly. several heuristics and some theoretical work have contributed to this area. 
 1  there is a slightly more subtle rule which applies more to goals which have solutions. although the success branches of the sld tree are fixed  the number and length of other branches is not. 

the rule  therefore  is to avoid creation of failure branches  and infinite branches  as much as possible. 
1. control rules 
   we now discuss many of control rules mentioned in the literature. they are put into three groups  according to the features mentioned above. 
1. minimizing the search tree size 
   unsurprisingly  this section is fairly small  though with more special case analysis  it could probably be expanded in the future. 
1.1. select calls which fau 
   sub-goals which match with no clauses should clearly be selected immediately. this rule was implemented in metalog 
 dincbas 1   which continually tested whether any atoms had no matching clauses. no method has yet been found for implementing this rule without significant overheads. 
1.1. select deterministic calls 
   by deterministic calls  we mean those which match with only one clause. selecting deterministic calls is optimal for goals with some solution s .  naish 1b  shows how control information can increase determinism which can be detected at compile time. we discuss this further in the section on wait declarations. 
1.1. database queries 
   given a goal consisting of calls to database procedures  which only contain facts    naish 1b  gives a formula for the number of calls needed to find all solutions. it is a heuristic  based on some assumptions about probabilities of various matches being independent  etc. this formula can be generalized to take account of the number of unifications performed  which depends on the form of indexing used  naish 1a  it can be minimized to find the best computation rule calls to large database procedures should generally be delayed until less expensive calls have been done. this generalizes the methods of  warren 1  and  stabler 1  and produces the best form of control for grandparent. 
1. detecting failure 
1.1. call tests as soon as possible 
   tests fail more often than other calls. thus  to detect failure quickly  they should be called as soon as possible. programmers generally have a good idea of what calls are tests and  naish 1b  and  naish 1a  suggest ways of recognising tests automatically. the proposed definition is that a test is a  deterministic and does not construct any variables when it is sufficiently instantiated and b  has an infinite number of solutions otherwise. one problem is that if tests are called too soon  they usually create failure branches. this is normally solved by delaying the call if certain variables are uninstantiated when they become bound  the test should be resumed quickly. 
1.1. eager consumers 
　　ic-prolog's eager consumer annotations  clark 1  can be used to call tests quickly without creating extra failure branches. placing an eager consumer annotation on some variable in a sub-goal prevents that sub-goal constructing the variable. the whole computation of the subgoal is delayed if an attempt is made to further instantiate the annotated variable. this has the unfortunate consequence of delaying instantiated tests in cases where the annotated sub-goal calls several tests. for example  if safe is made an eager consumer in the eight queens program  only one call to nodiag is called when a new queen is added. a similar problem is caused by the restriction that only one sub-goal can be a designated consumer of a particular variable. one advantage of eager l naish 	1 
consumers is the  inheritance  of the annotation to sub-terms. this is useful for the sameleaves program. 
1.1. fairness 
    lassez 1  shows that sld resolution is complete with respect to finite failure  assuming a fairness condition. depth first rules and rules for most primitives which delay calls are unfair. there are two aspects of fairness which could affect practical systems. the first concerns avoiding infinite loops and detecting failure where possible. a fair computation rule could be used when no better heuristics can be found. the second aspect concerns completeness. several control primitives can delay calls indefinitely  causing incompleteness. with a fair computation rule  all calls would be done eventually. 
1.1. breadth first 
   the simplest way to ensure fairness is to use a breadth first computation rule usually  generators and tests produce and consume  respectively  data structures at similar rates. typically  one level of recursion corresponds to one level of functor nesting. this implies that a breadth first rule would have a fairly small delay between generating and testing  so failures are found relatively quickly unfortunately  a strict breadth first rule is very poor at avoiding failure  especially when tests are called before generators. 
1.1. pseudo parallelism 
   ic-prolog's // connective has a declarative reading of  and   but the two  or more  sub-goals it connects are computed in pseudoparallel. the computation rule alternates between selecting atoms from each of the different sub-computations. the same control has also been used as an example of the power of the meta-interpreter approach to control used by two-level prolog  porto 1   if // is used for all and-connectives  the result is a fair computation rule. however  if one sub-computation is a generator and the other contains several tests  the execution of the tests tends to lag behind the generator. 
1.1. avoid left recursion 
   this is a goal ordering heuristic  suggested for mu-prolog in  naish 1b . actually  left recursion is desirable in some situations  such as perm in our alternative eight queens example. the problem is that left recursion is a pathological case for failure detection with a depth first rule  which most current systems use. with a breadth first control rule  failure detection is improved and left recursion is not a problem. 
1. avoiding failure 
1.1. freese 
   the main reason for delaying sub-goals in prolog is to avoid creating failure branches and there are very many primitives which enable this. the simplest is geler  freeze  of prolog ii 
 colmerauer 1 . freeze is used to delay a sub-goal until a particular variable is bound to a non-variable because it only delays a single call  the eight queens can be made more efficient than with eager consumers  though freeze is needed for four different sub-goals. however  because the control is not inherited to sub-terms of the variable  the same leaves program cannot easily be made efficient. also  because freeze only waits for one variable  it is less useful for multi-use procedures and cannot make perm work in both ways. 
1.1. lasy producers 
   ic-prolog's lazy producers provide a powerful method of avoiding failure and  to a lesser extent  detecting failure. a lazy producer annotation on a variable in a sub-goal prevents all other calls from constructing the variable. when another call attempts to construct the annotated variable  that call is delayed. the producer is then executed until it binds the variable  then the delayed call is resumed. the choice of which call is resumed does not help avoid 

1 l. naish 
failure but  if the call is a test  the choice helps detect failure. this overlaps with the control provided by eager consumers and means that coroutining between a generator and multiple tests is still difficult to implement 
1.1. walt declaration! 
　　under this heading  we include the wait declarations of muprolog  naish 1b  and the algorithm used for generating them automatically  naish 1b . we believe it is a major contribution to avoiding failure. the effect of wait declarations is local  like freeze  but they can be used to delay a call until one of several argument sets is sufficiently instantiated. this added flexibility makes it possible for procedures such as perm to work in multiple ways. the heuristic also produces the best form of control in goals like the following. the failure producing subgoals  safe  nodiag and perm  are delayed by automatically generated wait declarations whereas delete is not. 
  safe l   nodiag n  1  l   perm z  l   delete n   1 1 1 1   z . 
   automatically generated wait declarations also interact very favourably with the rule for selecting deterministic calls first. with the eight queens program  calls to all procedures except delete are forced to be deterministic and this can easily be detected by a preprocessor. using this information  our alternative eight queens control can be automated. however  there are situations where generated wait declarations delay calls unnecessarily or where wait declaration cannot be generated at all  such as ancestor . both these problems can be overcome by fairness the calls should just be given a very low priority  rather than being delayed indefinitely or not handled at all. with this control  parent would always be called before ancestor. 
1.1. delaying system predicates 
   in ic-prolog  partially instantiated calls to system predicates such as   act as generators  often creating failure branches. in muprolog  they delay instead  allowing our alternative eight queens control. for completeness  it would be preferable for the system tests to be called eventually  if possible. 
1. discussion 
   with most systems  the methods available for avoiding failure are not flexible enough. to delay the calls which create failure branches  other calls must be delayed also. this is manifest is two ways. firstly  ic-prolog delays whole sub-computations. secondly  most primitives only allow sub-goals to wait for a single variable to be bound  even though many procedures can work efficiently consuming several different subsets of their arguments. wait declarations are an exception. they only delay single calls and are flexible enough to enable multi-use procedures partly because of this  they can also be generated automatically the deficiencies in the algorithm can be partially compensated for by having a fair computation rule  so calls delayed by wait declarations are still done eventually. 
   there are also other deficiencies with failure detection  despite this being well understood. because of delaying whole subcomputations and the single eager consumer limitation in icprolog  failure detection is impaired when multiple tests are needed. with other systems especially  multiple  potential  generators  such as the same leaves program  are not handled well. left recursion also causes problems. both these areas can be improved by using a breadth first rule. this performs slightly worse than a more controlled coroutine approach but requires do programmer intervention. 
   our idealized system has three major features. firstly  calls which are likely to create extra failure branches are delayed. secondly  other calls which are likely to fail are called first. thirdly  the computation rule is fair  so even calls likely to create failure branches are called eventually. we propose a hierarchy of calls as follows: 
 1  tests. 
 1  other deterministic calls. 
 1  nondeterministic calls. 
 1  calls to database procedures. 
 1  calls to procedures for which wait declarations cannot be generated. 
 1  calls delayed by wait declarations.  1  delayed calls to system predicates. 
   the optimal order in which to call the database procedures can be determined and other types of calls should be done in a breadth first manner  for failure finding and fairness. furthermore  it is desirable that a lower priority call be done after some number of calls  say 1  of the next higher priority  to ensure fairness. 
1. conclusions 
   current prolog systems with extra control facilities have been designed in a fairly ad hoc manner  relying mostly on a few example programs. we have introduced some more general principles on which control rules can be judged. this shows the weaknesses and strengths of current control rules more clearly and should be of use in designing future systems which further exploit the advantages of flexible control strategies. 
1. 