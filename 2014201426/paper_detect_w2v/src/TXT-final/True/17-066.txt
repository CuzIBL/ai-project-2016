 
　　the paper presents a novel expert system architecture which supports explicit representation and effective use of both declarative and procedural knowledge. these two types of expert knowledge are represented by means of production rules and event-graphs respectively  and they are processed by a unified inference engine. communication between the rule level and the event-graph level is based on a full visibility of each level on the internal state of the other  and it is structured in such a way as to allow each level to exert control on the other. 
this structure offers several advantages over more traditional architectures. knowledge representation is more natural and transparent; knowledge acquisition turns out to be easier as pieces of knowledge can be immediately represented without the need of complex transformation and restructuring; inference is more effective due to reduced non-determinism resulting from explicit representation of fragments of procedural knowledge in eventgraphs; finally  explanations are more natural and understandable. 
the proposed architecture has been adopted for the design of prop  an expert system for on-line monitoring of the cycle water pollution in a thermal power plant. prop is running on a sun-1 workstation and has been tested on a sample of real cases. 
introduction 
     the artificial intelligence community has been successfully applying  since the mid-seventies  new powerful rulebased techniques to applications that could not be faced with more traditional approaches. in fact  the complexity of any classical solution was so evident as to discourage their use from the beginning. 
rule-based system technology  hayes-roth  waterman  and 
lenat  1  has offered a basic advantage over traditional programming: it has enabled the programmer to tackle problem solving at a higher level of abstraction and in a more flexible and natural way. the usual activities of problem analysis  invention of a solution algorithm  and programming are replaced in the expert system approach by the representation of knowledge about the application domain  including available resources  constraints  and problem solving skills   of the specific problem to be solved  and of the goal to be achieved. responsibility about how to use knowledge in order to solve the problem is left to the system  and the programmer only has to represent what is known about the problem and is likely to be relevant to its solution. the new concept of knowledge-based problem solving appears  therefore  as another way of programming  
 +  also with universita* di milano  isituto di cibernetica  milano  italy 
this research has been supported by enel-dsr  ente nazionale per 1'energia elettrioa - diresione studi e ricerche . suitable to large classes of challenging application domains  where  on the other hand  usual programming methods fail. 
　　a major reason for the success of expert system technology is the way knowledge on the problem domain can be represented to the system. this offers in fact several highly desirable features  such as: 
ability to represent knowledge in a highly declarative way  without bothering about its use; possibility of describing fragmentary  ill-structured  approximate  uncertain  heuristic knowledge  that is often of crucial importance in applications; possibility of incrementally creating  debugging  and updating very large knowledge bases. 
　　these features have made rule-based systems a real success in all those application domains where knowledge involved is mainly declarative and fragmentary in nature  buchanan and duda  1 . 
the wave of such successes  as well as increasing interest in the industrial world  has led artificial intelligence researchers to tackle new classes of problems where  in addition to declarative and fragmentary knowledge  a lot of well structured chunks of procedural knowledge is naturally available and has to be represented and used  friedland  1 . consider  for example  such areas as decision making  fault detection and diagnosis of complex systems  sensory data interpretation  monitoring of industrial processes  etc. in these cases  it would be foolish to disperse the available procedural knowledge into a flat declarative representation. in fact  this would be costly and heavy with respect to knowledge acquisition  as it implies complex fragmentation and coding of knowledge. moreover  it would cause a serious overload of the inference mechanism with the additional 
task of reconstructing  through a heavy non-deterministic search process  the correct procedural constraints between scattered fragments of knowledge. finally  it would make the explanation mechanism of the inference engine very oompiex  quite unnatural  and practically useless. 
　　it is evident that  for a number of applications where the classical rule-based system paradigm is not fully adequate  a new mechanism is needed  which can combine the structured coding of procedural knowledge proper of traditional programming with the declarative representation typical of a pure rule-based system. 
　　the issue of representing and using procedural knowledge in rule-based systems has been widely addressed in recent years in the frame of the studies about metaknowledge  davis  1a  1b; georgeff  1; genesereth  1; d'angeio  guida  pighin  and tasso  1 . but the focus of attention is here more on the procedural aspect of control knowledge rather than on a fusion of procedural and declarative representations both at meta-level and domain level. 
this topic has been only recently addressed in a neat way in 
1 	m. gallanti et al. 
 georgeff and bonollo  1 . their approach combines explicit representation of fragments of procedural knowledge with a mechanism for pattern-directed invocation  both goal-directed and data-driven . this approach allows effective solution of a class of practical problems  specially of consultation type  and discloses the challenging issue of heterogeneous knowledge representation in the design of expert system architectures. 
　　the purpose of the work reported in this paper is the development and experimentation of a new approach to the integration of rule-based mechanism and computation according to procedural knowledge  that can meet the following goals: 
effective and natural representation of pieces of procedural knowledge by means of a powerful and general language; use of production rules for representing declarative knowledge; integration of the two components into a unitary inference mechanism. 
　　this research effort yielded to the proposal of a novel expert system architecture that has been tested in the design and implementation of prop  an expert system for malfunction diagnosis and process surveillance concerning on-line monitoring of water pollution in a thermal power plant. 
　　the purpose of this paper is to introduce and discuss the main features of the new proposed architecture and to illustrate the results obtained in a practical application. the general organization of the proposed expert system paradigm is first introduced and compared to related works. afterwards  the application addressed is briefly described  and the specific architecture of the implemented expert system is illustrated. examples of prop operations are presented. finally  research results are critically evaluated and possible extensions of the proposed approach are outlined. 
production rules and event graphs 
　　the general architecture of the novel expert system paradigm we have developed is shown in figure 1. it comprises two knowledge bases  namely a rule base and an event-graph  base. the former is used to contain declarative knowledge expressed by means of usual production rules  while the latter embodies procedural knowledge represented through event-graphs. 

figure 1 - basic system architecture 
　　the notion of event-graph shares several features with the petri net formalism  reisig  1 . 
we disregard here the formal definition of an event-graph and only focus on its basic expressive features. 
an event-graph  eg  is a directed graph with two types of nodes  namely places and events  and a marking concept. nodes termed places are graphically represented as circles and nodes termed events are graphically represented as boxes. directed arcs can only connect nodes of different type. events are labeled with two expressions  specifying a condition and an action respectively. a sample eg is shown in figure 1. 

figure 1 - a sample event-graph 
a place can contain a mark; an eg can have an arbitrary number of marks: the set of all marked plaoes defines the current marking of the eg. for example  the current marking of the eg in figure 1 is {p1  p1}. an initial marking is defined for each eg. 
　　an event is enabled if all its ancestor places  called the input places  are marked. an event can fire  i.e. it is active  if it is enabled and its condition is true. 
we define as current conditions of an eg the set of conditions labeling the enabled events. for example  the current conditions of the eg in figure 1 is {c1}. an eg is active   resp.  enabled   if at least one of its events is active  resp.  enabled . firing an event means unmarking its input places and marking all its successor places  called the output places. firing an event also causes the execution of the action specified in the event. current marking thus evolves by means of event firing. 
we stress that the concept of event-graph embodies a static and a dynamic part. the static part  i.e. the definition of places  arcs  and events with conditions and actions  plus the initial marking   represents the code of a chunk of procedural knowledge. the dynamic behaviour of an eventgraph is represented by the sequence of current markings that the event-graph goes through as a consequence of successive event firing. thus  the static part of an event-graph may be aotivated in different contexts and produce several images corresponding to different current markings  similar to a re-entrant procedure which can be executed several times in parallel with different parameters. 
     two data bases  db1 and dbs  are available to the system to be used by egs and rules. they contain knowledge on the current state of the inference process and also constitute the link between the system and the external world  user  environment  etc. . as they can accept input data and produce output messages. data bases db1 and db1 are first 

initialized with information coming from outside  initial problem description . a modified recognize-act cycle is then entered  which is controlled by the achievement of a goal condition. this cycle comprises two phases   see figure 1}   1   event-graph level phase: 
　　egs are first matched with the content of dbl. the set of enabled egs is determined and conflict resolution is performed. the current conditions of selected  enabled  events of egs are then matched with the content of dbl and the set of active egs is determined. conflict resolution is performed again. all selected  active  events are eventually fired in parallel  and the corresponding actions are executed on dbl and db1;  rule level phase: 
　　rules are first matched with the content of db1. the set of active rules is then determined and conflict resolution is performed. selected rule/s is/are eventually executed on db1 and dbl. initialize vb1 and vb1 
repeat 
 event-gn.aph level 	pha1e  match. event-graph base with vb1 and determine enabled event gnaphs resolve 	conflict 
match selected event-graphs with vb1 and determine active  event-graphs re*olve conflict 
fire all active events and exacute relevant actions on dbl and db1 
	 rule 	level 	pha*e  
match rule ba*e with db1 and determine conflict set resolve conflict execute selected rule/s on vb1 and vb1 
until 	goal 	condition 
figure 1 - basic mode of operation of the inference engine 
　　the architecture above sketched is very general. both levels can contain representation of domain knowledge and meta-knowledge  and both dbl and db1 can embody knowledge on the problem and control knowledge on the problem solving strategy. the rule base can be organized according to any of the usual structuring techniques  such as partitioning  meta-rules  etc. also the event-graph base can be given arbitrarily complex structure by defining relations among egs. 
both the event-graph and rule levels maintain in their own data base  dbl and db1 respectively  the information needed for their operation  computation and deduction respectively . whenever some information has to be shared by the two levels it must be duplicated in the two data bases. 
each of the two levels can exert control on the other: rules can influence the operations of event-graphs by forcing  
	m. gallanti et al. 	1 
conditioning  or suspending their activation through modifications of the current markings stored in dbl; on the other hand  egs actions can change the conditions for matching rules by modifying the content of db1. 
　　the novel expert system paradigm above introduced embodies the features of usual rule-based paradigm as well as the ones proper of imperative programming languages. the most relevant contribution of our approach is the definition of an environment where these two components can naturally cooperate in a problem solving task. in this respect  it shares some characteristics with the work of georgeff and bonollo  1   but it also includes several new points: 
the visibility of the system on pieces of procedural knowledge is not limited to input/output information  procedural abstraction ; specific mechanisms are provided to access the internal state and influence the dynamic behaviour of egs; the design of the right dimension of pieces of procedural knowledge is not a critical point as intermediate results of partial eg computations can be accessed and used  note that generally too small fragments tend to reduce the advantages of having explicit representation of procedural knowledge  while too large chunks imply the possibility of long  useless computations  as once a procedural area is entered its interruption causes the loss of all intermediate results ; representation and use of declarative knowledge is not limited to the invocation part of a knowledge area. 
problem analysts and system specifications 
　　in this section we focus on the problem of on-line monitoring of water pollution in a thermal power plant that has been used as a testbed for the new expert system architecture introduced in the previous section. 
　　the usefulness of artificial intelligence techniques for assisting and advising the operator of a power plant in case of accidents has already been stressed in  nelson 1  and  underwood 1 . our problem  even if it is not concerned with plant safety  lies in this application area. the aim of the system is to avoid damages to critical subsystems of the power plant and to limit plant unavailability caused by chemical agents  by means of early fault detection and diag-
nosis  and appropriate intervention. 
　　a simplified schema of a thermal power plant is given in figure 1. in order to ensure the correct operation of the plant and to preserve the materials constituting some critical subparts  the cycle water must be kept as pure as possible. in fact  possible pollutants dissolved in the cycle water 

figure 1 - semplifled schema of a thermal power plant 

1 	m. gallanti et al. 
may react with the plant in different ways  mainly at high temperature  giving both oxidation products and acids that can damage the tubes  the walls of the boiler  and the rotating parts of the turbine. 
　　therefore a chemical treatment subsystem  cts  is included in the plant and is used by a human operator to clean the cycle water whenever it is affected by some pollutant. the cts includes two different kinds of filters: 
the mixed bed  containing ion exchange resins  that operates a chemical filtering; the pre filter and the powdex  containing cellulose and pulverized resin respectively  that remove oxides through a physical filtering. 
the insertion level of the filters is regulated by the operator depending on the nature and quantity of the pollutants in the water. 
pollutants of different kinds can enter into the cycle: 
marine or river water carrying salts and sand  through the condenser ; air  in particular  oxygen and carbonic dioxide ; cellulose and resins released by the cts itself. 
　　pollution phenomena are controlled by continuous measuring of several chemical parameters  total conductivity  acid conductivity  oxygen concentration  etc.  at several points of the cycle  see figure 1 . 
　　the control equipment currently installed in the plant can automatically open the valves that by-pass the critical subsystems  e.g.  boiler or turbine  when one of the above mentioned chemical parameters at a single measurement point increase beyond a fixed threshold level  in order to avoid immediate damage. the task of the operator is to prevent the pollution reaching this limit situation by properly activating the cts as soon as some sensors show abnormal values. in fact  when a limit situation occurs  some components of the plant may have already been damaged  and  in any case  the by-pass of a critical subsystem causes a significant loss of power. 
during working time the chemical staff can advise the operator on the most appropriate actions to be taken to control an incipient pollution phenomenon; during the night  week-end  and holidays the operator must follow the instructions in a handbook. 
　　the operative procedure above described has often proved to be unsatisfactory for several reasons: 
the operator usually guesses that a pollution phenomenon is occurring only when the sensors show highly abnormal values  so that the corrective action is not as timely as it should be. 
sometimes  the presence of a pollutant can be detected only by correlating the temporal trends of different parameters. these correlations require expertise not available to the operator. 
the operator is inclined to reason in terms of short time effects. therefore  he often underestimates slight pollutions that  however  can generate long term damage. 
when the operator has to manage situations without the advice of the chemical staff  he is often in trouble as the procedures specified in the handbook are too simple and schematic and turn out to be be useless in complex cases. 
　　in order to face these problems  we have investigated the possibility of using a computer-based system that can acquire chemical parameters from the sensors on the plant and give advice to the operator. a preliminary analysis of the knowledge required to recognize abnormal situations  identify the kind of pollutant  and suggest the proper intervention has shown that expert system methodology can be more advantageous than traditional approaches. 
　　this led to the design and implementation of prop  a real time expert system that can assist the cts operator. prop directly acquires data from the plant through sensors at a fixed time rate. these measurements concern general information on the plant  e.g.  flow rate  etc.   chemical parameters  e.g.  acid conductivity  oxygen concentration  etc.   and states of some subsystems  e.g.  mixed bed insertion  de-aerator valve position  etc. . moreover  through the keyboard  the operator can introduce further information that cannot be directly acquired by sensors  e.g.  results of off-line chemical analyses  etc. . 
as soon as an anomaly is detected  prop displays a set of hypotheses on the operator console  that can explain the malfunctioning. afterwards  the system keeps the evolving situation under control  tries to focus on the most plausible hypothesis  and suggests proper interventions. after the situation has been brought to normality  prop closes the diagnosis/intervention session  informs the operator as to the success of the undertaken interventions  and resumes normal monitoring activity. 
knowledge representation 
　　expert knowledge involved in the problem illustrated in the previous section can be organized at three different levels. the human expert uses  in fact  three kinds of knowledge: each of them is involved in a particular class of activities. 
data interpretation level 
it comprises the techniques that make the expert able to collect and analyze information about the behaviour of a large number of chemical and state parameters and to derive a representation of the state of the plant from the point of view of cycle water pollution. in other words  it contains knowledge about how to observe the plant in order to translate parameter values and trends into symbolic  higher level conceptual representation. a data interpretation activity is  for example  the early perception of an alarm condition detected by correlating a fast power decrease with a smooth rise  after a definite time interval  of the acid conductivity measured before the de-aerator. 
   such reasoning can be carried out only by paying attention to a restricted set of the available signals and parameters  with a precise concept of what one is looking for. the human expert is able to carry out a rather large number of different data interpretation activities and to choose the right one taking into account the current state of his hypotheses and expectations. diagnosis /intervention level 
it comprises the techniques currently utilized for fault diagnosis  i.e. for recognizing one or more of the possible pollution causes and for performing appropriate recovery actions. each diagnosis/intervention activity describes the hypotheses  expectations  and actions that relate to a specific pollution situation. it specifies which data interpretation activities have to be started  and how their results have to be evaluated in order to validate  or reject  a certain diagnosis. 
the confirmation of a suspected condenser leakage and the control of the leakage propagation along the plant are  for example  the tasks of two diagnosis /intervention activities. 
control level 
when an abnormal situation is detected in the plant  the expert formulates a number of hypothetical diagnoses. each of them can be validated or rejected by means of a diagnosis/intervention activity  and all of these tasks must be carried on in parallel. in a given instant the state of each diagnosis /intervention activity and the results  though partial  of each related data interpretation activity give an image of the state of the plant from the point of view of a hypothetical diagnosis. before a single diagnosis is definitely ascertained or when concurrent pollutions take place  the expert has to manage relationships and conflicts among all the active diagnosis/intervention activities. moreover  successful results achieved by a specific diagnosis/intervention activity are often detrimental to other ones. in general  in dealing with complex situations  chunks of information concerning the state of several diagnosis/intervention activities are to be compared. 
for example  a diagnosis/intervention activity which is concerned with propagation of a condenser leakage must inhibit consideration of all the diagnosis/intervention activities that assume a fault in a subsystem that is located further down the condenser in the cycle  e.g.  powdex  de-aerator  etc. . 
the human expert carries out this crucial control task by means of strategic knowledge  that makes him able to activate  deactivate  privilege  and influence the diagnosis/intervention activities necessary to globally diagnose and control the behaviour of the plant. 
data interpretation and diagnosis/intervention activities can be easily expressed in a procedural language. they can  in fact  be naturally seen as pieces of procedural knowledge: 
data interpretation activities are procedures that specify a sequence  with selections and iterations  of elementary observations of the plant; diagnosis /intervention activities are higher-level procedures that comprise as elementary steps the invocations and consultations of a number of data interpretation activities. 
a main point is that the dynamic behaviour of such procedures must be easily observed and influenced from outside. procedures are important here not only for the results they can compute  but specially for the intermediate computations they perform. the diagnosis/intervention level works on the behaviour of the data interpretation activities  and the control level must exert its influence on both diagnosis/intervention and data interpretation activities. 
　　expert knowledge that deals with time  which is of crucial importance in on-line applications  has an explicit role in our application at the data interpretation level only. in fact  experts explicitly refer to time relations only when they describe the procedures they use for observing the behaviour of the plant. the procedural nature of data interpretation level knowledge makes it easy to represent such temporal statements explicitly as time interval measurements. 
　　control knowledge is more declarative and fragmentary in nature. it can be represented by means of production rules to be used in a non-deterministic way. 
　　the knowledge analysis above developed can be usefully compared to the approaches of nii  feigenbaum  anton  and rockmore  1  on hasp/siap  of kahn  1  on mud  and of hudlicka and lesser  1  on fdd. 
　　we believe that the model above introduced for the analysis of knowledge involved in the diagnosis of cycle water pollution of a thermal power plant embodies several features of general significance. it could easily be applied to a large class of tasks concerning real-time fault detection  diagnosis  and intervention in complex systems. 
m. gallantiet al. 1 
prop architecture 
　　now we can merge the knowledge analysis above developed with the general architecture proposed. 
　　the procedural knowledge of the data interpretation and diagnosis/intervention levels can be properly represented in the event graph-base as a collection of independent egs. though data interpretation and diagnosis /intervention egs have the same syntactic representation  their events are labeled with expressions of two different languages: 
expressions appearing in data interpretation egs must be evaluated with respect to chemical and state parameters acquired from the sensors  stored in dbl . or with respect to time intervals. a condition referring to a time interval starts a counter the first time it is evaluated and it remains false until the time interval has expired. 
　　expressions of diagnosis/intervention egs  on the other hand  refer to the markings of data interpretation egs. current markings of egs are represented in dbl and duplicated in db1 inuch a way as to be explicitly and directly accessible by the rule level .too. the evaluation of a condition bound to an event of a diagnosis /intervention eg that refers to a not yet enabled data interpretation eg causes its enabling  i.e. the places in its initial marking are marked. therefore  a data interpretation eg has a current marking for each diagnosis /intervention eg that uses it. this represents the capability of the system to exploit  in an independent way  a single data interpretation procedure in different contexts. 
both eg base and dbl are naturally partitioned. in fact  it must be possible to distinguish data interpretation egs from diagnosis /intervention ones in the eg base and each of the independent markings of the data interpretation egs in dbl. 
　　control level knowledge fits in the rule base. it is represented by production rules whose conditions and actions refer to markings of both data interpretation and diagnosis/intervention egs. 
moreover  a credibility value is defined for each active diagnosis/intervention eg. it represents the promise for the eg to be most appropriate  up to the moment  for explaining the ongoing phenomenon and for suggesting the right actions on the plant. the maintenance of the credibility values is provided by the control level. they are used in conflict resolution activities. 
　　as eg markings and credibility values seem to be the only information required by the control level in our particular applicatioa we have merged in the implementation dbl and db1 into a single data base. this simplifies and speeds up system operation without loss of power  in fact  as pointed out above  in our application declarative knowledge has a controlling role only. 
an example 
　　prop has been implemented in franz lsp on a sun-1 workstation at cise laboratories and it has been tested on recorded patterns comprising a wide variety of different operating situations. a pilot on-site installation of prop is presently being developed. 
　　this section illustrates a few examples of prop operation. for easier understanding the examples are reported in a simplified way. 
　　the examples refer to the diagnosis of pollution arising in the condenser. to detect this kind of anomaly as soon as it occurs  the human expert must focus on the set of chemical parameters measured around the condenser. in 1 	m.gallanti et al 
particular  the increase of the acid conductivity between the condenser inlet and outlet must be considered a significant event. therefore a data interpretation activity  condenser-control  concerning chemical parameter trends in the condenser has been defined. acid conductivity increase beyond the normal level is an elementary observa-
tion included in this data interpretation activity. when such an event occurs  the human expert realizes that a pollution from the condenser is likely to take place  and he immediately defines some objectives that will support his successive observations and suggests proper corrective actions. the main objectives considered in this situation are reported below: each of them is represented in prop by a diagnosis/intervention activity  mentioned in parentheses : control of the pollution trend in relation to the intervention undertaken to remove the cause of pollution 
 condenser-leakage ; 
control of the pollution propagation along the plant  in particular towards the boiler  and reduction of the pollution effects by means of insertion of cts filters  condenser-leakage-propagation ; detection of the kind and source of pollution. in fact  pollution can be due to cooling water  coolingwater-leakage   to air contamination from condensate pumps  air-contamination   or to impurities of make-up water  pollutant-from-make-up-water . 
figure 1a illustrates the eg representing the condenserleakage diagnosis/intervention activity. events are labelled here with conditions only. the general form of a condition is a logical expression involving predicates of the type:   data-int-act-name  in  place-name    that is true if  at evaluation time  the place  place-name  in the data interpretation eg  data-int-act-name  is marked. when the condenser-control data interpretation activity has a mark in the place leakage-detection  the places in initial marking  first-rise  of the condenser-leakage eg are marked. 

the evolution of the diagnosis/intervention activity according to the condenser-leakage eg depends on the following events: 
 1  the ratio between acid conductivities at condenser inlet and outlet becomes stable  steady . in this case the pollution is assumed to have reached a defined value. 
 1  the ratio between acid conductivities at condenser inlet and outlet shows a peak  i.e.  the acid conductivity suddenly increases and then rapidly comes back to normal values  normality . 
 1  the acid conductivity keeps a steady value for a while and then decreases as a result of an appropriate intervention  but without reaching a normal value  decremented . 
 1  pollution comes back to normal values  normality . 
 1  pollution increases again  new-rise . 
when the place first-rise of the condenser-leakage 
eg is marked  events e1 and e1 are enabled. the data interpretation activities condensate-par-trend and condensate-par-value are started. event el will fire when the condensate-par-trend eg has the ac1nd1steady place marked and event e1 has not yet fired. 
　　in figure 1b we show the the condensate-par-trend eg. this eg verifies whether the acid conductivity increase measured at the condenser outlet has reached an abnormal value moreover  it checks the oxygen concentration variation during the conductivity increase. as mentioned above  this data interpretation activity is used to verify the condition c1 of event el in the condenser-leakage eg. other information given by this eg  e.g.  check of the oxygen increase  is used by control level rules  rule-1 - see below . 
　　predicates of data interpretation egs are evaluated with respect to an object oriented organization of the acquisition buffers and of the low level numerical programs  


figure 1a - condensate-leakage event-graph 	figure 1b - condensate-par-trend event-graph 

i.e. average and derivative calculations  etc. this choice was made to increase system flexibility in the interface with either a possible simulation environment or an operational one. a complete description of this representation schema is beyond the aim of this paper  so that a rather free predicate calculus-like notation is adopted in the eg of figure 1b. most of the expressions that label events in the condensate-par-trend eg are self-explanatory. in addition  we point out the following: 
an action  setting the local variable 'previous-acondl'  is associated with event e1. in the other events the action field is empty. 
in events e1  e1  and e1  the evaluation of the predicates c1  c1 and c1 involves a call to a numerical program that computes the average slope on a specified time interval. 
in events e1 and e1 the predicates c1 and c1 specify the difference between values of a parameter in two different instants. 
the function  query   in event e1 means that prop will ask to the human operator the values necessary to compute the truth value of condition c1. 
some examples of rules defined at the control level are shown in figure 1. 
in the action side of rule-1 the enabling of two diagnosis/intervention activities is defined these diagnosis/intervention activities are enabled in order to investigate the pollution source: the former  air-fromcondenser  verifies whether air contamination  for example from a condensate pump  is present  the latter  pollutant-from-make-up-water  considers impurities coming from the make-up water 
rule-1 
＼1 
codenser-leakage in steavv and 
condensate-par-ternds invoked-by condenser-leakage in oxygen-verified 
then enable air-from-condenser enable pollutant-from-make-up-water 
rule-1 ii 
condenser-leakage in active and 
pollutant-from-make-up-water in wait-confir-
mation and 
air-from-conpenser in verified 
then 
deactivate. pollutant-prom-make-up-water 
figure 1 - examples of rules 
	m. gallanti et al. 	1 
the premise of rule-1 is satisfied if; 
the condenser-leakage diagnosis/intervention aotivity has been enabled and it verifies that the pollution level has stopped increasing  that is  its eg has the place steady marked; the condensate-par-trends data interpretation activity activated by the condenser-leakage diagnosis /intervention activity verifies an increase of oxygen concentration. 
note that the two diagnosis/intervention activities enabled by rule-1 are concurrently involved in the explanation of the same phenomenon. the management of the results obtained from these two different points of view is accomplished by means of other control level rules  with the aim of definitely validating one hypothesis and rejecting the other. 
　　for example  rule-1 disregards the hypothesis that the pollution is due to the make-up water  deactivate pollutant-from-make-up-water  because  in the mean time  the hypothesis of air contamination from the condenser  air-from-condenser  has been verified  its verified place is marked . this takes place even if the 
pollutant-from-make-up-water eg cannot yet give definite results as it is still waiting for the firing of some of its events. 
conclusions 
　　the work done with prop has allowed definition and testing of a novel rule-based system architecture supporting heterogeneous knowledge representation. the proposed approach is expected to offer three major advantages: 
the knowledge representation mechanism constituted by the fusion of production rules and event-graphs makes knowledge acquisition more effective and easy 
and knowledge organization more transparent and natural; non-determinism is limited to those aspect of the problem domain which actually imply non-deterministic operation  and is not used extensively thus overcoming fictitious search problems deriving from a poor knowledge representation schema; explanation capability can closely follow the path of human reasoning  as a consequence both of the naturalness of knowledge representation and of the constrained non-determinism of the inference process. 
　　the research has disclosed several new issues to be considered in future work. among these we stress the extension of the proposed architecture to include explicit representation of the communication net connecting heterogeneous knowledge chunks  davis and smith  1   thus overcoming the limitations of the simple communication schema currently adopted. moreover  explicit temporal reasoning  credibility values computation and propagation  and the implications of the proposed architecture on meta-level structure are going to be investigated. 
acknowledgments 
　　the construction of the knowledge base of prop has been possible thanks to the experts of several enel departments  construction  operation and research & development departments  who have cooperated with cise in the frame of an internal enel working group. we are indebted to the above departments for the support and contribution offered. in particular  we would like to thank giovanni quadri of enel-dco  flavio bacci of enel-dpt  and raffaele pascali of enel-dsr. 

1 	m. gallanti et al. 
