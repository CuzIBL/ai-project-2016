 
in combinatorial auctions  multiple goods are sold simultaneously and bidders may bid for arbitrary combinations of goods. determining the outcome of such an auction is an optimization problem that is np-complete in the general case. we propose two methods of overcoming this apparent intractability. the first method  which is guaranteed to be optimal  reduces running time by structuring the search space so that a modified depth-first search usually avoids even con-
sidering allocations that contain conflicting bids. caching and pruning are also used to speed searching. our second method is a heuristic  market-based approach. it sets up a virtual multi-round auction in which a virtual agent represents each original bid bundle and places bids  according to a fixed strategy  for each good in that bundle. we show through experiments on synthetic data that  a  our first method finds optimal allocations quickly and offers good anytime performance  and  b  in many cases our second method  despite lacking guarantees regarding optimality or running time  quickly reaches solutions that are nearly optimal. 
1 	combinatorial auctions 
auction theory has received increasing attention from computer scientists in recent years.1 one reason is the explosion of internet-based auctions. the use of auctions in business-to-business trades is also increasing rapidly  cortese and stepanek  1 . within ai there is growing interest in using auction mechanisms to solve distributed resource allocation problems. for example  auctions and other market mechanisms are used in network bandwidth allocation  distributed configuration design  factory scheduling  and operating system memory allocation  clearwater  1 . market-oriented programming has 
1
  funded in part by darpa under the coabs program  contract #f1-c-1. 
1 	distributed ai 
been particularly influential  wellman  1; mullen and wellman  1 . 
   the value of a good to a potential buyer can depend on what other goods s/he wins. we say that there exists complementarity between goods to bidder b if  where is the utility to 
h of acquiring the set of goods g. if goods g and  were auctioned separately  it is likely that neither of the typically desired properties for auctions-efficiency and revenue maximization-would hold. one way to accommodate complementarity in auctions is to allow bids for combinations of goods as well as individual goods. generally  auctions in which multiple goods are auctioned simultaneously and bidders place as many bids as they want for different bundles of goods are called combinatorial auctions1. 
　it is also common for bidders to desire a second good less if they have already won a first. we say that there exists substitutability between goods g and h to bidder b when  a common example 
of substitutability is for a bidder to be indifferent between several goods but not to want more than one. in order to be useful  a combinatorial auction mechanism should provide some way for bidders to indicate that goods are substitutable. 
   combinatorial auctions are applicable to many realworld situations. in an auction for the right to use railroad segments a bidder desires a bundle of segments that connect two particular points; at the same time  there may be alternate paths between these points and the bidder needs only one  brewer and plott  1 . similarly  in the fcc spectrum auction bidders may desire licenses for multiple geographical regions at the same frequency band while being indifferent to which particular band they receive  milgrom  1 . the same situation also occurs in military operations when multiple units each have several alternate plans and each plan may require a different bundle of resources. 
1  auctions in which combinatorial bidding is allowed are alternately called combinatorial and combinational. 

　while economics and game theory provide many insights into the potential use of such auctions  they have little to say about computational considerations. in this paper we address the computational complexity of combinatorial auctions. 
1 	the complexity problem 
there has been much work in economics and game theory on designing combinatorial auctions. the clarkegroves-vickrey mechanism  also known as the generalized vickrey auction  or gva  has been particularly influential  mas-colell et al.  1; varian  1 . it is beyond the scope of this paper to review such mechanisms  but they share a central problem: given a collection of bids on bundles  finding a set of non-conflicting bids that maximizes revenue.  a more precise definition is given in section 1.  this problem is easily shown to be np-complete  rothkopf et al.  1 . 
   several methods have been conceived to cope with the computational complexity of combinatorial auctions  most aiming to ease the difficulty of finding optimal allocations. they can be classified into three categories based on the strategies they use. 
　one strategy is to restrict the degree of freedom of bidding to simplify the task of finding optimal allocations. rothkopf et al. show that an optimal allocation can be found in polynomial time if  1  each bid contains no more than two goods;  1  for any two bids  either they are disjoint or one is a subset of the other; or  1  each bid contains only consecutive goods given a one-dimensional ordering of goods  rothkopf et al.  1 . 
　another strategy is to shift the burden of finding an optimal allocation to bidders.  banks et al.  1  and  bykowsky et al.  1  have reported a mechanism called alism in which non-winning bids are pooled in a stand-by queue. bidders can combine their bids with other bids currently in the queue to form new allocations. a new allocation is adopted if it generates more revenue than the previously best allocation. 
　a third strategy is to attempt to find an optimal allocation but to be satisfied with a sub-optimal allocation when the expenditure of further resources becomes unacceptable. in other words  the optimality of the allocation is traded-off with the resources required  especially time. 
   in this paper we present two algorithms. the first is an anytime algorithm that attempts to exploit a problem's particular bid structure to reduce the size of the search. it also reduces search time by caching partial results and by pruning the search tree. the second algorithm uses a market-based approach to determine an acceptable allocation  although it is not guaranteed to find an optimal one. we then show results of experiments with synthetic data suggesting that these methods  though not provided with formal guarantees  appear to have surprisingly good 
1  the gva has the additional shortcoming of requiring bidders to submit an unreasonably large number of bids  but we do not address this issue here. 
performance. additionally  the market-based approach appears to produce allocations that are always optimal or nearly optimal.1 
1 precise problem statement 
in this paper we propose two methods for finding desirable allocations based on bids submitted. we start by formally defining the optimization problem. denote the set of goods by g and the set of non-negative real numbers by r+. a bid is an element of  
　　　　　let b be a subset of s. a set  is said to be feasible if denote the set of all feasible allocations for b by further  let  be the set of goods contained in the bids of b. 
 problem  	find 	an 	allocation 	such 	that 
 such an allocation is said to 
be optimal or revenue maximizing. 
　what kind of value interrelation between goods can be represented by the bids defined above  clearly  complementary values are easily accommodated. suppose a bidder bids $1 for each of {g} and {h}  and $1 for {g h}. in this case any revenue-maximizing algorithm will correctly select the {g h} bid instead of {g} and {h}. 
　this bid format is also sufficient for representing substitutability through an encoding trick. suppose a bidder is willing to pay $1 for {g} and $1 for {h} but only $1 for {g h}. in this case  bids cannot be submitted as before since the revenue-maximizing algorithm would select the pair {g} and {h} over {g h}  charging the bidder $1 instead of $1 for g and h. however  this problem can be solved by the introduction of 'dummy goods' -virtual goods that enforce an exclusive-or relationship.  bach dummy good must appear only in a single bidder's bids.  in our example  the bidder could submit the following bids:  $1  {g d}    $1  {h d}   and  $1  {g h}  where d is a new  unique dummy good. the first two bids are now mutually exclusive and so will never be allocated together. this technique can lead to a combinatorial explosion in the number of bids if many goods are substitutable  but in many interesting cases this does not arise. 
1 	cass algorithm 
when the number of goods and bids is small enough  an exhaustive search can be used to determine the optimal allocation. we propose an algorithm  combinatorial auction structured search  cass   presented as a naive brute-force approach followed by four improvements. cass considers fewer partial allocations than the bruteforce method because it structures the search space to avoid considering allocations containing conflicting bids. 
1  we do not analyze the impact of the approximation on the equilibrium strategies in auction mechanisms such as gva; we will address this issue in a future paper. 
fujishima  leyt1n-br1wn  and shoham 	1 

it also caches the results of partial searches and prunes the search tree. finally  it may be used as an anytime algorithm  as it tends to find good allocations quickly. 
1 b r u t e - f o r c e 	a l g o r i t h m 
suppose there are  goods 1  1  ...   bids 1  
1  ...  |z |. first  bids that will never be part of an optimal allocation are removed. that is  if for bid there 
exists a bid  such that 	and 	then 
is removed because it can always be replaced by b1  increasing revenue. then for each good g  if there is no bid  a dummy bid  is added. 
　our brute-force algorithm examines all feasible allocations through a depth-first search. let x be the first bid and y be the last bid. our implementation follows: 
1. if x does not conflict with the current allocation  add x to the current allocation 
1. increment x 
1. if more bids can be added to the allocation  go to 1. 1. update best revenue and allocation observed so far. 
1. if y is contained in the current allocation  remove it  set x=y+l and repeat from 1. 
1. decrement y. 
1. if y is not the first bid  go to 1. 
1 i m p r o v e m e n t # 1 : bins 
a great deal of unnecessary computation is avoided in the brute-force algorithm by checking whether bids conflict with the current allocation before they are added. however  work is still required to determine that a combination is infeasible and to move on to the next bid. it would be desirable to structure the search space to reduce the number of infeasible allocations that are considered in the first place. 
　we can reduce the number of infeasible allocations considered by sorting bids into bins  d1 containing all bids b 
where good  and for such that  
rather than always trying to add each bid to our allocation  we add at most one bid from every bin since all bids in a given bin are mutually exclusive. 
　　in fact  we can often skip bins entirely. while considering bin  if we observe that good  is already part of the allocation then we do not need to consider any of the bids in in general  instead of considering each bin in turn  skip where 
1 i m p r o v e m e n t # 1 : c a c h i n g 
let f  be the partial allocation under consideration when is reached during a search. define  where 
　　　　　　　　　　　　　　　　note that there are many different paretc.  that share the same c  and that then the search trees for  and  are identical beyond d . it is therefore possible to cache partial searches based on c . however  caching all possible values of c  would require a cache of size  which would quickly become infeasible. therefore  we only cache when c  in-
1 	distributed al 
cludes no more than k goods  where k is a threshold defined at runtime for each bin. d  requires a cache of size  
1 i m p r o v e m e n t # 1 : p r u n i n g # 1 
performance can be improved by backtracking whenever a given search path is provably unable to lead to a new best allocation. we can prune whenever and 
sum of the revenue from the cached path beyond fnl and the revenue leading up to  is less than the revenue from the best allocation seen so far. since  allocates a superset of the goods allocated in   thus overestimating revenue   a better allocation would not be found by expanding  
1 i m p r o v e m e n t # 1 : p r u n i n g # 1 
we can also backtrack when it is provably impossible to add any bids to the current allocation to generate more revenue than the current best allocation. before starting the search we calculate an overestimate of the revenue that can be achieved with each good   
is the largest average price per bid 
of bids containing good we backtrack at any point during the search with allocation  
/  best allocation . this technique is most effective when good allocations are found quickly. finding good allocations quickly is also useful if a solution is required before the algorithm has completed  i.e.  if cass is used as an anytime algorithm . we have found that good allocations are found early in the search when the bids in each bin are ordered in descending order of average price per good. similarly  the pruning technique is most effective when the unallocated goods are those with the lowest o g  values. to achieve this  we reorder bins so that for any two bins  
1 	vsa algorithm 
our second algorithm is called virtual simultaneous 
auction  vsa . this market-based method was inspired by market-oriented programming  wellman  1; mullen and wellman  1  and the simultaneous ascending auction  milgrom  1 . vsa generates a virtual simultaneous auction from the bids submitted in a real combinatorial auction  then runs a simulation for the virtual auction to find a good allocation of goods in the 
　 real auction. 
1 	algorithm 
first  a virtual simultaneous auction is generated based on the bids submitted in a real combinatorial auction. for each bid  a virtual bidder  is created. the virtual bidders compete in a virtual simultaneous auction that has multiple rounds. each virtual bidder  tries to 

win all the goods in  for the price  on an all-ornothing basis. the virtual auction starts with no goods allocated and the prices of all goods set to zero. the simultaneous auction is repeated round by round until either an optimal allocation is found or a pre-set time deadline is reached. in the latter case the current best allocation is adopted as the final result. 
　each round of vsa has three phases: the virtual auction phase  the refinement phase and the update phase. in the virtual auction phase each virtual bidder bids for the goods they want. bach individual good is allocated to the highest bidder. if a bidder succeeds in winning all desired goods  that bidder becomes a temporary winner. otherwise the bidder becomes a temporary loser and returns all allocated goods to the auctioneer. in the refinement phase each of the losers is examined in a random order to see whether making that agent a temporary winner  and consequently making a different winner into a loser  would increase global revenue. if so  the list of winners is updated. finally in the update phase the current highest price of each good is changed to reflect the price that its current winner bid. the current highest price for unallocated goods is reset to zero. 
　virtual bidders in vsa follow a simple strategy. if a bidder was the temporary winner in the previous round  the bidder does not bid in the current round. otherwise  agents calculate the sum of the current highest prices of the goods required. if the sum exceeds an agent's budget  the agent does not bid because the agent will not be able to acquire all the goods simultaneously. if the sum is less than the budget  the agent bids such that the surplus  budget - sum  is equally divided among the goods. 
1 	properties 
in certain circumstances  vsa will find an optimal allocation. additionally  it is sometimes possible to detect if an optimal allocation has been found  allowing the virtual auction to end before the deadline. 
|theorem| if no virtual bidder bids in a round in the virtual auction  the current set of winners is optimal. 
|proof| assume that no agents bid in a given round. define the function that calculates the revenue of an allocation f by and let o denote the optimal set of winners. split the current set of winners w into two parts 
oi and  and  also split o into o1 and o1 such that o1 is defined as before and 	 and g1 such that 	by the assumption  for each currently losing bidder  the sum of the current highest prices of the goods needed exceeds the bidder's budget. this is especially true for bidders in i.e.  
	where 	is the current highest price 
of good g. it follows that  
 remem-
ber that the minimum price of a good that is not allocated to any agent is zero and agents always bid their entire budgets.  the inequality means that w is optimal because 

　however  there is no guarantee that auctions will always finish  even if an optimal allocation is found. 
 theorem  there exists a set of bids b such that at least one virtual bidder always bids in every round of the virtual auction no matter what bidding strategy is used. 
 proof  suppose  where 
{1}}  and c={pc  {1  i}}. suppose further that pa   pn + 
 because the real bids are 
mutually exclusive  at most one virtual bidder becomes the temporary winner. if none is winning  and all the bidders bid in the current round. assume here that bidder a is currently winning. then  and hj-f . assume that neither b nor c bids in the current round. then for each of b and c  the sum of the prices of goods needed must be larger than or equal to the budget  
i.e.  	and 	this means that pa -
this argument 
doesn't depend on the bidding strategy as long as an agent bids if and only if their budget exceeds the sum of the minimum prices of the goods needed. 
it is this property that makes the refinement phase of 
vsa important. consider the case  where  and each b  satisfies the con-
dition from the proof above. if we omit the refinement phase then the winner in each subset changes every round except the case where there is no winner. therefore  an optimal global allocation is examined only when in every subset the optimal winner is temporarily winning. such synchronization is unlikely to occur unless the number of subsets is very small. the refinement phase causes the optimal winners to become the temporary winners in every round  leading to an optimal allocation even though it is not detected as optimal.  in some cases where  
 an optimal allocation may be 
impossible to achieve regardless of the time limit.  
1 	experimental evaluation 
as we have not yet determined each algorithm's formal complexity characteristics we conducted empirical tests. we evaluated  1  how running time varies with the number of bids  and  1  how percentage optimality of the best allocation varies with time  given a particular bid distribution and a fixed number of goods. 
1 	assumptions and parameters 
the space of this problem is large. roughly speaking it has three degrees of freedom: the number of goods  the number of bids and the distribution of bids. most problematic among these is the distribution. precisely because of the computational complexity of combinatorial auctions there is little or no real data available. in the absence of such data we tested our algorithms against bids drawn randomly from specific distributions. 
fujishima  leyton-brown  and shoham 	1 

　　throughout the experiment we use the following two distribution functions to determine how often a 

ability of each good being included in a given bid is independent of which other goods are included. the second distribution is of exponential form  representing the case where a bid for n+1 goods appears times less often than a bid for n goods. the prices of 
bids for n goods 	is 	uniformly distributed between 

　we do not present any experiments varying the number of goods in this paper because of space constraints. the results presented here are qualitatively similar to results we observed varying the number of goods. 
we ran our experiments on a 1mhz pentium ii with 
1mb of ram  running windows nt 1. 1 mb of ram was used for the cass cache. all algorithms were implemented in c++. 
1 	results 
to answer question  i  we measured the running time of cass  vsa and the brute-force algorithm. since vsa is not guaranteed to reach the optimal revenue  it was passed this value -calculated by cass-and stopped when it found an allocation with revenue of at least 1% of optimal. all the results reported here are averages over 1 different runs. figure i shows running time as a function of the number of bids with a binomial distribution  with the number of goods fixed at 1. figure 1 shows the same thing for an exponential distribution  without the brute-force algorithm. 
　to answer question  1   we measured the optimality of the output of both vsa and cass as a function of time. figure 1 shows both algorithms' performance with 1 bids for 1 goods  again averaged over 1 runs  with a binomial distribution. 
1 	discussion 
cass demonstrates excellent performance both in finding optimal allocations and as an anytime algorithm. the effectiveness of cass's  improvements  are strongly influenced by the distribution of bids  particularly as the number of goods increases. if bids contain k goods on average  improvement #1 will have a great effect because on average k bins will be skipped between every pair of bins that are considered  eliminating the need to individually consider all the bids in those bins. however  the caching scheme described in improvement #1 favors distributions with small bids because they increase the likelihood that partial allocations will be cacheable. the main advantage of the pruning technique described in 1 is that it reduces the number of nodes that are cached  reducing memory consumption and making cass feasible for larger problems. the pruning technique in 1 
often improves performance by two orders of magnitude  though it is most effective when the variance of average 
1 	distributed al 
figure 1: running time comparison  binom. dist.  

figure 1: running time comparison  exp. dist.  

figure 1: anytime behavior  binom. dist.  
price per bid is relatively small. this technique also reduces the optimal cache size  further reducing memory consumption. when using pruning techniques we have not found the amount of memory available for caching to be a limiting factor in cass's performance. 
　vsa is interesting for two reasons. firstly  it was the first heuristic method we applied to this problem. sec-

ondly  it provides a case study in the power of marketbased optimization. further work is needed to reach firm conclusions  but it appears that as a centralized optimization method vsa is overshadowed by other techniques. however  other attractions of market-based optimization-in particular its inherent distributed nature and robustness to change in problem specification-may make vsa attractive for some domains. there is also some evidence that vsa provides better anytime performance than cass when the number of goods is very large. both of these properties are topics for future study. 
1 	related and ongoing work 
as far as we are aware  the work most directly relevant to the ideas presented here is a paper by sandholm  that appears in these proceedings. sandholnfs bidtree algorithm appears to be closely related to cass  but important differences hold. in particular  bidtree performs a secondary depth-first search to identify non-conflicting bids  whereas casss structured approach allows it to avoid considering most conflicting bids. bidtree also performs no pruning analogous to our improvement #1 and no caching. on the other hand  bidtree uses an ida* search strategy rather than cass's branch-and-bound approach  and does more preprocessing. we intend to continue studying the differences between these algorithms  including differences in experimental settings. 
　our problem can of course be abstracted away from the auction motivation and viewed as a straightforward combinatorial optimization. this suggests a wealth of literature that could be applied. we are currently implementing some of these techniques and comparing them to our present results. we are especially interested in comparisons with mixed-integer programming and greedy methods. in particular  we have been investigating a new algorithm that orders bids in descending order according to average price per good.1 it performs a depth-first search  backtracking when the current revenue plus the average price of the next bid times the number of unallocated goods is less than the best allocation. this algorithm appears to offer performance similar to cass. 
1 	conclusion 
we have proposed two novel algorithms to mitigate the computational complexity of combinatorial auctions. 
　our cass algorithm determines optimal allocations very quickly  and also provides good anytime performance. in the future we intend to pursue a formal analysis of cass's computational complexity  and to test both cass and vsa with data collected from real bidders. 
　our vsa algorithm can determine near-optimal allocations even in cases with hundreds of goods and tens of thousands of bids. since it has been infeasible to run cass on much larger problems we do not yet know how 
1  this ongoing work is joined by liadan o'callaghan and daniel lehmann 
close vsa comes to optimally in these cases. an investigation of vsa s limits remains an area for future work. 
