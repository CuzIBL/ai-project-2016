 
　the vision system of an autonomous land vehicle is required to handle complex dynamic scenes. vehicle motion and individually moving objects in the field of view contribute to a continuously changing camera image. it is the purpose of motion understanding to find consistent threedimensional interpretations for these changes in the image sequence. we present a new approach to this problem  which departs from previous work by emphasizing a qualitative nature of reasoning and modeling and maintaining multiple interpretations of the scene at the same time. this approach offers advantages such as robustness and flexibility over  hard  numerical techniques which have been proposed in the motion understanding literature. 
1. introduction 
　visual information about the environment is an indispensable clue for the operation of an autonomous land vehicle  alv . due to the vehicle's egomotion  however  the resulting camera image is continuously changing even in a completely stationary environment. any change in the 1-d image is the result of some change in 1-d space  either induced by vehicle motion or by moving objects in the field of view. 
　the purpose of our approach is to find consistent interpretations of time-varying images obtained from the camera on a moving vehicle. specifically we are interested to determine 
  how is the camera moving   
  what is moving in the scene and how does it move   
  what is the approximate 1-d structure of the scene   
　the original input is a sequence of images  taken at a constant rate. a reliable low-level correspondence technique1 is assumed to be available  which extracts distinct features from every image and supplies their 1-d image locations in successive frames. the correspondence algorithm labels each feature and tracks it over time by generating tupels  feature-label  time  x-location  y-location . 
　previous work1 in motion analysis has concentrated mainly on numerical techniques for computing motion parameters and scene structure from image sequences. while a com-
*thit work was supported by the defense advanced research projects agency under contract daca 1-c-1 and monitored by the u.s. army engineer topographic laboratories. 
pletely stationary environment has often been assumed for the recovery of the camera motion  the possible presence of moving objects must be accounted for in this scenario. similarly  we cannot rely on a stationary camera setup to detect those moving objects. clearly  some kind of common reference is required  against which the movement of the vehicle as well as the movement of objects in the scene can be related. for this purpose  a vehicle-centered qualitative scene model  qsm  is constructed and maintained over time  representing the current set of feasible interpretations of the scene. 
1. image observations 
　the first step of our approach is to determine the vehicle's motion relative to the stationary environment between each pair of frames. if the vehicle moves along a straight line  all stationary features seem to expand from one single point in the image  the focus of expansion  foe . given the accurate location of the foe  the relative range of any  stationary  point p in the image can be determined at time t by the 
relation 	r t  
	z t  - v t  	f 
v r  
where z t  denotes the actual distance of the point from the image plane in 1-d  v t  is the velocity dzldt of the vehicle perpendicular to the image plane  r t  is the 1-d distance between the image of p and the foe  and v t  is the radial velocity dr/dt. since v t  is the same for any stationary point in the scene  r t  and v t  can be measured in the image and depth can be computed up to a common scale factor. furthermore  by knowing the vertical distance of the camera to the ground  absolute values for vehicle velocity and range can be obtained. 
　while the vehicle is traversing the environment  z t  keeps changing for every feature in the field of view. if the depth map itself was used as the scene model  the model would have to be updated continuously. the topology of the stationary part of the scene  however  should remain unchanged. 
　in reality the alv does not travel along a straight line but performs small rotations  which induce an additional vector field in the image  fig. 1 a  . the fact that all the displacement vectors of stationary features must intersect at a common point can be used to  derotate  the image1 and compute the vehicle's rotation and direction of translation  fig. 1 b  . due to inertia  the direction of translation as well as the amount of rotation about either axis cannot change drasti-
	burger and bhanu 	1 


	 a  	 b  
figure 1.  a  a typical displacement field taken from the alv undergoing translation and rotation. the foe lies inside the area marked by the rectangle   b  after derouuion all vectors intersect the foe-area  marked by a circle  giving the direction of instantaneous heading of the alv. 
cally between two frames. thus the previous motion parameters can serve as a good initial guess for computing the current vehicle motion. we do not assume that the exact location of the foe in the image plane can always be determined  but that a region can be specified  which contains the foe with high certainty. although this first step is done exclusively in the image plane  knowledge about the stationary features to be used must be available in some form. this information is supplied by the qsm which is described below. 
　the feature-property stationary!mobile and the closer relationship between features are the basic building blocks of the qsm. {mobile a  means  that a has been found moving once and is not considered part of the stationary environment. a point a is said to be closer than b  closer a b   if a is closer to the camera plane than b in space. the current set of image features together with assigned properties and mutual relationships constitute an interpretation of the scene. an interpretation is feasible  as long as it is free of internal conflicts  e.g.  closer a b  and  closer b a . the qsm comprises a set of feasible interpretations of the current scene. as the vehicle proceeds  new observations in the image are incorporated into the model  while existing hypotheses inside the qsm are verified. 
　since the interpretation of image motion is inherently ambiguous  different forms of visual information are employed for the construction of the qsm: geometric  spatial  and semantic information. each h of these three types of knowledge is formulated as a group of rules in a blackboard environment. the following examples shall illustrate the basic ideas: 
rule geometry-1: 
if image-point a is moving toward the foe-region then assert  mobile a . 
rule geometry-1: an image point a is said to be inside a point b  if a b are in some neighborhood and a is at a smaller distance from the foe than b.  denotes the 
euclidean distance from a to b at time t. if  stationary a b  a  inside a b  & then hypothesize  closer a b . 
rule geometry-1: this constraint-rule verifies that a 
hypothesis generated in the previous rule can be maintained 
1 	perception 

over time. 
if  stationary a b  &   da b t    d t+     then verify   d   f + l     d1tb t+1   . 
　while the results from geometry are valid for arbitrary configurations  certain assumptions can be made about the spatial layout of the scene which is encountered by the alv. for example  the fact that  for an upright camera  the lower features in the image are generally closer to the vehicle can be expressed in the following heuristic rule. 
rule spatial-1: for any pair of image points a b: 
if  lower a b  then hypothesize  closer a b  
as a consequence  it is very unlikely that a feature is farther away than all its surrounding neighbors. 
occlusion is another important source of spatial information  which is applicable for more complex features such as lines and regions. a feature occluding another is certainly closer to the viewer than the occluded feature. 
　semantic information becomes an important factor as soon as partial interpretations of the scene are available. for instance  if the horizon has been identified  any object above it must be in the sky and is probably not stationary. similarly  the features of an object recognized as a building would not be considered moving in an ambiguous situation. 
1. interpretation and conflict resolution 
　using a set of rules like the ones described in the previous section  the qualitative scene model is constructed. here we describe how the model develops over time  how new interpretations of the scene arc generated  and how conflicts are resolved. 
　an example with a scene containing three feature points a b c is shown in figure 1. initially  nothing is known about the spatial relationships between these points and whether they are stationary or not. the default assumption is that any point is stationary unless there is an indication that this is not true. the initial interpretation of the scene thus contains only 
interpretation 
 stationary 
　suppose that between t1 and to all three points show some amount of expansion away from the foe  giving rise to the conclusion  e.g. by rule geometry-1  that a is closer  to the vehicle  than b  a is closer than c  and c is closer than b. from the information gathered up to this point  the interpretation of the scene at time t1 looks like this: 
interpretation 
 stationary a b c   
 closer a b    closer a c    closer c b . 
　at time t1 one of the rules claims that c is closer than a and tries to assert this fact into the current interpretation. clearly  the new interpretation would contain the conflicting facts 
　 closer a c  and  closer c a   which would not be a feasible interpretation. the conflict is 


figure 1. development of the qualitative scene model  qsm  over time: at time t1 three features a  b  c are given  which are initially assumed to be stationary. at time tx three closer-relationships have been established between a  b and c. at time t1 a conflict occurs in interpretation a by the contradictory facts  closer a c  and  closer c a . two new interpretations  b and c  are created  each containing one feature considered mobile  a  c respectively . at time r  a new conflict occurs in interpretation b from the additional fact  closer b c . since another interpretation  c  exists at the same time which could absorb this fact  c is mobile in c   b is not branched out but discontinued. c remains as the only 

feasible interpretation. 
resolved by creating two disjunct hypotheses b and c  with either a or c as mobile: 
interpretation b r1 : 
 mobile a    stationary b c    closer c b . 
interpretation c t1 : 
 mobile c    stationary a b    closer a b . 
notice  that when a feature is hypothesized to be mobile  all its c/osr-relationships are removed from the interpretation. at this point in time  r1   two feasible interpretations of the scene are active simultaneously. all active interpretations are pursued until they enter a conflicting state  in which case they are either branched into new interpretations or removed from the qsm. 
in our example we assume  that both interpretations b and 
c are still alive at time tv at this point some rule claims  that if b  c are both stationary  then b is closer than c. this creates a conflict in interpretation b  because b contains the contradictory fact  closer c b ! again we could branch interpretation b into two new interpretations  d e   with either  mobile b  or  mobile c . at this time  however  there exists another active interpretation  c   which could absorb  closer b c  without causing an internal conflict  c is mobile in c . therefore b is not branched out but removed altogether from the model  and only interpretation c survives. 
　in summary  the development of the qsm is controlled by the following meta-rules: 
  after a hypothesis has been created by one of the analyzing rules  try to integrate this hypothesis as a fact into every active interpretation. 
  if the new fact is consistent with the interpretation  make it a part of this interpretation. 
  if the new fact is not consistent with the interpretation  and there are currently no other interpretations active  then create a new set of interpretations containing this fact without conflict 
  otherwise prune the search tree by deleting the conflicting interpretation from the model. 
1. conclusions 
　in this paper we presented a new approach for the problem of motion interpretation in the scenario of an autonomous land vehicle  following a qualitative line of reasoning and modeling. different forms of visual information are combined in a rule-based framework to construct and maintain a three-dimensional qualitative model of the environment instead of refining a single numerical model a set of disjunct interpretations of the dynamic scene are pursued simultaneously. 
　the work reported here shows the conceptual outline of our approach. while we have considered only point-features so far  the integration of lines and regions will be a natural extension. an implementation is currently under way using actual alv imagery.1 
