 
these notes discuss formalizing contexts as first class objects. the basic relation is ist c p . it asserts that the proposition p is true in the context c. the most important formulas relate the 
propositions true in different contexts. introducing contexts as formal objects will permit axiomatizations in limited contexts to be expanded to transcend the original limitations. this seems necessary to provide ai programs using logic with certain capabilities that human fact representation and human reasoning possess. fully implementing transcendence seems to require further extensions to mathematical logic  i.e. beyond the nonmonotonic inference methods first invented in ai and now studied as a new domain of logic. various notations are considered  but. these notes are tentative in not  proposing a single language with all the desired capabilities. 
1 	introduction 
these notes contain some of the reasoning behind the proposals of  to introduce contexts as formal objects. the present proposals are incomplete and tentative. in particular the formulas are not what we will eventually want   and 1 will feel free to use formulas in discussions of different  applications that aren't always compatible with each other.  while i dithered. 
r.v. guha wrote his dissertation.  
　our object is to introduce contexts as abstract math ematical entities with properties useful in artificial intelligence. our attitude is therefore a computer science or engineering attitude. if one takes a psychological or philosophical attitude  one can examine the phenomenon of contextual dependence of an utterance or a belief. however  it seems to me unlikely that this study will result  in a unique conclusion about what context is. instead  as is usual in ai  various notions will be found useful. 
　one major ai goal of this formalization is to allow simple axioms for common sense phenomena  e.g. axioms 
   'this work was partly supported by darpa contract nag 1- 1. 
for static blocks world situations  to be lifted to contexts involving fewer assumptions  e.g. to contexts in which situations change. this is necessary if the axioms are to be included in general common sense databases that can be used by any programs needing to know about  the phenomenon covered but which may be concerned with other mattters as well. rules for lifting are described in section 1 and an example is given. 
　a second goal is to treat the context associated with a particular circumstance  e.g. the context of a conversation in which terms have particular meanings that they wouldn't have in the language in general. 
　the most ambitious goal is to make ai systems which are never permanently stuck with the concepts they use at a given time because they can always transcend the context they are in if they are smart enough or are told how to do so. to this end  formulas ist  c p  are always considered as themselves asserted within a context  i.e. we have something like  the regress is infinite  but we will show that it is harmless. 
the main formulas are sentences of the form 
		 1  
which are to be taken as assertions that the proposition /  is true in the context c  itself asserted in an outer context c'.  i have adopted guha's  guha  1   notation rather than that of  mccarthy  1   because he built his into cyc  and it was easy for me to change mine. fv i now  propositions may be identified with sentences in english or in various logical languages  but we may later take them in the sense of  mccarthy  1b  as abstractions with possibly different identity conditions. we will use both logical sentences and english sentences in the examples  according to whichever is more convenient. 
　contexts are abstract objects. we don't offer a definition  but we will offer some examples. some contexts will be rich objects  like sit nations in situation calculus. for example  the context associated with a conversation is rich; we cannot list all the common assumptions of the participants. thus we don't purport to describe such contexts completely; we only say something about them. on the other hand  the contexts associated with certain microtheories are poor and can be completely described. 
here are some examples. 
　
1 
　
the signal on w i r e l w is 1 or 1. we can then write the lifting relation 

the idea is that we can introduce contexts associated with particular parts of a circuit or other system  each with its special language  and lift sentences from this context to sentences meaningful for the system as a whole. 
1 	entering and leaving contexts 
suppose we have the sentence ist c p . we can then enter the context c and infer the sentence p. we can regard ist c p  as analogous to  and the operation of entering c as analogous to assuming c in a system of natural deduction as invented by gentzen and described in many logic texts. indeed a context is a generalization of a collection of assumptions  but there are important differences. for example  contexts contain linguistic assumptions as well as declarative and a context may correspond to an infinite and only partially known collect ion of assumptions. moreover  because relations among contexts are expressed as sentences in the language  ist c p  allows inferences within the language that could only be done at the meta-level of the usual natural deduction systems. 
   there are various ways of handling the reasoning step of entering a context. the way most analogous to the usual natural deduction systems is to have an operation enter c. having done this  one could then write any p for which one already had ist c p . however  it seems more convenient in an interactive theorem proving to use the style of jussi ketonen's e k l interactive theorem prover  ketonen and weening  1 . in the style of that system  if one had ist c p   one could immediately write p  and the system would keep track of the dependence on c. to avoid ambiguity as to where an occurrence of ist   p  came from  one might have to refer to a line number in the derivation. having obtained p by entering c and then inferring some sentence q  one can leave c and get ist c q . in natural deduction  this would be called discharging the assumption c. 
   human natural language risks ambiguity by not. always specifying such assumptions  relying on the hearer or reader to guess what contexts makes sense. the hearer employs a principle of charity and chooses an interpretation that assumes the speaker is making sense. in ai usage we probably don't usually want  computers to make assertions that depend on principles of charity for their interpretation. 
　another application of entering a context has to do with quantifiers. it involves a distinguished predicate 
present c exp   where t u p names an object. if we have 

then when we enter c  then a special inference rule associated with the predicate present gives 

likewise if we have shown 
within the context c  we can infer 

　we could get similar effects by associating a domain  call it domain c   with each context c. 
   i'm presently doubtful that the reasoning we will want our programs to do on their own will correspond closely to using an interactive theorem prover. therefore  it isn't clear whether the above ideas for implementing entering and leaving contexts will be what we want. 
　sentences of the form ist c p  can themselves be true in contexts  e.g. we can have ist ci   ist{cl p  . in this draft  we will ignore the fact that if we want to stay in first order logic  we should reify assertions and write something like   where ist c p  is a term rather than a wff. we plan to fix this up in some way later  either by introducing terms like  st c p  or by using a modified logic. actually the same problem arises for p itself; the occurrence of p in ist c p  might have to be syntactically distinct from the occurence of p standing by itself. 
1 	rules for lifting 
consider a context above-theory  which expresses a static theory of the blocks world predicates cm and above. in reasoning about the predicates themselves it is convenient  not to make them depend on situations or on a time parameter. however  we need to lift the results of above-theory to outer contexts that do involve situations or times. 
to describe above-theory  we may write informally 

　we want to apply above-theory in a context c in which on and above have a third argument denoting a situation. in the following formulas  we put the context in which the formula is true to the left followed by a colon  d  denotes an outer context in which formulas not otherwise qualified are true. the next section has more about co. suppose that in context c we have 


which abbreviates to 	1 	transcending contexts 　in this derivation we used a function giving a context c {s  depending on the situation parameter s. contexts depending on parameters will surely present problems requiring more study. 
　besides that  the careful reader of the derivation will wonder what system of logic permits the manipulations involved  especially the substitution of sentences for variables followed by the immediate use of the results of the substitution. then* are various systems that can be used  e.g. quasi-qtiotation as used in the lisp or kif  use of back-quotes  or the notation of  buvac and mason  1  or the ideas of  mccarthy  1b   but all have disadvantages. at present we are more attached to the derivation than to any specific logical system and consider preferable a system in which the above derivation is preserved with as little change as possible. 
　as a further example  consider rules for lifting statements like those of section 1 to one in which we can express statements about justice holmes's opinion of the sherlock holmes stories. 
human intelligence involves an ability that no-one has yet undertaken to put in computer programs namely the ability to transcend the context of one's beliefs. 
　that objects fall would be expected to be as thoroughly built into human mental structure as any belief could be. nevertheless  long before space travel became possible  the possibility of weightlessness was contemplated. it wasn't easy  and jules verne got it wrong when he thought that there would be a turn-over point on the way to the moon when the travellers  who had been experiencing a pull towards the earth would suddenly experience a pull towards the moon. 
　in fact  this ability is required for something less than full intelligence. we need it to be able to comprehend someone else's discovery even if we can't make the discovery ourselves. to use the terminology of  mccarthy and hayes  1   it is needed for the epistemological part of intelligence  leaving aside the heuristic. 
　we want to regard the system as being at any time within an implicit outer context; we have used co in this paper. thus a sentence p that the program believes without qualification is regarded a s equivalent to ist c1 p   and the program can therefore infer ist ci  p  from p  thus transcending the context co. performing this operation again should give us a new outer context  call it c  1. this process can be continued indefinitely. we might even consider continuing the1 process transfinitely  for example  in order to have sentences that refer to the process of successive transcendence. however  i have no present use for that. 
　however  if the only mechanism we had is the one described in the previous paragraph  transcendence would be pointless. the new sentences would just be more elaborate versions of the old. the point of transcendence arises when we want the transcending context to relax or change some assumptions of the old. for example  our language of adjacency of physical objects may implicitly assume a gravitational held  e.g. by having relations of on and above. we may not have encapsulated these relations in a context.. one use of transcendence is to permit relaxing such implicit assumptions. 
　the formalism might be further extended to provide so that in c 1 the whole set of sentences true in c   is an object truths c1 . 
　transcendence in this formalism is an approach to formalizing something that is done in science and philosophy whenever it is necessary to go from a language that makes certain assumptions to one that does not. it also provides a way of formalizing some of the human ability to make assertions about one's own thoughts. 
　the usefulness of transcendence will depend on there being a suitable collection of nonmonotonic rules for lifting sentences to the higher level contexts. 
　as long as we stay within a fixed outer context  it seems that our logic could remain ordinary first order logic. transcending the outermost context seems to require a changed logic with what tarski and montague call reflexion principles. they use them for sentences like true p*  = p  e.g   'snow is white.' is true if and only if snow is white.  
　
　the above discussion concerns the epistemology of transcending contexts. the heuristics of transcendence  i.e. when a system should transcend its outer context and how  is entirely an open subject. 
1 	relative decontextualization 
quine  uses a notion of  eternal sentence1  essentially one that doesn't depend on context. this seems a doubtful idea and perhaps incompatible with some of quine's other ideas  because there isn't any language in which eternal sentences could be expressed that doesn't involve contexts of some sort. we want to modify quine's idea into something we can use. 
　the usefulness of eternal sentences comes from the fact that ordinary speech or writing involves many contexts  some of which  like pronoun reference  are valid only for parts of sentences. consider   yes  john mccarthy is at stanford university  but he's not at stanford today . the phrase  at stanford  is used in two senses in the same sentence. if the information is to be put  say  in a book to be read years later by people who don't know mccarthy or stanford  then the information has to be deeontextualized to the extent of replacing some of the phrases by less contextual ones. 
　the way we propose to do the work of  eternal sentences  is called relative: decontextualization. the idea is that when several contexts occur in a discussion  there is a common context above all of them into which all terms and predicates can be lifted. sentences in this context are  relatively eternal   but more thinking or adaptation to people or programs with different presuppositions may result in this context being transcended. 
1 	mental states as outer contexts 
a person's state of mind cannot be adequately regarded as the set of propositions that he believes at least not if we regard the propositions as sentences that he would give as answers to questions. for example  as i write this i believe  that george bush is the president of the united 
states  and if i were entering information in a database  
1 might write president u.s.a  	= 	george.bush. 
however  my state of mind includes  besides the asertion itself  my reasons for believing it  e.g. he has been referred to as president in today's news  and 1 regard his death or incapacitation in such a short interval as improbable. the idea of a tms or reason maintenance system is to keep track of the pedigrees of all the sentences in the database and keep this information in an auxiliary database  usually not in the form of sentences. 
　our proposal is to use a database consisting entirely of outer sentences where the pedigree of an inner sentence1 is an auxiliary parameter of a kind of modal operator surrounding the sentence. thus we might have the outer sentence believe president u.s.a.  = george.bush  because . .   where the dots represent the reasons for believing that bush is president. 
　the use of formalized contexts provides a convenient way of realizing this idea. in an outer context  the sentence with reasons is asserted. however  once the system has committed itself to reasoning with the proposition that bush is president  it enters an inner context with the simpler assertion president  u.s. a  - georgebush. 
if the system then uses the assertion that bush is president to reach a further conclusion  then when it leaves the inner context  this conclusion needs to acquire a suitable pedigree. 
　consider a belief revision system that revises a database of beliefs solely as a function of the new belief being introduced and the old beliefs in the system. such systems seem inadequate even to take into account the information used by tms's to revise beliefs. however  it might  turn out that such a system used on the outer beliefs might be adequate  because the consequent revision of inner beliefs would take reasons into account. 
1 	short term applications 
we see the use of formalized contexts as one of the essential tools for reaching human level intelligence by logicbased methods. however  we see formalized contexts as having shorter term applications. 
  guha has put contexts into cyc  largely in the form of microtheories. the above - theory example is a microtheory. see  guha  1.  for some of the details. 
  suppose the air force and general electric co. each have databases that include prices of jet engines and associated equipment. the items overlap in that jet engines that general electric sells to the air force are included. suppose further that the databases are not entirely compatible because the prices are based on different assumptions about spare parts and warranty conditions. now suppose that the databases are to be used together by a program that must check whether the air force database is up-to-date on general electric prices. our idea is that corresponding to each database is a context  e.g. context- g e-engine-priccs and contextaf-engine-prices. the program  however  must work with a context we may call context-ge-afcngme-prices. its language allows statements with auxiliary information about what is included in the price of an item. suitable lifting rides allow translating the sentences of the two other databases into this more comprehensive context. 
1 	remarks 
1. we have mentioned various ways of getting new contexts from old ones: by specializing the time or place  by specializing the situation  by making abbreviations  by specializing the subject matter  e.g. to u.s. legal history   by making assumptions and by specializing to the context of a conversation. these are all specializations of one kind or 
　
another. getting a new context by transcending an old context  e.g. by dropping the assumption of a gravitational field  gives rise to a whole new class of ways of get ting new contexts. 
these are too many ways of getting new contexts to be treated separately. 
1. we have used natural language examples in this article  although natural language is not our main concern. nevertheless  i hope that formalizing context in the ways we propose may be useful in studying the semantics of natural language. natural language exhibits the striking phenomenon that context may vary on a very small scale; several contexts may occur in a single sentence. 
consider the1 context of an operation in which the surgeon says  ''scalpel . in context  this may be equivalent to the sentence   please give me the number 1 scalpel . 
1. ist c p  can be considered a modal operator dependent on c applied to p. this was explored in  shoham  1 . 
1. it would be useful to have a formal theory of the natural phenomenon of context  e.g. in human life  as distinct from inventing a form of context useful for ai systems using logic for representation. this is likely to be an approximate theory in the sense described in  mccarthy  1a . that is  the term  context  will appear in useful axioms and other sentences but will not have a definition involving  if and only if . 
1. useful nonmonotonic rules for lifting will surely be more complex than the examples given. 
in d. michie  ed   machine intelligence 1  american elsevier  new york  ny  1. reprinted in  mccarthy  1 . 
 mccarthy  1a  mccarthy  john  1a :  ascribing mental qualities to machines  in philosophical perspectives in artificial intelligence  ringle  martin  ed   harvester press  july 1. reprinted in  mccarthy  1 . 
 mccarthy  1b  mccarthy  john  1b :  first order theories of individual concepts and propositions   in michie  donald  ed.  machine intelligence 1   university of edinburgh press  edinburgh . reprinted in  mccarthy  1 .. 
 mccarthy  1  mccarthy  john  1 :  generality in artificial intelligence   communications of the acm. vol. 1  no. 1  pp. 1. also in acm turing award lectures  the first 
twenty years  acm press  1. reprinted in  mccarthy  1 .. 
 mccarthy  1  mccarthy  	john: 	formalizing common sense  ablex  norwood  new jersey  
1. 
 quine  1  quine  w. v. o.:  propositional objects    in ontological relativity and other essays  columbia university press  new york  1. 
 shoham  1  shoham  y.:  varieties of context   in artificial intelligence and mathematical theories of computation  academic press  san diego and london 1. 

　
acknowledgments 
the development of these ideas has benefitted from discussions with sasa buvac  lorn costello  mike genesereth  fausto giunchigha and r. v. guha. guha wrote his thesis  guha  1  while this article was going through many versions as the ideas developed  and the mutual influences cannot be specified. 
