 
we consider two generalizations of the standard two-player game model: different evaluation functions for the players  and more than two players. relaxing the assumption that players share the same evaluation function produces a hierarchy of levels of knowledge as deep as the search tree. alpha-beta pruning is only possible when the different evaluation functions behave identically. in extending the standard model to more than two players  the minimax algorithm is generalized to the maxn algorithm applied to vectors of n-tuples representing the evaluations for each of the players. if we assume an upper bound on the sum of the components for each player  and a lower bound on each individual component  then shallow alphabeta pruning is possible  but not deep pruning. in the best case  the asymptotic branching factor is reduced to  1 +  /1 - 1 /1. in the average case  however  pruning does not reduce the asymptotic branching factor. thus  alphabeta pruning is found to be effective only in the special case of two players with a common evaluation function. 
1 	introduction 
minimax search with alpha-beta pruning is the predominant algorithm employed by two-player game programs. figure 1 shows a game tree  where squares represent max nodes and circles correspond to min nodes  along with its minimax value  bounds on interior nodes  and those branches pruned by alpha-beta. 
　there are two assumptions made in this model. one is that there are two players  and the other is that they 
   *this research was supported by an nsf presidential young investigator award  and nsf grant iri-1. 
thanks to chris ferguson for helpful discussions concerning this work  and valerie aylett for drawing the figures. 
both use the same evaluation function. there are  however  games that involve more than two players. furthermore  the knowledge of different players is likely to be quite different in practice. first we will consider the consequences for minimax and alpha-beta of assuming that two players use different evaluation functions. next we will examine multi-player game trees. finally  we will combine the two cases and briefly discuss multi-player games with different evaluation functions. 
1 	different evaluation functions 
given separate evaluation functions  there are two cases to consider  depending on whether or not each player knows his opponent's function. 
1 	separate but shared knowledge 
in the simplest case of separate evaluation functions  each player uses a different function and each player knows his opponent's function. this requires that minimax be modified as follows: each node now has two evaluations  one for max and one for min. in figure 1  the first component is max's value and the second is min's. the player to move at a given node uses his evaluation of the children  and backs up the complete ordered pair for which his component is a maximum or minimum  respectively. 
　in general  alpha beta pruning cannot be used in this case. compare figure 1 with the two-level tree in the lower left corner of figure 1. using either max or min's function exclusively would cause the last node to be pruned  yet its value is the minimax value of the root when both functions are used. the problem is that  1  is better than  1  for both max and min. 
simply applies his evaluation function to each of the children  and chooses the one with the largest value. 
　in a two-level tree with max at the root  max's choice of move depends on what he thinks min's move will be. min's decision will be based on min's evaluation of the terminal nodes  but max only has a model of min's function. thus  max applies his model of min's evaluation to the frontier nodes  and backs up the position with the minimum value. then  max's evaluation function is applied to the two positions that are backed up  and the one with the maximum value is chosen for the move. 
　the situation gets more complex with a three-level tree. again assume that max is to move at the root. max's decision will be based on what he thinks min will do. however  min's decision will be based on what he 　pruning is possible only if the two evaluation functions always agree on the relative ordering of the merits of different positions. in other words  if one node looks better to max than another  then it also must look worse to min. since the actual values of positions don't matter  but merely their relative order  this constraint implies that both evaluation functions always make the same decisions  and hence are effectively identical. if two evaluation functions rank different positions differently  then alpha-beta pruning cannot be used and the entire tree must be searched. 
1 	no shared knowledge 
so far we have assumed that each player knows his opponent's function. now we relax that constraint  and assume that each player merely has a model of his opponent's function  which may or may not be accurate. this is the most general and realistic case since in general one player can only guess at what his opponent may know. we will illustrate the necessary modification to minimax by a series of examples. 
in a one-level game tree with max at the root  max thinks max will do two levels down. thus  max's decision is based on what max thinks that min thinks that max will do. therefore  the evaluation function that is applied to each of the frontier nodes is max's model of min's model of max's evaluation  and the nodes with the maximum values are backed up to the max nodes directly above the frontier. next  max's model of min's evaluation is applied to the backed up nodes  and the nodes with the minimum values are backed up to the min nodes directly below the root. finally  max's evaluation is applied to these backed up nodes to determine the final move. 
　in general  an additional level of knowledge is added for each level of the search tree. in theory  each of these different levels of knowledge could involve different evaluation functions. while the concept of multiple levels of 
	korf 	1 

knowledge is well-known in the game theory context of simultaneous decisions   alternating-move game trees provide a simple and often overlooked example of this phenomenon in artificial intelligence. 
　the restrictions on alpha-beta pruning in this case are the same as in the case of different but shared functions. in other words  the models of the different evaluation functions must agree in their relative ordering of different positions  which is to say that they must be functionally equivalent. 
1 	multi-player game trees 
we now consider games with more than two players. for example  chinese checkers can involve up to six different players moving alternately. as another example  othello can easily be extended to an arbitrary number of players by having different colored pieces for each player  and modifying the rules such that whenever a mixed row of opposing pieces is flanked on both sides by two pieces of the same player  then all the pieces are captured by the flanking player. 
1 	m a x n a l g o r i t h m 
luckhardt and irani extended minimax to multiplayer games  calling the resulting algorithm maxn. we assume that the players alternate moves  that each player tries to maximize his return  and is indifferent to the returns of the remaining players. at the leaf nodes  an evaluation function is applied that returns an n-tuple of values  with each component corresponding to the estimated merit of the position with respect to one of the players. then  the value of each interior node where player i is to move is the entire n-tuple of the child for which the ith component is a maximum. figure 1 shows a maxn tree for three players  with the corresponding maxn values. 
   for example  in chinese checkers  the value of each component of the evaluation function might be the negative of the minimum number of individual moves required to move all of the corresponding player's pieces to their goal positions. similarly  an evaluation function for multi-player othello might return the number of pieces for each player on the board at any given point. 
　the negamax formulation of two-player minimax is a special case of maxn for two players. the evaluation function returns an ordered pair of x and - x   and each player maximizes his component at his moves. 
1 	alpha-beta p r u n i n g in multi-player game trees 
luckhardt and irani observed that at nodes where player i is to move  only the ith component of the children need be evaluated. at best  this can produce a constant factor speedup  but it may be no less expensive to compute all components than to compute only one. 
they correctly concluded that without further assumptions on the values of the components  pruning of entire branches is not possible with more than two players. 
　if  however  there is an upper bound on the sum of all components of a tuple  and there is a lower bound on the values of each component  then alpha-beta pruning is possible. the first condition is a weaker form of the standard constant-sum assumption  which is in fact required for two-player alpha-beta pruning. the second is equivalent to assuming a lower bound of zero on each component  since any other lower bound can be shifted to zero by subtracting it from every component. most practical evaluation functions will satisfy both these conditions  since violating them implies that the value of an individual component can be unbounded in at least one direction. for example  in the evaluation function described above for multi-player othello  no player can have less than zero pieces on the board  and the total number of pieces on the board is the same for all nodes at the same level in the game tree  since exactly one piece is added at each move. 
1.1 	immediate p r u n i n g 
　the simplest kind of pruning possible under these assumptions occurs when player i is to move  and the ith component of one of his children equals the upper bound on the sum of all components. in that case  all remaining children can be pruned  since no child's ith component can exceed the upper bound on the sum. we will refer to this as immediate pruning. 
1.1 	shallow p r u n i n g 
　a more complex situation is called shallow pruning in the alpha-beta literature. figure 1 shows an example of shallow pruning in a three-player game  where the sum of each component is 1. evaluating node a results in a lower bound of 1 on the first component of the root  since player one is to move. this implies an upper bound on each of the remaining components of 1 - 1 = 1. evaluating node / produces a lower bound of 1 on the second component of node e  since player two is to move. similarly  this implies an upper bound on the remaining components of 1 - 1 = 1. since the upper bound  1  on the first component of node e is less than or equal to the lower bound on the first component of the root  1   player one won't choose node e and its remaining children can be pruned. similarly  evaluating node h causes its remaining brothers to be pruned. this is similar to the pruning in the left subtree of figure 1. 
　the procedure shallow takes a node to be evaluated  the player to move at that node  and an upper bound on the component of the player to move  and returns a vector that is the maxn value of the node. sum is the global upper bound on the sum of the components. initially  shallow is called with the root of the tree  the player to move  and sum. note that shallow pruning includes im-


	korf 	1 


1.1 	failure of deep p r u n i n g 
　in a two-player game  alpha-beta pruning allows an additional type of pruning known as deep pruning. for example  in figure 1  nodes b and c are pruned based on bounds inherited from their great-great-grandparent  the root in this case. surprisingly  deep pruning does not generalize to more than two players. 
　figure 1 illustrates the problem. again  the sum of each component is 1. evaluating node b produces a lower bound of 1 on the first component of node a and hence an upper bound of 1 - 1 = 1 on the remaining components. evaluating node e results in a lower bound of 1 on the third component of node d and hence an upper bound of 1 - 1 = 1 on the remaining components. since the upper bound of 1 on the first component of node d is less than the lower bound of 1 on the first component of node a  the value of node / cannot become the value of node a. in a two-player game  this would allow us to prune node 
/. 
　with three players  however  the value of node / could effect the value of the root  depending on the value of node g. if the value of node / were  1 1  for example  the value of e would be propagated to d  the value of d would be propagated to c  and the value of b would be propagated to a  giving a value of  1 1 . on the other hand  if the value of node / were  1 1  for example  then the value of / would be propagated to d  the value of g would be propagated to c  and the value of c would be propagated to a  producing a value of  1 1 . even though the value of node / cannot be the maxn value of the root  it can effect it. hence  it cannot be pruned. 
1.1 	optimality of shallow p r u n i n g 
　given the failure of deep pruning in this example  is there a more restricted form of pruning that is valid  or is shallow pruning the best we can do  the answer is the latter  as expressed by the following theorem: 
theorem 1 every directional algorithm that computes the maxn value of a game tree with more than two players must evaluate every terminal node evaluated by shallow pruning. 
　by a directional algorithm we mean one in which the order of node evaluation is independent of the value of the nodes  and once a node is pruned it can never be revisited. for example  a strictly left-to-right order would be directional. the main idea of the proof amounts to a generalization of the above example to variable values  arbitrary depth  and any number of players greater than two. unfortunately  space constraints preclude us from including the proof here. 
1.1 	best-case performance 
　how effective is shallow pruning in the best case  to simplify the analysis  we will exclude immediate pruning by assuming that no one component can equal the upper bound on the sum. the best-case analysis of shallow pruning is independent of the number of players and was done by knuth and moore for two players. 
　in order to evaluate a node in the best case  one child must be evaluated  and then evaluating one grandchild of each remaining child will cause the remaining grandchildren to be pruned  see figure 1 . thus  if f d  is the number of leaf nodes generated to evaluate a tree of depth d with branching factor 1 in the best case  then f d  = f d - 1  +  b - 1  * f d - 1 . since a tree of depth zero is a single node  and a tree of depth one requires all children to be evaluated  the initial conditions are f 1  = 1 and -f l  = 1. note that in a binary tree  f d  is the familiar fibonacci sequence. the solution to the general recurrence has an asymptotic branching factor of  1 -f y/1b - 1 /1. for large values of 1  this approaches y/b which is the best-case performance of full two-player alpha-beta pruning. 
1.1 	average-case performance 
　knuth and moore also determined that in the average case  the asymptotic branching factor of two-player 

shallow pruning is approximately b/ log 1. they assumed independent  distinct leaf values. 
　in the case of multiple-players  however  our model of the evaluation function must have a lower bound on each component and an upper bound on their sum. for simplicity  assume that the lower bound is zero and that the sum is exactly one. thus  we need a way of randomly choosing n-tuples such that each component is identically distributed between zero and one  and the sum of all components is one. one way to do this is by cutting the zero-one interval in n - 1 places  with each cut-point independently and identically distributed from zero to one  and using the n resulting segments as the components of the n-tuple. furthermore  we assume that each tuple is independently generated. 
　under this average-case model  the asymptotic branching factor of shallow pruning with more than two players is simply b  the brute-force branching factor. the analysis relies on the minimax convergence theorem l   which was derived for two-player minimax trees but also holds for multi-player maxn trees as well. this surprising phenomenon is that if the leaf values are chosen independently from the same distribution  the variance of the root values decreases with increasing height of the tree  and in the limit of infinite height  the root value can be predicted with probability one. the actual limiting value depends on the leaf distribution and also on which player moves last in the tree  but the convergence does not. 
　in order for pruning to take place  the lower bound on one component must be greater than or equal to its upper bound  which equals one minus the lower bound on another component. thus  pruning only takes place when the sum of the lower bounds on two different components is greater than or equal to one. in order for this to occur in the limiting value  the values of the remaining components must be zero  since the sum of the two components in question is one. this cannot happen in the limiting value  assuming continuous terminal values. thus  while pruning occurs at low levels of the tree  at higher levels it becomes increasingly rare  and in the limit of infinite depth  it disappears entirely. thus  the asymptotic branching factor is simply 1. this has been verified experimentally  using the model described above. 
1 multi-player games with separate evaluation functions 
what happens when we combine the assumptions of separate evaluation functions and multiple players  the result is a hierarchy of multiple functions  each of which returns a vector of values for each position. for example  in the three-player game tree of figure 1  the evaluation function applied to the frontier nodes would be player l's model of player 1's model of player 1's evaluation function. at the next higher level  player l's model of player 1's function would be used  and finally player l's evaluation would be applied to the children of the root. 
　the constraints on alpha-beta pruning are the same. namely  deep pruning cannot be done  and shallow pruning can only be used where the corresponding functions behave identically. in the average case with more than two players  pruning does not reduce the asymptotic branching factor. 
1 	conclusions 
we have considered two extensions to the standard game-tree model. the first is to allow different players to have different evaluation functions  and different model's of their opponent's functions. in general  this produces a hierarchy of levels of knowledge that is as deep as the search tree to be evaluated. furthermore  alpha-beta pruning cannot be used unless the different evaluations are functionally equivalent. 
　the second is to allow an arbitrary number of players. this leads to a generalization of the minimax algorithm called maxn. if we further assume that there is a lower bound on each component of the evaluation function  and an upper bound on the sum of all components  then shallow alpha-beta pruning is possible  but not deep pruning. in the best case  this results in significant savings in computation  but in the average case it does not reduce the asymptotic branching factor. 
　this implies that alpha-beta is a rather specialized algorithm whose effectiveness is limited to the case of two-players with a common shared evaluation function. since alpha-beta pruning is one of the main reasons for the effectiveness of the minimax backup rule  alternative backup rules may be more competitive in these more general settings. 
