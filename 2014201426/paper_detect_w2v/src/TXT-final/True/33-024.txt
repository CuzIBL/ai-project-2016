 
　　　much of adult learning is gradual  almost imperceptible. our model for this knowledge-based  incremental learning is to augment normal story comprehension processing with a failure tracking mechanism. when a comprehension rule f a i l s   the failure and its correction are stored in an exception episode attached to the failing rule. the rule is otherwise unchanged. subsequent failures of that rule trigger the retrieval of these exception episodes  failure-driven reminding . rule modification occurs when classes can be found for the known exceptions. the alfred program is a preliminary implementation that classifies and remembers failures of  everyday knowledge  in the domain of political economics. 
a learning example 
　　　one of the members of our learning group read an article in favor of controlling credit cards. the article said that they account for $1 b i l l i o n of the total credit in the american economy  and this convinced him that credit cards contribute to inflation and probably should be controlled. 
　　　but two days later he read an article that ssid that credit cards were insignificant compared to the $1 t r i l l i o n of total credit in the economy. this changed his mind. he realised he had been wrong in thinking $1 b i l l i o n was a large part of total credit. 
　　　a week later  he read an article that said that adding a loi per gallon tax on gas would decresse consumption by 1 barrels a day. at f i r s t   that effect looked too big  but then he remembered having misjudged the size of $1 billion the week before. resding further  he found that current consumption was over 1 millions barrels a day  so the expected decrease was actually quite small  in keeping with the small site of the tax. 
　　　we believe that being reminded of prior failures is part of the following underlying learning process: 
1. when new beliefs contradict old beliefs  debugging processes decide which belief to reject and which inference rule to blame for having accepted that belief  a non-trivial problem - see  and  . 
1.
 an exception episode describing both the failure and the f i x is attached to the faulty inference rule. 
1. later  if the same rule is blamed for another failure in some new situation  the previously stored episode is retrieved  this is called iailurc-drmp reminding -
when a subset of the exception episodes can be grouped into a class  e.g.  episodes within one domain   the failing rule can be modified to treat that class correctly  and the exceptions removed. 
　　　we do not have a classification scheme for exception episodes to handle the last step  but we hope thst existing methods  e.g.     w i l l be appropriate. we report here on a special - but common - case of the above process: the failure of  everyday knowledge   auch as that 1 b i l l i o n is a big number. we use such rules freely and yet we find it very hard to give reasons why we believe them. as we become more expert in some f i e l d   we learn to replace these rules with more specific facts  and to use more cautious rules  such as:  don't assume - find out!  
　　　thus  as we become better at economics  we learn not only the real sices of various economic quantities  but we learn to postpone judging the relative sises of things until we have explicit points for comparison. outside of economics  of 

course  we w i l l s t i l l think 1 b i l l i o n is a lot. 
　　　nor do we stop using everyday rules in economics immedistely. the f i r s t time one f a i l s   it is neither removed nor changed. it is only 
this work was funded in 	part 	by 	the 	office 	of 	tagged 	with 	the 	failure 	episode. 	the rule is 
naval research under contract n1-c-1. 	s t i l l used to generate new beliefs  as long as 	no 
1 

further problems t r i t e * if t problem does t r i t e   however  end the rule is considered suspect  its previous failures tre remembered. the tdvtnttge of t h i t approach is that rules stay simple and efficient as long ae they work most of the tine. but failures tre noted and chtnges made if a rule fails several tines. the distdvtnttge of this tpprotch is thtt a rule known to have problems may s t i l l be tdding plausible  but incorrect  beliefs to the system. 
the alfred project 
	alfred 	 automatic 	learning 	using 
failure-driven reminding in an expert domain  is a program being developed at yale to model learning sequences such as the one above. in february and march  1  several learning sequences were gtthered by the alfred project while retding stories in the wall street journal end the new york times about politicians and their proposals regarding the economy. these stories were about credit controls  anti-inflation proposals  economic platforms  partisan battles over budget cuts  and to on. as our i n i t i t l beliefs tbout i n f l t t i o n   recession  politicians  and so on  were found wanting  t number of obviout letrning experiences became the basis for our research. 
learning and understanding 
　　　like solowty 1  tnd sussmtn   we believe thtt letrning does not sttrt from scratch  but occurs in the context of an ongoing application of knowledge that already exists. new things are interpreted as instances of old things  and failures of f i t ctute existing knowledge and processing structures to be modified. in our case  we made alfred a story understanding program  similar to sam  tnd pan  1   but with three major differences. 
　　　f i r t t   alfred does not yet ttke natural language input. we give it conceptual repretentttiont equivtlent  tt t crude level  to sentences from selected articles. this is t serious wetkness. ve feel that skimming and focusing strttegiet tre closely linked with the letrning process. alfred needs more than t  natural language front-end.  it needs a we1-developed model of language analysis driven by dynamically changing intereats and beliefs. 
　　　second  alfred chtnges its knowledge structures on the basis of the stories it understands. it is not enough for alfred to understand an argument. it must also decide 
whether to believe it or not. 
 members of the yale letrning group htve included mtrk burstein  gregg collins  drew mcdermott  shoshana hardt and alan cypher. 
　　　third  alfred is designed to detl with expectations thtt f t i l rtther then succeed. we deliberately choose stories that contradict what alfred already believes. 
the alfred program 
     we developed two programs to test the failure-driven reminding aspect of our learning 
model. one program  written by mark burstein  covered the the credit card and gas tax example given at the start of this paper. the program took hand-analyred input  looked for related stored beliefs  and checked for contradictions. if one was found  the belief supported only by an everyday rule was rejected and the everyday rule 
was marked with an exception episode. 
　　　the first input represented  the government has proposed controls on credit cards.  alfred linked this to a belief that credit causes inflation  and predicted further input supporting the notion that credit card control would reduce inflation. 
 proposed-act 
act  govt-control 
object  credit type  credit-card     
found causal connection 
 cause 
ante  rate-ch dir *dvar obj  credit   
conse  rate-ch dir *dvar obj  inflation    
inferring problem is inflation 
expecting support for 
 cause actor  us-covt  
ante  rate-ch dir  nec  
obj  credit type  credit-card    
conse  rate-ch dir  neg  obj  inflation    
　　　the next input represented  credit cards contribute $1 billion in credit.  alfred used a set of rules called check-scales which decided that $1 billion was enough to make credit cards a significant part of total credit and hence a 
　　　significant factor in cauaing inflation. 
 fraction 
part  credit 
type  credit-card  
amount  1 scale  billion  
unit  $    
of  credit actor  consumer    
check-scales - credit-card is a significant part of total credit 
accepting input as support for  cause 
ante  rate-ch dir  neg  
obj  credit type  credit-card    
1 conse  rate-ch dir  neg  obj  credit    
　　　alfred now believed credit card control would work. the next input represented  controls on credit cards w i l l do l i t t l e to combat inflation   which was contradicted the newly acquired belief. the input was not yet supported however so nothing happened. 
 cause 
ante  govt-control-economy obj  credit type  credit-card    
　　　　con1e  rate-ch dir  nec  obj  inflation  size  small    found referent govt-control-economyo 
*** input is contradiction to known causal - expecting support for contradiction statement. 
　　　the next input represented  credit cards are only $1 b i l l i o n out of $1 t r i l l i o n in total credit.  check-scales said that this made $1 billion a small fraction of total credit  supporting the new claim. since it was an everyday rule in check-scales  called 
cs-default-whole  that said that $1 b i l l i o n was big  alfred saved the current story as an exception to cs-default-whole. 
 fraction of  credit amount  1 unit  $  scale  billion    
part  credit type  credit-card  amount  1 unit  $  scale  billion     
check-scales - credit-card is a small part of total credit 
accepting input as support for negation of 
 cause 
ante  rate-ch dir  nec  obj  credit type  credit-card    
conse  rate-ch dir  neg  obj  credit    
***** processing error - accepted contradictory supports 
searching for errors made in process check-scales 
found probable source of error in use of 
cs-default-whole in check-scales when processing input 
 fraction size  large  
part  credit type  credit-card   of  credit actor  consumer    
indexing error episode ep1 on mop check-scales 
　　　now alfred was given  the representation for  the government announced a 1 cent tax on o i l to reduce its consumption.  this was linked to a belief that prices affect consumption. 
 proposed-act 
act  govt-control problem  oil-consumption  
	solution 	1 
 sales-tax object  oil unit  gal   
amount  1 unit  cents      
found support 
 cause ante  change dir *dvar 
obj  purchase-price 
obj *ovar   
conse  rate-ch dir *dinv 
obj  $buy actor  consumer  
obj *ovar    
for input. 
	the next input represented  this 	would 	save 
1 barrels of o i l per day.  this was linked to a belief that causal effects are commensurate; hence  a small change in price should lead to a small change in consumption. but check-scales  using cs-default-whole  said that 1 barrels was a large change. an internally generated contradiction was noted  blamed on cs-default-whole  and the previous story episode was remembered. 
 cause 
ante  sales-tax object  oil unit  gal   
　　　　　　　　　amount  1 unit  cents    conse  rate-ch dir  neg  
obj  $buy actor  consumer  obj  oil   
amount 
 1 scale  thousand  unit  barrel  
per  day     
check-scales --  1 unit  cents   is a small part of total 
 purchase-price obj  oil unit  gal    
check-scales -  1 scale  thousand  
unit  barrel  per  day   
is a significant part of total $buy1 
error detected 
 size  of consequent - significant 
does not match expectation given antecedent 
 size  - small 
noted error in applying verify-prediction 
found probable source of error in use of cs-default-whole in check-scales 
** step cs-default-whole cauaed previous error in episode ep1 
reducing certainty of process-step 
cs-default-whole to 1 
　　　there ate many problems with the program just presented. it was not a general purpose story understander  and it did not start with a lot of knowledge. but the moat glaring problem to us was that we had no well-defined structure for episodes and no well-defined deacription of the debugging process. our solution  presented in the rest of this paper  tries to answers both deficiencies 
with the same data structure. 
1 

mops several kinda of prtdicatta and relationships needed in the political domain  aee  . 
　　　alfred's proceaaing structures are baaed on govt-control ia invoked after reading a schank'e memory organisation packeta  mopa   1 . aentence such as  carter propoaea controla on although mopa are basically juat frames     1     credit carda.  thia f i l l s two variablea: 
1    the important thing ia that they organise epiaodic experiences in long-term memory while actor    carter/us-government they simultaneously process those experiencea. object  - credit carda reminding ia basic to understanding  since the proceaa of understanding ia the same aa the because the normal function of credit carda ia to proceaa of epiaodic memory search. furthermore  get credit: aa inputs change the aet of categories uaed in 
memory  the 	courae 	of 	future 	understanding 	ia 	activity  = get credit changed. 
　　　　　　　　　　　　　　　　　　　　　　　　　　　　　because credit causea inflation and inflation ia mopa in alfred have the following parte: one of the problems the government wanta to f i x : 
1. a conceptual pattern called the trigger 	problem  ＊ inflation 
1. a aet of conceptual patterns  that make 	in thia way  alfred infers that carter intends to up the content of the mop 	limit credit card uae in order to fight inflation. 
1. a aet of indicea to submope or epiaodea the rulea uaed to f i l l variablea are important in alfred because they explicitly 1. a aet of rules for f i l l i n g in the repreaent a kind of knowledge that changea during variablea in the conceptual patterns learning. in particular  there ia a class of rulea  called default rulea  that f i l l in variablea with approximate answera when exact onea in the description below  we shall mostlly can't be found. as alfred becomes more expert in ignore the indicea. each index value labels a political economics  it haa to learn to replace link to either a particular epiaode  or a submop theae default rulea with more apecific  more 
collecting together a aet of similar epiaodea  aee accurate onea.  and  . 
	to 	organise 	rulea  	we 	uae 	proceaa 	mops. 
　　　here ia an outline of covt-control  a mop where a regular mop organisea evente and other organising knowledge about governmental regulation mopa  a proceaa mop organises inference rules. a of some activity: pattern in a proceaa mop may aay something like 
	 rule tr failed   where the variable r 	ia 	f i l l e d 
govt-control 	with a pointer to some rule. 
trigger:  actor control  object 	one uee of proceaa mopa ia to organise a 	aet of 	rulea 	into a atrategy  which can then be uaed 
concepts: tactor authorise aa a rule. for example  check-scales ia a aet of lbgal-constraint uee of  object  rulea for judging the relative aise of a number: cause 
	rate of tactivity = decreaae 	check-scales: 
	goal of tactor 	trigger: to find the relative aise tr for tn 
	= govt-fix-problem tproblem  	unite of tx 
	indices: domain of activity 	rulea: to fill tr: 
	kind of regulation 	compare tn againat a known scale 
	object regulated 	for tx 
	rulea: to fill tactivity: 	if thia f a i l s   compare tn againat a 
	{activity    function of 1bject 	known scale for a auperclaaa of tx 
	to fill  problem: 	the aecond rule for f i l l i n g tr ia 	a 	default 
	find an undeaired state cauaed by 	rule. 
tactivity 
	another example 	of 	a 	proceaa 	mop 	ia 	the 
　　　question marks precede the variablee in the exception mop. it recorda what happens when a conceptual patterna. legal-constraint and problem in understanding occurs. below are the govt-fix-problem are other mopa. legal-constraint trigger and conceptual parte for the exception containa knowledge about how laws work. proceaa mop  the rulea w i l l be described shortly : govt-fix-problem containa knowledge about reducing unwanted situationa by regulation  de-regulation  taxation  and ao on.  authorise  ia one of 
i t a 

exception: 
trigger: belief 1 conflicts with  b1 
concepts: belief  b1 is wrong. 
 b1 is supported by rule  r1. use  r1 instead of  r1. 
　　　this says that when a new belief contradicts an old one  find the incorrect belief  b1  find the rule rl that led to i t   and find a better rule  r1. 
　　　the exception process nop provides not only a mechanism for fixing the problem  but a frame for remembering how the problem was fixed. with the exception process mop we have both a mechanism to drive the debugging process  and  at the same time  a knowledge structure to organise the relevant pieces of the episode for long-term memory. 
　　　the exception process mop is invoked when a 
　　　belief conflict is recognized. sometimes  sn article may explicitly contradict a held belief. more commonly  the conflict arises during the inference process. for example  when the member of our learning group read that an additional tax on gas of 1c* per gallon would cause consumption to decrease by 1 barrels per day  he thought that this effect was too big for that small an increase in the price of gas. 
　　　in our model  the contradiction arose from inferences triggered by this causal: 
increase price of gas by 1cv a gallon cause 
decrease use of gas by 1 barrels a day 
knowledge about causation includes the following inference rule: 
if a causes b 
and a and b are changes in quantities 
then the change in b is commensurste with the change in a 
　　　in order to use this rule  we find out how big the changes are with the check-scales process mop. check-scales compares the 1 gss tax against the cost of a gallon of gas  $1  snd concludes that the increase is small. therefore  the causal rule above predicts that only a small change should result in something else. 
　　　but when check-scales looks at the decrease of 1 barrels per day  it can't find any actual value for gas consumption. therefore it uses a default value of millions of barrels per year. millions of barrels per year implies that 1 barrels per day is a large change. 
　　　the contradiction between the small change predicted by the causal and the large change returned by check-scales invokes the exception process mop. its job is to find out what went wrong and f i x i t . 
　　　the exception proceas mop f i l l s in ita variables by finding the belief at fault  where that belief came from  and what can be done to prevent it from happening again. to do this  the exception process mop has the following rules: 
exception: 
trigger: belief  b1 conflicts with  b1 
concepts: belief  b1 is wrong. 
 b1 is supported by rule  r1. 
 r1 should be used instead of  r1. 
rulea: to fill  b1   r1  the incorrect belief and rule : 
if  b1 is not yet supported then 
 wait for more input  
if tbi   b1  ia supported only by a default rule  r  then  b1   b1  and 
 r are at fault 
to fill  r1  the better rule : 
if a default rule is at fault  and  v is the variable that the rule f i l l s   then use the rule:  to fill 
 v: wait for more input  
　　　the above assumes that alfred at least partially remembers how it inferred the faulty belief. also it only deals with failures by default rules. a more realistic mop would reconstruct probable sourcea of faulty beliefs and would deal with other kinds of rule failures. 
　　　the exception process mop waita until the new input is supported. then it finds the faulty belief by looking to see which one is supported by s default rule. the belief based on a default rule is replaced by the belief that contradicted i t   and the default rule is replaced with the more cautioua  wait for more input.  if the faulty belief is the new one  then the replacement rule can be uaed immediately. in our example  when our learner realised that he might have incorrectly acaled 1 barrels in the article he was reading  the  wait for more input  was applied at once. he looked for the real value to use. 
　　　 wait for more input   by delaying variable bindings  can cauae aome complex and d i f f i c u l t problems for a predictive understanding process. an alternative possibility would be to scan the text for the desired information  juat aa the frump program  skimmed newspaper articles to f i l l in its sketchy scripts. 

summary of the learning model 
     our research hat stretted several idessa regarding the learning procett: 
1. episode-taving - when an inference rule in a mop f a i l s  or it inadequate  in understanding an episode  an exception link it made from that rule to the episode  tpecifying what the correct rule ahould have been. 
1. failure-driven reminding - when an inference rule in a mop f a i l t  or it inadequate   i t t exception linkt  if 
any  are followed to tee if a previout epitode providet a better antver. 
1. the exception procett mop - thit directt recovery and organizes the memory of the failure for later retrieval. 
