 
constructing  good  models for chemical carcinogenesis was identified in ijcai-1 as providing a substantial challenge to  knowledge discovery  programs. attention was drawn to a comparative exercise which called for predictions on the outcome of 1 rodent carcinogenicity bioassays. this - the predictive toxicology evaluation  or pte  challenge - was seen to provide ai programs with an opportunity to participate in an enterprise of scientific merit  and a yardstick for comparison against strong competition. here we provide an assessment of the machine learning  ml  submissions made. models submitted are assessed on:  1  their accuracy  in comparison to models developed with expert collaboration; and  1  their explanatory value for toxicology. the principal findings were:  a  using structural information available from a standard modelling package  layman-devised features  and outcomes of established biological tests  results from mlderived models were at least as good as those with expert-derived techniques. this was surprising;  b  the combined use of structural and biological features by ml-derived models was unusual  and suggested new avenues for toxicology modelling. this was also unexpected; and  c  significant effort was required to interpret the output of even the most  symbolic  of ml-derived models. much of this could have been alleviated with measures for converting the results into a more  toxicology-friendly  form. as it stands  their absence is sufficient to prevent a whole-hearted acceptance of these promising methods by toxicologists. this suggests that ml techniques have been able to respond - not fully  but nevertheless substantially - to the pte challenge. 
1 	challenge papers 1 	introduction 
in his essay  two conceptions of science   medawar  1   the distinguished biologist peter medawar describes the valuation of contributions to science thus:-
here then are some of the criteria used by scientists when judging their colleagues' discoveries and the interpretations put upon thern. foremost is their explanatory value - their rank in the grand hier-
archy of explanations and their power to establish new pedigrees of research and reasoning. a second is their clarifying power  the degree to which they resolve what has hitherto been perplexing. .. 
　explanations that reach this stage of inspection are usually understood to have achieved an acceptable level of accuracy  however measured. with the emergence of ml programs capable of constructing empirical generalisations from scientific data  it is possible to examine the extent to which such machine-authored descriptions meet the criteria used to judge their human counterparts. this is of special interest if such programs are intended to act as genuine scientific assistants to experts. 
　one area for conducting such an examination was proposed in the form of the predictive toxicology evaluation challenge  in ijcai-1  see  srinivasan et a/.  1  . the problem of predicting chemical carcinogenesis described there is particularly well-suited as a testbed for a number of reasons. besides its undisputed humanitarian value  principal reasons are that:  1  there is an urgent need for low-cost  accurate toxicity models that can reduce a reliance on slow  expensive rodent bioassays  bristol et a/.  1 ;  1  there is much to be learnt about the molecular mechanisms underlying carcinogenic activity; and  1  there is a well-established scientific programme within the u.s. national toxicology program  ntp  concerned with the comparative evaluation of toxicity models  which may be of human origin  see: dir.niehs.nih.gov/dirlecm/pte1.htm1 . these provide machine-based  hypothesis constructors  the opportunity to construct accurate models  which may yield 
     1  all internet sites mentioned in this paper are to be prefixed with http:// unless otherwise indicated 

new insights and subject to review much in the manner described by medawar. 
　this paper reports on the machine learning  ml  submissions made to this ijcai challenge from its inception in august  1 to december  1. the paper is organised as follows. section 1 summarises the course of the challenge from 1  and presents the models selected for further evaluation. section 1 contains an assessment of the accuracies of the ml models in comparison to those developed under the guidance of expert toxicologists  this includes toxicology expert systems . section 
1 contains an appraisal of the explanatory value of the ml models1. section 1 concludes this paper. 
1 	the i j c a i p t e challenge: details and submissions 
as part of the ntp  the national institute of environmental health sciences  niehs  organises the predictive toxicology evaluation  or pte  project. the project  bristol et a/.  1  is concerned with predicting the outcome of rodent bioassays measuring the cancerous activity of a pre-specified set of compounds. in its simplest setting  predictions are restricted to either 
 pos  to denote carcinogenic  or  neg  if otherwise. there is no restriction on the type of method used to construct the toxicity model. the pte project accepted predictions until late 1 for 1 compounds  collectively known as pte1  undergoing bioassays within the ntp - the last of these assays being completed by june  1. 
　the relevance of the pte project to programs concerned with  knowledge discovery  directly led to the pte challenge in ijcai-1. here  it was proposed to collect submissions from ai techniques. submissions were to be made at a prescribed internet site  www. comlab.ox. ac.uk/oucl/groups/machlearn/pte  and consisted of two parts:  1  prediction: pos and neg classification for the pte1 compounds; and  1  description: details of the materials and methods used  and results obtained with the technique. the former was needed to assess model accuracy  and the latter for replicabiiity of results and evaluations of model comprehensibilty. 
the site accepted submissions from august 1  1 
 one week after the challenge was announced at ijcai1 . submissions received up to november 1  1 were eligible for assessments of chemical comprehensibility. the challenge was regularly advertised at major ai conferences and in electronic newsgroups  and our records indicate that the data provided by the challenge site were retrieved over 1 times1. by november 1 
1
　　performed by one of the authors  d.w.b.   who is a toxicologist. 1 clearly  only very limited conclusions can be drawn from this figure. our records suggest that the data were extracted by groups with a wide range of research interests. however  the reader will note that the final submissions appear to be largely from those interested in inductive logic programming  ilp . while it is possible that the emphasis on a descriptive 1  1 legal submissions were received  by legal here we mean that both  prediction  and  description  parts of the submission were in order . these are summarised in figure 1. space restrictions prevent us from providing a description here of each entry the reader is directed to the internet site under the  description  column for complete details1. 
　at this point  it is worth noting an important point of difference between the submissions made to the ntp's pte project  and those in figure 1. all predictions by the former were made before true classifications on any chemical in pte1 were known. the timing and duration of the ijcai challenge has precluded the possibility of such a truly blind trial. we rely on submissions to abide by challenge regulations that prevent the use of pte1 classifications in any way to direct model formation or selection. 
1 	assessment of predictive accuracy 
at the time of writing this paper  the classification of 
1 of the 1 compounds had become available. figure 1 tabulates the predictive accuracies achieved by the models described in the submissions in figure 1  henceforth called  ml-derived models  . 
　benigni  benigni  1  provides a tabulation of the predictions made by several toxicity prediction methods on a subset of the pte1 compounds. we concentrate here on those techniques that involve substantial input from experts. these include models devised directly by toxicologists or those that rely on the application of compilations of such specialist knowledge  that is  expert systems . in  benigni  1   there are 1 such  expertderived  models due to: huff et al.  huf   huff et al  1    oncologic  onc   woo et a/.  1    bootman  bot   bootman  1    tennant et al.  ten   r.w. tennant  1    ashby  ash   ashby  1j   benigni et al  ben   r.benigni et al.  1    purdy  pur  
 purdy  1    derek  der   marchant  1    and compact/hazardexpert  com   lewis et a/.  
1  . excluding missing entries  predictions are available from these methods for 1 pte1 compounds. a comparative tabulation on this subset against the mldcrived models is in figure 1. 
　comparisons based on predictive accuracy overlook an important practical concern  namely that the costs of different types of errors may be unequal. in toxicology modelling  the cost of false negatives is usually higher than those of false positives. borrowing from terminology in signal-detection   sensitivity  refers to the fraction of pos chemicals classified as pos by a model; and  specificity  refers to the fraction of neg chemicals 
component discouraged the use of methods like neural networks  we have no way of knowing why some ml researchers failed to respond to the challenge. 
1
　　 the reader should note that the submission ou1 was from two of the authors here  a.s. and r.d.k. . as far as we are aware  none of the submissions appear to have involved a toxicologist during model-development. 
	srinivasan  king  and bristol 	1 


figure 1: legal submissions to the pte challenge. here  ilp  stands for inductive logic programming. 

figure 1: estimated accuracies of submissions made to the pte challenge. here  accuracy refers to the fraction of 
pte1 compounds correctly classified by the ml-derived model. the quantity in parentheses next to the accuracy figure is the estimated standard error. the classifications are based on the outcome of 1 of the 1 pte1 bioassays. the classification of remaining 1 is yet to be decided.  def  refers to the simple rule that states that all compounds will be  pos . this was not an official submission to the challenge and is only included here for completeness. 

classified as neg by a model. figure 1 is a scatterdiagram that shows the position of each model in this two-dimensional probability space. 
　complementary to sensitivity and specificity are: the fraction of pos predictions that are actually pos  and the fraction of neg predictions that are actually neg. termed here as  positive predictivity  and  negative predictivity   these measure the accuracy of each type of prediction. good models should exhibit high predictivity values. figure 1 shows the scatter-diagram of the models along these dimensions. 
　keeping in mind the mandatory caution that must be exercised when interpreting figures derived from such small test-sets  figures 1  1  1 and 1 appear to suggest that ml-derived models are able to at least match the performance attained by their expert counterparts. as is evident  1 of the 1 ml-derived models achieve the predictive accuracy threshold set by the def model. this is in contrast to 1 of the 1 expert-derived models. 1 ml-derived models  le1  le1  lrd  lrg  oai  ou1  achieve false-negative error rates of at most 1 with false-positive rates of no more than 1. this is matched by only 1 expert-derived model  onc . 1 mlderived models  the previous 1 and ou1  also achieve positive and negative predictive rates of at least 1 
1 	challenge papers 
 figure 1 . this is in contrast to 1 expert-derived models. elsewhere  we present a more detailed assessment  of these trends based on a cost-sensitive technique termed roc-analysis  srinivasan et a/.  1 . due to space restrictions  a summary has to suffice here. the analysis shows the ml-derived models to be extremely competitive  with lrg being the pick of the best across a range of reasonable error-costs and prior distributions over class values. lrg was obtained with a stochastic technique which resulted in rules that use  amongst others  attributes encoding the results from ilp methods. 
1 	assessment of explanatory value 
at the outset of this section  it is worth emphasising that as submitted  none of the ml-derived models would be considered toxicology acceptable. this comment extends even to the most transparent submission like ou1  which presents a relatively simple  by ml standards  decisiontree obtained from a well-known algorithm  c1 . much of this probably stems from a lack of toxicology expertise amongst the program users  and the lack of any  client specifications  in the statement of the challenge. we intend to rectify the latter in future experiments  pte-1  see  srinivasan et a/.  1  . however  some attempt by all developers at improving clarity by including tables of 


figure 1: comparison of estimated accuracies of expert and ml-derived models. the figures are based on the classification of 1 of the 1 pte1 compounds for which predictions are available from all models. as before  estimates of standard errors are in parentheses. some expert-derived models include a third category of classification called  borderline carcinogen.  these are simply taken as a pos classification here. as before def predicts all 

chemicals as pos. 
names and structures identified by the rules  clear statements of their reliability etc.  would have greatly assisted the evaluation exercise. the application of ml techniques to modelling toxicity endpoints is a relatively new research development in toxicology  and it is essential that descriptions of representations used and results obtained are as thorough as possible  see for example   bristol  1  for an appraisal of the requirements of models from both developer and prospective-client points of view . nevertheless  the performance of the models have been sufficiently intriguing to foster further examination. 
　in performing an evaluation of the explanatory value provided by the ml-derived models  we have found it instructive to examine their contributions in the following categories: 
a. those that suggest any new lines of investigation for toxicology modelling; 
b. those that confirm  clarify or contribute to current ideas in toxicology; and 
c. those that are uninteresting or unlikely. 
our examination is restricted to the models that showed the most promise in the previous section  namely: le1  le1  lrg  oai  ou1. unfortunately  the most accurate model  lrd  could not be considered  as no explicit model was provided. further  it is not our intention to single out any one model as being the  best  - rather  it is to provide an overall assessment of the value of using ml methods in toxicology. 
　of most interest is the frequent use of combinations  in models like lrg  of chemical structure and biological tests. for some time  there has been vigourous debate on how classical structure-activity modelling can be applied to toxicity problems. this form of modelling relates chemical features to activity  and works well in-vitro. the extent to which these ideas transfer to toxicity modelling - which deals with the interaction of chemical factors with biological systems - is not evident. by using a combination of chemical features and biological test outcomes  the ml-derived models provide one possible method for dealing with the chemical effects in such  open  systems. if the accuracies obtained with such rules are borne out on larger datasets  then this would constitute a significant advance in structureactivity modelling for toxicology. this is certainly worth further investigation and falls in category a. 
　a number of aspects of some of the models can be categorised in category b. as an example  ou1 selects a combination of mouse lymphoma and drosophilla tests as a strong indicator of carcinogenicity. many toxicologists believe that relationships exist between genotoxicity and carcinogenicity. while the only accepted correlation involves the salmonella assay  this rule suggests a different combination of short-term tests could be equally  or more effective. similar comments could be made on a number of other fronts: the presence of methoxy groups  sulphur compounds  and biphenyl groups are all identified in various ways as being related to toxicity. these are in line with what is currently 
	srinivasan  king  and bristol 	1 

'1 
c 
figure 1: scatter-diagram showing the performance of expert and ml-derived models based on their false positive 
 x-  and false negative  y-  error rates. for two models with the same x-value  the one with the smaller y-value is 

preferable. 
known in toxicology. 
　given the relative opaqueness of the output  it is hard to judge the extent to which the models have identified aspects in category c. the general approach in toxicology is to be wary of  explanations  that only pertain to a few or uninteresting chemical structures. these do occur in the models submitted  and appeal to have been ignored  except in the case of ou1  where some editing attempt is undertaken . we do not enumerate examples of this here. 
1 	conclusions 
toxicology is a young science that is primarily driven by intense health and industrial interests focused on specific chemical substances. a practicing toxicologist is regularly confronted with urgent requests to provide reliable information about the next substance of interest - whatever it might be. this situation demands that the toxicologist be able to call on  or develop  predictive models that are not only accurate  but also cover an extremely wide range of noncongeneric dissimilar chemicals. these range from pure organic and inorganic compounds to polymers and complex mixtures. predictions also need to be generated for a variety of toxicity endpoints  bristol  1 . aspiring assistants - human or otherwise - seeking to aid an expert toxicologist in this model-building endeavour  must be capable of suggesting robust solutions that are accurate and understandable. this forms the crux of the pte challenge - do at programs meet these requirements when constrained to the task of predicting chemical carcinogenesis  the short answer  for the submissions participating in the challenge  is:  not yet.  the qualifier is important though  as they do show considerable potential to achieve this goal. this opinion is based on the evidence that  a  mod-
1 	challenge papers 
els developed by these programs are clearly competitive on accuracy terms with those derived with significant expert assistance; and  b  even with almost no effort made to render the output chemically understandable the models have still suggested unusual ways to proceed with toxicology modelling. whether such programs can make the transition from promising apprentices to valuable assistants will depend on whether their developers recognise the paramount importance of ensuring that the models are phrased in terms familiar to a toxicologist  and on continued good results with larger datasets. 
a c k n o w l e d g e m e n t s 
the authors would like to acknowledge the significant effort made by the machine learning community in responding to the pte challenge. in particular  sincere thanks are due to the groups whose models we have used in the analysis here  namely those at leuven  belgium   lr1  france   ofai 
 austria   and the al lab  taiwan. at oxford  the model oul was largely developed by ngozi dozie  a msc student in 
computation. a.s currently holds a nuffield trust research 
fellowship at green college  oxford. during the first six months of the pte challenge  he was supported by smithkline beecham. a.s. and r.d.k would also like to thank donald michie  stephen muggleton  and michael sternberg for interesting and useful discussions concerning the use of machine learning for predicting biological activity. we thank the support staff' of the computing laboratory  oxford in particular  ian collier for his help with the wet  pages related to the pte challenge. 
