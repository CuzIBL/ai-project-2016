 
　inducing disjunctive and iterative macro-operators from empirical problem-solving traces provides a more powerful knowledge compilation method than simple linear macro-operators. whereas earlier work focused on when to create iterative macro-operators  this paper addresses how to form them  combining proven optimization methods such as extraction of loop invariants  with techniques for further optimizing retematch efficiency. the disjunctive and iterative composition processes have been implemented in fermi and its underlying production system language. empirical results confirm substantial rule-match speedups and system performance improvements in different application domains. 
1 introduction: the nature of disjunctive and iterative macro-operators 
whereas classical ai techniques for problem solving and planning require vast amounts of search to produce viable solutions for even moderately complex problems  humans typically require much less search as they accrue experience over time in any given domain. inspired by this ubiquitous observation  researchers in various subdisciplines of ai have sought methods of encapsulating more knowledge to reduce search. these methods range from expert systems  where all knowledge is laboriously handcoded at the outset  to machine learning approaches  where incrementally ac-
cumulated experience is stored  processed and compiled into a generalized reusable form. 
　machine learning approaches to knowledge compilation include analogical and case-based reasoning  carbonell  
1  carbonell  1  schank  1  schank  1  doyle  1  hammond  1  where past experience is recycled directly  as well as the compilation of new rules distilling essential aspects of past experience. the latter methods range from explanation-based generalization  dejong & mooney  1  mitchell et al 1  shavlik & dejong  
1  minton & carboncll  1  minton et al  1   to generalized chunking  newell  1  laird et al 1   and all forms of macro-operator formation  fikes  
1  anderson  1  korf  1  minton  1  cheng & carbonell  1 . in all cases  the objective is to transform knowledge into a much more efficient  operational form  using past experience and domain analysis as primary 
jaime carbonell 
school of computer science 
carnegie mellon university pittsburgh  pa 1 
resources. 
　although the basic idea of a macro-operator has been well-defined since the days of strips  fikes  1   their full potential is only recently being realized. until the more recent work on the fermi problem solver  cheng & carboncll  1   macro-operators were considered to be nothing more than frozen sequences of atomic operators with several generality and efficiency modifications  e.g.: the triangle-table encoding in strips that enabled all subsequences of larger macro-ops to be encoded compactly and used by the problem solver . systematic methods for determining when and how to build useful macro-operators were developed after strips  such as exploiting problem decomposability  korf  1  or providing heuristic utility metrics for deciding whether a new macro-op was likely to increase overall problem-solver performance  e.g.  iba's peak-topeak heuristic  iba  1  and minton's s-macros and tmacros  minton  1  . figure 1 depicts the basic process of linear macro-operator formation. 

1 disjunctive macro-operators 
one phenomenon that reduces the effectiveness of simple linear macro-operators is the variation inherent in nontrivial task domains. if multiple variants of a problem present themselves  each may require separate macrooperators that differ on only one or two component steps. three solutions present themselves: creating a very general macro-operator  which will likely be overly-general   enabling analogical transformation of macro-operators  which incurs high partial-match costs   and producing a disjunctive macro-operator that shares the common parts and diverges only at the key differences. we have chosen the third alternative  see figure 1   generalizing the macro-operator composition algorithm to create disjunctive macro-operators and introducing disjuncts into our rule-description language. section 1 describes and evaluates the disjunctive composi-

　 this research was supported in part by darpa contract number f1-c-1 amendment 1  and aip-onr contract number n1-k-1-n1. 
1 	machine learning 

tion algorithm in detail. 


figure 1: 	juxtaposed operator sequences and single disjunctive sequence  solving variants of a problem 
1 iterative macro-operators 
simple linear macro-operators can never generalize to an arbitrary number of applications of atomic operators; for example  different macro-ops must be learned to solve the 1-disk tower of hanoi  the 1-disk one  etc. furthermore  both linear macro-ops and soar chunks  laird et al  1  which encode multiple applications of a rule turn polynomial-time matches into exponential ones  tambe  1 . iterative macro-operators  as depicted in figure 1  prevent these serious problems in fermi and would solve the soar  expensive chunk  problem. 

　previous work on formulating iterative macro-operators focused on detecting situations where such macro-operators would be useful. for instance  cheng and carbonell  cheng & carbonell  1j formulated a method of searching for repeated subgoal-change differences in the solution trace of a complex problem. riddle  riddle  1   on the other hand  repeatedly decomposed the problem-solution graph by fractioning at the minimal interaction points among the subgoals and operators in the graph  until the remaining fragments were either atomic  single operator  or highly interconnected sets of operators. from each highlyinterconnected set  she composed an iterative macrooperator by simply grouping the operators with an exit condition. 
　in principle  macro-operators  iterative or otherwise  can reduce search in two different ways: 
1. a macro-op prevents the application of incorrect or irrelevant operators within the body of the macro-op. if the macro-op were not present  the problem solver could traverse unproductive search paths before backtracking to the correct solution path. however  the reduced state-space search is accomplished at the cost of increasing the match-time search of the larger set of operators  original ones plus the new macroops . utility metrics attempt to optimize this tradeoff  minton  1 minton et al  1  iba  1   as does the creation of disjunctive and iterative macro-operators. since both of the latter are more general than simple linear macro-ops  fewer need be generated. 
1. a macro-operator can also compile away temporary computation in the matching process  especially in iterative subsequences. moreover  when the iterative macro-op is functionally equivalent to multiple invocations of the original operator  the original operator need not be matched. thus match-level optimizations can reduce  fine-grain search  just like operator-level aggregations can reduce  coarse-grain search . 
　although cheng's and riddle's methods address the course-granularity search reduction problem  they do not address the equally important issue of optimizing the macroop itself - both methods keep the complete primitive operators as inviolate atomic units. if one knows that a set of operators will be applied in a fixed iterative sequence  then u-ansformations to the operators themselves can yield significant efficiency improvements  as we show in section 1. this paper addresses those transformations in detail  and demonstrates speedups greater than six-fold  see section 1 . in order to synthesize and exploit iterative macro-ops effectively one needs both: a reliable method for recognizing when they should be formulated  and an effective method for composing them efficiently. 
1 composing disjunctive operators 
previous work on learning disjunctive concepts has focused on learning in predicate logic representations  quinlan  1  iba  1   rather than learning disjunctive production rules. the bagger system  shavlik & dejong  
1  learns a limited form of single-operator iterative rules  allowing only one source rule to be focused on. also  disjunctions are limited to different instantiations of the same single operator. cheng  cheng & carbonell  1  used only linear composition techniques  so when alternate rules were encountered they were not composed together but were placed into an  agenda  and tested sequentially. in the present work  rule sequences which differ by which rules fire as well as how they are instantiated  are composed into a single more efficient disjunctive macrooperator. 
　unlike linear macro-operators  disjunctive macrooperators retain the generality of the original rules by encoding all possible paths through these rules. for example  even though the training example depicted in figure 1 demonstrates two solution paths  the single induced disjunctive macro allows all four paths to potentially be taken. encoding these paths with linear macro-operators requires a rule for each path  and since  cheng & carbonell  1  doesn't compose disjunctive rules  it would only compose the a and b operators together. once all implicit sequences have been learned with a disjunctive operator  the atomic source rules no longer need to be matched  resulting in more savings. 
	shell and carbonell 	1 

　the three phases of forming disjunctive macro-operators are: 
1. identifying similar operator subsequences. different operator sequences that solve the same goal and that share relevant substructures must be noted. these alternate sequences are the basis of the ensuing composition processes. 
1. identifying alternate rules. the operator sequences identified in the first step are juxtaposed to find shared subsequences and alternate rules  see figure 
1 . 
1. composing disjunctive operators. the shared and alternate rules are composed into a single disjunctive macro-operator. this allows the elimination of computation of temporary results by disjunctive elements  as well as computation which is redundant across alternate disjunct operators. 
　identification of similar operator subsequences was described in  cheng & carbonell  1 . we describe in this section how we identify the alternate rules  show how we have extended linear operator-composition methods to compose those alternate rules into a single disjunctive macro-operator  and show the usefulness of disjunctive macro-operators with timings. 
1 identifying alternate rules 
cheng identified alternate rules by the goal they solved. 
but since our disjunctive composition algorithm acts on rule sequences  we no longer have to assume that every rule matches a goal and instead find these alternate rules by applying sequence-comparing techniques similar to  sankoff  
1  to the alternate linear rule traces. for example  in the fermi algebra module  eliminating an unknown algebraic variable from a system of linear simultaneous equations may be achieved by either of the two sequences of rule applications: 
sequence 1 rule # sequence 1 
solve-for-unknown-n 1 solve-for-unknown-n reduce-eqns&unkns 1 reduce-eqns&unkns select-var 1 select-var 1 rearrange-eqn select-eqn 1 select-eqn substitute 1 substitute eliminate 1 eliminate 　the composition program identifies rearrange-eqn as an alternate rule in sequence-1  and pairs the remaining rules. the preconditions and actions in rearrange-eqn at this position are called condition element disjuncts and action disjuncts  respectively.1 
1 composing disjunctive macro-operators cheng in  cheng & carbonell  1  assigned the alternate rule disjuncts to agendas instead of composing them into a disjunctive macro-op. by adding disjunctions to our retebased  forgy  1  production-system language frulekit  shell & carbonell  1  and introducing domainindependent disjunctive operator composition  we are able to encode multiple alternate rules in a single disjunctive macro-op. first we will summarize the linear rulecomposition algorithm  then show how it is extended to 
　　1   condition elements  refer to tests for the existence of objects meeting given constraints. 
1 	machine learning 
composing disjunctive rules. 
1.1 summary of composition basics 
　in the linear composition algorithm on which all previous composing programs are based  see  anderson  1    one of the following actions are taken with each condition element  ce  in the input  or source rules: 
  discard. ce's that match a wme1 that was created previously in the rule trace are declared redundant and are discarded. 
* merge. ce's are merged into others  that is  the union of their tests and bindings are taken  if they match a wme that also matched a previous ce in the sequence. 
  insert. all other ce's  including absence tests 1 are retained and inserted into the macro-op. actions are treated similarly. 
1.1 discarding redundant ce's and actions 
　when generalizing composition to multiple rule sequences  note that the same ce is matched by different wme's in each such sequence. therefore a ce is discarded only if  in every alternate rule sequence  the wme that matched it was created previously in that sequence. if the ce is redundant within some sequences but not others  then the sequences are not considered analogous and a disjunctive macro-op will not be formed. instead  two linear macro-ops will be created. similarly  action elements are only labeled redundant if they create wme's that are removed later in all sequences  or if they remove wme's that were created earlier in all sequences. 
　another extension to handling redundant ce's concerns production variables bound in an eliminated ce. if these variables are used later in the rule  then an alternate expression for them must be found. if the eliminated variable can not be re-expressed in terms of an inserted non-disjunct action or condition element  then it must be found in inserted action or ce disjuncts. the variable will take on the value of that disjunct expression only if the associated ce disjunct was true. 
　for example  when composing the substitute rule  see figure 1  into the macro-op  its action 