 
much work has been done in dialogue modeling for spoken and multi-modal humancomputer interaction. problems can arise in situations that do not correspond to the dialogue model. for this reason  we propose information-centered dialogue processing in which the actions to be taken by the dialogue system are determined as a function of the information available in the discourse  the database and the domain model. in order to arrive at fully specified representations of the intended actions  the specificity of the representations is increased by unification  integrating information from multi-modal input  database access and domain knowledge. our approach differs from other state-of-the-art systems in that it does not rely on explicit dialogue models. instead  we show how partial and underspecified representations of the situation can be used in a spoken dialogue system to generate clarification questions and to guide the user to arrive at his or her communicative goal. we show furthermore how probabilistic information can be used to disambiguate without clarification questions. evaluation results and dialogue examples demonstrate the flexibility and naturalness of our approach. 
1 	introduction 
many state-of-the-art spoken dialogue systems rely on explicit dialogue modeling. often  modeling is done by describing the dialogue states and the expected response using finite-state automata  dialogue grammars or rules. typically  the models are built and evaluated using data from the wizard-of-oz technique. 
　however  modeling a dialogue explicitly as a sequence of actions has several drawbacks. first  dialogue models are costly to construct. the dialogue corpus collected have to be large enough to allow generalizations about the dialogue scenario  and considerable human effort is required to create and refine dialogue models. second  even if the corpus is large enough for building good dialogue models  there is always the sparse data problem. third  as the number of input modalities increases  so does the complexity of the dialogue model. this situation is exacerbated by the fact that different modalities provide different aspects of information  e.g. a touch screen device typically provides geometric information that must be dealt with appropriately. fourth  instructions given by the user are often severely underspecified to the degree that the information conveyed by the request alone is not sufficient to perform the intended operation. fifth  recognition errors in any of the modalities may cause partially inappropriate representations of requests to be generated. here again  fall-back strategies have to be provided. all these difficulties increase modeling complexity. 
　to overcome these problems  we propose a departure from the model-based approach to dialogue processing in favor of an information-centered approach. we develop and use semantic representations that can be compared by the information they contain. possible systems actions can thus be determined in function of the degree of specificity of the available information rather than a dialogue state. additionally  these representations permit situated recovery strategies in cases where the user underspecifies the request or speech recognition errors occur. furthermore  the information-oriented view allows for easy integration of multi-modal input. to demonstrate the feasibility of our approach we implemented an interactive map program with spoken and multi-modal input. 
1 	using information in interpreting situations 
we consider the semantic information that stems from a users' request  taken together with the context and domain modeling  as a situation. we claim that a situation in dialogue is non-hostile  since  in general  the dialogue partners are cooperating. thus  in order to reduce dialogue modeling  we can exploit information we encounter in the present situation to guide the actions of our system. 
　we place ourselves in the context of task-oriented human-computer interaction in which the user wants the system to perform certain operations or to deliver certain information. the dialogue system is able to perform a given set of operations such as displaying objects  printing out information on objects  and the like. each operation requires a set of parameters that have to meet lower bounds of information. for example  the operation display obj might require the coordinates of all objects to be uniquely defined. the purpose of the lower bounds on the parameter values are twofold. first  they serve to 

1 	natural-language processing and graphical presentation 

determine the minimal amount of information the user must provide in order to execute the intended action. second  they also define communicative goals that have to be met if the user wants to execute an action. the system has to determine which operation the user wants to perform and sufficiently identify the required parameters. 
1 	information-centered representations 
1 	domain modeling 
in many knowledge representation formalisms  knowledge is organized in a hierarchical way. to represent the background knowledge  we use a partial ordering of concepts. we call the concepts types and the ordering relation  the subsumption relation  according to carpenter . additionally  we describe what features a type consists of by so-called appropriateness conditions  carpenter  1 . the terminological knowledge base allows us to express the is-a relations  in the following noted in cursive letters  and is-part-of relations  noted in capital letters  that hold between objects. we restrict the type hierarchy to be a rooted tree. we can then extend the hierarchy by adding probabilities along the i s - a links expressing the degree of confidence that an object of type is also of type where is a direct supertype of . for the time being  the probabilities are supplied manually  but they could also be determined empirically1. we ensure that the probabilities on the i s - a links leaving a type  sum up to one  

so that p is indeed a probability distribution. a part of the domain modeling we use in our interactive map implementation is shown in figure 1. 

figure 1: a part of the type hierarchy and its appropriateness conditions used in the map application. the least specific type is at the bottom of the tree. 
　note that the domain model does not make any assumptions about the form of the dialogue  i.e. the type hierarchy only represents knowledge about the objects present in the chosen domain  but does not encode any assumptions on how interaction between user and system should take place. 
!
　　this can be done as follows: among x objects in the data base  we find x1 restaurants  thus we set 
p f is of type obj-restaurant   f is of type obj-concrete  = x1/x 
1 	the semantic representations 
in many situations  the information conveyed in the users' request is not specific enough to determine the intended operation and its parameters entirely. the representations of the requests must reflect this fact in order to be able to represent partial information and to leave disjunctions unresolved. 
partially specified semantic representations 
we use typed feature structures  carpenter  1  to represent the semantics of the users' requests. these structures easily combine domain-dependent knowledge provided by the type hierarchy and semantics of utterances. moreover  they can represent partial information. we think of the semantic representations as partial descriptions of operations or objects. furthermore  typed feature structures can - as can types - be ordered by subsumption. we can thus determine if the information provided is specific enough for the execution of an action. the natural language input is analyzed by the 
phoenix parser developed by ward . its output  a partial semantic parse tree  is converted to a semantic representation by traversing the parse tree and applying construction rules to the nodes. the semantics of the utterance is given by a set of possibly partially specified feature structures that are stored in a discourse history. each structure represents the semantics of a phrase of one of the main syntactic categories np  vp  or pp. 
underspecified representations 
typed feature structures are partial descriptions of objects that themselves are represented by typed feature structures over the same type hierarchy. this allows us to determine described objects by compatibility check as well for anaphoric reference as for accessing objects from a database. 
　however  in general  feature structures do not adequately represent unresolved disjunctions  since the generalization of a set of feature structures is in general only an approximation of the set. for this reason  we use un~ derspecified feature structures to represent non uniquely 
referring expressions. examples of underspecifled feature structures are shown in figure 1. we think of an underspecifled typed feature structure as a compact representation of a set of  possibly partial  descriptions. underspecifled feature structures are a generalization of the typed feature structure formalism. our underspecifled representations are optimal in the sense that they represent explicitly all information which is common to more than one structure. since they explicitly factor out common information  they contain more information than the set of disjuncts itself. as described in the next section  this information is used when generating clarification questions. 
   in the attribute-value-matrix notation that we use to display feature structures  the type marked with an asterisk is the most specific lower bound of the types in its scope. the scope is indicated by curly brackets. the alternatives are represented inside curly brackets. indices behind types identify the typed feature structure this information belongs to. if there are no indices  the information belongs to all feature structures. features that are common to only a subset of all represented feature structures are in the scope of the most specific type that is in common to that subset. the feature phone in figure 1  a  is such an example. 
	denecke 	1 

　second  in cases in which the speech recognizer does not recognize the spoken utterance well or the utterance is ill-formed  it is probable that the parser will skip part of the input. in these cases  it generates a semantic representation of the utterance that represents only partially what has been said. typically  the information 

figure 1: three underspecified feature structures representing the objects referred to by the nps  the museum    the beehive  and  primanti brothers . there are two objects called  beehive  in our data base  one being a cinema  the other one a cafe. moreover  we find three different museums and three restaurants called  primanti brothers . 
　the shape of the type hierarchy is of importance for the information represented in underspecified structures. the 'deeper' the type hierarchy  the more knowledge about the relations of the types is encoded. this is analogous to the information content of decision trees. consequently  the specificity of underspecified feature structures increases with the amount of information in  or the depth of  the type hierarchy. 
　moreover  the nodes of underspecified feature structures are arranged as decision trees themselves that are sub-trees of the original type hierarchy  see figure 1 for an example . the probabilities along the is-a links have to be re-normalized to take missing types into account. in order to adapt the probabilities correctly  the underspecified feature structures must be optimal. 
1 	information-centered dialogue processing 
1 	integrating information 
the flexibility of a dialogue system increases with the capability of integrating information from different sources. in the representation is not sufficient to trigger the intended operation. an example which occurred during our test sessions is the request how can i get to the elbow room that was recognized as how can i get to   zoom out  . the semantic parser skips the bracketed 
part of the input so that the generated feature structure 
is 

a total type inference procedure allows us to determine the least specific well-typed feature structure while retaining all present information. in this case  the type inference procedure yields 

this representation makes requests for missing values easier  or even unnecessary  to trigger  since all possible features are present after the type inference and furthermore  their value is set to be the most general type allowed for in this context. this means that strict domain modeling contributes to more specific representations. 
1 	natural-language processinc; and graphical presentation 　third  when unifying well-typed feature structures the result is not necessarily well-typed  carpenter  1 . type inference may yield more specific structures  thus allowing for more specific clarification dialogues. this is important in cases in which the specificity of a parameter increases during the dialogue  and the associated operation also needs to be more specific. 
integrating information from different input sources 
in systems that allow for discourse context and multimodal input at the same time  ambiguities between the deictic and anaphoric use of pronouns arise. the information supported by a pronoun is that it refers to an object the user expects to be uniquely identified by the context and possibly additional input. if complementary deictic information is present  this information is used to determine the object the user refers to. in case where more than one pronoun of possibly deictic use occur in the phrase  time information is used to correctly join deictic and acoustic information. 
　in our case  a gesture can be a point given by coordinates  a line given by the coordinates of the two endpoints  or an area given by a set of lines. on the semantic level  this information is represented in feature structures. if complementary semantic information coming from spoken input is available  the gestural and language representations are associated and unified. for example  this makes it possible to disambiguate the representation of an anaphor as shown in figure 1 by mouse click or drawn circles to refer to areas in which all restaurants should be shown. 
database access 
data retrieval procedures are linked to the types of the roots of feature structures. for the semantic representation of every np in the discourse an appropriate data retrieval procedure  if provided  is executed. database retrieval procedures generate an underspecified feature structure on the object level representing all objects that are compatible with the information on the semantic level. note that the database access also takes geographical information into account  for example when assigning to the semantic representation of t h i s restaurant 
+  mouse click  

the restaurant that is displayed on the screen is closest to the given point as opposed to some other object such as the intersection that is even closer to the point than the restaurant. 
　the same retrieval procedures apply when resolving reference of anaphora. this makes it possible to generate representations of ambiguous referring anaphora. 
1 	strategies for d i s a m b i g u a t i o n 
due to speech recognition errors or inappropriate input  only parts of the input may be used for interpretation. as an example  consider a database access that yields an underspecified feature structure representing the destination of a path. another example is the case in which necessary information is not conveyed by the user. in both cases  the representation is not informative enough to execute the users' request. 
　we investigate two strategies to recover from this state. the first strategy  an unbiased one  is to ask a clarification question  a second  a biased strategy  is to automatically choose the most probable interpretation  thus avoiding the clarification question. note that the proposed representations do not favor one strategy over another. contrarily  they allow for determining all possible solutions of the request in a first step. disambiguating using clarification questions yields an unbiased strategy. on the other hand  a selection according to some  domain specific  criterion implements the biased strategy. this gives a general domain-independent dialogue strategy that is parametrized by domain-specific constraints such as selecting the next place in a map task or always asking clarification questions in high-security environments. 

do you mean the cafe or the cinema  
do you mean the carnegie museum of natural history  the andy warhol museum or the fort p i t t museum  
and 
do you mean the one cherry ave  the one on 1th st or the on forbes ave  
respectively. the first question makes use of the different type of the two objects  thus based on a path whose length is zero  the second question asks for the name of the object  since the type is the same  namely obj university   and the third question asks for the ad-
dress  since type  obj-restaurant  and name  ' 'primanti brothers''  are the same. this example shows again that the information currently present in the situation determines the form of the question. 
　how then can the disambiguation be achieved  if all readings that are incompatible with the additional information are removed from the underspecified structure  only the structures satisfying the users' constraints remain. 
　the advantage of this method is that one question is sufficient to disambiguate the underspecified structure. the drawback of this approach is that the question tend to appear unnatural if the number of disjuncts is large  greater than 1 . in these cases  a second strategy is provided. one could ask the user to provide a certain 
	denecke 	1 

bit of information that helps to reduce the number of possible entities and repeat the process as long as the expression refers uniquely. the caveat here is that the user does not necessarily know the answer to the question and often more than one question must be asked. 
　the information the user may provide to disambiguate the underspecified representations is determined by the underspecified representations and  since these are the result of preliminary processing  by the context. moreover  all choices that are compatible with the present information are explicitly determined. thus  the proposed strategy leaves all possible choices to be decided by the user. for this reason  this strategy is unbiased. 
　note that a prerequisite for the approach are underspecified representations that factor out differences between the possible options. in underspecified feature structures it is easy to determine where the differences of a set of feature structures are and how different  in terms of entropy  the values are. 
　it should also be noted that the system does not expect the user to pick one of the proposed answers. instead  the system is able to deal with any information that serves to disambiguate  not necessarily entirely  the underspecified representations1. 
avoiding clarification dialogues 
there are cases in which the unbiased strategy described above leads to tedious and lengthy dialogues. in these cases  a biased strategy is used. consider for example the discourse'' show me the path from here to carnegie mellon u n i v e r s i t y ' ' and ''can i have more information on t h a t   . a  simplified  representation of the information conveyed by the anaphora is given by the underspecified feature structure 

　the underspecified representation yields the following information: first  the most specific type p* that subsumes the type of all objects  obj in the above example   and second  the n types  whose most specific lower bound is p* of the objects  obj-path and obj.concrete in the above example . this applies recursively until the final types  those that are not marked with an asterisk  are reached. the paths from the type of the root to the final types yield a decision tree that is a subtree of the type hierarchy. re-normalizing the probability distributions for the sub-hierarchy yields probability distributions again. the decision tree for the above example is shown in figure 1. 
　the representations allow us to calculate the probabilities p  pk | p*  just by going from p* to pk in the 
1
　　in the current implementation  the language model predicting the answer is generated on the fly which means that the speech recognizer assumes the answer to be one of the proposed options. however  this is a limitation imposed by the way we control the recognizer in the current implementation  not a limitation of the dialogue processing algorithms. 

figure 1: the decision tree extracted from the type hierarchy after re-normalization of the probability distributions 
sub-hierarchy while multiplying the conditional probabilities according to 
		 1  
the resulting distribution is indeed a probability distribution  since 

　the result of this process is a probability distribution assigning probability to each object the anaphor may refer to as a function of the context  the domain modeling and the a priori probabilities. we use a heuristic to disambiguate the anaphora: if the difference between the largest probability and the second largest probability exceeds a certain threshold  there is a strong preference to one reading  thus this reading is assumed to hold. otherwise a clarification dialogue is generated in order to ask for additional information. 
　this strategy is biased in that it disambiguates an underspecified representation such that it refers to the preferred reading. in other words  not all options are left to the user  since the system decides itself what the user meant. the intention behind this heuristics is that it is cheaper in average to repair an incorrect reading a few times than ask every time a question. 
　a prerequisite for correct probabilistic interpretation in eq. 1 is the optimality of underspecified representations w.r.t. representing all common used information. let us assume for the sake of example that the underspecified structure does not represent the fact that both the current position and the university are subsumed by obj.concrete. this yields a structure that represents adequately the circumstances but is suboptimal in that the fact that both obj.university and cur pos are of type obj.concrete is not represented. 

　the decision tree represented by this underspecified structure is not optimal either. 
1 	an example application 
1 	natural-language processing and graphical presentation to verify empirically the validity of our approach  'we implemented an interactive map dialogue program whose purpose is to provide a test bed for interactively accessing information about places on a map and to generate path descriptions. as one of the input sources  we use the janus continuous speech recognizer  waibel  1  using a 1 word vocabulary. 
   the dialogue system is implemented as a multiblackboard system. the currently used blackboards are the map database providing street and place information  the discourse blackboard storing the semantic representations of formerly uttered requests and dialogue answers and the multi-modal blackboard representing objects that can be referred to by gesture. the data base stores information of about 1 streets  1 of which have been selected to be in the vocabulary of the speech recognizer  and of about 1 different locations. knowledge sources may contribute complementary information. each knowledge source implements a set of typed predicates that are used to form expert system style rules. the rules contain typed variables that are instantiated with typed feature structures stored in the discourse blackboard  such as word  parse tree  semantic representations or objects in the discourse module provided the type of their root is as least as specific as the type of the variable. the set of rules mediates the communication between different modules and the integration of information. the users input is added to the discourse blackboard. the behavior of the system  i.e. the interaction of the knowledge sources  the blackboard and the user is entirely determined by the information available in the blackboards and the rules together with the side effects of the predicates as implemented by the knowledge sources. this results in a stepwise refinement of the available representations. 
　this design allows for easy adaptation to a new domain since adaptation does not require new dialogue modeling. no assumptions on the domain have been hard-coded. new knowledge sources may easily be added so that new predicates may be made use of in the constraints  thus implementing a possibly completely different behavior of the system. 
1 	evaluation 
the implemented dialogue system can perform ten different actions that include panning or zooming the map  calculating paths  their lengths and travel times as well as scheduling hotel and restaurant reservations. altogether  1 request were presented to the system. in 1 cases  the system generated a representation of an incorrect operation. these errors were mostly caused by recognition errors. the length of the dialogues ranged from 1 system-initiated turns  for fully specified requests  to 1 system-initiated turns for hotel reservation. 
　in 1 cases  at least one feature was missing in the final representation. most often  this was due to incorrectly interpreted prepositional phrases. in 1 cases  features were assigned incorrect types which were mostly wrong place names or street names which again was due to misrecognitions. 
　type inference proved to be a useful feature since  due to recognition errors  the semantic parser often skipped parts of the input. in these cases  it was oftentimes possible to restore at least partially the original information as conveyed by the users request. 
1 	summary 
in this paper  we developed an information based approach to dialogue systems. the central idea is that actions are performed according to the specificity of the representations  not as a function of an explicit state the system is in. in particular  the system does not make any assumptions on what information in which order at what time using which input device the user should provide. 
　the chosen representations are particularly useful for representing spontaneous speech since spontaneous speech consists for the most part of utterance fragments for which no closed formula is derivable. moreover  speech fragments may increase specificity not only by adding fillers but also by generating more specific types. the disambiguation of underspecified feature structures using fragmentary and elliptical input shows some similarities to the micro conversational events described in  poesio and traum  1  since the unification of the semantic representations of answers incrementally increases the information in underspecified representations. 
　we showed that  in task-oriented domains  context information and domain model are informative enough to determine what the system should do. since our approach is information-centered  multi-modal input can easily be implemented if all input information is represented using the same formalism. 
　we investigated two strategies to obtain complementary information of the user. the unbiased strategy leaves all action to the user at the expense of possibly many questions to answer  whereas the biased strategy restricts possible actions. biased strategies are of particular interest if unintended actions can be avoided or repaired so that the mean effort is minimized. 
acknowledgements 
i would like to thank alex waibel  wayne ward and bernhard suhm for discussions  advice and suggestions concerning the topics discussed in the paper. also  i would like to thank the three anonymous reviewers for their helpful comments. 
