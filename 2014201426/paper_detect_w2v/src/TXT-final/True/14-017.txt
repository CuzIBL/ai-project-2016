 1. the registration problem 　image registration finds a variety of applications in computer vision. unfortunately  traditional image registration techniques tend to be costly. we present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of newton-raphson iteration. our technique is taster because it examines far fewer potential matches between the images than existing techniques 　the translational image registration problem can be characterized as follows: we are given functions f x  and g x  which give the respective pixel values at each location x in two images  where x is a vector. we wish to find the disparity vector h that minimizes some measure of the difference between f x + h  and g x   for x in some region of interest r.  see figure 1  

　the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies  either expressed or implied  of the defense advanced research projects agency or the us government. 
　an obvious technique for registering two images is to calculate a measure of the difference between the images at all possible values of the disparity vector h-that is  to exhaustively search the space of possible values of h. this technique is very time consuming; if the size of the picture g x  is nxn  and the region of 
1 

possible values of h is of size mxm  then this method requires 1 m1  time to compute. 
   speedud at the risk of dossible failure can be achieved by using a hill climbing technique this technique begins with an initial estimate h1 of the disparity to obtain the next guess from the current guess hk  one evaluates the difference function at all points in a small  say  1  neighborhood of hk and takes as the next guess h k+1 that point that minimizes the difference function. 
　another technique  known as the sequential similarity detection algorithm  ssda    only estimates the error for each disparity vector h. in ssda  the error function must be a cumulative one such as the l1 or l1 norm. one stops accumulating the error for the current h under investigation when it becomes apparent that the current h is not likely to give the best match. 
some registration algorithms use a coarse fine search strategy. 
see |1  for an example. one of the techniques discussed above is used to find the best registration for the images at low resolution  and the low resolution match is then used to constrain the region of possible matches examined at higher resolution. 
　the algorithm we present specifies the order in which to search the space of possible h's in particular  our technique starts with an initial estimate of h  and it uses the spatial intensity gradient at each point of the image to modify the current estimate of h to obtain an h that yields a better match this process is repeated in a kind of newtonraphson iteration. if the iteration converges  it will do so in 1 m1 log n  steps on the average. this registration technique can be combined with a coarse fine strategy  since it requires an initial estimate of the approximate disparity h. 
　our solution to this problem depends on a linear approximation to the behavior of f{x  in the neighborhood of x  as do all subsequent solutions in this paper. in particular  for small h  

the success of our algorithm requires h tn be small enouqh that this approximation is adequate. in section 1 we will show how to extend the range of h's over which this approximation is adequate by smoothing the images. 
　the approximation to h given in  1  depends on x. a natural method tor combining the various estimates of h at various values of x would be to simply average them: 
	 1  
we can improve this average by realizing that the linear approximation in  1  is good where f{x  is nearly linear  and conversely is worse where |f  x | is large. thus we could weight the contribution of each term to the average in  1  in inverse proportion to an estimate of |f  x |. one such estimate is 

1. the registration algorithm 
　in this section we first derive an intuitive solution to the one dimensional registration problem  and then we derive an alternative solution which we generalize to multiple dimensions. we then show how our technique generalizes to other kinds of registration. we also discuss implementation and performance of the algorithm. 
1. one dimensional case 
　in the one dimensional registration problem  we wish to find the horizontal disparity h between two curves f x  and g x  = f{x + h . 
this is illustrated in figure 1. 

	 1  
since our estimate is to be used as a weight in an average  we can drop the constant factor of 1/h in  1   and use as our weighting function 
	 1  
this appeals to our intuition; for example  in figure 1  where the two curves cross  the estimate of h provided by  1  is 1  which is bad; fortunately  the weight given to this estimate in the average is small  since the difference between f' x  and g' x  at this point is large. the average with weighting is 
	 1  
　having obtained this estimate  we can then move f x  by our estimate of h  and repeat this procedure  yielding a type of newton raphson iteration. ideally  our sequence of estimates of h will converge to the best h. this iteration is expressed by 
1 	 1  
1. an alternative derivation 
   the derivation given above does not generalize well to two dimensions because the two-dimensional linear approximation occurs in a different form. moreover   1  is undefined where f' x  ＊ 1  i.e. where the curve is level. both of these problems can be corrected by using the linear approximation of equation  1  in the form 
	 1  
to find the h that minimizes the l1 norm measure of the difference between the curves 
	 1  
this is essentially the same solution that we derived in  1   but with the weighting function w x  = f' x 1. as we will see  the form of the linear approximation we have used here generalizes to two or more dimensions. moreover  we have avoided the problem of dividing by 1  since in  1  we will divide by 1 only if f' *  = 1 everywhere  in which case h really is undefined   whereas in  1  we will divide by 1 if f' x  = 1 anywhere. 
the iterative form with weighting corresponding to  1  is 
which can be accomplished by smoothing the image. the tradeoff is that smoothing suppresses small details  and thus makes the match less accurate. if the smoothing window is much larger than the size of the object that we are trying to match  the object may be suppressed entirely  and so no match will be possible. 
　since lowpass-filtered images can be sampled at lower resolution with no loss of information  the above observation suggests that we adopt a coarse-fine strategy. we can use a low resolution smoothed version of the image to obtain an approximate match. applying the algorithm to higher resolution images will refine the match obtained at lower resolution. 
　while the effect of smoothing is to extend the range of convergence  the weighting function serves to improve the accuracy of the approximation  and thus to speed up the convergence without weighting  i.e. with w x  = 1. the calculated disparity h1 of the first iteration of  1  with f{x  = sin x falls off to zero as the disparity approaches one half wavelength. however  with w x  as in  1   the calculation of disparity is much more accurate  and only falls off to zero at a disparity very near one half wavelength thus with w x  as in  1  convergence is faster for large disparities 
1. implementation 
　implementing  1  requires calculating the weighted sums of the quantities f'g  f'f  and  f' 1 over the region of interest r. we cannot calculate f'{x  exactly  but lor the purposes of this algorithm  we can estimate it by 
　　　　　f{x + ax - f x  f' x  ~ 
and similarly for g' x   where we choose ax appropriately small  e.g. one pixel  some more sophisticated technique could be used for estimating the first derivatives  but in general such techniques are equivalent to first smoothing the function  which we have proposed doing for other reasons  and then taking the difference. 


1 

as a 
as the quantity to minimize with respect to 	and h. the 

　the discussions above of iteration  weighting  smoothing  and the coarse fine technique with respect to the one dimensional case apply to the n dimensional case as well. calculating our estimate of h in the two dimensional case requires accumulating the weighted sum of five products   g - f fk   g - f f y  f1x  f1r and fxf   over the region r  as opposed to accumulating one product for correlation or the l1 norm. however  this is more than compensated for  especially in high resolution images  by evaluating these sums at fewer values of h. 
1. further generalizations 
　our technique can be extended to registration between two images related not by a simple translation  but by an arbitrary linear transformation  such as rotation  scaling  and shearing. such a relationship is expressed by 

where a is a matrix expressing the linear spatial transformation between f x  and g x . the quantity to be minimized here is 

to determine the amount aa to adjust a and the amount ah to adjust h  we use the linear approximation 
		 1  
when we use this approximation the error expression again becomes quadratic in the quantities to be minimized with respect to differentiating with respect to these quantities and setting the results equal to zero yields a set of linear equations to be solved simultaneously. 
　this generalization is useful in applications such as stereo vision  where the two different views of the object will be different because of the difference in the viewpoints of the cameras. linear transformations account for the distortion of planar objects assuming orthographic projection; this is often an adequate approximation to the local distortions of arbitrary objects under the actual perspective projection. 
　a further generalization is possible to account for the fact that the brightness values of the pixels may be different in the two minimization of this quantity  using the linear approximation in equation  1   is straightforward. this is the general form promised in section 1. if we ignore a  minimizing this quantity is 
equivalent to maximizing the correlation coefficient  see  for example   ; if we ignore a and b as well  minimizing this form is equivalent to minimizing the l1 norm. 
1. application to stereo vision 
　in this section we show how the generalized registration algorithm described above can be applied to extracting depth information from stereo images. 
1. the stereo problem 
　the problem of extracting depth information from a stereo pair has in principle four components: finding objects in the pictures  matching the objects in the two views  determining the camera parameters  and determining the distances from the camera to the objects. our approach is to combine object matching with solving for the camera parameters and the distances of the objects by. 
using a form of the fast registration technique described above. 
　techniques for locating objects include an interest operator   zero crossings in bandpass-filtered images   and linear features . one might also use regions found by an image segmentation program as objects. 
　stereo vision systems that work with features at the pixel level can use one of the registration techniques discussed above. systems whose objects are higher level features must use some difference measure and some search technique suited to the particular feature being used. our registration algorithm provides a stereo vision system with a fast method of doing pixel-level matching. 
　many stereo vision systems concern themselves only with calculating the distances to the matched objects. one must also be aware that in any real application of stereo vision the relative positions of the cameras will not be known with perfect accuracy. gennery  has shown how to simultaneously solve for the camera parameters and the distances of objects. 
1. a mathematical characterization 
　the notation we use is illustrated in figure 1. let c be the vector of camera parameters that describe the orientation and position of 
1 

camera 1 with respect to camera 1s coordinate system. these parameters are azimuth  elevation  pan  tilt  and roll  as defined in . let x denote the position of an image in the camera 1 film plane of an object. suppose the object is at a distance z from camera 1. given the position in picture 1 x and distance z of the object  we could directly calculate the position p x z  that it must have occupied in three space. we express p with respect to camera 1 's coordinate system so that p does not depend on the orientation of camera 1. the object would appear on camera 1's film plane at a position q p c  that is dependent on the object's position in three-space p and on the camera parameters c. let g x  be the intensity value of pixel x in picture 1  and let f q  the intensity value of pixel q in picture 1. the goal of a stereo vision system is to invert the relationship described above and solve for c and z  given x  f and g. 

1. applying the registration algorithm 
　first consider the case where we know the exact camera parameters c  and we wish to discover the distance z of an object. suppose we have an estimate of the distance z. we wish to see what happens to the quality of our match between f and g as we vary z by an amount az. the linear approximation that we use here is 
	 1  
this equation is due to the chain rule of the gradient operator; 
1q/1p is a matrix of partial derivatives of the components of q with respect to the components of p  and df/dq is the spatial intensity gradient of the image f q . to update our estimate of z  
we want to find the az that satisfies 


　we have implemented the technique described above in a system that functions well under human supervision. our program is capable of solving for the distnaces to the objects  the five camera paprameters described above  and a brightness and contrast parameter for the entire scene  or any subset of these parameters. as one would expect from the discussion in section 1  the algorithm will converge to the correct distances and camera parameters when the initial estimates of the z 's and c are sufficiently accurate that we know the position in the camera 1 film plane of each object to within a distance on the order of the size of the object. 
　a session with this program is illustrated in figures 1 through 1 the original stereo pair is presented in figure 1  readers who can view stereo pairs cross eyed will want to hold the pictures upside down so that each eye receives the correct view  the camera parameters were determined independently by hand-selecting matching points and solving for the parameters using the program described in . 
　figures 1 and 1 are bandpass filtered versions of the pictures in figure 1. bandpass filtered images are preferred to lowpass filtered images in finding matches because very low spatial frequencies tend to be a result of shading differences and carry no  or misleading  depth information. the two regions enclosed in rectangles in the left view of figure 1 have been hand selected and assigned an initial depth of 1 in units of the distance between cameras. if these were the actual depths  the corresponding objects would be found in the right view at the positions indicated figure 1. after seven depth adjustment iterations  the program found the matches shown in figure 1. the distances are 1 for object 1 and 1 for object 1. 

1 figures 1 and 1 are band pass-filtered with a band one octave higher than figures 1 and 1. five new points have been handselected in the left view  reflecting the different features that have become visible in this spatial frequency range. each has been assigned an initial depth equal to that found for the corresponding larger region in figure 1. the predicted position corresponding to these depths is shown in the right view of figure 1. after five depth-adjustment iterations  the matches shown in figure 1 were found. the corresponding depths are 1 for object 1  1 for object 1.1 for object 1  1 for object 1  and 1 for object 1. 
1. future research 
　the system that we have implemented at present requires considerable hand-guidance. the following are the issues we intend to investigate toward the goal of automating the process. 
  providing initial depth estimates for objects: one should be able to use approximate depths obtained from low-resolution images to provide initial depth estimates for nearby objects visible only at higher resolutions. 
  constructing a death map: one could build a depth map from depth measurements by some interpolation method. 
  selecting points of interest: the various techniques mentioned in section 1 should be explored. 
  tracking sudden depth changes: the sudden depth changes found at the edges of objects require some set of higher-level heuristics to keep the matching algorithm on track at object boundaries. 
  compensating for the different appearances of objects in the two views: the general form of the matching algorithm that allows for arbitrary linear transformations should be useful here. 
