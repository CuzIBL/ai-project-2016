 
finding models of a predicate logic formula is a well-known hard problem  whose complexity is exponential in the number of variables. however  even though this number is kept constant  substantial differences in complexity arise when searching for solutions in different problem instances. such a behavior appears to be quite general  according to recent results reported in the literature; in fact  several classes of hard problems exhibit a narrow phase transition with respect to some order parameter  in correspondence of which the complexity dramatically rises up  still remaining tractable elsewhere. in this paper we provide an extensive experimental study on the emergence of a phase transition in the problem of matching a horn clause to a universe  searching for a model of the clause or for a proof that no such model exists. as it turns out  phase transition in the matching problem depends in an essential way on two order parameters  one capturing syntactic aspects of the clause structure  intensional aspect   while the other related to the structure of the universe  extensional aspect . 
1 	introduction 
recent investigations have uncovered that several classes of computationally difficult problems  such as ksatisfiability problems  k-sat   cheeseman et al.y 1; 
crawford and auton  1; freeman  1; selman and 
kirkpatrick  1   constraint satisfaction problems  csp   smith and dyer  1; williams and hogg 1; prosser  1   graph k-coloring problems  cheeseman et al.  1; hogg  1   and the decision version of the traveling salesperson problems  gent and walsh  1; zhang and korf  1   show a phase transition with respect to some typical order parameter  i.e.  they present abrupt changes in their probability of being solvable  coupled with a peak in computational complexity  hogg et al  1 . 
1 	search 
　the identification of a phase transition may have important consequences in practice. in fact  the standard computational complexity of a class of problems is a pessimistic evaluation  based on worst-case analysis. the investigation of phase transitions can provide information on single instances of the class  moving the focus from the maximum complexity to a typical complexity of instances. the location of the phase transition divides the problem space into three regions: one in which the probability of existence of a solution is almost zero  and then it is  easy  to prove unsolvability; another region  where many alternative solutions exist  and then it is  easy  to find one; finally  a third one  where the probability of solution changes abruptly from almost 1 to almost 1  potentially making very difficult to find a solution or to prove unsolvability. 
　goal of the present work is to experimentally investigate the emergence of phase transition phenomena in the problem of matching a first order logic  fol  formula to a universe  in order to possibly find one of its model. more specifically  we extend the work of prosser  on csp along two directions. firstly  we investigate in depth the relation between formula complexity and universe complexity  and secondly  we compare complexities in a deterministic and a stochastic search approach. 
　the basic motivation for studying the matching problem is that it is a basic step in learning structured concept descriptions from a set of positive and negative examples  michalski  1   the exponential  in time and/or space  complexity of this task severely limits the types of concepts that can be learned and used. then  an effort to better understand the source of this complexity might suggest new and more effective learning strategies. even though we keep in sight this ultimate goal  we limit ourselves  in this paper  to present results on the matching problem per se. 
1 	problem definition 
a class of problems for which phase transitions have been investigated is that of constraint satisfaction 
problems  csp   williams and hogg  1; smith and 

dyer  1; prosser  1 . in a csp  values are to be assigned to n variables  knowing that each variable can take values in an associated set ak of cardinality a set r =  of constraints on variable values is given. the problem consists in finding a substitution for each variable such that all the constraints in are satisfied. a relation r involving variables is represented as a table  in which the allowed tuples of values  are specified. 
any tuple not occurring in the table is not allowed. if all the relations are binary  the csp is called binary  williams and hogg  1; prosser  1; smith and dyer  1 . 
　two parameters are usually defined in order to account for the constrainedness degree of a csp: constraint density and constraint tightness  prosser  1 . when dealing with a binary csp  the constraints can be represented as edges on a graph with n vertices  each one corresponding to a variable. the graph has possible edges; several constraints on the same pair of variables can be reduced to a unique one. by denoting by c the actual number of different edges activated on the constraint graph  the constraint density p1  prosser  1  is defined as: 

　parameter p1 belongs to the interval  1   with 1 corresponding to no constraints  and 1 corresponding to the case in which all possible pairs of variables are constrained. for a constraint involving the pair of variables  the tightness of the constraint is the fraction of value pairs ruled out by the constraint itself. if n is the cardinality of relation  the constraint tightness   prosser  1  is defined by: 

where l is the cardinality of the set of constants occurring in the universe. 
it is immediate to see that the matching problem is a 
csp. finding a solution for a csp can be formalized as a search on a variable assignment tree. solution nodes can only exist at level n  both for the csp and for the matching problem. 
　formulas we consider are existentially quantified  conjunctive formulas  of the type  with 
variables  from a set x  and m atomic predicates  from a 
set p . given a universe u  consisting of a set of relations  tables  containing the extensions of the atomic predicates  formula  is satisfiable if there exists at least one model in u. in learning relations  a formula is an inductive hypothesis and a universe is a positive or negative example of the concept to learn. then  in the learning problem  each hypothesis generated by the learner has to be matched against all the training examples  each one corresponding to a different universe. in machine learning  conjunctive formulas are the basic components of a global concept description  consisting of the disjunction of a number of them. 
　the following simplifying assumptions have been adopted in this framework: 
  each variable  ranges over the same set of constants  containing l elements 
  only binary predicates are considered. 
  every relation in u has the same cardinality  namely it contains exactly n tuples  in this case  pairs of constants . 
　instances of the matching problem  consisting of a formula  and a universe u  have been generated according to the procedure described in the following. given x and p  with the additional constraint m the generation of a formula  involves two steps. first  a skeleton  is deterministically constructed  using predicates from the set p: 
		 1  
　the skeleton guarantees that the resulting formula is not disjoint  i.e.  that  cannot be partitioned into two subformulas with disjoint sets of variable names. afterward  all the remaining  predicates in p are added to  randomly  uniformly  and without replacement  inside each predicate  selecting their arguments from the set x. with this procedure we obtain a formula: 
 1  
that 
may appear in more than one predicate. 
　considering now a universe u  each relation in u is constructed by creating the cartesian product  of all possible pairs of values  and selecting n pairs from it  uniformly and without replacement. in this way  a same pair cannot occur twice in the same relation. 
　in summary  the matching problems we consider are defined by a 1-tuple  n  m  l  n . from preliminary studies by the authors  sec also  prosser  1    it emerged that the phase transition location depends upon a combination of p1 and p1. in the present experimentation  we have directly considered the parameters l  number of constants occurring in the universe  and m  number of predicates occurring in a formula   and we have explored points in the whole  l  m  plane  by keeping n  number of variables  and n  cardinality of the relations in the universe  constant. 
1 	experimental setting and results 
the exploration of the plane  has been done by considering a mesh covering the region corresponding to the cartesian product of the sets  and m 
 for each of the 1 points  1 problems have been generated  according to the procedure described in section 1  for n = 1 and n = 1  1  1  1 and 1. the values for the number n of variables have been chosen 
	giordana  botta  and saitta 	1 

consistent with those actually employed in learning relations in machine learning  where a value n = 1 is rarely depassed. notice that the generation procedure requires that and the non repetition of pairs in relations requires that 
1 	probability of solution 
as the type of search algorithm does not affect the probability of a problem being solvable  but only the ease to find a solution  if any   we describe in figure 1  the 1dimensional plot of the probability of solution  as a function of l and m  for n = 1. for each point in the mesh   has been evaluated as the fraction of solvable problems among all the generated ones. 
　some contour level curves have also been reported in the  l m  plane; the leftmost curve corresponds to  = 1 and the rightmost one to  the graphs in 
figure 1 have several noteworthy characteristics  first of all  their striking steepness. the transition from  to  occurs in the region bounded by the contour level 
curves. 

figure 1 - 1-dimensional plot of the probability of solution  for n = 1  when n = 1. in the  l m  plane some 
countour level curves have also been drawn. 
　to the left of these curves  the problem has always a solution  whereas to the right of them no solution could ever be found. the second characteristic is the regularity on the horizontal planes: the projection on the  l  m  plane is a very smooth curve with a hyperbolic behavior. finally  by increasing the number of variables  there is a shift toward up and right  causing an enlargement of the solvable problems region  as it can be clearly seen in figure 1. 
　to perform the search  two algorithms have been used  a deterministic one  ad  and a stochastic one  ast and run on every problem instance. 

figure 1 - contour plots of the probability of solution for different values of the number of variables n = 1  1  and 1. 
1 	deterministic search 
the deterministic algorithm  explores the search tree depth-first  and stops as soon as a solution is found  or it explores the whole tree up to level n  if no solution exists. given a formula  with the structure  1   the search tree  is built up in such a way that each level corresponds to the assignment of values to the variables  considered in the sequence  the search proceeds through the construction of partially satisfied subformulas of  until either the whole  is satisfied or unsatisfiability is proved. we start with a subformula 
where is the subformula of  p  x  that contains those predicates with arguments  xi x1 . obviously  subformula may be empty  if the pair  x| x1  does not occur in 
is satisfiable  we consider variable x1 
and subformula 
where is the subformula of containing the predicates with arguments the process goes on in the same way until variable is considered. 
　in figure 1 a   the graph of the complexity  of the search  measured as the number of expanded nodes in the tree  and averaged over 1 repetitions  is reported. as we can see  the shape and location of the region of higher complexity roughly matches that of the transition in probability  but it is more irregular and much broader  


1 	search 

actually we have also experimented with different variable orderings  for example by considering the most constrained variables first. even though reduction in complexity may results from applying such heuristics  the qualitative behaviour does not change. hence  we have preferred to use a simpler search algorithm  because efficiency of the searcher in not on focus in this paper. 

like a  mountain chain . in particular  we may notice that in the bottom-left corner  where the easy problems should be  there are a few quite high peaks  even though there is a general decrease of the complexity. similar phenomena have been observed before  for instance by gent and walsh . finally  inside the  mountain   there is a large variability among different instances  witnessed by the variance plot  reported in figure 1 b . as one may expect  the highest variance occurs in correspondence of the highest peaks. 
　finally  in figure 1  the contour level plots of the probability of solution and those of the complexity are superimposed  in order to localize the maximum complexity with respect to the curve at 
figure 1 -  a  plot of the complexity  of a depth-first search for a first solution  for n = 1  averaged over 1 problem instances in each point   b  plot of the standard deviation of the complexity. 
　as we can see  the maximum complexity  apart from the anomalous peaks in the bottom-left corner  coincides with the line at  = 1  as it has been previously found  hogg ex al.  1 . 

figure 1 - contour level plots of the probability of solution and of the complexity of the search. the bold line corresponds to the probability level  = 1. for the complexity  four contour level plots have been drawn  corresponding to = 1  1  1 and 1  respectively. 
1 	stochastic search 
given the large size of the search tree  and the possibility for a solution to be anywhere inside  one may wonder under what circumstances a stochastic search algorithm may be effective. the use of a stochastic algorithm is also suggested by the added value offered by the on-line estimation of interesting quantities related to the tree  for instance its size  bailleux  1 . 
the specific search algorithm used here is a monte 
carlo algorithm mc  which explores one path on the search tree  starting from the root and ending in a leaf v  which may or may not be a solution. since we remember the already explored leaves  this path sampling is performed without replacement. algorithm mc is a monte carlo one  brassard and bratley  1   because it always provides an answer y  but the answer may be incorrect. 
　the same graphs as in figures 1 and 1 are reported in figures 1 and 1  for the complexity  of the stochastic search. 
　　from figure 1 a  we can see that the complexity has a more regular behaviour than cd. in fact  highest peaks are lower than  finding confirmed by the lower variance in figure even though  on average over all instances  the complexities are almost the same for the two cases. for instance  one may notice that the complexity of the stochastic search is higher than that of the deterministic one in the region of low l values and high m values. 
　an interesting aspect of the greater regularity of the stochastic search is the total absence of anomalous peaks in the  easy  region  which is absolutely flat. this more regular behaviour clearly appears in figure 1  the analogous of figure 1. the contour level plots are much cleaner and the maximum complexity neatly coincides with the line at 
	giordana  botta  and saitta 	1 

figure 1 -  a  plot of the complexity stochastic search algorithm  for n = 1  averaged over 1 problem instances in each point   b  plot of the standard deviation of the complexity. 
1 	discussion of the results 
the results described in the previous section extends the ones presented in  prosser  1 . in fact  by using a higher granularity in the mesh and collecting a larger variety of measures  some new phenomena emerge. first of all  it is impressive the very large variance in the complexity which is almost of the size of the average complexity. this can be explained considering the structure of the formula  which is not captured by the order parameter p1. depending on how the literals aggregate  the complexity can be extremely high or very low in correspondence of the mushy region. a similar behavior has been already mentioned in  hogg et al.  1 . however  the phenomenon seems even more evident here because of the double variability due to both the universe structure and the formula structure. it is worth noting that the stochastic algorithm exhibits a much lower variance  while the mushy region is sharper and the contours are more regular. the explanation is that the variability due to the localization of the solutions in the search tree is averaged by the specific stochastic strategy  while the variability due to the formula structure is not affected by it. 

figure 1 - contour level plots of the probability of solution and of the complexity  of the search. the bold line corresponds to the probability level  = 1. for the complexity  four contour level plots have been drawn  corresponding to = 1  1  1 and 1  respectively. 
   finally  from figure 1 it clearly emerges a quasihyperbolic relation between m and l. this pattern was partially visible in some diagrams reported in  prosser  1   but in figure 1 it is better defined  being the explored region wider and more finely sampled. in the following we give a theoretical interpretation of this phenomenon. let us consider the region of the phase transition  i.e.  the line in the  plane corresponding to this curve has a meaning only when m 
 we can try to justify the shape of this curve as follows. when  the average number of solutions is about 1  gent and walsh  1; walsh  1   i.e.  half of the instances are unsolvable  whereas the other half has a small number of solutions. 
　according to our procedure for generating problem instances  this situation corresponds to the case in which the first binary relation may be any  the following ones have one element partially constrained by the preceding ones  constants must be chained  in order to have a solution   and the remaining  have one element completely fixed  because they contain only variables already appeared in the first part of the formula. then  the probability of this event is proportional to: 
		 1  
　by taking the natural logarithms  we obtain from  1  a relation between m and l at the phase transition: 
 1  
   in  1  the constant parameter has been estimated  for each n  from a unique point on the experimental curve  obtaining the degree of fit shown on figure 1. it is interesting to note that  for  = 1   this relation coincides with the one previously obtained by the authors  

following a methodology similar to prosser's . 
1 	search 

figure 1 - experimental and theoretical contour plots of 1  for n = 1 and different values of n. the curves  for each value of n  are indistinguishable. the fitted values are; 

1 	conclusions 
in this paper  the complexity of matching first order conjunctive formulas has been analyzed  obtaining a relation linking the parameters describing the syntactic complexity and the semantic complexity. more specifically  we have identified the presence of three regions: a region  a  where the complexity is low and usually formulas are satisfiable; a region  b  where the complexity is very high and the probability of solution quickly moves from 1 to 1; a region  c  where the complexity is low again but the probability of solution is zero  in practice. 
　in order to correctly interpret such results  it is worth noting that  in region  c  only means that it is very rare to find a formula satisfiable in this region when the formulas and universes are extracted at random. on the contrary  it is always possible to construct a matching problem that has solution in region  c   and also it is always possible to construct problems in region  a   which do not have solutions. 
　therefore  the existence of a group of solvable problems in region  c  or of unsolvable problems in region  a  has to be interpreted as the evidence of a regularity  which potentially can be learned by a relational learner. vlasie  has pointed out a similar phenomenon for graph 1-colorability. on the contrary  the presence of solvable and unsolvable problems in the mushy region is exactly what one expects from a random instance generation. moreover  the high complexity in region  b  is a serious obstacle for any learning algorithm. 
　finally  the high variability inside the phase transition suggests to use  when necessary  on-line estimation of the expected complexity  therefore complementing the information derivable from a static localization in the phase plane of the problem to be solved. this dynamic estimation would allow the search to be interrupted when the expected complexity is likely to exceed the available computational resources. 
