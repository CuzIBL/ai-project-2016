 
the dipmeter advisor program is an application of al and 
expert system techniques to the problem of inferring subsurface geologic structure. it synthesizes techniques developed in two previous lines of work  rulte-based systems and signal understanding programs. 
　　　　this report on the prototype system has four main concerns. first  we describe the task and characterize the various bodies of knowledge required. second  we describe the design of the system we have built and the level of performance it has currently reached. 
         third  we use this task as a case study and examine it in the light of other  related efforts  showing how particular characteristics of this problem have dictated a number of design decisions. we consider the character of the interpretation hypotheses generated and the sources of the expertise involved. 
finally  we discuss future directions of this early effort. 
we describe the problem of  shallow knowledge  in expert systems and explain why this task appears to provide an attractive setting for exploring the use of deeper models. 
1. introduction 
unlike fanciful movie images  oil is rarely discovered in gushers that send it spewing out of the ground. more typically  the discovery and draining of fields is a painstaking process involving inferred reconstruction of underground geology. the presence of prehistoric beaches  deltas  and faults several thousand feet underground are important information suggesting the likely location of oil bearing formations. 
　　　　the reconstruction process is based in large part on measurements provided by a number of probes. the probes are lowered into a well and then slowly retrieved  measuring various physical properties of the rock every few inches as they ascend. since a log may be as much as 1' long  there is a significant amount of data to be interpreted. 
　　　　one of the most important and widely used probes is the dipmeter  which yields information about orientation: from its measurements the inclination  or  dip   of the subsurface rock layers can be computed. other commonly used probes provide measurements from which such properties as rock resistivity and porosity can be determined. 
　　　　interpretation of a dipmeter and related logs requires inferring the presence of large scale  three dimensional geologic formations from small scale  two-dimensional information about physical properties a segment of a log is shown in figure 1  the resulting analysis is given in figure 1. 
　　　　the task is suited to the expert systems paradigm for several reasons first  there are recognized human experts who routinely solve the problem  providing both an acknowledge source of expertise that can be tapped to help build the knowledge base and a standard by which to judge program performance. second  skill at this task is acquired via training and experience. becoming an interpreter involves explicit study and the skill is in large measure cognitive  rather than perceptual. both of these make it more likely that it can be captured as a collection of inference steps finally  the domain is at the appropriate stage of development. it is sufficiently well established that it has a vocabulary of basic concepts and a collection of informal but useful rules of thumb  but is not yet so well developed that there is a uniform and reliable general solution method. at this stage of development a qualitative  symbolic reasoning approach can be very effective. 
　　　　work on this task also has a strong pragmatic motivation. the field of log interpretation is at present manpower-limited. given the current emphasis on exploration  a program capable of high performance on this task would have considerable utility. 


1 


1 user interface 
         interaction with the system is via the ramtek  a high resolution color display  primarily by using the mouse to point at various areas on the screen and to  push buttons  displayed there. a joystick and keyboard are also available. the system includes facilities for data input and display  program control  and examination and modification of results produced by the interpretation system. log data are accessible via either slow speed scrolling  for visual scan  or random access  for quick access to a particular segment of the log . 
　　　　considerable attention was paid to human engineering issues in designing the interface. this  combined with sophisticated graphics facilities  results in a system that provides a range of powerful display features  yet is relatively easy to use. 
1 log interpretation module 
the overall organization of the log interpretation module is shown in the right half of figure 1. the knowledge base currently contains a few dozen rules that infer the existence of geologic structures from the presence of various features in a log. a sample rule is shown below. 
if 
there is red pattern 1 over a f a u l t . 
the d i r e c t i o n of the red pattern is perpendicular 
to the f a u l t   and 
the length of the red pattern 1s greater than 1 f e e t   
then 	the f a u l t is a growth f a u l t . 
the rules are written in a simple language referring to both features of the log  e.g.  red patterns  and geologic entities  e.g.  faults . the premise part of the rule consists of one or more clauses  each of which is composed of a predicate on one or more patterns. the first clause of the rule above  for instance  is represented internally in a form approximated by 
 above  redpattern    f a u l t interval   
where the items in o's are pattern specifiers matched against the data base  described below . the rules are currently quite simple in syntax and do not as yet make use of inexact inferences. 
　　　　in addition to the rules  the knowledge base also contains a few simple feature detectors. these are procedures used to scan the log data and provide the initial level of data reduction. 
　　　　the data base is the system's repository for everything it currently knows about the well. it is structured in levels of successively more abstract information  ranging from the initial log data at the bottom level  to hypotheses about large scale geological structures at the top level. 
　　　　conclusions are represented as patterns describing segments of the log. the inferred presence of a fault zone  for 
instance  is represented as 
            fault 1 growth 1 1  which indicates the top  1'   bottom  1'   orientation 
 along a line running from 1 to 1 degrees  roughly ene to wsw   and direction of the downthrown block  1  sse . 
　　　　the inference engine provides the overall control in the system. it invokes subsets of rules in data-directed fashion  matching them against patterns in the data base and adding new conclusions wherever a rule matches successfully. 
　　　　we view the overall process of log interpretation as one of data aggregation and abstraction  carried out in several passes over the log  each producing a successively more abstract description. as this view suggests  our work has benefited from the experience gained in previous rule-based and signal interpretation systems  notably the hearsay-ii  and mycin  1  systems. 
　　　　the dipmeter advisor program was developed using logs from the us gulf coast area and has begun to display a level of competence for that region comparable to that of a newly trained human interpreter. 
1. interpreting a log 
in our current view  log analysis involves five major sources of expertise  applied in sequence:  1 validity check and initial data reduction   ii  determination of structural dip   iii  analysis of faults   iv  analysis of local geologic features   v  assembly of a composite picture. the knowledge base is subdivided correspondingly and each subset of rules invoked in turn in the data-directed fashion noted earlier. a description of each phase is given below  simplified for brevity. 
1 initial data reduction and validity check we begin by applying the feature detector operators  to produce the first level of data reduction and abstraction. the first subset of rules is then invoked  examining the log for signs that the data are bad  and checking for several typical causes of error  e.g.  mechanical malfunction of the dipmeter  operator error  etc. . 
1 structural dip 
inclination of rock layers results from two different processes. small scale processes  river flow  tidal action at shorelines  etc.  produce characteristically varying patterns that typically extend over 1 to 1 feet  while large scale processes  uplift or subsidence of a whole region  contribute additional  relatively constant dip  that extends 1 to 1 or more feet. the large scale phenomenon is referred to as structural dip. it is important for two reasons. first  it provides an indication of the overall orientation of the rock layers. this in turn indicates the likely direction of flow of any deposits  hydrocarbons  being lighter than water  will  float uphill  through porous rock . second  the structural dip is a  background  signal that must be removed before the small scale patterns can be detected and interpreted accurately. 
1 analysis of faults and missing sections 1 when two regions slide past one another  porous rock layers may end up abutting non-porous layers  producing a trap where hydrocarbons collect. the detection and analysis of faults is thus an important part of the interpretation process. the subset of 

rules dealing with fault analysis is invoked in this third stage  looking for discontinuities in structural dip and other signals of faulting action. 
 1. the chaosnet it a highspeed broadcast packet network developed at mit in 1 and modeled after xerox's ethernet. 
 1. characteristic patterns on the logs are traditionally referred to by color names. a  red pattern  is a sequence of tadpoles with smoothly increasing dip magnitude and relatively constant direction. a  blue pattern  is a similar sequence with smoothly decreasing magnitude.  1. a missing section is a discontinuity in the pattern of rock layers. faults are one common cause of a missing section. 1 

1 stratigraphy 
features produced by small scale processes are termed stratigraphic. once underlying structural dip has been subtracted  the characteristic  fingerprints  produced by these processes become clearer. a typical fingerprint is a collection of patterns found in a particular order and orientation on the log  e.g.  a red pattern above a blue . since we do not yet have a definition of the patterns precise enough to automate their detection  they are marked manually by the user  employing the graphics display and annotation facility.1 
       one subset of rules invoked at this stage analyzes the environment at the time of rock layer deposition  e.g.  how deep the water was . a second subset then checks the patterns marked by the user  looking for known configurations  and uses this along with the environment information to infer the presence of stratigraphic features. some of these features are indicators of hydrocarbon-bearing rock. 
1 composite picture 
since geologic formations often extend over considerable horizontal distances  the same features may show up in other wells drilled in the same area. thus  when data from multiple wells are available  it is sometimes possible to produce a composite picture that extends over several acres. we do not currently attempt to develop composite pictures. 
1. nature of the task 
as the discussion above suggests  log interpretation confronts issues similar to those encountered in previous efforts at signal interpretation. we have benefited from the experience gained in those efforts in designing and constructing the prototype system described here. but even our limited experience to date has demonstrated differences between this task and those attempted previously  differences that are interesting both for the perspective they supply on the possible variety in signal interpretation tasks  and for the directions they suggest for continued development of our system. 
1 character of the task 
since our current program works with only some 1 or so distinct geologic entities  it is reasonable to ask whether the solution space is not in fact small enough to admit an exhaustive search. 
　　　　an analogy to speech will help illustrate the difficulties that rule out such an approach. imagine attempting speech recognition under the following conditions. there are multiple speakers who somtimes overlap  multiple geologic forces can be at work simultaneously . the speech is intermittent  in a noisy background  interesting geologic features are sparsely scattered on the logs; data are subject to the problems of making measurements on an uneven rock wall in a borehole filled with high pressure mud . there is a small vocabulary  but speech rate and pronunciation differ  there are relatively few distinct geologic entities  but they appear in different sizes and manifestations . each speaker is generating words that are relatively unconnected 
 the presence of one geologic feature says relatively little about those around it . 
       under these circumstances the difficulties arise not so much because the search space is large in the traditional combinatorial sense. instead it is the character of a solution that makes the problem difficult: a log interpretation is a sequence of loosely constrained  at times overlapping features with interspersed periods of uninteresting noise. as we explore below  this has significant consequences for the system design. 
1 character of the hypotheses generated 
       compared with previous efforts  there are interesting differences here in the type  number  and density of interpretation hypotheses generated first  there is  as suggested earlier  both a  global   structural dip  and  local   stratigraphic  component to the interpretation  reflecting the existence of two different kinds of 
1. earlier we noted that log interpretation it largely cognitive. the detection of these patterns is an interesting unsolved problem involving both cognitive and perceptual issues. 
forces at work. second  interpretations  at least in the current state of the art  are in general quite sparse. a log several thousand feet long may present no more than a half-dozen interesting features. third  there is a relatively low degree of ambiguity  especially as compared to  say  speech. 
       fourth  adjacent hypotheses constrain each other only very weakly and there is relatively little constraint imposed by a sense of  global consistency  to an interpretation. what constraints exist arise from the continuity over time of geologic forces and environments. since depth in the well is an indirect measure of time  there are constraints on the rate of change vs depth in the phenomena we expect to see similarly  there are limits to the extent of change in depositional environment  marine coast  inland mountain  etc  over the whole well. these two 
factors provide some local and global consistency  respectively  to the interpretation  but they constrain the space of possible interpretations very weakly  especially as compared to  say  the situation in speech. there  syntax and semantics impose strong constraints on word adjacency  while the entire utterance is constrained to be a legal sentence. 
       finally  the analysis of any given feature can involve fairly extended chains of inference for example  four inference steps are commonly required to discover and analyze the presence of a fault. 
       the differences in number and density of hypotheses generated have clear implications for the system design. the sparseness and low ambiguity of hypotheses simplifies things  since it means a reduced chance of combinatorial explosion and hence less need for careful scheduling or attention focusing devices. the paucity of local or global constraints  on the other hand  makes the problem more difficult  since each hypothesis must be evaluated much more  on its own merits   with less information available from those surrounding it. 
1 character of the interpretation expertise a major consideration in constructing programs of this sort is the character of the knowledge available  since this in large measure determines the appropriate problem solving architecture. 
       to illustrate this issue  consider the sources of expertise available to previous expert systems. dendral  and hearsay! . for example  had generators constrained by knowledge about the problem at hand; knowledge about patterns in the mass spectrum  dendral  or plausible moves in chess  hearsay . the existence of both a clearly defined solution space and strong constraints to focus the generator made generate and test plausible. 
       hearsay ii  by contrast  had no strong constraints on its solution space: the bibliographic retrieval task  for example  offered far less a prion constraint on the sentence than did chess. this made made the generation and testing of entire sentences infeasible. instead  that system focused on hypothesizing and testing individual components of the solution  syllables  words  etc.  and found its constraints in the consistency between components  e.g.  syllables have to form words  words have to form syntactically and semantically valid sentences  etc. . 
here we lack both a priori constraints on the solution and 
 as 	noted 	earlier  	strong 	consistency between 	solution components.1 
       as a result we have focused instead on what we do have: knowledge about the processes that produce the signal. the rules in the program reflect a very simple but growing knowledge of geologic forces and phenomena - deposition  faulting  erosion  compression  etc. - that produce the formations. 
       one consequence of all this is the strongly data-driven character of our program. with no a prion constraints on the 
1. there is some   priori information in the different formations typically associated with each geologic environment  e.g.  tidal channels and flood deltas typically appear in the shallowest water . experienced interpreters thus expect certain formations more than othors in a given environment. we are still determining the amount of guidance this can supply. 
1 
solution and little information available from internal consistency checks  a pure generate and test or hypothesize and test approach would be inappropriate. 
         a second consequence is the obvious importance of developing a good understanding of the forces and phenomena involved. we are not unique in attempting this: dendral  for example  has a theory of how molecular bonds break in a mass spectrum device. but it uses this theory as a guide and constraint for the generator. we  on the other hand  are using this information as the central source of interpretive power.  if dendral were forced to do the same  it would have to produce its entire analysis by reasoning about every peak in the mass spectrum as the result of molecular fragmentation.  this clearly puts a strong emphasis on developing a good model and understanding of the forces. 
         in this undertaking we are attempting to use knowledge about geology to provide the model and to provide a way of inverting the sequence of events. in reality  geologic processes produce characteristic patterns of bedding planes  which may then be distorted by various forces and events  resulting finally in the patterns recorded by the dipmeter. we wish to go in the other direction  using an understanding of geology to proceed backward from the pattern on the log to the processes and formations which produced them. 
1 shallow knowledge 
we have emphasized the importance of knowledge about geologic processes as a basis for interpretation and alluded to the early stage of development in which this knowledge currently exists. one important way in which the knowledge is still underdeveloped is its  shallowness . rules of the form shown in section 1 are useful for embodying a summary of the experts reasoning process  but they do not capture the more basic phenomena responsible for the events on which that reasoning is based. even where far more complex models of geology have been assembled  e.g.  prospector    the result has still been a distillation that omits a great deal of the more fundamental knowledge. 
         to illustrate the character of the knowledge missing from our rules  consider the rule in section 1  which suggests that fault regions associated with long red patterns are growth faults . this is a useful rule of thumb that captures some part of interpretation skill. but why is it true  the sequence of idealized drawings in figure 1 suggests one mechanism. 
         from  we learn that  growth faults are characteristic of a rapidly growing delta where thick sand/shale deposits overlie a layer of mobile clay... it appears that high fluid pressure in the underlying clays forms a low friction glide plane.  fig. 1a; the initial conditions and forces at work . under the force of gravity  parts of the sand/shale block move toward the lowest point of the basin by incremental creep.  fig. 1b; the fault appears . due to the minimal overburden pressure... formation blocks slump into the fault plane under the force of gravity    fig. 1c . 
         if the fault were buried  overlying layers of rock would keep the two faces of the fault firmly in contact  and the rock layers would be distorted in the direction of the frictional drag  fig. 1e  a  drag fault  . since the fault is on the surface  frictional force is minimal and instead the top layers tend to roll over into the 
fault plane  fig 1c . since deposition continues during and after fault movement  additional layers subsequently deposited on top will conform to this bending less and less as time goes on  as deposition  fills in  the fault. the sum total of all of these processes produces the characteristic pattern of fig. 1d. 
　　　　note that the rule in section 1 is thus only a summary  the characteristic pattern  of a fairly complex process. understanding that process requires knowledge of geology  knowledge about the sequence of events  and the ability to reason about the process of rock movement over time. 
　　　　the collection and formalization of this more detailed knowledge about the task domain will be a central focus for much of the future work on the program. it is  we believe  one important key to both more powerful expert systems and to systems that will have a more thorough understanding of their domains. 
1. future directions 
         future development of this early prototype system will focus on four main items: 
knowledge acquisition. a major part of our effort will be devoted to working on additional logs in order to build and refine the knowledge base. we estimate that a few hundred rules of the sort we now have will produce a system strong enough for use in the field. 
more general control strategy. logs are currently processed in the sequence of steps given earlier. it appears useful to have a more general strategy that allows results of later phases to trigger re evaluation of actions in earlier phases. 
other sources of information. often  there is available other information about a well in addition to the dipmeter logs. we will be studying ways to integrate this information into our framework to aid in the analysis. 
more detailed modeling of geology. finally  as noted earlier  a second major focus will be on developing more detailed symbolic models of geologic forces and phenomena  to provide a more complete body of knowledge than that contained in the rules. 
acknowledgments 
         j. baker  head of systems science at sdr  provided management support and encouragement. the staff of computers services at sdr provided assistance and technical support h cannon and j. callan installed the chaosnet. coding and other assistance with system development was provided by d. barstow  h. cannon  m forlastro  and k. lerman. comments from barstow  r. engelmore  a. gershman and c. rich improved the presentation in this paper. 
