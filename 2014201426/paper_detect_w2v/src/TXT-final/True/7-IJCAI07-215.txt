
classic direct mechanisms require full utility revelation from agents  which can be very difficult in practical multi-attribute settings. in this work  we study partial revelation within the framework of one-shot mechanisms. each agent's type space is partitioned into a finite set of partial types and agents  should  report the partial type within which their full type lies. a classic result implies that implementation in dominant strategies is impossible in this model. we first show that a relaxation to bayes-nash implementation does not circumvent the problem. we then propose a class of partial revelation mechanisms that achieve approximate dominant strategy implementation  and describe a computationally tractable algorithm for myopically optimizing the partitioning of each agent's type space to reduce manipulability and social welfare loss. this allows for the automated design of one-shot partial revelation mechanisms with worst-case guarantees on both manipulability and efficiency.
1 introduction
an important challenge facing ai is the design of protocols through which self-interested agents might interact to achieve some desirable outcome  such as negotiating an outcome that maximizes social welfare . as a consequence  mechanism design -which studies precisely this problem from an economic and game-theoretic point of view-has become an important area of study within ai and computer science more broadly. roughly speaking  a mechanism is a game intended to implement some social choice function  scf   i.e.  a function that selects some outcome as a function of the preferences of the participating agents.
모a key result in mechanism design  the revelation principle  states that mechanisms can be restricted to incentive compatible  direct mechanisms  in which agents fully reveal their true type  i.e.  utility function over outcomes . for instance  vickrey-clarke-groves  vcg  is such a mechanism for social welfare maximization.
모unfortunately direct type revelation is problematicin practice  since utility functions can be extremely difficult for agents to even compute effectively or communicate to the mechanism  especially in settings with large  multiattribute outcome spaces  a familiar example is combinatorialauctions  . thus the design of mechanisms where utility functions are bot fully revealed  thus relieving agents of some of the computational and communicational burden  has become an important problem in computational mechanism design.
모in this paper we consider the design of one-shot mechanisms that make decisions using partial type information. in section 1  we present a model of partial revelation and survey those models and results that influence our approach  with emphasis on the tension between partial revelation and dominant strategy implementation. in section 1  we show that relaxing implementation to bayes-nash or ex-post does not allow for the design of  useful  partial revelation mechanisms. we therefore consider approximate dominant incentive compatibility  in which the potential gain from misreporting one's partial type in bounded. we define a class of regretminimizing mechanisms  section 1  that chooses an outcome that minimizes the worst-case loss  w.r.t. social welfare  over all possible types in the declared partial types. we then define several payment schemes  describe the important properties of our mechanisms  specifically  approximate efficiency  rationality and incentive compatibility  and argue for their suitability. while these results hold for any partial types  the quality of the approximation depends critically on the choice of partial types. in section 1 we define an algorithm to optimize the choice of partial types that allows one to tradeoff the amount of elicitation with the degree of efficiency and incentive compatibility loss. taken together  regret-based mechanisms and the optimization algorithm provide a framework for the automated design of partial revelation mechanisms in which one can explicitly address such tradeoffs. preliminary computational experiments confirm the efficacy of our approach. we defer all proofs to a longer version of the paper.
1 background and definitions
we begin with some essential background. to motivate our definitions  we will use a simple running example of a buyer wishing to purchase a car from a seller. we wish to facilitate the negotiation: they must agree on the car  from the seller's inventory  and the price to be paid; but buyer's valuation for different cars and the seller's cost is not known to us. ideally  we would identify the car that maximizes surplus  the difference between the buyer's valuation and the seller's cost .
1 mechanism design
we adopt a standard quasi-linear environment with n agents in which the aim is to choose an outcome or allocation x from the set x of all possible allocations. each agent i 뫞 n has type ti drawn from set ti  and valuation function vi : x뫄ti 뫸 r  with vi x;ti  denoting the value of allocation x if i has type ti. in many cases  we can view ti as encoding i's utility function over x. letbe the set of full type vectors. the social welfare of x given t 뫍 t is sw x;t  =
. let t i denote a type vector over all agents but i  and sw. in our example  the buyer's type tb would determine its valuation vb x;tb  for any transacted vehicle x  and similarly for the seller  its cost . the space of possible types tb could be defined in a number of ways. for instance  if |x| = n  tb could be the set of n-vectors 1 뫞 v 뫞 c for some constant c  with vi denoting the utility of the ith vehicle . however  valuations can often be represented more compactly. for instance  if a buyer's utility is known to be linear with respect to a small set of car features  then a tb may be k-dimensional  for some k   n   and any type captured by a set of k parameters.
모a mechanism consists of a set of actions  an allocation function o : a 뫸 x and n payment functions pi : a 뫸 r. intuitively  the mechanism offers the action set ai to i  and chooses an allocation based on the actions taken by each agent. we assume quasi-linear utility; that is  an agent i's utility for an allocation x and payment 뷈i is ui x 뷈i ti  = vi x;ti    뷈i. mechanism m induces a  bayesian  game assuming probabilistic beliefs over types: each agent i adopts a strategy 뷇i : ti 뫸 ai associating an action with its type.1
모the goal of mechanism design is to design m to implement some scf f : t 뫸 x. for instance  f may be social welfare maximization  i.e.  f t  = argmaxsw x;t  . in this work  we focus on social welfare maximization or efficient allocation. implementation then depends on the equilibrium concept used; specifically  if m induces strategies 뷇i for each agent in equilibrium such that o 뷇 t   = f t  for all t 뫍 t  we say that m implements f. standard equilibrium concepts lead to dominant strategy  ex post  and bayes-nash implementation.1 the revelation principle allows one to focus attention on direct  incentive compatible mechanisms in which ai = ti and each agent will reveal his type truthfully in equilibrium. in our example  this would allow restriction to mechanisms in which we ask the car buyer and seller to report their complete valuation and cost functions  respectively.
모the groves scheme is a famous class of mechanisms for quasi-linear environments  of which vcg is an instance  in which social welfare maximization is implemented in dominant strategies: it is characterized by any efficient allocation function  and the groves payments :
     pi t  = pi t i x   = hi t i    sw  i x ;t i   1  for any functions hi : t i 뫸 r. in non-trivial settings  the groves scheme is the only class of mechanisms that can implement any scf in dominant strategies. this follows from two famous results: roberts  showed that if x contains at least 1 outcomes and all valuations are possible  then an scf is implementable in dominant strategies iff it is an affine welfare maximizer  i.e.  affine transformation of social welfare ; while green and laffont  proved that to implement an affine welfare maximizer one must use groves payments. thus  to implement social welfare maximization in dominant strategies  one must not only elicit enough information to determine the efficient allocation but generally also enough further information to determine the groves payments.1
1 partial revelation mechanisms
we define a partial type 붿i   ti for agent i to be any subset of i's types. a partial type vector 붿 includes a partial type for each agent. a  direct  partial revelation mechanism  prm  is any mechanism in which the action set ai is a set of partial types 붣i  i.e.  the agent is asked to declare the partial type in which its true type lies . since agents only reveal partial types  the notion of truth telling must be relaxed somewhat:
definition 1. a prm is incentive compatible  ic -under the relevant equilibrium concept-if it induces equilibrium strategies 뷇i for each agent i such that ti 뫍 뷇i ti .
모in other words  an ic prm will induce each agent to report a partial type that contains its true type. in our example  we might define the partial type space of the buyer by defining a set of rough bounds on the valuation for each car  with some cars having a more precise range than others. for instance  one partial type might assert that vb car1  뫍  1 1   vb car1  뫍  1 1   and so on. limiting revelation to partial types of this form allows the buyer to negotiate without having to precisely determine its valuation for each car  but simply estimate it roughly.
모partial types may or may not be overlapping or exhaustive. if they are not exhaustive  incentive compatibility is not generally possible. if they are overlapping  more than one truthful report may be possible  and an agent can reason strategically to choose among them while maintaining truthfulness  something that is not possible if types do not overlap. our key results  specifically incentive and efficiency guarantees  do not require non-overlapping types. we will  however  assume in what follows that partial types are exhaustive.
모in general  given a partial type vector 붿  a mechanism will not be able to determine an efficient allocation x-the allocation x  t  that maximizes social welfare for type t may be different for various t 뫍 붿. a corollary of roberts' result is that a one-shot prm cannot be used for dominant strategy implementation: unless the partitioning of each agent's type space is such that each joint partial type 붿 determines a unique maximizing x  for all t 뫍 붿  dominant strategy implementation will not be realized  in general .
1 related work
recent research has examined methods involving limited or incremental elicitation of types to circumvent the difficulties of full type revelation  especially in single-good and combinatorial auctions . most work on incremental elicitation involves techniques that elicit  just enough  information to determine the vcg outcome fully  both allocation and payments fully  thus maintaining incentive properties  e.g.  in cas  1; 1  . such mechanisms  being incremental  do not fit precisely into our framework  and generally allow only ex post implementation; issues pertaining to approximate efficiency are avoided altogether. furthermore  the sequential approach is critical to avoiding full revelation. unfortunately  the amount of information required to fully determine the vcg outcome may be considerable   and enforcing ic over and above just implementing an scf itself induces significant cost  .
모alternatively one can elicit enough information to determine an approximatelyoptimal outcome a common approach in single-agent elicitation   sacrificing decision quality to reduce elicitation effort. we adopt this perspective here. recently  we used this approach in the design of sequential prms   leading to approximate ex-post implementation. the one-shot mechanisms presented in this paper have stronger incentive properties  approximate dominant implementation   and allow for more interesting payment schemes. another class of approaches to prms is exemplified by priority games  1; 1 . in these models  partial types are elicited and exact  not approximate  dominant strategy implementation is realized. however  these prms are designed only to deal with agents having one-dimensional  or  single-parameter   types  for example  agents in a single-item auction where valuation for an outcome can be specified by one parameter. indeed  roberts' result is escaped only by restricting the space of preferences in this severe fashion. combinatorial auctions with single-minded agents are similarly restricted . unlike our model  these mechanisms do not generalize to more realistic valuation structures .
모approximate ic has been considered before from several perspectives. nisan and ronen  show that computational approximation of vcg can destroy truth-telling  but manipulation of approximate vcg can be made computationally difficult   thus inducing  practical  incentive compatibility. ic in expectation or with high probability can also be demanded . finally  one can attempt to bound the gain an agent can achieve by lying  e.g.  as proposed for exchanges in  . it is this latter view of approximate ic that we adopt here. our class of partial revelation mechanisms  along with our partitioning algorithm provide the first approach to automated partial revelation mechanism design .
1 bayes-nash and ex-post implementation
in the bayes-nash context  each agent has a probabilistic prior over the types of the others  pr t i|ti . if truth-telling is a bayes-nash equilibrium in a prm  this defines a distribution over the reports  partial types  of other agents; hence for each of its reports 붿i  agent i has a distribution  x붿ii  over allocations selected by the mechanism. for each x define:

in this section  we restrict ourselves to partitions of the type space that are  grid-based : each parameter's space of values is split into a finite number of intervals of the form  lb ub   with lb   ub. we can derive the following results:
theorem 1. if all valuation functions are possible  in a bayes-nash ic grid-based prm  we have:
 1 
 1 
모property 1 states that  regardless of its report  agent i has the same posterior xi over outcomes. property 1 states that this distribution is also the same for all agents. if the allocation function is deterministic  then it selects the same allocation for each report vector. we call such a mechanism trivial. triviality may be avoided if allocations are probabilistic  but even then  these properties are very restrictive:
proposition 1. no bayes-nash ic grid-based prm has higher expected social welfare than the trivial mechanism that always picks the allocation with highest ex ante social welfare.
proposition 1. if ex-interim  or  a fortiori ex-post  individual rationality  ir  is required  the expected sum of payments of any bayes-nash ic grid-based prm is zero.
모in a sense  though partial revelation bayes-nash implementation is not strictly trivial  it is useless since it achieves the same result as a mechanism with no revelation. given that an ex-post equilibrium is a vector of strategies that are in bayes-nash equilibrium for all possible probabilistic priors  the above results imply that any ex-post ic prm is trivial.
모note that the grid-based restriction is a sufficient condition for the above results to hold. we are currently looking into identifying necessary conditions. for example  we strongly suspect that any partitioning of type space into convex partial types will lead to the same negative results. we do not have such results at present however.
1 regret-based prms
a partial revelation mechanism must choose an allocation x 붿  for each reported partial type 붿 뫍 붣  but cannot generally do so in a way that ensures efficiency. we propose the use of minimax regret  1; 1  to choose the allocations associated with each partial type vector.
definition 1. the pairwise regret of decision x with respect to decision x  over feasible type set 붿 is
	r x x  붿 	=	max sw x ;t    sw x;t  	 1 
t뫍붿
 this is the most the mechanism could regret choosing x instead of x   e.g.  if an adversary could impose any type vector in 붿 . the maximum regret of decision x and the minimax regret of feasible type set 붿 are respectively:
mr x 붿 =max r x x  붿 
x  1 mmr 붿 =min mr x 붿  1 x
모a minimax-optimal decision for 붿  denoted x  붿   is any allocation that minimizes eq. 1. without distributional information over the set of possible utility functions  choosing  or recommending  a minimax-optimal decision x  minimizes the worst case loss in efficiency with respect to possible realizations of the types t 뫍 붿. we refer to the regret maximizing x  in eq.  1  as the witness for x.
모recent approaches to minimax regret optimization have shown it to be practical when utility models are factored into a convenient functional form such as generalized additive independence  gai    and utility uncertainty is expressed in the form of linear constraints on such factored models . in this setting  minimax regret optimization can be formulated as a linear  mixed-integer program  mip  with exponentially many constraints  but can be solved using an iterative constraint generation procedurethat  in practice  enumeratesonly a small number of  active  constraints .
definition 1. a regret-based partial revelation mechanism is any mechanism in which the allocation function chooses an outcome that minimizes max regret given the revealed partial type vector; that is  o 붿  = x  붿  for all 붿 뫍 붣.
모assume we have a prm m in which each agent declares a partial type 붿i 뫍 붣i  and that m is regret-based  i.e.  o chooses x  붿  with minimax regret w.r.t. social welfare for any declared type vector 붿:
observation 1. let m be a regret-based partial revelation mechanism with partial type space 붣. if mr x  붿  붿  뫞 붼 for each 붿 뫍 붣  then m is 붼-efficient for truth-telling agents.
모this simply formalizes the obvious fact that since max regret for any mechanism choice is bounded by 붼  then if all agents reveal their partial types truthfully we are assured to be within 붼 of maximizing social welfare.
모with prms we cannot generally guarantee efficiency: different type profiles within a partial type vector 붿 may require a different allocation choice to maximize social welfare. as a consequence  the result of roberts means we will be unable to implement our  approximate  choice function in dominant strategies. instead  we relax the implementation concept in a natural fashion and derive a payment scheme that ensures approximate ir and ic in dominant strategies.
모consider the following generalization of groves payments. given joint report 붿 =  붿i 붿 i  of all agents  and the corresponding choice x   agent i's payment is:
pi 붿  = pi 붿 i x   = hi 붿 i    sw i x ;fi 붿 i  
where hi : 붣 i 뫸 r is an arbitrary function and fi : 붣 i 뫸 ti is any function that  given partial type vector 붿 i  selects a type vector t i from that set  i.e.  fi 붿 i  뫍 붿 i .
모recall that under full revelation  fi 붿 i  is the complete type vector t i reported by the other agents and hi must take that particular t i as an argument. our partial groves payment scheme  however  can select an arbitrary type for each agent consistent with their declared partial types and apply standard grovespayments eq. 1  to these. the selected types can differ for each payment function pi  and the arbitrary hi functions also depend only on the partial types revealed. partial groves payments can thus require significantly less revelation. together with regret-based allocation  they give:
theorem 1. let m be a regret-based partial revelation mechanism with partial type space 붣 and partial groves payment functions pi. if mr x  붿  붿  뫞 붼 for each 붿 뫍 붣  then m is 붼-efficient and 붼-dominant ic.
모in other words  truth telling is an 붼-dominant strategy equilibrium  i.e.  truth telling for any agent has utility within 붼 of optimal regardless of the reports of others . we can specialize partial groves payments to partial clarke payments:

 where xx is an arbitrary function that chooses an allocation based only the reports of agents other than i. this restriction allows the following ir guarantee:
theorem 1. let m be a regret-based partial revelation mechanism with partial type space 붣 and partial clarke payments pi. if mr x  붿  붿  뫞 붼 for each 붿 뫍 붣  then m is 붼-efficient  붼-dominant ic and ex-post 붼-ir.
모in other words  no agent has incentive greater than 붼 not to participate in the mechanism.
모we have provided some intuitive justification above for the use of minimax regret to determine the allocation associated with any revealed partial type profile. we can also provide formal justification for the use of minimax regret with respect to incentive properties of prms. specifically  under the partial groves and clarke payment schemes  worst-case manipulability  over possible type profiles  is exactly equal to the greatest minimax regret-level  again  over possible type profiles . thus one can show:
proposition 1. let 붣 be a fixed partial type space  and m a regret-based prm  w.r.t. 붣  using the partial clarke payment scheme. any other prm  w.r.t. 붣  using the partial clarke scheme  will have worst-case manipulability  efficiency loss and rationalityviolation at least as great as that of m. there exist non-regret-based prms where this inequality is strict.
모in other words  no non-regret based scheme can perform better than a regret-based scheme with respect to efficiency loss  obviously   gain from misreporting one's partial type  and incentive for non-participation. the analog of this proposition holds regarding manipulability and efficiency when using the partial groves payment scheme.
모even with the  clarke-style  restriction above  our payment scheme is quite general: x and fi are arbitrary functions. the choice of these will not affect the worst-case properties above  but it can be used to:  a  reduce the likelihood  if any  of a rationality violation; and/or  b  maximize revenue of the mechanism. if reducing or removing a rationality violation implies revenue loss  then a trade-off can be made between the two criteria. an attractive feature of our prms is the considerable scope for optimization of the payment scheme due to the nature of the partial type revelation.
모when dealing with approximate incentive properties  one must be aware that a small deviation from the truth by one agent can cause major changes in the mechanism's allocation  leading  say  to large losses in efficiency . but with partial groves payments  an agent can gain at most 붼 compared to revealing its partial type truthfully. in most settings  the computational cost of finding a good lie  especially given the considerable uncertainty in the value of any lie  due to uncertainty about others' types   will be substantial  see  e.g.   . thus  if 붼 is small enough  it will not be worth the cost: our formal  approximate incentive compatibility is sufficient to ensure practical  exact incentive compatibility.
모to develop a sense of the difficulty associated with manipulating such a mechanism  considerthat an agent must be able to compute an untruthful strategy  or lie  with greater utility than truth-telling in order to exploit our approximate incentive guarantee. to do this one must first determine the true value of a lie  incurring the valuation or cognitive costs similar to revealing truthfully . however evaluating a lie also requires considerable  and accurate  information about the types and strategies of the others; even with decent priors  the costliness of such computations  e.g.  in time  cognitive  or computational resources  implies that manipulation is not worthwhile unless the bound 붼 is quite loose  and incentive compatibility will thus  in practice  be exact.
모a similar argument can be made regarding approximate ir: determining whether you gain from not participating will be very difficult. thus a potential small loss will be worthwhile for an agent given the savings our mechanism provides in revelation and computational costs  relative to the full revelation alternative . finally  given the complexity of many mechanism design settings  when cognitive  computational and communication costs are accounted for  the potential loss in efficiency will be an acceptable trade-off  given the high level of revelation required by exactly efficient mechanisms.
1 construction of partial types
so far we have focused on the design of regret-based prms with a fixed collection of partial types. however  the selection of partial types is critical to the performance guarantees above  since it is these types that determine the degree of regret incurred by the mechanism. the key design issue is the construction of a suitable set of partial types that minimizes both revelation and the maximum minimax regret  i.e.  붼  over that set. we describe a heuristic  but reasonably tractable  approach to the automated optimization of the type space partitioning. although the class of mechanisms is fixed and it is the partition that is being optimized by our algorithm  together these constitutes a tractable approach to automated partial revelation mechanism design.
모in what follows  we assume an agent type is simply a bounded n-vector with valuations for each allocation x 뫍 x. when dealing with a multi-attribute outcome space  we allow for an agent's type/utility function to be factored using a generalized additive independence representation   in which utility parameterized with local sub-utility functions over small sets of attributes. in a flat  un-factored  model  the parameters are simply the valuations for allocations x. we assume in what follows that the type space ti is given by upper and lower bounds over the parameters of agent i's utility model and focus on partial types specified similarly.

figure 1: example of a mechanism tree.
1 partial type optimization algorithm
we describe an offline  iterative  myopic approach to the optimization of agent type space partitions. it is myopic in the following two senses:  a  at each step  it focuses on reducing the minimax regretof the joint partial type with greatest regret by refining  or splitting  it  without considering the impact on other partial types; and  b  it only considers the immediate effects of this refinement  with no look-ahead to future splits.
모to simplify the presentation  we first describe a naive  computationally intensive method  formulated in terms of decision tree construction  and then show how it can be modified to be made much more tractable. the algorithmuses a heuristic function which  given a partial type vector  selects an agent whose partial type will be split. it is important to realize that these splits are not  queries  to the agent-the mechanism is not sequential. rather  splitting a partial type further will increase the number of partial types from which an agent must choose when the mechanism is actually executed. once all splits to all agents are determined  the mechanism will ask agents to select from the partial types induced by this refinement process. in other words  offline we construct the partial types used by the one-shot mechanism. we discuss the heuristic function further below.
모figure 1 illustrates the creation of partial types for a prm in terms of decision tree construction. at the outset  the only information available to the mechanism is the set of possible types for each agent given by our prior  defining the initial partial type vector  붿1 ... 붿n  with 붿i = ti. this labels the initial  root  node of our tree  node 1 . we call the heuristic function on this vector  which selects an agent  say agent 1  and a split of that agent's partial type 붿1 into two more refined partial types and. the reasons for choosing a particular split are elaborated below  but intuitively  such a split should have a positive impact with respect to max regret reduction of the mechanism. this creates two child nodes corresponding to partial type vectors  and
  see nodes 1 and 1 in figure 1 . these two new leaves in the tree correspond to the partial type vectors to be used by the mechanism should the splitting process terminate at this point. thus  we update the partial type space 붣i for agent 1 by removing 붿1 and adding and. we then compute the minimax regret level  optimal allocation and witness  in a single optimization  for these two new leaf nodes given their partial type vectors.
모with multiple leaves  the heuristic functionmust first select a leaf node for splitting before selecting a split. it does this by selecting the partial type vector  leaf node  with greatest minimax regret. the algorithm iterates in this fashion  repeatedly selecting the leaf node with greatest minimax regret and using the heuristic to decide which agent's partial type  within that node  to split  and how to split it   until some termination criterion is met  e.g.  the worst-case max regret is reduced to some threshold  or some maximum number of partial types- per agent or overall-is reached .
모unfortunately  unlike standard decision tree construction  a split at one leaf has implications for all other leaves as well. for example  after the initial split above  a split may be recommended at node 1 in the tree  corresponding to
. suppose a split of agent i's partial type 붿i into and is suggested for some . since 붿i is included in the partial type vectors of both nodes 1 and 1  this split affects both child nodes  since agent i will have to distinguish  at the very least from. we there must replace nodes 1 and 1 with four new leaf nodes  nodes 1   corresponding to the combinations of.
모this naive approach has two obvious problems. first  there is an exponential blow-up in the number of leaves of the  mechanism tree  since any reasonable heuristic  including the one described below  will often  roughly  alternate splits between the agents whose type uncertainty is still relevant. the algorithm is therefore computationally demanding. second  consider the example above. the split of 붿i at the second iteration of the algorithm was recommended by the heuristic based on the partial type vector at node 1  which includes   because of its ability to reducethe minimax regretlevel of that specific partial type vector. however  this split may have little or no effect on minimax regret when applied to node 1  in which agent 1's partial typeis different . this split may indeed be  useless  when considered at node 1. these problems can be avoided by modifying the algorithm as follows.
모when a split is made at some node k  even though the partition has been updated in a way that might affect a partial type at another node k  we can choose to ignore the effect on k. thus node k corresponds to a partial type vector that is no longer in our partition but includes a collection of partial type vectors that are. we call k a joint node  and for each such node  we record the splits that have been ignored. in our example  the split of node 1 on 붿i may be ignored at node 1  leaving node 1 to be a joint node. in the tree  node 1 would generate two descendants  nodes 1 and 1   while node 1 would remain a leaf node  nodes 1 and 1 would not be generated . while the split of i's type into  and will eventually need to be considered at node 1  or its descendants   we defer this decision  as discussed below   and can consider making additional splits of node 1 first should this split of 붿i be of little value. this saves having to consider the splits of multiple descendants of node 1 independently.
모note that multiple ignored splits may be  nested . for example  perhaps the first split cuts the partial type into one where some utility parameter p1 is greater than .1  call this 붿i 1  and one where it is lower  붿i 1 ; the second splits 붿i 1 on p1 at .1; the third splits 붿i 1 along parameter p1 at .1  and so on. when such joint node is the leaf with greatest regret level  i.e.  the one to be considered for expansion   we first check if there is a useful ignored split before considering the split recommended by the heuristic. if so  we  un-ignore  it  thus creating another leaf but without increasing the com-
find leaf node n with highest regret
call heuristic on n's partial type vector. output: hsplit
if there exists ignored split isplit on same parameter as hsplit:
splitnode n isplit 
else search for  good  ignored split gsplit if there exists one:
splitnode n gsplit 
else test hsplit
if hsplit is  good':
 splitnode n hsplit  else-if hsplit is  ok': search for  ok  ignored split oksplit if there exists one:
splitnode n oksplit 
else: splitnode n hsplit 
table 1: split selection algorithm
splitnode n split 
붿 = partial type vector of n; i = agent involved in split split according to split update i's partition
compute new mmr for both 
create corresponding new nodes separate n's ignored split list into those for replace leaf n in tree with leaf nodes
for all leaf nodes with 붿i in their partial type vector add split to list of ignored splits
table 1: splitnode function
plexity of the partition. the precise way in which we select splits is described in tables 1 and 1. a split is called  good  if both resulting nodes have lower regret than the node that was split  and  ok  if only one of them does. with this improved algorithm  new mechanism nodes are only added if they are helpful. since the naive approach results in useless splits  computational requirements can be greatly reduced by adopting this more sophisticated approach.
yes and no. when splitting  say  x   the partial type corresponding to the no answer  i.e.  lowering the upper bound  is unlikely to have lower regret unless x  also turns out to be the witness of the second best regret minimizing allocation. in that case  lowering its upper bound will help reduce the second lowest regret and raising the lower bound will help with the lowest. we therefore also compute the second lowest max regret solution x 1 and its witness x 1. if both x  = x 1 and x  = x 1 are true  or neither is true  we split the one with the largest gap  the difference between its upper and lower bounds . if only one is true  we split that parameter  unless its gap is below some threshold  and the other gap is not.
모this seemingly trivial strategy has interesting properties when utility models are factored using gai. in this setting  our heuristic is an adaptation of the current solution elicitation strategy of  to an offline one-shot elicitation scenario. we defer details to a longer version of this paper.
1 empirical results
we report on experiments in a multi-attribute negotiation domain. a buyer and a seller are bargaining over a multiattribute good to trade. the set of 1 possible goods is specified by four boolean variables  x1 x1 x1 x1  denoting the presence or absence of four specific item features. the buyer's valuation and the seller's cost are represented using gai structure. each agent's utility function is decomposed into two factors  each factor with two different variables: vb x  = vb1 x1 x1  + vb1 x1 x1  and vs x  =
. each subutility function is specified
using four parameters  indicating the local value of the four possible combinations of features. thus eight utility parameters fully define each agent's utility function.
모initial prior bounds on utility parameters  i.e.  the initial type space  are drawn uniformly between 1 and 1  seller cost  or 1 and 1  buyer value   ensuring a positive transaction exists. though 1 goods may seem small  it is much larger than problems solved by existing automated approaches to  one-shot  mechanism design  all of which are restricted to a small  finite type space . the social welfare maximizing allocation is that good that maximizes surplus  difference between buyer value and seller cost .
모we assess the performance of our mechanisms by showing how the worst case minimax regret level  over all possible agent types  reduces with the number of partial types created by our approach  expressed in number of bits . since prms are designed to work for agents with any true types  there is no single true type or optimal allocation to compare to. we could simulate specific agents  but our worst-case regret bounds any such  true loss  results  and these bounds are tight in the sense that at least one set of agent type profiles will incur this worst case regret. of course  regret any specific collection of agents  or type profile  will generally be lower 
so we also show expected regret in our results  assuming a uniform distribution over type parameters. we compare our myopic approach to type construction  i.e.  where regret reduction is used to determine splits of partial types  to a simple approach for partial type construction that simply splits each partial type evenly across all parameters.1
모figure 1 shows the worst case minimax regret level of our regret-based prms  averaged over thirty runs using different priors  when partial types are constructed using our myopic algorithm and when uniform splitting is used. we also show expected minimax regret level  assuming a uniform distribution over types . results are reported as a function of the number of bits of communication necessary for an agent to report some partial type in the proposed partition. bounds on manipulability  efficiency loss  and rationality violation are all dictated by this worst-case regret  depending on whether partial groves or clarke payments are used .1
모it is clear that using regret-reduction to decide how to  refine  partial type space offers a significant improvement over a uniform partitioning. our regret-based approach provides good anytime behavior while uniform partitioning reduces 붼 as a step function  averagingsmoothsthe results in the graph . naturally  average manipulability is lower than worst-case manipulability  thus further justifying the use of approximate incentives. we note that the initial regret level  assuming only one partial type  i.e.  ti  for each agent i  corresponds to an error between 1% and 1% of the optimal social welfare  depending on the actual agent types  and is reduced using 1 bits of communication  to communicate one's partial type  to 1% error by our regret-based approach versus only 1- 1% by the uniform approach. with only 1 bits  the regretbased approach reduces efficiency loss and manipulability by about 1% while a uniform partition reduces it by about 1%. to reach an average manipulability level of around 1  a uniform approach requires 1 bits compared to 1 for regretbased splitting  which constitutes a 1% savings in communication. to reach manipulability level of roughly 1  the regret-based approach provides a 1% savings in communication  1 bits vs. 1 bits . note that this savings will be realized repeatedly if the mechanism is used to support  say  multiple bargaining instances. finally  it is worth remarking that 1 bits corresponds to about 1 bits per parameter and 1 bits per allocation  which is quite small in an example of this size.
모preliminary tests using a  computationally demanding  myopically optimal heuristic  that considers each parameter and chooses the highest regret drop  show only modest improvement over regret-based splitting  thus motivating the investigation of non-myopic splitting techniques.
1 conclusion
we have proposed a general model for partial revelation mechanisms in which social welfare maximization is the desired objective and explored their incentive properties. as a result of our negative results on bayes-nash and ex-post implementation  along with classical results on dominant strategies   we have relaxed the requirement of exact incentive

figure 1: worst case and expected 붼  as a function of the number of bits used per agent. averaged over 1 runs.
compatibility and focused on approximating both the efficiency and incentive properties of prms  allowing one to exploit the trade-off between the computational  communication and cognitive costs of type revelation with the degree of approximation. regret-based prms  in particular  allow one to bound efficiency loss  gain from manipulation and non-participation  and admit promising optimization methods for the automated design of prms. critically  when the gain from non-truthful revelation is sufficiently small  our results on formal  approximate incentive compatibility ensures  practical  true incentive compatibility.
모apart from more extensive empirical evaluation  there are several directions in which this work should be extended. the first is the integration of techniques for approximating regret computations into our algorithm to tackle realistic problems . the second is the investigation of more efficient splitting heuristics that improve both the communication requirements of our mechanisms and the computational costs of designing them. the design of non-myopic incremental partial mechanisms is of special interest. precisely determining the complexity of manipulation by formally modeling the costs involved is also an important task in further justifying our emphasis on approximate ic and ir. we are exploring further benefits offered by partial revelation and  bounded  approximate ic w.r.t. to circumventing some other classic drawbacks and  impossibility  results for direct mechanisms. finally  we are very interested in the exploiting prior distributional information about types in the construction of partial type space to reduce expected efficiency loss and manipulability  while retaining our worst-case guarantees  similar to the approach taken in  full revelation  automated mechanism design .
acknowledgements: thanks to vincent conitzer  kevin-leyton brown  david parkes and the referees for helpful discussions and comments. this work was funded by nserc.
references
 a. archer  c. papadimitriou  k. talwar  and e. tardos. an approximate truthful mechanism for combinatorial auctions with single parameter agents. soda-1  pp.1  baltimore  1.
 l. blumrosen  m. feldman. implementation with a bounded action space. acm ec-1  pp.1  ann arbor  1.
 l. blumrosen and n. nisan. auctions with severely bounded communication. focs-1  pp.1  vancouver  1.
 c. boutilier  r. patrascu  p. poupart  and d. schuurmans. constraint-based optimization and utility elicitation using the minimax decision criterion. art. intell.  1-1  1.
 w. conen and t. sandholm. partial-revelation vcg mechanisms for combinatorial auctions. aaai-1  pp.1  edmonton  1.
 v. conitzer and t. sandholm. complexity of mechanism design. uai-1  pp.1  edmonton  1.
 p. cramton  y. shoham  and r. steinberg  editors. combinatorial auctions. mit press  cambridge  1.
 r. fadel  i. segal. the communication cost of selfishness: ex post implementation. tark-1  pp.1  singapore  1.
 p. c. fishburn. interdependence and additivity in multivariate  unidimensional expected utility theory. intl. econ. rev.  1- 1  1.
 j. green and j.-j. laffont. characterization of satisfactory mechanisms for the revelation of preferences for public goods. econometrica  1-1  1.
 t. groves. incentives in teams. econometrica  1-1  1.
 r. holzman  n. kfir-dahav  d. monderer  and m. tennenholtz. bundling equilibrium in combinatorial auctions. games and econ. behavior  pp.1  1.
 n. hyafil and c. boutilier. regret minimizing equilibria and mechanisms for games with strict type uncertainty. uai-1  pp.1  banff  ab  1.
 n. hyafil and c. boutilier. regret-based incremental partial revelation mechanisms. aaai-1  pp.1  boston  1.
 r. lavi  a. mu'alem  and n. nisan. towards a characterization of truthful combinatorial auctions. focs-1  pp.1  cambridge  ma  1.
 d. lehman  l. i. o'callaghan  and y. shoham. truth revelation in approximately efficient combinatorial auctions. j. acm  1-1  1.
 a. mas-colell  m.d. whinston  and j.  r. green.  microeconomic theory. oxford university press  new york  1.
 n. nisan and a. ronen. computationally feasible vcg mechanisms. acm ec-1  pp.1  minneapolis  1.
 n. nisan and i. segal. the communication requirements of efficient allocations and supporting prices. j. economic theory  1. to appear.
 d.c. parkes. auction design with costly preference elicitation.  annals of math. and ai  1-1  1.
 d.c. parkes and j. kalagnanam. iterative multiattribute vick-  rey auctions. management science  1-1  1.
 k. roberts. the characterization of implementable choice rules. in j.-j. laffont  ed.  aggregation and revelation of p