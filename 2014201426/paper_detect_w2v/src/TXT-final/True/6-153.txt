 
we propose a purely logical framework for planning in partially observable environments. knowledge states are expressed in a suitable fragment of the epistemic logic s1. we show how to lift the effects of actions  both physical actions and sensing actions  from the state level to the epistemic level. we show how progression  regression and plan generation can be achieved in our framework. 
1 introduction 
planning under incomplete knowledge and partial observability is a tricky issue in ai  because of its computational  temporal and spatial  hardness. partially obsewable markov decision processes  pomdp  are the mainstream approach to partially observable planning. nevertheless  the applicability of the pomdp approach is limited from the practical side as soon as the set of states has a strong combinatorial structure  rendering the number of states much too high for an explicit representation of actions  preferences  and policies. on the other hand  logical approaches to planning under incomplete knowledge allow for much more compact encodings of planning problems than pomdps; most of them deal with an incomplete initial state and/or nondeterministic actions  but either they do not handle partial observability  or at least they do it in a very simple way  by assuming for instance that the set of variables is partitioned between  directly  observable and unobservable variables. 
　to fill the gap between pomdps and logical approaches  an abstraction of the pomdp model  leaving aside probabilities and expected utility  can be considered. it should account at least for the following elements: a set s of states; a set of belief states built from s ; a set of actions  where each action is associated with a transition model between states and/or belief states; some preference structure  e.g.  a simple goal or a utility function ; and a set of observations  together with some correlation function between states and observations. 
　while policies for a fully observable mdp map states to actions  the output of such an abstract pomdp is a policy mapping belief states to actions; indeed  a pomdp can be viewed as a fully observable mdp over the set of belief states  this is a classical way of understanding pomdps - and even to solve them . 
　in this paper  we present a rich logical framework that instantiates the abstraction above  views a partially observable process as a fully observable process over belief states  and allows for expressing actions and policies in a compact way. the framework has a fairly good level of generality  since it avoids for instance to commit to a particular action language  see section 1  and is therefore modular enough to be easily adapted or extended. 
　the simplest and best-known way of distinguishing between truths and beliefs in logic consists in expressing the problem in an epistemic or doxastic logic. to make the exposition simpler  we assume that the agent has accurate beliefs  i.e.  all she believes is true in the actual world. this means that we identify belief and knowledge  since knowledge is usually viewed as true belief ; therefore our framework is based on the logic s1 and instead of belief we use the term knowledge throughout the paper.  s1 is computationally no more complex than classical logic: s1 satisfiability is np-complete  ladner  1. 
　in section 1 we define two notions of knowledge states: simple knowledge states  for on-line plan execution  and complex knowledge states  for off-line reasoning about the effects of a plan . in section 1 we show how a knowledge state evolves when an action is performed. then we show in section 1 how to perform goal regression  and we show in 
section 1 how it can be used so as to implement a sound and complete plan generator. section 1 discusses related work. 
1 knowledge states 
       1 alternatively  we could have chosen to work with beliefs  using the doxastic logic kd1  which is very similar to s1 except that beliefs may be wrong  that is  is not an axiom. the technical issues developed in this paper would have been almost identical. now  choosing another logic than s1 or kd1 would induce a lot of complications  including an important complexity gap. the language  of propositional logic s1 is built up from a finite set of propositional variables var  the usual connectives  the logical constants and and the epistemic modality k. s1 formulas are denoted by capital greek letters  etc. an s1 formula is objective  or modality-free  iff it does not contain any occurrence of k  i.e.  it is a classical propositional formula . objective formulas are denoted 

reasoning about actions and change 	1 

a structure1 for s1 is defined as a nonempty set of states 
m  s. rather than  structure   we call m a knowledge state  sks . intuitively  it represents all the states the agent considers possible. the satisfaction of an s1 formula by an sks m for a state s m is defined inductively by: 
　a complex knowledge state  cks  is a positive epistemic formula 1 generated by epistemic atoms and the connectives 
　　　1this semantics is equivalent  and simpler for our purpose  to the usual semantics by means of kripke models  w  wa/  r  where w is a set of worlds  val a valuation function and r an equivalence relation. sec for instance  fagin et al.  1. 
1 	actions and progression 
in general  actions have both physical  or otitic  and epistemic effects  i.e.  they are meant to change both the state of the world and the agent's knowledge state  but without loss of generality we assume  as usually in ai  that any  mixed  action can be decomposed into two actions  the first one having only ontic effects and the second one only epistemic effects. for instance  the action of tossing a coin is decomposed into a bj i n d - t o s s action followed by a see action telling the agent whether the coin has landed on heads or on t a i l s . 
ontic actions 
ontic actions are meant to have effects on the world outside the agent  especially physical effects such as moving a block  switching the light  moving etc. they are assumed to be described in a prepositional action language  allowing or not for nondeterminism  for ramifications/causality . any action language can be chosen  provided that it is propositional and that it expresses the effects of an action a within a formula involving atoms labelled by t and atoms labelled by 
　　　 the former for the state before the action is performed  the latter for the state after it is performed . among candidate languages we find those of the family  gelfond and lifschitz  1    propositionalized  situation calculus  lin  1  and causality languages  mccain and turner  1 .1 
　the description of an action allows for computing the successor state of a state s  or the set of successor states if  is nondeterministic . this set is represented by any objective formula prog   whose models form the set of successor states . this definition extends to sets of initial states  or equivalently to propositional formulas  by 


1 	reasoning about actions and change 

then she still knows it after  and reafter performing then after observing it . these three 
　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　ciated with the outcome set 	can be represented by the following progression operator: 
reasoning about actions and change 	1 

and built up from variables of 
　the latter abductive characterization of ontic actions is in- plans are defined inductively as follows: dependent of the action language chosen - and it now allows   the empty plan is a plan; 
for characterizing the regression of complex epistemic states 	  any action  ontic or epistemic  is a plan; 
by an ontic action. 	
1 	regression for epistemic actions 
1 	reasoning about actions and change 

definition 1  valid plans  a plan is  alid plan for the planning problem v if and only if prog 
exemple 1  cont'd  initially  the agent does not know the values of and  her initial knowledge state is and her goal is to reach a belief state where she knows the value 

　a valid plan can be computed by the following backward algorithm based on goal regression which is reminiscent of dynamic programming. the current goal expressed in ednf  is initialized as then we nondeterministically pick an action and compute the current goal is then updated by 	the process is iterated until or it is not possible to improve anymore. since there is a finite number of possible belief states  the algorithms stop and returns valid plan  
if such a plan exists. an ordered list l is constantly updated  initialized by where '. 
　　　　　　　　each time a new disjunct  i.e.  not subsumed by any previous disjunct of is added to after regressing by action a  the pair is added to l. 
　there are two slightly different possible outputs:  1  either the output is just l  i.e.  an ordered knowledge-based program  or decision list : at execution time  when observations are made  the new knowledge state is computed  then we look for the leftmost in l such that is true in the current knowledge state and is performed;  1  or the output is a ready-to-use conditional plan computed by  simulating  possible executions from 
1 	related work 
knowledge-based programs in the planning community  the idea of using explicit knowledge preconditions for actions and plans comes back to  moore  1; morgenstern  1j. developed in a different perspective  agent design   knowledge-based programs  fagin et al  1; brafman et al  1; herzig et al  1; reiter  1  are high-level protocols that describe the actions an agent should perform as a function of her knowledge. thus  in a knowledge-based program  branching conditions are epistemically interpretable  and plans explicitly involve deduction tasks during on-line execution  just like in our framework . actually  the output of our plan generation process is a knowledge-based program. therefore  our work can be seen as an upstream task that generates a valid knowledge-based program from a compact specification of action effects and goals. 
action languages a number of works have extended action languages so as to handle explicit knowledge and partial observability  especially  lobo et al.  1; de giacomo and rosati  1; baral and son  1 . knowledge is represented in all cases by an explicit or implicit epistemic modality  plus a  minimal knowledge  semantics in  de giacomo and rosati  1  . the line of work most related to ours is of  baral and son  1 ; indeed  not only they represent epistemic actions with an epistemic modality but they also allow for conditional plans with epistemic branching conditions. our work can be seen as an extension of theirs:1  i  our formalism is general enough to accept any propositional action language  including those handling causal rules  for representing the effects of ontic actions ;  ii  our syntax is less restricted  since we allow for any and-or combination of sks  i.e.  ckss  while they consider sks only; as argued in section 1  this makes the representation more compact  when reasoning at planning time about the future consequences of actions;  hi  our progression and regression operators have significant computational characterizations  e.g.  ontic regression has an abductive characterization ; lastly  we have a sound and complete algorithm for plan generation. 
planning under partial observability there is a number of recent approaches for logic-based plan generation under partial observability. 
　 bonet and geffner  1  give a high-level language for describing action effects on both the world and the agent's beliefs. their language is a decidable fragment of first-order logic. by describing ontic actions with successor state axioms  they allow for handling the frame problem and ramification problems. after a problem has been represented in their language  its description is automatically translated 
into a pomdp model and solved by using pomdp algorithms  so that there is no need to define progression and regression directly in the logic  nor to have an explicit knowledge modality: this is the main difference with our approach  where the compact logical representation is kept and propagated throughout the process. 
　the next three approaches solve the plan generation problem directly in a high-level language but  on the other hand  they all make important restrictions that lead to a loss of expressivity. these restrictions imply that none of these approaches makes use of action languages  while ours can benefit from the huge amount of work in this area and accordingly  can handle the frame problem as well as ramification and causality in the best possible way while maintaining computational complexity at a reasonable level. 
reasoning about actions and change 	1 　 bacchus and petrick  1; petrick and bacchus  1   like us  use an epistemic modality. apart from the representation of ontic actions  less expressive than ours due to the abovementioned point1   they restrict the syntax of epistemic formulas  for instance  simple disjunctive beliefs such as k av1  cannot be expressed  and consequently  as they notice  their algorithm sometimes fails to discover a valid plan. 
  . the approaches  sertoli et al.  1; rintanen  1  do not make use of an epistemic modality  and therefore cannot explicitly express disjunctions of belief states  i.e.  ckss  or complex knowledge-based programs. the representation of belief states in both approaches uses bdds  which allow for a compact representation but not as space efficient as dag-based propositional formulas. while the algorithm in  bertoli et al  1   uses progression  based on model checking    rintanen  1  has a regression operator  and  interestingly enough  his combination operator  between belief states  which aims at computing  given two belief states b  and b1  the maximal belief states in which  after observing the values of observable variables  leads to know that the true state is in 1 or to know that the true state is in b1  can be reformulated using our epistemic regression  section 1 1 and thus epistemic logic helps understanding how and why this operator works.1 
situation calculus  scherl and levesque  1  represent sensing actions in the situation calculus by means of an explicit accessibility relation between situations  which means that knowledge is treated as an ordinary fluent  which corresponds exactly to the semantics of our epistemic modality  once situations have been identified with states . our approach expresses the problem at the formula level and enables thus a more concise representation and can benefit from existing complexity and automated deduction results for s1. levesque  levesque  1  builts on the above framework towards a general theory of planning with sensing  handling complex plans involving  like ours  nondeterminism  observations and branching  and also loops . 
acknowledgements 
the third author has been partly supported by the iut de 
lens  the universite d'artois  the region nord / pas-decalais under the tact-tic project  and by the european community feder program. 
