ions in predictive state representations
brian tanner and vadim bulitko and anna koop and cosmin paduraru
department of computing science edmonton  alberta  canada t1g 1
{btanner  bulitko  anna  cosmin} cs.ualberta.ca
　
abstract
this paper proposes a systematic approach of representing abstract features in terms of low-level  subjective state representations. we demonstrate that a mapping between the agent's predictive state representation and abstract features can be derived automatically from high-level training data supplied by the designer. our empirical evaluation demonstrates that an experience-oriented state representation built around a single-bit sensor can represent useful abstract features such as  back against a wall    in a corner   or  in a room . as a result  the agent gains virtual sensors that could be used by its control policy.1
1 introduction
it is often useful for intelligent agents to reason at a level more abstract than their perceptions. abstractions aggregate many sensory situations into a single configuration of abstract features  allowing behavior expressed in abstract terms that generalize across similar situations. this generalization allow humans designers to encode control policies closer to the level of human reasoning. for instance  using abstractions  an agent's designer can define a policy such as  avoid navigating through open areas  or  don't stop near a doorway .
　the desire to write control policies in abstract terms is often thwarted because the policies must be implemented over the set of state variables and sensor readings available to the agent. in simulation  one option is to directly augment the environment with high-level information  e.g.  each tree in a forest may be annotated as a possible cover for a soldier agent   paull and darken  1 . if access to the environment is not available  a programmer may write code to map low-level state  e.g.  coordinates and obstacle detectors  to higher-level abstract terms  e.g.  being in a narrow corridor where the unit cannot move sideways   orkin  1 .
　as realism of simulations used for real-life training and education  dini et al.  1  increases  both approaches are becoming expensive. indeed  the number of abstract features and the amount of underlying software engineering needed to define them has been compared to construction of the tower of babel  mcdonald et al.  1 . likewise  manually annotating modern games and simulations is prohibitively timeconsuming and error-prone.
　this paper makes several contributions to the aforementioned problems. we propose an automated approach for learning a mapping from agent state representations to human-defined abstractions using a small set of data labeled by a human expert. we use a  i know it when i see it  approach to defining abstract features; instead of programmatically defining or assigning values to the abstract features  the human expert examines a number of examples and labels them appropriately. a machine learning classification algorithm  such as c1  quinlan  1   can then create a classifier that will appropriately label novel future experiences.
　for this approach to be useful  it is important that the agent's state representation allows the values of the abstract features to generalize well between the labeled examples and unseen data. we argue that agents using subjective  grounded representations are well suited to making these generalizations. a subjective  grounded approach represents the agent's state in terms of experience with its sensors and effectors. specifically  we use a predictive representation of state: the agent's state is stored as a vector of probabilities of outcome sensations given various sequences of action  littman et al.  1 . we believe that both concise and vague abstractions can be characterized by patterns of interaction: abstractions learned in terms of a predictive representation are portable to novel situations with similar patterns of interaction.
　in a small navigation domain  we demonstrate that an agent using a simple classification algorithm can learn to identify intuitive abstractions like back-to-wall  corner  narrow-corridor  and room using both subjective and objective state representations. further  we show that in the subjective case  the learned classifier allows the agent to identify these abstractions in a novel environment without any additional training.
1 background and related work
in a typical situated agent framework  the agent  decision maker  interacts with an environment at a series of time steps. the agent receives perceptions or observations from the environment at each moment and responds with actions that may affect the environment. in this paper  we model the world as a partially observable markov decision process  pomdp . we assume that at each discrete time step  there is a set of data  called the state  that is sufficient to make accurate probabilistic predictions of future experience  the markov assumption . the state is not directly observable by the agent  the observation received from the environment may correspond to multiple different states.
　the standard pomdp model represents the agent's current state as a probability distribution over a set of unobservable situations that the agent may be in. each of these unobservable situations is called a nominal state; distributions over nominal states are called belief states. pomdps use the conditional probability rule  a nominal state transition model  and an observation model to update the belief state with each new action and observation. the transition and observation models are usually determined by a human expert and then later these parameters are optimized with data.
　alternatively  history-based methods also model partially observable environments by considering either a fixed or variable length window of recent interactions with the environment  mccallum  1 .
　predictive state representations  psr  are a third type of representation that model both observable and partiallyobservable environments  littman et al.  1 . instead of focusing on previous interaction with the environment  the predictive model represents state as a set of predictions about future interactions. in a psr  the agent's state is represented as answers to questions about future experience in the world. for example  one element of the state representation might be  what is the probability of receiving the sequence of observations  o1 ...oi  if i take the sequence of actions  a1 ...aj   . singh et al.  proved that linear predictive state representations can represent all environments that can be represented by a finite-state pomdp or a finite-length history method.
　a psr has two components: structure and parameters. the structure is the set of events that the psr makes predictions about  called the core tests. each core test predicts the probability of observing a particular sequence of observations if a particular sequence of actions is chosen by the agent. the parameters are used to update the core test values after each new action and observation. algorithms have been proposed for learning the psr parameters  singh et al.  1  and discovering and learning psr structure and parameters together  mccracken and bowling  1 .
1 abstractions
a state representation stores each state as a configuration of variables. in a traditional mdp  the state is often represented by a single discrete variable with a unique value for each state in the state space. in a pomdp  the state is represented by a vector of n continuous-valued variables （  1   where n is the number of underlying nominal states. in a linear psr  the state is also a vector of n continuous-valued variables （  1   where n is the number of core tests.
　in this paper  an abstraction is a many-to-one operator φ that maps several configurations of state variables to a single configuration of a different set of variables. for example  consider an mdp for a navigation task where the state is represented using three discrete variables . the first two variables  represent a location  while θ denotes rotation or orientation in a coordinate system. one abstraction φi might identify the north-east-corner  defined as all states within 1 units of the corner of the environment. in this case:

　we generally refer to the outcomes of abstractions as abstract features. abstract features allow a control algorithm to make useful generalizations: to behave similarly in states that have different state variable combinations but similar abstract features. for example  our agent may know that northeast-corneris a good place to recharge its batteries.
1 representing abstractions
useful abstract features can often be invented by a human expert leveraging knowledge about a particular domain or task. no matter what the agent's representation  these abstract features are understood in the expert's terms. thus  a mechanism must be found that reliably converts the agent's state representation into the abstract features. this is usually an extensive software engineering effort involving lengthy tuning via trial and error  paull and darken  1 . in games and virtual reality trainers the resulting abstraction is sometimes referred to simply as  sensors   orkin  1  or  situation awareness components   kunde and darken  1 .
　the agent's state representation has a strong impact on the complexity and robustness of any script that converts the agent's state into abstract features. for instance  abstract features such as back-to-wall or narrow-corridor are difficult to concisely define as a function of. these features can have value 1 in various disjoint locations in the map  making their values difficult to know without explicit reasoning about walls or other obstacles. on the contrary  a predictive representation that stores the state as predictions about future perceptions can succinctly capture these abstractions in terms of patterns of interaction with the environment.
1 learning abstractions
we propose a machine learning approach for automatically finding a mapping between an agent's state representation and an expert's understanding of abstract features. the expert can look at a number of situations and appropriately label the abstract feature values in each case. we call this set of labeled examples the training set. for example  in the case of our mobile agent  the expert looks at a map of a particular environment and labels examples of the agent being in a narrow corridor. the agent then uses an off-the-shelf machine learning algorithm such as a decision tree learner to learn a set classifier that takes state variables as inputs and emits abstract feature values as outputs.
1 experimental results
in detail. specifically  our agent has four actions and a single for the demonstration  we chose a simple model of a pathfinding environment that allows us to evaluate our approach ment where some cells are open and some are blocked. the agent occupies exactly one cell and has four possible orientations  up  down  left  and right . the agent's actions are: go forward  f   turn left  l   turn right  r    and go backward  b . if the agent moves forward or backward and collides with an obstacle  the agent's position remains unchanged. at any time step  the agent's sensor reports 1 if the agent faces a blocked cell and 1 otherwise.
　we chose to make the grid world deterministic: the actions always succeed. determinism greatly simplifies the performance measures and visualization of our experiments without weakening the results.
　we use two different maps in our experiments. the first  map a  figure 1   has a total of 1 reachable grid locations with four orientations each  for a total of 1 states. the second environment  map b  figure 1   has a total of 1 reachable grid locations with four orientations each  for a total of 1 states.
state representations
the agent uses two different state representations  one that is based on objective coordinatesand another that is a predictive representation. as we have discussed  the objective  coordinate system is useful for characterizing certain abstractions that are tied to physical location on a map. if certain areas of the map have a certain abstract feature value  such as  in a room    then a classifier learned over thestate will correctly classify other states within the same room with very few training examples. however  if the agent has seen no examples of a particular room  the classifier will have no means to identify it even if it is identical in size and shape to another room seen previously.
　the agent's predictive representation is a vector of test values. each test value corresponds to the probability of the test's observations matching those generated by the environment  conditioned on the test's actions being executed.
figure 1: map b  used for testing the agent's virtual sensors.
　as an example  consider a predictive state representation with only two core tests. core test t1 is defined as seeing  1  after executing action  f . the value of t1 will be 1 if and only if the agent is facing an obstacle or can reach it within one step forward. core test t1 is defined as seeing  1 1  while executing  r r r . the value of t1 will be 1 if the agent had obstacles on its right  behind it  and on the left side of it. in a deterministic environment any core test has the value of 1 or 1. thus  this micro representation has four states:  t1 = 1 t1 = 1    t1 = 1 t1 = 1    t1 = 1 t1 = 1   and  t1 = 1 t1 = 1 . these tests are compactly denoted as
f1 and r1r1.
　we construct the psr representation from an accurate pomdp model of the environment using an adaptation of an algorithm introduced by littman et al. for creating linear psrs from pomdp models . the psr construction algorithm is a polynomial algorithm that uses depth-first search to find the set of psr core tests and their values in all of the pomdp nominal states. our straightforward adaptation of littman et al.'s algorithm uses breadth-first rather than depth-first search  yielding considerably shorter core tests.
abstract features
we chose four abstract features for our experiments  ranging from the formally and succinctly defined back-to-wall to the more vague room:
1. back-to-wall is a feature that is on when the agent would hit a wall if the backward action was taken  and off otherwise.
1. corner is a feature that is on in every grid location that has a corner where two blocked grid cells meet.
1. room is a feature that is on when the agent is in a room. this is a difficult feature to program manually due to the fact that  room  is a vague human-level concept. in our approach we circumvent this problem by simply allowing a human designer to label certain states as room without formally defining it  figures 1 and 1 .
1. narrow-corridor is a feature that is on in all 1-cell wide corridors  labeled by a human designer. this and the room abstraction are not labeled entirely consistently within or across the two environments because of subjective decisions made by the human designer.
1. finally  some grid cells are labeled as  neither  becausethe expert knew they should not be classified as room or narrow-corridor  but there was no other abstract feature to label them with.
1 experiment 1:  vs. psr on map a
in this experiment  we compare the classification accuracy of decision trees learned from varying amounts of training data within a single map  map a  using both representations. we hypothesize that with few training examples  the  representation will generally perform better on abstract features that are well characterized by spatial locality  e.g.  the room feature . conversely  we expect the predictive representation to perform well for abstract features that are well characterized by patterns of interaction  e.g.  backto-wall .
experimental method
all states in map a are labeled as either positive or negative examples of each abstract feature. the agent then uses the j1  similar to c1  quinlan  1   classification algorithm to create a separate decision tree for each abstract feature in both representations using the weka machine learning software package  witten and frank  1 . in all of our experiments  the reported results are for a psr created using some subset of the core tests generated by our pomdp to psr conversion algorithm. this subset is the first k tests found by the algorithm.
using the full set of thousands of core tests is simply not necessary. for various sample sizes p = {1% 1% 1%}  p of the examples are randomly sampled from map a and put into the training set  the other examples are left out and used as a test set. the classifier learned on the training set is then applied to the test set and classification accuracy is measured. the proportion of positive examples to negative examples is often quite biased  so all or our results report the accuracy of a baseline classifier that simply predicts the majority class from the training data. precision  recall  and specificity statistics were also measured but are not reported as they exhibited similar trends to the accuracy. this procedure is repeated 1 times and the mean and standard deviation of the accuracies is reported.
　this experiment was performed on all four abstract features  here we present the two results that represent either end of the performance spectrum: room and back-to-wall  shown in table 1.
% data used for training
	1%	1%	1%
roombaseline 1% ＼ 1	 1% ＼ 1	1% ＼ 11 tests 1% ＼ 1.1% ＼ 1
1% ＼ 1.1% ＼ 11% ＼ 1
1% ＼ 1back-to-wall	baseline	1% ＼ 1	1% ＼ 1	1% ＼ 1
	x y θ	1% ＼ 1	1% ＼ 1	1% ＼ 1
	1 tests	1% ＼ 1	1% ＼ 1	1% ＼ 1
table 1: accuracy of a classifier learned with  representation against a classifier learned with a 1 core test psr on the room and back-to-wall abstract features. test and training data sets are disjoint.
discussion
as expected  the  classifier was generally more accurate than the psr classifier on the room feature. surprisingly  for small amounts of data  the psr classifier is actually more accurate. this indicates that the subjective state representation is able to identify the most canonical examples of the room feature with very little data.
　when testing the back-to-wall feature  the psr classifier was substantially better than the  classifier. back-to-wall can be characterized by a very simple pattern of interaction even though it occurs in various locations on the map in all orientations. this makes it an ideal candidate for being represented in a subjective representation instead of a coordinate-based one. the decision tree that is learned for the psr classifier with 1 core tests is noticeably lengthier  1 leaf nodes  than a manually crafted classifier would be  1 leaf nodes . we believe this to be due to overfitting. when the same experiment is run on the backto-wall feature using fewer core tests  1 or fewer   the 1-node decision tree is found  figure 1 .

figure 1: decision tree classifier for the back-to-wall feature learned using a predictive state representation with 1 or fewer core tests.
1 experiment 1: transfer using psr
in this experiment  we investigate the degradation in classification accuracy when a decision tree learned on training data from map a is used to predict the abstract feature values on map b. good performance in map b is evidence that a classifier learned over a subjective state representation can be successful with novel experiences that share patterns of interaction with previous experiences. note that we will not compare the psr classifier's ability to transfer toclassifier in this experiment because the decision tree has no basis for being used in a different map. indeed  locations for the abstract features are highly map-specific and not even translation or rotation invariant.
　we perform this set of experiments using varying amounts of core tests as features for the classifier. we anticipate that some abstractions  back-to-wall and corner  will be easily identified with a small number of short tests as features.
the vague  larger area abstractions like room and narrow-
corridor may require more  longer tests. if this hypothesis holds  accuracy on the room and narrow-corridor abstractions should be worse for classifiers built using fewer core tests  and better when more core tests are used.
experimental setup
all states in map a and b are labeled as either positive or negative examples of each abstract feature. like the previous experiment  the agent then uses the j1 algorithm to induce decision tree classifiers from the training set  in this case all of the states from map a. the decision tree is then tested on all examples from map b. because the agent has access to all of the available training and testing data  only a single learning trial is used and no standard deviation values are reported in table 1. we present the results of using 1  1  1  and 1 core tests.
　the results labeled baseline correspond to predicting the value of the abstract feature that occurred most frequently in the training data: it is the accuracy that a classifier would get with no information about each training example except its label.
roomcorridorback-wallcornerbaseline1%1%1%1%1 tests1%1%1%1%1 tests1%1%1%1%1 tests1%1%1%1%1 tests1%1%1%1%table 1: accuracy of psr-based decision trees when training on map a and testing on map b with various amounts of tests.
discussion
the transfer results  shown in table 1  show the accuracy of the decision trees for all four abstract features when tested on map b. all of the accuracies are very good  close to perfect with the exception of the room abstraction. room is particularly hard  not only because it is vague  but because the
room feature is locally aliased. that is  there are places in map b labeled as not room that look very similar to areas in map a labeled as room. this is evident in the bottomleft and middle-right rooms in figure 1. both of these rooms have sections that look locally very much like the double wide area from the top of map b in figure 1  which is labeled as not room.
　the results in table 1 are produced using a classifier learned over different numbers of core tests. these tests are the first k found by a breadth-first search  meaning they may be quite short and ask questions only about states in the immediate neighborhood. most of the abstract features  backto-wall  narrow-corridor and corner  are well characterized by short tests as evidenced by their high accuracy with only a 1 test psr.

figure 1: errors identifying the value of the abstract feature
room. grid locations with marks indicate errors; ranging from small circles  error in a single orientation  to large circles  error in all four orientations .
　the bottom rows in table 1  1  1  and 1 tests  provide empirical support for the conjecture that larger area abstractions may need more  longer core tests. classification accuracy of the room abstraction increases substantially as more core test values are provided to the classification algorithm. the number of leaf nodes in the decision tree grows from 1 leaves with 1 core tests  to 1  1  and finally 1 with 1  1  and 1 core tests respectively. this seems to indicate that it is not the sheer volume of tests that is improving the quality of the classifier: which tests are used makes a difference in the accuracy of the classifier.
　a small amount of classification accuracy was lost as we moved up to 1 core tests  presumably because the low ratio of features to training examples allowed the classifier to overfit the training data.
figure 1 shows the location of misclassified room feature in map b. the decision tree induced from 1 tests makes mistakes in cells that appear locally similar but have the opposite labeling in map a. the decision tree also misclassifies certain states that are not similar to anything seen in map a.
1 limitations
our results provide evidence that subjective representations have desirable generalization properties for representing abstractions. however  our experiments were limited to a simple grid world and a linear predictive state representation. further substantiation of our claim will require wider experimentation with more abstractions  various environments  and more general subjective representations.
　our approach does not eliminate human experts: they are still required to identify which abstractions will be useful. this expert must also manually label a small amount of data before the learning algorithm can be applied. in the near future  an automated approach like reinforcement learning may be used to learn the control policies for these agents. when the expert is no longer creating control policies manually  it will not be necessary for these abstractions to have an interpretation suitable for humans. in this case  it would be very useful to have the agent automatically discover useful abstractions through its own experience  grollman et al.  1 .
1 conclusion
in this paper we have proposed a method for automatically learning a mapping from low-level state representations to high-level abstract features. in particular  we have demonstrated that a subjective  predictive state representation can generalize from a small sample of designer-labeled examples to novel experience. our experiments also show that a classifier learned over a predictive representation can effectively classify new experience in a different environment with similar high-level characteristics.
　this work is a step along the path to the automatic construction of virtual sensors that will be useful for creating strong control policies. this generalization ability will enable the design of control policies applicable in a wide variety of situations  allowing for richer domains and more complex agents.
1 acknowledgments
the authors gratefully acknowledge the ideas and encouragement they received from richard sutton  mike bowling  dan lizotte  mark ring and especially martha lednicky for helping compile the results.
