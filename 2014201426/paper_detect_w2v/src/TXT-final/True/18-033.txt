 
　　in the dialogue part of our system  we have tried to increase the user's possibilities to criticize the machine's results flfd require explanations of them. the system must then provide a clear justification : either by furnishing the chain of reaso-
ning or by asking a  good question  when it failed. the system must also be able to engage in a real dialogue  with more than one question / one answer. to do that  the system must build and use several kinds of representation : the reasoning  the topics and a mode  of the user  which is used to tailor the system's responses. i. introduction. 
　　artificial intelligence systems developed during the 1's were based on knowledge representation. the applications were supposed to showcase the different types of representation  such as frames  scripts  scenarios  or expert-systems. the dialogue problem 
was partly neglected. some programs  1  were then related to written dialogues; their primary purpose 
was to really understand the attitudes of both participants  but they didn't mind engaging in dialogue. at the same time  theoretical research has been pursued on this point  but has not always given rise to practical applications  1    1  ... 
　　following this path  we have tried to determine the types of knowledge implicated in human conversation. even if they are not always well defined  there are some rul-es which govern the elaboration of the sentences uttered in conversation. in this paper 
we will focus on the knowledge a program needs to cooperate in a dialogue. after a brief overview of the works that have influenced our research  the paper presents examples of possible dialogues. we then describe how the different kinds of knowledge representations are built and used. 
i i . the role of the machine in a dialogue. 
　　most studies in the theory of speech acts   l i      1  agree on grice's cooperation principle for analysis of human dialogues  a . a conversation is a relational act in which each participant is required to take an active part : else it would be a monologue or a dictatorial lecture! each interlocutor must take into account the other's goal. no one can be engaged in a dialogue if he can't explain his own utterances  or cannot specify what he couldn't understand in someone else's previous statements. 
to detail his principle  grice proposes some 
axioms that must be respected  otherwise  as your interlocutor assumes your statement was intentional  
he will make incorrect inferences. 
　　we have established that to be considered as a help  a question-answering system must respect the three following principles : 
　- be able to participate in a real dialogue  with more than just  one question - one response   
　- be able to restart the dialogue when some problem prevents the successful operation of the system 
　- be able to justify itself i.e. the chain of reasoning it used to produce a previous answer. 
1  examples of di alogues. 
　　in this paper  we describe dialogues where both participants are involved; the user expects from the machine a well-formed answer  i.e. not in some jargon   and the machine doesn't limit the user's part to a choice among a set of predefined questions. we are currently working on an application in which a program takes the place of the yellow pages  of the french telephone directory  the professional listings : suppliers of goods and services . 
　　this system assumes that the user's goal is to obtain a phone number; when a problem is posed  it searches for someone who might solve i t . the system has a deterministic parser  1  which analyzes the user's utterances; it uses a semantic network with different kinds of links. each listing is represented by its name  i.e. a concept and a list of sentences describing the activity of the supplier  1 . 
example el  illustrates the explanation process  
ul : t would like to move my safe. 
s1 : i suggest an art mover or a piano mover. 
u1 : why a piano mover   
s1 : because  both your safe and a piano are very heavy. 
u1 : why an art mover   
s1 : because your safe may contain valuable objects  and an art mover handles things of value. 
　　in ul  the topic recognized is  to move a safe . then  the reasoning process  reason  looks for an answer to this request : first it chooses the listings whose name contains the concept  move  or the concept  safe   then it searches the list of sentences describing the activity of the supplier. here it finds nothing  so it uses the  synonym  reasoning process  it examines the links between the concepts in the semantic network  and their possible combinations  e.g.  sort of  and  part of  give  part of  . reason finds that safe is the  approximate synonym  

a. vilnat and g. sabah 1 


1 a. vilnat and g.sabah 
 1  the system's chain of reasoning. tn the examples we demonstrate the necessity of different levels of detail in the chain of reasoning so as to present a  good  justification. in an order to obtain those levels  we have represented the reasoning as a tree  the sets of procedures which form reason constitute an implicit hierarchy; this hierarchy is reflected in the structure of the  reasoning tree  we produce. as a one-time procedure  for each version of reason  we build a tree which represents all the possibilities of reason   the image of the algorithm : imalgo  . each time reason is called  a new sub-tree is extracted  corresponding to the particular execution  the image of the execution : imexec . 1mexec is the trace of the reasoning used to solve a certain problem. j t will be used by the explanation process  explain . 
 1  the user's representation. in cr  we store a pointer towards a representation of the user as we currently define it  it is dynamic . it is composed of two elements : the knowledge level the system attributes to the user  and our current definition of the user's problem. the knowledge level is used to avoid to drown the user in details when the system explains its reasoning. it is based on tmalco. the representation of the user's problem is composed of the couple  predicate  object  which was used to call reason. joined to this is a list of concepts which modify one of the couple's two elements. we see in e1 that it is used to solve some cases of amb igui ty. 
　　it is the set of all these representations interconnected bycr which allow us to manage a dialogue  taking into account as best we can the three points un de r 1 ine d above : 
- participation in more than  one question - one answer  dialogue  
- restart the dia1ogue  
- s e 1 f - j us t i f i c a t i on. 
v  the use of these representations for the dialogue 
　　to enable us to accept questions regarding the whole dialogue  the cr is updated at each utterance  a new entry is created showing who spoke  the topic developed  the user's representation as it is currently perceived and the chain of reasoning. 
　　let us examine what happens when a user's utterance is addressed to the system. tt is first analyzed. then dialog acts in different ways  depending on the kind of question and the topic developed if the question contains a topic change  reason is called to search the knowledge base  in e1 : 1 and u1  . if it is a question concerning a prior topic  explain is called  in el : 1 . otherwise it is treated as information to resolve an ambiguous point  in e1 : u1  . at the end of the reasoning process  a good answer either has or has not been found.dialog will then transmit the good answer to the generation process  otherwise it tries to determine a question  in order to pursue the dialogue  see e1 . 
　　when explain is called  it first decide   by referring to topic and cr where this problem has been solved. then it retrieves the part of imexec concerned by the question  and taking into account the knowledge we assumes the user has  it builds an explanation. after that  the user's representation is modified so if he asks again for an explanation we may give him more details. 

v1 . conc1 us i on 
　　our goal is to give control of the dialogue back to the user  to permit him to change the subject  to 
backpedal  and to question the system's responses. in any case  if the system can't solve the whole problem  it must be able to efficiently aid the user to modify the request. to this end  the system's questions take into account the work already accomplished and indicate to the user the various paths possible to arrive at their goal. 
　　during a conversation  each participant assumes an enormous amount of knowledge on the part of the other s . this is what is shown in grices's maxims. he points out that the violation of any of the axioms derived from the cooperation principle is given significance equal to that of the actual contents of the utterance. this is why our system is constructed to act in accordance with these principles. the system's utterance must be clear so that the user doesn t have 
to search for hidden meanings. 
