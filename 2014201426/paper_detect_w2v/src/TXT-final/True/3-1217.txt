
in general  knowledge-intensive data mining methods exploit background knowledge to improve the quality of their results. then  in knowledge-rich domains often the interestingness of the mined patterns can be increased significantly.
in this paper we categorize several classes of background knowledge for subgroup discovery  and present how the necessary knowledge elements can be modelled. furthermore  we show how subgroup discovery methods benefit from the utilization of background knowledge  and discuss its application in an incremental process-model. the context of our work is to identify interesting diagnostic patterns to supplement a medical documentation and consultation system. we provide a case study in the medical domain  using a case base from a realworld application.
1 introduction
knowledge-intensive learning methods usually exploit background knowledge  because this can improve the quality of their results significantly  c.f.  richardson and domingos  1  . in this paper we exploit background knowledge for subgroup discovery  wrobel  1; klosgen  1：    applied for exploration or descriptive induction  to discover  interesting  subgroups concerning a certain property of interest. background knowledge can help to focus the algorithm for subgroup search on the relevant patterns according to the goals of the user  thus reducing uninteresting patterns and restricting the search space. this can increase the quality of the discovered set of subgroups significantly  as well as the efficiency of the search method. it is obvious  that the amount of available background knowledge depends on the particular application domain. for example  in the medical domain usually a lot of background knowledge is available.
　besides  simple  constraints the background knowledge for the presented knowledge-intensive process consists of two categories: a task-specific subset of derived attributes and general ontological background knowledge  that can be refined incrementally. certain knowledge classes can also be used to derive new  lower-level  knowledge. the knowledge classes can potentially be used in other rule-based learning methods in a straightforward manner. similar to the applied knowledge  subgroup discovery results can also be formalized incrementally and can be provided as input to the search method. we will introduce this approach in this paper.
　our implementation and evaluation is based on the knowledge-based documentation and consultation system for sonography sonoconsult  huettig et al.  1   which is in routine use in the drk-hospital in berlin/kopenick.：
　the rest of the paper is organized as follows: first we describe the knowledge-intensive process for subgroup discovery. we introduce the subgroup discovery method  present the different types of suitable background knowledge and discuss their characteristics in detail. after that  an experimental evaluation of the impact of the proposed method is demonstrated by a case study in the medical domain. finally  we conclude the paper with a discussion of the presented work  and we show promising directions for future work.
1 knowledge-intensive subgroup discovery
in this section  we first give an overview of the subgroup discovery method and define the basic concepts of our knowledge representation schema. furthermore  we present the knowledge-intensive subgroup discovery process  and describe the background knowledge in detail.
1 subgroup discovery
subgroup discovery  wrobel  1; klosgen  1：   is a method to discover  interesting  subgroups of individuals  e.g.   the subgroup of patients who are treated in a small  understaffed hospital are significantly more likely to suffer from complications in the future than the patients in the reference population . subgroups are described by relations between independent  explaining  variables and a dependent  target  variable  rated by a certain interestingness measure. for example  two possible criteria are the difference in the distribution of the target variable concerning the subgroup and the general population  and the subgroup size. the main application areas of subgroup discovery are exploration and descriptive induction  to obtain an overview of the relations between a target variable and usually many explaining variables. subgroup discovery does not necessarily focus on finding complete relations; instead partial relations  i.e.   small  subgroups with  interesting  characteristics can be sufficient.
　before defining the subgroup discovery task  we first introduce the necessary notions concerning our knowledge representation schema. let  a the set of all attributes. for each attribute a （  a a range dom a  of values is defined. furthermore  we assume va to be the  universal  set of attribute values of the form  a : v   where a （  a is an attribute and v （ dom a  is an assignable value.
　a subgroup discovery task mainly relies on the following four main properties: the target variable  the subgroup description language  the quality function  and the search strategy. the target variable may be binary  nominal or numeric. depending on its type  there are different analytic questions  e.g.  for a numeric target variable we can search for significant deviations of the mean of the target variable.
　a subgroup discovery problem encapsulates the target variable  the search space of independent variables  the general population  and additional constraints.
definition 1  subgroup discovery problem . a subgroup discovery problem sp is defined as the tuple
sp =  t a c cb  
where t （  a“va is a target variable. a    a is the set of attributes to be included in the subgroup discovery process. cb is the case base representing the general population used for subgroup discovery. c specifies  optional  constraints for the discovery method. we define  sp as the set of all possible subgroup discovery problems.
　the definition above allows for arbitrary target variables. however  for our analytic questions we will focus on binary target variables  i.e.  t （ va.
the description language specifies the individuals from the reference population belonging to the subgroup.
definition 1  subgroup description . a subgroup description sd = {ei} consists of a set of selection expressions  selectors  ei =  ai vi  which are selections on domains of attributes  i.e.  ai （  a vi   dom ai . a subgroup description is defined as the conjunction of its contained selection expressions. we define  sd as the set of all possible subgroup descriptions.
　a quality function measures the interestingness of the subgroup  c.f.   klosgen  1：   for examples .
definition 1  quality function . a quality function
q :  sd 〜  sp ★ r
evaluates a subgroup description sd （  sd given a subgroup discovery problem sp （  sp. it is used by the search method to rank the discovered subgroups during search.
　for binary target variables  examples for quality functions are given by
  
where p is the relative frequency of the target variable in the subgroup  p1 is the relative frequency of the target variable in the total population  n = |cb| is the size of the total population  and n denotes the size of the subgroup. in contrast to the quality function qbt  the quality function qrg only compares the target shares of the subgroup and the total population measuring the relative gain. therefore  a suitable support threshold is necessary to discover significant subgroups.
　considering the subgroup search strategy an efficient search is necessary  since the search space is exponential concerning all the possible selectors of a subgroup description. commonly  a beam search strategy is used because of its efficiency  klosgen  1：  . for our search strategy  we use a modified beam search strategy  where an initial subgroup description can be selected as the initial value for the beam. beam search adds a selector to the k best subgroup descriptions in each iteration. iteration stops if the quality as evaluated by the quality function q does not improve any further.
1 the knowledge-intensive process model
often suitable background knowledge can help both to focus the subgroup discovery task on the relevant patterns concerning the given analysis goals  and to restrict the search space. we propose an incremental approach in which background knowledge can be applied initially at the start  but also during the discovery process. the proposed knowledge-intensive process for subgroup discovery is depicted in figure 1.
　we start with a defined population given as a case base cb and existing background knowledge  if available. for the analysis task defined by a subgroup discovery problem the subgroup discovery method generates a set of subgroups. if these are considered as interesting by the user  the results are presented  and the process is finished. otherwise the subgroups are analyzed  and background knowledge including constraints can be added to the subgroup discovery problem. additionally  selected subgroups can be used as the basis for further refinement. then the process continues with a new iteration: all constraints of the current subgroup discovery problem are applied for the search process. in summary  the knowledge-intensive process consists of three main steps:
1. discover: discover subgroups - result set sg
1. inspect: if sg is interesting - stop and present the subgroup discovery results; otherwise
1. refine: analyze the discovered subgroups; adapt thesubgroup discovery problem  i.e.  extend or modify background knowledge and/or use interesting subgroups as a starting point for step 1. goto step 1

figure 1: the knowledge-intensive process model
step 1 is performed by the domain specialist according to the analysis goals. examples for the adaptation of the subgroup discovery problem are given in the case study in section 1.
1 background knowledge for subgroup discovery
we want to make the acquisition of helpful background knowledge as easy as possible. therefore  we try utilize knowledge known from other knowledge systems  that the domain specialist is already familiar with. there are different classes of background knowledge which can be used in the knowledge-intensive process for subgroup discovery: constraints  ontological knowledge  abstraction knowledge  and pattern knowledge. knowledge acquisition is always expensive  so its costs should be minimized. sometimes knowledge can be derived from already formalized knowledge  e.g.  we can derive constraints from ontological knowledge  and thus reduce its acquisition costs.
　in the following table  we summarize the different classes and types of background knowledge  ck = constraint knowledge  ok = ontological knowledge  pk = pattern knowledge  ak = abstraction knowledge . we show their characteristics in terms of the 'derivable knowledge' if applicable  their costs  and their potential contribution to restricting the search space and/or focusing the search process. considering the costs and the impact of the knowledge types on the search space  the label - indicates no cost/impact; the labels +  ++  and +++ indicate increasing costs and impact. a + +  signifies  that the respective element has low costs if it can be derived/learned  and moderate costs otherwise. similarly ++ +  indicates this for moderate and high costs  respectively.
knowledgederivablecostsearch spaceclasstypeknowledgerestr.focuscksyntactical constr.-+++ckquality constr.-+++++ckattr. values constr.-+ + ++ckmeta values constr.-+ + -++ckattributes constr.-+ + ++++oknormality infoattr. val. constr.++++okabnormality infoattr. val. constr.+++++meta val. constr.-++oksimilarity infometa val. constr.++ + -++okordinality infometa val. constr.++++++okattr. weightsattr. constraints+ + +++akderived attributesderived attributes+++++++++pksubgroup patternderived attributes+ + -+pkpriority groups-++-+　the most important types of background knowledge with an especially good cost/benefit ratio are indicated in bold type. derived attributes are a special case with potentially high benefit as discussed below. then  the need for derived attributes depends on the specific application domain.
constraint knowledge constraints are a class of background knowledge  which is especially simple to apply. the different constraint types can be described as follows:
  attribute values constraints: the attribute values can be restricted to the set of relevant values.
  meta values constraints: specific value groups defining an abstracted 'meta value' can be specified  e.g.  intervals for ordinal values. meta values are not restricted to intervals  but can cover any combination of values.
  constraints for attributes: specific attributes and/or combinations of attributes can be excluded.
  general constraints restricting the syntactical form of the discovered subgroups  or quality constraints for the discovered subgroups can be applied.
constraints can significantly restrict the search space and focus the search process. the knowledge acquisition cost for constraints is moderate  depending on the number of relations that need to be modeled; the costs can also be decreased utilizing ontological knowledge as described below.
pattern knowledge in general  pattern knowledge specifies the kinds of patterns that the user is especially interested in. for example  pattern knowledge can be used to define already known subgroups  that can be directly applied in the discovery process for subgroup refinement. as another kind of pattern knowledge  the user can specify priority groups which are partial disjunctive sets of attributes  that have an assigned priority  e.g.  depending on the association strength between an attribute and the target variable. then  we can start with the set of attributes with the highest priority. if the discovered subgroups cannot be improved any further by the attributes in the current set  then we take the attributes in the next prioritized attribute set into account  in the next iteration. the costs for pattern knowledge are not too high  if the patterns are discovered automatically. for priority knowledge  the cost is encoded in the partially disjunctive separation of attributes. pattern knowledge does not really restrict the search space  but can help to focus the search.
ontological knowledge we can utilize ontological knowledge which is commonly used in the development of knowledge systems  e.g.  in case-based reasoning systems. the following elements need to be defined by the domain specialist if they cannot be learned  semi- automatically  e.g.   baumeister et al.  1 .
  weights of attributes denoting their importance
  similarity information about the relative similarity between attribute values
  abnormality information about attribute values
  ordinality information about attributes
abnormality/normality information if abnormality or normality information about attribute values is available  then each value v （ dom a  of an attribute a is attached with a label that explains  if v is describing a normal or an abnormal state of the attribute. normality information only requires a binary label while abnormality information defines several categories. for example  consider the attribute temperature with the value range dom temperature  = {normal marginal high very high}. the values normal and marginal denote normal states of the attribute  while the values high and very high describe abnormal states. several categories can be defined according to the degree of abnormality. we use five degrees of abnormality given by the symbolic values a1 a1 a1 a1 a1. category a1 denotes a normal value; the categories {a1 a1 a1 a1} denote abnormal values in ascending order. using abnormality/normality knowledge we can constrain the value range of an attribute: e.g.  either all values corresponding to selected abnormal categories or the values marked with the normal category can be excluded from the domain of an attribute used in the subgroup discovery method  by a global exclusion condition. then  attribute values constraints are derived accordingly.
meta values abnormality information and similarity information concerning attribute values can be used to define additional meta values: e.g.  if the similarity between two attribute values is very high  then they can potentially be analyzed as one value  thus forming a disjunctive selection expression on the value range of an attribute. likewise  global abnormality groups can be defined by providing groups of abnormality degrees that specify which values should be combined. this is especially relevant in the medical domain with attribute values such as probable  possible  and unverifiable. in diagnostics the value probable contributes more evidence to the represented concept than the value possible. however  for analysis often the values probable and possible have an almost equivalent meaning and can be considered as one value.
　ordinality information that specifies if an attribute is ordinal can be used to define meta values relating to ordinal groups: we can generate meta values covering all adjacent combinations of attribute values  or all ascending/descending combinations of values  starting with the minimum or maximum  respectively. if abnormality information is available  then we partition the value range by the given normal value and only start with the most extreme value. for example  for the ordinal attribute liver size with the values 1:smaller than normal  1:normal  1:marginally increased  1:slightly increased  1:moderately increased and 1:highly increased  we partition by the normal value  1  and obtain the following meta values:  1    1  1  1  1    1  1  1    1  1  and  1 .
　we summarize how constraints can be derived from ontological knowledge: the set of relevant attributes can be constrained using attribute weights  with a suitable threshold. given similarity and abnormality/normality information about attribute values we can model/restrict the value ranges of attributes. ordinality information about attribute values can be easily used to construct ordinal grouped meta values  which are often more meaningful for the domain specialist. then  the original values can be replaced  optionally.
abstraction knowledge this class of background knowledge is given by derived attributes that are inferred from basic attributes or other derived attributes. derived attributes often correspond to certain known dependencies between attributes  or known intermediate concepts  that are not stored as basic attributes. for example  in the medical domain  we can infer the derived attribute body mass index  given the attributes height and weight. additionally  if there are a lot of basic attributes in the case base   known  multi-correlations between basic attributes can cause unstructured subgroup discovery results. then  data abstraction can increase the interpretability of the subgroup discovery results significantly. simple concepts can be aggregated to intermediate concepts to form more potentially meaningful and interesting selectors. a nominal derived attribute a （  a is defined using abstraction rules  which are utilized to derive the values via （ va concerning attribute a. a rule of the form rva = cond rva  ★ va is used for a value va of attribute a  where the rule condition cond rva  contains conjunctions and/or disjunctions of  negated  attribute values vi （ va. furthermore  derived attributes with a numerical value range can be defined by algebraic formula expressions.
improving the handling of missing values considering the quality functions abstraction knowledge contributes to one major point - handling missing values. missing values in cases are a significant problem for subgroup discovery and machine learning in general. for example  in medical case bases for a specific patient usually only a subset of the possible examinations is performed  given a structured data gathering strategy in real-world applications. then  only the relevant questions for the diagnostic tasks are presented to the user. this results in reduced costs for the examiner  however then a specific instance of the data set concerning the basic attributes may be quite sparse.
　there exist several strategies for dealing with missing values: a common strategy  tsumoto  1  removes objects  cases  with missing values from the set of analyzed objects. other strategies try to fill in the missing values according to statistical evaluations  or try to model the distribution  ragel and crewmilleux  1＞  . the subgroup quality functions basically perform a kind of statistical hypothesis testing given a subgroup description  the target variable and the general population. for such a test only the cases of the population can be considered in which all variables have defined values. the power of the test is decreased significantly  if many analysis objects are removed due to missing values.
　in general  we cannot simply apply the  closed-world assumption   i.e.  that missing values of a concept indicate the non-existence or negation of the concept. for example  in the medical domain  a diagnosis may be missing  because either all its relevant observations are missing or they are known but denote the normal  i.e.  the non-pathological state. consequently the diagnosis is not inferred. if we construct a derived attribute to indicate the cases when the relevant observations are missing  then we can use this derived  helper  attribute to indicate when the diagnosis really has a missing value. additionally  derived attributes besides the described  helper  attributes can also be constructed accordingly to minimize missing values themselves  such that a certain default value is provided which denotes the normal category. so  the derived attributes serve three purposes:
  they focus the subgroup discovery method on the relevant analysis objects 
  they decrease multi-correlations between attributes that are not interesting 
  derived attributes can reduce missing values for a given concept  since they can be constructed such that a defined value is more often computed if the respective concept would have a missing value otherwise.
the derived attributes can either be constructed based on expert knowledge  or on specific discovered subgroups. a subgroup description is a set of selectors for a specific target concept that are highly correlated with the concept. if the selectors can be abstracted into a derived attribute  then it can be used as potential background knowledge as well. furthermore  derived attributes can potentially be refined according to the subgroup discovery results  by specialization or generalization. abstraction knowledge is probably the most costly class of background knowledge in the knowledge-intensive process. if the abstractions are not based on discovery results  then they have to be formalized manually by the expert.
1 related work
using background knowledge to constrain the search space and pruning hypotheses during the search process has been proposed in ilp approaches.  weber  1  proposes requireand exclude-constraints for attribute - value pairs  in order to prune the search space.  zelezny et al.  1  integrate constraints into an ilp approach as well; the used constraints are mainly concerned with syntactical restrictions and constraints relating to the quality of the discovered subgroups.
　the main difference between the presented approach and the existing approaches is the fact  that we are able to integrate several new types of additional background knowledge. this additional background knowledge can be refined incrementally according to the requirements of the discovery task  and can additionally be used to infer new background knowledge on the fly  e.g.  constraints. as a major point we apply special abstraction knowledge  which can be defined by the expert  or can be constructed semi-automatically using the subgroup discovery results. this type of knowledge can be applied dynamically in the process and does not rely on a static data-preprocessing and cleaning task  for example.
1 case study
in this section we describe a case study for the application of the knowledge-intensive process. we use cases taken from the sonoconsult system  huettig et al.  1  - a medical documentation and consultation system for sonography - which has been developed with the knowledge system d1  puppe  1 . the system is in routine use in the drkhospital in berlin/kopenick and documents an average of： about 1 cases per month. these are detailed descriptions of findings of the examination s   together with the inferred diagnoses  binary attributes . the derived diagnoses are usually correct as shown in a medical evaluation  c.f.  huettig et al.  1    resulting in a high-quality case base with detailed case descriptions. the applied sonoconsult case base contains 1 cases. the domain ontology contains 1 basic attributes with about 1 symbolic values on average  1 symptom interpretations  which are rule-based abstractions of the basic attributes  and 1 diagnoses. this indicates the potentially huge search space for subgroup discovery.
　subgroup discovery was performed using the  vikamine  1   visual  interactive and knowledgeintensive analysis and mining environment  system  developed at the department of computer science vi of the university of wurzburg. we used beam search with a beam： size of 1 as the search strategy  and the quality function qrg as defined in section 1. the discovered subgroups were evaluated by domain specialists according to  clinical  novelty  interestingness  and actionability aspects.
　first  we performed subgroup discovery only using basic attributes and general background knowledge. we used attribute weights for feature subset selection. the subgroup discovery algorithm presented many significant subgroups  that supported the validity of the subgroup discovery techniques. however the results at this stage were not really novel  since they indicated mostly already known dependencies  e.g.  the relation between relative body weight and body-mass index.
　in the next stage  the expert decided to define new attributes  i.e.  abstracted attributes which described interesting concepts for analysis. the expert provided 1 derived attributes  that consist of symptom interpretations directly indicating a diagnosis and intermediate concepts which are used in clinical practice  for example pleura-effusion  portal hypertension  or pathological gallbladder status. furthermore  constraints were formalized  that prevented the combination of certain attributes  to restrict the search space. some examples are depicted in the table 1  where the dependent and independent variables are directly related to each other. the
target variableindependent variablechronic pancreatitispancreas diseasepancreas diseasecarcinoma of the pancreasbody mass indexrelative body weight　　table 1: examples of known/uninteresting relations newly defined abstraction knowledge was applied extending the search space to the expert-defined attributes. for each attribute a in the set of derived attributes and each value vi （ dom a   a subgroup discovery problem spai （  sp was generated using the binary target variable  a = vi .
　the impact of the added background knowledge was proven by a greater acceptance of the subgroup discovery results by the expert. however still too many subgroups were not interesting for the expert  because too many normal values were included in the results  e.g.  liver-size = normal  or fatty liver = unlikely. this motivated the application of abnormality information to constrain the value space to the set of abnormal values of the attributes. additionally  the expert suggested to group sets of values into disjunctive value sets defined by abnormality groups  e.g.  grouping the values possible and probable for some attributes. furthermore  ordinality information was applied to construct meta values of ordinal attributes like age or liver size.
target variabledef. pop.subgroup descriptionaorta-sclerosis = calcified1pancreas disease={probable;possible}aorta-sclerosis = calcified1pancreas disease={probable;possible}
and ascites = presenttable 1: example: missing value problem
　further investigation showed that missing values play a central role in the discovery process. sometimes the defined population significantly decreased  when adding a selection expression to a subgroup description  compared to the parent subgroup. an example is given in table 1; the defined population is indicated in the second column. in this example  the attribute ascites has many missing values. this problem was solved by adapting the derived attributes to indicate when a missing value corresponds to the value  disease not present . then  the final set of interesting subgroups was obtained.
　figure 1 shows exemplary discovered subgroups concerning the target variable gallstones  that were considered as interesting for clinical practice  lines 1 . all these subgroups were at least significant at the 1 level. the individual subgroups are shown in the rows of the table. subgroup parameters given in the columns are:  subgroup  size  tp  true positives   fp  false positives   pop.  defined population size   rg  relative gain  and the value of the binomial quality function qbt  bin. qf   c.f.  section 1. the domain specialists evaluated the discovered subgroups concerning interestingness for clinical practice: for them  the relative gain was the primary criterion to rank the subgroups in a first step. then  as a combined  helper  measure for subgroup size and gain quality  the value of the binomial quality function qbt was used for post-processing the set of subgroups.
target variable: gallstones#agesexliver sizeaorta sclerosis11mf111ncsizetpfppop.p1prgbin. qf1xxxxxx1111111xxxxxxx1111111xxxxxxx1111111xxxxxx1111111xxxxx1111111xxxxxxx1111111x1111111xx1111111x1111111xxx111111age:	sex:	liver size:	aorta sclerosis:
1 =  1	m = male	1 = smaller than normal	1 = slightly increased	n = not calcified
1 = 1	f = female	1 = normal	1 = moderately increased	c = calcified
1 =  =1 = marginally increased	1 = highly increased
figure 1: examples of discovered subgroups  clinically interesting: lines 1 : e.g.  the first line depicts the subgroup  1 cases  described by age −1 and sex=female and liver size={slightly or moderately or highly increased} and aorta sclerosis=calcified with a target share  gallstones  of 1%  p  compared to 1%  p1  in the general population  with a relative gain of 1%  rg .
　especially interesting for the expert proved the situations  when a specialization of a subgroup significantly improved its quality  #1 vs. #1 . additionally  an important criterion to determine sound subgroups was the comparison of possible value combinations for ordinal and nominal attributes  e.g.  #1 vs. #1 or #1 vs. #1 .
　for clinical practice  the expert preferred small subgroup descriptions if the subgroups were comparable concerning the relative gain measure. this is in line with the heuristic of preferring simpler knowledge for actionability. however  significant improvements in a subgroup specialization countered the increase in the length of the subgroup description  e.g.  #1  #1  #1 vs. #1. furthermore  the baseline qualities of known factors  e.g.  age  gender   c.f.  #1 to #1  were also very important for the domain specialist as a reference for subgroup comparison. in summary  the interpretation and judgment of the subgroup discovery results ultimately depends on the expert: even if a suitable quality function is applied  the expert still needs to semantically interpret the subgroup descriptions for the final assessment of a subgroup.
1 summary and future work
in this paper we presented how exploiting background knowledge can help to improve subgroup discovery results in a knowledge-intensive approach. we described several classes of background knowledge in detail  that can potentially be used in other rule-based learning methods besides subgroup discovery as well. a case study using cases from a realworld application showed that applying background knowledge helped to focus the discovery algorithm on the interesting subspace of subgroup hypotheses  increasing the quality of the discovery results. furthermore  we discussed how applying abstraction knowledge can help to handle the problem of missing values.
　in the future we are planning to consider appropriate quality measures concerning the simplicity of the discovered subgroups. primary work for learning rule bases was presented e.g.  in  atzmueller et al.  1 . we will especially focus on quality measures which are easy to interpret and tunable to the analysis goals.
