
hypertree decomposition has been shown to be the most general csp decomposition method. however  so far the exact methods are not able to find optimal hypertree decompositions of realistic instances. we present a backtracking procedure which  along with isomorphic component detection  results in optimal hypertree decompositions. we also make the procedure generic; variations of which results in two new tractable decompositions: hyperspread and connected hypertree. we show that the hyperspread width is bounded by both the hypertree width and the spread cut width  which solves a recently stated open problem. in our experiments on several realistic instances  our methods find many optimal decompositions  while the previous methods can find at most one.
1 introduction
a csp decomposition method dm is tractable if  for a fixed k  determining whether the dm-width of a csp instance is at most k takes polynomial time and all the csp instances having dm-width at most k can be solved in polynomial time. a method dm1 is more general than an another method dm1 if all the csp instance classes having bounded dm1-width also have bounded dm1-width but not vice-versa. likewise  dm1 is better than dm1 if the dm1-width of any instance is at most its dm1-width  and for an instance its dm1-width is smaller than its dm1-width. among several tractable decomposition methods  freuder  1; dechter  1; gyssens et al.  1; gottlob et al.  1   the hypertree decomposition has been shown to be the most general  gottlob et al.  1 . but no exact procedure for hypertree decomposition has been able to handle instances of realistic sizes. this is mainly due to huge preprocessing in the existing exact methods  gottlob et al.  1; harvey and ghose  1 .
¡¡we first present a backtracking procedure for hypertree decomposition. we identify isomorphic components of a hypergraph  and use it to speed-up the procedure. we generalize the procedure the variations of which results in two new tractable decomposition methods: hyperspread and connected hypertree. finding a tractable decomposition better than hypertree decomposition has been recently stated as an open problem  mat  1 . we show that hyperspread width is bounded by both hypertreewidth and spread cut width  which gives a simple positive answer to the open problem. in the experiments on several instances our hypertree and connected hypertree decomposition methods result in finding optimal decompositions of many instances  while the previous methods can find optimal decompositions of at most one instance. in our experiments with a given time limit  for all the instances we are able to obtain a connected hypertree decomposition of width at least as small as the obtained hypertree decomposition. we finally state as an open problem whether the connected hypertree width of an instance equals the hypertree width.
¡¡the next section lists necessary definitions. the section 1 presents the backtracking procedure and defines isomorphic components. the generic procedure and its variants are presented in the section 1. the section 1 presents the experimental results. the section 1 concludes the paper.
1 definitions
a constraint satisfaction problem instance  csp  is a triple  v  d c   where v is a set of variables  d is a set of domains and c is a set of constraints. a variable vi ¡Ê v can take values in the finite domain di ¡Ê d. a constraint ci ¡Ê c is a pair  si ri   where si   v is the scope of the constraint and ri is a relation over si. the ri restricts the allowed combination of values the variables in si can be assigned. a solution to a csp is an assignment of values to all the variables in the csp  such that the assignment restricted to a scope si belongs to the relation ri. a csp is satisfiable if there is a solution for the csp.
¡¡a constraint hypergraph of a csp  v  d c  is a hypergraph h =  v  e   where the set of nodes in the hypergraph v is the same as the set of variables in the csp. for each  si ri  ¡Ê c  there will be an edge  also called a hyperedge  ei ¡Ê e  such that ei = si  i.e.  e = {si |  si ri  ¡Ê c}. hereafter  just the term hypergraph refers to a constraint hypergraph. for a set of edges k   e  let the term
  i.e.  the union of variables occurring in the edges k. for a set of variables l   v   let the term edgevars  i.e.  all the variables occurring in a set of edges  where each edge in the set contains at least one variable in l.
¡¡a tree decomposition  robertson and seymour  1; dechter  1  of a hypergraph  v  e  is a pair td =  t ¦Ã   where t =  n a  is a tree and ¦Ã is a mapping which for each node n ¡Ê n associates ¦Ã n    v . additionally  a tree decomposition has to satisfy two properties:  1   e ¡Ê e.  n ¡Ê n. e   ¦Ã n   and  1   v ¡Ê v   the nodes {n | n ¡Ê n v ¡Ê ¦Ã n } induces a connectedsubtree in t. a hypertree  gottlob et al.  1  of a hypergraph  v  e  is a triple  t ¦Ö ¦Ë   where t =  n a  is a rooted tree. the ¦Ö and ¦Ë are mappings that associate for each node n ¡Ê n  ¦Ö n    v and ¦Ë n    e. if is a subtree of t  then .
let the term tn denote the subtree rooted at the node n ¡Ê n. let the term nodes t  = n. the width of the hypertree  t ¦Ö ¦Ë  is max {|¦Ë n | | n ¡Ê nodes t }.
¡¡a hypertree decomposition  gottlob et al.  1  of a hypergraph h is a hypertree hd =  t ¦Ö ¦Ë   which has to satisfy the three properties:  1   t ¦Ö  is a tree decomposition of h   1   n ¡Ê nodes t   ¦Ö n    vars ¦Ë n    and  1   n ¡Ê nodes t   ¦Ö tn  ¡É vars ¦Ë n     ¦Ö n . the hypertree width of h  denoted htw h   is the minimum width of all possible hypertree decompositions of h.
¡¡to simplify the presentation  we assume that h is connected. given a set of variables p   v   and two variables m n ¡Ê v   the variables m and n are  p -adjacent if  e ¡Ê e. m n ¡Ê  e p . a set of variables q   v is
 p -connected  if for any two variables m n ¡Ê q  there is a sequence of variables m = l1 l1 ... lr 1 lr = n  such that  for each i ¡Ê  1 r   1   li and li+1 are  p -adjacent. a set of variables q   v is a  p -component  or  p -comp in short   if it is a maximal  p -connected subset of v . let  p components  or  p -comps in short  denote the set containing every  p -component.
¡¡given an integer k and ¦Á   e  ¦Á is a k-edge  if |¦Á| ¡Ü k. let the set k-edges = {¦Á | ¦Á   e |¦Á| ¡Ü k}  i.e  the set containing every k-edge. given a k-edge ¦Á  an ¦Á-comp is a  vars ¦Á  -comp. the size of ¦Á-comps  which contains every ¦Á-comp  is at most |e|  as for every ¦Á-comp edgevars ¦Ácomp  will uniquely contain at least one edge e ¡Ê e. given a set of variables q   v   the sub-hypergraph induced by q is the hypergraph     where
e}. let a pair of the form  ¦Á ¦Á-comp   where ¦Á is a k-edge  be called a k-edge-component.
1 the backtracking procedure
our procedure is shown in figure 1. the main procedure isdecomposable takes the pair   v  e   k  as input. the output is a hypertree decomposition if htw  v  e   ¡Ü k  otherwise the message 'not-k-decomposable'.
¡¡given a k-edge-component  ¦Á ¦Á-comp   we say the pair  ¦Á ¦Á-comp  is k-decomposable iff the sub-hypergraph induced by the nodes in edgevars ¦Á-comp  has a hypertree decomposition hd' of width at most k  such that  if the root node of hd' is r  then edgevars ¦Á-comp    ¦Á-comp   ¦Ö r . essentially  the notion k-decomposable tells us whether the sub-hypergraph can be decomposed into a hd' of width at most k  such that hd' can be used as a block in building a decomposition for the whole hypergraph. hence  the pair    v   is k-decomposable iff the htw  v  e   ¡Ü k. we say that the  ¦Á ¦Á-comp  is k-decomposable by using the k-edge ¦Â if there exists a hd' with ¦Ë r  = ¦Â.
¡¡the procedure addgood is used to add a tuple  ¦Á ¦Ácomp ¦Â ccs  to the set goods  if the pair  ¦Á ¦Á-comp  is kdecomposable by using the k-edge ¦Â. the set ccs in the tuple  denotes the elements of ¦Â-comps contained in ¦Á-comp. similarly  the procedure addnogood is used to add a pair  ¦Á ¦Á-comp  to the set nogoods  if the pair  ¦Á ¦Á-comp  is not k-decomposable. the procedure isgood ¦Á ¦Á-comp  returns true iff a tuple of the form  ¦Á ¦Á-comp ¦Â ccs  exists in the set goods. similarly  the procedure isnogood ¦Á ¦Á-comp  returns true iff the pair  ¦Á ¦Á-comp  exists in the set nogoods.
¡¡the procedure decompose takes a  ¦Á ¦Á-comp  pair as input and returns true iff  ¦Á ¦Á-comp  is k-decomposable. the line 1  of the procedure finds cv  the set of variables through which the ¦Á-comp is connected to the rest of the variables in the hypergraph. the loop that begins at line 1  iterates for every k-edge ¦Â  such that  vars ¦Â  ¡É ¦Á-comp  cv   vars ¦Â  . that is the ¦Â should be such that vars ¦Â  contains at least one variable in ¦Á-comp  and cv is contained in vars ¦Â . the set ccs in line 1  is the set of elements of ¦Âcomps  which are contained in ¦Á-comp and hence necessary for consideration by the decompose procedure.
¡¡the internal loop starting at line 1  of decompose checks whether a  ¦Â cc  pair is k-decomposable. the variable success will be true at the line 1  iff  for each cc ¡Ê ccs  the pair  ¦Â cc  is k-decomposable. a call to decompose ¦Â cc  at line 1  is made iff both the calls to isnogood ¦Â cc  and isgood ¦Â cc  return false. this makes sure that for any  ¦Â ¦Âcomp  pair  the call decompose ¦Â ¦Â-comp  is made at most once. at line 1   if the variable success is set to true  then the tuple  ¦Á ¦Á-comp ¦Â ccs  is added to the set goods and the procedure returns true. otherwise  the loop at line 1  continues with an another k-edge choice for ¦Â. if all choices for ¦Â at line 1  is exhausted without any success  then the procedure adds the  ¦Á ¦Á-comp  pair to the set nogoods at line 1  and then returns false.
¡¡in case the call decompose   v   at line 1  of the procedure isdecomposable returns true  then a hypertreedecomposition  hd  is built and returned. otherwise  a message 'notk-decomposable'  meaning the hypertree width of  v  e  is larger than k  is returned. at line 1  of the procedure a root node r is created and a tuple of the form    v  ¦Â ccs  is obtained from the set goods. the third entry ¦Â in the tuple corresponds to the k-edge used during the first call of the recursive decompose procedure. hence  ¦Ë r  is set to ¦Â. by the definition of hypertree decomposition  for a root node r  ¦Ö r  = vars ¦Ë r  . hence  the ¦Ö r  is set to vars ¦Â . in the lines 1   for each cc ¡Ê ccs  a child node of r is created by the call buildhypertree  ¦Â cc r . the procedure buildhypertree in fact recursively calls itself and extracts  from the set goods  the subtree rooted at a child vertex of r. at line 1   the procedure returns a hypertree decomposition.
theorem 1. isdecomposable h k returns a hypertree decomposition iff htw h  ¡Ü k.
¡¡the proof of the above theorem follows from the fact that  our procedure is essentially a backtracking version of the optk-decomp  gottlob et al.  1  procedure for hypertree de-
set goods =  ; set nogoods =  ; hypertree hd =  t ¦Ë ¦Ö 
decompose  ¦Á ¦Á-comp 
1: cv = vars ¦Á  ¡É edgevars ¦Á-comp 
1:  ¦Â ¡Ê k-edges.  vars ¦Â  ¡É ¦Á-comp
1:	ccs = {cc | cc ¡Ê ¦Â-comps  cc   ¦Á-comp }
1:	success = true
1:	  cc ¡Ê ccs
1:	if  isnogood ¦Â cc   then success = false
1:	else if  isgood ¦Â cc   then continue
1:	else if  decompose ¦Â cc   then continue
1:	else success = false
1:	if  success  then addgood ¦Á ¦Á-comp ¦Â ccs ; return true
1: addnogood ¦Á ¦Á-comp ; return false
isdecomposable   v  e  k 
1: if  decompose   v    then
1: add root node r to t; find    v  ¦Â ccs  ¡Ê goods ¦Ë ¦Â	¦Â
1:
1:	buildhypertree  ¦Â cc r 
1:	return hd
1: else return 'not-k-decomposable'
isgood  t1 t1 
1:    tw tx ty tz  ¡Ê goods
1:	if  t1 t1  =  tw tx  then return true
1: return false
isnogood  t1 t1 
1:    tx ty  ¡Ê nogoods 1:	if  t1 t1  =  tx ty  then return true
1: return false
addgood  t1 t1 t1 t1 
1: goods = goods ¡È { t1 t1 t1 t1 }
addnogood  t1 t1 
1: nogoods = nogoods ¡È { t1 t1 }
buildhypertree  ¦Á ¦Á-comp s 
1: find  ¦Á ¦Á-comp ¦Â ccs  ¡Ê goods
1:	add a node t to t as a child node of s
1: ¦Ë t  = ¦Â; ¦Ö t  =  vars ¦Â  ¡É edgevars ¦Á-comp  
figure 1: the pseudo code of the backtracking procedure for hypertree decomposition.1:   cc ¡Ê ccs 1:	buildhypertree  ¦Â cc t 
¡¡
composition. the opt-k-decomp procedure suffers from a huge pre-processing cost. for a given k  the opt-k-decomp implicitly finds all possible decompositions of width at most k and extracts the optimal one. but our backtracking procedure stops as soon as it discovers a decomposition of width at most k. hence  our procedure will be able to stop quickly when there are several decompositions of width at most k.
theorem 1. the time complexity of isdecomposable h k  is o |e|1k+1 .
proof. the time complexity is dominated by decompose. during a call to decompose  the loop over choices for ¦Â iterates at most o |e|k . the |ccs| is at most |e|. since each k-edge results in at most |e| k-edge-components  the total number of k-edge-components is o |e|k+1 . the cost of each call to isnogood/isgood will take o |e|k+1  time  as the size of goods/nogoods can be at most the number of k-edge-components. we can ignore the cost for calls to addgood/addnogood as their contribution to the complexity is dominated. hence  the cost for each call to decompose is o |e|1k+1 . there can be at most o |e|k+1  calls to decompose  at most once for each k-edge-component. hence  the time complexity of the procedure isdecomposable is o |e|1k+1 .	
¡¡given two k-edge-components  ¦Á comp  and  ¦Á comp'   they are isomorphic if comp = comp'.
theorem 1. given two isomorphic pairs  ¦Á comp  and
 comp'    ¦Á comp  is k-decomposable iff  ¦Á comp'  is kdecomposable.
proof. by definition comp = comp'. hence  the only difference between the calls decompose ¦Á comp  and decompose comp'  are the first parameters:. in decompose the distinction between and is of importanceonly at line 1   where the set cv is calculated. we now show that cv is independent of ¦Á. since  ¦Á comp  is a k-edge-component by definition   e ¡Ê e. e   edgevars comp     e comp    ¦Á. also  comp ¡É vars ¦Á  =  . this implies that  during the call decompose ¦Á comp   the set cv = edgevars comp   comp . therefore  the set cv remains the same during both the calls decompose ¦Á comp  and decompose comp' . hence  the proof.	
¡¡for each set of isomorphic components we need to make at most one call to decompose. hence  by using isomorphism the number of calls to decompose may reduce significantly.
1 variants of hypertree decomposition
the figure 1 presents the pseudo code for a generic decomposition procedure isdecomposablege  based on the hypertree framework. there are two changes in the generic procedure from the earlier procedure in figure 1. first change is that  the generic version is able to detect isomorphism  so that a call to decompose is made at most once for a set of isomorphic components. the second change is in line 1  of the procedure decompose  where the code ¦Â ¡Ê k-edges in the old procedure has been replaced with  ¦Â q¦Â  ¡Ê ¦¸ in the generic version. each element in the set ¦¸ is a pair of the form  ¦Â q¦Â   where ¦Â ¡Ê k-edges and q¦Â   vars ¦Â . in all the places where vars ¦Â  was used in the old procedure  q¦Â is used in the generic procedure. the set ¦¸ defines  for each ¦Â ¡Ê k-edges  the allowed subsets of vars ¦Â  which can be used for decomposition. essentially  by allowing subsets of vars ¦Â  to be considered for obtaining a decomposition we obtain a generic procedure. note  the procedures isgood  addgood  isnogood  and addnogood are not listed in figure 1 as the old versions of them can be naturally modified to work in the generic framework. let the set ¦¸htd = { ¦Á vars ¦Á   | ¦Á ¡Ê k-edges }. we have the following theorem.
theorem 1. when ¦¸ = ¦¸htd  isdecomposablege h k  returns a hypertree decomposition iff htw h  ¡Ü k.
set goods =  ; set nogoods =  ; hypertree d =  t ¦Ë ¦Ö 
decompose  comp isdecomposablege   v  e  k 
1: if  decompose v    then
1:	add root node r to t; find  v  ¦Â q¦Â ccs  ¡Ê goods1: 1: 1: 1: 1:
1:
1:
1:ccs = {cc | cc ¡Ê  q¦Â -comps  cc   comp } success = true
  cc ¡Ê ccs
   if  isnogood cc   then success = false else if  isgood cc   then continue else if  decompose cc   then continue else success = false if  success  then addgood comp ¦Â q¦Â ccs ; return true1:	return d
1: else return 'not-k-decomposable'
buildhypertree  comp s 
1: find  comp ¦Â q¦Â ccs  ¡Ê goods
1:	add a node t to t as a child node of s
1: ¦Ë t  = ¦Â; ¦Ö t  =  q¦Â¡É edgevars comp  
1:   cc ¡Ê ccs
1:	buildhypertree  cc t 1: addnogood comp ; return false1: cv = edgevars comp    comp	¦Ë r	¦Â ¦Ö r	q
1:
1:   ¦Â q¦Â  ¡Ê ¦¸.  q¦Â¡É comp1:	buildhypertree  cc r 
figure 1: the pseudo code of the generic procedure for decomposition in hypertree framework.1 hyperspread decomposition
an unbroken guarded block  ug-block   cohen et al.  1  is a pair  ¦Á q¦Á   where ¦Á   e and q¦Á   vars ¦Á   satisfying two conditions:  1   e1 e1 ¡Ê ¦Á. e1 ¡É e1   q¦Á  and  1  each  q¦Á -comp has non-empty intersection with at most one  vars ¦Á  -comp. the size of an ug-block  ¦Á q¦Á  is |¦Á|.
¡¡for some ¦Á   e and v ¡Ê v   let the label  l¦Á v  = {cc | cc ¡Ê  ¦Á -comps  v ¡Ê edgevars cc }. an ug-block  ¦Á q¦Á  is canonical if  e ¡Ê ¦Á.  v1 v1 ¡Ê e q¦Á. l¦Á v1  = l¦Á v1 . let ¦¸hsd be the set of all the at most k sized canonical ug-blocks of  v  e . note  by the definition of canonical ug-blocks  ¦¸htd   ¦¸hsd. given k and a canonical ug-block  ¦Á q¦Á  with |¦Á| ¡Ü k  let a triple of the form  ¦Á q¦Á  q¦Á comp  be called a k-spread-component. it has been shown in  cohen et al.  1  that  there exists at most  |e|+1 k+1 k-spread-components. the notion of isomorphism can be naturally extended to k-spread-components. given two kspread-components  ¦Á q¦Á comp  and   comp'   they are isomorphic when comp = comp'.
¡¡a spread cut  cohen et al.  1  of a hypergraph h is a hypertree sc =  t ¦Ë ¦Ö   satisfying the two conditions:  1   t ¦Ö  is a tree decomposition of h  and  1   n ¡Ê nodes t    ¦Ë n  ¦Ö n   is a canonical ug-block. the spread cut width of h  denoted scw h   is the minimum width of all possible spread cuts of h.
¡¡a hyperspread decomposition of a hypergraph h is a hypertree hsd =  t ¦Ë ¦Ö   satisfying the two conditions:  1   t ¦Ö  is a tree decomposition of h  and  1   n ¡Ê nodes t .   ¦Á q¦Á  ¡Ê ¦¸hsd. ¦Ë n  = ¦Á. ¦Ö n  = q¦Á ¡É ¦Ö tn . the hyperspread width of h  denoted hsw h   is the minimum width of all possible hyperspread decompositions of h.
due to a variant of isdecomposablege  we have:
theorem 1. when ¦¸ = ¦¸hsd  isdecomposablege h k  returns a hyperspread decomposition iff hsw h  ¡Ü k.
by arguments similar to those of theorem 1  we have:
theorem 1. when ¦¸ = ¦¸hsd  the time complexity of isdecomposablege h k  is o  |e| + 1k+1 .
¡¡given a hyperspread decomposition of a csp  the csp can be solved by the same algorithm for csp solving using hypertree decompositions  gottlob et al.  1 . also  for a fixed k  determining whether hsw of csp is ¡Ü k takes polynomial time. hence  the hyperspread decomposition is tractable.
¡¡we now state that the hyperspread width is bounded by both hypertree width and the spread cut width.
theorem 1. hsw h  ¡Ü htw h  and hsw h  ¡Ü scw h 
proof. the last two conditions in the definition of hypertree decomposition implies that:  n ¡Ê nodes t .   ¦Á q¦Á  ¡Ê ¦¸htd. ¦Ë n  = ¦Á. ¦Ö n  = q¦Á ¡É ¦Ö tn . since for any k 
¦¸htd   ¦¸hsd  each hypertree decomposition is also a hyperspread decomposition. hence  hsw h  ¡Ü htw h .
¡¡the second condition in the definition of spread cut implies that:  n ¡Ê nodes t .   ¦Á q¦Á  ¡Ê ¦¸hsd. ¦Ë n  = ¦Á. ¦Ö n  = q¦Á. therefore  each spread cut is also a hyperspread decomposition. hence  hsw h  ¡Ü scw h . 
¡¡recently in  mat  1   the existence of a tractable decomposition better than hypertree decomposition was stated as an open problem. in  cohen et al.  1   a family of hypergraphs hn  for n = 1 ...  was presented for which the hypertree width of hn is at least 1n  while the spread cut width is at most 1n. note  it is not known whether for any h  scw h  ¡Ü htw h . since for any h  hsw h  ¡Ü htw h  and hsw hn  ¡Ü scw hn    htw hn    hyperspread decomposition gives a simple positive answer to the open problem.
1 connected hypertree decomposition
a connected hypertree decomposition is a hypertree decomposition chtd =  t ¦Ë ¦Ö   satisfying two conditions:  1  for the root node r of t  |¦Ë r | = 1  and  1  if c ¡Ê nodes t  is a non-root node and the parent node of c is p  then  e ¡Ê ¦Ë c .  v ¡Ê ¦Ö c  ¡É ¦Ö p . v ¡Ê e. the second condition states that for any non-root node c with parent node p  each edge e in ¦Ë c  should have at least one variable that is common to both ¦Ö c  and ¦Ö p . the two conditions in the definition results in a significant reduction of the branching choices in the procedure decompose. we show empirical results in the next section to support such reduction. let the connected hypertree width of a hypergraph h  denoted chtw h   be the minimum width of the all possible connected hypertree decompositions of h. by definitions  htw h  ¡Ü chtw h . it is an open problem whether chtw h  = htw h .
let ¦¸chtd cv  = { ¦Á vars ¦Á   | ¦Á ¡Ê k-edges  cv =
 
instanceexact methodsheuristicnamesizearitychtdchtd-noisobe+chtdhtdhtd-noisobe|v | |e|¦Ì  maxtime widthtime  widthtime  widthtime  widthtime  width¦Ìt  ¦Ìw  minw1.1.cp1  1.1  1  1*1  1*1  1*1  1  1.1  1  1fischer1-fair.smt1  1.1  1  1  1  1  1  1  1  1fischer1-fair.smt1  1.1  1  1  1  1  1  1  1  1baobab1.dag1  1.1  1  1  1  1  1  1.1  1  1baobab1.dag1  1.1  1  1*1  1  1*1  1  1.1  1  1complex.cp1  1.1  1  1  1  1  1  1  1  1das1.dag1  1  1  1*1  1*1  1*1  1*1  1.1  1  1isp1.dag1  1.1  1.1  1*1  1*1  1*1  1*1  1*1  1  1isp1.dag1  1.1  1  1*1  1  1*1  1  1.1  1  1large-partial.cp1  1.1  1  1*1  1*1  1*1  1*1  1*1  1  1large1.cp1  1.1  1  1*1  1*1  1*1  1*1  1.1  1  1renault.cp1  1.1  1.1  1*1  1*1  1*1  1*1  1*1  1  1# optimal111n/atable 1: experimental results. the mean  ¦Ì  and the maximum arity of the instances are also listed.where cv   v corresponds to the connection variables in the procedure decompose. as an another variant of the generic decomposition procedure  we state the following theorem.
theorem 1. when ¦¸ = ¦¸chtd cv   a connected hypertree decomposition is returned by isdecomposablege h k  iff chtw h  ¡Ü k.
¡¡unlike the previous two variants of the generic decomposition procedure  when ¦¸ = ¦¸chtd cv   the set ¦¸ is newly defined during each call to decompose based on the connection variables cv.
¡¡since connected hypertree decompositions are subsets of hypertree decompositions  connected hypertree decomposition is tractable.
1 experiments
we have implemented the presented backtracking procedures for both hypertree decomposition and connected hypertree decomposition. we have not implemented the hyperspread decomposition procedure  which does not seem easy to implement. we plan to do it in the future. all of our experiments are done on an intel xeon 1ghz machine  running linux and with 1gb ram. we use 1 instances in our experiments. they are constraint hypergraphs from different sources: five from configuration problems  *.cp   five from fault trees  *.dag   and two from smt instances  *.smt . our tools and instances are available online1.
¡¡in our implementation  for a given ¦¸ and h =  v e   we find an optimal decomposition by a sequence of queries to the procedure isdecomposablege h k . the parameter k will take values in the sequence k1 k1 ... kl 1 kl. in the sequence  k1 = |e|. if the query isdecomposablege h ki  returns a decomposition of width k  then.
if the query isdecomposablege h ki  returns the message 'not-k-decomposable'  then l = i. the optimal width will be kl + 1. we found that the l is often very small due to jumps the sequence could make. the results of our experiments are listed in table 1. all the experiments in the table are done with a time limit of 1 cpu seconds. the legend 'chtd'  'htd'  refers to the experiments with ¦¸ = ¦¸chtd
 ¦¸ = ¦¸htd .	the legend 'chtd-noiso'  'htd-noiso'  refers the 'chtd'  'htd'  procedure without detection of isomorphic components. for each method  we list the best width obtained. in the cases we are able to prove optimality  the entries in the width columns will be of the form k . we also tested the heuristic 'be' in the htdecomp1 tool. the be uses tree decomposition heuristics and set covering heuristics to obtain a heuristicgeneralized hypertree decomposition  ghtd   gottlob et al.  1 . in case of a ghtd  the third condition in the definition of hypertree decomposition may be violated. since be is randomized  we ran experiments using be five times  and list in the table the mean time  ¦Ìt   the mean width  ¦Ìw  and the best width  minw . we also did experiments on a hybrid be+chtd  in which five runs of be will be used to first obtain five ghtds. if the best width of the ghtds so obtained is kbe  then the chtd procedure will be invoked with k1 = kbe. note  the best width decomposition found by the hybrid be+chtd may be a ghtd  whose width can be smaller than htw. although the htdecomp tool has heuristic choices otherthan be  we choose be since we think it is the best choice. the be+chtd combination can be naturally extended with any initialization heuristic. the last row  #optimal of the table lists the number of proven optimal width decompositions obtained by each method. note  to prove optimality  the query corresponding to kl needs to return 'not-k-decomposable' within the time limit.
¡¡all the exact methods listed in the table are our contributions. the experiments using the implementations1 of the previous exact methods opt-k-decomp  and an improvement overopt-k-decomp red-k-decomp harvey and ghose  1   either exceeded time limit or aborted in all cases except renault.cp  in which red-k-decomp took 1 seconds to find an optimal decomposition. in fact  both the experiments using the opt-k-decomp and red-k-decomp tools consisted of only one query to the tool. for an instance h  if the 'chtd' finds a decomposition of width k in 1 seconds  then the opt-k-decomp and red-k-decomp are just asked to find a decomposition of width k. hence  the experiments are done in a favorable setting to the previous methods.
from the table  we can observe that the chtd procedure

figure 1: width vs. cpu-time  y axis in logscale . the empirical complexity peaks at k    1.

figure 1: the effect of detecting isomorphism and chtd vs. htd in isp1 instance  time limit 1 seconds .
gives more optimal decompositions than others. in none of the instances the htd could find a better decomposition than that of chtd. in three instances the be finds ghtds of width smaller than those by the exact methods. for use in practice the hybrid be+chtd seems the best choice  as it results in best decomposition in all the cases.
¡¡in figure 1  we plot the time taken for the queries isdecomposablege h k  with ¦¸ = ¦¸chtd  k ¡Ê {1 ... 1} and h being one among the eight instances for which chtd succeeds in obtaining optimal decompositions within 1 seconds. we can observe that  for each instance h  the cost of queries until k   1  where k  is chtw h   increases exponentially. the cost suddenly decreases at k  and continues to decrease exponentially.
¡¡in figure 1  we plot the results of queries on the four different exact procedures for the instance isp1  with time limit 1 seconds. the plot shows a huge benefit of identifying isomorphism. the plot also shows an exponential difference between the runtime of chtd and htd which is due to the branching restrictions in chtd. the htd and htd-noiso timed out for some queries.
1 conclusion
we have presented a backtrackingprocedurefor hypertreedecomposition and defined isomorphism to speed-up the procedure. we generalized the procedure  the variants of which results in two new tractable decompositions: hyperspread and connected hypertree. we have shown that hyperspread width is bounded by both hypertree width and spread cut width  which solves a recently stated open problem. the experiments using our methods are able to find optimal decompositions of several instances.
¡¡avenuesfor futurework include: implementationof hyperspread decomposition  determining chtw = htw   identifying other tractable variants  and comparison with exact methods for tree decomposition like  gogate and dechter  1 .
