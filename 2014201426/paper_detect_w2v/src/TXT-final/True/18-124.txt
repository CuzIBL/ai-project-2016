p a n e l : 	e x p e r t s y s t e m s : h o w f a r c a n t h e y g o   
terry winograd  randall davis  stuart dreyfus  brian smith 
   
   we arc in the midst of a great wave of enthusiasm about the potential for expert systems in every area of human life and work. there is no agreement  however  as to just how much they can do  and where they will run into fundamental limits. the intent of this panel is to present and discuss some basic questions as to what expert systems can really be expected to do: 
what is the nature of the problem domains in which expert systems are likely to succeed and those in which they will not  are there domains in which their use might be dangerous  
   how will their performance compare with that of human experts in the domain  are there different facets of expertise that are not amenable to programming  how can human and machine expertise best be combined  
   to what extent can we count on rule-based systems for 'flexibility' in dealing with unexpected situations  how reliable will such systems be in cases where the programmers  or knowledge engineers  did not anticipate significant possibilities  
   how can a 'knowledge base* be subjected to standards of accountability  who is responsible for what an expert system contains and what it does  
expert s y s t e m s : 
what to do until the t h e o r y arrives 
randall davis 
mit 
in reading a newspaper recently i was struck by the profusion of expert advice available. there were three different expert opinions on the future course of the economy  several compelling  and contradictory  opinions about the likely course of events in the mideast and a 
number of suggestions about avoiding heart disease  as well as claims about long term weather patterns  advice from ms. manners on behavior and guidelines from a 
therapist on drinking and sex. 
all of which made me begin to wonder: 
experts: how far can they go  
   we are in the midst of a great wave of enthusiasm about the potential for experts in every area of human life and work. there is no agreement  however  as to just how much they can do  and where they will run into 
fundamental limits: 
   what is the nature of the problem domains in which experts are likely to succeed and those in which they will not  are there domains in which their use might be dangerous  
   to what extent can we count on carbon-based systems for 'flexibility' in dealing with unexpected situations  how reliable will such systems be in cases where their teachers did not anticipate significant 
possibilities  
   how can a person's knowledge be subjected to standards of accountability  who is responsible for what an expert contains and what that person does  
   hardly an original satire  but it does serve several purposes. first  it demonstrates that the questions are neither unfamiliar nor inherently mysterious. the answers for people may not be well established  but we do know something of how to proceed and we do believe there is no magic here: some form of knowledge accounts for an expert's competence. the nature and source of it may be far from understood  but that doesn't make the question unanswerable. 
   next  it sets the argument out on what i believe to be an important direction: the questions we are asking are first about knowledge and only then about technology. that is  the first question should not be what can expert systems do  but rather what do we know  only then we can address the technology issue and ask and how easily can wc encode that knowledge  both matter but the order is important 
   finally  the comparison is valid and provides an interesting way to proceed. asking the same questions about people provides a useful  non-thrcatening way of examining the topics. our answers may differ for people and programs  but even those disparities will prove interesting. we explore peoples understanding of a subject with a test that examines only a limited sample of their knowledge  and then extrapolate  saying that people who pass 'understand' the material  meaning by that something more than that they can do exactly the problems chosen for the exam. if a program passed the same exam  would we be willing to do the same extrapolation  if not  why not  jf we can determine what it is that makes us hesitate in the case of the program  we have the beginnings of an intriguing research agenda. 
   in developing these themes i will argue that there are two attributes of expert systems  and much of al  that are central to this discussion: 
it is a weak technology 
it is a technology for dealing with incompletely understood ideas. 
   i will suggest that the first of these is a temporary vice that will be remedied in time  though not soon  and that the second is a permanent virtue. 
   both of these have interesting implications for the use of expert systems  and indeed much of al . perhaps the most important implication is that most traditional rule-based expert systems will never have all the knowledge they need  and as a consequence they are guaranteed to fail occasionally  though perhaps infrequently  during all of their operational lives. 
   i will suggest ways of proceeding that take these issues into account  allowing us to employ the technology while reducing the potential difficulties that can arise. 
the nature of expertise 
stuart e dreyfus 
university of california  berkeley 
   all ai work with the exception of a few 'connectionist' theories assumes that knowledge must be represented in the mind as symbolic descriptions. expert-system builders further assume that the expert possesses a particular kind of symbolic description: a knowledge base of facts  beliefs and 'if-then' rules that allow the drawing of inferences. 
   1 will argue that expert-system builders fail to recognize the real character of expert human understanding. expertise is acquired in a five-stage process. the beginner applies rules to context-free features as would an expert system deprived of situational knowledge appropriate to the particular case. the advanced beginner learns from experience to recognize aspects of a situation without requiring a definition of them in terms of context-free features. 
t. winograd et al. 1 
   aspects arc recognized after seeing several examples  apparently because of their similarity to already experienced prototypical cases. an interactive expert system could use aspects if they were identified for it by a human user. at the next stage  the competent performer organizes behavior by selecting plans  goals  or perspectives which determine hierarchically what facts to consider and what rules to apply. expert systems can do likewise and  if they accept human situational assessments  could appropriately be called 'competent systems.' this  however  is the best they can do. the fourth stage  proficiency  is achieved when the performer no longer uses his knowledge to select a perspective or goal  but simply recognizes the appropriate one based on prior experience in similar situations in which goals were chosen and events either confirmed the wisdom of the choice or showed it to be mistaken. as with the recognition of situational aspects by the advanced beginner  the involved  intuitive recognition of similarity of whole situations is apparently not produced by rules operating on features but seems to be effortless and holistic. while the proficient performer still analytically figures out what to do once the situation is intuitively understood  at the highest level of skill the expert has experienced so many situations that he associates with each prototypical situation in his memory the decision  action or strategy that he has found to work. he reasons out neither strategy nor action. intuitively responding to situational patterns as experience has shown appropriate  his skill depends neither on problem solving nor planning. expert systems can neither recognize situations holistically without analysis into components nor know what to do without applying rules to decomposed knowledge  so they can be neither proficient nor expert. 
   if time permits  an expert will deliberate about his intuitive understanding. to fine-tune his responses  he will attempt to take account of subtle differences between his current situation and similar prior ones  he will ask himself whether there might be another quite different way of intuitively viewing his circumstance  and he will consider whether he has had enough experience in the particular kind of situation to trust his intuition. but he will rarely regress to competent detached problem solving. 
   while 'competent systems' have their useful place  there is no reason to expect them to perform as well as experts who have passed beyond the use of facts  beliefs  and rules of inference and who rely on memories of thousands of concrete experiences and what has worked in each. an examination of the performance of various expert systems supports the above analysis. in domains where human beings pass from reasoning to recognition as they become experts  expert systems  even when experts participate in their development  never perform as well as experts. 
   
1 	t.winogradetal. 
models in expert s y s t e m s 
brian smith 
xerox parc 
	all expert systems are based on models. 	the 
'knowledge' embodied in expert systems  in particular  is usually encoded in a set of 'rules' that describe the problem and specify the behaviour that the system should manifest. these rules are always formulated with respect to a model of the underlying domain. this model must be determined in advance by the programmer  who may in 
turn have derived it from an analysis of the experts' performance on which the system is based. 
   indeed  one of the prime tasks in building an expert system is to develop an appropriate model. there are various ways to do this: by analysing the desired behaviour  by building on underlying scientific theories  or by codifying the models apparently used by expert human practitioners. what phenomena are dealt with  what phenomena are ignored  and what patterns or regularities connect the phenomena that are dealt with -- all these decisions are made at the level of the model. 
   for example  a medical expert system designed to administer drugs might model drug absorption in terms of a scalar quantity proportional to the square of a patient's height  or proportional to the weight  neither model  of course  would be expected to be entirely accurate . an expert system for the office might model a secretary as a customer  producer  and processor of information  with a complex internal state. a defense warning system might model incoming missiles as point masses on parabolic flight paths  and model the atmosphere as a linear retarding force. and so on and so forth: the use of models permeates formal systems of all sorts. 
   when expert systems are actually deployed  however  they interact with the world itself  not with models. for example  when drugs are actually administered  or when offices are actually equipped with expert systems intended to work alongside people  we have full  thick situations to deal with  of at least potentially arbitrary complexity. furthermore  the success of expert systems ultimately depends on their ability to deal with these rich  embedded situations. their success  in other words  isn't exhausted by their ability to deal appropriately with the model used in their construction  or encoded in their knowledge bases. 
   in fact the only ultimate point of the models in expert systems is to help them succeed in the 'real world'. rca  for example  is primarily interested in whether their satellites will actually get into orbit and stay there; they have only a derivative interest in whether the programs guiding them are proved correct with respect to a particular orbital model. 
   it is clear  therefore  that in order to analyse expert systems we need to understand the appropriateness of the models on which they are based. analysing expert systems  in other words  comes in two parts: understanding the behaviour of a system in terms of the model on which it is based  and understanding the relationship between that model and the embedding world. at the present state of the art  we have a variety of techniques that enable us to study the former relationship  between system and model: formal semantics  model theory  hence its name   program verification. we have virtually no techniques  on the other hand  with which to study the latter relationship  between model and world. we are largely unable  therefore  to assess the appropriateness of models  or to predict when models will fail. all that we do when we prove a program 'correct' is to prove that it will behave as specified with respect to a model. it would be something quite else -something we don't know how to do - to prove that a system will in fact do the 'correct' thing once embedded into a real situation. 
   two conclusions. first  we should develop and use expert systems only in those domains where we have confidence in the accuracy and appropriateness of our models. second  we should develop a 'theory of models' with which to understand better how models work  and how they make sense of the infinite complexities of the worlds they represent. although such a theory may strain at the edges of what can be formalized  or even pass beyond strict formal limits  we can still develop rigorous tools  and use clear-headed thinking  in analysing this important relationship. 
the trivialization of expertise 
terry winograd 
stanford university 
   professor moto-oka of the japanese fifth generation project  predicts that:  fifth generation computers are expected to function extremely effectively in all fields of society. ...totally new applied fields will be developed  social 
productivity will be increased and distortions in values will be eliminated   feigenbaum and mccorduck  proclaim that:  we are now at the dawn of a new computer revolution...  leading  to computers that reason and inform ...the engine that will produce the new wealth of nations.... perhaps equally important to all the economic advantages the fifth generation promises is that intangible thing called quality of life. a society where knowledge is quickly and easily available to anybody who wants it will... be an alluring 
place.  
   we might dismiss these statements as merely naive self-serving propaganda  but in doing so would we fail to 
   
recognize the background in which they could be made sincerely and taken seriously by intelligent and educated readers. the computer is a powerful embodiment of a 'rationalistic' tradition that equates certain limited modes of rational description and inference with the full scope of how people think and what they do with language. this tradition is both demonstrated and further promoted by inflated claims for the potential benefits of 'expert 
systems.' 
   rationalistic understanding has been extremely powerful in the creation and expansion of the physical sciences and in increasing our mastery over the physical world. at the same time  its power in dealing with these domains of reality has blinded us to its weakness in dealing with those more related to human life and society. the rationalistic orientation often promotes a wrong understanding of what constitutes a 'problem' in a human domain  and what computers can do to 'solve problems.' the failure of the rationalistic approach has led to a crisis in the practical areas where it has been applied seriously. the recognition of this crisis has emerged in the past few years in works on management theory  military systems  medicine  energy policy  and many other fields. 
   the problem is illustrated by the illusion promoted by the label 'expert system.' a human 'expert' is someone whose depth of understanding serves not only to solve specific well-formulated problems  but also to put them into a larger context. we distinguish between experts and idiot savants. what  in contrast  do computer systems do  
   expert systems are built on the basis of a relatively small  precisely defined set of object types and properties  together with a  possibly large and disorganized  collection of rules relating them. in pre-selecting the relevant elements out of which to build rules  one must cut out the role of context and background  which are at the heart of al's theoretical difficulties . this process by its very nature creates blindness - a limit is set by the way the world has been articulated. there is always the potential for breakdowns that call for moving beyond this limit -for returning to the context and reformulating the problem. 
   one might argue justifiably that this blindness is a problem for people as well. but  with the exception of idiot savants   people are not programmed for a particular task. a normally intelligent person can always step back and recontextualize. expert systems  even those with 'meta-rules' do not have this openness. further  the blindness inherent in representation leads to difficulty in understanding the range and limitations of a particular program. a human expert can enter into a dialog about his or her own range of knowledge and limitations  moving outside the putative domain and using ordinary language and ordinary common sense. failures of al programs will in part reflect the inability of people to understand what 
	t.winogradetal. 	1 
the program is actually doing  as opposed to what it might appear to be doing if the metaphor of 'thinking' is accepted. 
   although the assumptions of the rationalistic orientation may seem self-evident  to those within our modern western society   they are indeed only assumptions and can be challenged  see  for a more comprehensive discussion of this and the other issues raised in this paper . instead of treating 'data* as the objective representation of reality  we can recognize symbols  on paper  or in a computer  as a medium for language  which is based on human commitment and is always relative to an unarticulated shared background. instead of trying to get the machine to have 'understanding' through a collection of 'rules ' we can recognize that its manipulation of symbols is grounded in the background and interpretation of people who interact through it. we can identify and articulate 'systematic domains' of symbolic manipulation for which appropriate rules can be generated  and we can integrate these into a broader appreciation of human knowledge and expertise. 
