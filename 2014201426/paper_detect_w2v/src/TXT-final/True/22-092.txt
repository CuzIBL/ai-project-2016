 
potentially  the advantages of marker-passing over local connectionist techniques for associative inference are  1  the ability to differentiate variable bindings  and  1  reduction in the search space and/or number of processing elements. however  the latter advantage has mostly been realized at the expense of accuracy and predictability. in this paper we consider a class of associative inference to which marker passing is often applied  variously called abductive inference  schema selection  or pattern completion. analysis of marker semantics in a standard semantic net representation leads to a proposal for more strictly regulated marker propagation. an implementation strategy employing an augmented relaxation network is outlined. 
1 	introduction 
both marker-passing and local connectionist1 models have been applied to a class of inference we call recognition. the essence of the task is to find a construal for some set of input evidence  by retrieving enough additional structure from the knowledge base to  fill in the gaps  and thereby infer an explanation for the input. the construal should be the most plausible  coherent explanation that can be found within a relatively instantaneous unit of time. a natural language processing example is interpreting gooseneck lamp as a lamp whose shaft is a gooseneck  and pool table lamp as a lamp hanging over a pool table  in each case by finding the schemata that best relate the individual concepts. the task of interpreting partially obscured visual 
   *this research was sponsored in part by the defense advanced research projects agency  dod   monitored by the space and naval warfare systems command under contract 
n1-c-1  the office of naval research under grant n1-c-1  and the sloan foundation under grant 1-1. 
     1  in local connectionist models  each node represents a concept  whereas in distributed models  concepts are represented by a pattern of activation over multiple nodes  hinton et al. 1 . we do not discuss here the advantages and disadvantages that marker-passing and local connectionist models share by virtue of employing local representations. 
1 	cognitive models 
patterns has also been cast as a problem of selecting schemata that best account for the input evidence  mcclelland and rumelhart 1 . various authors view the same or similar tasks as pattern completion  abductive inference to explain the occurrence of particular combinations of concepts  schema selection and composition  concretion  wilensky et al. 1   or classification-style realization  mark 1  schmolze and lipkis 1 . 
　with marker-passing models  input is given by simultaneously placing origin markers on several concepts in a semantic network. the system then propagates markers outward from the concepts of origin  effectively doing a parallel intersection search for relational paths between the concepts. with local connectionist models  input is given by raising the activation of several nodes  causing activation to spread to neighboring nodes and eventually highlighting the relational paths. the primary difference is that connectionist models propagate only numeric activation  rather than symbolic information.1 
　no clear winner has emerged between marker-passing and connectionist models. although local connectionist models can technically be regarded as numeric marker passing  researchers have exploited the connectionist restriction by analyzing activation propagation more carefully than marker propagation  giving connectionist systems more precise search characteristics. on the other hand  symbolic markers retain the advantage of handling variable bindings  that is  the binding of general concepts and roles to particular occurrences. binding is a serious problem in connectionist systems  since currentapproaches require too large a network to be practical. 
　in this paper  we examine another potential advantage of marker passing  which is reduction in the search space and/or number of processing elements  by restricting the search to localized areas of the network. marker-passing models have not yet realized this advantage; those which do restrict marker propagation rely on arbitrary assumptions that lead to inaccurate search. this paper analyzes how marker propagation should be regulated so as to reduce search in a motivated fashion. the proposal  like several other recent proposals  is a hybrid model that attempts to synthesize advantageous aspects of marker-
1
passing and connectionist techniques. 	1 	sensitivity to notational variants 　　one aspect of marker passing that has no parallel in connectionist models is that it is often used as a heuristic for generating possible inferences  with an evaluation stage that selects the best ones. our analysis excludes evaluation stages. 1 	issues 
1 	m a r k e r propagation and resource limits 
the main issue this paper addresses is how to regulate marker propagation to make computation feasible. for sequential implementations  marker passing is a theory of search  and the goal is to reduce the search space. for parallel implementations  the goal is to reduce the number of processing elements.  in this paper we use  propagation  to mean creating a new marker on a neighboring concept  as opposed to moving the same marker from concept to concept. markers created by propagation are non-origin markers.  
　existing models do not limit propagation in a satisfactory way. the reason is that most marker-passing approaches depend on an  over-propagation  strategy to ensure finding the desired concepts or paths; i.e.  markers are propagated to relatively large distances in all directions  so that the chance of missing a desired path is small.  because extensive propagation tends to find too many remote connections  special filters are used to eliminate spurious paths  based on heuristic evaluation.  the problem is that it is not clear how much over-propagation is sufficient  and so either the search is susceptible to arbitrary failure  or it makes excessive resource demands. for example  some systems restrict propagation by presetting the number of links a marker can be propagated  e.g.  hirst 1   but because number of links does not reflect semantic distance in a welldefined way  no preset limit guarantees the desired path can always be found within that number of links. more sophisticated techniques employ numeric activations on markers. the simplest such method is to assign lower activation for markers that are farther from the point of origin  e.g.  norvig 1   using different decrements for each link type  and inhibiting propagation below a threshold. another method  used by hendler   ensures that a more constant number of nodes is searched by making the propagated activation inversely proportional to branching factor. however  the search regions are still determined using number of links and branching factor as a rough approximation of semantic distance. 
　several ways of managing over-propagation schemes have been proposed. charniak  allows activation to decay exponentially over time  to remove old markers. anti-promiscuity rules  charniak 1b  do not permit propagation in the case of concepts with branching factor above some threshold  with the rationale that such concepts are too general to provide much evidence anyway. other systems assume that resource limitations can be overcome with massive parallelism  and perform exhaustive marker propagation assuming one processor for every concept  e.g.  fahlman 1   like in local connectionist models. this should be a last resort  however  as the number of concepts is quite large for real domains. finally  alshawi  suggests an indexing scheme that keeps track of  clusters  of markers to improve search times for large numbers of markers; again  however  no effort is made to reduce the number of markers. 
semantic nets are subject to notational variation  because the same propositional information can be represented in many ways  e.g.  intermediate abstraction levels can be introduced arbitrarily . the effect of notational variants is to alter the network's indexing. however  search should not be affected arbitrarily by changes in indexing. in a sense  connectionist and propositional models represent extremes in sensitivity to network structure  and semantic nets should fall somewhere in between. connectionist models rely entirely upon network structure to direct search. marker-passing search is also guided by network structure  but the structure should be regarded as providing heuristic rather than conclusive indexing. like propositional models  this frees the investigator from the connectionist requirement that concepts be defined by a comprehensive set of indexes to related concepts  by providing a language for abstract concept definitions  with a uniform semantics for notational variants. the extra degree of freedom must be accompanied by a search strategy that minimizes sensitivity to the notational variants. as far as we know  little if any work has addressed this issue  except by performing exhaustive search. 
1 	usage of activation 
some models employ numeric activation levels on markers. there are two kinds of usage: controlling propagation  as in ′1 above   and measuring belief. the latter usage equates activation with certainty. alshawi  uses a set of  context factors  that influence activation in different ways  in effect giving functions for combining evidence sources  for language interpretation . charniak  has a weak form of belief  by computing a  path strength  from the activations of markers on a path  such that the inference mechanism only considers paths with strengths of the highest order of magnitude. 
　while both usages seem appropriate at the intuitive level  it is not feasible to empirically verify whether particular methods work for large conceptual domains  without a complete theory of acquisition. neither do the methods of computing activation appear to be based on probabilistic models that would provide better motivation. the distinction between the two usages is sometimes blurred. moreover  belief measures tend not to be well-defined  and several authors have pointed out the need to formalize such measures  cheeseman 1  pearl 1 . charniak  also suggests that prior probabilities  not activation  should be used to define belief measures. 
1 	formal definitions 
to reduce arbitrary propagation  what marker propagation represents must be defined more precisely than in existing models. our analysis proceeds as follows: first  what a marker represents is defined  followed by what propagation and intersection represent. the next section examines desirable propagation characteristics. finally  an implementation strategy is discussed. 
the approach differs from path-based formalizations  
	wu 	1 
which characterize the semantics of paths rather than markers  e.g.  charniajk 1  norvig 1 . path semantics assume a path has already been found  and do not help constrain propagation. 
　to maximize the scope of our analysis  we assume a fairly standard semantic net: a simplified kl-one style net with conceptual is-a and subpart hierarchies used as a term-defining language.1 the representation is compatible with or translatable into most existing models. a partial semantics is given in appendix a. 
1 	caveat 
to analyze propagation  we formalize concepts as predicates that apply to occurrences  rather than predicates that apply to individuals. concepts occur when they help construe input evidence. for example  x in lightbulb x  represents an occurrence of the generic light bulb concept  and y in light-bulb-1{y  represents an occurrence of an individual light bulb concept.1 the reason is that we are interested in determining when concepts are worth searching  i.e.  likely to help construe the input. thus  we prefer a uniform notation for describing occurrences of concepts  regardless of whether they are generic or individual since either type may participate in the construal. if instead  we allowed concepts to predicate individuals  as in light-bulb light-bulb-l   we would need the explicit  meta-  predicates 
generic-occurrtnce{x light-bulb   	and indiv-occurrence y light-bulb-j . 
1 	markers 
markers represent hypotheses being considered by the interpreter or inference mechanism. this is true in any marker-passing model  regardless of whether it is explicitly noted. a hypothesis has at least two components  which may be implicit or explicit : a proposition  and an estimate of the chance of intersection. many models also include a belief measure. 
   the first component is a proposition about the occurrence of a concept. for example  a marker on the gooseneck concept in figure 1 hypothesizes that gooseneck io . for concepts with conceptual subparts   schemata    an occurrence of the concept implies occurrence of its subparts; thus  a marker on lamp hypothesizes 

　the second part of a marker's hypothesis is an estimate of the chance that the marker lies on a propagation path that will intersect another path.  thus  part of the hypothesis is implicitly represented by the location of the marker.  in many marker-passing implementations  the estimate is implicitly binary: the interpreter believes that intersection is likely or unlikely  and accordingly places or does not place a marker  e.g.  fahlman 
*i.e.  is-a and subpart relations carry no assertional force. 
1
　　thus  we have at least a tri-part ontological distinction between generics  individuals  and occurrences. this is the sort of distinction where connectionist models are hampered by the aforementioned variable binding problem. 
1 	cognitive models 

1  hirst 1  norvig 1 . to facilitate analyzing propagation  we shall allow estimates to be real numbers between zero and one  to denote degree of belief that intersection will occur. deriving estimates is discussed in ′1. 
1 	propagation 
propagating a marker represents generating a hypothesis. the new hypothesis depends upon the source marker's hypothesis  and the semantics of the link propagated over. transformation functions are given by example  for the classes of links in our model: 
　downward is-a: propagating down an is-a link specializes the hypothesis. for example  propagating a marker from lamp to gooseneck-lamp transforms h1 into 

we write h1  -  h1 to indicate the propagation path  which is important because the variables in the two hypotheses are not independent. the dependency arises from predicating the same concept occurrences; i.e.  h1 hypothesizes that the occurrence in h1 of the lamp concept is specifically an occurrence of the gooseneck lamp concept  so h1 entails h1. because propagation is against the direction of implication  charniak  calls this an abductive assumption. 
   upward is-a: propagating up an is-a link abstracts the hypothesis. the transformation is the reverse of downward transformation  and the same dependency holds. 
　downward subpart: propagating across a conceptual subpart link from part to whole also specializes the hypothesis. for example  propagating a marker from lightbulb to lamp transforms 
i 
into h1 above. again the dependent variables mean that h1 implies ho. thus  h1 is also an abductive assumption; this is why we call propagation from part to whole  downward . 
   upward subpart: abstracts the hypothesis  with the same dependency. 
　for semantic nets with associative relations  i.e.  relations between concepts that are not conceptual partwholes  propagation involves similar transformation of 
1 henceforth  the existential will be left out. hypotheses. however  the dependency between the hypotheses cannot be expressed clearly. for this reason  we treat an associative relation between two concepts as an abbreviation for a third concept that acts like a  frame  with the two concepts as subparts.1 the propagation rules above then hold. 
1 	intersection 
an intersection represents a meta-hypothesis about performing unification. intersection occurs when two markers propagated from different origins are placed on the same concept. for example  suppose the path ho  -  h1-   h1 intersects at gooseneck-lamp with another path h1 -  h1: 

the intersection suggests unifying i1 = i 1   i1 = i1  etc. unification  if performed  represents collapsing two occurrences of a concept. 
1 	desirable propagation characteristics 
having derived the above definitions from the semantics of the representation  we would like to optimize propagation. we make the assumption that the interpreter has no information about the connectivity of the semantic net prior to searching because  1  it should be as insensitive as possible to notational variants  and  1  any acquisition strategy for concept formation dynamically changes a semantic net's connectivity. given this constraint  the only information that can be utilized to guide propagation is the information derivable from knowledge stored at the concept nodes where markers already are. consequently  propagation for each origin marker must be optimized independently of other origin markers  until intersection . 
1 	deductive propagation 
deductive  upward  propagation cannot be restricted. when an origin or non-origin marker is created  upward propagation to all its ancestors in the is-a and subpart hierarchies must follow immediately. the reason is that the occurence of a concept also implies the occurence of all concepts standing for more primitive feature/role combinations  appendix a . intersections through any of these ancestral levels must be equally detectable; in the absence of connectivity information  all ancestors must be simultaneously marked. immediate complete upward propagation is also employed by martin and riesbeck . 
　deductive propagation is not as expensive as it may appear  since it applies only to term-defining is-a and subpart relations. searching assertional is-a and subpart relations can be treated as a special case of abductive propagation.1 
1
an example is the assertional is-a in appendix a. 
1
minimizing the deductive is-a and subpart closures is 
1 	u t i l i t y maximization for abductive propagation 
to regulate abductive  downward  propagation  our approach is to ensure that propagation occurs in the order that  given the information possessed by the interpreter at any point in time  the next propagation maximizes the chance of intersection. under the unknown-connectivity assumption  the best estimate that can be made for the likelihood of intersection involving a given marker is proportional to the posterior probability of the marker's proposition. the reason is as follows: for any single origin marker  the interpreter does not know which links connect the concept to more nodes  by the connectivity assumption. using the maximum entropy assumption  we assume an equal distribution of nodes for all links. given this  intersection chances are maximized by choosing the propagation that creates the marker with the most probable proposition  given the input evidence. 
　this does not guarantee maximizing the objective probability of finding an intersection  i.e.  the probability that is defined as the frequency of finding intersections relative to the frequency of propagations  anywhere in the net  and involving any origin marker. maximizing objective probability is not possible when there is missing information  as with the connectivity assumption. the approach does however maximize subjective probability under the connectivity assumption  i.e.  the probability that is computed by assigning uniform distributions where unknown  following maximum entropy.1 
1 	marker probabilities 
the  probability  of a marker's proposition really refers to the posterior probability given all the input evidence. when an origin marker with proposition ho is created in response to an input  its posterior probability p ho  reflects the degree of confirmation provided by the input evidence co.  with reliable evidence indicators  p h1  will essentially be 1.  
　for the abductive case  where a marker with proposition h1 derives from origin ho such that h1 entails ho   the posterior probability is 

　posterior probabilities for the deductive case require explicit normalization factors.1 
1 	necessity of frequencies 
to compute the conditional probability term  the frequency of occurrence for each concept must be known. assuming that / cn i   is the frequency of occurrence of the concept that the marker hi is on  

requiring frequency information is equivalent to requiring weighted is-a or subpart links  because it is the rel-
an efficiency argument for distinguishing terminological and assertional uses. see the semantics of assertional is-a in appendix a. 
　　1  discussions of objective vs. subjective probabilities can be found in walpole and myers  and cheeseman . 
1
　　pearl  discusses normalization in simple taxonomic belief hierarchies. 
	wu 	1 
ative frequency ratios that must be derivable. the same information could thus be stored as ratios on links between concepts. 
　frequencies are the only assertional knowledge in our representation  i.e.  they assert how often concepts occur in dealing with the external world  everything else up to this point is used for defining terms . theoretically  frequencies should be acquired by counting whenever a concept occurs in a construal. 
1 	insensitivity to notational variants 
deductive propagation is insensitive to intermediate levels of abstraction since complete upward propagation occurs at once. for abductive propagation  sensitivity to notational variants is minimized by tying the order of propagation to the frequency of concept occurrence  rather than number of links . this ensures the same order of propagation for notational variants  except that extra intermediate levels may be inserted. 
1 	effect of intersection 
if an intersection occurs and results in unification  then the two colliding markers are merged  and the posterior probabilities of all hypotheses involving the unified concept occurrences must be revised  by taking the combined input evidence from both origins as support for the hypotheses. prior to intersection  hypotheses derived from the two origins are treated as being independent; however  when the variables in the hypotheses are unified  the hypotheses become dependent. that is  given input evidence e1 and e1 for origins fto and ft   p h1  = p hi eo e1  should be computed for each affected hypothesis hi  because it is no longer assumed that p{hi eo e1  = p hi eo . propagation proceeds from the merged marker as before. 
1 	conflating utility and belief 
if a marker's posterior probability is also used as a belief measure-a reasonable first approximation-then the two usages of activation can be conflated in one numeric measure. roughly speaking  the inferences that should be made are the subset of hypotheses after some period of propagation that end up with the highest posterior probabilities  say  above a threshold of 1. no evaluation stage is required  as a result of constraining propagation to discover the most probable concepts first. 
　things become more complicated upon closer analysis. some of the issues are:  1  when should the search cease   1  how can posterior probabilities be efficiently normalized as evidence accumulates   1  how can search be biased to  commit   i.e.  to  over-estimate  the more likely prior probabilities  and  under-estimate  less likely ones  as a default effect  while we have no conclusive answer to these questions  a strategy we are pursuing is outlined below. 
1 	implementation strategy 
if the last three points are not considered  then a sequential implementation of most-probable-first search is straightforward. however  because of those points  and in order to exploit parallelism  an extension to the model 
1 	cognitive models 
is proposed. there are two obvious ways to parallelize marker passing: processor-per-concept and processorper-marker. having discussed how to localize the regions searched  we adopt the processor-per-marker approach  to reduce processor requirements.  this is equivalent to cost-per-marker under sequential simulation.  furthermore  we assume that markers propagate autonomously at variable speeds  and thereby implement most-probable-first search. 
　the first step is to ensure that the basic formulation is compatible with the analysis above. to do this  we use an imaginary model  where for each origin marker ho  each potential abductive marker h   and each time point t   the value of c ho  h  t  is a real number between zero and one. for this model to fit the analysis  the function c should have these characteristics: 

by restricting propagation such that a hypothesis h does not propagate unless c ho  h  t    thr  we get the approximation shown in figure 1b. the model does not find intersections below threshold but is otherwise accurately most-probable-first. for comparison  the way that discrete binary marker-passing models propagate is shown in figure 1c. 
　the advantage of formulating the model this way is that it can be implemented using a technique that fits our desired propagation characteristics  and also appears to be suited to handling the three issues brought up at the end of the previous section. in this technique  the dependencies between hypotheses are used to link the markers  forming a new net  which instantiates parts of the semantic net's structure. the marker net is an augmented relaxation network where the activation of each marker represents c h1  h  t . the following incremental algorithm is used: 
1. update the activation of each marker as a function of its previous activation and the activations of its immediate neighbors. 
1. discard the markers with very low activation. 
1. augment the marker net by propagating markers above threshold. 
1. repeat. 
figure 1: augmented relaxation network algorithm. 
　non-linear activation functions can be designed to give the curves in figure 1b.  in the case where an intersection results in unification  the activation function should give similar curves  modified to reflect evidence combination.  moreover  the model suggests possible approaches to the more difficult issues:  1  cease searching when relaxation settles  i.e.  when the activation no longer changes significantly with each iteration. hypotheses below threshold are not worth searching.  1  attach inhibitory normalization links to markers with no ancestors  so as to normalize the activations of all descendants; introduce inhibitory disjointness links between sibling markers with mutually exclusive hypotheses  such that the sum of their activations is not permitted to exceed that of their common parent.  1  bias the activation functions to distort the belief/utility settling points so as to  over-commit  above a threshold probability and  under-commit  below it. 
1 	discussion 
we have suggested how to restrict marker propagation more accurately than in existing models  based upon a probabilistic analysis  and we have explained the usage of activation more precisely. it remains to be shown whether the assumptions made under our analysis justify the suggested extensions. 
　the augmented relaxation network is similar in spirit to dynamic connectionist nets  e.g.  berg 1 . chun and mimo  have also suggested combining marker passing and relaxation. however  in our model more emphasis is placed upon maintaining the symbolic properties of semantic networks than in others  since we feel that ease of manipulating the knowledge representation is one of the advantages of symbolic ai. hendler  suggests combining marker passing with microfeatures  using a  defining characteristic  link  but does not use a term-defining hierarchy to represent microfeature combinations at varying levels of abstraction. 
　a comparison with  pure  recognition models illustrates the hybrid advantage. hobbs et al.  cast a number of natural language interpretation problems as abductive inference in a theorem-prover  but noted that some way to control the potentially explosive search is necessary. as symbolic models make increasing use of parallel techniques for efficient computation  connectionist work has moved toward addressing structured representations  traditionally a symbolic strength  feldman 1 . shastri  presents a connectionist model that handles the single-schema subcase of the recognition problem using a hierarchical representation  but still lacks the means to handle variable binding. 
　an open question is how to decide whether to perform unification when an intersection occurs. moreover  multiple intersections may suggest mutually exclusive unifications  so discrimination criteria are needed. 
　another issue involves relaxing the assumption that the interpreter has no a priori information about the semantic net's connectivity. in this case  a global optimization strategy might be used to restructure the network or provide additional indexing weights to improve the worst case search cost. 
　an implementation called fresco is under development  wu 1 . it is being applied to analyzing noun compounds such as gooseneck lamp  with parallel parsing and semantic interpretation. 
acknowledgements 
thanks to robert wilensky and michael braverman for valuable discussions  as well as jerry feldman  peter norvig  jim hendler  joachim diederich  the members of bair  berkeley ai research   and the al/cognition group at tu munich. 
a 	representation semantics 
since knowledge representation terminology is often confusing  the semantics of the assumed representation is sketched here: 
1. a concept cn is a one-place predicate  with an associated frequency of occurrence 1   f cn    1 . 
1. an occurrence / of the concept is a constant such that cn l  holds. 
1. a  terminological  is-a relation between two con-cepts cn1 and cn1 means  vx  cni z  -  cn1 t  . 
1. a primitive conceptual subpart relation between two concepts cn  and cn1 means  vi  cni i  -   where rl is a two-place pred-
icate. 
1. a defined conceptual subpart relation between two concepts cn1 and cn1 must correspond to another subpart relation s between two concepts cn1 and cn1  such that cn1 is-a cn1  and cn1 is-a cn1 it means | where r/1 is a two-place predicate  and 
     r/1 is the two-place predicate in s. additional constraints for transitivity and disjointness have been left out  but are assumed; also  a more general form of quantification is lacking. assertional is-a is a non-primitive associative relation: 
  an assertional is-a between two concepts cn1 and cn1 is itself a concept cn1 with defined subpart relations to cn1 and cn1. the ratio f' cn1 / f cn1  indicates the salience of cn1 to cn1  and f  cn1 /f' cn1  the salience of cn1 to cn1. 
	wu 	1 
