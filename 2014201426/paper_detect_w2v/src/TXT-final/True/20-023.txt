 
a system has been developed to find the most likely attachment for prepositional phrases in english sentences in a fairly unrestricted way. the system receives as input a syntactic sentence parse provided by a general-purpose computational grammar called peg  plnlp english grammar  the semantic decision that is necessary to make the right attachments is made  a  by parsing  also with peg  the natural language definitions of an online standard dictionary  in this case webster's seventh new collegiate dictionary;  b  by relating words to other words in the dictionary; and  c  by reasoning heuristically about the comparative likelihood of different possible attachments. the basic assumption of this research is that natural language itself is a knowledge representation language that can be conveniently accessed and richly exploited. techniques such as those presented here offer hope for eliminating the timeconsuming and often incomplete hand coding of semantic information that has been conventional in natural language understanding 
systems. 
	/. 	introduction 
programming a computer to make a reasonable syntactic analysis of a sentence is possible. programming a computer to understand that sentence is more difficult  largely because the computer lacks the kind of prior experience that would enable it to  know  what it is supposed to  understand* there have been various frontal assaults on overcoming this difficulty these have generally involved the manual encoding of information in specific systems:  semantic lexicons   e.g.  johnson 1 ;  deep semantics  for a subdomain  e.g.  sager 1 ; or attempts to specify world knowledge in some more exhaustive way  usually by reducing experience to formulations in predicate logic  e.g. lenat et al.  1 . 
   this line of work has produced interesting results but has also raised difficult problems. on the one hand  to encode manually the knowledge necessary for any large scale application is an enormous 
and possibly self-defeating task. on the other hand  encoding means choosing a specific representation  which is by no means easy given that nobody has yet a complete picture of the kind of information that must be represented. some researchers have even challenged recently the notion that an encoding of any type could lead to any real form of natural language understanding  winograd and elores 1 . 
   we suggest another approach based on the fact that natural language words are also symbols and  as such  can be handled very well by computers. most knowledge can be directly expressed in natural language  a fact which has already been recognized  kayser 1  zadrozny forthcoming . moreover  large bodies of knowledge  such as human dictionaries and encyclopedias  arc already available online. if computers can access that information  and use it to solve natural language processing ambiguities  they  and we  would be much further ahead. 
i 
this research was entirely performed at the ibm thomas j. watson research center. 
karen jensen 
computer science department 
ibm thomas j. watson research center p.o. box 1 
yorktown heights  new york 1  1 s a 
　　the research presented here is aimed toward that goal as a first step  we arc concentrating on the disambiguation of prepositional phrase attachments  a difficult problem which is of considerable current interest  lytincn 1  dahlgren and mcdowell 1  schubert 1  wc are developing and implementing techniques for processing the definitions of an online standard dictionary in order to extract from them the semantic information necessary to resolve such ambiguities. possible extensions include the processing of other kinds of attachment ambiguities and word meaning disambiguation 
   'this work addresses the areas of natural language understanding  reasoning  knowledge representation  and  briefly  learning understanding is approached by treating online reference works as knowledge bases. a heuristic reasoning component gives robust results. one of the most interesting directions of this research is the suggestion that natural language itself is a knowledge representation language that can be conveniently accessed and richly exploited at the end of the paper  wc make a small incursion into the domain of learning  suggesting that formal knowledge bases could be progressively built by automatically extracting information from natural language sources. 
　　the computational principles discussed here offer hope for eliminating the time-consuming  and often incomplete  hand coding of semantic information that has been conventional in natural language understanding systems. 
//. prepositional phrases attachment ambiguities 
consider the following sentences: 
 1  / ate a fish with a fork  1  / ate a fish with many bones. 
 1  / ale a fish with my fingers. 
 1  / went to boston by bus. 
 1  / will have finished this work by noon. 
   at the syntactic level  all these examples offer attachment ambiguities sentences  1  to  1  were discussed in  binot 1 ; sentence  1  is discussed in  sowa and way 1 . however  in both cases  the attachment ambiguity was solved by hand-coded knowledge. we are designing a semantic expert which is able to decide by consulting automatically a standard dictionary what is the correct attachment for the prepositional phrase in each case  and also what is the intended meaning of the preposition. the input to this system is a syntactic parse tree for the ambiguous sentence  produced by a grammar called peg. 
   the computational grammar peg  plnlp english grammar  analyzes english sentences by using syntactic information in augmented phrase structure rules with a bottom-up  parallel processor 
 jensen forthcoming . the system that provides these facilities is plnlp  or the programming language for natural language 
processing  heidorn 1 . peg produces useful sentence parses for a large amount  and a wide variety  of english text. these parses contain syntactic and functional  subject  object  etc.  information  
	binot and jensen 	1 

but  as yet  no semantic information  or other information beyond the functional level. 
   peg's method for dealing with attachment ambiguities is to attach modifiers in a single arbitrary pattern  usually to the closest possible head   but to mark other possible attachment sites so that they can be referred to for later semantic processing. a question mark indicates these possible attachment sites  sec figure 1  this mark triggers the intervention of the semantic expert  which attempts to solve the ambiguity. 
decl np pron*   i   verb*  ate  np det adj*   a   noun*   f i s h     pp prep   w i t h   quant adj* 	 many  noun*  bones  figure 1. peg parse tree for a syntactically ambiguous sentence 
	///. 	establishing semantic connections 
disambiguation is not a matter of exact deduction  but rather of finding the 'most likely* interpretation in a given context our system does that by consulting dictionary entries for specific words in the context in order to assign to each possible interpretation a likelihood factor.*1 these factors  like the certainty factors in mycin  shortliffe 1   may range from -i  absolute disbelief  to 
+ 1  absolute belief   with 1 denoting complete uncertainty. this process of assigning likelihood factors is directed by declarative rules which  making use of expert system technology  try to capture in some sense the semantic expertise brought to bear by a person while consulting a dictionary. figure 1 shows the answer that the system gives to the problem posed by the ambiguity in figure 1. 
  with  eat   fork   
 instrument 1   manner 1   
 coagent -1xpartof - 1 .   ass1ciati1n - 1 .    
  with  fish   f1rk   
 association 1   part1f -1   
 coagent -l.  instrument - 1 .   manner - 1 .    
figure 1. solution of the semantic expert for sentence  1  
   this answer is an ordered list of the possible constructs  each construct being provided with an ordered list of the possible interpretations of the preposition for that construct. the likelihood factor of a construct is defined as the likelihood factor of its best interpretation. translated into english  figure 1 says that there are two possible attachments for the with-pp: to the main verb  eat*  with  eat   fork    or to the immediately preceding noun  fish   with   fish     fork   . for the first construct  the instrument meaning of the preposition receives a rating of 1  the manner meaning a rating of 1  etc. thus  according to the system  the most likely interpretation of the ambiguity in example  1  is to attach 'fork  to  cat* with an instrumental meaning. 
   the system works by evaluating successively each possible construct and each possible meaning of the involved preposition. due to space constraints  we shall only discuss here the instrument 
l 
for now  we arc using only the context of the immediate sentence; but we have plans lo move to intcrscntcnlial context. 
1 	natural language 
and partof meanings of  with ' and the ins t rumenti and i imf  meanings of  by   although other meanings are handled by the system  as figure 1 shows. 
   the basic strategy for evaluating a construct is to use the dictionary in order to find some semantic connection between the two terms of the proposed construct  the head and the complement . dictionary entries contain several kinds of information that arc of interest for this aim the definition s   example sentences and phrases  synonyms  and usage notes and other comments. in the first stage of this research  we are using only the definitions provided by webster's seventh new collegiate dictionary  w1 . 
   finding semantic connections in the dictionary is possible because there arc specific words and phrases in definitions  forming what we shall here call patterns  which arc almost systematically used to express specific semantic relations  markowitz ct al. 1 . for the two meanings of  with  illustrated in the previous examples  some of these patterns are 
partof part of  arises from  end of  member of  etc 
instrument* for  used for  used to  a means for  etc 
i*hesc patterns generally take  as their objects  some central term  or terms  in the definition of the complement word an attempt can then be made to link that term with the head of the construct that is being studied. we shall illustrate this with sentence  1  the system starts by looking up in w1 the definitions of the ambiguous prepositional complement  fork   and by parsing each of them the first definition reads: 
fork. 1 an implement with two or more prongs used exp for taking up  as in eating   pitching or digging. 
fhe corresponding parse tree as produced by peg is shown in figure 1 
the system will apply to such parse trees a pattern-matching mechanism looking  in this case  for one of the instrumlvnt patterns mentioned above. each pattern is formally represented as a recursive formula like the one shown in figure 1: 
 ctake head   segtype pp  
 has prp   base for     chas head   prespart    
   
figure 1. a pattern for instrument indications in parse trees. 
   such formulas use the fact that every parse tree node and every word is represented in penlp as a record with attributes and values. this specific pattern instructs the system to look in the parse tree for a node having a type of pp  prepositional phrase   having a prp  prcposition  attribute pointing toward a record representing the preposition tor   and having a head attribute pointing toward a term marked as a present participle  prespart . if such a record is found  its head should be returned as value by the pattern-matching mechanism  or  if it is a coordinate structure  the heads of all conjuncts should be returned . 
   applying this pattern to the parse tree of figure 1  the system will find one pp node satisfying the description:  especially for taking...  the heads of the vp conjuncts inside that pp then yield three possible instrument indications:  take    pitch   and  dig.  the system will try to relate these terms with  eat  by using synonym or taxonym relations also extracted from the dictionary.  for the present  we deliberately avoid the definition phrase  as in eating  -which offers a direct match --in order to show that our approach does not rely on such lucky coincidences.  

figure 1. pfg parse tree for the first definition of fork. 　　basically  the taxonym relations arc established by extracting the heads of the dictionary definitions  using the same techniques as above. in this case  'take  is defined as a direct hypcrnym of 'cat* in w1  because one of the definitions of 'cat* is  to take in through the mouth...  thus  a plausible meaningful connection has been established between 'fork  and  eat  using an instrument link; this constitutes a strong positive indication in favor of the likelihood of the interpretation  instrument eat.fork  . the connection found can be viewed as forming a path in a semantic network  as illustrated in figure 1: 

figure 1. a semantic path connecting  cat  and  fork  in w1 
　　it must be emphasized that this network is only an implicit structure illustrating the connections found by the system  and has not been provided as hand-coded knowledge. the main characteristic of our approach is that connections between concepts are established by tracing word relationships in the natural language entries of a standard dictionary. 
   no stronger indication will be found for the other possible construct   with   fish     fork      or for the other possible meanings of the preposition  in particular  there is no partof pattern in the definitions of  fork  that would allow us to connect  fork  to  fish  . thus   instrument cat fork   will be the preferred interpretation of this example. 
　　let us now turn our attention to sentence  1 . when evaluating the construct   with  fish   done     the system will find the following partof pattern in the definition of bone: bone: 1. one of the hard parts of the skeleton of a vertebrate. 
this yields two possible partof indications:  skeleton  and 
 vertebrate.  the system tries to relate each of these terms to  fish.  since  fish  is a direct hyponym of  vertebrate  in w1  we find an easy connection  shown figure 1   which gives a strong indication in favor of the interpretation  partof fish bone  . 
   again  as no shorter path will be found for any other possible interpretation  this will be the preferred interpretation. 

iv. using inferences 
in many cases  the dictionary entry for the prepositional complement does not provide the necessary information. specific inference rules can then be tried. these rules depend on the nature of the connection that the program is trying to establish  and they will usually direct the examination of other dictionary entries. 
   thus  in sentence  1   the system will not be able to find directly a useful instrument pattern in the definitions of the prepositional complement  bus . but we can make the reasonable inference that a term can have the same instrumental uses as its hypemyms. the system will go up one level in the hierarchy  and try to find instrument patterns for the direct hypernyms of  bus . one of these hypernyms in w1 is  vehicle   which offers the following instrument pattern: 
vehicle: 1. a means of carrying or transporting something... 
this gives us two instrument indications:  carry  and  transport.  
the taxonomic information offers different ways to connect  carry  and  go   as shown in figure 1. 
   the value of the likelihood factor returned by a rule is related to the length of the connection path found. thus the instrumental interpretation will receive a weaker likelihood factor for  1  than for  1 . however  once again  no stronger preference can be obtained for the other interpretations  and  instrument go bus   will be preferred. 
	binot and jensen 	1 


figure 1. semantic paths between 'bus* and  go* in w1 
　　in sentence  1   neither  finger  nor its direct hypernyms will offer any useful instrument pattern in their definitions. however   finger  is defined as  one of the five terminating members of a hand  a  hand  is characterized as a grasping organ and  grasp is related to  eat  via  take.  by making tie inference that if something can play an instrumental role  then a part of this something can play the same role  the system is able to establish the following connection: 
isa 
figure 1. a semantic path connecting  finger  and  eat  in w1 
   this inference is at best approximate  and the connection is thus regarded as weaker than the ones in figures 1 and 1. however  no other possibility provides a stronger connection  and *instrument eat finger * will be the preferred interpretation. 
   example sentence  1  illustrates another kind of inference using a partof link. the criterion for evaluating the time interpretation of  by  is to try to establish a connection between the complement  noon  and one of the terms  time  or  period . no direct taxonomic relation can be found. however  noon  is defined as 
 the middle of the day   and  day* is a direct hyponym of  time  in w1. by using the inference that a part of a time can also be a time  the system establishes a strong connection between  noon  and 
 time   which will lead to the preference of the interpretation  time finish noon  : 

figure 1. a semantic path connecting  finish  and  noon  in w1 
v. implement a tion of the dictionar y semantic expert 
a standard dictionary is plagued by incompleteness and inconsistency; moreover  the information that it carries  being expressed in natural language form  is complicated. therefore our rules are designed as heuristics  which can only provide approximate results. the cumulative effect of many heuristics  and not the perfection of each one taken separately  has to do the job. 
1 	natural language 
   heuristics can make use of syntactic and semantic information for determining likelihood factors  lf   as can be seen in the following english description of the rule handling the partof meaning of the preposition  with   as  for example  in the construction  a fish with bones  : 
h1- checking for a partof relation between a head and a  with'' complement: 
	1. 	if the head is not a noun  the relation doesn't hold  lf -
-i ; 
1. if some partof pattern exists in the dictionary definition of the complement  and if this pattern points to a defining term that can be linked with the head  then the par i of relation probably holds  lf - 1 ; 
1. else assume that there is more chance that the relation doesn't hold  lf - -1 . 
   each rule appears as a list of clauses  with each clause containing a condition and an action. the conditions are evaluated in sequence until one of them is satisfied. the corresponding action  indicated in parentheses in the rule description  defines the resulting likelihood factor  lp  the first clause of rule h1 is a syntactic test expressing the fact that we want only to consider a possible partof meaning for 'with* when the head is a noun. the second clause directs the search for a semantic connection using a partof link  as illustrated in section 1 the third clause provides a default value to be used when all other tests in the rule have failed. 
   different preposition meanings may require different types of inferences in order to establish meaningful connections and may also have different syntactic cues therefore the system includes at least one rule for each meaning of each preposition it knows about several rules may apply to the same preposition meaning  their resulting likelihood factors will then be combined  as in mycin  by the formula '  and lf 1 arc 
the factors to be combined 
   as an example  we give below another rule used when checking for partof connections this rule uses a syntactic cue. it expresses our strong intuition that the presence in the prepositional phrase of a possessive which disagrees in person with the possible head noun precludes a partof relation  as  for example  in the construction  a fish with my fingers'  
h1- for checking for a partof relationship between a head and a  with  complement: 
1. if 
a. the head is a noun  and 
b. the complement is qualified by a possessive  and 
c. this possessive doesn't agree in person with the head  
then the partof relation probably doesn't hold  lf= 
-1   
	1. 	else this heuristic doesn't give any indication  lf = 1 . 
　　h1 will be applied in parallel with 1. most of the time  the result will be the neutral value zero  which does not affect the results of other rules. when the syntactic cue is present  the rule will decrease strongly the resulting likelihood factor for the partof interpretation. generally speaking  the rule structure offers a choice between sequentially and parallelism. tests which should be performed sequentially will be included as successive clauses in a rule. tests which should reinforce each other will be implemented as separate rules. 
   the condition of a clause may define subgoals  which will be evaluated by applying other rules. thus the attempt to use taxonomic or synonymic relations to connect two terms  such as  fish  and  vertebrate  in sentence  1  is defined as a separate subgoal  which will be invoked by the second clause of 1  this can be seen in the formal implementation of the rule  given in figure 1 below . different rules may be applied to this subgoal  one checking for a direct taxonomic link  another for a synonymic link  a third if the two terms have a common parent. the evaluation of 

the subgoal will also yield a likelihood factor which  if positive  will be multiplied by the one expressed in the action part of the rule  thereby decreasing it. 
   the choice of likelihood factors rests mainly on intuition. some choices are easy; some inferences  for example  are obviously weaker than others. in other cases the values have to be adjusted by trial and error  by processing many examples. it is interesting to note that  as our corpus of examples increases  the likelihood factors are converging toward apparently stable values. 
   the resulting likelihood factor of an interpretation must also be inversely tied to the length of the semantic path corresponding to that interpretation. this is basically accomplished by designing the rules so that a given rule will search only for one link in a path  the other links being identified by subgoals called by that rule. the longer the path  the longer the reasoning chain  and the lower the final likelihood factor. 
   the rules are written in the plni p language  heidorn 1   which we shall not describe here. we shall only give below  as an illustration  the formal version of rule 1: 
h1 controler*ptr complement*ptr  
 segtype controler .ne.'noun'   -lf  partof'   -1    
 subg1al1 'pref'...controler... 
entries complement 'partof  ... 
segtype controler ...1   
 -lf 'partof   1    
 -lf  partof'  -1    
figure 1. plnlp formulation of rule h1 
   our prototype system includes currently twenty rules and is able to handle the prepositions  with    by    after* and  in.  it has been tested on about 1 examples so far. 
vi. learning useful facts 
re-parsing all the definitions of a word every time that word is encountered will soon lead in practice to unsurmountablc efficiency problems. human beings do not look up repetitively the same word in the dictionary eventually  they will learn something about its meaning 
   we have included in our system a simple but helpful form of learning which consists of remembering useful information extracted from dictionary definitions. each time the pattern-matching mechanism identifies semantic relations  they are stored in a  memory file  where they will remain available for processing further input. if the same word occurs again later on  the system will check to see if the remembered relations are useful before attempting to parse the definitions. figure 1 below shows some of the information remembered for sentences  1  and  1 . 
	 put 'fork 	'partof 	'none  
	 put 'fork 	'instrument 	' take pitch dig   
	 put 'bone 	'partof 	' skeleton vertebrate   
	 put 'bone 	'instrument 	' stiffen   
figure 1 information learned from the definitions of  fork  and  bone  
   the remembering mechanism offers two significant advantages. first  it can speed up significantly the disambiguation process. second  it provides an interesting tool for finding out what information is useful and how to store it. obviously  however  there is still room for considerable improvement in this learning process. in particular  it does not attempt to infer new information  induce new concepts  or even to structure the information in more useful ways. in the long term  this line of research could lead to the automatic building of formal knowledge bases from natural language sources. 
vii. conclusions 
we have shown that it is possible to consult automatically a standard machine-readable dictionary as a knowledge base  in order to resolve ambiguities in the computational parsing of natural language text. only prepositional phrase attachment ambiguities have been studied so far  but the techniques described here should be extendible to ambiguities that involve all other classes of phrases and 
clauses. furthermore  there is no need to stop with dictionaries: encyclopedias and other online written works are available  valuable sources of information. 
   all types of information present and available in dictionary entries should eventually be used to help in the disambiguation process: examples  synonyms  and usage notes  as well as the definitions themselves. other important areas for future development include the development of new heuristics; the adjustment and improvement of the likelihood factors; the analysis of relationships that are signaled by prepositions  conjunctions  and other function words; and also the addition of information on phrasal verbs  verb-particle pairs  verb-preposition pairs   and an investigation of how these will help in the parsing process. 
   this line of research highlights several principles of computer cognition: 
  knowledge is represented in natural language. 
  natural language text can be accessed by a syntactic parser and a reasoning module  in this case  heuristic reasoning . 
  heuristics can be used to help the program reach new levels of understanding. 
the work should benefit all areas of natural language processing -from text analysis to machine translation to data base query -- by opening up the prospect of a genuinely broad-coverage approach to meaning and understanding. 
acknowledgments 
thanks are due to george heidorn for the many useful discussions that we had with him during this research and for helpful comments on a previous draft of this paper. 
