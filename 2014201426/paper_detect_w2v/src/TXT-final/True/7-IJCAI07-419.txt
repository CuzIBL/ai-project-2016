
in this paper we prove that the well-known correspondence between the forward-backward algorithm for hidden markov models  hmms  and belief propagation  bp  applied to hmms can be generalized to one between bp for junction trees and the generalized inside-outside probability computation for probabilistic logic programs applied to junction trees.
1 introduction
bayesian networks  bns  and probabilistic context free grammars  pcfgs  are two basic probabilistic frameworks in uncertainty modeling  bns  and in statistical natural language processing respectively. although they are independently developed  there is a strong indication of their close relationship. for example both include hidden markov models  hmms  as a common subclass. furthermore belief propagation  bp  applied to hmms coincides with the forwardbackward algorithm for hmms  smyth et al.  1  which is a specialization of probability computation used in the insideoutside  io  algorithm for pcfgs  baker  1 . nonetheless  however  no exact correspondence beyond this one is known to our knowledge.
¡¡in this paper1 we upgrade this correspondence. we prove that the inside-outsideprobability computationin the io algorithm  when generalized for probabilistic logic programs and applied to junction trees  yields bp. in particular we prove that collecting evidence  resp. distributing evidence  in bp coincides with the computation of inside probabilities  resp. outside probabilities  in this generalized io computation.
¡¡to prove the computational correspondence between bns and pcfgs in a unified manner  we need a general language that can describe bns and pcfgs1. we choose prism  sato and kameya  1  as a first-order probabilistic language for this purpose. we also need  propositionalization  of bns  sato and kameya  1; mcallester et al.  1; chavira and darwiche  1 . by propositionalization we mean to represent a discrete random variable x having n values {v1 ... vn} by a set {xv1 ... xvn} of mutually exclusive binary random variables such that xvi = 1  true  iff x = vi  1 ¡Ü i ¡Ü n . this propositionalization explodes the number of states in a bn. however the benefit often outweighs the explosion because it makes possible to share computation with finer grain size value-dependently at runtime by dynamic programming and rule out 1 probability computation at compile time. it explains  though we omit details  why probability computation in polynomial time cannot be expected of the direct application of bns to pcfgs  pynadath and wellman  1  while it is carried out in o n1  time where n is the sentence length by prism and by case-factor diagrams  cfds   mcallester et al.  1 .
¡¡in what follows  we first review basic notions in section 1. we then prove main theorems after a series of lemmas in section 1. due to space limitations  the description is sketchy and the reader is assumed to be familiar with logic programming  doets  1  and bp in junction trees  jensen  1; lauritzen and spiegelhalter  1; shafer and shenoy  1 . prism  a probabilistic logic programming language used in this paper  is detailed in  sato and kameya  1 .
1 background
1 bayesian networks and junction trees
a bayesian network bn is a directed acyclic graph defining a joint distribution p x1 = x1 ... xn = xn  =  such that nodes are random
variables x1 ... xn and if a node xi has parent nodes ¦°i = xs1 ... xsk  k ¡Ý 1   a conditional probability table representing a conditionaldistribution p xi = xi | ¦°i = ¦Ði  is associated with xi  1 ¡Ü i ¡Ü n . here a lower case letter xi denotes a value of xi and similarly for ¦Ði. we denote the range of xi by r xi  and the direct product r xs1 ¡Á¡¤¡¤¡¤¡Ár xsk  by r ¦°i  and write xi ¡Ê r xi  and ¦Ði ¡Ê r ¦°i . hereafter we use p x1 ... xn  for p x1 = x1 ... xn = xn  etc. when we consider p xi | ¦Ði  as a function of xi ¦Ði  the set {xi} ¡È ¦Ði is called the arguments of p xi | ¦Ði . let ¦Á = {s1 ... sk} be a set of variable indices    {1 ... n} . x¦Á stands for the set of variables {xs1 ... xsk}. for example if ¦Á = {1 1}  x¦Á = {x1 x1 x1}. this notation extends to vectors.
¡¡a junction  join  tree t =  v e  for bn is a tree satisfying the following conditions. first a node is a set x¦Á of variables in bn. in what follows we use x¦Á and its index set ¦Á interchangeably. an edge connecting ¦Á and ¦Â is labeled by ¦Á ¡É ¦Â. second p x1 ... xn  = ¦°¦Á¡Êv ¦Õ¦Á x¦Á  must hold where ¦Õ¦Á x¦Á   a potential  function   is a product of some  or no  conditional distributions such that their arguments are included in x¦Á. the third condition is the running intersection property  rip  which dictates that if nodes ¦Á and ¦Â have a common variable  it must be contained in every node on the path between ¦Á and ¦Â. rip ensures the conditional independence of the subtrees given variables in the node and is the key property for efficient probability computation by bp. given a bn  a junction tree is constructed by way of triangulation or variable elimination  jensen  1; kask et al.  1; lauritzen and spiegelhalter  1 .
1 pcfgs and inside-outside probabilities
a pcfg is a cfg with probabilities assigned to production rules in such way that if a nonterminal a has n rules 
a ¡ú ¦Á1 ... a ¡ú ¦Án  a probability pi is assigned to  holds. pi is the
probability of choosing a ¡ú ¦Ái to expand a in a probabilistic derivation. pcfgs are a basic tool for statistical natural language processing and include hmms as a subclass.
¡¡let a i j  denote an event that a nonterminal a probabilistically derives the substring wi ... wj of a sentence l = w1 ... wn  1 ¡Ü i ¡Ü j ¡Ü n . the probability of a i j  is called the inside probability of a i j  and defined as the sum of the products of probabilities associated with rules in a derivation belonging to a i j . similarly the outside probability of a i j  w.r.t. l is the sum of products of the probabilities associated rules used in a derivation that starts from the start symbol and derives w1 ... wi 1awj+1 ... wn. the product of inside-outside probabilities of a i j  gives the probability of deriving l via a i j . inside-outside probabilities are computed by dynamic programmingin time o |l|1 . we next generalize inside-outside probabilities in the context of probabilistic logic programming.
1 probabilistic logic programming language prism
we briefly explain a probabilistic logic programming language prism. in a nutshell  prism is prolog extended with tabling1  a probabilistic built-in predicate called msw  multiary random switch  and a generic parameter learning routine that learn parameters embedded in a program by computing generalized inside-outside probabilities  sato and kameya  1 .
¡¡one of the basic ideas of prism is propositionalization of random variables using a special built-in predicate msw/1. let v be a discrete random variable with a set r v   of ground terms as its range. to represent a proposition v = v  v ¡Ê r v     we introduce a ground term i as a name  identifier  for v and a ground msw atom msw i n v  which is true iff the outcome of an n-th trial of v named i is v. here n is a natural number. v as iids are represented by the set {msw i n v  | v ¡Ê r v   n = 1 ...} of msw atoms. these msw atoms must satisfy certain conditions1. the probability of msw i n v  being true is called a parameter.
¡¡in prism a program db = r ¡È f consists of a set r of definite clauses whose head is not an msw atom and a set f of msw atoms together with a base distribution pf defining probabilities  parameters  of msw atoms in f. simple distributions are definable soley in terms of msw atoms but complex distributions are constructed by using definite clauses. in our semantics  db defines a probability measure pdb ¡¤  over the set of herbrand interpretations  distribution semantics  sato and kameya  1  . hereafter we consider pdb ¡¤  as a distribution on ground atoms as well.
1 propositionalization through tabled search
in our approach  pdb g   the probability of an atom g defined by a program db  is computed in two steps. the first step is propositionalization. we apply the sld refutation procedure doets  1 to db and   g as a top-goal we search for all sld proofs of g and reduce g to a logically equivalent but propositional dnf formula e1 ¡Å ¡¤¡¤¡¤ ¡Å ek where ei  1 ¡Ü i ¡Ü k   an explanation of g  is a conjunction of ground msw atoms. they record probabilistic choices made in the process of constructing an sld proof of g and each msw atom represents a probabilistic event v = v for some random variable v . then in the second step  we compute the probability of g as pdb g  = pdb e1 ¡Å ¡¤¡¤¡¤ ¡Å ek .
¡¡in general since there are exponentially many proofs and so are explanations  the naive proof search would produce an exponential size dnf. fortunately however by introducing tabling in the first step  we can often produce an equivalent but polynomial size boolean formula such that common subexpressions in the ei's are factored out as tabled atoms. the factored formula  expl g   becomes a set  conjunction  of definitions of the form h   w where a tabled atom h is defined by w which is a conjunction of tabled atoms and msw atoms. we assume the defining relation of these tabled atoms is acyclic. for convenience we sometimes think of each definition as an and-or graph and conventionally call expl g  an explanation graph as the collection of such and-or graphs. hereafter expl g  stands for the factored formulas and their graphical representation as well.
1 generalized inside-outside probabilities
to compute pdb g   we convert each definition h   a1 ¡Å
...¡Åal in expl g  where ai = b1¡Ä¡¤¡¤¡¤¡Äbmi¡Ämsw1¡Ä¡¤¡¤¡¤¡Ä mswni  1 ¡Ü i ¡Ü l  to a numerical sum-product equation.
pdb h =pdb a1  + ¡¤¡¤¡¤ + pdb al pdb ai =pdb b1 ¡¤¡¤¡¤pdb bmi ¡¤ 1 pdb msw1 ¡¤¡¤¡¤pdb mswni 
note that this conversion assumes the mutual exclusiveness of disjuncts {a1 ... al} and the independence of conjuncts {b1 ... bmi msw1 ... mswni}. although guaranteeing these two conditions is basically the user's responsibility  they are automatically satisfied as far as the prism program describing junction trees is concerned  see section 1 and lemma 1 . we denote by eq g  the set of converted equations.
¡¡for a ground atom a  we call pdb a  a p-variable. p-variables are just numerical variables named by ground atoms. as we assume the defining relation of tabled atoms is acyclic  p-variables in eq g  can be linearly ordered so that eq g  is efficiently solved in a bottom-up manner by dynamic programming in time proportional to the size of eq g . also the acyclicity implies that a higher p-variable is a multivariate polynomial in the lower p-variables  and hence we can take the derivative of a higher p-variable as a function of the lower p-variables.
¡¡suppose we are given a program db. in an analogy to inside-outside probabilities in pcfgs  we define a generalized inside probability inside a  of a ground atom a by
def
inside a  = pdb a  and extend the definition to a conjunction w of ground atoms by inside w  def= pdb w .
¡¡we also define a generalized outside probability outside g;a  of a w.r.t. a top-goal g as follows. first enumerate a's occurrences in expl g  as
.
then outside g;a  is recursively computed by eq. 1.
outside g;g  = 1 outside g;a  = outside  inside w1 j 
+¡¤¡¤¡¤ + outside  inside wj j .
              1  using eq. 1  all outside probabilities are computed in time in the size of eq g   sato and kameya  1 . we can prove that for a ground atom a  the product inside a ¡¤outside a  is the average number of occurrences of a in a proof of g and that our definition is a generalization of the usual definition of inside-outside probabilities in pcfgs  lafferty  1 .

1
¡¡¡¡as mentioned above  pdb g   a p-variable  is a function of other p-variables pdb a  and the mathematical definition of outside g;a  is
outside 
db
which derives eq. 1.

figure 1: junction tree
1 belief propagation as the generalized io computation
in this section  we prove that the generalized io computation  i.e. the computation of generalized inside-outside probabilities  subsumes bp in junction trees.
1 program for bp messages
suppose we have a bn defining a joint distribution p x1 =

a junction tree t =  v e  such that p x1 ... xn  =
¦°¦Á¡Êv ¦Õ¦Á x¦Á . let ¦Ä be the root node of t1.
¡¡we construct a prism program dbt = ft ¡È rt that describes bp in t as follows1. introduce for each conditional probability p xi | ¦Ði  a ground msw atom msw bn i ¦Ði  once xi . if xi has no parent put ¦Ði =   null list . define a finite set ft of msw atoms by
def
	ft	= {msw bn i ¦Ði  once xi  |
1 ¡Ü i ¡Ü n xi ¡Ê r xi  ¦Ði ¡Ê r ¦°i }
and set parameters ¦Èbn i ¦Ði  xi by ¦Èbn i ¦Ði  xi = pf  msw bn i ¦Ði  once xi   = p xi | ¦Ði .
thenit is easy to see that every joint probabilityis represented by a conjunction of these ground msw atoms  i.e. we have
msw bn i ¦Ði  once x .
¡¡next introduce an atom msw bn i ¦°i  once xi  containing variables xi and ¦°i for each i  1 ¡Ü i ¡Ü n . msw bn i ¦°i  once xi  represents the conditionaldistribution p xi = xi | ¦°i = ¦Ði 1. for every node ¦Á in the junction tree t  define a conjunction w¦Á x¦Á  representing the potential ¦Õ¦Á x¦Á  of ¦Á and introduce a clause c¦Á defining a message atom q¦Á¦Ã x¦Á¡É¦Ã  that describes a message in bp sent from ¦Á to its parent node ¦Ã. they are respectively defined as
msw bn i ¦°i  once xi  
.
here ¦Â1 ... ¦Âk  k ¡Ý 1  are the child nodes of ¦Á in t. the next lemma states that w¦Á x¦Á  correctly describes the potential of node ¦Á. the proofis straightforward and omitted. lemma 1
.

for the root node ¦Ä in t  it has no parent but we add a special parent node 1 to v and define c¦Ä as

where are the child nodes of ¦Ä. q¦Ä1 has no arguments but calls every message atom directly or indirectly. finally put
def
	rt	= {c¦Á | ¦Á ¡Ê v t =  v e }.
¡¡we illustrate a small example. take a discrete bayesian network bn1 on {x1 ... x1} on the left-hand side of figure 1 and its junction tree t1 on the right-hand side with the root node ¦Ã1. dotted lines in bn1 indicate edges added by triangulation. figure 1 shows the definitions of message atoms for t1.

	bn1	junction tree t1
figure 1: bn1 and a junction tree t1
1 explanation graphs for bp messages
let dbt = ft ¡Èrt be the program constructed in subsection 1. after declaring every q¦Á¦Ã predicate as a table predicate  we apply tabled search for all proofs to a top-goal   q¦Ä1 where ¦Ä is the root node of t. the search always terminates and yields an explanation graph expl q¦Ä1  which contains a msw bn 1 once   x1 ¡Ä
msw bn 1 once  x1 x1   x1 ¡Ä q¦Á1¦Ã1 x1 x1 
q¦Â ¦Á  x  x      	 once  x1   x1 ¡Ä
	 	msw bn 1 once  x1   x1 
figure 1: the definitions of message atoms for t1.
definition of tabled atom q¦Á¦Ã x¦Á¡É¦Ã  for every node ¦Á in t as shown below.

here x¦Á¡É¦Ã denotes an arbitrary ground instantiation of x¦Á¡É¦Ã and q¦Á¦Ã x¦Á¡É¦Ã  represents the message sent from ¦Á to ¦Ã  ¦Á's parent node  after receiving messages from ¦Á's child nodes ¦Â1 ... ¦Âk  see figure 1 .
¡¡we next prove that the recursive equations eq. 1 are  solved  uniquely. let t¦Á be the subtree of t rooted at x¦Á and x¦Î¦Á be the set of variables appearing in t¦Á. we first introduce a formula ¦Ó¦Á x¦Î¦Á  for ¦Á by eq. 1 and rewrite it to eq. 1. it represents the potential of the subtree t¦Á.
 1 
 1 
lemma 1
 from rip of t 
 1 

proposition 1 	
 proof  by well-founded induction on t. when ¦Á is a leaf in t  the proposition is obviously true. assume it is true w.r.t. the child nodes of ¦Á.
 by eq. 1
  ¦Á   ¦Ã  and  ¦Âi   ¦Á 's are mutually disjoint 
 by eq. 1
 by induction
	=	q¦Á¦Ã x¦Á¡É¦Ã  by eq. 1	q.e.d.
1 bp and the generalized io computation
let pdbt be the distribution defined by dbt. the generalized inside probability of the tabled atom inside q¦Á¦Ã x¦Á¡É¦Ã   and the generalized outside probability outside q¦Ä1 ;q¦Á¦Ã x¦Á¡É¦Ã   w.r.t. q¦Ä1 can be computed using eq. 1 by sum-product computation specified in eq. 1 if the independence of conjuncts and the mutual exclusiveness of disjuncts on the right-hand side of eq. 1 are guaranteed.
¡¡since each msw atom msw bn i ¦°i  once xi  occurs only once in some w¦Á reflecting the fact that a conditional distribution function p xi | ¦Ði  in the bn belongs exclusively to one potential ¦Õ¦Á in the junction tree  w¦Á x¦Á  and the q¦Âi¦Á x¦Âi¡É¦Á 's do not share any msw atoms. hence the first condition  the independence condition  is satisfied automatically. on the other hand  proving the mutual exclusiveness condition is not straightforward. lemma 1 below assures the exclusiveness condition when combined with proposition 1.
note that ¦Î¦Á ¡É ¦Ã = ¦Á ¡É ¦Ã holds thanks to rip of t. so we
rewrite ¦Ó¦Á x¦Î¦Á  as¦Ó¦Á x¦Î¦Á =¦Ó¦Á x¦Î¦Á ¦Ã x¦Î¦Á¡É¦Ã =¦Ó¦Á x¦Î¦Á ¦Á x¦Á¡É¦Ã .lemma 1 let  be two different ground instantiations of x¦Î¦Á ¦Ã. then for an arbitrary ground instantiation x¦Á¡É¦Ã  we have
 .	
 sketch of proof  without loss of generality  we can write x¦Î¦Á ¦Ã = xi1 ... xim in such a way that if xij is a parent node of xik in the original bn  xij precedes xik in this list. as xis
s
then first we noteholds since xis appears only in t¦Á and the conditional distribution p xis | ¦°is  must be contained in some potential in t¦Á by rip. second we have ¦°is ¡É x¦Î¦Á ¦Ã   {xi1 ... xis 1}. we also have ¦°is ¡É x¦Î¦Á¡É¦Ã = ¦°is ¡É x¦Á¡É¦Ã. we can conclude from these facts that  x¦Î¦Á ¦Ã x¦Á¡É¦Ã  instantiates p xis | ¦°is  to
p xis | ¦Ðis  while  instantiates p xis | ¦°is  to where. the rest is immediate and omitted.q.e.d.
¡¡we now prove main theorems by applying computation in eq. 1 to the tabled atoms defined by eq. 1. recall that inside a  = pdbt a  for a ground atom a where pdbt is the distribution defined by dbt. we derive an equation satisfied by inside probabilities of tabled atoms.
theorem 1
k
inside inside q¦Âi¦Á x¦Âi¡É¦Á  .
	x¦Á ¦Ã	i=1

 proof  inside q¦Á¦Ã x¦Á¡É¦Ã  
p
by proposition 1
 by lemma 1

		by eq. 1

 by lemma 1
	inside q¦Âi¦Á x¦Î¦Âi¡É¦Á  	q.e.d.
theorem 1 tells us that the generalized inside probabilities of tabled atoms satisfy exactly the same equations as messages in the collecting evidence phase of bp in t with the root node ¦Ä  jensen  1; lauritzen and spiegelhalter  1; shafer and shenoy  1 . hence  the bottom-up computation of generalized inside probabilities is identical to bp in the collecting evidence phase.
¡¡let p1 be the distribution defined by bn1 in figure 1. the equations for generalized inside probabilities of tabled atoms for the junction tree t1 are:
inside q¦Á1¦Ã1 x1 x1  
  msw bn 1  x1   x1   ¡¤ inside q¦Â1¦Á1 x1 x1  
 inside q¦Â1¦Á1 x1 x1  
inside q¦Â1¦Á1 x1 x1  
  msw bn 1  x1   x1   ¡¤
pdbt1  msw bn 1  x1   x1  
.
¡¡we next compute generalized outside probabilities of tabled atoms. without loss of generality  we compute the outside probability of a tabled atom for ¦Â1. we apply the definition of generalized outside probability in eq. 1 to expl q¦Ä1  while noting that a tabled atom q¦Â1¦Á x¦Â1¡É¦Á  occurs in expl q¦Ä1  as in eq. 1. we obtain recursive equations about generalized outside probabilities as follows.
theorem 1
outside 
outside inside q¦Âi¦Á x¦Âi¡É¦Á  .

 proof  outside q¦Â1¦Á x¦Â1¡É¦Á   outside 
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡x ¦Á ¦Ã   ¦Â1¡É¦Á  inside q¦Âi¦Á x¦Âi¡É¦Á  	by eq. 1
                         k outside inside q¦Âi¦Á x¦Âi¡É¦Á  
x¦¤
where
 outside inside q¦Âi¦Á x¦Âi¡É¦Á  .
i=1
q.e.d.
outside q¦Ä1  = 1 holds for the top-node ¦Ä. therefore we have the following corollary:
corollary 1 let's child nodes.
                                           k outside inside .
		i=1

theorem 1 in conjunction with corollary 1 clearly shows that the computation of generalized outside probabilities of tabled atoms in a top-down manner that starts from the topnode ¦Ä and proceeds to lower layers in expl q¦Ä1  is exactly the same as the distributing evidence phase of bp in t with the root node ¦Ä  jensen  1; lauritzen and spiegelhalter  1; shafer and shenoy  1 . we illustrate below the computation of the generalized outside probabilities of atoms in rt1 w.r.t. the junction tree t1 in figure 1. outside q¦Á1¦Ã1 x1 x1  
  msw bn 1   x1  ¡Ä msw bn 1  x1 x1   x1  

outside q¦Â1¦Á1 x1 x1    outside q¦Á1¦Ã1 x1 x1   ¡¤
pdbt1  msw bn 1  x1   x1  
.
¡¡finally we confirm that since inside q¦Ä1  = 1 and every tabled atom occurs only once in the proof of q¦Ä1  the product of generalized inside-outside probabilities equals a marginal probability as follows.
	inside 	  outside q	 x  x   
1 conclusion
we have proved that bp in junction trees is nothing but the generalized io computation applied to junction trees  theorem 1 and 1  corollary 1 . this equivalenceis a generalization of the well-known equivalence between the forwardbackward algorithm and bp applied to hmms  smyth et al.  1  and provides a missing link between bp and pcfgs for the first time.
¡¡the most closely related work to ours is cfds proposed by mcallester et al.  mcallester et al.  1 . cfds are a propositional framework for probabilistic inference of markov random fields. they proved that a single algorithm can efficiently compute probabilities both for pcfgs and for bns in their framework but the relationship between bp and their algorithm remains unclear. since prism also generates propositional expressions  explanation graphs  from first order expressions by  tabled  search  it is an interesting future topic to relate cfds to prism.
