 
we propose a variant of the hierarchical constraint logic programming  hclp  scheme of borning  wilson  and others. we consider compositionality and incrementality in constraint logic programming  introduce hclp  and present wilson's proof that it is noncompositional. we define a scheme for composing together solutions to individual hierarchies and show that hierarchy composition can be expressed very simply using filtering functions over bags  multisets ; we present some properties of these functions  and define and explain an alternative to bag intersection which is also used in our scheme. we present an example involving three strength levels and show that we can achieve a close approximation to the solutions produced by standard hclp. 
1 	introduction 
the hclp  hierarchical constraint logic programming  scheme  borning et al  1; wilson and borning  
1  greatly extends the expressibility of the general clp scheme  jaffar and lassez  1 . there is also related work by satoh . a semantics has been defined for hclp  wilson and borning  1  and some instances of it have been implemented  menezes et a/.  1 . however  the semantics is not as natural as one might hope  and the implementations are inherently less efficient than those of clp. we believe that these two issues may be related  and suggest that an equally expressive scheme which gives similar but not identical answers may go some way to overcoming both of them. 
　therefore we propose a weakening of the semantics of hclp  in which the results of composing solutions to individual hierarchies approximate the solutions that would be obtained from combining the programs and starting from scratch. our semantics are adequate for some of the standard examples in the literature. they are definitely not sufficient to solve some of the other 
constraint satisfaction 
examples exactly  but our approximations are very reasonable. 
1 	incrementality and compositionality 
an important difference between logic programming languages and  say  theorem provers  is that the former are more efficient; expressibility and completeness are traded-off against efficiency. standard hclp is beautifully expressive  but the efficiency of its implementations may be poor  and its semantics lacks certain desirable properties. our proposal in this paper involves tradirigoff completeness to gain efficiency and more tractable semantics. in constraint logic programming  efficiency is discussed with reference to 'incrementality'  and semantics can be discussed with reference to compositionality  which is what we will do in the rest of this section. 
　compositionality is a desirable property for a system to have because it shows that the semantics of the system can be modelled by a mathematical system with formal properties  and because it suggests that implementations will be efficient. this is because compositionality implies decomposition ality  i.e. we can solve a complex problem by splitting it into simpler parts  solving them  and then composing the results into a complete solution. 
　whereas compositionality is a property of formal systems  incrementality is a  desirable  property of constraint logic programming implementations. there is no precise definition  but what it means is that the work required to add an extra constraint to the solution of a large set of constraints and check its satisfiability is proportional to the complexity of the addition  and not related to the size of the initial set. if a system is not incremental  then adding one more constraint to the solution of  say  1 constraints  involves as much work as solving the system of 1 constraints from scratch. 
　in fact  even in an 'incremental' system the amount of work required to deal with an additional constraint will probably depend on more than just the constraint itself: the number of variables in the original set may be relevant  as well as other factors. 
　we wish to suggest that compositionality is weaker than incrementality. a theory which has compositional 

semantics may have a non-incremental implementation  but a truly incremental implementation of a noncompositional formalism is not possible. what is more important than the distinction between incrementality and compositionality is the distinction between having both these properties and having neither  which is related to the distinction between 'sufficiently efficient' and 'unusably inefficient'. both logic programming and constraint logic programming are in principle sufficiently efficient  and they have compositional theories  see next section   and so compositionality is assumed to hold in general  almost without being mentioned. therefore  the focus in previous clp work has tended to be on incrementality alone  rather than on its relationship with compositionality. 
1 query composition in logic programming and clp 

figure 1: composing queries in logic programming 
consider the two programs in figure 1. they may be logic programs or constraint logic programs. the subscripts 1 1 are not part of the predicate names; they indicate that the query  - p x  will have up to three solutions {p1  p1  p1}  one from each of the three clauses of p. the composed query  - p x  & q x  will have up to six solutions  arising from  r   the composition  in some sense  of the elements of the cartesian product of the two sets of solutions. we could treat each of the {p1   r  qj  combinations independently  and make a distinction between this multiplicity and multiple solutions all arising from one branch  but we will just consider the collection of solutions as a whole  ignoring how they arose. 
　in standard logic programming  the composition of the solutions to two or more queries is the most general unifier  m.g.u.  of those solutions. calculating the m.g.u. of two solutions takes time related to the size of the solutions  and not related to the size of the original programs. similarly  in constraint logic programming  solving the conjunction of two output sets of constraints will depend on the size of the output  not on the size or complexity of the input constraints. 
　hierarchical clp is not compositional  and so incremental implementations have to make assumptions which may then need to be retracted  menezes .et a/.  1 . but before we can demonstrate this noncompositionality  it is necessary to provide an overview of hclp. 
1 	hierarchical constraint logic programming 
a good introduction to hclp can be found in molly wilson's phd thesis  1  chapter 1  or in the early reference  borning et al.  1 ; here is a brief overview. just as logic programming can be extended to clp  so clp can be extended to a hierarchical clp scheme including both 'hard' and 'soft' constraints. the hclp scheme is pararneterised not only by the constraint domain v but also by the comparator c  which is used to compare and select from the different ways of satisfying the soft constraints. 
an hclp rule has the form 

where t is a list of terms  p q1 .. . qm are atoms and l1cl ...  /ncn are labelled constraints. a program is a bag  multiset  of rules  and a query is a bag of atoms. the strengths of the different constraints are indicated by a non-negative integer label. constraints labelled with a zero are required  hard   while constraints labelled j for some  are optional  soft   and are preferred over those labelled k  where   a program can include a list of symbolic names  such as required  strongly-preferred  etc.  for the strength labels  which will be mapped to the natural numbers by the interpreter. if the strength label on a constraint is omitted  it is assumed to be required.  
　goals are executed as in clp  except that initially non-required constraints are accumulated but otherwise ignored1. if a goal is successful but with a non-unique answer  the accumulated hierarchy of optional constraints is then solved  which refines the valuations in the solution. the method used to solve the non-required constraints will vary from domain to domain  and for different comparators within a given domain. 
　the constraint store sigma  a set  is partitioned into the set of required constraints so and the set of optional ones si. the solution set for the whole hierarchy is a subset of the solution set of so  such that no other solution could be 'better'  i.e. for all levels up to k  sk is completely satisfied  and for level sk 1 this solution is better  in terms of some comparator  than all others. backtracking and incomparable hierarchies give rise to multiple possible solution sets  each a subset of the solution to so.  solutions in standard hclp are generally described using sets  not bags.  
　certain comparators can be used with any domain. for example  a 'predicate' comparator prefers one solution to another if it satisfies more constraints at some 'menezes et al. use an alternative strategy . 
	jampel and hunt 	1 


constraint satisfaction 

will use them in the next section to define rules for hierarchy composition; particular examples are discussed later  but in general filter functions will be denoted by f. note that the guard operator // is concerned with the relationship between different strength levels in a hierarchy  whereas filter functions select solutions within a given level.  similarly  in standard hclp the comparators compare solutions within a given level.  more details can be found in section 1  where we examine one particular filter at length. 
1 	two-level hierarchy composition 
we now come to the main interest of the paper. in this section we define an operation o which combines bags and sets in a certain way to form new bags. our interpretation of these rules is that o approximates the solutions to a composition of hierarchies. 
　let p and q be two programs  and p and q be queries with respect to each of those programs. we will also use capital letters to refer to the entire hierarchy  i.e. program  query  and solutions . let so p  be the set of valuations which are solutions to the required constraints in the hierarchy  and let s1 p  be the set of valuations satisfying both the required and the  one level of  optional constraints. note that s  p   so p . similarly s1 q  c so q . define the solution set for the query p as a tuple containing the solution sets for each level of the hierarchy: s p  =  s1 p   s1 p  . 
　note that the solutions to a single  branch of a  query are assumed to form a set  or  rather  a set-like bag . the multiplicities will arise when the solutions to separate queries are composed using bag union.  treating solutions to a single query as bags would give more weight to duplicated solutions from one hierarchy  rather than treating equally all the hierarchies to be composed.  
　later we will use lp & q' to refer to a standard hclp query  solved by starting from scratch  and compare it to po q  which has solutions defined as follows: 
definition  composeol : 

the reason for guarding the two si's with so p 1 q  is to remove solutions for p which are inconsistent with q's required constraints and vice versa  although remember that at this stage we should not really be discussing hierarchies and solutions  because we are still merely manipulating bags.  in fact  as s1 p  c so p   it is enough just to guard s1 p  with s1 q  and vice versa  as can be shown using absorption and distributivity properties  but this does not generalise neatly to compositions of more than two hierarchies.  
　note that we type-coerce sets to be set-like bags whenever we wish to do bag operations on them. note also that in the definition of s1 p1 q   we have not included an application of set. we consider it to be the very last 

　although o is commutative  i.e. poq - qop   it is not associative  because of the filter functions  i.e. po qor  =  p o q  o r = p o q o r. only p o q o r is 'correct' for our purposes  which implies the following: if we have calculated the composition poq but suspect that we may later need to compose with another hierarchy  we cannot discard the solutions to p and q  but must store them to be able to calculate poqor subsequently. thus we trade space against time compared to standard hclp. 
　if there are no constraints at the required level  the solution set is the entire domain  the cartesian product of the domains of all the variables  i.e.  it can be seen that guarding any bag with this universal set using // will not have any effect:  -a. if there are no constraints at one of the optional levels  the solutions for that level will just be the same as for the next higher level i.e. . therefore the rules we have defined here will work for hierarchies with arbitrarily many or few constraints at any given level. 
 in hclp  the key difference between required and nonrequired constraints is that the former can cause failure to occur. in other words  the required constraints may have an empty solution set  but no weaker constraints can cause a failure if stronger constraints have been satisfied. in our composition rules  in  a represents the solutions for a weaker level than b  and yet the definition of  allows the possibility of being empty even if b is not  in the case that . thus our rules appear to allow failure to arise from optional constraints. in fact  as we define the solution s to be the tuple  so  s1 ...  sn  and not just its final element sn  it is not a problem if one of the elements of s is empty: 
	jampel and hunt 	1 

the solution that is offered to the user is no longer the final element of the tuple  but the final non-empty element. thus this aspect of hclp is not present in our logic  but is left until the interpretation. 
1 the filter fmax 
the rules defined in the previous section are parameterised by filter functions. we now define one particular filter function fmax  which is the most interesting when compared to hclp's 'locally-predicate-better' comparator  wilson and borning  1 . fmax removes those elements of a bag which do not occur a maximal number of times. in other words  if some elements occur once in a given bag  and some elements occur twice  fmax defines the bag containing only those elements occurring twice. could take constant time  or at worst time related to the size of the smaller of the two bags. filtering and guarding will  admittedly  take time bounded by the size of the union of the two bags. but all these operations  intersection  union  filtering  etc.  are computationally very cheap compared to constraint solving. they may be considered unit time operations when measured on the scale of constraint solving. therefore  when compared to the cost of composing the two programs and queries and starting from scratch  it is reasonable to say that our scheme is incremental. 
1 example and comparison with hclp 
the multi-compose definitions from section 1 can be unfolded as follows: 


constraint satisfaction 

ing {1   x   1} as short-hand for the uncountably infinite set-like bag { x = 1    x = 1    x = 1  ...   x = 1    x - 1  ...}  but it is obvious within this notation that the bag union of  say  {1   x   1} and {1   x   1} has 1   x   1 and 1   x   1 with multiplicity 1  and 1   x   1 with multiplicity 1.  
　secondly  if we initially apply compose1 to p and q and then apply it again to poq and r  s1  po q  o r  will be the same as s1  p o g o r   with different muliplicities at the s1 level . but if instead we compose p with qor  then s1 po qor   = { x = 1   x = 1  which differs from s1   p o q  o r  and is a worse approximation to the result given by standard hclp. this non-associativity gives rise to multiple possible composition orders and hence solutions  which is why we define the only correct answer to be the one based on composing all three subsolutions simultaneously. 
　thirdly  and most importantly  if we apply compose1 all at once  we get an answer which differs from the standard hclp solution  because it omits the valuation which maps x to 1. any system which calculates exactly the same answers as hclp will be vulnerable to wilson's proof of non-compositionality  discussed earlier in section 1   so the question is whether compose1 gives a reasonable approximation. we believe that it does; in this example  the only valuation omitted is one which was not present in the original sub-solution containing the constraint which gave rise to it. in r  the x = 1 possibility for x div 1 was dominated by the strong constraint x   1. in standard hclp  this domination is weakened by other strong constraints from completely separate hierarchies. in other words  the only solution not calculated by compose1 is one which we probably do not want anyway! 
1 	conclusions and further work 
we have seen that by storing the intermediate solutions to a hierarchy in a tuple  s1 s1  .. .  sn   we can find an approximate solution to its composition with other hierarchies. we use simple filtering functions and bag operations  with clear mathematical characterisations  which avoids the need to invoke the constraint solver and start from scratch calculating a solution to the combination of the constraints. the non-associativity of filter functions means that the method is not truly compositional  but it does avoid the need to invoke the constraint solver. in general  constraint satisfaction is of exponential complexity  compared to which filtering and set operations are very cheap indeed. therefore we feel justified in calling this scheme 'incremental'. 
　thus we have developed a variant of hierarchical clp in which the solution to a composed problem is defined in terms of the solutions to its sub-problems. the operations involved are simple to understand and efficient and closely approximate the answers we would obtain from standard hclp  while avoiding its computational expense and complex semantics. 
　in the future we wish to extend this scheme to take account of error sequences  and hence bring different comparators within the scope of our filtering scheme. we would like to investigate constraint deletion and dynamic constraint satisfaction  which are difficult in most formalisms but should be made easier by the modular nature of our tuple representation of solutions. 
　more generally  we are investigating inconsistencies arising from the composition of clp programs i.e. programs without hierarchical strength labels. we wish to explore the parallels between composition of these unlabeled systems and composition of the labelled systems discussed in this paper. 
acknowledgements 
thanks to rob scott  david gilbert  steven eker and bernie cohen for helpful discussions on clp and hclp. 
