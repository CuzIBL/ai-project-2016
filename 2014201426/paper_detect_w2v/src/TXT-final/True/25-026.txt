 
whilst much emphasis in ai has been placed on the use of goals in problem solving  less emphasis has been placed on the role of perception and experience. in this paper we show that in the domain that may be considered the most abstract  namely mathematics  that perception and experience play an important role. the mathematician has a vast amount of mathematical knowledge  and yet is able to utilise the appropriate knowledge without difficulty. we argue that it is essential to model how well the knowledge is grasped  so that mathematical knowledge can grow from partial knowledge to important results that are easily accessed. not all knowledge is equal in its importance  and we argue that perception and experience play a key role in ordering our knowledge. features play a role in both representing the information from the environment  and indexing the knowledge of our memories  but a key requirement is that the features should be dynamic and not be built in. this research is implemented in the program mu  the mathematics understander  which utilises the cms  contextual memory system. mu has sucessfully  read  university level texts in pure mathematics  checking the proofs and solving the simple problems. 
1. introduction 
problem solving has been thought of as the primary examplar of intelligence  and has been central to work in artificial intelligence from the early work of newell and simon's gps  to expert systems and theorem proving. laird  rosenbloom and newell's soar  1  has problem solving as the cornerstone of its architecture. however  whilst expert systems  and in particular lenat and feigenbaum  1   have shown the importance of a large amount of knowledge to give systems power  theorem proving in contrast has tended to concentrate on general methods such as resolution  tempered by metalevel reasoning  eg bundy 1 . given the evidence that expert problem solving tends to have access to large amounts of knowledge and tends to use shallow search methods  it is surprising that much of the ai community continues to pursue methods which are knowledge thin rather than knowledge rich. 
　　it can be argued that if one is concerned with discovering powerful machine problem solving methods  then these do not necessarily have to be similar to human problem solving methods. furthermore  it is clearly more elegant to have neat general problem solving methods  rather than a collection of special purpose methods. however  schank  1  has argued that even if one's goal is to build intelligent machines  it is a good first step to model how humans perform the task. we argue that the neat approaches to problem solving do not sufficiently model genuine ecological tasks  are of insufficient power  and since they take little account of learning are inadequate accounts of human cognition. 
　instead we present an alternative thesis on cognition which places learning at the centre of what it is to be intelligent  rather than placing problem solving at the centre. interestingly  this is a view much nearer to alan turing's thought  1   than his turing machine conception of computation. turing wanted to know not only how machines could solve problems  but how they could learn. certainly soar places great impotance on learning  but it is in our view an impoverished view of learning to see it only as search within a problem space. 
   for too long perception has been seen as almost a separate faculty from the mainstream of al and cognition  and yet degroot  1  and chase and simon  1  have convincingly showed that expert knowledge in chess is very largely a matter of 1 perceptual features. one could argue that board games are naturally prone to perceptual processing  but we show that the same arguments apply in the domain of pure mathematics. given the highly abstract nature of pure mathematics  if perceptual features play an important part in problem solving in this domain  it may well be the case that they play an important role in many other types of problem solving. 
   it is easy to demonstrate that perception plays an important part in problem solving. consider the following proposition: 
	 1  
 1  is difficult to recognise  but by using the usual letter names as in  1: 

 
we have a proposition that is easily recognised by mathematicians as the definition of the limit of the sequence xn as n tends to infinity is x. however  since  1   is obtained from  simply by a change of letters  it is logically equivalent to  1  . thus there is more to problem solving than logic. what we are arguing is that expressons such as act as perceptual features which enable the expert to rapidly recognise the mathematical result. 
　it is obvious that experience plays a role in an expert's ability to solve problems. however  apart from our own work  we believe there is no convincing account of how this might work. too many models of expertise are relatively static  and yet all expertise must have been learned at some time  and experts continue to grow in expertise. through the study of education  and in particular mathematics text books  one can see how knowledge is slowly acquired. we argue that in text books  any particular mathematical result goes through three stages of usage in problem solving: 
1. the result is stated explicitly  for example: 

1. the result is used implicitly  for example: 

 ie the same as  1  but without the explanation . 
1. the result is used in compound inferences  e.g.: 

   not all mathematical results get beyond stage  1   some results may only be used a few times  and may then be forgotten. in contrast  results which are frequently used become so well known through their stage  1  usage  that eventually they get used in stage  1 . thus  ironically the most important results are the ones which are not mentioned at all  precisely because they are so well known. 
　if all of an expert's knowledge was of equal importance  and therefore equally easy/difficult to access  most experts could not function at all. yet most truth maintenance systems work on this basis. in contrast we argue that the expert has a perceptual system and memory so organised that important results are easily recognised and retrieved. furthermore  we will show how the contextual memory system  cms   furse 1  furse and nicolson 1  allows a continuing change of the perceptual and memory systems  so that the novice can become the expert through sufficient learning experience. 
　the cms is a network architecture of features and items. the features are used to both encode the external object in the environment  and to index items in memory. both features and items have an energy level  and the links between features and items have a strength. the novel characteristic of this architecture is that the features are generated dynamically from the environment  and the configuration of connections is frequently changed during memory processes. 
1 	cognitive modeling 
1. pure mathematics 
pure mathematics is a good domain in which to study problem solving since although it is a genuinely ecologically valid task  it uses little common sense knowledge  and all the mathematical knowledge has been acquired through learning. indeed  some branches of pure mathematics  such as group theory  can be learned by arts undergraduates  illustrating the point that the subject can be learned with little prior knowledge. within a course a large body of knowledge is built up which is used to understand proofs and solve problems. 
   this research has concentrated on modelling the understanding of mathematics texts. since about the beginning of this century pure mathematics texts have taken the form of definitions  theorems and lemmas  a lemma is a little theorem   their proofs and exercises. clearly it would be a large scale exercise to develop a program to read verbatim mathematics texts  and so the natural language component has been factored out by rewriting the texts by hand in the language fel  formal expression language   furse  1 . fel has a formal syntax and is very expressive  as the example in figure 1 shows. 

there are many levels of understanding a mathematics text  but this research has focused on the ability to check proofs by giving explanations of the steps and solving the simple problems. the problem solver uses a number of built-in general heuristics and uses the cms to filter the mathematical results to ensure there is no combinatorial explosion. many theorem provers model an artificial task by carefull feeding of only the results needed to solve the problem. in contrast  mu has access to the whole body of mathematical knowledge it has learned at the time  and uses its experience to focus on the problem in hand. 



homomorphism implying that there was a normalsubgroup. thus these features enable a rich representation of partial knowledge. with sufficient features the original propostion can be reconstructed  and given the development of sufficiently specialised features  it can be represented exactly and compactly. 1. learning and experience 
not only does the expert mathematician learn a large body of mathematical results  but also a large number of features of these results. this then ensures that results are easily recongised and retrieved. given a mathematical step such as: 

the mathematician has little difficulty in noticing that the result: 

has been used  or at least in checking the forward reasoning on applying this inference rule to produce the intermediate step: 
　given that the mathematician has hundreds or even thousands of results that might be relevant at any particular step  it is an important computational problem how the appropriate result is retrieved without difficulty. we argue that it is patterns or features that the mathematician learns to recognise. thus  in the above example  the mathematician has no difficulty in seeing the pattern  x - y  x + y  as being the left hand side of a well known result. 
   if this result has been used sufficiently often then a specialised feature such as has-form-
may have been stored with which the result is indexed and retrieved. it remains to explain how items are first stored in memory in terms of features  and how these features change through experience. 
　as explained in the previous section  when a result is first processed by the cms it is broken up into a large number of features using knowledge free methods. some of these features may already have been stored  others will be completely novel. the cms stores a mixture of old and new features  where the old ones are selected from the ones with highest energy  all features being given an energy value which is adjusted with utilisation. if only old features were used  then we would soon be in a closed box representation  but at the time of storage one does not know which of the new features may be useful. for example  consider the definition of a normal subgroup: definition. n isa normal-subgroup of g iff n isa subgroup of g and 
here  on initial encoding features that might be used could include: has-form- * a b  has-form-   subgroup a b   but the crucial feature is: has-form- * a  * bjinv a    
but it is only through experience that the mathematician learns of the importance of recognising the feature gng-1. 
   within the cms  when a result is retrieved  for example in proof checking or problem solving   the features are adjusted to ensure that retrieval is more efficient in future. recall involves first computing the features of the probe. for example  in trying to prove that: 
log  x - y  x + y l + 1og y  = 1og x  the system first searches for a whole matching result before just trying to reason from the left hand side. in reasoning from the left hand side  the lhs acts as the probe for the cms  generating features such as: 
lhs-has-form- log a  has-form-  *  a b  lhs-has-form-|- a bl lhs-lhs~has-form- * a b  
all these features must be existing ones  for clearly it is pointless to use a novel feature as an index to old knowledge. the feature generating mechanisms generate many features  and a subset is chosen of those of highest energy. 
　in the second stage of recall this set of features is used to index a number of mathematical results. results which do not match the probe are considered failures. ideally the features should only index relevant results  which can be applied  but this only comes through experience as the feature space changes. the matching results are then applied and the outcome which has the highest plausibility in terms of being nearer to the goal and a simpler expression is chosen. 
   in the third stage of recall learning takes place to ensure that the found item is more easy to retrieve in future. this means ensuring that the same set of input features should be more likely to retrieve the found item than the failures. this is achieved by four processes: 
  storing the uncomputed features 
  encouraging the useful features 
  discouraging the unuseful features 
  creating new distinguishing features 
   most of the features used in the probe will already index the found item  but some of them may have arisen from storing other items  and may not be connected to the found item. these are known as uncomputed features  and provided the found item possesses the feature  they are now stored. by this means new connnections between features and items are regularly being made during retrieval. 
   useful features are features which index the found item but not the failures. these features are encouraged by increasing both their energy and the link strength between feature and found item. conversely  unuseful features index the failures but not the found item  and have their energy decreased. 
   the final method of adjusting the cms involves the dynamic creation of novel features which index the found item but not the failures  and do not already exist. this is achieved by means of comparing the large 

feature sets of the found item and the failures generated 
1 	cognitive modeling 

by bottom-up methods. by such a mechanism  specialised features such as can be generated. 
　by these means the cms ensures that results which are important have a number of high energy specialised features so that such results are recognised easily. thus as a result is used through the stages  l - 1  described above  so its representation changes from initially being encoded only partially in terms of its features  and likely to be retrieved with other similar results  to ultimately being a result with specialised features easy to recall and use. see furse  1  for more details of the cms. 
1. the mathematics understander 
the mathematics understander  mu    furse 1a   is a computer program which utilises the cms to  understand  mathematics texts expressed in fel. the original text is translated by hand into fel  which is then input to the program. mu parses the input using a parser whose syntactic knowledge is built up dynamically from definitions and stored in the cms. the parsed input is fed to the proof checker and problem solver which utilises the acquired knowledge in the cms to produce explanations of the steps and solutions to the problems  see fig. 1 . 
mu thus has parsing  proof checking and problem solving knowledge built in  but no knowledge of mathematical results. all the mathematical results arc acquired through the reading of texts. fig. 1 shows an example of a problem solution generated by mu. the built in heuristics used in problem solving are: 
  expand a definition 
  break a compound step into parts 
  suppose the left hand side 
  simplify 
   simplification involves the application of known results using the cms to only retrieve relevant results rather than all possibly applicable results. the results retrieved are applied and their plausibility measured in terms of nearness to the goal and simplicity. the result which achieves the highest plausibility is the one chosen  and if necessary  mu will backrack  but this is very rarely found to be necessary. 
　mu is implemented in macintosh common lisp and runs on apple macintosh computers. the cms can be displayed in a graphical format  and navigated through. it is also possible to set parameters for individual modelling. see fig. 1. mu has successfully read texts in group theory and classical analysis  and solved simple problems in group theory. 

education in pure mathematics is often a process of the student understanding the proofs of theorems and solving the problems. this experience enables the student to develop appropriate features so that relevant results can easily be retrieved when necessary. the lazy student who skips the proofs and the simple problems runs the risk of not being able to solve the harder problems. if mu  reads  only the definitions and theorems  and skips the proofs and simple problems  it too cannot retrieve the results needed when trying to solve the problem in figure 1 and gives up. 
1. discussion 
in some sense an expert  sees  that in solving a problem a particular step should be taken. it seems implausible that a large scale search takes place of knowledge which might be useful. rather the knowledge required almost springs out from the problem. it is this notion which places perception and learning centre stage in cogntion which this research attempts to address. we have shown how in the domain of pure mathematics expertise can be captured with a large body of knowledge indexed by features. further the cms allows the modelling of how these features are learned through experience. 

   naturally the cms uses several ideas which are wellknown in the literature. for instance  the feature recognition mechanism has similarities with epam  feigenbaum and simon  1 . the energy mechanism resembles the activation used by anderson in act-r and act*  1   though the there is no spreading activation in the cms. we believe  however  that the cms is distinctive in combining all these ideas within an integrated environment. 
　the cms can  in principle  be applied to other domains than mathematics  since there is no built in mathematics in its construction. the major requirement is the development of appropriate feature generating mechanisms. work is in hand in applying the cms to the learning of board games. 
　research in neural networks has brought learning back to the centre of work in artificial intelligence  and there is a clear emphasis in their application to perceptual classification problems. however  to our knowledge there has not been much success in applying such architectures to problem solving in domains as complex as pure mathematics. furthermore  it could be argued that a neural network is restricted in its internal representations by the features used as the input to the network. in contrast  the cms generates its features dynamically from the environment. 
the other main competitors to the cms model are 
anderson's act* model and laird  rosenbloom and 
newell's soar. whilst both architectures model problem solving  and in particular model goal based reasoning  which the cms does not model  the focus is quite different. both models are essentially based on a production systems architecture  and this ultimately limits their scope for adaptation. although both act* and soar model learning  they do not appear to model declarative learning which the cms is designed for. anderson has concentrated on modelling how knowledge becomes proceduralised  but does not address the question of how the initial knowledge is learned in the first place. newell defined learning as search within a problem space  but as both norman  1   and boden  1   have remarked  this seems an impoverished view of learning. pure mathematics cannot be represented as a problem space since new constructs are continually being introduced in a relatively ad hoc manner. soar appears to want the domain to be precharacterised as a problem space in advance  before learning can take place. a similar problem occurs with explanation based generalisation whereby a domain theory is required in advance. however  human learning is much more piecemeal  and teachers almost never map out in advance a characterisation of the domain to be learned. 
　　in conclusion  perception and experience play an essential part in problem solving. it is not sufficient to be an expert to know a lot of facts. the expert also has to be able to recognise when they are relevant and be able to retrieve them. 
1 	cognitive modeling 
1. 