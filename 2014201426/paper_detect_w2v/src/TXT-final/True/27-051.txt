an efficient algorithm for surface generation 
c h r i s t e r s a m u e l s s o n * 
universitat des saarlandes  fr 1  computerhnguistik 
posfach 1  d-1 saarbnicken  germany internet c h r i s t e r   c o l i u n i - s b de 

a b s t r a c t 
a method is given that  inverts  a logic grammar and displays it from the point of view of the logical form  rather than from that of the word string lr-compiling techniques are used to allow a recursive-descent generation algorithm to perform  functor merging  much in the same way as an lr parser performs prefix merging this is an improvement on the semantic-headdnven generator that results in a much smaller search space the amount of semantic lookahead can be varied  and appropriate tradeoff points between table size and resulting nondeterminjsm can be found automatically 
1 	i n t r o d u c t i o n 
with the emergence of fast algorithms and optimization techniques for syntactic analysis  such as the use of explanation-based learning in conjunction with lr parsing  see  samuelsson & rayner 1  and subsequent work  surface generation has become a major bottleneck in nlp systems surface generation is the inverse problem of syntactic analysis and subsequent semantic interpretation the latter consists in constructing some semantic representation of an input word-string based on the syntactic and semantic rules of a formal grammar in this article  we will limit ourselves to logic grammars that attribute word strings with expressions in some logical formalism represented as terms with a functor-argument structure the surface generation problem then consists in assigning an output word-string to such a term in general  both these mappings are manyto-many a word string that can be mapped to several distinct logical forms is said to be ambiguous a logical form that can be assigned to several different word strings is said to have multiple paraphrases 
　we want to create a generation algorithm that generates a word string by recursively descending through a logical form  while delaying the choice of grammar rules to apply as long as possible this means that we want 
 the work presented in this article was funded by the 
n1  bidirektionole lingoistische deduktion  bild   project in the sonderforschnngbbereich 1 hunituchc intelligent- wissenabasierte systeme 
1 	natural language 
to process different rules or rule combinations that introduce the same piece of semantics in parallel until they branch apart this will reduce the amount of spurious search  since we will gain more information about the rest of the logical form before having to commit to a particular grammar rule 
　in practice  this means that we want to perform  functor merging  much in the same ways as an lr parser performs prefix merging by employing parsing tables compiled from the grammar one obvious way of doing this is to use lr-compilation techniques to compile generation tables this will however require that we reformulate the grammar from the point of view of the logical form  rather than from that of the word string from which it is normally displayed 
　this gives us the following working plan we will first review basic lr compilation of parsing tables in section 1 the grammar-inversion procedure turns out to be most easily explained in terms of the bern an tic-head driven generation  shdg  algorithm we will therefore proceed to outline the shdg algorithm in section 1 the grammar inversion itself is described in section 1  while lr compilation of generation tables is discussed in section 1 the generation algorithm is presented in section 1 together with techniques for optimizing the generation tables section 1  finally  discusses the findings 
1 	lr compilation for parsing 
lr compilation in general is well-described in for example  aho ct al 1   pp 1 here we will only 
sketch out the main ideas 
　an lr parser is basically a pushdown automaton  l e   it has a pushdown stack in addition to a finite set of internal states and a reader head for scanning the input string from left to right one symbol at a time the stack is used in a characteristic way the items on the stack consist of alternating grammar symbols and states the current state is simply the state on top of the stack the most distinguishing feature of an lr parser is however the form of the transition relation - the action and goto tables a nondetermimstic lr parser can in each step perform one of four basic actions in state 1 with lookahead symbol1 sym it can 
   *the lookahead symbol is the next symbol id the input siring  l e   the symbol under the reader head 


	samuelsson 	1 

　a simple semantic-head-dnved generator might work as follows given a grammar symbol and a piece of logical form  the generator looks for a non-chain rule with the given semantics the constituents o  the rhs of that rule are then generated recursively  after which the lhs is connected to the given grammar symbol using chain rules at each application of a chain rule  the rest of the rhs constituents  1 e   the non-head constituents  are generated recursively the particular combination of connecting chain rules used is often referred to as a chain the generator starts off with the top symbol of the grammar and the logical form corresponding to the 
string that is to be generated 
　the inherent problem with the shdg algorithm is that each rule combination is tried in turn  while the possibilities of prefiltering are rather limited  leading to a large amount of spurious search the generation algorithm presented in the current article does not suffer 
from this problem  what the new algorithm in effect does is to process all chains from a particular set of grammar symbols down to some particular piece of logical form in parallel before any rule is applied  rather than to construct and try each one separately m turn 
1 	grammar inversion 
before we can invert the grammar  we must put it in normal form we will use a variant of chain and nonchain rules  namely functor-introducing rules corresponding to non-chain rules  and argument-filling rules corresponding to chain rules the inversion step is based on the assumption that there are no other types of rules 
　since the generator will work by recursive descent through the logical form  we wish to rearrange the grammar so that arguments are generated together with their functors to this end we introduce another difference list a1 and a to pass down the arguments introduced 
1 	natural language 
figure 1 sample grammar in norma  form 
by argument-filling rules to the corresponding functorintroducing rules here the latter rules are assumed to be lexical  following the tradition in gpsg where the presence of the subcat feature implies a preterminal grammar symbol  see  gazdar ct al 1   p 1   but this is really immaterial for the algorithm 
　the grammar of figure 1 is shown in normal form in figure 1 the grammar is compiled into this form by inspecting the flow of arguments through the logical forms of the constituents of each rule in the functorintroducing rules  the rhs is rearranged to mirror the argument order of the lhs logical form the argumentfilling rules have only one rhs constituent - the semantic head - and the rest of the original rhs constituents are added to the argument list of the head constituent note  for example  how the np is added to the argument list of the vp in rule 1  or to the argument list of the p in rule 1 this is done automatically  although currently  the exact flow of arguments is specified manually 
　we assume that there are no purely argument-filling cycles for rules that actually fill in arguments  this is obviously impossible  since the number of arguments decreases strictly for the slightly degenerate case of argument-filling rules which only pass along the logical form  such as the  vp l  -   v  l  rule  this is equivalent to the off-line parsability requirement  see  kaplan & bresnan 1   pp 1 1 we require this in order to avoid an infinite number of chains  since each possible chain will be expanded out in the inversion step since subcategonzation lists of verbs are bounded in length  patr ii style vp rules do not pose a serious problem  
   *if the rhs v  were a vp  we would have i. purely argument-filling cycle of length 1 

lr compilation for generation 

which on the other hand the  adjunct-as-argument  approach taken in  bouma & van noord 1  may do however  this problem is common to a number of other generation algorithms  including the shdg algorithm 
　let us return to the scenario for the shdg algorithm given at the end of section 1 we have a piece of logical form and a grammar symbol  and we wish to connect a non-chain rule with this particular logical form to the given grammar symbol through a chain we will generalize this scenario just slightly to the case where a set of grammar symbols is given  rather than a single one 
　each inverted rule will correspond to a particular chain of argument-filling  chain  rules connecting a functor-introducing  non-chain  rule introducing this logical form to a grammar symbol in the given set the arguments introduced by this chain will be collected and passed down to the functors that consume them in order to ensure that each of the inverted rules has a rhs matching the structure of the lhs logical form the normalized sample grammar of figure 1 will result in the inverted grammar of figure 1 note how the right-hand sides reflect the argument structure of the left hand-side logical forms as mentioned previously  the collected arguments are currently assumed to correspond to functors introduced by lexical entries  but the procedure can readily be modified to accommodate grammar rules with a non-empty rhs  where some of the arguments are consumed by the lhs logical form 
　the grammar inversion step is combined with the lrcompilation step this is convenient for several reasons firstly  the termination criteria and the database maintenance issues are the same in both steps secondly  just as when compiling lr-parsing tables  the compiler operates on sets of dotted items each item consists of a partially processed inverted grammar rule  with a dot marking the current position here the current position is an argument position of the lhs logical form  rather than some position in the input string 
　new states are induced from old ones for the indicated argument position  a possible logical form is selected and the dot is advanced one step in all items where this particular logical form can occur in the current argument position  and the resulting new items constitute a new state all possible grammar symbols that can occur in the old argument position and that can have this logical form are then collected from these  all rules with a matching lhs are invoked from the inverted grammar each such rule will give rise to a new item where the dot marks the first argument position  and the set of these new items will constitute another new state if a new set of items is constructed that is more specific than an existing one  then this search branch is abandoned and the recursion terminates if it on the other hand is more general  then it replaces the old one 
　the state-construction phase starts oft  by creating an initial set consisting of a single dummy item with a dummy top grammar symbol and a dummy top logical form corresponding to a dummy inverted grammar rule in the sample grammar this would be the rule {s'tt{l  w1lw e t  - {s z w1lw c c  the dot is at the beginning of the rule  selecting the first and only argument the rest of the states are induced from this one the first three states resulting from the inverted grammar of figure 1 are shown in figure 1  where the difference lists representing the word strings are omitted 
the sets of items are used to compile the generation 
	samuelsson 	1 

tables in the same way as is done for lr parsing the goto entries correspond to transiting from one argument of a term to the next  and thus advancing the dot one step the reductions correspond to applying the rules of items that have the dot at the end of the rhs  as is the case when lr  parsing there ib no obvious analogy to the shift action - the closest thing would be the descend actions transiting from a functor to one of its arguments 
　note that there ib no need to include the logical form of each lexicon entry in the generation tables instead  a typing of the logical forms can be introduced  and a representative of each type used in the actual tables  rather than the individual logical forms this decreases the size of the tables drastically for example  there is no point in distinguishing the states reached by traversing john  nary and par is  apart from ensuring that the correct word is added to the output word-1tnng this is accomplished much in the same way as preterminals  rather than individual words  figure in lr-parsing tables 
1 	a new generation algorithm 
the generator works by recursive descent through the logical form while transiting between internal states it is driven by the descend  goto and reduce tables a pushdown stack is used to store intermediate constituents 
　when generating a word string  the current state and logical form determine a transition to a new state  corresponding to the first argument of the logical form  through the descend table a substring ie generated recursively from the argument logical form  and this constituent is pushed onto the stack the argument logical form  together with the new current state  determine a transition to the next state through the goto table the next state corresponds to the next argument of the original logical form  and another substring is generated from this argument logical form  etc when no more arguments remain  an inverted grammar rule is selected nondeterministicaily by the reduce table and applied to the top portion of the stack  constructing a word string corresponding to the original logical form and completing this generation cycle 1 
　the logical form can be inspected down to an arbitrary depth of recursion when compiling the sets of items  and this parameter can be varied this is closely related to the use of lookahead symbols in an lr parser  increasing the depth is analogous to increasing the number of lookahead symbols the amount of semantic lookahead is reflected in the goto and descend entries the key parameter influencing the generation speed 1 the amount of nondetermimsm in each  reductive state    1 e   each state where the dot is at the end of some rule increased semantic lookahead will split potential nondetermimsm in the resulting reductive states into distinct seta of items  yielding reductive states with less nondetermimsm 
　no semantic lookahead would mean only taking the functor of the logical form into consideration  and in the 
　　thu u a boltom-up rule invocation scheme it could easily be modified so that a rule is instead applied before constructing the substrings recursively  resulting in & topdown rnle-idvocation scheme  which might be a good idea in conjunction with semantic lookahead ′ee the following 
1 	natural language 

running example  a typical action table entry would be doac nd l  mod      1  1 this would mean that the generator would operate on state 1 of figure 1 when generating from the first argument of the nod      term  and both the s alternative and the  merged  vp alternative   would be attempted nondetermimsticaliy 
　by taking the arguments of the logical form into account  the degree of nondeterminism can be reduced  and for the sample grammar used throughout this article  it is eliminated completely in the example  if the second argument of the mod      term is ynq  then only the s alternative will be considered when generating from the first argument  since the relevant states and descend entries will be those of figure 1 
　the optimal depth may vary for each individual table entry  and even within it  and a bcheme has been devised to automatically find such an optimum by inspecting the number of items left in each reductive state the bcheme employs a greedy algorithm with iterative deepening to thib end in the running example  the first argument ofnod      contributes no important information when descending from state i  while the second one does the scheme correctly finds the optimal depths when transiting from state 1  resulting in the state 1 and descend entry of figure 1 this is described in detail elsewhere 
1 	summary and discussion 
the proposed algorithm is an improvement on the semantic-head-driven generation algorithm that allows  functor merging   l e   enables processing various grammar rules  or rule combinations  that introduce the same semantic structure simultaneously  thereby greatly reducing the search space the algorithm proceeds by recursive descent through the logical form  and using the 
*here a   denotes a don't-care variable 
terminology of the shdg algorithm  what the new algorithm in effect does is to process all chains from a particular set of grammar symbols down to some particular piece of logical form in parallel until a reduction is attempted  rather than to construct and try each one separately in turn this requires a grammar-inversion technique that is fundamentally different from techniques such as the essential-argument algorithm  see the following  since it must display the grammar from the point of view of the logical form  rather than from that of the word string lr-compilation techniques accomplish the functor merging by compiling the inverted grammar into a set of generation tables 
　the set of applicable reductions can be reduced by using more semantic lookahead  at the price of a larger number of internal states  and there is in general a tradeoff between the size of the resulting generation tables and the amount of nondeterminism when reducing the employed amount of semantic lookahead can be varied  and a scheme has been devised and tested that automatically determines appropriate tradeoff points  optionally based on a collection of training examples 
　the grammar inversion rearranges the grammar as a whole according to the functor-argument structure of the logical forms other inversion schemes  such as the essential-argument algorithm  see  strzalkowski 1  or the direct-inversion approach  see  mmnen et al forthcoming   are mainly concerned with locally rearranging the order of the rhs constituents of individual grammar rules by examining the flow of information through these constituents  to ensure termination and increase efficiency although this can occasionally change the set of rhs symbols in a rule  it is done to these ends  rather than to reflect the functor-argument structure 
　some hand editing is necessary when preparing the grammar for the inversion step  but it is limited to specifying the flow of arguments in the grammar rules furthermore  this could potentially be fully automated 
　although the sample grammar used throughout the article is essentially context-free  there is nothing in principle that restricts the method to such grammars in fact  the method could be extended to grammars employing complex feature structures as easily as the lrparsing scheme itself  see for example  nakazawa 1   and this is currently being done 
　the method has been implemented and applied to much more complex grammars than the simple one used as an example in this article  and it works excellently although these grammars are still too naive to form the basis of a serious empirical evaluation lending substantia  experimental support to the method as a whole  it should be obvious from the algorithm itself that the reduction in search space compared to the shdg algorithm is most substantial nonetheless  such an evaluation is a toppriority item on the future-work agenda 
acknowledgements 
i wish to thank greatly gregor erbach  jussi karlgren  manny rayner  hans uszkoreit  mats wiren and the anonymous reviewers of acl  eacl and 1jcai for valuable comments and suggestions to improvements on draft and previous versions of this article and other related publications special credit is due to kristma striegmtz  who assisted with the implementation of the system 
r e f e r e n c e s 
 aho et al 1  alfred v aho  ravi sethi and jeffrey 
d u1 man compilers  principles  techniques and tools addison-wesley 1 
 alshawi  ed  1  hiyan alahawi  editor the core language engine mit press 1 
 bouma u van noord 1  gosse bouma and gertjan van noord  constraint-based categonal grammars   procs ssnd annual meeting of the association for 
	computational linguistics  pp 	1  acl 1 
 gazdar et al 1  gerald gazdar  ewan klein  geoffrey pullum  and ivan sag generalized phrase structure grammar harvard university press 1 
 kaplan & bresnan 1  ronald m kaplan and joan bresnan  lexical-functional grammar a formal system for grammar representation1' in joan bresnan  editor  the mental representation of grammatical relations  pp 1 mit press 1 
 minnen et al forthcoming  guido minnen  dale gerdemann and erhard hinrichs  direct automated inversion of logic grammars  to appear in new generation computing  1 
 nakazawa 1  tsuneko nakazawa  an extended lr parsing algorithm for grammars using feature-based 
syntactic categories  procs 1th conference of the european chapter of the association for computational linguistics  pp 1  acl 1 
 samuelsson 1  christer samuelsson  notes on lr parser design  procs 1th int conference on convputational linguistics  pp 1  iccl 1 
 samuelsson k rayner 1  christer samuelsson and manny rayner  quantitative evaluation of 
exp ian at ion-based learning as an optimization tool for a large-scale natural language system  procs 1th int joint conference on artificial intelligence  pp 1  morgan kaufmann 1 
 shieber et al 1  stuart m 	shieber  gertj an van 
noord  fernando c n pereira and robert c moore 
 sema'itic-head-driven generation  computational linguistics 1   pp 1  1 
 strzalkowski 1  tomek strzalkowski  how to invert a natural language parser into an efficient generator an algorithm for logic grammars  procs isth int conference on computational linguistics  pp 1  iccl 1 
 uszkoreit et al 1  hans uszkoreit  rolf backofen  stephan busemann  abdel kader diagne  elizabeth 
a hinkelman  walter kasper  bernd kiefer  hans-
ulnch kneger  klaus netter  gunter neumann  stephan oepen and stephen p spackman  disco - an hpsg-based nlp system and its application for appointment scheduling  procs 1th int con ference on computational linguistics  pp 1  iccl 1 
	samuelsson 	1 
