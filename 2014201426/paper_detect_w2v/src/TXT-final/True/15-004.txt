 
an algorithm is presented which takes a least fixed point query expressed by a basis and inductive step and transforms it into a non-recursive iterative program. by augmenting a relational system with this algorithm  least fixed point queries can be handled automatically  and there is no need to proceduralizc relational algebra for such queries. 
1. motivation 
we present an algorithm for synthesizing a nonrecursive  iterative program from a least fixed point query  defined later . there are three reasons why such a synthesis will be of interest to researchers in ai in general  and to researchers in program synthesis in particular: 
1. it  efficiently  solves a real world problem of practical utility for database workers. 
1. the method was derived using techniques from logic programming systems. in particular the backward-chaining depth-first problem solving metaphor leads to an intuitive understanding of the algorithm. thus a link between logic programming and program synthesis is illustrated. 
1. finally  it illustrates the idea that if programs can be classified into domains  e.g. sort programs  list processing programs etc.  then may be we can derive algorithms for synthesizing programs within a domain. 
1. background 
consider a relational expression of the form 
	r - f r  	- l  
 throughout this paper we shall assume that the degree of the left and right hand sides of all such equations is the same . a lfp of  1  is a relation r* such that r* - f r*  and r* c s for any s satisfying  1 . examples of such lfp operations are calculating the number of flights between two cities during a given time period  finding the lowest-level manager common to a group of employees  and determining whether there is an active circuit connecting two points. none of the above can be couched in relational algebra  ahol. 
in studying the question of how powerful a data query language should be  aho and ullman  ahol postulated two general principles and noted that least fixed point  lfp  queries satisfy those principles but cannot be supported by the traditional relational calculus  codd . since in general a lfp of  1  may not exist  tars   a relation r can be constructed inductively by specifying the basis and inductive rules: 

in  ahol it is further shown that if in  1  there is only one occurrence of r in f r  then certain optimizations can be performed in the calculation of the lfp through  1 . in this paper we present a method of automatically synthesizing a non-recursive while-loop program  i.e. a program like  1  except that it will be non-recursive  from a lfp query of the form of  1 . such a transformation would have the following points of interest for database researchers: 
1. the non-procedural nature of relational algebra is preserved although it would take a fairly sophisticated user to write a lfp query. 
1. no theorem-proving is required to support lfp queries as in  wrig  though our method is grounded in the resolution principle of robinson  rob . 

1 s. naqvi and l. henschen 
1. the program derived for  1  is non-recursive. 
1. with a slight abuse of notation of  1   link queries  defined later  of qbe  zloo  can also be supported in the same framework. 
1. intuitive explanation of the algorithm 
it is simpler to develop and explain the algorithm by assuming that the lfp query will be written in relational calculus. thus  equation  1  becomes 

as an example  consider a database containing the relations father x y  and parent u v  for particular values of x  y  u and v. then a query asking for  certain kinds of  ancestors of a person v can be stated as follows: 

a few comments on the notation are in order. first  all variables are assumed to be universally quantified. second  the syntax  on purpose  is like that of 
prolog  pere . third  any base predicate  i.e.  a relation occurring in the database  with at least one argument instantiated to a constant represents a retrieval request. thus  the expression parent w a  can be read as s1-a parent   select from the parent relation those tuples whose second components have the value v. fourth  we have purposefully chosen a somewhat obscure and incomplete definition of ancestors. this is to highlight a distinction later. finally  our method of handling lfp queries  as described below  has two advantages over a prolog system. it not only works for left-recursive assertions but is also independent of the order of the assertions. in fact  putting the above query to a prolog system will cause an infinite computation. 
in order to proceed with an intuitive description of our method  we need to specify how a backward-chaining problem-solving system works. given an assertion of the form 

now  assume we have a backward-chaining problemsolving system and  further  that a problem p x y ....  is solvable only if at least one of the variables x y ... is instantiated to a constant. finally  it is evident that a lfp query can be replaced by a view. thus   1  can be replaced by the query 

we now describe how a backward-chaining problemsolving system would solve  1  using  1a  and  1b . from this description  our method will become obvious. 
to solve  1   we match it with the head of  1a  and 
 1b . since  1  matches both the assertions  let us choose  1a  first. the matching substitution is  u- w v -a}  and  thus  the original problem is replaced by the body of  1a   namely  father  w a . this subproblem is solvable and  in fact  yields a first set of answers which we can collect in a relation  say ancestor. from  1  and  1b   the original problem is replaced by the body of  1b  with the matching substitution applied. this yields ancestor w y   parent y a . proceeding in a depth-first manner  the subproblem ancestor w y  is not solvable  but parent y a  is and yields a set of values for y. these values for y are substituted back into the failed subproblem ancestor w y  and this subproblem is asked again. once again we have a choice between  1a  and  1b  and the above process repeats. 
the above iterative pattern can be captured in the following steps: 
1. retrieve father w a  and insert these tuples into the answer relation  ancestor. 
1. stack the value v. 
1. pop a value from the stack and assign it to v. 
1. retrieve parent y z  and use these new values of y to retrieve father w y . also stack these values of y. collect tuples retrieved for father w y  in ancestor. 
1. go to step 1. 

and a problem  c  such a problem-solving system matches the problem to the head  i.e. left-hand side of the assertion. if the match succeeds then the original problem  c  is replaced by the subproblems g1  g1  
i.e. the body of the assertion  with the matching substitution applied to the subproblems. if the head of more than one assertion matches a problem then the system has to make a choice. 

s. naqvi and l. henschen 1 
insert-in-queue q a  inserts the value v into queue q 

if 'a' has not been inserted into q before in the current computation. finally  removc-from-queue q  removes the top element of q. 
let us now consider a right-recursive definition of the above lfp query. 
  
once again  a similar problem solver would solve the above query as follows:  1  and  1  yield the primitive subproblem father w a . from  1  and  1   to solve ancestor w a  solve parent w y  and ancestor  y a . cannot 
as the basis residue  br . thus from  1    1a  and  1b  the basis residue is father u v  and the inductive residue is parent y z . now notice that the program forms  a  and  b  differ in the order in which the basis and inductive residue expressions are used. if we call the constants specified in the basis step r1 -  r as driver constants  we are lead to the general program form  c  shown in fig. 1. 
the only thing left to explain is the order in which br and ir expressions are to be used. this order can be elucidated as follows. consider an lfp query stated as  1a  and  1b . hypothesize solving r in  1a  by using  1b . this generates the subproblems 
now  by examination  if the subproblem r in the above expression is solvable  i.e. at least one of its variables is known  then the order is  eval ir ; r u eval br ''  otherwise it is  eval br ; r u eval ir  . 
figure 1: general program form 
a proof that the program form above produces correct answers is given in  hen . briefly  correct answers are those values logically implied by the definitions. our process is essentially supported resolution which is sound and complete  so that all and only answers are generated. clearly  if the relation r is not cyclic  the stack must become empty at some point. certain kinds of cyclicity  e.g. reflexivity   can be easily recognized by slight additions to the algorithm. in any case  a more elaborate termination test for the while-loop  based on remembering the derivation of each value added to r  yields termination in all cases. see  hen  for details. 

1 s. naqvl and l henschen 
the transformation algorithm 	itself has complexity based on identifying cycles in a  clause connectivity  
graph and on unification  both of which admit efficient algorithms. the general case allows for programs representing non-tail recursive definitions as well. in these cases  the eval ir  part of the loop includes an expanding formula corresponding to the non-tail recursive part of the definition. 
although  we give preference to select operations over joins  this is not required. however  most of the time it 
is obviously 	more efficient. 	for 	example  	in 	the expression  aho  
 codd  
 hen  