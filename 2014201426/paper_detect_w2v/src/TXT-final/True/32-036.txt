 
we describe a coherent view of learning and reasoning with relational representations in the context of natural language processing. in particular  we discuss the neuroidal architecture  inductive logic programming and the snow system explaining the relationships among these  and thereby offer an explanation of the theoretical basis for the snow system. we suggest that extensions of this system along the lines suggested by the theory may provide new levels of scalability and functionality. 
1 	introduction 
the paper explores some aspects of relational knowledge representation and their learnability. while the discussion is to a large extent general it is made in the context of low-level natural language processing  nlp  tasks. recent efforts in nlp emphasize empirical approaches  that attempt to learn how to perform various natural language tasks by being trained using an annotated corpus. these approaches have been used for a wide variety of fairly low level tasks such as part-of-speech tagging  prepositional-phrase attachment  context-sensitive text correction  and word selection in speech recognition and translation. 
　in this paper we study the general form of such problems in a relational setting. thus  our interest here is in learning to perform such tasks given a set of previously 
processed sentences  each represented using a relational representation. we use the task of part of speech tagging  pos  - one of the basic tasks studied in this line of research and often viewed as a prerequisite to performing many of the other tasks - as our running example. pos is the task of assigning each word in a given sentence the part of speech it assumes in that sentence. for example  assign n or v to talk in the following pair of sentences: have you listened to his  him  talk  * partly supported by epsrc grant gr/m1. 
　　+ research supported by nsf grants iis-1 and sbr-1. 
　* research supported by grants nsf-ccr-1 and onr-n1-1. 
　the snow system  roth  1  has been used successfully for several nlp tasks and  in particular  for learning to perform part of speech tagging  roth and zelenko  1 . the system uses perceptron-like representations and propositional learning algorithms. on the other hand  relational representations are very natural for nlp tasks and logic programs have been widely used in this context  hobbs et al.  1; pereira and shieber  1 . a natural approach would thus be to apply learning in first order logic or inductive logic programming  ilp  for learning to perform the relevant tasks  as done e.g in  cussens  1; dzeroski and erjavec  1 . 
　in this paper we discuss the theoretical basis underlying the snow system in terms of the neuroidal architecture  particularly following specific suggestions  valiant  1a; 1  for representing relational information using linear threshold elements as discussed earlier in  valiant  1 . using this analysis we show that snow can be viewed as a relational learning system  and this enables us to go on to compare it more directly with ilp. 
　the main contribution of the paper is therefore in analyzing the snow system in terms of the neuroidal architecture and consequently as a system learning relational information. this analysis provides insight into some of the theoretical and practical considerations that have been made in the search for scalable systems in this context. secondly  since the theory is somewhat more general than current implementations  this suggests that extending the snow system in a manner consistent with the theory may provide new levels of functionality. finally  by providing a single framework for discussing both snow and ilp we enable future comparative work of these seemingly disparate approaches. 
　the presentation is organized as follows. we first describe the input  a sentence  and program representation  horn rules and variants  for the relational tasks under consideration. we then discuss various computational aspects of the representations and their learnability. this leads to a description of the snow system and a discussion of some of the pragmatics of systems that learn to perform these tasks. 
	khardon  roth  and valiant 	1 

1 	representing a sentence 
we use first order logic statements with a finite set of predicates and allow only constants  i.e. no other function symbols  in expressions. since the specific predicates used do not affect the conceptual issues  we shall give a simple running example that will serve to illustrate the computational issues.1 the representation is as follows: 
  each word has a constant associated with it. 
  the linear structure of the sentence is captured by the predicate  which means that word  is immediately before w1 in the sentence. 
  a variety of relations conveying linguistic or seman-tic information may be added. for example we may add is a possible part of speech for word another example is adding where is a word describing an object in a class of objects described by the word  
　for simplicity we assume in the examples below that 1e/   and pposq are the only relations used in the representation. thus the sentence this can will rust is represented as the collection of all the atoms that hold  are active  in it: 
s = {be f  this  can  bef  can  will  bef  will  rust   ppos this  art  ppos can  noun   ppos  can  verb   
ppos will  noun  ppos will  verb  ppos rust  noun   
　　ppos rust verb } 	 1  it is implicit in the above that atoms not listed  such as be f  this rust   are false for this sentence. 
　the above representation may be too restricted if words appear more than once in a sentence. this can be easily dealt with formally by replacing constants representing words with unary predicates and using  token constants  to represent positions in the sentence  valiant  1a; 1 . in order to keep the notation simple we ignore this issue in the rest of the paper. 
1 	representing programs 
1 horn representations 
a program should take a sentence as an input and produce part of speech tags for the words in this sentence. one possible representation for such a program is a set of horn rules. for example  the rules1 

represent a simple program for predicting whether a 
   *the examples are meant only to illustrate the language used and may not be the most accurate - indeed  one reason learning is crucial in this domain is that it is hard to come up with concise rules that perform well. 
1  note that the first rule is logically equivalent to  but 
the existential presentation is more intuitive from an operational perspective. 
1 	natural language processing 
word is a noun or not. these rules exemplify several aspects of the representation. first  we may want to construct  complex features  such as and f1   out of the base predicates. secondly  such features may include existentially quantified variables as in the first rule or constants as in the first or second rule. note that the same program can be represented by the single rule 

1 	threshold elements with quantified propositions 
this section reviews a previous proposal for implementing relational predicates by means of linear threshold elements  valiant  1a; 1 . consider a relational horn rule 
where appears only in the antecedent. by an appropriate choice for this rule can be represented using a threshold element 
we impose the restriction that the quantified antecedent variables appear in each condition separately. that is  the rule r1 is not legal since y is shared between and c1. an example for a legal rule  not equivalent to the one above  is: 

　in fact  our restriction also allows for universally quantified variables within a single condition  which differs from quantification outside the rule . under this restriction  for any sentence and given a binding for  the conditions of the form   where q is a quantifier  are essentially boolean variables. that is  they are either true or false but have no parameters. we call these quantified propositions to emphasize this point. 
　as before  rules that use quantified propositions can be described using a linear threshold element: 

thus a special case of rule representations is used but it is generalized through the use of linear threshold elements  that can represent  as well as other functions   and more general quantifiers. 
　note that the restriction can be overcome by changing the set of relations. for example  instead of above 
while the resulting program is the same  the representation will need to include f1   that explicitly mentions the variable y. 
1 	learning 
in this section we discuss the learnability of programs of the form presented in sec. 1 in a supervised learning paradigm. the input to the learning algorithm is given in terms of an input sentence representation 1 as in 

eq.  1  along with an atom p  such as pos  rust  verb   that holds in this sentence. we call the pair   s p   a labeled example. a single sentence may thus give rise to 
several examples  one for each word. 
　in the following discussion it is sometimes useful to assume that there is a program in the class of programs discussed  that can produce correct labels for any sentence. such a program is called the target program  
1 	relational methods 
an example   s p   can be represented as  1  p . 
an example of this form is a ground horn clause that is implied by the target program  a set of horn rules . this is exactly the scheme of learning from entailment studied in inductive logic programming.  notice that this representation assumes that negative atoms are not relevant for the label i.e. we cannot use  in the condition of a rule . several techniques from ilp use examples in this form  and can be applied to this task  muggleton and de raedt  1; cohen  1a .1 one of the main features that distinguishes ilp from other formalizations of learning is the use of background knowledge. a similar effect can be achieved in our formalization by enriching the input representation of sentences with the relevant relational information. thus  given rules  say  that compute isa   relations between words   e.g.  using wordnet  we can augment our initial representation s with the isa   atoms implied by these rules  for words in the sentence . 
　studies in ilp suggest that unless the rule representation is restricted the learning problem is intractable. we briefly discuss some of the common restrictions studied and their relation to the use of quantified propositions. a horn clause is constrained if all the variables in the consequent also appear in the antecedent  page and prisch  1 . this is a special case of determinacy defined as follows. assume one imposes an order  left to right  on the predicates in a rule's antecedent. a predicate is determinate if in any example and given a binding for the consequent and the first i - 1 predicates  there is at most one binding that makes the i'th predicate true. clearly  given a binding for the consequent  every predicate in the condition is a boolean variable  similar to our restriction above  a fact which has been used both in theoretical results and practical applications  dzeroski et a/.  1; lavrac and dzeroski  1 . in our case  while there may be more than one binding for each quantified proposition  the condition is still boolean. 
　another related restriction is the depth of terms in a clause. we assign a depth to terms using the order on conditions in the antecedent from left to right. a term in the consequent is of depth 1. if  is the next atom in the condition  such that u has been assigned depth i  and no other term has been assigned a lower depth  and v has not yet been assigned a depth  then 
1 previous ilp work for similar problems  cussens  1; 
dzeroski and erjavec  1  use a different formalization and are therefore not directly comparable here. 
v is of depth i + 1. depth is only assigned to  linked  clauses where at least one term in any atom is already assigned a depth by the previous atoms. clearly our restriction means that variables in clauses are of depth at most 1 but constants may create chains of longer depth. positive results in ilp  dzeroski et a/.  1; cohen  1a  show that a single non-recursive  or with limited recursion  determinate clause of constant depth is learnable in polynomial time. however  relaxing any of the restrictions  to 1 clauses  non-constant depth  recursive clauses  or non determinate clauses makes the problem computationally hard  kietz and dzeroski  1; cohen  1b; cohen and page  1 . 
　on the other hand  there are heuristics for learning programs with more than one rule and these may be used here as well  muggleton and de raedt  1; cussens  1 . another way to make the problem tractable is to use queries. in particular  for entailment membership queries  the learner presents a new example  sn -  pn  and asks whether it is implied by the target. if a user can answer such questions or if one can otherwise simulate these then techniques from  khardon  1; reddy and tadepalli  1  can be used to learn programs with more than one rule. 
　to summarize  the restriction imposed by using quantified propositions creates a situation that is similar to determinacy and constant depth in that it reduces the complexity of the learning problem but is incomparable to these. one important difference is the fact that determinacy is a property of the data that may not hold for every domain whereas our restriction is purely syntactic. 
1 	using quantified propositions 
in the rest of this section we concentrate on the problem of learning a single rule that uses quantified propositions and can be expressed given the predicates in the representation of the sentence. to make this concrete  in 
terms of the examples above  we might be trying to learn the rule r1 from sentence representations that include 1e/   ppos   f1   /1  . in the next section we discuss combining rules learned separately in a single system. 
projection 
a possible reduction in complexity comes from splitting the learning task into a few smaller ones. this is natural for part of speech tagging. it seems unlikely that the same condition can be used to predict the part of speech of  say  both nouns and verbs. therefore  it may be better to avoid trying to learn a general rule of the form condition pos x  y  and instead learn a set of rules  one  or more  for each part of speech  e.g.  conditioni 
pos x noun     condition1  pos x verb   etc. if general patterns do not occur  and thus will not be useful  then we are effectively reducing the complexity of the learning problem. 
　one can think of this as projecting the relation pos x y  over its second argument  the pos tag   where posq is implemented as a logical disjunction of the various sub-relations. this clearly works if the instances 
	khardon  roth  and valiant 	1 

describe disjoint sets  which they do. the projection we use here  for pos    depends on the label of the example. this does not cause a problem during the learning process but one may need to resolve between competing learned rules when the programs are used. other projections  that depend only on the input sentence  can be used in other nlp tasks. in fact  this has been done implicitly in nlp studies  where the task is defined as disambiguating between a small set of candidates.1 
　our examples of projections simply partition the learned predicate into several disjoint parts  where the parts are identifiable in advance  and all parts are needed  e.g. we need to learn pos x  y  for each possible value of y . projection learning  valiant  1b  provides some more general conditions under which learning projections on the input space is guaranteed to work. this holds even if one has a set of projections that is not dis-
joint and not all projections are needed. in addition  as we discuss below  this can be done in an attribute efficient manner. 
using propositional learning algorithms 
as presented in sec. 1 the neuroidal architecture  valiant  1a  restricts the use of rules so that quantified variables in different parts of the condition can be evaluated separately from the others. the main advantage of this restriction is that it allows one to encode relational learning examples into a propositional setting. consider learning the rule r1 =  
where c1   and c1o are the features used in the representation. for a sentence representation 1 and a binding of the variable x  which determines the example provided to the learning algorithm  each predicate in a rule  e.g.  is assigned a single binary value. thus an example can be described by assigning a binary value to each of the given features. in our example sentence  learning r1 in terms of bef   ppos    f1    f1o  for x =this we have f1 x  = 1  f1{x  = 1  bef x can  = 1  and for x =can we have f1{x  = 1  f1 x  = 1  and bef x  can  = 1. since an example always specifies the binding for the atom in the consequent this can always be done.1 as a result  under this restriction any propositional learning algorithm can be used for learning  even though the rule itself is relational! the rule learned is an approximation to an equivalence rather than an implication  valiant  1 . 
　1 when learning to perform context sensitive spelling  the task is to decide what is the correct word to use for a given confusion set e.g. piece or peace. in this case  projection on the confusion set  i.e.  learning for piece  peace and for weather  whether separately  makes sense since it is unlikely that the same condition will disambiguate different sets. 
　1 this should be contrasted with the expression r1 =  va;  1y ci x y  ac1 x y  -  new x    where for each binding for y we still get a binary value for each attribute  but these binary values are dependent upon each other  so that the example cannot be described simply using a set of binary values. 
1 	natural language processing 
dealing with many attributes 
recall that in the ilp setting an example is a clause of the form  1 -  p   implicitly assuming that the atoms that do not hold in the sentence are irrelevant for it. this  closed world assumption  is especially important if the number of atoms that hold in a sentence  positive atoms  is much smaller than the number of those that do not hold in it  negative atoms . this is likely to be the case in the current context especially if we use features that are partly ground  such as bef x  can   bef x  will   bef x  table  etc.  repeated for every word in our lexicon. in this setting  the number of potential features may be in the order of 1 and explicitly mentioning all of them may be computationally costly. 
　therefore  when using a propositional learning algorithm in this setting one would like to make sure that the algorithm handles only the features active in the example and  preferably  does not even represent negative features since even their representation and manipulation will be time consuming. in turn  this efficiency requirement may imply that the program learned cannot depend on negative features. the infinite attribute model suggested by blum  provides a theoretical framework in which this can be studied. in this model  an example is represented as a list of the attributes that are active in it  and a learning algorithm is required to be efficient  polynomial  in terms of the number of the features active in the examples rather than the total number of attributes. to a certain extent  algorithms in the infinite attribute model can deal with negative features  blum  1 . 
attribute efficient algorithms 
the sample complexity - the number of examples required in order to achieve learnability - is another important aspect that requires attention. consider the case when the target program depends only on nr  relevant  attributes  which is small relative to nc  the number of attributes active in any particular example  and very small relative to na the number of potential attributes. as indicated above  this is realistic in many nlp problems  in which the number of potential attributes depends on the size of the lexicon. in this case  one would like the number of examples required for learning the program to depend only weakly on ne or na. littlestone's winnow algorithm  littlestone  1   adapted to the infinite attribute model  can achieve this and requires 1 nr log nc  examples. that is  the number of examples needed is independent of na and depends only logarithmically on ne. 
　an important aspect of projection learning  as mentioned previously  is that it can be achieved attribute efficiently  valiant  1b . this requires no special attention if the projection forms a partition  as in the pos example  but even in a more general case when we have a large number of projections of which only a small number is relevant  there is a logarithmic dependence on the number of irrelevant projections. 

target-word centered representation 
our initial description used a single representation for a sentence  as in eq.  1 . in this formulation  a single sentence gives rise to several examples  each corresponding to the part of speech of a word in the sentence  but all have the same relational representation and differ only in their label. it is thus worth noting that when using the propositional translation this does not hold. in particular  the boolean value of the features depends on the binding for x  the word for which we are trying to predict the part of speech. in this way  a sentence produces several examples  each corresponding to a word and its part of speech  but the propositional representation of each of these examples is different. 
　1 the snow system 
the snow system1 provides an architecture within which several learning algorithms - all making predictions using linear functions over the feature space - can be implemented. the architecture is a network of linear threshold gates. nodes in the input layer of the network represent simple relations on the input sentence and are being used as the input features. target nodes represent features for which programs are sought. target nodes are linked via weighted edges to input features; if ft is the set of features linked to the target node t  wi is the weight associated with the ith feature  and 1t is a threshold associated with t  we can say that t is represented by the generalized rule 

each snow unit may include a collection of subnetworks  one for each of the relations for which a program is learned. a given example is treated autonomously by each target subnetwork; an example labeled t is treated as positive example by the subnetwork for t and as a negative example by the rest of the target nodes  modulo projection considerations . the learning policy is online and mistake-driven  and the most successful update rule used within snow is the sparse winnow algorithm. this is a variant of littlestone's  multiplicative update rule  tailored to the situation in which the set of input features is not known a priori  as in the infinite attribute model  blum  1 . once target subnetworks have been learned and the network is being evaluated  a decision support mechanism is employed to select the dominant active target node in the network or to output an otherwise coherent output  munoz et al  1 . 
　originally  the snow system was described as a propositional system. in the rest of this section we shall detail a new interpretation of it as a relational system. 
   1 other nlp learning systems like brill's system  also incorporate some of the aspects we present; in particular  they use similar features and decompose the tasks similarly. however  snow corresponds more directly to the neuroidal architecture in its use of threshold elements. 
we briefly discuss how-some of the aspects presented earlier are reflected in the design of the system  and then present a few more pragmatic aspects that are somewhat harder to discuss theoretically at this point. most of these aspects have been evaluated experimentally and found to perform successfully on a variety of nlp tasks. in particular  single snow units have been evaluated on context-sensitive spelling correction  golding and roth  1 ; chaining of snow units  as well as other aspects  has been studied in  roth and zelenko  1; munoz et al.  1  several aspects of projections have been studied in  rosen  1   and a preliminary study of incorporating background knowledge by augmenting the input features is in  krymolovsky and roth  1 . 
1 	sentence representation 
while the description above suggests that snow uses a propositional representation  a relational representation of sentences as in eq.  1  is used. this is done by utilizing quantified propositions and using a propositional representation of these as features. accordingly  examples are target-word centered and a single relational sentence representation may give rise to several propositional examples  corresponding to the target word. 
　quantified propositions include features with constants  as in f1   in sec. 1  and existential features  as in /i   in sec. 1 . the system generates the features and the word-centered representation automatically using a simple language for relational feature definitions. specifically  features are relations of the form  where the predicate c   is one of three types:  1  relations that can be readily read from the sentence  like bef {this  can .  1  relations that become active as a result of evaluating other  previously learned programs.  1  relations that are read from an outside source. these may include predicates like isa    and synonymq. in this way background knowledge is incorporated in a transparent way and plays the same role in the representation as do simpler predicates. 
　the predicate c   can also be a small conjunction of predicates of the above types. the pattern for existential features is restricted to bind words within a fixed distance of the target word. thus  /i   above can be rephrased as  ppos y  verb  holds for the word y which is two positions to the right of x . notice that due to the semantics of bef    these features are determinate in any rule; more general features like  ppos{y  verb  holds for some word y which is at most 1 positions away from x  are also used  but they too have bounded determinacy. 
　the above syntactic description generates a large number of possible features. following the positive sentence representation principle discussed above  features are allocated only if they are active in the example sentence. the architecture supports a limited use of negative features by learning several programs at the same time and using positive features for one program as potential negative features for others. 
khardon  roth  and valiant 1 

1 	learning 
  snow is a propositional learning system that uses linear threshold functions over the set of quantified propositions as its knowledge representation. 
  two complementary aspects of projection are han-dled in snow. precondition projection is similar to the one described above. this is a condition applied to the input representation  either just the sentence or the label as well  that is employed to learn several target programs rather than a single  more abstract  program as described above for pos and the spelling examples. in this way  different examples can be used to train different programs. task projection is a form of projection that is employed at prediction time  when several learned programs are being evaluated  and is used to restrict the programs that are being evaluated on a given input example  thereby simplifying the prediction process. for example  when learning programs for each of the possible pos  a  learned  task projection may prevent the evaluation of the pos x  adj  program given that the target word is can. in particular  this form of projection addresses one of the issues discussed above  when the projection is with respect to the label. an experimental evaluation of the forms of projections within snow  exhibiting both significant efficiency and performance gains is presented in  rosen  1 . 
  snow implements several on line learning algorithms for linear functions  including variations of winnow  perceptron  naive bayes and a memory based algorithms  the last two use only positive examples for learning . in all cases  the variation implemented is tuned to  be on-line and  deal with many attributes along the lines described above. this is imposed by the sparse architecture of the system  which assigns a positive weight to a feature only if it is active together with the target predicate in a single example. 
1 	other pragmatic issues 
  snow can learn programs that are represented in terms of predicates which are themselves consequents of other programs  that were learned previously . thus snow supports chaining of learned programs assuming that each of the learning stages is supervised. one difficulty in this process is that learned rules may not be completely accurate  resulting in potentially noisy input to the other learning stages. this imposes another practical constraint on the algorithms used in this setting  namely robustness to attribute noise. 
  snow allows for some use of recursive rules in the following way. when learning from labeled data  the pos   labels are available for all words and may be included in the input representation. as a result  the learned rule may be recursive in that it includes pos   predicates in the antecedent. 
1 	natural language processing 
however  when evaluating the learned program for posq on new sentences that are not annotated  one needs to initialize the posq predicates in the antecedent in some way  e.g.  use the most frequent part of speech for each word  and then  the same program may be applied to the sentence representation  even several times  as to improve the approximate input representation before the output posq is decided upon  roth and zelenko  1; munoz et al.  1 . 
  finally  whenever a collection of programs is learned  given an input sentence  there is a need to make a decision that may involve several learned programs. in particular  as in pos  the programs compute competing pos tags and there is a need for a procedure that determines which of them to select.  note that in snow this results from the use of projection.  snow employs a few mechanisms for decision making including a winner-take-all mechanism and a learned decision making mechanism. 
1 discussion 
based on an analysis of snow in terms of the neuroidal architecture  we presented a framework describing snow as a relational learning system and explained its relation to ilp. this  in particular  facilitates future comparative studies involving snow and ilp. 
　since the theory presented is more general than current implementations  extensions of snow along the lines suggested by the theory may provide new levels of scalability and functionality. this is  however  not straightforward and requires careful consideration. additionally  our analysis may provide guidelines for further analysis of some issues which are not well understood yet. one of the issues that can be addressed in future work is the following tradeoff: adding more complex existential features to the representation increases computational complexity  but at the same time results in more expressive programs and more significant gain from the use of attribute efficient algorithms. a second issue is the use of more general forms of projections. finally  one advantage of relational methods is the ability to choose the right features dynamically and in fact change them during the learning process. for example  if a sentence includes the atom bef  can  will   this feature may be needed as part of a learned rule. naturally  we do not know in advance whether the feature should be ground or whether a more general form  one of bef x will   1e/ can y   or bef x y  should be used. in the current propositional setting  each of these is used separately as a feature and the learning algorithm may use any of them. on the other hand  computing the least general generalization  plotkin  1  over several example sentences we may be able to find the right general form of the feature. it is not clear whether a technique that changes the features in this way  during the on-line process of learning  can be incorporated in the propositional setting. 

