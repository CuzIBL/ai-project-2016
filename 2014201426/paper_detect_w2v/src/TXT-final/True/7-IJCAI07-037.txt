
p-log is a probabilistic logic programming language  which combines both logic programming style knowledge representation and probabilistic reasoning. in earlier papers various advantages of p-log have been discussed. in this paper we further elaborate on the kr prowess of p-log by showing that:  i  it can be used for causal and counterfactual reasoning and  ii  it provides an elaboration tolerant way for non-naive conditioning.
1 introduction and motivation
in recent years there has been a lot of progress in logical knowledge representation and reasoning as well as probabilistic knowledge representation and reasoning. there have been some attempts at developing formalisms that allow both logical as well as probabilistic knowledge representation.
one such approach is pearl's probabilistic causal models  pearl  1 . while pearl's formalism is an improvement overtraditional propositionalprobabilityrepresentationssuch as bayes' nets  there are still the limitations that are associated with propositional representation as well as classical  and hence monotonic  reasoning. in recent years approaches to overcome both have been proposed. proposed approaches to overcome the limitations of propositional representation include probabilistic relational models  koller  1; getoor et al.  1   various probabilistic first-order logics  nilsson  1; bacchus  1; bacchus et al.  1; halpern  1; 1; pasula and russell  1; poole  1   and approaches based on assigning weights to first-order formulas  paskin  1; richardson and domingos  1 . there have been also many formalisms that integrate logic programming with probability such as poole's probabilistic horn abduction  pha   poole  1   his independent choice logic  icl   poole  1; 1   the lpad formalism  vennekens et al.  1   bayesian logic programming  kersting and raedt  1   alterid  breese  1; wellman et al.  1   probabilistic knowledge bases  ngo and haddawy  1   stochastic logic programs  muggleton  1; cussens  1   probabilistic constraint logic programs  riezler  1; santos costa et al.  1   interval based probabilistic logic programming  ng and subrahmanian  1; 1; dekhtyar and dekhtyar  1; lukasiewicz  1   dynamically ordered probabilistic choice logic programming  de vos and vermeir  1   and the recent langauge p-log  baral et al.  1; 1 . our focus on this paper is on plog.
earlier it was shown that p-log has many advantages over the other languages. in particular  p-log allows a wide variety of updates compared to the other approaches; it allows explicit specification of background knowledge; and it allows logical reasoning to dynamically decide on the range of values that a random variable can take. in this paper we show how p-log can also do causal and counterfactual reasoning of the kind in pearl's probabilistic causal models. we give an encoding of probabilistic causal models in p-log and state the correspondence. our correspondenceshows that while the computation of causal and counterfactuals in pcms is algorithmic in nature  in the encoded p-log it is automatically captured by the semantics of the language. we then show that p-log's ability to allow logical reasoning to dynamically decide on the range of values that a random variable can take leads to a elaboration tolerant way to perform non-naive conditioning  halpern  1 . we illustrate this with respect to halpern's second-ace puzzle example.1
1 background
in the next two subsections  we will briefly review the syntax of a simplified version of p-log  baral et al.  1  and the syntax and semantics of probabilistic causal models  pearl  1 .
1 p-log lite: an overview
following by t we denote a vector of parameters consisting of terms  and by we refer to p and by p we refer to  p.
¡¡¡¡¡¡1earlier work on p-log  baral et al.  1  hinted at this with respect to the monty hall example. however no general methodologies for  non-naive  conditioning were proposed.for simplicity  we will define a subset of the probabilistic logic programming language p-log  which we will call p-log lite. we use logic programming terminology of terms  atoms and literals. a p-log lite program ¦° consists of  i  a set of boolean attributes {p  p : p is an atom }   ii  a regular part   iii  a set of random selection rules   iv  a probabilistic information part  and  v  a set of observations and actions. in the  ii  regular part: the regular part of a p-log lite program consists of a collection of logic programming rules  without disjunction and under the stable model semantics .
 iii  random selection: a random selection is a rule of the form
	random a t  .	 1 
statement  1  says that one of a t  or  a t  is selected at random. in p-log with non-boolean attributes the random statement is more general and is of the form: random attr : {x : p x } .
 iv  probabilistic information: information about probabilities of random attributes taking particular values is given by probability atoms  or simply pr-atoms  which have the form: pr l  = v.	 1 
where l is a t  or  a t   and pr a t   = v would cause a t  with probability v.
 v  observations and actions: observations and actions are statements of the respective forms: obs l  and do l .
observations are used to record the outcomes of random events  i.e.  random attributes and attributes dependent on
them. the statement do a t   indicates that a t  is made true as a result of a deliberate  non-random  action.
semantics of p-log lite:
the semantics of a p-log lite program ¦° is given by a collection of the possible sets of beliefs of a rational agent associated with ¦°  together with their probabilities.
we start with translating the logical part of a p-log lite program ¦° to an answer set prolog program ¦Ó ¦°  as described below.
 a  ¦Ó ¦°  contains the regular part of ¦°.
 b  for each attribute atom a t   ¦Ó ¦°  has the rules:
intervene a t   ¡û do a t  . intervene a t   ¡û do  a t  .
 c  for each random a t   in ¦°  ¦Ó ¦°  has the smodels rule: 1{a t   a t }1 ¡û not intervene a t  .
the left hand side of the above rule means that one of a t 
and  a t  must be in the answer set.
 d  ¦Ó ¦°  has all the actions and observations of ¦°.
 e  for all literals l  ¦Ó ¦°  has the rules:
¡û obs l  not l. l ¡û do l .
an answer set of ¦Ó ¦°  is called a possible world of ¦°. the set of all possible worlds of ¦° is denoted by ¦¸ ¦° .
let w be a possible world of a p-log lite program ¦°. if ¦°
contains a random selection rule of the form random a t   
then we say that both a t  and  a t  are possible in w with respect to ¦°. for every w ¡Ê ¦¸ ¦°  and every literal l possible in w we now define the corresponding probability p w l .
for each l possible in w:
if l ¡Ê w  ¦° has a pr-atom pr l  = v and w does not contain intervene l  then p w l  = v  and p w  l  = 1   v.
if for any attribute literal l  we do not have pr-atoms for either l or  l  l ¡Ê w and w does not contain intervene l  then p w l  = 1  and p w  l  = 1.
now we are ready to define the measure  ¦Ì¦°  induced by the p-log lite program ¦°.
definition 1.  measure   i  the unnormalized probability  ¦Ì ¦° w   of a possible world w induced by ¦° is ¦Ì ¦° w  =
  where the product is taken over literals for which p w l  is defined.
 ii  the measure  or the normalizedprobability  ¦Ì¦° w   of a possible world w inducedby ¦° is the unnormalizedprobability of w dividedby the sum of the unnormalizedprobabilities of all possible worlds of ¦°  i.e. 
when the program ¦° is clear from the context we may simply write ¦Ì  and ¦Ì instead of ¦Ì ¦° and ¦Ì¦° respectively. 
the truth and falsity of propositional formulas with respect to possible worlds are defined in the standard way. a formula a is true in w is denoted by.
definition 1.  probability 
the probability with respect to program ¦° of a formula a  p¦° a   is the sum of the measures of the possible worlds of
¦° in which a is true  i.e. .	
when ¦° is clear from the context we may simply write p instead of p¦°. conditional probability in p-log lite is defined in the usual way. moreover  under certain consistency conditions  which hold for the examples discussed in this paper  on p-log lite programs t  formulas a  and a set of literals b such that  we have pt a|b  = pt¡Èobs b  a 
1 probabilistic causal models
in this section we present many definitions from  pearl  1  and give our definition of a pcm-probabilistic query.
causal model: a causal model is a triple where
 i  u is a set of backgroundvariables   also called exogenous   that are determined by factors outside the model;
 ii  v is a set {v1 v1 ...vn} of variables  called endogenous  that are determined by variables in the model - that is  variables in u ¡È v ; and
 iii  f is a set of functions {f1 f1 ...fn}  such that each fi is a mapping from u ¡È v  vi  to vi  and such that the entire set f forms a mapping from u to v . in other words  each fi tells us the value of vi giventhe values of all other variablesin u ¡Èv   and the entire set f has a unique solution for v   given a realization of u. symbolically  the set of equations f can be represented by writing vi = fi pai ui   i = 1 ... n  where pai  connoting parents  is a subset of variables in v   vi and ui stands for a subset of variables in u.
we will refer to the realization of a set of variables y   v given the causal model m and the background variable realization of u = u as ym u . y  u  will be used as shorthand for ym u   but we will explicitly use the subscript mx for realizations of submodels defined below.
example 1. we have a simple causal model consisting of a background variable u  endogenous variables a and b  and the set of the following causal functions:
a = u ¡Ä b.	b = u ¡Å a.
for each value of u  there is a unique solution for a and b.
that is  for u = 1  a = b = 1 and for u = 1  a = b = 1. 
submodel: let m be a causal model  x be a set of variables in v   and x be a particular realization of x. a submodel mx
where fx = {fi : i	=	.
submodels are useful for representing the effect of local actions and hypothetical changes. mx represents the model that results from a minimal change to make x = x hold true under any realization of u.
effect of action: let m be a causal model  x be a set of variables in v   and x be a particular realization of x. the effect of action do x = x  on m is given by the submodel mx.
potential response: let x and y be two subsets of variables in v . the potential response of y to action do x = x   denoted ymx u   is the solution for y of the set of equations fx  where u is a particular realization of u.
counterfactual: let xi and y be two subsets of variables in v . the counterfactual sentence  the value that y would have obtained  had xi been forced to be xi  is interpreted as denoting the potential response ymxi u   where u is a particular realization of u.
probabilistic causal model: a probabilistic causal model
 pcm  is a pair  where m is a causal model and
p u  is a probability function defined over the domain of u.
because the set of functionalequations forms a mapping from u to v   the probability distribution p also induces a probability distribution over the endogenous variables.
for every set of variables y   v   we have: p y = y  =

the probability of a counterfactual statement is defined using the potential response  ymx u   induced by the submodel . it can be expressed in a similar manner: p ymx = y  =
	{u | ymx u =y}	   
pcm probabilistic query: joint probabilities of counterfactuals that are conditional on observations will be the focus of our counterfactual reasoning. let ymx1 = y1 ...  ymxm = ym be counterfactuals and let b and c be subsets of v. a pcm probabilistic query is of the form p ymx1 = y1 ...  ymxm = ym  b = b | c = c   and its value is given by:

1 encoding pearl's firing squad in p-log lite
in this section we will consider pearl's firing squad example and show how one can encode this example in p-log lite and ask counterfactual queries.
the firing squad pcm: the pcm of the firingsquad has two background variables u and w  and endogenous variables a b c  and d; which stand for
u = court orders the execution; c = captain gives a signal; a = rifle a shoots; b = rifle b shoots; d = the prisoner dies; w = rifle a pulls the trigger out of nervousness.
the causal relationships between the variables are described by the functional equations c = u; a = c ¡Å w; b = c; d = a ¡Å b. in addition the probabilities of the background variables are given as p u  = p and p w  = q.
1 example of an observation assimilation query
consider the query that asks the probability that b shot given that the prisoner is dead  in pcm formalism this will be expressed as p b|d .
to translate this query to an equivalent p-log lite query we will use a program ¦°1 that captures both the causal relationships and the probabilistic arguments found in the firing squad pcm. the program ¦°1 will have explicit rules for the positive and negative boolean variables. the p-log lite predictive query is not conditioned on the fact that the prisoner is dead. instead  the fact that the prisoner is dead is added to ¦°1 as an observation rule obs d . the p-log lite program ¦°1 consists of the following:
1. declarations for each background variable:
	u : boolean.	random u .
	w : boolean.	random w .
1. declarations for each endogenous variable:
c : boolean.	a : boolean.
	b : boolean.	d : boolean.
1. pr atoms and logic programming rulespr u  = p. pr w  = q.
1. reminder of the logic programming rules
c ¡û u.	 c ¡û  u.
a ¡û c.	a ¡û w.	 a ¡û  c ¡Ä  w.
b ¡û c.	 b ¡û  c.
d ¡û a.	d ¡û b.	 d ¡û  a ¡Ä  b.
result 1. p b|d  = p¦°1 ¡È obs d  b  = 1  1 pp  1 q 
1 example of an intervention query
now let us consider the following intervention query: what is the probability that the prisoner is dead given that a is not allowed to shoot  in pcm formalism this is expressed as
p dm a .
to translate this query to an equivalent p-log lite query we will use a program ¦°1 which is similar to ¦°1 with respect to the parts  1 - 1  of ¦°1  but differs on part  1  by having rules which are blocked when an intervention is done. in this the nonmonotonic operator not of logic programs comes in handy.
part  1  of ¦°1
c ¡û u  not do c   not do  c .
a ¡û c  not do a   not do  a .
a ¡û w  not do a   not do  a .
b ¡û c  not do b   not do  b .
d ¡û a  not do d   not do  d .
d ¡û b  not do d   not do  d .
 c ¡û  u  not do c   not do  c .
 a ¡û  c  w  not do a   not do  a .  b ¡û  c  not do b   not do  b .
 d ¡û  a  b  not do d   not do  d .
result 1. p dm a  = p¦°1 ¡È do  a  d  = p
1 example of a counterfactual query
we now consider the following counterfactual query from  pearl  1 :  what is the probability that the prisoner would be alive if a had not shot given that the prisoner is in fact dead  
in pcm this counterfactual query is expressed as either p  dm a| d  or as p  dm a| dm   where m is the original causal model.
thus the pcm counterfactual query has two causal models in the probabilistic query. the conditional variable dm  which is an equivalent representation of variable d  is a member of the original causal model m  while the variable ym a is a member of the submodel m a.
our encodings in ¦°1 refers to the model m and our encoding in ¦°1 refers to the model m a. now we need both. we achieve this by carefully using the indices 1 and 1 for the endogenous variables. we do not use any index for the exogenous variables as they remain the same in both models.
note that in ¦°1 we do not apply do   rules to the original model m  since by definition submodels are the result of an effect of action do   on the original model m. therefore all variables that are members of the m do not need intervention rules in the translation.
the p-log lite encoding of the above example will consist of the program ¦°1 given below. to ask the query all one needs to do is to add obs d 1   and do  a 1   to ¦°1 and compute the probability of  d 1 . in the syntax of p-log lite this is expressed as p¦°1 ¡È obs d 1   ¡È do  a 1    d 1  .
the intuition behind adding obs d 1   is that d is observed with respect to the original model m which is encoded by the index 1. the intuition behind adding do  a 1   is that  a is established  through an action  resulting in a new model m a which is encoded by the index 1. the intuition behind asking the probability of  d 1  is that the query is asked about the model m a which  as we mentioned earlier  is encoded by the index 1. now we describe the program ¦°1. its constituents are as follows:
  declarations for each background variable:
	u : boolean.	random u .
	w : boolean.	random w .
  probability atoms correspondingto the backgroundvariables u and w. pr u  = p. pr w  = q.
  indices to enumerate the models m and m a:
index = {1  1}.
  declarations for each endogenous variable:
	c : index ¡ú boolean.	a : index ¡ú boolean.
	b : index ¡ú boolean.	d : index ¡ú boolean.
  rules that allow us to reason about the model m.
we use the index 1 for the endogenous variables. the background variables do not have an index as they remain unchanged with respect to the original model and its sub-models.
	c 1  ¡û u.	 c 1  ¡û  u.
	a 1  ¡û c 1 .	 a 1  ¡û  c 1  ¡Ä  w.
a 1  ¡û w.
	b 1  ¡û c 1 .	 b 1  ¡û  c 1 .
d 1  ¡û a 1 .	 d 1  ¡û  a 1  ¡Ä  b 1 . d 1  ¡û b 1 .
  rules that allow us to reason about the model m a.
since doing an action  as an assignment to a variable  necessitates surgery to the model so that the parents of the variable that is assigned no longer affect the variable; we do it logically by adding  not do  in the bodies of the rules. as a result we have the following rules:
c 1  ¡û u  not do c 1    not do  c 1  .
a 1  ¡û c 1   not do a 1    not do  a 1  . a 1  ¡û w  not do a 1    not do  a 1  .
b 1  ¡û c 1   not do b 1    not do  b 1  .
d 1  ¡û a 1   not do d 1    not do  d 1  .
d 1  ¡û b 1   not do d 1    not do  d 1  .
 c 1  ¡û  u  not do c 1    not do  c 1  .
 a 1  ¡û  c 1  ¡Ä  w  not do a 1    not do  a 1  .
 b 1  ¡û  c 1   not do b 1    not do  b 1  .
 d 1  ¡û  a 1  ¡Ä  b 1   not do d 1    not do  d 1  .
to answer p¦°1 ¡È obs d 1   ¡È do  a 1    d 1   all one needs to do is to add the intervention and observation facts do  a 1    and obs d 1    respectively and compute the probability of  d 1  with respect to the resulting theory.
result 1. p  dm a| d =

1 a general encoding of pcm to p-log lite
we now generalize the encoding illustrated in the previous section to arbitrary pcm theories and for queries that may refer to multiple hypothetical models. we will refer to our encoding1 as t. to accommodate multiple submodels  the plog lite rules will use an index variable s  where s = 1 will correspond to the original model of the pcm theory and  s = 1...m  will correspond to the m sub-models necessitated by the probabilistic query. the encoding t will consist of the following.
step 1: enumerate the models and submodels necessitated by the probabilistic query 1 ... m. the variable s used in the endogenous variables rules is in the domain of index: index = {1 ... m}
step 1: for each background variable u ¡Ê u  for which the pcm has the probability p u  = q  t will have the following: u : boolean. pr u  = q. random u .
step 1: for each endogenous variable v  with x1 ... xn ¡Ê u ¡È v  v  and with the associated function fv x1 ... xn   we do the following:
1. add the following declaration:
v : index ¡ú boolean.
1. let the disjunctive normal form of fv x1 ... xn  be c1 ¡Å ... ¡Å cn  where each ci is a conjunction of literals made up of from x1 ... xn. in the translation the parameter s is added to each endogenous variable xi of x1 ... xn  such that xi becomes xi s . the p-log lite program t will have the following rules: v s  ¡û c1  not do v s    not do  v s  .
... v s  ¡û cn  not do v s    not do  v s  .
1. let the disjunctive normal form of  fv x1 ... xn  be d1 ¡Å ... ¡Å dn  where each di is a conjunction of literals made up of from x1 ... xn. in the translation the parameter s is added to each endogenous variable xi of x1 ... xn  such that xi becomes xi s . the p-log lite program t will have the following rules:
 v s  ¡û d1 s   not do v s    not do  v s  .
...
 v s  ¡û dn s   not do v s    not do  v s  .
step 1: encoding the query p b ymx1 = y1 ... ymxm = ym|c 
1: for each counterfactual statement ymxi = yi:
for each variable v ¡Ê v that is a member of the realization of xi = xi: if v is positive  we add do v s = i  ; else  i.e.  v is negative  we add do  v s = i  .
1: for each variable w ¡Ê c: if w is positive  we add obs w 1  ; else  i.e.  w is negative  we add obs  w 1  . 
before presenting a theorem that formally relates pcm theories and queries with our encoding  we need to consider a notion of  being able to compute unique solutions of a causal model using three valued iteration . consider the causal model from example 1 which had the functions: a = u ¡Äb. b = u ¡Å a. in example 1 we showed that for each value of u  there is a unique solution for a and b. in this case  these unique solutions can be computed in an iterative fashion. suppose we initially assign the value false to u. we then assign unknown to a and b. we now use 1-valued logic on the causal functions and compute the values of a and b. after the first iteration a has value false and b has value unknown. after the second iteration we reach a fixpoint where a and b are both assigned to false. this is what we refer to as  being able to compute unique solutions of a causal model using three valued iteration. 
having unique solution does not necessarily mean that it can be obtained using the above mentioned three valued iteration. following is a counterexample1:
let a =  b ¡Å c ¡Å u  b =  a ¡Ä  c  and c = a ¡Å  b.
when u is false we can not derive the value of a  b  or c by a three valued iteration. but  there is the unique solution a = true  b = false  and c = true that satisfies the causal functions.
theorem 1. given a pcmdenote the probabilistic query with respect to it and let the p-log lite program t be obtained by the encoding of m as described in the previous section. let b  c  y1 ... ym and x1 ... xm be realizations of subsets of the endogenous variables v . also let ymxi = xi be counterfactual statements  where mxi is a submodel of m. if all realizations of u = u give unique solutions for endogenousvariables in the submodels mxi and the unique solutions can be computed in an iterative fashion starting fromthe backgroundvariableswe have the following:

discussion on the theorem and its proof:
here the encoding has three main aspects:  i  the encoding of the pcm equations   ii  taking into account the severing of connections between variables when an action is performed  and  iii  considering models and submodels in parallel during counterfactual reasoning. for part  i  the notion of  unique solutions being computed in an iterative fashion  is important as that leads to a correspondence between the unique solutions and the answer sets. to do  ii  we use the negation as failure operator  not  and to do  iii  we introduce multiple time lines. overall  the proof is based on splitting the logic programming translation of t to many layers  where the bottom layer consists of the enumeration of the backgroundvariables.
1 pcm  pal and p-log lite
a related work is  tran and baral  1   where an encoding of pcm in an action language pal is given. the encoding here to a probabilistic logic programming language p-log lite is different from the encoding in  tran and baral  1 . there the key issue was to encode the severing of connection between variables when an action is performed. it was achieved by introducing an ab predicate and having effect axiom make vi  causes {ab vi  vi} and a static causal law  ab vi  causes vi   fi pai ui  to capture the pcm equation vi = fi pai ui .
1 non-naive conditioning in p-log
we now show how p-log provides an elaboration tolerant way to perform non-naive conditioning in that it shows a way to incorporate new observations through simple addition of knowledge rather than a surgery of existing knowledge. halpern in  halpern  1   uses the term naive conditioning to refer to conditioning with respect to the 'naive' state space one usually constructs when trying to reason. he discusses several examples  where naive conditioning gives the wrong answer. following is his second-ace puzzle:
a deck has four cards: the ace and the deuce of hearts and spades. after a fair shuffle  two cards are dealt to alice. it is easy to see that  at this point  there is a probability of 1 that alice has both aces  a probability of 1 that alice has at least one ace  a probability of 1 that alice has ace of spades and a probability of 1 that alice has ace of hearts.
alice then says   i have an ace.  conditioning on this information  by discarding the possibility that alice was dealt no aces   bob computes the probability that alice holds both aces to be 1. this seems reasonable. next  alice says   i have the ace of spades.  conditioning on this new information  bob now computes the probability that alice holds both aces to be 1. but suppose that alice had instead said   i have the ace of hearts.  it seems that a similar argument again shows that the conditional probability that alice holds both aces is 1.
is this reasonable  when bob learns that alice has an ace  he knows that she must have either the ace of hearts or the ace of spades. why should finding out which particular ace it is raise the conditional probability of alice having two aces  put another way  if this probability goes up from 1 to 1 whichever ace alice says she has  and bob knows that she has an ace  then why isn't it 1 all along 
halpern  halpern  1  analyzes the above example and points out that it is important to know to what question alice answered:  i have ace of spades.  he goes on to say that if she is asked  q1  to name an ace if she has any and it is given that if she has both aces she will pick one of their colors with equal probability  naive conditioningdoes not lead to the right answer. we agree with halpern. in this case instead of the naive possible worlds  one needs to take into account the new question and create a new set of possible worlds. plog allows us to do that within the language in a nice way. on the other hand if alice's answer is with respect to the question  q1  which asks if alice has the ace of spades  then the assimilation of alice's answer is different  and in this case naive conditioning works. the second-aces puzzle in p-log:
consider the following encoding ¦°1 of the second-ace puzzle in p-log.1card1 and card1 have the domain card = {1s 1s 1h 1h}. random card1 .
 p1 x  ¡û card1 = x. p1 x  ¡û not  p1 x . random card1 : {x : p1 x } .
hasalice x  ¡û card1 = x. hasalice x  ¡û card1 = x.
result 1. probabilities w.r.t. ¦°1
 i  p¦°1 hasalice 1s  ¡Ä has alice 1h   = 1
 ii  p¦°1 hasalice 1s  ¡Å has alice 1h   = 1  iii  p¦°1 hasalice 1s   = 1

now we will consider that alice's response of  i have ace of spades  is with respect to the question q1. in that case we propose that the new information is incorporated to ¦°1 by adding the following to ¦°1: random o : {x : p x } . p 1s  ¡û has alice 1s . p 1h  ¡û hasalice 1h .
we refer to the resulting p-log program as ¦°1.
result 1. p¦°1 hasalice 1s  ¡Ä hasalice 1h |o = 1s  = 1
a general methodology:
from the encodings in the previous section one can draw the lesson that when an observation x about a particular concept is made  one can incorporate that observation correctly and avoid possible error associated with naive conditioning by:
1. adding rules for a new predicate p x  that define the value that o can take.
1. adding the random declaration for a new attribute o: random o : {x : p x } .
1. adding the observation obs o = x .
moreover the steps  1  and  1  are useful for defining the values that an attribute can take. it is used in ¦°1 when defining the values the attribute card1 can take  after card1 has been assigned a value.
1 conclusion
in this paper we have shown how to do non-naive conditioning and encode pearl's probabilistic causal models  pcms  in p-log lite. we show how one can reason about simple observations  observations as a result of answers given to specific queries  interventions and counterfactuals  in p-log lite. there is a distinct difference between how reasoning about interventions and counterfactuals is done in pcms and in plog lite. in the former  surgery is done on a given pcm theory to obtain sub-models due to interventions  while in the later one just needs to add do facts  and let the semantics take care of the reasoning. another differencebetween the two approaches is that p-log  because of its superior logical knowledge representation aspect  allows one to specify more nuanced theories. for example  with respect to the firing squad example  one can express knowledge such as  rifleman b normally follows the captain's order . an elaboration tolerant representation of  normally  will allow easy elaboration
of new knowledge such as:  b  as a conscientious objector to death penalty  defies his captain with respect to shooting.  such representation and elaboration is straightforward in plog  while the corresponding pcm theory will need surgery.
1 acknowledgement
this work was supported by a contract from arda and nsf grant 1. we thank michael gelfond and nelson rushton for discussions on this topic.
