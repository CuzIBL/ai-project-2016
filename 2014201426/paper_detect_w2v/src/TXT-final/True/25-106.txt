 
this paper is about some of the social aspects of knowledge and action relevant to thinking in ai  and in particular the basic experience of multiple perspectives and integrating different kinds of local knowledge. it discusses ways of rethinking a number of familiar concepts including facts  interaction  knowledge  and organization  raising questions about how well we can currently capture their social dimensions conceptually  representationally  and computationally. it suggests several approaches to developing more complete computational models of these phenomena. 
1 	introduction 
this paper is about some of the social aspects of knowledge and action relevant to thinking in ai  and i want to explain a bit about how and why i these ideas came to interest me so deeply. the crux of the matter is that in my own intellectual life  i have been continuously involved in more than one  field  at once. two of the primary arenas in which i've found myself have been computing-specifically experimental computer science and ai-and sociology-specifically symbolic interactionism and studies of the integration of technology and work. the original idea i had was that these seemingly quite different arenas actually had a lot in common  and it would be interesting to try to articulate what i found fascinating in each to people who were more focused on the other-to be a boundary-spanner. for example  when i first seriously encountered computing in the mid 1s  the problematic of large-scale software development was central  and it certainly seemed that large-scale software 1  was developed by large groups of people   see  e.g.   scacchi 1   and 1  might have many of the structuring characteristics of large-scale organizations of other types  when software was seen as collections of processes  cf.   durfee  et ai 1; fox 1; fox 1; gasser  et ai 1  . similarly  some ai researchers were beginning to deal with questions of scale and concurrency. they turned their attention to multiagent and distributed systems  ostensibly to cope with increasing problem complexity and to reflect what they saw as basic characteristics of the  real-world   bond and gasser 1 . these movements within ai seemed to me to offer a very happy marriage with what i was reading about certain branches of sociology-most especially symbolic interactionism  the very name itself seemed just right  and later with  science studies  - the sociology of science and scientific knowledge. 
   in the midst of this ferment  1 quickly found that while the discourses in computing/ai and in sociology had stimulating and encouraging similarities  there were certain underlying assumptions that made them  in practice  virtually incommensurate. and  in a very real way  my personal experiences in the several worlds as a boundary-spanner mirrored the incompatibilities in the world-views. this experience of living in several worlds at once  then  is both the primary motivation for and the main point of the present paper: to help explain what it means for several world-views not to jive  and to provide some new ways of seeing  looking into  some basic issues of ai and computing through glasses of incommensurate perspective--to get at the pragmatics of deeply-experienced heterogeneity. 
　the basic experience of multiple perspectives  what might be called a fundamental point  is simply these two observations: 1  experiences vary over place and time  and 1  experiences in different places and times interact  necessitating some sort of integration. 
   elsewhere  i have discussed several notions that derive from these observations  gasser 1; gasser 1; gasser 1 . they include the existence of a fundamental tension between local and global knowledge and action; certain results concerning the impossibility of common semantics or shared representations; the nature of and strength behind commitment as a binding force in interagent relations  and the causal direction of goals  social laws  rules  programs  etc. in shaping behavior. taken together  it seems to me  the impacts of a perspective shift that first takes heterogeneity  not commonality  as given  and that second  observes the joint and interlocked nature of so much human and human-computer interaction  are great. how can this patterned  ongoing  joint  interlocked behavior be explained and designed  without recourse to commonality  
　the outcomes of long-term inquiries into these issues seem interesting to me  because they help to address questions such as what are the differences between ma-
	gasser 	1 
chine and human societies  how does this difference translate into explaining the problematics of how societies of machines and people coexist together  how do we as societies develop the categories of analysis that sometimes keep people and machines separate  and that sometimes treat them in common or related terms  to me  these sorts of questions are central to understanding the integration of computing  and of machines in general  with human activity. they critically influence the processes of construction and use of machines  e.g.  specifications  explanations for errors and for proper behavior  etc. . in a sense  i think it is important to build bridges between the social worlds of system development  use and comprehension  and the material worlds of computational artifacts. i believe that these are not just exercises in formality  but are practical issues of high impact. 
　the overall aim of this paper  then  is to begin some new conceptual modeling  or in fact re-modeling  of some familiar concepts-to take some concepts familiar in ai such as communication  interaction  individual agency  knowledge  action  etc. and to recast them from a viewpoint that takes a heterogeneous social system as its basis. 
　why would we want to do this  first  as an exercise in flexibility: trying to see things in new ways  and exploring alternative conceptions to those we are already familiar with. second  because we are beginning to confront conceptual problems with current approaches when we approach the social aspects of agent behavior  as in the following circumstances: 
  when we consider individual agents' cognition sit-uated in group and social contexts  rogoff and lave 1 . 
  when we consider groups  e.g.  organizations  as loci of action or knowledge  cf. ihutchins and klausen 1; weick and roberts 1  . 
  when we consider knowledge and activity that is distributed over space  time  semantics  etc.  bond and gasser 1; gasser 1; gasser 1  
  when we consider open versus closed systems ques-tions  such as creativity and the generation of fundamentally new forms. 
　in order to examine this process of re-modeling  we need some objects of study. 
1 	objects of study for social analyses 
i take one ongoing task of a mature science to be the specification of its objects of study-the delineation of the conceptual entities that are of interest for its scientists. what are the objects of study that raise questions of social knowledge and social action useful for progress and theory in ai 1 i'd like to make some observations about what things or phenomena we might examine and seek to describe  analyze  and explain in computational 
　　1 in describing the study objects that follow here  i mean the words  individual    organization * etc. to refer to either people or machines; i mean this as a provocative stance. 
1 	invited speakers 
terms  and to investigate what are some questions to raise about these things. this is a suggestive  rather than an exhaustive list; in particular it will leave out individuals ' knowledge and behavior  social cognition  that is  knowledge about social and organizational entities  higgins  et al. 1 ; risks  costs and moral order  and goals or intention  which i intend to treat at greater length elsewhere. 
1 	facts and social facts 
there are several kinds of alternatives to the relatively conventional  in ai  conceptualizations view that facts are statements about the world known to be true in all contexts  e.g.  possible worlds semantics of knowledge and belief . these include 1  the treatment of facts as continuously reinterpreted statements with dynamic  facticity -statements repeatedly transformed  reinforced  and re-valued as they are incorporated in ongoing discourses  cf.  latour and woolgar 1   so that their stable or reified character is a product of action  rather than simply a basis of action  and 1  durkheim's notion of  social facts.  durkheim described social facts as  ways of acting  thinking  and feeling  that exist outside individual consciousness  that are diffused widely within a group  and that exert  a coercive power  over the activities of individuals   recognizable by the resistance that it offers any individual action that would violate it.  he points out that when taking on certain social commitments   i perform obligations which are defined outside myself and my actions...we are ignorant of the details of the obligations we must assume  and ...to know them we have to consult the legal code and its authorized interpreters...the above statements will apply  to  each member of a society in turn   thompson 1   pp. 1. the point is that social facts reside in collectivities  not in individuals:  the determining cause of a social fact must be sought among antecedent social facts  and not among states of individual consciousness   thompson 1   pp. 1 . 
1 	individuals  facts  agents  etc.  
individual knowledge  performance and achievement has long been the focus of ai  cf.  bond and gasser 1; bobrow 1  . but much has been taken for granted. 
what is the nature of the individual agent  in what sense is it possible to conceive of an individual  carving one out of a continuous web of social interaction and involvement  said another way  what aspects of individuals are not social facts  what is the boundary of any individual  in terms of action  time  knowledge  perception  etc.  and how is our knowledge of these boundaries constituted non-socially 1 how do stable individuals emerge in the collective action of societies and organizations  . 
1
    once you think you have a clear answer to the boundary question  consider individuals as aggregates of parts-as  de composable systems-and see if your answer holds up! see below... 1  for the uninitiated  the notion of individuals emerging in collective activity may seem strange. two examples: stable software processes built and maintained by software teams 
   gerson has presented a simple and cogent conception of individual as  something for which nothing else will substitute for each and every purpose   gerson 1  pg 1. he points out that any conception of an individual thing depends on a recognizer  who assesses the substitutability and differentiation of the individual thing   and that the ongoing process of recognition is subject to mistakes. we discover and correct these mistakes  in general  due to the restrictions on action that they entail. suppose a medical-diagnosis knowledgebase is mistakenly loaded into a circuit-diagnosis system  and doesn't substitute. the diagnosis system does somethin-g-maybe it beeps  crashes  or emits an error message-but it doesn't cooperate with its user in diagnosing circuits. trying to treat a painter like a car mechanic won't work  because we depend on the painter's participation in fixing the car  and it's not forthcoming. in gerson's words   in specific local circumstances we live in a world of alliances which corrects mis-identifications   gerson 1  pg. 1  cf. durkheim's concept of the coercive power of social facts  mentioned above . 
   thus  says gerson  non-substitutability  is a function of cooperation and response from others; there is no single thing in general...we can reliably recognize something as an individual and as the same individual only if there is equivalence of criteria across recognizers  over time and place . this is achievable only for very narrow purposes and for relatively short periods of time.  moreover   some things  e.g.  people  can actively manipulate the process of recognizing  by how they  anticipate and negotiate the criteria which others use to recognize them. they can insist on some criteria and rule out others....they can decide to be another individual  or  to be  individual in another way. when this happens we have things recognizing or constructing each other as individuals  the identity of each being dependent upon its cooperation with the identity of the other. in this situation  things demand recognition of their identities on their own terms as the price of cooperation   gerson 1  pgs. 1. 
1 	i n t e r a c t i o n s 
what is the nature of interaction among individuals  do we need a clear and delineated conception of the individual in order to conceive of interaction  for example  once we have located the very nature of individual agenthood in social processes-once agents become social facts-against what ground are we to give semantics to messages which travel across time and place between agents  what are the boundaries of interaction  for instance  suppose a sending agent gives notice to a receiving agent that  a proposal will arrive in a following message.  where and when does the interpretation of the proposal message begin and end  does it begin with the notice message  does it begin with prior messages  activities  and world states that over time generated the 
are very clearly individuals that continuously  re emerge in social processes. similarly  people are products of collective action in very physical ways-food  clothing  shelter  health care  etc. are all continuously and collectively  re arranged  and the knowledge involved in these activities is no less so. internal and external structures that allowed for interpretation of the notice message and subsequent assimilation of the proposal message  how do we separate the interpretation of a message from the activity and structures that establish the context in which it is interpreted   cf. gerson's note on the ways agents can influence their own substitutability and identity . it is certainly possible to set up very complex interpretation structures beforehand and to reduce interaction to sending a very small set of tokens  or even to sending none  genesereth  et al. 1 -that is  to place more and more of the import of the message into what kenneth gergen has termed the retrospective and emergent contexts of action  see below . it would seem that the nature of the boundaries of interpretation  hence of the meaning of  message  is contingent on the socially-emergent definition of  message  and the nature of these contexts. 
　of course  the same is true of other kinds of interactions. gergen has indicated the difficulty of interpreting and even of identifying social action  using the following example: 
　　 if i see my friends ross and laura approach each other at a social gathering  and ross reaches out and momentarily touches laura's hair  precisely what have i observed  what action has occurred before me  how am i to identify it    gergen 1  pg. 1. 
　gergen points out that while precise measurement of the movements  e.g.  assessments of physical state change  might be possible  they would tell us little about what the movements mean in terms of ongoing relations at the social gathering  before it  and after it. that is  any such measurements would tell us little about how to act in relation to laura  ross  and others. he points out that  and gives long examples of how  both  retrospective context   things that have occurred and interpretations that have been made before the observed action  and  emergent context   occurring after the action  play key roles in our interpretations. as we piece together these contexts  new information may trigger arbitrary revisions of prior interpretations.  we should note  following durkheim  that all of these interpretations and the processes of their revision are subject to the coercive power of social facts.  this leads gergen to three conclusions  quoted from  gergen 1  pgs. 1;  collins 1  and  baker and hacker 1  make many similar points : 
1.  the identification of any given action is subject to infinite  post-hoc  revision.  
1.  the anchor point for any given identification is not fundamentally empirical  but relies on a network of  other  interdependent and continuously modifiable interpretations.  
1.  any given action is subject to multiple identifications  the relative superiority of which is problematic.  
　the basic point of conclusion following gergen's analysis is that actions by themselves  that is  measured changes of state  the most common representations of action in ai  are next to useless as a ground for identifying 
	gasser 	1 
and understanding social activity. this is especially the case since so much social activity is a matter of symbolic interaction  not physical constraint  and such symbolizations are durkheimian social facts  situated with ongoing activities. where is identification and specification of action  and  by extension  of state  to be  grounded   the perception  identification and interpretation of action from a social standpoint is a matter of classification within a system of meanings  that is  within a localized classification system which itself is a collection of social facts  and thus has socially coercive power . as w.i. thomas has pointed out   things perceived as real -that is  perceived through a socially-factual system of classification and interpretation- are real in their consequences   thomas 1 . what we haven't yet been able to accomplish squarely  it seems to me  is to model computationally the dynamic  social  and multilayered nature of classification and interpretation processes  so that they are intimately coupled with  and become  a coercive social power. the stability of our networks of interaction comes  in general  by predefinition  through predefined  regular computational structures  rather than by emergence and social interaction among participants. 
1 	p r a g m a t i c k n o w l e d g e 
suppose we consider the pragmatic knowledge of a system to be the ability of that system to produce certain patterns of outputs when given certain patterns of inputs. for example  if a particular knowledge-based design system is given information about technical features of a manufacturing technology  organizational goals  etc.  and manages to produce acceptable human infrastructure designs  gasser et ai 1    we could say  intuitively  that the system  knows how  to produce useful designs. that is  it produces input-output mappings judged effective by some evaluator. if a vehicle tracking system is given a set of low-level sensor data and produces accurate interpretations of that data as vehicle tracks  we will say that the the analysis system  knows how  to produce those interpretations  cf.  durfee  et ai 1 . this view of the knowledge of a system locates that knowledge in what the system actually does in context-not in what is the lasting truth-value of statements in its knowledgebase1. that is  from this vantage point  the pragmatic knowledge of a system encompasses all the circumstances of that system's use  including the process by which its results are judged to be acceptable  the re-
sources it uses  and even  in the extreme  that fact that the system was supplied with power-for without these things  by our definition  the system would not  know how  to produce interpretations or designs. 
　with this pragmatic view of knowledge as  knowing how to do   we ground knowledge in the practical be-
1
　　to me  this makes more sense anyhow  because facts  statements  in and of themselves are useless; any  fact   to be useful  must be applied  in a context-that is  it must somehow be incorporated into action. this is not to say that a system with such know-how is autonomous in its knowledge  or that somehow the knowledge is solely embedded in the system itself-in fact my argument is just the opposite. 
1 	invited speakers 
havior and context of a system. if the system has  all the facts   necessary to address a problem  and so is  epistemologically adequate   in mccarthy's terms   but cannot move deductions based on those facts from one place to another within its internal organization  then the system doesn't  know how  to produce its results. if a result is described by a quality or time constraint  and the system cannot structure itself to meet that constraint  then  the system does not  know how  to produce its results1. moreover  if the interpretation of a system's output changes after the output has been produced  emergent context   then that system's knowledge has also changed. thus pragmatic knowledge is not solely located  within  the system  but is the outcome of the engagement of the system with its inputs  and with its interpretive  i.e. retrospective/emergent  and resource contexts. 
   one way to see part of this notion computationally is to think of flexible distributed production systems such as the one discused in  ishida  et ai 1 . this system allowed flexible reconfiguration of production systembased agents  their number  identity  and knowledge boundaries  in response to changing environmental demands and resources. when faced with time  quality  or resource demands it could not meet  the system reorganized its agent-to-knowledgebase associations  including facts  rules  and agent models   adding or deleting agents until the demands could be met or until the overall system resources were overtaxed. that is  the pragmatic knowledge of the system-being able to produce results that met external criteria-was a matter of the dynamic system organization tn the particular environmental context  and not simply of the facts  rules  and mapping knowledge in the agents' databases. changing the environmental demand meant that knowhow disappeared and then was recovered as the system adapted its structure. 
1 	o r g a n i z a t i o n a l c o g n i t i o n 
how can concepts such as action  cognition  perception  and memory be conceived where organizations and groups are the active  cognizing  perceiving  remembering entities  cf.  hutchins and klausen 1; weick and roberts 1    for each of these concepts  where is its locus  and what gives it its stability or pattern  how does organization emerge along with the collective action of individuals  
   first  let us consider the issue of aggregation: how to  put together  collections such as knowledge-based processes   agents   and/or people into an organized whole  and how to have them act together in response to some higher-order phenomenon-that is  a phenomenon at the level of the whole  not at the level of the components. what would this look like  
   we can think of aggregation as having the following four aspects. first  there would be some identifiable entities that are put together. second  these entities would be individually responsive to some environmental circumstances on their own-there must be a way of 
1
　　this is not entirely like mccarthy's heuristic adequacy  because it encompasses factors outside the system. 
talking about them as individuals  with respect to some class of environmental stimuli and substitutability criteria. third  there would be some mechanism or process that welds them together into an ongoing unit that exhibits some routineness  stability  or pattern. fourth  this higher-order unit would itself respond in some patterned way to some qualitatively different class of stimuli  such that the overall response of the aggregate is different from the response of the individual units. that is  the group of individuals will not be substitutable for the aggregate with respect to the ongoing aggregate-level environment  and the responses and character of the individuals would be different by virtue of their participation in the organization. 
   from this description we can see there is some relationship between the interconnecting process and the class of higher-order stimulus that defines the nature of the aggregation. we can also see that the defining characteristic of an aggregate is 1  that it is a higher-order patterned response  which means that the interactions among parts must also be patterned to some degree  and 1  that the identifying character of the aggregate is determined in part by the character  and level  of the stimulus and response; in effect  the environment has a hand in defining whether something is an aggregate or not.  this is in line with the previous discussion of individuality as non-substitutability.  
   note that nowhere have we spoken of the members of the aggregate having any sort of  common  goals or intentions. to be identified as an aggregate vis-a-vis some observer or interactor  it is sufficient that there is an overall pattern to the members' collective activity in response to a class of stimuli  and we need not attribute any notions of  cooperation  or  working together  to that pattern1. 
   overall  for thinking about socially-constituted knowledge and action  we would like to avoid the notions of goal and intention because we want to deal with multilevel aggregates at multiple and arbitrary levels of aggregation. in such structures  concepts such as goals and intention become problematic  because we don't have a clear idea of where to situate responsibilities  e.g. of parties for goals  when parties are aggregates  or how to allocate action  e.g.  for achieving goals  when action is distributed and simultaneous. 
   a number of proposals and approaches to aggregation exist for ai systems. these include: 
  aggregation using commitment and action restric-tions  levesque  et al 1 . 
  aggregations using federation  that is  coupling through standard languages  or interaction interfaces  such as those proposed for enterprise integration and knowledge interchange  eif 1 . 
  aggregation using metaobjects and metalevel in-formation  including representations or models of other agents for prediction and interpretation as used commonly in d a i approaches to coordination 
1
　　this also opens the door to reconceptualizing goals and intentions as simply repeated patterns of action  rather than as mental states; details will be left to a future paper.  durfee  et al 1; gasser  et al 1; gasser and briot 1  
   as currently described  all of these still require apriori common objects  namely the interaction languages  metaconcepts  and behavioral rules or programs that will cause agents to conforms to the standards. how can we think of an alternative  
   what we need to look at is not shared metalanguages for interaction  but instead the processes through which new metalanguages become generated  accepted and integrated. a particular interaction standard is not the interesting part-the interesting part is the standard formation process itself; this is what we need a model of. this is because  first  we should begin to think about aggregation as not as state but instead as an ongoing process of aggregating  cf.  weick 1  . a consequence of this is that boundaries of aggregates are always fluid  in terms of knowledge and action. second  in successful precesses of aggregation  something keeps the parts together over time. that is  something keeps the aggregating process  on track.  aggregation is then not a state  it is a process of keeping things on track. how is this accomplished  we might suggest that if can be accomplished in several ways: 
  by setting up social barriers to participation  social coercive power : if a participant doesn't conform to the recognized interaction patterns  it doesn't get into the game. how do these patterns come about  one way to think about this is that those agents who already have a game going in some way that get to set up new games with new requirements. one would expect that in open systems  aggregations would build around existing islands of compatible behaviors  rather than in a completely adhoc fashion  and this reflects observed patterns in biology and in social groups . 
  by establishing open systems of checks and balances for assessment and social control. rather than hierarchical systems  in which distributed control meets singularities at the top and bottom of the hierarchy  we need to explore non-hierarchical control regimes in which agents control one another via distributed checks and balances. 
  by balancing degrees of reification and control with environmental pressures for disaggregation-that is  intentionally allowing interpretations and actions to vary for different participants  and allowing room for local adaptation  e.g. by activities of fitting  augmenting  and working around  gasser 1  
for example  in the context of a theory-based organization design/analysis system under construction at usc  gasser et al 1   we have found that system interactions tend to be differentially interpreted in different organizational and social contexts  yet those contexts must interrelate. thus the same system inputs and outputs must serve as bridges across organizational cultures. this has meant i  a conscious decision to use loosely-defined user input categories and qualitative input measurements  such as high-medium-low   so that the definitions 
	gasser 	1 
more easily fit into local users' interpretations  1  user-tailorability of the definitions of the system's key conceptual vocabulary  and 1  a model of design as alignment between user-interpreted criteria. thus the social use of a system fosters reconfiguration of its meanings.  additional examples of this sort of reconfiguration in the context of error redefinition and system workarounds are provided in 
 gasser 1 .  
1 	conclusions and some new research actions 
trying to use individual programs as a basis of action in distributed  situated  or group-based systems is like trying to use individual facts as a basis of action: they are insufficient in themselves. thus  the idea of building a distributed community out of a pre-existing collection of programs is inadequate  when we treat programs as facts-programs must be evolved by the community at all levels. of course  in reality this is what happens  if we consider the actual trajectory of any program  and not just at its autonomous behavior. what makes it work in practice is the open human activity in the marketplace of its use and evolution. 
　in a similar vein  the notion of substitutability in flexible social contexts is key to understanding knowledge interchange and interoperability of heterogeneous systems. using programs in different contexts is a social process  and can't be located in the interaction languages or individual programs themselves. 
　most dai research works from the premise that some stable set of agents with stable architectural boundaries come together and coordinate their activities in the solution of joint problems. that is  a stable society of agents emerges from the constructive interactions of multiple pre-existing members. the primary problem  then  is how to design the individuals so that they can effectively coordinate when enlisted in joint problem-solving situations. in the social theories underlying these systems  social roles and social-level effects are founded in individual action and knowledge. 
　the argument in this paper is not that machines and mechanized knowledge or action necessarily are and must be inherently a-social. instead  i have been trying to show  first  something of what we might need to do to incorporate greater sociability into machines  and second  some more directly social angles for thinking about the machine/human ensembles that we do work with. unlike the stances of collins  dreyfus  searle  etc.  collins 1; dreyfus 1; searle 1   i'm not saying that for ai to be complete in some sense  artificially intelligent agents must be fully socialized. instead  i'd like to suggest that with computers as partners  we have several opportunities to explore alternative theoretical models of sociability and culture  namely  the varieties of society and culture that emerge among collections of semi-autonomous machines and people-machine ensembles. i suggest seriously treating these as alternative  model cultures and societies  to learn more about how far our current conceptualizations of culture and society go. 
1 	invited speakers 
　here are some suggestions for how to take some concrete steps toward more fully social yet nonetheless computational models: 
  learn to describe  build  and experiment with com-munities of programs 1  that generate  modify  and codify their own local languages of interaction; 1  in which kinds and degrees of structure and reification and both increase and decrease with use; and 1  that modify both their knowledge and their activity structures at all levels of analysis-i.e.  communities of programs that evolve the languages in which they are written. 
  define and demonstrate social mechanisms of dy-namic category formulation  classification  and concomitant reification-the active  re formulation of agreed-upon basic concepts and their use in joint interpretation and discourse processes.  social mechanisms  would be those in which categories  classification activities  reifications  structures  etc. were subject to durkheim's social coercion. 
  investigate how these and similar reasoning  mod-eling  explanation  and activity structures-e.g.  dynamic aggregation  reification  etc.- appear in other fields and contexts  including biology  evolutionary  developmental  and theoretical biology   formulation of scientific knowledge  and social control/social change processes. 
1 	acknowledgements 
both the style and substance of this paper have been significantly influenced by the work of leigh star  who  with many others  has eloquently argued the necessity of making work and responsibility visible. the other primary influences on my thinking here have been phil agre and  as usual  elih gerson. the actual writing was simplified greatly by the generous encouragement of leslie b. hill. 
