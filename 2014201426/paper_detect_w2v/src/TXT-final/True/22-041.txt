 
speed alone is insufficient for real-time performance. we define real-time performance in terms of speed  responsiveness  timeliness  and graceful adaptation. we claim that all four aspects are essential if a system is to support real-time problem-solving. we also present a distributed knowledge rocessing architecture based on the lackboard paradigm that addresses all aspects of real-time performance. primary attention was given to flexibility of behavior without compromising on the efficiency of implementation so that the applicability of the architecture to an application may be experimented with. performance metrics are crucial for validating real-time performance  and form an integral component of a real-time system. in this paper  we present performance metrics for responsiveness and timeliness at the architecture level. 
1. introduction 
　　real-time performance issues have only recently begun to attract the attention of the ai community. this is largely spurred by the emergence of real-time applications amenable to ai techniques: manufacturing process-management  in-flight fault diagnosis systems  darpa's pilot's associate and battle management programs  and nasa's mars rover and space station initiatives. such problems may best be characterized by the highly dynamic environments providing input data as well as one or more interactive users who influence the system's problem-solving processes. 
　　the richness of the applications enable not only testing ai approaches  but generally  incorporating innovative hardware and software approaches. however  all these approaches tend to  overlook  the real-time per formance aspects of the problems in lieu of the more interesting  non-real-time aspects. we have made real-time issues primary to our research without compromising on other aspects of problem-solving  essential for the complete solution. we firmly believe that a direct solution to real-time issues lies in a performance-oriented  yet flexible knowledge processing 
author's current address: ai center  intel corp  p. o. box 1  
sc1  1 mission college blvd  santa clara  ca 1 
1 	real-time and high performance software architecture. 
　　the paper introduces  in section 1  a definition of real-time. the real-time architecture is presented in section 1. the performance metrics  defined in terms of the real-time definition  which are used to validate our architecture are discussed in section 1. we follow this with related work described in section 1. conclusions and future directions are presented in section 1. 
1. what do we mean by real-time  
	real-time 	systems 	have 	been 	defined 	as: 
 predictably fast enough for use by processes being serviced''   marsh and greenwood  1 ;  there is a strict time limit by which a system must have produced a respoase  regardless of the algorithm employed''   o'reilly and cromarty  1  ;  ability of the system to guarantee a response after a  domain defined  fixed time has elapsed    laffey et al.  1  ; and   a system  designed to operate with a well-defined measure of reactivity   fgeorgeff  1  . these definitions are general and hence and open to interpretation depending on the problem at hand. in fact  stankovic  presents an excellent analysis of real-time systems which lays out some of the shortcomings of current approaches. 
1. four aspects of real-time performance 
　　while speed is indeed fundamental to real-time performance  speed alone is not real-time. the four aspects of real-time performance are: 
  speed 
  responsiveness 
  timeliness  and   graceful adaptation. 
　　speed is the rate of execution of tasks. tasks could refer to problem-solving tasks  large or small  or eventprocessing tasks. 
　　responsiveness is the ability of the system to stay alert to incoming events. since an interactive real-time system is primarily driven by external inputs  the system should recognize that such input is avail able. it may not necessarily process the new event right away; that may depend upon the its criticality relative to other events the system is currently processing. 
　　timeliness is the ability of the system to react to and meet deadlines  which can be achieved by processing the more critical tasks first. criticality of tasks may be defined by several factors  either domain dependent or 
　　
domain independent or both. for instance  urgency of response to an event is related to the amount of slack time; that is  the difference between the earliest start and latest start for the event to still complete before its deadline.  the deadline for an event is specified by the domain.  yet another example is the importance of an event relative to the other events  strictly a domain issue.  importance of an event may depend upon the 
context  hence would be dynamic.  
　　graceful adaptation is the ability of the system to reset task priorities according to changes in work load or resource availability. graceful adaptation allows for a smooth transition across potential perturbations to the system. without this ability  the system may waste processing resources as well as time by executing less relevant tasks or wait for scarce resources. 
　　it seems imperative that we utilize a knowledge processing approach in order to address all four aspects of real-time performance to solve problems of the type and complexity listed earlier. 
1. a real-time architecture 
　　we now present a real-time knowledge processing architecture  rt-1  which conforms to the real-time definition given above and supports evaluating an application in terms of its requirements on speed  responsiveness  timeliness  and graceful adaptation. we will discuss the overall rt-1 architecture first  followed by a description of the component modules and processes. 
1. overview of the architecture 
　　rt-1 is a small-scale  coarse-grained  distributed architecture based on the blackboard paradigm. 

　　　the main features of the top level architecture  shown in figure 1  are: 
　　  it consists of a collection of reasoning modules which share a common blackboard dataspace and communicate with each other by signaling events. the reasoning modules run in parallel on independent processors. 
　　  the reasoning modules operate asynchronously. some of the modules in the rt-i system may be in the communication mode  accessing the blackboard or signaling events  while the others may be in the compute mode  making control decisions or executing domain actions . the asynchronous mode of operation of the modules eliminates the inefficiency associated with synchronous operation in which faster modules have to wait for the slower modules in order to accomplish the synchronization. 
　　  each reasoning module is event driven. knowledge processing actions in a reasoning module are triggered by events. events may be signaled by knowledge sources in the reasoning module or by blackboard changes. these events may be made available to all reasoning modules. 
　　  there is an event directory which used to route events to their destination modules. events are signaled by the sender without designating the receivers. the event directory  established at compile time  serves to route an event signaled from a module to the appropriate destination modules interested in processing the event. the advantages of the event directory are the reduction in volume of communication  since events do not have to be broadcast  and that a module receives only those events for which it has the capability and interest to process. 
　　  the blackboard is the shared repository for data common to all reasoning modules. typically  blackboard data may be used to establish context for knowledge processing actions  generate hypotheses  as well as to control problem-solving within the reasoning module. in a distributed multiprocessing environment  the blackboard is also distributed with each module physically storing only a part of the shared blackboard. the blackboard path facilitates the sharing of information  transparent to the individual reasoning modules. 
the rt-1 system is implemented in genera 1 on the 
symbolics lisp machine  using flavors and common 
lisp. 
1. the reasoning module 
　　the reasoning module  as shown in figure 1  consists of three processes linked via blackboard and event paths. the three processes are: the i/o process  the blackboard process  and the reasoning process. 

　　　the i/o process allows for the asynchronous sending and receiving of events to and from other reasoning modules. the blackboard process executes a queue of blackboard demons. the blackboard demoas are low level routines initiated as a result of blackboard transactions. the reasoning process performs the knowledge processing actions of the reasoning module. 
1.1. the i/o process 
　　the i/o process within a reasoning module receives incoming  external  events from other reasoning modules and sends out events from the reasoning process of its reasoning module to other reasoning modules. the i/o process is capable of queuing the external events on the asynchronous event list while the reasoning process 
	dodhiawala  sridharan  raulefs and pickering 	1 
　　
is in any one of its top level cycle steps. the outgoing events are checked against a global event directory to determine the destinations of the event  and the i/o process then dispatches the events appropriately. 
1.1. the blackboard process 
　　the blackboard is shared by all the reasoning modules. the class definitions of various domain dependent objects reside on the blackboard. at run time  modules may create or delete instances of these objects  or read or modify the slots of the instances. the blackboard objects may have demons associated with these transactions. the demons perform computations  like range checking on data  calculating averages  or time-stamping updates  that are too mundane for the knowledge processing actions in the reasoning process. the blackboard demons execute in the blackboard process and may also signal events which  for instance  may indicate anomalies like  out of range  values. thus  blackboard demons provide a way to decouple knowledge processing actions  in knowledge sources  from the data validation actions associated with blackboard data. without the blackboard process  these tasks would have to be performed by the reasoning process  possibly via knowledge sources  resulting in increased overhead in the reasoning process. 
　　the blackboard also holds control information used by the reasoning module and its processes for performing control decisions. information about goals  plans  their status  current problem-solving strategy  and temporal constraints is stored in the control structures. 
1.1. the reasoning process 
　　the reasoning architecture  shown in figure 1  is based on the blackboard paradigm. the system is eventdriven with knowledge processing actions embodied in knowledge sources and shared data stored on the blackboard. 

figure 1: the reasoning process 
　　the reasoning process receives external events from the i/o process and the internal events signaled as a result of actions of the knowledge sources. the top level cycle of the reasoning process is made up of four steps: trigger  precondition check  schedule  and execute. 
　　the trigger step is mainly responsible for recognizing the arrival of events and establishing relevant response s  to these changes. an event may trigger knowledge sources which are instantiated as knowledge source activation records  ksars . see 
 hayes-roth  1  for more details on the trigger step. 
the precondition check step ascertains for each 
1 	real-time and high performance 
triggered ksar whether the information context exists for the execution of the action body of the corresponding knowledge source. this check also permits obviating a ksar in case the context can no longer be established or the ksar has simply become redundant or obsolete. preconditions establish the readiness criteria for knowledge source execution. 
　　the schedule step establishes the appropriateness of executing the executable knowledge sources at any point in time. it prioritizes the executable ksars using control heuristics.  this is ksar prioritization  in contrast to event priorities associated with event channels explained below.  the control heuristics defined within a reasoning module establish control regimes for the various goals of the reasoning module and these  in turn  contribute to the goals of the overall system. the set of active heuristics allow focusing the system's resources to achieve the current goal in a timely manner and may be changed dynamically. 
　　the execute step uses the execution margin  described below  to select a subset of the scheduled ksars and executes  in the same cycle  the action body of the corresponding knowledge sources. the preconditions are checked just prior to execution to reaffirm the information context. if the context is invalid  the failure body of the knowledge source is executed instead. knowledge sources may signal new events  perform blackboard transactions or even change control parameters that enable decision-making on what actions to prefer next. 
　　the main features of the reasoning process that support real-time performance are the prioritized event channels  the explicit control reasoning capability  and the regulation of reactivity via execution margin. the prioritized event channels allow more critical events to be processed before less critical events. control reasoning permits opportunistic selection of knowledge sources which best meet the current goal of the reasoning module  and thus  the goal of the overall system. execution margin allows the system to be completely reactive  completely goal-directed  or any intermediate state that strikes a balance between reactive and goal-directed behavior. 
　　the external events  signaled by other reasoning modules' reasoning processes  are called asynchronous events  while the events that are signaled internally within a reasoning process are called synchronous events. associated with each event is a priority. the different event priority levels are determined by the application. the reasoning process is sliced into multiple channels  one for each event priority level. these channels extend across the top level cycle of the reasoning process. an event's priority determines the channel to which it is routed. further processing of the event  as it proceeds through the various steps of the top level cycle  continues on the same channel. the top level cycle is uniformly similar for all the event channels  and  as described above  applies to any event channel. however  it may be customized for an event channel commensurate with the priority associated with the events on that channel. 
　　the rationale behind the multiple event channels is to pay more attention to events of higher priority. the top level cycle processes events and knowledge sources on the highest event priority level. only if there is no work to be done on the highest channel will the top level cycle proceed to work on the next lower event 
　　
channel. in this way  event and knowledge source processing on the lowest channel is possible only if there are no outstanding events or knowledge sources to be processed on the higher channels. thus  the reasoning process will be more responsive to events in the higher priority channels. however  the increased responsiveness of the higher priority event channels comes at the expense of the reduced responsiveness of the lower pnority event channels. from this discussion  it is evident that the reasoning process is a single process with a single locus of execution. channel mix  or allowing more than one channel to be processed in a single top-level cycle  allows for simulated multiprocessing capability within the reasoning process. 
　　execution margin amortizes the control overhead by executing multiple knowledge sources  as compared to single knowledge source execution found in most blackboard systems . it allows trading off responsiveness for timeliness. an execution margin setting that results in selecting only one ksar from the prioritized agenda and executing its knowledge source allows fast cycle times  thus displaying responsiveness to the incoming events. the disadvantage of this setting is that if there are no new events  the response to the goal at hand is being unnecessarily interrupted. however  an execution margin setting that results in selecting all the ksars on the prioritized agenda and executing the corresponding knowledge sources is goal-directed  displaying timeliness to system goals. the disadvantage of this setting is lack of responsiveness to incoming  possibly critical events. the spectrum of values of execution margin between these two extremes establishes a compromise in responsiveness and timeliness. the output of the execute step is a set of events created by the executed knowledge sources. realize that an event signaled from a knowledge source may have a different priority assignment than the priority of the event that signaled the knowledge source. hence  new event priorities may change dynamically via knowledge source execution. 
　　the reasoning process offers considerable flexibility in experimenting with the various features. in fact  the strength of the architecture is just that: it is malleable enough to allow adjusting the features of the system for a variety of applications. 
1. performance metrics 
　　the rt-1 system is well instrumented. we measure various aspects of the performance of the system in a separate process  not discussed above. the probes in the system are used to compute various performance metrics and indicators. currently  these metrics and measures are defined at the architecture level. they permit experimentation with the features of the system and primarily help to analyze and validate the architecture. the first phase of our performance metering and experiments addressed different aspects of responsiveness and timeliness. evaluating the architecture for graceful adaptation is not complete at this time and will be reported later. 
1. real-time performance measures 
　　we describe the real-time performance of the rt-1 system in terms of measures  metrics  and probes. a 
　　performance measure is a quantity characterizing a particular aspect of real-time performance. ranges of values for performance measures are generally unbounded. a performance metric is a normalized measure so that there are upper and lower limits for the values of a metric  usually related to best and worst case performance. a performance probe allows the rt-1 system to collect performance data throughout a run. 
　　performance measures allow comparisons between the system's performance for the different settings of the system parameters  such as execution margin and control heuristics. performance metrics provide the basis for rating what has been achieved with regard to optimal and worst performance and for making further judgements based on those ratings. performance measures and metrics are computed from data collected by the probes. 
1. responsiveness measures 
　　the responsiveness of a system is inversely related to the channel latency or the total time it takes to notice a new event  and to begin composing a response for the event. the response task for an event e includes the set of ksars triggered by event e and eventually executed. the response latency is the time between the signaling of an event until its response task completes. response latency is computed from time-stamps that the 
rt-1 system attaches to events. the five probes for an event e are: 
1. sending-time e  is the time at which e is signaled. 
　　1.receiving-time e  is the time at which e is received by a reasoning process and placed on one of its event channels. 
　　1.begin-ack-time e  is the time at which e is acknowledged by a reasoning process; that is  the time at which the reasoning process starts triggering ksars off the event. 
　　1.end'scheduling-timelcycle# e   is the time at which the scheduling step of the top level cycle for the cycle numbered cycle# e  ends. here  cycle# e  is the cycle in which e was acknowledged. 
　　1.event-response-time e  is the time at which execution of the last ksar in the response task of e terminates. 
　　from these time-stamps  we can compute the following latencies: 
　　l.the communication latency for an event e is the delay between the time e is signaled and the time e is received by a reasoning process.  see rl in figure 1.  
　　1.the channel latency for an event e is the time for which e stays on an event channel of a reasoning process  starting at the time it is received by the reasoning process  and ending at the time the reasoning process starts triggering ksars from the event.  see r1 in 
figure 1.  
　　1the tps latency for an event e is the time the system spends on triggering t  ksars from e  checking preconditions p  of the triggered ksars  and scheduling s  the activated ksars  all in the cycle where ksars are first triggered off event e. the tps latency is the time delay caused by activating and scheduling the response task for event e in the cycle where event e is noticed or acknowledged. it does not include delays for checking preconditions and rescheduling ksars that remain in the system after the first cycle of noticing event e.  see r1 in figure 1.  
　　1. the execution latency of an event e is the delay between the time when the ksars in the response task 
	dodhiawala  sridharan  raulefs and pickering 	1 
of e are first scheduled and the time at which the last 
ksar responding to e terminates execution.  see r1 in 
figure 1.  
     the total response latency for an event e is the sum of the above four latencies. it reflects the time delay between occurrence of e and completion of the response to e.  see r1 in figure 1.  
　　the average channel latency is the indicator of the responsiveness of a channel. if the average channel latency is low  the system is extremely responsive to the events on that channel. it is evident that the channel latency deteriorates as one goes from the highest priority channel to the lowest priority channel. also  the channel latency is primarily influenced by the following features  taken one at time: 
　　  the channel latency increases with increasing cycle time of the same or lower channels. 
　　  the channel latency increases with increasing values of the execution margin setting of the same or lower channel. 
　　  the channel latency is affected by channel mix. the channel latency of the higher channel increases while that of the lower channel decreases with channel mix turned on. 
　　  the channel latency is higher if the granularity of knowledge source is large on the same or lower channels; lower otherwise. 
a good metric for responsiveness is channel-latency e /total-response-latency   . 
　　in general  small cycle times improves responsiveness. 
1. timeliness measures 
we make two assumptions about event deadlines: 
　　  each synchronous and asynchronous event received by a reasoning process has a required deadline for completing its response task. the deadline is specified as a delay after the sending time of the event. 
　　  for each event  it is possible to recognize when a response for that event is completed. 
we define event response timeliness  ert  as: 
ert e  := response-time e  - deadline-time e  
　　ert is zero if the response is on time  negative if early and positive if late. 
　　ert gives a measure of lateness  and can be used to measure the how well the system did on an individual event basis. however  a more global perspective is desirable  possibly over sets of significant events  or event windows. event windows may either be based on event receiving times or event response times. very simply  the complete processing cycle is an event window. averaging over ert values within a window of both early and late responses causes negative and positive values to cancel each other  and destroys information about the distribution of response timeliness. we propose l-ert and lw-ert measures to include only late events. 
　　late ert  l-ert  averages erts of those events in the event window w which are late  as given in equation tl in figure 1. 
since not all events are equally important  late 
weighted ert  lw-ert  takes a weighted average of 
erts of late events in a given event window. equation for lw-ert is given in t1  figure 1. 
　　both l-ert w  and lw-ert w  are unbounded nonnegative numbers. corresponding averages may be computed for early responses. 
　　one possible lateness-factor may be the lateimportance-mass-ratio  late-imass-ratio  of an event  defined as equation t1 in figure 1  where importance k  is the importance rating of the ksar k by a domain specific control heuristic  and response-task e  the set of ksars that were triggered by e and ultimately executed. using late-imass-ratio as the lateness factor in lw-ert weights events by the portion of the response that missed the deadline. 
　　the ratio lw-ert w /l-ert w  is a metric defined only for windows where some events have late responses. lw-ert w    l - e r t   h   since late-imassratio ranges between  1   and the metric tends towards 1 as less mass is completed late. thus  it indicates whether the system  and the particular control regime used during w  prefers more important events. 
1. related work 

	1 	real-time and high performance 　　there is ample literature on real-time systems in general. real-time ai has not received widespread attention until recently  particularly when conventional approaches fall short of handling the complexity of today's sophisticated applications. most of the issues that are primary in our research are succinctly expressed by stankovic  . the survey by  laffey et al  1  is a good starting point of getting acquainted with the state of real-time ai. the work in process control   raulefs and thormiyke  1  raulefs et al  1   was the primary motivation for our interest in real-time problem-solving.  dodhiawala  et al  1  is an expanded version of this paper  reporting some of the motivations behind the rt-1 architecture  and results of early experiments. 
　　current work on guardian   hewett and hayesroth  1   addresses some of the issues in asynchronous communication in bb1  leaving the main inference engine almost intact. their primary goal is to deliver sensor data in a timely manner  with the reasoning process capable of setting sensor sampling rates and fusion commands. 
real-time planning as addressed by durfee and 
lesser   durfee and lesser  1    raises issues of appropriate level of planning mainly because plans may cnange due to unforseen implications of plan actions or to new information from the environment that violates plan assumptions. the issues of approximate reasoning in  lesser et al  1  have been part of our research also. in fact  lw-ert based on the late-imass-ratio as the lateness factor gives an indication of how the system did in terms of partial results within the event's deadline. in rt-1  it may be used in an anticipatory fashion to determine how good an answer may be made available in the given time. 
　　prs   georgeff  1   utilizes a variant of the blackboard architecture and primarily addresses issues of reactive responses and meta-level reasoning comparable to our event priority channels and control reasoning. however  prs lacks the flexibility we offer in rt-1. one advantage of prs is its knowledge area formalism. 
it allows sequencing of knowledge sources and already contains a lot of context that we have to establish in rt1 knowledge sources at trigger time. 
　　work on distributed gbb   corkill  1   is mainly at the blackboard level  not at the control architecture and has come out of work on distributed problem-solving  planning and real-time performance. 
1. future directions 
　　we believe that we have made significant progress toward understanding real-time issues and performance criteria. however  our work is only a step in this direction. several major issues still remain. some of these relate to the capability of the rt-1 architecture  while others are general real-time issues. the next set of research activity involving the architecture includes extension for graceful adaptation  more intelligent schedulers  control overhead issues  intemiptibility of knowledge sources  and global coherence in a distributed setting. general real-time issues include guaranteeing response  predicting response times and solution quality  incremental algorithms  and anticipatory processing. 
acknowledgments 
　　this work has benefited greatly from the advice and criticisms offered by perry thomdyke and barbara hayesroth. we also thank tom hester for his support  bill 
murray for helping out with the implementation  and charles key for reviewing earlier drafts of this paper. 
