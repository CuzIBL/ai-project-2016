 
i describe a real-time implementation of ullman's visual routine processor  vrp  theory of intermediate vision for visual search. the system performs serial self-terminating visual search and computes 1d spatial relations of objects from live color video using low cost hardware. i present a formal model of a vrp with unbounded resources and quantify the amount of external control structure required to solve horn clauses using the vrp. in discussing the effect of resource limitations i show that contemporary models of biological visual attention are unable to solve surprisingly simple queries. i also describe a novel logic programming system that finds satisfying variable assignments for horn clause queries using the vrp. the system contains no internal database: all logic variables are directly grounded in the world using vrp queries. finally  i briefly discuss experiments with natural language interpretation and motor control using the vrp. experiments on real data are given.1 
1 	introduction 
shimon ullman proposed the visual routines theory of intermediate vision as a way of explaining how the human visual system might solve certain visual tasks  such as computing spatial relations  that seem to require serial processing  ullman  1 . at a gross level  the theory proposes that the visual system contains a set of registers that can contain different types of visual data  a means of focusing visual attention on task-relevant portions of the image  and a set of primitive  instructions   such as coloring and line drawing  that can be combined like instructions in a computer program to compute useful 
support fot this research was provided in part by the 
university research initiative under office of naval research contract no1-k-o1  and in part by the advanced research projects agency under office of naval research contract n1-k-1  and in part by the national science foundation under grant number iri-1. joanna bryson kindly read drafts of this paper and provided useful comments. 
1 	action and perception 
properties of an image. these resources are collectively referred to as the visual routine processor or vrp. 
　the visual routines theory have received increasing attention from the ai community in recent years   agre and chapman  1   chapman  1  reece and shafer  1l  romanycia  1  whitehead and ballard  1  . much of this attention has come from the reactive reasoning and planning community  in part because agre and chapman's implementation of the visual routines model provides an alternative interface between reasoning and perception  which is both easier to implement and more biologically plausible than standard databaselike interfaces. 
　despite the level of interest  there has yet to be a vrp implementation that runs on real camera images. to date  vrp systems have run either off of hand-drawn bitmaps  romanycia  1  or have been directly interfaced to the world model of a world simulator  thus bypassing low-level vision entirely  agre and chapman  1  chapman  1  r eece and shafer  1 . 
　in this paper  i describe jeeves   a working visual routine processor that runs off of color video at approximately 1hz using only relatively simple hardware. this is work in progress. as of this writing  jeeves implements the visual search portion of the theory  the part which is presently best worked out. i will also present a formal analysis of the amount of control machinery required to solve arbitrary-length horn clauses  discuss the effect of resource limitations on visual search  and give an example of a simple horn clause for which most current biological theories of visual search cannot account. finally  i will describe bertrand  a novel logic programming system that answers horn clause queries about scenes without the use of an internal proposition database. 
1 overview of the v r p model 
1 	early vision and attention 
virtually all theories of vision presuppose a stage of early or low level processing that extracts local features from the image such as edges  color information  or depth. it is generally believed that early vision computes a set of low level maps each displaying the strength or value of a specific feature for all points in the image. these maps are believed to be computed bottom-up and in parallel. 
　in the last decade  covert visual attention  the problem of selecting image-plane regions for processing  has been widely studied in the psychophysical and neurophysiological communities. a wide range of neural models of covert attention have been proposed  see  tsotsos et a/.  1  for a detailed survey . these models assume 
image regions are selected based on their low level features  see above . most use a pyramid structure  and so are referred to as  attention-  or  addressing-pyramids . models differ on what the attention mechanism reports to the next level about the region. some models such as  koch and ullman  1  route aggregate feature values of the attended region to their outputs  while other models  such as  olshausen et a/.  1   route resampled images to their outputs. jeeves   is patterned after  koch and ullman  1j  although dynamic resampling would be easy to add. 
　for the purposes of this paper  the most important data on covert attention are the experiments of treisman et al.  treisman and gelade  1   which suggest the vision system can search all points in the image in parallel for many low level features  called  pop-up  properties  but must handle conjunctions of features by serially enumerating regions satisfying one of the conjuncts and then testing them for the other s . most neural models of attention have image-parallel hardware for matching pop-up properties to handle the simple cases  and provide some return-inhibition mechanism to support region enumeration for conjunctions. return-inhibition stores the locations of previously attended regions and prevents them from being selected in the future. all regions satisfying a given pop-up feature can then be enumerated by repeatedly selecting a region and inhibiting it. 
　it is outside the scope of this paper to debate the validity of treisman's experiments or the various neural models of covert attention. the interested reader is directed to  tsotsos et o/.  1 . 
1 	visual routines 
the visual routine model  ullman  1  claims that certain kinds of visual work are done by selecting relevant regions of the image and applying simple geometric operations to them such as drawing lines to connect them  searching along the lines for other regions  or checking whether a point lies within a closed curve using flood-fill operations. the essential claims are that  1  there exists a visual routine processor  vrp  that consists of a set of discrete functional units  each capable of performing a specific operation such as line drawing or flood filling and  1  these operations can be combined in taskspecific manners to do useful visual work in the same way subroutines are built up from primitive machine instructions  hence the name  vrp  . the model presupposes a number of basic architectural features of the visual system: 
  an early vision system to compute primitive fea-tures  
  an attention system to select task-relevant regions based on those features and route them to the vrp  
  a set of functional units for executing primitive in-structions  and 

  a set of specialized state elements for holding inter-mediate values  registers . 
the details of the registers and functional units are unknown. chapman's system  chapman  1  contained four types of state elements: markers  which held image locations; lines and rays; activation planes  which were general registers that could hold arbitrary binary images; and a return inhibition map. all state elements except the return inhibition map could be directly named and manipulated. the return inhibition map had its own specialized operations. in chapman's system  a blocksworld visual routine for finding the first block underneath some blue block would consist of the following operations: 
1. clear the return inhibition buffer 
1. select a blue block and inhibit it 
1. set marker 1 to the location of the selected region 
1. set ray 1 to project downward from marker 1 
1. set marker 1 to the first object along ray 1. if the previous operation failed  go to step 1. 
if this routine succeeds  then marker 1 will designate the blue block and marker 1 the block underneath it. 
1 	jeeves implementation 
jeeves is the first system to implement the vrp model on real camera data using a real low level vision system. it implements the necessary extensions to allow operation on scenes in which objects have non-trivial spatial extent and/or occlude one another. it implements marker and line operations  but presently does not implement activation plane operations  the current domain doesn't exercise them adequately . it implements queries on 1d spatial relations and simple feature values and has been tested on children's blocks  real ones  with differing shapes   books  and brightly colored kitchen utensils. the architecture of jeeves is shown in figure 1. i hope to apply it to other domains and to extend its repertoire of computations soon. 
　jeeves runs on 1 x 1 images at approximately 1hz. it is written in c and presently runs on color vision hardware designed at mit by chris barnhart. the hardware consists of roughly $1us worth of components  including a texas instruments c1 floating-point dsp and an ntsc color digitizer. it is controlled from a sparc-1 running scheme over a 1k-baud serial port. 
	horswill 	1 

　the process of building a low-level vision system and vrp that can run at 1hz required a great many compromises  most importantly  the use of low resolution images and the lack of a shape-matching system. in some cases  these compromises limited the tasks that could be solved by the system. i have tried to restrict my attention to claims and tasks that are unaffected by these limitations. 
1 	low-level maps 
after grabbing the image and averaging it down to low resolution  the system computes a number of low level retinotopic maps. as of this writing  it computes various color maps  r  g  b  r/i  g/i  b/i   intensity  temporal and spatial derivatives  including laplacian  v1g edges  and a grey-scale symmetry operator. an optic flow detector has also been implemented but is not presently used. 
1 	preattentive segmentation 
chapman's sivs system ignored the issue of dividing the image into regions corresponding to distinct objects  effectively assuming that objects were single points. chapman argued from psychophysical evidence that the vision system might perform a first-pass segmentation before the attention pyramid. the attention pyramid would then select among segments rather than points. other models assume that the attention pyramid can select among different scales  but does not use segmented input. as much for engineering reasons as for theoretical ones  i choose to use a preattentive color segmentation system as a preprocessing stage for the attention pyramid. the system finds color boundaries in the image and uses a connected-components algorithm to label regions of homogeneous color. the segmentation system also allows the higher level to specify minimum and maximum segment sizes. minimum sizes allow the suppression of  noise  segments and maximum sizes act as a crude form of figure/ground separation. 
　i do not propose the simple color segmentation system as any kind of theory of human preattentive segmentation. however  the use of segmentation is logically independent of other design decisions; one could change or remove the segmentation system and still have a usable vision system. 
1 	the saliency map and visual attention 
the vrp selects task-relevant image regions by computing a pixel-by-pixel weighted sum of the low level maps  clark and ferrier  1  ahmad and omohundro  1 . the weights are one of the input parameters of the system and can be changed continuously by the higher levels  see figure 1 . weighted sums may be more powerful than the human system. one can adjust the weights to select for conjunctions  for example. however  this would presuppose something like a perceptron learning algorithm running to learn the proper weights for the proper conjunctions. since this would require considerable training  the human system might use the weighted combinations and still be unable to do parallel search for conjunctions. in point of fact  more recent psychophysical results do indicate that at least some conjunctions 
1 	action and perception 

figure 1: structure of the attention system 
can be learned with sufficient training  see  weismeyer  1  and  tsotsos et a/.  1  for surveys of recent results . 
　the attention system computes the region with the maximum integral of salience. this differs from previous systems which have either found the image point with maximal salience or the image point with maximal smoothed salience  perhaps over several different scales. finally  the attention system computes the bounding box  area  centroid  and average low level map values for the winning segment. 
1 	visual markers 
the only directly-addressable memory in jeeves is a small collection  1  of registers called  markers   chapman  1  which can hold the centroid and bounding box of a segment. markers can be loaded with the specifications of the currently attended region  compared to one another  or used to focus attention  see below . 
1 	ret urn-inhibit ion and spatial constraint 
in many biological attention models and also in many computer implementations  return inhibition is implemented as a function internal to the attention pyramid itself. indeed  most biological models provide only very limited control over return inhibition  if any. chapman's model provides control lines to enable and disable the addition of the current point to the set of inhibited points and to clear the set of inhibited points. it does not provide the capability to suppress return-inhibition without permanently clearing the set of inhibited points. 
　jeeves implements return inhibition through a separate return-inhibition map  rim  that is summed into the saliency map  see figure 1 . jeeves provides separate control lines for adding the current region to the rim  clearing the rim  and including the rim in the the saliency measure. the latter is controlled through the same weighting mechanism used for other maps. 
　both chapman and ullman propose that the vrp can search for objects along specified rays. in chapman's system  this is implemented though a separate attention mechanism. as with return inhibition  spatial constraint 


	horswill 	1 

variables  
we create a shift register tape whose cells are oracle inputs that enumerate the respective literals of the con-
junction. thus cell i  is the tuple giving the signature of the ith literal  the registers for the literal's argument variables  and a context register to use. we will use context register ci for literal i. the restart flag must be generated at run time  so it will not be included in the cell. the shift register tape is then: 
  
and the tape for the clause in  1  would be  using x as variable 1 and y as variable 1 : 
  
the only non-trivial part of this compilation process is computing the signature. it is easily done by keeping track of which variables have appeared so far in a leftto-right reading of the clause. 
　given this tape  we can enumerate all satisfying variable assignments of the clause by adjoining a simple automaton to the oracle. the tape is augmented with leftand right- end-of-tape markers  and the shift register is started at the left end of tape. the automaton has a single flip-flop  called restart  which is initialized to 1. it follows the rules: 
  if restart  then shift to the next cell to the right  else to the left. 
  if not at end of tape  take current cell's tuple  ap-pend restart to it  and feed it to the oracle  storing the result in restart. 
  if at the right end of tape  signal success and clear restart. 
  if at the left end of tape and restart is clear  termi-
1 	resource constraints 
current biological theories of covert visual attention tacitly assume only a single  context register   the returninhibition state. the return-inhibition state can only track the enumeration of a single variable. thus  it would seem that the vrp can only handle clauses containing a single variable. in point of fact  this can be optimized somewhat. 
backtracking with markers 
the predicate on x  y  be solved in the vrp by projecting a short ray downward from a known x and placing y on the first object found along the ray  or by projecting upward from a known y . the same procedure also works for the immediately-above  iabove  relation1 if we use an infinitely long ray. a solution to iabove x y  is also a solution to above x y . to find any other solutions to above x  y   we can inhibit return to the previous solution and resolve. this requires an extra return-inhibition map  however. if we adopt the idealization that an object can only immediately above one other object  then we can solve above x y  without an extra return-inhibitionmap. the reasin is that aboveness is the transitive closure of immediately aboveness: 

which gives us the following procedure for enumerating values of y given x: to restart an enumeration  project a ray down from x and bind y to the first object found along the ray; to backtrack the enumeration  project a ray down from the current value of y and rebind y to the first object found along the ray. 
　in effect  this technique causes the object registers to do double-duty as context registers. the technique is applicable to any right-unique relation:1 

nate. 
these rules are easily implemented in a few gates. 
　in effect the tape acts as the backtracking stack  one cell per frame  and the context registers named on the tape hold the backtracking history of their respective frames. each time the automaton reaches the right eot and signals success  it has found a complete satisfying variable assignment for the clause. it can be shown that: 
claim 1 the automaton above signals success once for each satisfying variable assignment of the clause. 
sketch of proof: by induction  the number of rightward tape crossings out of the ith cell is equal to the number of satisfying variable assignments for the first i literals in the clause. rightward crossings out of the last cell enter the right eot and so signal success. 
　this allows us to quantify the amount of control state needed to satisfy arbitrary length horn clauses with an enumeration oracle. 
　we have assumed the enumeration oracle handles arbitrary signatures of arbitrary literals. we can weaken these assumptions somewhat through compiletime transformations by forcing variables to be enumerated one at a time using weaker predicates or by evaluating the literals in a different order. such transformations are outside the scope of this paper. 
1 	action and perception 


figure 1: an image  above left   its subsampled version  above right   and an example query and execution trace  below . semicolons mark annotations. note that the system assumes any uniformly colored region is a block. it does not recognize the other objects  although it can tolerate their presence. 
1 a database-free logic programming system 
　bertrand is logic programming system built to experiment with the search capabilities of the vrp. it is essentially a direct implementation of the horn-clause satisfier discussed above. it has a compilation phase that translates clauses into shift-register tapes and an execution phase in which vrp markers are set to a satisfying variable assignment for the clause using backtracking search. marker positions are overlaid as colored x's on the live video image. an example execution trace is shown in figure 1. 
　at present  bertrand runs with only one returninhibition map  although this could be easily changed. 
1 answering natural language queries 
the above results suggest a natural extention to the processing of simple natural language utterances: we add a simple parsing front end and a semantics system that defines the semantics of visual words in terms of vrp instructions that find their referrents. we can then answer the sort of natural language queries whose logical forms are simple horn clauses of the form that bertrand can solve: 
  is there a green block  
  is the green block on another block  
  show me the blue block on the red block  e is it on a red block  
  is there a green block on a blue block on a red block on an orange block under a green block  
　ludwig is a natural language system that can answer simple questions using the vrp. although quite limited  it is novel in that it uses not only no world-model  but no tree-structured representations whatsoever! ludwig is implemented entirely as a set of piplined parallel processes  each finite state  with fixed connections between them. connections are simple activation levels  binary values  or narrow busses.1 in this sense  it is compatible with connectionist ideas. to my knowledge  ludwig is the most sophisticated system to date based on the notion of using the world as its own best model. it is also the only such system that supports fully compositional representation and recursive structures. 
1 	motor control 
we have mounted the vision system on a mobile robot base and used it for simple visuo-motor experiments. although designed for visual search  the visual routine processor already contains much of the machinery necessary for the visual system of the polly robot  horswill  1 . for example  the polly system performs collision avoidance by steering to avoid texture in the image. since the floor of polly's environment has no surface markings  the presence of an edge necessarily indicates the presence of an obstacle and so an edge detector is sufficient to act as an obstacle detector. polly computes the depths of edges using image-plane height. in particular  polly steers by computing three distances  dj  dc  and dr   which are defined as the image plane heights of the lowest edge pixels in the left  center and right thirds of the image  respectively. polly then turns at a rate proportional to di - dr and advances at a rate proportional to dc. 
　such a control regime is easily added to the vrp. the output of the saliency map is fed to a motor control unit that computes di  dc  and dr  defined to be the image plane heights of the lowest salient pixels in their respective image areas. the motor control unit also computes zmin  the x coordinate of the lowest salient pixel in the whole image. a motor control instruction then consists of a vrp instruction to determine the settings of the salience parameters and a matrix a and a vector b used to compute the motor velocities as: 

　for example  using a vrp instruction to attend to spatial derivatives and specifying 

where dstop is the desired stopping distance for the robot  yeilds the standard polly collision avoidance algorithm  while the values 

where dw  is the desired distance reading for the left wall  yeilds polly's left-wall following algorithm. finally  

   1 in fact  ludwig is implemented directly in a registertransfer-level hardware language. 
	horswill 	1 

yields a primitive following algorithm that steers toward and approaches the nearest object. 
　the motor control unit is also able to make ballistic turns to face in the direction of a given marker. after a ballistic turn of the robot's body  marker positions are automatically updated to compensate for the motion. 
　finally  the motor control unit has been integrated into bertrand to allow motor control operations to be mixed with visual search operations. thus the program: 
red x   on x  y   blue y   face x   approach  . 
will cause the robot to find a red block on a blue block and drive up to it. 
1 	conclusions 
this paper provides the first vrp implementation that runs on real camera data and one of the few implementations of biological theories of covert visual attention that runs on real data. it also provides a formal study of the vrp's visual search capabilities and the effects of the resource limitations in biological attention theories  for a study of visual search independent of the vrp architecture  see  tsotsos  1  . 
　one of the outcomes of the formal analysis is that some surprisingly simple queries cannot be solved without assuming more machinery than current biological theories provide. this is not fatal to the theories  it simply means that must either  1  we revise the theory   1  assume that some other system is in charge of finding arches  or  1  assume the problematic queries aren't important in everyday life.  1  is simple: just assume there are multiple return-inhibition maps and that their effects on the attention pyramid can be gated by higher level processes. this may not be true  but it suggests a whole range of interesting psychophysical experiments.  1  is more tricky. many computer models of recognition tacitly assume the ability to perform complicated backtracking searches. explaining one system's inability to backtrack by assuming another's ability to backtrack simply begs the question. if psychophysical experiments should show that the human visual system really is limited in its ability to backtrack in visual search  this would lend support to view-based models of recognition. 
　bertrand and ludwig are interesting because they have no internal world model: database operations on the model are translated directly into image-plane operations  yielding a high performance interface that is plug-compatible with a database. an existing problem solver could be modified to do the same. the result would be a system that seamlessly alternated between image operations and world-model operations  depending on the type of query. 
