
we introduce a new np-complete problem asking if a  query  hypercube is  not  covered by a set of other  evidence  hypercubes. this comes down to a form of constraint reasoning asking for the satisfiability of a cnf formula where the logical atoms are inequalities over single variables  with possibly infinite variable domains. we empirically investigate the location of the phase transition regions in two random distributions of problem instances. we introducea solution methodthat iterativelyconstructs a representation of the non-covered part of the query cube. in particular  the method is not based on backtracking. our experiments show that the method is  in a significant range of instances  superior to the backtracking method that results from translation to sat  and application of a stateof-the-art dp-based sat solver.
this paper is an extendedabstract. more details can be foundin the long versionof the paper  hoffmann and kupferschmid  1 .
모we introduce a new np-complete problem asking if there is a point in a given n-dimensional  query  hypercube that is not covered by - contained in the union of - a set of other ndimensional  evidence  hypercubes. an n-dimensional hypercube is a cross product of n intervals. intervals in our context are defined as statements of the form l    뫞  x    뫞  u where  x  is a variable   l  and  u  are members of x's domain  and     is a total order defined over this domain.1definition 1 let qcover denote the following problem: given an n-dimensional hypercube q  and a set e of ndimensional hypercubes  is there a point in q that is not contained in se뫍e e 
모covering problems of this kind arise  e.g.  in the context of regression planning with numeric state variables  koehler  1 . more generally  qcover is a form of constraint reasoning asking for the satisfiability of a cnf formula where the logical atoms are inequalities over single variables  with possibly infinite variable domains. the correspondence is the following. a qcover instance is a constraint problem with n variables xd. the query hypercube specifies a region inside which the solution must lie  the evidence cubes specify regions inside which the solution must not lie. a hypercube corresponds to a conjunction of inequalities of the form c    뫞   뫟  xd. so the complement of a hypercube  of an evidence hypercube  corresponds to a disjunction of such inequalities  and the overall problem is a conjunction of disjunctive constraints. vice versa  any conjunction of such disjunctive constraints can be expressed as hypercubes  if a disjunctive constraint does not mention a variable xd  then the interval in dimension d is the whole variable domain .
proposition 1 qcover is np-complete.
모we empirically explore two random distributions of qcover instances. the first one  which we call random qcover  chooses the end points for all intervals uniformly from a set of m possible values. the second one  which we call random 1-qcover  is similar to the fixed clause-length model for generating random 1sat instances  mitchell et al.  1 . it always selects the querycubeto be the cross-product of the  whole  variable domains  and  in the evidence cubes  assigns the whole variable domains to all but 1 randomlychosen dimensions. for both distributions  we investigate the location of the phase transition regions. as it turns out  random 1-qcover shows a typical phase transition behaviour while random qcover shows no such behaviour  see figure 1.

figure 1: typical plot of the proportion of unsatisfiable instances against k for  a  random qcover and  b  random 1-qcover.
모by 1% point  we denote the number k of evidence cubes at which our random instances have  empirically  equal probability of being satisfiable or unsatisfiable. the 1% point depends on n and m. we use instances from the 1% points to evaluate different solution methods.
모today  in most cases the empirically most efficient solution methods for satisfiability problems are backtracking methods. such methods are depth-first searches that split  in each search node  the search space along the possible values of a variable. a polynomial propagation of constraints is used to determine conflicts early on in the search tree  and analysis of conflicts is used to prune unnecessary branches. methods of this kind have proved successful for solving constraint satisfaction problems. in particular  the modern descendants of the davis putnam procedure still constitute the state-ofthe-art in determining the solvability of propositional cnf formulas. in our work  we have implemented a backtracking method for qcover by plugging a straightforward translation to sat into chaff  moskewicz et al.  1 .1 to contrast this method  we have also developed an algorithm  named cube elimination  that  instead of backtracking over possible variable values  iteratively constructs a representation of the non-covered part of the query cube. see figure 1.
procedure cube elimination q  e 
q := {q} for all e뫍e do q1 :=   for all q1 뫍q do q1 := q1 뫋 minimal cover q1  e  endfor
q := q1
if q=  then answer  unsatisfiable   return   endif
endfor answer  satisfiable   return q
figure 1: cube elimination.
모the algorithm maintains a set q of hypercubes that initially contains only the query cube itself. then iteratively all evidence cubes e are  eliminated  by subtracting them from all cubes q in q. the result q   e of such a subtraction is not necessarily a hypercube; we represent it as a set of hypercubes  computed by the minimal cover procedure. the latter is a simple for-loop over all dimensions  returning a set of hypercubes that covers exactly q   e  and that is minimal in the sense that there is no smaller set of hypercubes covering exactly q   e  the worst-case size of the set is 1n .
모in sat  where all variables are boolean and have only two possible values  cube elimination comes down to transforming the cnf into a dnf. this seems a hopeless approach  but  for our random qcover distribution  our experiments show that cube elimination is often superior to the backtracking method implemented by chaff. figure 1 shows our results for the random qcover distribution  in terms of  nr. of search decisions made by chaff  divided by  total nr. of cubes generated by cube elimination . clearly  cube elimination becomes superior as the value of m increases. this is particularly true in the unsatisfiable instances where the cube elimination search space is  in the largest instances  around
1 orders of magnitude smaller than that of backtracking. it should be noted that cube elimination produces a representation of all satisfying assignments in the satisfiable cases.

	 1	 b 
figure 1: search space size quotient chaff vs. cube elimination in random qcover  averaged over  a  all instances   b  only unsatisfiable instances. the z-axis is log-scaled  the plain z = 1 is included for orientation.
모in the random 1-qcover distribution  we found backtracking to be generally superior to cube elimination. for lack of space  we ommit the details. in spirit  cube elimination is somewhat similar to the  bucket elimination  framework defined by rina dechter . the cube elimination algorithm is easiest to understand  and was originally motivated by  viewing the satisfiability problem we consider as a geometrical problem. this opens up the question if geometrical interpretations of other satisfiability problems can lead to interesting new methods for these problems.
