 
the video demonstrates research accomplishments in interactive design and assembly with 1d computer graphics environments. agent techniques and dynamic knowledge representation techniques are used to process qualitative verbal instructions to quantitative scene changes. a key idea is to exploit situated 'perceptive' information by inspecting the computer graphics scene models. 
   computer-based presentations of synthetic geometry data  transformed to visual surface structures by way of rendering techniques  are of growing importance in the design and construction areas. to make better profit of this new technology  new ways of human-computer interaction are called for. previous work has concentrated on gesturing and pointing  for instance  by using the data glove. an alternative way we explore at the ai & computer graphics lab is to use verbal interaction to communicate alterations. these are put in effect by a mediating system which changes the arrangement or assemblage of scene objects. our general goal is to use ai to establish a communication link between humans and multimedia. this is  however  possible only when the image of a design or an assembly is not a meaningless visual presentation  but is coupled to an internal semantic representation of the presented images. 
   as the user gets immersed in the visual scene  verbal statements likely make reference to what can be seen in the current situation. thus the semantic processing of verbal instructions needs to draw on what is true in a situation. we do not try to give a full propositional account of the scene  which might also be affected by direct mouse or glove manipulation  because of the known problems of  keeping track   the frame problem . rather  we exploit the current situation by inspecting the internal scene description  geometry models  materials  etc. . since the user perceives the scene by eye inspection  system and user can communicate about scene details from the same  point of view.  we call this situated verbal interaction. 
¡¡the video illustrates our approach in two examples  one in virtual design and one in virtual assembly. it is our aim that user and system can communicate about a dynamic scene. to this end  we have developed dynamic knowledge representations to account for changing conceptualizations of objects and scene  and we use software interface agents which inspect graphic scene descriptions and keep track of varying situation parameters. discourse in simple written natural language is used for communication  in the future we want to use voice input . qualitative communications of the user are evaluated so as to produce appropriate quantitative changes in the scene description which is then visualized for the user. 

v i r t u a l design environment in the viena project   virtual environments & agents    we have chosen interior design as an example domain  and we build on the softimage modeling and rendering software installed on a silicon graphics indigo. instead of using the complex mouse-and-menu commands to manipulate objects we communicate with the system by way of natural language. our aim is to keep the user  designer  free from technical detail such as geometry planning. we have developed a set of software interface agents  see figure above   realized as autonomous unix processes  which altogether form an intelligent mediator. taking special responsibilities in processing verbal instructions  
	cao  jung  and wachsmuth 	1 

the viena agents cooperate with each other and with the user to offer a goal scene meeting the user's wants. for instance  a space agent translates qualitative relations such as to appropriate scene coordinates. 
the offer can be changed in further interaction  that is  semantics construction is coupled into the visible scene and can be negotiated in discourse. 
   the agent framework developed in viena combines different cooperation models such as contract-net  master-slave  and blackboard. each agent is equipped with a bidder-specific frame which triggers the activation of the agent's local functionality. out of this  contractorspecific primitives are inserted depending on the situation and the task. 
¡¡the viena system is tested in a prototype scenario with various items of furniture as well as color and light impressions of a virtual office room which can be changed interactively. sample interactions are shown in the video. 
v i r t u a l assembly w o r k b e n c h in the cody project   concept dynamics    we develop a knowledge representation scheme for dynamic object conceptualization in assemblage. in our testbed scenario  we assemble a toy airplane and similar constructs from building blocks on a virtual assembly bench. as shown in the video  the user can inspect the graphics scene from different perspectives and change the building blocks1 configuration by way of natural verbal communication. instructions can refer to visual object properties  such as their location and color  but also to conceptual structures that are superimposed dynamically on the geometry models. 
   conceptual knowledge is defined in two knowledge bases  one describing the building blocks and their connection ports  the other one containing specific knowledge about the target aggregate's structured assembly groups. this background knowledge enables the user to assemble any complex aggregate from the building blocks with special support for predefined constructs. concepts for assembly groups are defined by their parts and the relations between them  which are expressed through logical and geometric constraints. when instances of assembly groups are to be recognized  logical constraints require logical relations  e.g.   to be asserted between part representations  whereas geometric constraints  e.g.   trigger tests in the geometry models on an if-needed basis. 
¡¡every time objects are composed on the virtual assembly bench  logical relations such as are inferred from the geometric scene description. in an internal loop  these relations are propagated along the structure in the logical data base. unstructured 
aggregate representations are created dynamically and matched against the model knowledge base. the logical description is restructured when instances of assembly groups are recognized. furthermore  functional names and properties are ascribed to object representations de-
1 	videos 

pending on their aggregate context. for example  a bolt functions as an axle when it is part of a half-axle-system  see figure above . assembly operations  typically  are subject to side effects  i.e.  they may affect objects not mentioned in instructions. the system detects these side effects and updates object representations accordingly. 
conclusion natural communication with responsive virtual environments is a decisive factor in making this cutting-edge technology widely applicable. complementing direct manipulation  situated verbal interaction seems a promising way to make better profit of the ways humans communicate. our research achievements depend on the integration of various ai techniques  and they lead into various application areas beyond our testbed scenarios  for example  in virtual prototyping and in car assembly planning. at the same time  we found that our scenarios provide a springboard for goal-oriented research on dynamic knowledge representations and on software interface agents. acknowledgment credit to further project personnel is given in the video. research in the viena project is partly supported by the ministry of science and research of the federal state north-rhine-westphalia. 
cody is a project in the collaborative research center 
 situated artificial communicators  at the university of bielefeld and is in part supported by the german national science foundation  dfg . 
