 
progressive processing is a resource-bounded reasoning technique that allows a system to incrementally construct a solution to a problem using a hierarchy of processing levels. this paper focuses on the problem of meta-level control of progressive processing in domains characterized by rapid change and high level of duration uncertainty. we show that progressive processing facilitates efficient run-time monitoring and meta-level control. our solution is based on an incremental scheduler that can handle duration uncertainty by dynamically revising the schedule during execution time based on run-time information. we also show that a probabilistic representation of duration uncertainty reduces the frequency of schedule revisions and thus improves the performance of the system. finally  an experimental evaluation shows the contributions of this approach and its suitability for a data transmission application. 
1 	introduction 
progressive processing  mouaddib  1  is a problemsolving technique that allows a system to trade-off solution quality against computational resources. this technique is suitable in situations where it is not feasible  computationally  or desirable  economically  to compute the best result. progressive processing shares the motivation of such resource-bounded reasoning techniques as flexible computation  horvitz  1   anytime algorithms  boddy and dean  1; zilberstein  1; 1   and design-to-time  garvey and lesser  1 . the distinctive characteristic of progressive processing is the use of a multi-level deliberation hierarchy in order to gradually transform an approximate solution into a 
   * support for this author is provided in part by the ganymede ii project of the contract plan etat/nord-pasde-calais and by menesr. 
   + support for this author is provided by the national science foundation under grants iri-1  iri-1  int-1  and by the u.s. air force under grant f1-1. 
shlomo zilberstein+ computer science department university of massachusetts amherst  ma 1 	u.s.a. shlomo cs.umass.edu 
precise one. the mapping from the set of inputs  problem instances  to the set of outputs  solutions  is based on progressive utilization of data and knowledge. this incremental process is facilitated by using a hierarchical structure of input elements defined by the system's designer  mouaddib and zilberstein  1 . this mapping is especially suitable for domains where the reasoner uses abstraction to structure the search space  as in hierarchical planning   and for problems that require the result to be expressed at varying levels of detail  as in modelbased diagnosis . 
　in systems based on this technique  each timeconstrained component is designed in such a way that it  can produce a usable approximate solution within the available run-time. however the use of progressive processing as a component of a real-time system introduces a problem of execution monitoring: determining how long to run. this kind of scheduling problems are common in real-time al applications  such as medical monitoring 
 hayes-roth  1   real-time data transmission  millanlopez et al  1   speech processing  feng and liu  
1   mobile robot navigation  zilberstein  1  and flexible manufacturing. the real-time data transmission application that we address in this paper is another example. these application require a meta-level control mechanism that can deal with  1  dynamic environment   1  limited amount of time to produce a response  and  1  uncertainty regarding the duration of problem-solving. 
　the focus of this work is handling duration uncertainty. most of the existing approaches to the problem do not deal with duration uncertainty and their schedulers work in isolation; the schedule runs for the predetermined length of time regardless of the situation  boddy and dean  1; liu et al.  1; millan-lopez et al.  1 . hansen and zilberstein  hansen and zilberstein  1  show that monitoring the progress of problem solving allows a system to take advantage of the information gathered during execution time and to improve the overall performance. garvey and lesser  garvey and lesser  1  introduce a design-to-time technique that represents duration uncertainty and revises the schedule during execution. we address two limitations of that approach:  1  its time interval repre-
	mouaddib & zilberstein 	1 
sentation of duration uncertainty is not sufficiently informative when the duration variation is large; and  1  its scheduler is assumed to always complete its processing. this design-to-time approach is suitable in domains characterized by low level of uncertainty so that the scheduler is significantly faster than the evolution of the controlled process. we suggest that it is beneficial to design the scheduler itself as an incremental process so that it can handle rapid change in the environment and unexpected interruption before completing its execution. 
　this paper focuses on the problem of meta-level control of computational resources in domains characterized by rapid change and duration uncertainty. we show that the task structure of progressive processing facilitates efficient run-time monitoring and meta-level control. the approach we present is based on an interruptible algorithm which incrementally builds a schedule and returns an approximate complete schedule when it is interrupted unexpectedly. this approach can handle rapid change and a large deviation from the predicted schedule. the incremental scheduler that we present allows:  1  to initially construct schedule that contains the first reasoning level for each task and to then refine it progressively by introducing additional reasoning levels for each task   1  to revise the schedule when a significant deviation is detected at run-time  and  1  to reduce the frequency of revision using information on duration uncertainty. 
　section 1 presents a data transmission application for which our approach was implemented. section 1 presents a formal definition of the problem and the initial task structure. a description of our approach based on an incremental scheduling and a revision technique is given in section 1. section 1 presents an empirical comparison of our approach with an adaptation of the design-to-time approach to handle progressive processing. we conclude with a summary of the contributions and future work. 
1 	real-time data transmission application 
we examine a data transmission application that provides real-time communication services. these services include time constraints on the duration of transmission and a deadline for data delivery. the duration of transmission is the time interval between the point at which the data is generated and the point at which it is delivered. this duration is uncertain because of the variation on the behavior of the communication network. data misses its deadline whenever the duration of transmission exceeds the maximum permitted time. 
　our approach is designed to manage real-time worldwide web  www  services providing information on staff members of our laboratory. this information may include textual data  video frames and voice. the system must satisfy asynchronous requests of information by taking their deadlines into account. the implementation consists of eleven  1.  w w w pages  each of which 
1 	planning and scheduling 
contains information on one member of the laboratory. each page consists of textual data  video frames and voice. different requests for information may refer to the same page. the information system must handle  1  asynchronous requests  dynamic and rapid change aspect of the application ; and  1  uncertainty regarding the behavior of the network  uncertainty on execution time . to apply the progressive processing technique  we assume that each w w w page could be transmitted as three separate packages of information  text  video frames and voice . the incremental process of satisfying a request is based on dividing it into a sequence of information packages. consequently  the requests could be satisfied at varying levels of detail. our experimental evaluation is based on a simulation of arrival of information requests and transmission of information packages. 
1 	formal framework 
1 	description of the problem 
our framework relaxes two assumptions that are common in classical scheduling systems. first  they optimize performance by satisfying the most important requests and if time permits they satisfy additional requests. these approaches neglect the fact that each request could be satisfied at varying levels of detail. it has been demonstrated that requests can be logically decomposed into two parts: a mandatory part and an optional part  liu et a/.  1 . this structure facilitates the development of more flexible systems that allow to satisfy the mandatory parts of all the requests and then improving performance by satisfying some of the optional parts. this approach is applies to problems that could be solved at varying levels of detail  such as hierarchical planning  knoblock  1  and incremental diagnosis  hayes-roth  1 . second  classical scheduling systems ignore the deviation of execution time from the predetermined expected length. in fact  data transmission applications are characterized by a high level of uncertainty regarding transmission time that cannot be ignored. 
　more precisely  the problem we solve consists of a set p = {p 1  ...  pn  of individual problems such that: 
  p is constructed dynamically; a new problem is added to the set when a new request arrives    each problem pi has a deadline di to respect    each problem pi could be solved at varying levels of detail using a hierarchy of processing levels  and   each processing level has probabilistic information characterizing its duration and duration uncertainty. 



	mouaddib & zilberstein 	1 


1 	planning and scheduling 

1 	properties 
to summarize  here are the main properties of our approach: 
  its scheduler could be interrupted at any time and it re-turns an approximate global schedule  global means that all the prus are included . as a result  this approach can deal with applications characterized by rapid change and a high level of uncertainty. 
  the probabilistic representation of duration uncer-tainty reduces the deviation from the predetermined schedule during execution. it also helps reducing the frequency of revising the schedule and thus limits the effect of revision time on the performance of the system. 
1 	experimental evaluation 
to evaluate our scheduling and monitoring technique  we compare its performance to the design-to-time technique. the comparison examines two fundamental questions:  1  the ability of each approach to handle duration uncertainty that is typical in such applications as realtime data transmission; and  1  the advantage of using a resource-bounded scheduler in domains characterized by rapid change and high level of uncertainty. before assessing both approaches  let us give a brief overview of design-to-time. this approach assumes the existence of multiple methods for each subtask with each method having different duration and quality. the problem is to design a solution to a problem that uses all the available time to maximize solution quality  design-to-time tolerates uncertainty in its prediction if monitoring can be performed quickly and each method performs as expected or within a small variation. the experimental results confirm these characteristics. 
1 	e x p e r i m e n t design 
we describe first how we have transformed the pru structure to multiple methods used by design-to-time. the linear precedence-constraint graph of each pru is mapped to a set of methods designed as follows: the first method m1 consists of the first level  the first node in lg  while the  method mi consists of the subgraph of the lg containing the first levels  mouaddib  1 . with this adaptation  we can evaluate both approaches for different problem instances generated based on a given set of size and time parameters. 
　since the w w w data transmission application is under development right now  we tested the scheduler with synthetic data simulating this application. the initial problem is specified in a pru'-language allowing us to create prus for the specific application. we have collected data on the scheduling and the execution phase for both the incremental scheduler and the design-to-time technique. the data for each problem instance includes intrinsic-utility  total cpu consumed and the frequency of revision. finally  we compare the results based on the notion of global utility  gu  and the notion of revision frequency  freq. the global-utility is computed as follows: 
 1  
is the intrinsic utility of an executed process-
ing level. we compare freq and gu for different problem sizes and time. 
handling duration uncertainty 
the frequency of revision reflects the degree to which an approach is suitable for handling duration uncertainty. we measured the frequency and global utility as a function of the size of the application. problem instances were generated with execution time variation of 1%  this figure is quite conservative for data transmission applications . the table  figure 1  summarizes the frequency of revision of our approach  is  and design-totime  dtt : figure 1 shows the evolution of the global 

figure 1: revision frequency according to size 
utility over size in both approaches. 

figure 1: global utility according to size 
resource-bounded scheduling 
this experiment measures the performance of both approaches when the scheduling algorithm operates under time constraints  figure 1 . the experiment tests the degree to which an approach is suitable for dynamic environments in which the scheduler may not have enough time to complete its processing. for this experiment  we use a size of 1 and a variable allocation of time to the scheduler of both approaches. we measured the intrinsic utility that allows to compute qu. design-to-time requires to finish its processing before delivering a complete schedule for all tasks. in this experiment  we measure the intrinsic utility of the current available schedule that is not complete for all tasks but only for the earlier ones. 
	mouaddib & zilberste1n 	1 

figure 1: global utility according to time 
1 	summary of results 
  handling duration uncertainty: our approach is more efficient than design-to-time in handling duration uncertainty. the main reason is the time interval representation of duration uncertainty used by design-to-time which is not sufficiently informative and leads to more schedule revisions. the higher frequency of revision has a negative effect on the overall performance of the approach as shown in the figure 1. 
  resource-bounded scheduling: design-to-time schedules tasks one by one by selecting for each task the appropriate method to optimally trade solution quality against computational resources. if the scheduling is interrupted before completing its processing  the latest tasks are not scheduled. this situation arises in applications that must respond to frequent and rapid state change. in contrast  our incremental scheduler  with its incremental processing  is able to be interrupted at any time and to return a solution. we show in figure 1 that our approach is more suitable to these applications than design-to-time. 
1 	conclusion and future work 
we describe in this paper an approach to scheduling progressive processing units in domains characterized by rapid change and duration uncertainty such as in data transmission applications. our approach is based on a utility-directed greedy scheduling algorithm that produces a minimal schedule of all the tasks and refines it when time permits. this is a local optimization approach to a scheduling problem that is hard to optimize globally. the incremental structure of the scheduler  its interruptibility  and its ability to dynamically revise the schedule during execution time make it an attractive resource-bounded scheduling technique. experimental evaluation shows that for the type of progressive processing tasks that we are interested in  the incremental scheduler has advantages over the design-to-time technique. future work is concerned with alternative representations and propagation of duration uncertainty by mapping the graph g to a bayesian network  mouaddib  1 . another future direction is concerned with 
1 	planning and scheduling 
applying this model to non-linear structure of prus. 
