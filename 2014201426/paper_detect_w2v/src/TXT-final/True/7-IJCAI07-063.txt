
cognitive psychologists have long recognized that the acquisition of a motor skill involves a transition from attention-demanding controlled processing to more fluent automatic processing. neuroscientific studies suggest that controlledand automatic processing rely on two largely distinct neural pathways. the controlled pathway  which includes the prefrontal cortex  is seen as acquiring declarative representations of skills. in comparison  the automatic pathway is thought to develop procedural representations. automaticity in motor skill learning involves a reduction in dependence on frontal systems and an increased reliance on the automatic pathway. in this paper  we propose a biologically plausible computational model of motor skill automaticity. this model offers a dual-pathway neurocomputational account of the translation of declarative knowledge into procedural knowledge during motor learning. in support of the model  we review some previously reported human experimental results involving the learning of a sequential key pressing task  and we demonstrate  through simulation  how the model providesa parsimoniousexplanation for these results.
1 introduction
learned motor skills are central to most human activities. learning plays a critical role in our abilities to walk  talk  cook  type  and play games like ping-pong  for example. the importance of learning in human motor performance has led many robotics researchers to examine machine learning approaches to motor control. we currently lack a clear and complete computational account of how humans acquire motor skills  however. in hopes of addressing this deficit  this paper offers some insights into the neurocomputational structure of motor skill learning.
　one of the central findings of cognitive research into skill learning involves the process of automaticity  through which fluency at a skill is improved by gradually shifting from a declarative representation of the task to a more procedural representation  anderson  1 . a growing body of neuroscientific evidence suggests that declarative and procedural processes are implemented by two largely separateneural networks in the brain  bapi et al.  1; hikosaka et al.  1; wolpert et al.  1 . both networks have the capability to individually acquire motor skills  but they typically coordinate with each other during learning. the controlled pathway includes dorsolateralprefrontal cortex  dlpfc   anterior cingulate cortex  acc   anterior parts of the cerebellum  anterior parts of the basal ganglia  and the pre-supplementary motor area  presma . this pathway is seen as acquiring representations of motor skills that are primarily declarative. declarative representations are formed very quickly  and they guide skill execution during the early stages of learning. the second network  which we call the automatic pathway  includes areas like the supplementary motor area  sma   primary motor cortex  lateral parts of the cerebellum  and lateral parts of the basal ganglia. as a skill becomes well practiced  this network slowly encodes a procedural representation of the skill. with practice  the involvement of the frontal controlled pathway decreases  and the skill comes to be primarily executed by the automatic pathway. the modulation of frontal involvement is thought to be governed by a separate coordination mechanism  perhaps embodied in the presma and the acc  hikosaka et al.  1 .
　this paper addresses a key question concerning this process - are the information processing properties of these brain regions  as they are currently understood sufficient to account for the behavioral shift in skill learning  to address this question  we have explored a neurocomputational model of motor skill learning that is based on the dual-pathway hypothesis. we report the results of simulation experiments involving a sequential key pressing task. in these simulations  keys are pressed using a two joint planar arm. the arm learns to trace out a sequence of trajectories such that the end effector successively moves from one key to the next in a trained sequential order.
　in our model  the controlled pathway learns a declarative representation of the task: the key sequence. when executing the task  the prefrontal cortex  pfc  in the controlled pathway actively maintains an abstract representation of the next key to be pressed. this representation of the desired key  along with the current state of the arm  is then transformed by the network into an appropriate reaching trajectory toward that key. once the current target key has been pressed  the pfc rapidly updates to encode the next key in the sequence  and the next reach is produced. thus  the controlled pathway needs only to learn the sequence of keys during task learning  depending on a pre-trained motor area to translate the pfc representation of each target key into an appropriate reaching motion.
　in contrast  the automatic pathway of our model learns the entire motor skill from scratch. it acquires a proceduralrepresentation of the skill by learning the entire motion trajectory needed for the complete sequence of key presses. this pathway learns more slowly than the controlled pathway  because much more detailed knowledge must be learned.
　as the automatic pathway becomes proficient in executing the sequence  the involvement of the controlled pathway is withdrawn. in our model  this shift is driven by a cognitive control mechanism. this mechanism monitors performance error and modulates the weight given to the controlled pathway appropriately. when error is high  the contribution of the fast-learning controlled pathway is strengthened. as error falls  the contribution of the automatic pathway is allowed to dominate.
1 background
1 leabra
our model uses the leabra modelingframework oreilly and munakata  1 . leabra offers a collection of integrated cognitive modeling formalisms that are grounded in known properties of cortical circuits but are sufficiently abstract to support the simulation of behaviors arising from large neural systems. it includes dendritic integration using a point neuron approximation  a firing rate model of neural coding  bidirectional excitation between cortical regions  fast feedforward and feedback inhibition  and a mechanism for synaptic plasticity. of particular relevance to the current model are leabra's synaptic learning rules and its lateral inhibition mechanism.
　leabra modifies the strength of synaptic connections in two ways. an error correction learning algorithm changes synaptic weights so as to improve network task performance. unlike the backpropagation of error algorithm  however  leabra's error correction scheme does not require the biologically implausible communication of error information backward across synapses. in addition to this error-correction mechanism  leabra also incorporates a hebbian correlational learning rule. this means that synaptic weights will continue to change even when task performance is essentially perfect.
　the effects of inhibitory interneurons tend to be strong and fast in cortex. this allows inhibition to act in a regulatory role  mediating the positive feedback of bidirectional excitatory connections between brain regions. simulation studies have shown that a combination of fast feedforward and feedback inhibition can produce a kind of  set-point dynamics   where the mean firing rate of cells in a given region remains relatively constant in the face of moderate changes to the mean strength of inputs. leabra implements this dynamic using a k-winners-take-all  kwta  inhibition function that quickly modulates the amount of pooled inhibition presented to a layer of simulated cortical neural units based on the layer's level of input activity. this results in a roughly constant number of units surpassing their firing threshold. in our model  this mechanism both encourages learning through the development of sparse neural representations and it helps to make neural network outputs interpretable.
1 cognitive control
cognitive control involves the ability to behave according to rules or goals instead of responding in a reflexive manner. prefrontal cortex  pfc  is critical for robust cognitive control  oreilly and munakata  1 . dense recurrent connectivity in pfc allows it to actively maintain information in firing rate patterns  and it is thought that this active maintenance of task relevant information is central to task directed behavior. also  interactions with the midbrain allow the pfc to rapidly update its state  based on task requirements  rougier et al.  1 . we have incorporated both active maintenance and rapid updating in the pfc component of our model.
　the strength of cognitive control can be modulated based on the task requirements. botvinick et al.  proposed that the anterior cingulate cortex  acc  monitors the amount of conflict between parallel neural pathways and strengthens cognitive control when conflict is high. in our model  performance error is seen as a sign of conflict. thus  we modulate the strength of cognitive control between trials  in proportion to the amount of error experienced on previous trials.
1 motor skill learning
a wide variety of sequential key pressing tasks have been used to investigate human motor skill learning  bapi et al.  1; hikosaka et al.  1; rand et al.  1   and a number of interesting findings have resulted. there is a period of rapid improvement in performance during the early stages of training. during this stage  learning is effector independent  e.g.  switching hands does not substantially degrade performance . further  interfering with the frontal systems involved in the controlled pathway during this period seriously disrupts performance. interfering with the automatic pathway  however  does not affect performance during this early period.
　after extensive training  the execution of the skill becomes more automatized. the skill becomes relatively effector dependent. also  performance remains robust if the controlled pathway is disrupted.
　additionally  studies of choking under pressure have suggested that errors in performance in the face of stress may have different causes early and late in learning  beilock et al.  1 . early in learning  when the controlled pathway dominates  errors may arise due to a failure to engage cognitive control systems. with a well practiced skill  however  degraded performance may be due to the excessive exertion of unnecessary cognitive control. these results are also reflected in our model.
1 previous computational models
ours is certainly not the first computational model of motor skill learning. for example  wolpert et al  1; 1  proposed mosaic  a model for sensorimotor control. mosaic consists of multiple modules  where each module consists of a pair of forward and inverse models. while mosaic has many strengths  it does not address the issue of representational change in skill learning. there is no mechanism for early declarative representations  making mosaic somewhat analogous to our automatic pathway.
　the automatic pathway in our model is largely based on the previous leabra networks of gupta and noelle  1b; 1a . these networks were used to explore the neurocomputational principles underlying skill savings and the transfer of knowledge from one skill to another.
　nakahara et al.  proposed a skill learning model that is very similar in general architecture to our own. there are a number of important differences between our models  however. first  their model does not focus on the question of differences in declarative and procedural represntations of the skill. instead  the early dominance of the controlled pathway is driven by differential learning rates  with the controlled pathway made to learn faster. in contrast  our model is novel in showing that declarative and procedural representations can naturally emerge from neural encodings  and this difference in encoding easily explains the difference in the speeds of learning. also  unlike our model  the nakahara model does not include a mechanism for dynamically adjusting cognitive control - the relative contribution of the controlled pathway. while the previous model does include a  coordinator  the function of this mechanism is not the same. hence  in their model  once a skill has been automatized  its controlled execution based on task demands is not possible. this is inconsistent with the behavioral observations. lastly  our model critically depends on the active maintenance of target key representations in the pfc and the rapid updating of these representations as keys are pressed  while the nakahara model incorporates no such mechanism.
　the biggest point of difference between our model and the previous models of skill learning is that our model grounds the previous more-abstract theories in well established neurocomputational mechanisms. in other words  our model demonstrates that the declarative/procedural translation theory fits naturally with leabra neurocomputational primitives  and our instantiation takes a step toward the generation of quantitative predictions for the model.
1 tasks
we have used our model to simulate the learning of key pressing motor sequences. our model controls a simulated 1-joint planar arm which moves over a 1-key keyboard  as show in in figure 1. the state of the arm at any point in time is represented by the vector  q1  q1   where q1 and q1 are the two joint angles. the joint angles range between 1  and 1 . movements are to be generated in such a way that the end effector follows a straight line trajectory from the position of the previous key to the position of the next key in the sequence. the arm starts over of the bottom-left key. the motion trajectory is discretized at equidistant time intervals  and hence  any trajectory is represented as a sequence of arm states over the successive time steps. during training  the arm is essentially guided along the desired trajectory  with differences between the motor output of the arm controller and the configuration of the arm  as specified by the guide  acting as a measure of error to drive synaptic weight change.

figure 1: a two joint planar arm and a keyboard. the state of the arm at any point in time is given by the vector of joint angles  q1  q1 . the arm produces motion trajectories such that its end effector moves from one key to the next  in sequence.
1 the network
figure 1 shows the leabra network used for our simulations. the sensory input layer provides the current state of the arm as input to the network and the motor output layer is to produce the desired arm state for the next time step. each joint angle is encoded over a pool of 1 neural units. each of the 1 units has a preferred angle  ranging from  1  to 1   in 1  increments. to encode a given joint angle  the closest unit with regard to preference  as well as its two neighbors  are set to their maximal firing rates. similarly  patterns of activity over each row of 1 units in the motor output are decoded by identifying the preferred angle of the unit in the middle of the three adjacent units that are all active. other patterns of activity in the motor output layer are considered to be ill-formed. with each joint angle encoded over 1 units in this way  the complete arm configuration is encoded over 1 units.
　the network is composed of two pathways: the controlled pathway on the left and the automatic pathway on the right. in the automatic pathway  the sensory input layer influences the motor output layer via the automatic path layer. this is similar to the network used by gupta and noelle  1a; 1b   with one addition. a contextual hidden layer has been added to this pathway  which provides a copy of the automatic path layer activity at the previous time step as input to the automatic path layer during the next time step. connection weights from the automatic path layer to the motor output are not allowed to exceed 1% of the maximum weight value allowed by leabra  implemented by setting the relative weight scaling parameter to 1 . this restriction allows the controlled pathway to strongly dominate over the automatic pathway by strengthening the controlled pathway's influence on the motor output layer beyond what is possible for the automatic pathway. this dominance occurs when cognitive control is strong. when cognitive control is weak  however  the automatic pathway weights can still be strong enough to drive appropriate outputs.
　in the controlled pathway  the sensory inputlayer provides input to the pfc layer. this layer generates a declarative representation of the key sequence  by sequentially activating a single unit in the pfcoutput layer corresponding to the cur-

table 1: network performance  sse  during early stages of learning.
sequenceboth pathways  high control controlled pathway aloneautomatic pathway alonesequence 1.1  ＼1 1  ＼1 1  ＼1 sequence 1.1  ＼1 1  ＼1 1  ＼1 sequence 1.1  ＼1 1  ＼1 1  ＼1 figure 1: the leabra network. each gray box corresponds to a neural processing unit. each arrow represents complete interconnectivity between the units in two layers. the dashed line from the motor output layer to the sensory input layer signifies that  when the arm is unguided  the output at the previous time step is the input for the next time step.
rent target key. the pfccontext layer feeds the pfc layer activity from the previous time step. the pfcoutput layer  as well as the sensory input layer  provide input to the motor area layer. the motor area layer translates the current key target  in pfcoutput  and the current sensory input into an appropriate action at the motor output. it is important to note that  during training  the pfcoutput layer receives an explicit error signal  as does the motor output layer   driving the pfc to learn to produce the correct sequence of target keys. finally  the pfc layer also provides input to the automatic path layer. this input helps guide learning for the automatic execution of the sequence.
　our model includes a cognitive control modulation mechanism. this mechanism modulates the strength of the controlled pathway's contribution to the final motor output as well as the strength of the input going from the controlled pathway to the automatic pathway. cognitive control is modulated as follows:
controlnew = λ controlold + 1  λ  α conflict + β 
controlnew specifies the value of control for the currenttrial. this value  which is between 1 and 1  is used to scale the weights from the controlled pathway  using leabra's relative weight scaling parameter . controlold specifies the value of control for the previous trial. α  β and λ are constants  with values of 1  1 and 1 respectively  determined by an ad hoc search. conflict is a normalized measure of performance error  and it is computed as follows:

where error is the sum squared error  sse  produced in the motor output layer during the previous trial. θ and γ are constants with values of 1 and 1  determined by an ad hoc parameter search. if the value of control is less than 1  it is thresholded to 1. if the value of control is greater than 1  it is set to 1. hence  the magnitude of control is approximately proportional to a running average of output error over previous trials. when error has been high  control will be high  and the influence of the controlled pathway will be strong.
　the focus of this work is on the learning of specific motor skills  rather than on the development of basic motor competence. thus  it was assumed that the system included the means to generate a reaching motion to a single target key  with the identity of that key being actively maintained in pfc. this pfc-controlled reaching process was implemented in the pathway from the pfcoutput  through the motor area  to the motor output. this portion of the network was pre-trained to capture fundamental motor competence. during pre-training  the network experienced every possible arm configuration along with every possible target key  and it was trained  using leabra's standard synaptic modification rules  to produce the next time step of an appropriate reaching response. once this pre-training was complete  learning was disabled for all projections going into or out of the motor area layer.
　in order to examine the learning properties of our model  we trained it to produce three randomly generated 1-key sequences. each simulation involved the learning of one of these sequences. random generation of the key sequences resulted  at the finer level of arm motion time steps  in sequences of 1  1 and 1 arm states for the three sequences. for each sequence  we examined the learning profile of each of the two pathways when isolated  as well as the performance of the model as a whole. each simulation was repeated five times with different random initial synaptic weights in the network  and we report the mean and standard error of the mean over these five repetitions for each measurement taken.
1 results
table 1: network performance  sse  after extensive training.
sequenceboth pathways  high control controlled pathway aloneautomatic pathway alonesequence 1.1  ＼1 1  ＼1 1  ＼1 sequence 1.1  ＼1 1  ＼1 1  ＼1 sequence 1.1  ＼1 1  ＼1 1  ＼1 initially  the automatic pathway was disabled  and only the controlled pathway was trained. on each trial  the initial arm state was presented at the network's input  and this triggered the selection of a target key at the pfcoutput layer. a training signal was then provided to this layer  specifying the correct target key. the correct target was then actively maintained in the pfc while the motor area layer generated the corresponding reaching motion. once each reach was complete  the pfc was allowed to rapidly update  based on the activity in the pfccontext layer and the sensory input layer  selecting a new target key at pfcoutput. a training signal was then provided  once again  to pfcoutput  and this process continued until the end of the sequence  and the end of the trial  was reached. through this training process  the controlled pathway learned quickly. an average of 1  ＼1   1  ＼1   and 1  ＼1  trials were required for the controlled pathway to learn the three sequences to criterion  respectively.
　next  the controlled pathway was disabled in order to examine the learning performance of the automatic pathway. once again  each trial began with the initial arm position being provided as input. synaptic weight changes were made in response to training signals provided at the motor output layer  with performance error driving learning in the standard leabra manner. the arm was guided from key to key in the sequence  forcing the sensory input to always fall along the correct trajectory. this process continued until the motor sequence was complete. an average of 1  ＼1   1  ＼1  and 1  ＼1  trials were required for this pathway to master the three sequences  respectively. hence  the time required to train the automatic pathway was found to be substantially greater than the time required to train the controlled pathway for all three sequences. clearly  learning the declarative sequence of key identities was easier than learning the nuanced motor trajectory needed to visit every key in order. this provides an explanation for why learning in the controlled pathway is generally faster  allowing it to dominate performance early in skill acquisition.
　finally  the complete model was trained on each key sequence  with the control modulation mechanism determining the strength of the controlled pathway on any given trial. initially  performance error was high. this quickly resulted in a high level of control  i.e.  a control value of 1   maximally increasing the influence of the controlled pathway. because the controlled pathway can learn rapidly  error then dropped rapidly. this drop occurred after 1  ＼1   1  ＼1  and 1  ＼1  training trials for the three sequences  respectively. network performance at this point in training is shown in table 1  alongside the performance that arose when each pathway was temporarily disabled at this point in training. note that correct motor sequences were produced by the intact model and by the controlled pathway alone but not by the automatic pathway in isolation. this is consistent with the observation that human performance suffers early in skill learning when the controlled pathway is disrupted e.g.  under pfc-based working memory load .
　another interesting observation is that the full model was able to generate the correct sequence despite the automatic pathway's tendency to generate incorrect responses. it appears as if the controlled pathway  which was the primary contributor to the correct output  learned to compensate for some of the erroneous activity from the automatic pathway. this may be the reason why the error for the isolated controlled pathway is slightly greater than the error for the full model. the isolated controlled pathway might have been overcompensating for an automatic pathway that was no longer present.
　training was continued past this point. when the control was up-modulated to a high value  the network produced correct motor sequence due to the corresponding frontal involvement. however  as correct outputs were generated  the running average of error decreased and the strength of control dropped. when this happened  the controlled pathway's contribution to the motor output decreased  bringing error back up and strengthening control. thus  control oscillated close to its maximum level. during this entire process  the automatic pathway continued to learn. when the strength of control was high  the network generated correct output. since the amount of error was negligible on these trials  leabra's error-correction learning rule played only a small role  and the automatic pathway learned primarily through the hebbian component of the learning algorithm. when control dipped and significant error appeared at the output  the automatic pathway benefited from the error driven learning component of leabra. for the three sequences  the automatic pathway needed an average of 1  ＼1   1  ＼1  and 1  ＼1  training trials  respectively  to master the task. once the automatic pathway learned the sequence  the strength of control dropped to 1. this signified that no control was being employed and the task had been automatized.
　network performanceat this late stage of learning is shown in table 1. at this point  each pathway produced reasonable performancewhen isolated fromthe other. interestingly error increased when both pathways were incorporated and control was set to its maximum level. thus  our model suffers when excessive control is employed during the execution of an automatized motor skill  just as is observed in humans who are performing a well-practiced skill under pressure  beilock et al.  1 . late in training  as control reached its minimum value of 1  the automatic pathway learned to generate the correct motor sequence without any input from the controlled pathway. hence  the introduction of control resulted in unwanted frontal input  degrading performance.
　a final curious observation is that the time required by the automatic pathway to learn the sequence in the full model is substantially greater than the time needed when the automatic pathway is trained alone. this occurred because the controlled pathway kept the network error low  limiting the utility of leabra's error driven learning mechanism and causing connection weights to change more slowly.
1 discussion
we have reported some initial explorationsof a computational cognitive neuroscience model of automaticity in motor skill learning. the use of this computational framework now gives us the capability to produce both qualitative and quantitative predictions concerning human behavior. in our model  a declarative representation of the skill is quickly acquired in the frontal controlled pathway. with additional practice  a procedural representation of the skill is also acquired in the automatic pathway. as the automatic pathway becomes more and more proficient  the contribution of the controlled pathway is gradually retracted by a control modulation mechanism.
　for the simple sequence learning task that was explored in these simulations  the controlled pathway was faced with the relatively simple task of learning a sequence of key identities. the actual motor output was initially produced as a succession of reaching motions that were generated by a pre-trained component of the model. not all motor tasks lend themselves to such a simple declarative representation  however. while skilled motions like a golf put or a ping pong smash can definitely be broken down into discrete declarative steps  the actual execution of each of those steps is not as simple as a previously-mastered reaching behavior. when learning such skills  it might be necessary for the motor areas participating in the controlled pathway to learn to execute each component step  limiting the utility of the controlled pathway.
　some theories of automaticity suggest that the declarative component can assist in the training of the procedural component. this happens  in a small way  in our model. early in training  the controlled pathway produces correct output activation levels  and this allows hebbian learning in the automatic pathway to improve performancein that pathway. hebbian learning in leabra is fairly weak  however  particularly in comparison to the error driven learning mechanisms used in this framework. we intend to explore ways in which this this interaction can be strengthened  allowing the controlled pathway to  teach  the automatic pathway.
　the main limitation of our model is that it does not yet capture execution-time differences between controlled processing and automatic processing. it is well established that controlled execution of an skill is slower than automatic execution. this is our most pressing matter for future research.
acknowledgements
this work was supported  in part  by the usa national science foundation under grant eia-1. the authors also extend their thanks to the members of the vanderbilt computational cognitive neuroscience laboratory  ccnl  and to three anonymous reviewers.
