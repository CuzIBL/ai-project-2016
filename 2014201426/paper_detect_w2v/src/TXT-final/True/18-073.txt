i n f o r m a t i o n a c q u i s i t i o n i n m i n i m a l w i n d o w s e a r c h 
alexander reinefeld t 
jonathan schaeffer 
t.a. marsland ft 
computing science department  
university of alberta  
edmonton  
canada tog 1 

a b s t r a c t 
　　the alpha-beta tree search algorithm can be improved through the use of minimal windows. branches are searched with a minimal window 
 α α+l  with the expectancy that this will show the sub-tree to be inferior. if not  then that sub-tree must be re-searched. in this paper  several methods are discussed to minimize the cost of the re-search. two new algorithms  ins and pns  are introduced and their performance on practical trees is shown to be comparable to sss*  but with considerably smaller overhead. 
1. introduction 
　　the use of minimal windows  l  provides an improvement to the alpha-beta tree-searching algorithm  ab    minimal window search is based on the assumption that all subtrees are inferior to the best subtree searched thus far  until proven otherwise. having searched the lirst branch with a full window  α 1   all remaining branches are searched with a minimal window  α α+1   where a represents the best minimax value found so far. if the value returned is indeed   a  then our assumption was correct and the subtree is inferior. otherwise  this subtree is superior and usually must be re-searched with a wider window. 
	the 	re-search 	idea originally appeared 	in 
pearl's scout algorithm . subsequently  there have been two generalizations  principal variation search  and negaseout . figure 1 shows the 
negaseout  ns  algorithm for searching a tree of width w and depth d. if a node p is terminal  evaluate p  returns its value. for interior nodes  gencrate p  determines the w branches from p. 
those branches whose minimal window search produces a better minimax value of v usually must be re-searched. only when α   v   1  and the remaining depth of search is greater than 1  is a re-search with a window  v 1  necessary. 
t current address: universitaet hamburg  farhbereich informatik  schlueterstr.1  d-1 hamburg 1  westgermany. tt research reported here was supported in part through canadian nserc grants a1 and e1. 
this paper introduces two new algorithms. 
those use information acquired from the original search of a. subtree to minimize the cost of a possible re-search. informed negascout  ins  uses 
all available information to generate the smallest possible trees  but does so with increased storage overhead. partially informed negascout  pns  is a compromise between ns and ins. the performance of ns  pns  and ins is compared with ab and sss*  1 . ins searches trees of size comparable to those traversed by sss1'  but does so with lower overheads. 


a. reinefeld et al. 1 
information gathered from the initial search of 

the subtree is used on a re-search to allow two new types of cut-offs. figure 1 illustrates the ignore left cut-off. in figure 1a  the subtree has been searched with a minimal-window of  1 . the descendant b returned a value of 1 causing a normal beta cut-off. if at some future point it is necessary to re-search this subtree  descendant a need not be looked at again since it has already been shown to be inferior to b  figure 1b. 
　　figure 1 illustrates the prove best cut-off. at these nodes  a beta cut-off has not occurred and all descendants have been examined. each of the values returned is an upper bound on the subtree's true value  figure 1a. if a re-search is necessary on this subtree  there are three things that can be done to minimize tree size. first of all  the branches can be re-ordered according to their values from the initial search. by sorting the branches in descending order of value  the branch with the highest upper bound  and therefore with the highest probability of being the root of the best subtree  is searched first. figure 1b. 
　　secondly  since the initial value for each subtree represents an upper bound  the re-search can be done with a narrow window instead of a minimal-window. by doing this  no re-searches of re-searches can ever occur. 
　　finally  if the search of a subtree returns a true value that is greater than the upper bound of any of the other descendants  then those descendants can be discarded without any further work. for example  in figure 1b  if move b is re-searched and returns a true value of 1  then moves a  and c need not be searched again  since their values can never exceed that of b. 
　　it turns out that ignore left cut-offs are just a 
　　special case of prove best cut-offs. branches proven inferior can be treated as having value - and the rest of the branches as having a +± value. retrieving this information and performing a stable sort creates the prove best condition. the cut-offs are treated differently because in an actual implementation the ignore left cut-offs require less storage to maintain the necessary information  e.g. only the number i of the best descendant thus far need be saved. on a re-search  descendants 1 through i-l are ignored and the remainder searched. at prove best nodes  the values for all descendants must be saved. 
1. algorithms 
　　negascout can be enhanced to use information from the initial search of a subtree to aid in any re-searches. every time a node is visited  a record is kept of the results obtained from searching each descendant subtree. either a beta cut-off occurs  and ignore left information is available for a re-search  or all descendants are examined  and prove best information is available. in both cases  this information can be linked together to form a map of the subtree just searched. if a re-search is necessary  the map data can be used to achieve ignore left and prove best cut-offs that are not possible in negascout. informed negascout  ins   see appendix  does exactly this for all nodes in a 
　　tree. 
the storage overhead in saving all this infor-
mation is proportional to w* entries  which is less than for sss*. nevertheless this may be too much  even if one reclaims storage whenever possible. as an alternative  partially informed negascout  pns  has been implemented  providing a compromise between the complete information of ins and the zero information of ns. one can devise many different compromise algorithms  our version of pns only retains information about prove best cut-offs near the root of each subtree and maintains the principal variation  the path to the terminal node that the initial search considered best. this algorithm tries to provide many of the benefits of ins without the storage overhead. 
　　an important point to note is that the information used by ins is not a hash table or a transposition table  1 . whereas transposition tables are most useful in directed graphs  the methods described here are applicable to any tree structure and do not depend on the properties of the application. 

1 a. reinefeld al 
1. results 
　　figures 1 and 1 illustrate some results comparing ab  ns  pns  ins  and sss*. the number of leaves se are lied by each algorithm is normalized to the size of the minimal game tree . each data point represents an average over 1 runs. random trees  where each descendent has an equal probability of being best  and strongly ordered trees   where the first descendent has a 1% probability of being the best  were searched by all algorithms. in figure 1  data at depths 1 and 1 are not available for sss* and ins  because of memory constraints. 
　　the graphs provided  as well as results for other widths not reported here  show that the curves oscillate  with sss* varying the least. the oscillation is normal and occurs because the formula for the minimal tree size depends on whether the tree is of even or odd depth. sss* fluctuates least since it is a best first search algorithmt; the other algorithms are  partly  directional. for even search depths sss* visits fewer nodes than ins  but for odd search depths ins is usually better  because ins postpones node expansion until it is proven that the principal variation lies in this part of the tree. of course  minimal window techniques are favored in strongly ordered trees  since researches are less probable. here even a modest amount of information is enough to allow pns to outperform sss* at odd depths. 

　　nodes visited is not the only consideration when comparing tree searching algorithms. sss* and ins have significant overheads when compared to ab and ns. obviously  any timing results are implementation dependent. our experience is that a call to ins is  on the average  about twice as expensive as a call to ab  ns  or pns  and that sss* is 1 times slower than ins. whether this overhead is significant or not depends on the application. 
1. conclusions 
ins has been shown to be competitive with 
sss* in terms of leaf nodes searched. however the data structure to support ins is more efficient. not only is it slightly smaller  but it can be processed in one tenth the time required by sss*. perhaps more importantly  by storing the information acquired during the minimal window search in a hash table  rather than as a map of the re-search tree  the memory needs can be reduced to the space available. the cost for use of such reduced memory is increased search overhead  but the search time is bounded below by ns. 
　　pns represents a good compromise  yielding significant reductions in tree size with little time and space overhead. in our experience  pns is the preferred algorithm for large trees  especially under conditions of well ordered interior nodes. 
　　the results reported here show the relative properties of the algorithms. experiments are continuing to obtain a better measure of the standard deviation. current work includes empirical performance analyses of these algorithms in practical game playing programs. 


a. reinefeld et al. 1 
t.a. mars!and and m.s. campbell  parallel search of strongly ordered game trees  acm computing surveys 1  1  1   1. 
a. reinefeld  an improvement of the seoul tree search algorithm  icc a journal 1     1   1-h. 
go. stockman  a minim ax algorithm better than alpha-beta  artificial intelligence 1  1  1   1. 
m. campbell and t.a. marsland  a comparison of minimax tree search algorithms  artificial intelligence 1   1   1. 
