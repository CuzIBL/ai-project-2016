 
this paper compares alternative approaches to pose estimation using visual cues from the environment. we examine approaches that derive pose estimates from global image properties  such as principal components analysis  pca  versus from local image properties  commonly referred to as landmarks. we also consider the failure-modes of the different methods. our work is validated with experimental results. 
1 introduction 
a considerable amount of research has been conducted on the problem of using vision to localize a robot in a known environment. two basic approaches have emerged; the first correlates global properties of the image  such as a principal components subspace projection; whereas the second correlates a set of local properties  or landmarks. each approach has its own strengths and weaknesses  and is based on its own assumptions about the environment. it is often argued that local feature-based representations are more robust to scene dynamics and illumination variation than globally-derived representations. it is also widely assumed that feature-based approaches require less online computation time than global approaches. 
　the goal of this paper is to critically examine a selection of image-based pose estimation methods and compare them for their performance under a variety of conditions. we consider accuracy and running time as the two major indicators of performance. 
1 previous work 
pose estimation from monocular vision data is non-intrusive and conceptually appealing as a research direction. position estimation entails a combination of estimating local displacement with recognizing familiar locations. it has been approached as both a coarse place-recognition problem  e.g. based on color histograms for familiar locations  ulrich and nourbakhsh  1   and also as a problem of recognizing a set of local features associated with a specific location  for example  se et al.  1  . in several approaches  authors have suggested interpolating between familiar locations to produce a position estimate more accurate than the density of training data  using either global image features   nayar et al.  1; pourraz and crowley  1   or sets of local image features   sim and dudek  1  . in this paper we compare the performance of some of these alternatives.. 
1 localization methods 
framework we assume the same framework for all of the methods presented below. first  a set of training images has been collected from known poses in the environment. a model  or models  are constructed by building an interpolant over the set of training poses. we employ bilinear interpolation of the observation space over the delaunay triangulation of the pose space. the cost of constructing the triangulation and any other preprocessing of the training images  such as tracking features  is referred to as the offline cost. 
　when a pose estimate is required  a probability distribution is computed using a multi-resolution grid-based discretization of the pose space. at each grid position a predicted observation is generated and compared with the actual observation. the probability is computed using bayes' rule  whereby  assuming a uniform prior  the probability of a pose q is proportional to the probability of the observation z given the pose: p{q z  oc p{z q  
once a cell with maximal probability is determined  a higher resolution discretization is computed in the neighborhood of that cell  and the process recurses until a desired level of resolution is achieved. by setting the maximum discretization to a fixed value  we fix the number of times the likelihood function is evaluated  thus allowing us to benchmark the performance of the method. this running time is referred to as the online cost. 
1 	global methods 
edge density out first globally-based method computes a map of the local edge density of the image. the density is approximated by convolving the image edge map with a wide  1 pixels  gaussian kernel. the edge map is relatively resistant to illumination changes  and measuring edge density propagates edge information locally. depending on the width of the kernel  a linear combination of neighboring training edge densities can loosely approximate the motion of edges as the camera moves. 

1 	poster papers 

principal components pca operates by computing a lowdimensional subspace of the space spanned by the training images. for this work  we employ the first twenty principal components. when pose likelihoods are computed online  only the low-dimensional projections of the training inputs are interpolated. the input observation must be projected into the subspace; an operation that is performed once; and subsequent comparisons are between low-dimensional vectors. 
1 	local methods 
the alternative to computing global image features is to extract a set of local image features  or landmarks  and model their behavior as a function of position. local features must be selected and tracked  and subsequently they are modeled. finally  when online they must be matched to features in the input observation. once matching is complete  the individual estimates from different landmarks must be combined in a robust manner. 
we use the landmark-based method proposed by sim and 
dudek  sim and dudek  1 . that model selects landmarks using saliency  and  once they are tracked across the training space  models the landmark behaviors as a function of pose. the models compute a linear interpolant of the landmark attributes over the triangulation of the pose space. 
　we employ two versions of the landmark model; the first  referred to as dynamiclm models the appearance of the landmarks as a function of pose  and thus matching may require several instantiations of the landmark before it is successfully matched. the second  referred to as fixedlm  fixes the landmark appearance  speeding up the matching  but reducing the range of poses that the landmark can model. 
1 experimental approach 

figure 1: images from a  the training set  top left   b  thenoisy verification set  top right   c  the occlusion set with noisy occluders  middle left   d  the occlusion set with solid occluders  middle right   and e  the illumination set  bottom . 
poster papers 
	mean 	max 	tot. 	online 	online 
	err. 	err. 	train'g 	preproc. 	loc'zn 
	 cm  	 cm  	time s  	 s/img  	 s/img  

edge density 1 1 1 1 1 nn  edgedens  1 1 n/a n/a n/a pca 1 1 1 1 1 nn  pca  1 1 n/a n/a n/a || global methods 
local methods dynamiclm 1 1 1 1 1 fixedlm 1 1 1 1 1 table 1: localization results for normal set. 
training we used a robot to collect 1 images in a grid pattern at 1cm intervals  over a 1m by 1m area  figure la  . ground truth was obtained by mounting a laser pointer on the robot and measuring by hand the position of the laser point on the floor. as such  the ground truth is accurate to ~1cm. 
　the same set of training images was provided to each localization method for preprocessing and training  and the running times for this phase were recorded. 
verification a set of 1 verification images were collected with the robot from random locations at the same orientation as the training images. ground truth was measured by hand. the images were collected under the same illumination conditions and observed the same static scene. these images constitute our normal verification set. gaussian white noise was added to these images to create a noisy verification set  figure la    and a set of occluders were randomly painted into the images to generate two occlusion sets  figure lb  and lc  . the first set of occluders consists of white noise  and the second consists of solid tiles. 
　a second set of ten images was collected under lowlight conditions from random locations. ground truth was recorded by hand. these images are referred to as the illumination verification set  figure id  . 
　each localization method was applied to each verification set  and the mean error between the maximum-likelihood  ml  estimate and ground truth was compiled on a permethod  per-set basis. the computational cost of preprocessing the input images and computing the ml estimate was also recorded. for each image  the multi-resolution grids were evaluated at a total of 1 distinct poses. 
measuring performance consider the expected error using a method that selects the nearest training image with 
1% accuracy. this magic number can be computed to be 1cm for our experiments. a mean error of less than 1cm could be considered to be successful at interpolating over the training set. in practice a nearest-neighbor implementation is unlikely to be perfect  and will generate larger errors. we have applied a nearest neighbor  nn  approach to the two global methods on the normal set. 
1 experimental results 
table 1 depicts the results for the normal set. the mean localization error  maximum outlier  and offline and online run-
1 
mean  cm  max 
 cm  estimates global methods 
edge density pca 1 
1 1 
1 1 1 local methods 
dynamiclm 
1 fixedlm 1 
1 1 
1 1 
1 table 1: localization results for noisy set. 
mean 
 cm   max   cm  estimates global methods edge density 
pca 1 
1 1 
1 1 
1 local methods 
dynamiclm 
1 fixcdlm 1 
1 1 
1 1 
1 table 1: localization results for noisy occlusion set. 
ning times are depicted. for the two global methods  nearest neighbor results are also tabulated for comparison. only the pca and fixedlm methods approach the magic number. the nearest neighbor approaches perform poorly against the magic number. as expected  pca presents a large offline computational cost  but very low online cost. 
   table 1 depicts the results for the noisy set. in the case of the landmark-based approach  we have indicated error results for only those images where at least one landmark was successfully matched. the number of estimates is indicated in the last column  out of the total number of verification images. both global methods saw an improvement in performance. 
   table 1 depicts the results for the occlusion set with noisy occluders. the local methods perform significantly worse  despite improved matching output in the fixedlm case. pca continues to perform well  but the edge density approach is confounded by the introduction of regions of high edge density. 
   table 1 depicts the results for the occlusion set with solid occluders. the local methods demonstrate a degradation in performance  although not as great as for the white noise occluders. there is also a reversal in performance for pca versus edge density. 
   table 1 indicates the results under altered illumination conditions. while all of the methods perform poorly  the edge density approach suffers the least degradation. 
mean 
 cm   max  cm  estimates global methods 
edge density pca 1 
1 1 1 1 1 local methods 
dynamiclm 
1 fixedlm 1 
1 1 
1 1 
1 table 1: localization results for solid occlusion set. 
mean  cm  max 
 cm  estimates global methods 
edge density pca 1 
1 1 
1 1 
1 local methods 
dynamiclm 
| fixedlm 1 
1 1 1 1 table 1: localization results for illumination set. 
1 	discussion and conclusions 
both pca and the landmark-based methods present significant offline costs  calling into question their practicality for applications such as simultaneous localization and mapping. however  pca was robust to some types of adverse imaging conditions  and was demonstrably faster in computing online pose estimates. 
   while the edge density method was less accurate than pca  it took significantly less time to train  at the cost of slower online performance. however  the ongoing increase in cpu speeds makes global methods such as these increasingly practical. 
   finally  the landmark-based methods presented a smooth degradation in performance as the imaging conditions became increasingly adverse. in general  these methods performed well  but were significantly more expensive online due to the cost of matching and frequent invocation of the landmark prediction model. online performance of these approaches depends to a large extent on the nature of the prediction model itself. 
   we have presented a comparison of several localization methods in a known environment against a variety of imaging conditions. the results challenge some widely held assumptions about the various advantages and disadvantages of local and global methods. 
