 
　　additive and/or graphs are defined as and/ /orgraphs without c i r c u i t s   which can be considered as folded and/or trees; i.e. the cost of a common subproblem is added to the cost as many times as the subproblem occurs  but it is computed only once. additive and/or graphs are naturally obtained by reinterpreting the dynamic programming method in the l i g h t of the problem-reduction approach. an example of this reduction is given. 
　　a top-down and a bottom-up method are proposed for searching additive and/or graphs. these methods are  respectively  extensions of the  arrow  method proposed by nilsson for searching and/or trees and dijkstra's algorithm for finding the shortest path. a proof is given that the two methods find an optimal solution whenever a solution exists. 
1  introduction 
　　in the l i t e r a t u r e on a r t i f i c i a l i n t e l l i gence  and/or trees have proved to be a good formalism for representing the problem-reduction approach to problem solving . usually  the search is for any solution tree  but in a paper by nilsson the problem is presented of finding the best solution tree  where arcs have a given cost  and the cost of a tree is simply the sum of the costs of the arcs. nilsson gives there an algorithm which assumes available  for each node  an estimate of 
the cost of the  optimal solution tree rooted at that node. 
　　an algorithm for searching and/or graphs has been proposed by chang and slagle 1 . here a solution graph is defined in the usual way  and  as for trees  the cost of a solution graph is the sum of the costs of i t s arcs. 
　　in this paper we introduce a new type of and/or graphs called additive  which can be considered as folded and/or trees  i.e. trees where different nodes have been recognized to be roots of equal subtrees and have been ident i f i e d   thus generating and/or graphs without c i r c u i t s . however  the cost of a solution subgraph is defined as equal to the cost of the unfolded equivalent tree. in other words  the cost of a common subproblem is added to the cost as many times as the subproblem occurs  but it is computed only once. 
   additive and/or graphs are naturally obtained by reinterpreting the dynamic programming method of optimization in the l i g h t of the problem-reduction approach1. 
　　for giving an idea of the technique of reduction  we w i l l consider here the w e l l -known problem of halancing binary search trees  solved by knuth viith a  modified  dynamic programming algorithm . here a number of ordered items  lexicographically ordered words  for instance  are given  together with 
probabilities of a new item occurence to 
be any of the given items or to be a new item 
located in any intermediate position. for 
example  the data 
mean that there are 1 probabilities out of 1 that a new word w i l l be  do  and 1 nrohahilities that a new word w i l l be any word between  do  and   i f   . 
　　a binary search tree for these data is a tree of the type shown in fig. 1. for instance if the new word  array  is generated  i t s proper location is found by means of three tests  namely comparisons with the given words   i f   and  begin  respectively and a termination test. 
　　given a search tree  the average number of tests m necessary for reaching a node  is then given by summing up the products of the number mj. of tests required for any node i and i t s probability p1 

   for instance  the average number of tests for the tree in fig. 1 is 

the problem is to find a search tree with minimal cost m. for instance  the tree of fig.1 
is optimal for the data 	 1 . 
　　an equivalent formulation of the same problem considers frequencies instead of prob a b i l i t i e s . in this case the cost is called weighted path length. 
   two properties allow the use of a dynamic programming technique in this case. f i r s t   if t =  a a 1  is an optimal tree rooted in a and having a and 1 as subtrees  then both o and b are optimal. furthermore  the data for a and s are d i s j o i n t substrings of the data for t. second  if fa  fa  fb ' l a 'lb are the frequencies of a o and 1 and the weighted 

 in the dynamic programming algorithm  all the subproblems of the given problem are considered  whose data are substrings of the given data. such problems are divided in lev els  according to the length of the data  and solved in increasing order* a problem at a level can be solved by picking up a root in all possible ways *   say jo and thus decomposing the problem in k pairs of subproblems at lower levels. the cost of every decomposition is computed using  1 and a best decomposition is chosen. 
　the 	optimal 	search tree problem described above is a good example of the gener al case where  at each stage  the computation of each alternative requires the sum of 
the costs of one or more  in fact  two  sub problems. 
　in this case  the structure of the problem is conveniently reflected into an additive and/or graph  whose and nodes correspond to subproblem cost sums  and or nodes to alternative selections. for instance  the and/or graph for the optimal search tree problem  with data  1   is shown in fig. 1. there and nodes are marked with circles and or nodes 
 corresponding to subproblems  with squares. the optimal solution graph  corresponding to the search tree in fig. 1  is blackened. 
　reduction of dynamic programming to addit1 ve and/or graphs can imply several advantages. first  the and/or graph expresses the structure of the problem in the form of a partial ordering of subproblems. dynamic pro gramming solves all the subproblems bottom-up in some static order which respects the partial orderings. however in section 1 of this paper a bottom-up algorithm is described  which solves every time the cheapest available subproblem  thus considering  in general  only a subset of subproblems in a 
 *  actually  knuth1 gives a modified dynamic programming algorithm which excludes a priori most of the decompositions  using a particular monotonieity property. 
dynamic order. 
   second  in many cases estimates of the subproblem costs are available  which can be used for directing a top-down search. in fact  in section 1 we give an extension of nllsson's tree algorithm to the additive graph case  which  if the estimate is a lower bound of the minimal cost  is guaranteed to find the optimal solution graph. the algorithm is slightly simplified if the estimate satisfies a  consistency  constraint. finally  various known heuristic techniques can be applied to additive and/or graphs which can find a good solution where the exact dynamic programming algorithm is too expensive1. 
   we emphasize that this paper extends to general dynamic programming a reduction technique which is well-known in the so called  sequential  case1. there  each alternative can be computed by summing a constant to the cost of one simpler subproblem  thus reducing an additive and/or graph to an or graph. in this case  a solution tree reduces to a path and thus shortest path algorithms apply  like dijkstra's algorithm1 in the uninformed case and the algorithm by hart  nilsson  and raphael1 if an estimate is available. 
   finally  note that in the shortest path case no distinction between top-down and bottom-up is needed  while it is suggestive in the general case. 
1  additive and/or graphs 
   in this paper  we shall consider and/or graphs without cycles. an example is given in fig. 1. node a is called the start node and represents the problem to be solved. node a is called an or node  *  because a solution is 
constructed by selecting either its successor b or its successor c. node b is called an and node  because all of the suboroblems represent ed by its successors d and e must be solved in order to solve problem b. an and node is indicate by a line across the arcs connecting it to the successor nodes. nodes g and h are called terminal nodes and correspond to problems 
with known solution. 
   we assume that all the nonterminal nodes are either or nodes or and nodes  that is  there are no nodes corresponding to problems which can be solved by solving some of their successors. 
we give here a definition of or nodes and and nodes  which is opposite to the one given by nilsson1. we do so  because we want each node to be either an or node or an and node  instead  with nllsson's definition  we could have a node which is at the same time an or node because of one parent and an and node because of another parent. 
we s h a l l be concerned w i t h and/or graphs 
- i m p l i c i t l y s p e c i f i e d by a s t a r t node 	s 	and a successor o p e r a t o r 	t . a p p l i c a t i o n 	of r 	to any node 	n 	qenerates a f i n i t e number of successors of 	n 	and a l a b e l s n e c i f y i n o 
whether the successors are 	and nodes or or nodes  
   a s o l u t i o n graph of an and/or granh g w i t h s t a r t node s is any suhoranh of p c o n t a i n i n g s and havino the f o l l o w i n g p r o p e r t i e s ; 
 1  suppose node n of p is an or node and is included in the s o l u t i o n oraph. then one and o n l y one of the successors of n is a l s o included in the s o l u t i o n graph. 
 1  suppose node n of r is an and node and is included in the s o l u t i o n g r a p h . then a l l of the successors of n are a l s o included i n the s o l u t i o n oranh. 
 1  the s o l u t i o n granh is f i n i t e   meanlno t h a t i t ends i n a s e t o f t e r m i n a l nodes  
   fig. 1 shows two s o l u t i o n oranhs of the and/or qraph in f i g . 1. 
   in g e n e r a l   a c o s t is associated w i t h every arc of an and/or g r p h . let the funct i o n c   n  n.  g i v e the cost to he associated w i t h the are connecting node n i w i t h one of i t s successors n j . for a d d i t i v e and/or oranhs the c o s t of a s o l u t i o n granh is r e c u r s i v e l y d e f i n e d as f o l l o w s : 
 1  the cost c * 1 is associated w i t h everv t e r m i n a l node i n the s o l u t i o n o r a n h . 
 1  let c 1   -   c k be the costs associated w i t h the k successors of node n in 
the s o l u t i o n o r a n h . then we associate w i t h 	n 	the cost 	c 	oiven b y   *   
k 
c = 1  	  c   	+ c   n   n    i-1 
 1  the cost associated w i t h the s t a r t node s 	is the cost of the s o l u t i o n oranh. 
   the cost of a s o l u t i o n oranh can alwavs be obtained w i t h the above d e f i n i t i o n   	because s o l u t i o n e/raphs do not c o n t a i n c v c l e s . 
   the cost of a s o l u t i o n graph can a l s o be obtained by r e p r e s e n t i n g the s o l u t i o n nranh as a t r e e by d u n l i c a t i n q the suboranhs rooted at nodes w i t h more than one i n c i d e n t arc and t a k i n g the sum of a l l the arc costs of the t r e e . 
note t h a t both t h e and and the or case are here i n c l u d e d   since in a s o l u t i o n graph or nodes can have o n l y one successor. 
   for example  l e t us consider the two s o l u t i o n oranhs in f i g . 1  where we assume u n i t arc c o s t s . the cost of the f i r s t s o l u t i o n is 1 and the cost of the second one is 1  because the cost of the subtree rooted at t is considered t w i c e . 
   in the next s e c t i o n s   we s h a l l o i v e two a l o o r i t h m s t o f i n d s o l u t i o n oranhs having 
minimal cost f o r a d d i t i v e and/or oranhs. 
1  top-down search aloorithm 
   the a l g o r i t h m oiven in t h i s section f i n d s a s o l u t i o n oranh havino minimal c o s t   b e o i n nino w i t h the s t a r t node s and using t- to oenerate the oranh. at everv staoe in the g e n e r a t i o n of the g r a p h   a d e c i s i o n must be made about which node should have i t s successors oenerated n e x t .  reneratino the successors of a node hv r is c a l l e d expanding a n o d e .   . 
   the a l o o r i t h m is an extension of the algor i t h m nronosed hv n i l s s o n f o r and/or t r e e s and the two a l g o r i t h m s are p r a c t i c a l l v i d e n t i c a l f o r the n a r t i c u l a r case of anp/or t r e e s . the search method uses a set of arrows to ouide it from the s t a r t node down throuoh the and/or oranh searched thus f a r to t h a t node to he exnanded n e x t . fach expanded node has an arrow p o i n t i n g to one and only one of i t s successors based on e v a l u a t i o n s of the successors  when a node is oenerated f o r the f i r s t t i m e   i t s e v a l u a t i o n i s a n e s t i m a t e   which must be a v a i l a b l e on separate  rounds  of the cost of a minimal cost s o l u t i o n graph s t a r t i n g at t h i s node. the network of arrows is maintained bv updating the e v a l u a t i o n s of 
nodes t h a t are ancestral 	to those exnanded d u r i n o the process. the e v a l u a t i o n of a node gives 	the estimate of the cost of an optimal s o l u t i o n oranh havino t h a t node as s t a r t node. 
   the a l o o r i t h m c o n s i s t s of the f o l l o w i n n s t e p s : 
 1  begin w i t h the s t a r t node- s  
 1  if 	s 	is not marked solved  oo to 	  1   ; otherwi se e x i t w i t h the s o l u t i o n graph  this oranh 	is c o n s t r u c t e d by s t a r t i n g at 	s 	and using the f i n a l d i r e c t i o n s of the arrows to decide which 	successors 
of or nodes should be i n c l u d e d   
 1  trace down the arrows from s to a node n and expand i t . suppose node n has successors n 1 ..........n k . 
 1  undate the e v a l u a t i o n s and arrow d i r e c t i o n s of node n and a l l nodes ancestral to n  as f o l l o w s : 
tf a successor n1 of n has been oenerated b e f o r e   it has a l r e a d y an e v a l u a t i o n 
h   n i   . if a successor n i is generated f o r the f i r s t t i m e   i t s e v a l u a t i o n 
h n j   is the estimate of the cost of a minimal cost solution graph starting at node n j . if a successor is a terminal node  i t s evaluation is zero and it is 
marked solved. 
　　if node n is an or node  i t s undated evaluation is 

the arrow is directed from n to the successor n1 for which the minimum is achieved and n is marked solved if and only if n1 is marked solved. 
　　if node n is an and node  i t s updated evaluation is 

the arrow is directed from n to one of i t s successors which is not marked solved  according to a given c r i t e r i o n . a reasonable heuristic is the one of directina the arrow to that successor having the largest evaluation. if a l l the successors are marked solved  n is 
marked solved. 
the procedure of undating evaluations and arrow directions is then repeated for a l l the ancestors of node n by backing up the granh to s. 
 1  go to  1 + 
　note that during step  1    a node can he updated several times  because there can be several paths in the granh between a nair of nodes. however  the procedure w i l l alwavs terminate  since in the graph there are no cycles by hypothesis. 
　an example of search with the given alonrithm is shown in tin. 1. the nranh to he searched is shown in fig. 1a. arc costs are assumed to be unity and terminal nodes are marked. the numbers adjacent to every node are the estimate of the cost of a minimal cost solution araph starting at that node. fig. 1b through 1g show the parts of the graph generated after each cycle of the algorithm. the numbers attached to each node are the updated evaluations and marked nodes are solved nodes. finally  fig. 1h qives the solution graph found by the alnorithm. actually  this solution granh has minimal cost  as we shall show below. 
　as in the case of the arrow algorithm of nilsson1 or the algorithm of hart  nilsson and raphael1 for or graphs  we can show that  if the estimate function h n  is a lower bound on the cost of a minimal cost solution graph  then the algorithm is admissible  that is it w i l l always find a minimal cost solution araph. 
　　let a t i n node be a node of the aranh nenerated at a certain stage by the alnorithm 
which has not vet been expanded. let h n  he the cost of a minimal cost solution graph starting at node n. we then have: 
lemma 1. if h n   h n  for a l l t i n nodes  then at anv stane durinn the search process we have h n   h n  for a l l nodes n in the graph. moreover  if a node n is marked solved we have h n  = h n  and an optimal solution aranh can he obtained hv tracing down the arrows from n. 
proof. we shall prove the lemma by induction on the stages of the algorithm. the lemma is t r i v i a l l y true at staae 1. let us assume that it is true at a certain staae and let us nrove that it is true at the next stane  that is after the exnansion of a node  sav node n . 
in sten  a  of the alnorithm  we update 
a l l the nodes which are ancestors of node n. therefore  l e t us consider the subgraph g of the search aranh obtained un to this stage  which consists of a l l the ancestors of node n. beinn the graph without cycles  an index can be attached to each node of gf startina with n＜ = n  in such a wav that a l l the naths from node n1 to node n＜ contain only nodes n 
with i  i. 
　　we shall nrove the lemma bv induction on the index i. the lemma is certainly true for node n. tn fact  if anv of i t s successors n  has been nenerated before  we have bv induction and if the successor ni is generated for the f i r s t time  we have h n j     h n j   bv hypothesis. therefore  bv computing h n  according to sten  1  of the alnorithm  we have h n   h n . moreover  if node n is marked solved and is an op node  we know bv induction that for the successor 
n.| pointed to bv the arrow we have h  n i   =h  n1  and that an optimal solution for n1 can he obtained bv tracina down the arrows from nj  an optimal solution aranh for node n 
	w i l l contain node n j   since 	anv other 
solution nranh through another successor n1 
would have a not smaller cost. tn fact  from 

thus  if node n is marked solved and is on or node  we have h n  = h n  and an optimal solution graph can he obtained bv tracing down the arrows from n. the same holds if node n is marked solved and is an and node. 
1 
　　now  l e t us assume that the lemma is true for a l l the nodes 	nj 	with j 	  	1; then the lemma is true for node 	ni 	. this can be shown easily  by repeating for node 	ni 	the above arguments for node 	n. 
q.e.d. 
now we can prove the following: 
theorem 1. if a solution graph exists  if h n   . h n  for a l l t i p nodes n and if a l l arc costs are larger than some small positive amount 1   then the top-down algorithm is admissible. 
proof. 	we consider three cases: 
case 1. termination without finding a solution graph. this case is impossible. in fact  termination can only occur at step  1  when the start node is solved. but this can only happen if a solution graph has been found. 
case 1. no termination. let us examine the algorithm at a certain stage. if we trace down the arrows from node s  we obtain a path from node s to the node n to be expanded next. let c s n  be the cost of this path  that is the sum of the costs of i t s arcs. for each are   n j   n j     belonging to this path  we have h n i   c  n i  nj  +h nj . therefore  we have h s   c s n . let us assume now that  at a certain stage  we expand a node n for which c   s   n     h   s   . this is not possible because it would imply h s    h s  contradicting lemma 1. therefore  the algorithm can only expand those nodes n for which c s n     h s . the number of these nodes is f i n i t e because every node has a f i n i t e number of successors and the cost of every arc is greater than 1  hence the algorithm must terminate. 
case 1. termination with a solution oraph having non minimal cost. when the alqorithm terminates  node s is marked solved and 
we have h s  = h s  by lemma 1. moreover  lemma 1 states that an optimal solution graph can be obtained by tracing down the arrows from s. therefore  the algorithm can only terminate with an optimal solution graph. 
q.e.d. 
　　hart  nilsson and raphael introduced an assumption  called the consistency assumption  for the estimate h n   which allows a simplification of the algorithm for searching or graphs. analogously  we can give the consistency assumption for additive and/or graphs as follows. let h n  be the given estimate of the cost of a minimal cost solution graph starting at n. then the consistency assumption is if n is an or node . h n     hfn   + c n nj  for each successor n1 if n is an and node 
h n   i  h n1  + c n n i    
1 
　　with the consistency assumption  it is easy to see that the evaluation of each node can only increase at each stage of the algorithm. therefore  we can modify the last statement of step  1  of the algorithm as follows. one step of the procedure of backinq 
up the graph of the ancestors of node n  consists of updatino a l l the parents of a certain node m. assume that one of these parents mi is an or node. since the evaluation of each node can only increase  the evaluation of node mi w i l l be changed only if node mi has the arrow pointing to node m. therefore  in the procedure of backinq up the qraph of the ancestors of node n  we can consider only those or parents of a certain node m  which have the arrow pointing to m.note that  even in this case  a node can be undated several times during step  1 . 
1  bottom-up search algorithm. 
　　this algorithm finds a solution graph having minimal cost  starting from the terminal nodes and expanding a node at each stage. in this case  expandinq a node means generating a l l the parent nodes of that node. the algorithm does not use any estimate  thus it can be considered as an extension of dijkstra's algorithm for or graphs1. an evaluation function is computed for each node and the node whose evaluation function is minimal is expanded. the evaluation function for a node n gives the cost of a minimal cost solution graph startina at node n  obtained so far. 
   the algorithm is based on the assumption that we have a f i n i t e number of terminal nodes and it consists of the following steps: 
 1  put every terminal node ti on a l i s t called open and set h ti  = 1 for every i 
 1  remove from open that node whose h value is smallest and put it on a l i s t called closed.  resolve ties a r b i t r a r i l y   . call this node n. 
 1  if n is the start node  exit with the solution graph obtained by tracing back through the pointers  otherwise continue. 
 1  expand node n  generating a l l of i t s parents. for each parent ni do the 
following: 
         if ni. is an or node  we can have three cases 
a  ni 	is neither on open nor on closed. 
 associate with ni the value of the evaluation function 
	 n1  	   n  + c  ni n  
put node ni on open and direct a pointer from it to n. 
b  ni is on open. let h ni  be the evaluation associated with n i . associate with it a new value of the evaluation function given by 

if 	h ni  	has been changed  redirect the pointer from 	n i to n. 
c  ni is on closed. continue 
if 	ni 	is an and node  we can have two cases 
a  there is some successor of ni which is not on closed . continue. 
b  a l l of the successors of ni are on closed. associate with node ni the value of the evaluation function 

where the nodes nk are the successors of ni . direct pointers from ni to a l l of i t s successors and put ni on open. 
 1  go to  1  . 
　this algorithm is closely related to the dynamic programming method. in fact  the latter can be seen as a bottom-up breadth- f i r s t search algorithm  which expands a l l the nodes according to a fixed ordering. our algorithm  on the contrary  expands the nodes according to their cost  thus expanding  in general  fewer nodes. 
　an example of search with the given algorithm is shown in fig. 1. the graph to be searched is given in fig. 1a. the estimates attached to i t s nodes are not used by this algorithm. figs. 1a through 1j show the parts of the graph generated after each cycle of the algorithm. marked nodes are the closed nodes and the other nodes are the open nodes. arc costs are assumed to be unity and the numbers adjacent to the nodes are the values of h. nodes without an adjacent number are and nodes which have some successor not yet closed. fig. 1k gives the solution graph. 
　note that the graph generated by this algorithm has a simpler structure than the one generated by the top-down algorithm. in f a c t   at every stage of the algorithm  an or node has only one pointer to one if i t s successors whereas  at every stage of the top-down algorithm  the complete structure of the graph has to be retained. 
　we can show that the bottom-up algorithm is admissible  that i s   it w i l l always terminate in an optimal solution graph  
1 
whenever a solution graph exists. 
lemma 1. if a l l arc costs are positive  then  when a node n is closed by the 
algorithm  we have h n  = h n  and theoptimal solution graph can tracing down the pointers from n. moreover  a l l the nodes m with h m    h n  have been closed before node n. 
proof. the lemma w i l l be proved by induction on the stages of the algorithm. the lemma is t r i v i a l l y true at stage 1. let us assume it is true at a certain stage and let us prove that it w i l l s t i l l be true after the next stage. 
　let n be the open node whose h value is smallest at this stage. this node is closed by the algorithm. let us assume that a node m exists with h  m   h n    which has not yet been closed by the 
algorithm. let g be an optimal solution graph for node m. certainly  there is an open node of g  such that a l l of i t s successors in  g are closed. it is possible to see that h r  = h   r   . in f a c t   if r is an and node a l l i t s successors are closed and by the induction hypothesis their h value is the cost of a minimal cost solution graph  hence h r  * h   r   . 
	if 	r 	is an or node  we have 

where the nodes ri are the successors of r which have been closed so far. but we assumed that one of these successors belongs to an optimal solution graph for r  therefore h r  - h r  . 
moreover we have 

since the optimal solution graph for r is a subgraph of g  and 

since n is the open node whose h value is smallest. therefore we have 

which contradicts our hypothesis that node m has not yet been closed and we have shown that a l l the nodes m with h m  h{n  have already been closed. 
　now  we can show that h n  - h n . if n is a terminal node  this is obviously true. if n is an or node  we have shown above that  for any successor ni of  n which is not closed  we have h ni   h n . therefore  an optimal solution graph must contain a closed successor  because any solution graph through one successor which is not closed would have a larger cost. the pointer is directed from n to the closed successor n for which  h n j   + c n njl  is minimal and  by the induction hypothesis h n j  =h n j  . therefore  we have h n  = h n  and an optimal solution graph for n can be obtained by tracing down the pointers. 
   if n is an and node  a l l of i t s successors are already closed. since the lemma is true for the successors by the induction hypothesis  it is also true for n. 
q.e.d  finally  we can prove: 
theorem 1. if a solution graph exists and if a l l arc costs are positive  then the bottom-up search algorithm is admissible. 
proof. we prove the theorem by assuming the contrary. there are three cases to consider: 
case 1. termination without finding a solution graph. this case is impossible because the algorithm can only terminate at step  1  with a solution graph. 
case 1. no termination. assume that at a certain btage the algorithm closes node n with h n    h s . this is impossible  because  according to lemma 1  node s must have been closed before and when s is closed the algorithm terminates. therefore  the algorithm can only close those nodes n with h n     h s . but the number of these nodes is f i n i t e   since the arc costs are positive  and the algorithm must terminate. 
case 1. termination with a solution graph having nonmlnlmal cost. this is not possible  because it would contradict lemma 1. 
q.e.d. 
refefences. 
1 nilsson  n.j.  problem-solving methods in a r t i f i c i a l intelligence  mc graw-hill  new 'fork  1. 
1 nilsson  n.j.  searching problem-solving and game-playing trees for minimal cost solutions  proc. ifif congress 1  h  pp. 1. 
1 chang  c.l  and slagle  j.r.  an admissible and optimal algorithm for searching and/or graphs  a r t i f i c i a l intelligence  vol. 1  pp. 1- 1  1  . 
1 m a r t e l l i   a. and montanari  u.  dynamic programming via and/or graphs  in preparation. 
1 knuth  d.e.  optimum binary search trees  acta informatlca  vol. 1  pp. 1  1 . 
1 m a r t e l l i   a   edge detection using 
heuristic search methods  computer 
graphics and  image processing vol. 1  n. 1  pp. 1  august 1. 
1 kaufmann  a. and cruon  r.  dynamic programming  academic press  1. 
1 dijkstra  e.  a note on two problems in connection with graphs  numerlsche mathematlk  vol. 1  pp. 1  1 . 
1 hart  p.  nilsson  n.j  and raphael  b.  a formal basis for the heuristic 
determination of minimum cost paths  i.e.e.e. trans. scc 1  n.1  pp.1  july 1. 




1 

1 

1 


1 















