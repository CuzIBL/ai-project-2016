 
recently  hummel and landy proposed a variation on the 
dempster/shafer theory of evidence that tracks only the first and second order statistics of the opinions of sets of experts. this extension permits the tracking of statistics of probabilistic opinions  however  as opposed to tracking merely boolean opinions 
 or possibilities within the  frame of discernment  . both the dempster/shafer formulation and the hummel/landy formulation assume that bodies of experts that are combined to form new statistics have independent information. we give a model for parameterizing degree of dependence between bodies of information  and extend the hummel/landy formulation for combining evidence to account for sets of experts having dependent information sources. 
1. background 
     many systems using artificial intelligence concepts must combine information from disparate sources of knowledge to make a decision. often the information that is given is incomplete: evidence is accumulated suggesting one alternative or another  but in a quantitatively inconclusive way. the use of purely bayesian techniques sometimes encounters difficulties  due to the lack of sufficient information. there are thus many different ways that have been proposed for combining evidence. one method  called here the dempster/shafer theory of evidence   has received considerable interest and some use in experts systems. 
     central to the dempster/shafer theory  and several other formulations of combination of evidence  is a way of handling uncertainty in propositions. rather than assigning probabilities to possible labels  from a  frame of discernment    these theories attempt to assign degrees of confidence to the various propositions. in shafer's explanation of the dempster/shafer theory of evidence  this is done through the use of  belief functions  to assign weights to subsets of labels in their theory. in general  there is a set of possible labels  and a set of numbers representing a current state of belief. when additional information is obtained  the numbers are changed to a new state. each state is 
associated with the body of evidence obtained to that point  and the updating method represents the combination of the current body of evidence with the incremental evidence. 
     for example  for medical diagnosis applications  a patient can have one of a set of possible diseases. evidence is obtained in the form of symptoms and test results. given a current set of symptoms and results  a doctor might decide to run an additional test  and update the assessment of the patient's condition based on the results  in conjunction with the information already present. 
     in the theory of  belief functions   a state is represented by a probability distribution over the power set of the set of possible labels. thus a number is assigned to every subset of labels. new evidence is represented  in the dempster/shafer theory  by a new state  also assigning a number to every subset. the dempster rule of combination  is used to combine these two states to form a new state. 
     other possibilities include  bayesian  approaches  for which a state is generally represented as a probability distribution over the set of possible labels. each value is regarded as a  subjective  or  inferential  probability  and the use of bayes' formula in the presence of various independence or simplifying assumptions is defended by a body of research and results  especially those developed by good  savage  de finitti  and ramsey et al. a survey treatment is given in . 
     in a recent work by hummel and landy  1   it is shown that the dempster/shafer formulation is equivalent to the tracking of statistics of sets of experts expressing boolean opinions over the set of labels. the sets of experts update by combining  using bayesian updating  in pairs over the product space of experts. further  an alternate formulation is suggested. in this formulation  experts have probabilistic opinions  rather than boolean opinions  and the state of the system is represented by the mean and covariance  of logarithmic values  of those opinions. 
   a drawback of both developments is that conditional independence assumptions regarding the sources of information must be imposed. these assumptions are often unrealistic. roughly speaking  the assumptions state that the probability of a particular piece of information in the context of a single label  given some existing information  is the same as the probability without the existing information. independence is defined in terms of probabilities taken over the set of all labeling situations. consider  for example  the case of a medical diagnosis example. assume that s1 represents the set of symptoms and information obtained to date  and j1 is the new information. what is required is that the probability of the existence of the symptoms s1 amongst the set of all patients having a given disease must be the same as the probability of the existence of the same set of symptoms s1 among the set of patients having the symptoms s1 and the disease . further  this equivalence must hold for all diseases . in essence  this says that information about the symptoms s1 yield no information as to the probability of the symptoms s1  in the presence of any given disease. since symptoms generally have a common basis  this assumption rarely holds. 
     in fact  the independence assumption is not very realistic for most applications. it is required to justify the updating formulas  and is so predominant in most formulations for the combination of evidence that the limitations are generally overlooked. 
     in this paper  we introduce a model for measuring a  degree of independence  between sets of information. the degree of independence is measured by a single variable  which can in turn depend upon the information values  the symptoms   
 we then extend the hummel/landy formula-
tion for the combination of information to the case where the information it a-independent. the case will correspond to the same independence assumption as before. the case corresponds to completely dependent information  in the sense 
	hummel and manevitz 	1 
that s1 implies the information j 1 . 
     moreover  we develop formulti to that the statistics are taken over the union of the sets of experts  rather than over the product space. we find the use of the product sets of experts  less natural  than simply combining all experts into one collection. the difficulty  of course  is that when combining the experts into one collection  each expert must be required to update his opinion based on some other opinion  and it is not a priori specified which other opinion should be used. we suggest a solution. 
1. formulation 
¡¡¡¡let be a set of experts. each expert   is privy to a body of information  symptoms  about the current situation. we denote by t the information shared by the associated experts. the goal is to label the current situation  i.e.  the current patient  with a label x from the set of possible labels a. it is assumed that a is mutually exclusive and exhaustive. each expert  evaluates the information t and assigns a probability distribution to the set of possible labels a  represented by the set of values the average opinion  computed by taking a mean over all ' ~  is denoted by likewise  the covariance values are given by the formula by the formula '     
where prob x  is a prior probability of label x over all situations  e.g.  the probability of the given disease among all patients . the value c  is an indeterminate constant  meaning that the ys values are defined only to within an additive constant independent of x and of e. means and covariances of the y't are also defined  
yielding means and covariances of the logarithms  and are denoted by u f  and c /  respectively. the use of the logarithmic opinions simplifies the formulas  and is suggested in . 
now  suppose that we have two collections of experts c  and 
¡ê1 and thus two bodies of information s  and s1. we wish to combine the information  to obtain a new mean u.#1 1 * new covariance cn1n. similarly  we should combine the means and covariances of logarithms. 
     in hummel and landy   the formula is given for the log's  with complete independence. the formulas are: 

these formulas are derived by assuming that updating takes place using the set of all committees of two consisting of one expert from and one expert from  i.e.  the product space   and that within each committee  bayesian updating is used with a conditional independence assumption. 
1. 	unions of experts and a -independence 
conditional independence  used in the formulas above  
assert that prob  where the probabilities are taken over the set of all labeling situations  e.g.  patients   and not over the experts. 
     we now define the information independent if: 
for all 
note that for 
a - 1   the assumption reverts to conditional independence. 	for 
1 	reasoning 
a = 1   we have that the information s1 implies  with probability one  the information i 1 .  corresponds to negative evidence. the existence of such an a constitutes an assumption  and is not a completely general measure of independence or dependence. specifically  we are assuming that  is independent of  this is a strong assumption  but is not as strong as the assumption of independence. 
     one possibility for obtaining the  would be to poll experts for their estimates. alternatively  a might be obtained from the formula: 

of course  these kind of joint statistics are often hard to obtain. 
     in the presence of a s1  s1 -indepcndence  it is not hard to show that log-probabilities now update according to the formula 

the new updating formulas become 

obviously  the formulas have changed very little: the updating term giving the new information is simply weighted by the degree of independence of the new information. while this idea is fundamentally simple  we have justified the use of this weighted updating through a precise definition of a-independence. 
   we now introduce a second new concept to the formulation  that of union-based combination. in the formulas from the previous section  the information in is based on the product space of experts we find it more desirable to base formulas on the union space of experts the resulting set of information  contains updated opinions for each expert 
¡¡¡¡¡¡¡¡however  we must specify the manner in which each expert performs the updating  since there are no longer obvious pairs of opinions for each resultant expert. the method advocated here is to have the experts in update in a bayesian fashion based on the mean opinion from the set likewise  the experts in update using the information obtained from the mean opinion of experts in this changes the component formulas  so that  
likewise  for .   we have the same formula  but with all occurrences of and exchanged. in particular  we make use of the value a s1 si -
   the combination formulas for the means and covariances over the union of the sets of experts can be calculated  and now depends on the number of experts in the component sets  and for the log-probabilities  with a-independence  the formulas are: 


where we have suppressed the a. argument in the first equation  and p = 
   we see that a state now consists of the mean log-opinion all labels the covariance of the opinions and a weight of evidence  corresponding to the number of experts participating in those opinions. in the case of 
complete independence  1  the above formulas become simple addition of the means and covariances  as in the original hummel/landy formulation. however  with the covariance formula  there are additional mixed terms which measure the difference in the mean opinions of the experts in   and the experts in 
¡¡¡¡¡¡many other formulations are possible. for example  we can compute means and covariances of the probabilities instead of the log-probabilities. we omit the formulas here  for lack of space. we could also use only incremental evidence  so that experts in update using the means of the opinions of   while the experts in  use their actual opinions. this leads to slightly different for-
mulas. finally  as we have seen  the formulations can be posed for either the product spaces of experts  or the union set of experts: many variations are possible. 
1. discussion 
     the entire approach of tracking statistics of sets of experts has a number of features to commend it. for example  a belief function as used in the dempster/shafer theory of evidence requires the specification of 1n values  where there are n labels. if only first and second order statistics are tracked  as suggested here  then the number of values needed to specify a state is only 
 for large n  this can mean a substantial savings 
in computational effort needed to update a state. 
     further  we at least in principle have replaced the notion of subjective probabilities with objective statistics. these statistics  given sufficient resources  could be measured by  for example   polling  methods. our formulas are thus firmly based on objective probability theory  and thus foundationaly secure. of course  the assumptions are still debatable in the context of any particular application  and the value of  in the aindependence of two sets of evidence is most likely to be a subjective quantity. we expect that  in practice  information will be deemed to be  for example  1-independent  based on subjective criteria. in essence  the subjective component of combination of information has been pushed to a meta-level  where degrees of independence of information sources are estimated  instead of estimating degrees of confidence of labels in the presence of specific information. 
     the use of a collection of opinions permits a distinction between uncertainty and ignorance. a state of belief consists not of a single opinion  but of a collection of opinions. the state can be represented by a mean opinion  and a measure of the spread  or distribution  of those opinions. the spread measures a degree of uncertainty  since if all opinions are identical  there is a considerable degree of certainty in the single expressed opinion. updating is done by combining the mean opinions and combining the uncertainties. basically  the new mean opinion becomes a compromise between the two mean opinions of the composing evidence. uncertainties are likewise mixed  and generally accumulate. further  in the presence of dependencies in the information sources  uncertainty increases if the opinions from the two sources of information are divergent. 
     finally  we note that the theory makes explicit the dependence on the order in which information is combined. that is  if information s1   j1          *     are to be combined  the various a values and the outcome of the entire system will depend upon the order in which the information is mixed. the system is neither commutative nor associative  in the presence of the aindependence formulation. this may be realistic  in the sense that decisions are often based on incrementally gaining evidence  and that the interpretation and outcome depends on the order in which information is obtained. a separate expert system could be used to decide on the order in which to combine information. 
acknowledgements 
this research was supported by office of naval research 
grant n1-k-1  work unit nr 1. 	we thank 
michael landy for useful discussions. 	manevitz thanks the 
courant institute for their kind hospitality during his visit to nyu. 
