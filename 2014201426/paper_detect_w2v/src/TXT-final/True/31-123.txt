 
to what extent is distribution beneficial to the search quality and computational resources used by a genetic algorithm execution  most distributed genetic algorithms rely on communicating genetic information  in the form of individual solutions  between concurrently evolving populations. 
another way of effectively using the additional information generated by the parallel executions is the profiling approach to communication  where populations decide whether their own performance is satisfactory  relative to the global average improvement curve. thus  communication between populations takes the form of improvement histories. this is shown to improve on the traditional communication approach  in terms of both solution quality and execution performance. 
1 	introduction 
nature is essentially distributed. distributed processing permits both nature and genetic algorithms to benefit from the parallel exploration of different solutions. this concept of separate populations developing in parallel and sharing information motivates distributed genetic algorithms. this approach is best implemented on a distributed system of computers  which provides parallel processing and data sharing. these two elements comprise the essential components of a distributed genetic algorithm  dga : the core algorithm to be distributed  and the approach to sharing information between the processes. 
　this paper investigates the effect of distribution on a genetic algorithm  and  more specifically  studies the contribution of communication between concurrently executing processes to the distributed ga's performance. most approaches to communication between concurrently evolving populations involves the migration of individual solutions from one process to another. the benefit of these approaches is highly dependent on the 
   * schema - evolutionary algorithms ltd.  1a hadar st.  herzlia 
characteristics of the problem and its solution space. a new communication paradigm for dg as is described: no genetic information is migrated between populations; instead  information about the improvement rate of neighbouring populations is used to measure a population's viability. this new approach introduces new parameters  which are described and analysed for robustness. the approach is tested on two different problems  and compared against a similar dga without communication  and the basic sequential ga. 
　this paper is structured as follows: section 1 discusses the construction of the dga  and describes the sequential ga and the non-communicating dga which are used for performance and behaviour comparisons with the new dga. this section includes a short analysis of traditional dga communication  which motivates the new communication approach. section 1 introduces the profiling model of communication and describes the new parameters. section 1 describes the problems used  the platforms tested on  and presents and analyses experimental results. our conclusions are discussed in 1. 
1 	the construction of a distributed ga 
to what extent is distribution beneficial to the search quality and computational resources of a ga execution  how well does the genetic algorithm paradigm lend itself to distribution  to what extent does the specific problem influence the effectiveness of the distribution  
　the obvious questions of parallel search  muhlenbein  1  are: 
  are n parallel searches of time t as efficient as a single search of time n x t   
  are n linked searches more efficient than n independent searches  
  how should the linkage be done  
additionally  do the benefits of linkage justify its cost  
　this section describes the construction of a distributed genetic algorithm  dga  which provides the basis for answering these questions. 
the well-known ga paradigm is described in figure 1. 
maresky  etal 

produce an initial population of many individual solutions  
evaluate all individuals  
while termination condition is false: 
{ 
select fitter individuals for reproduction  
produce new individuals  
insert some of these individuals into the population  at the expense of other individuals  
re-evaluate all individuals  
} 
report on results. 
figure 	1: 	basic 	description of the genetic algorithm paradigm 
1 	t h e r e s t a r t operator 
any analysis of a ga's performance depends on both the quality of solution and execution resources used  and may be implemented by holding constant one of these variables and observing the other. the inclusion of the restart operator  maresky  1  is beneficial to this analysis. in order to continue a ga's search when the population has converged  the restart operator introduces new genetic material  typically  by completely reinitializing the population  and thus moves the ga into another solution region. this involves the obvious tradeoff between the probability of discovering sufficiently better individuals within the current area of the search space  and the use of extra resources in creating a new population and improving it to a similar level as the previous converged population. it has been shown in  takana  et a/  1  that a ga with optimal population size and the appropriate number of restarts  exhibits better performance than the same ga functioning without the restarts  and an appropriately larger population size. 
the operator operates outside the main loop of the ga 
 see figure 1  which extends the inner loop of figure 1  and is reliant on some definition of convergence. 
　the resultant ga is used as the sequential basis for a distributed genetic algorithm. 
1 a distributed genetic algorithm without communication 
there are many different approaches to parallelizing a genetic algorithm  fogarty and huang  1 . most algorithms differ on the topology of the distribution and the separate processes themselves: how they are controlled  how they communicate and what their tasks are. in particular  the island approach  tanese  1  is least reliant on processor synchrony and coordination. communication between processes is minimized by the controlling algorithm assigning separate populations to the processes  which develop in parallel and may exchange information. this exchange generally takes the form of copying individuals between the populations. 
invited speakers 
while termination condition f a l s e : 
{ 
produce population  and evaluate individuals  
while population has not converged  and termination condition is false: 
{ 
do an inner reproduction loop of figure 1  
} 
update global result  if necessary  
} 
report on results. 
figure 1: outer loop structure of the genetic algorithm with restart operator 
　this allows the construction of a dga without communication. each process is assigned a population  of the same size as that of the sequential ga. communication only occurs after the termination criterion has been met  in order to summarize the global results of the execution. this model forms a basis for the determination of the specific effects of adding different forms of communication. the resulting algorithm is shown in figure 1. 
figure 1: distributed ga  good-enough approach  with simple deme communication 
　here  each processor's results are independent of its neighbours. as the probability distribution of solution quality and function executions used during an execution is not uniform  the speedup  improvement due to distribution  is expected to be sub-linear in the number of processes used. 
1 traditional communication in distributed gas 
any improvement in the performance of the algorithm as a result of communication is beneficial  unless the cost of communication outweighs the benefits. previ-

ous island dgas communicate genetic information between the populations  mostly in the form of individual solutions  copied  migrated  either at intervals or continuously  pettey  et a/  1; starkweather  et a/  1; tanese  1 . this approach is beneficial for higly separable problems  where the good solutions from different areas of the solution space may be successfully combined. however  the algorithm's performance is highly dependent on its parameters  migrant selection policy  rate of migration  migrant insertion policy  and is less beneficial for less separable problems. 
   additionally  this form of communication suffers from conqu est  maresky  1 . populat ions evolving asynchronously in parallel are often at different levels of evolution. the arrival of highly evolved migrants from a strong population will result in their higher rate of selection than local  jess evolved individuals. thus  the sending population's solution is often imposed on that of the receiver. conversely  migrants arriving from a less evolved population are not selected for reproduction and are wasted. 
1 	the profiling model 
another way to take advantage of the parallel processing and resultant increase of available information is through the dynamic cross-checking of a process's progress. this approach does not communicate genetic information  rather information about a process's progress. as such  the profiling approach departs from the popular analogy with biological systems. 
　it has been shown that under certain circumstances  the quality of a ga execution is correlated to the steepness  or speed  of its improvement  davidor and benkiki  1; manderick  et a/  1 . that is  the more rapid the improvement  the more chance of the ga execution reaching a good result  and vice versa. the ga and  more specifically  the process  has no a-priori knowledge of the solution space of the problem  or what constitutes  good  progress. a process receiving information regarding the progress of other processes checks its own relative progress. if this is inferior  the process restarts in similar fashion to the normal restart operator. 
　a restart in this manner does not mean that a better solution would not have been found in the old search space. rather  as in the case of the restart operator  see section 1   it is less likely that the old search space would yield a better solution. the use of resources in restarting the population and bringing it to a comparable level  is probably more beneficial in producing better solutions. 
　this approach implies regular communication  unlike the traditional communication model where genetic information is migrated at any time. this communication is of profiles: strings of costs  unnormallized fitness values  forming the history of a process's progress  see figure 1 . in this example  the first cost value is stored after 1 evaluations; additional values are stored at intervals of 1 evaluations. 
profiles are sent to other random processes at regular 

figure 1: 	a profile of the execution improvement against time 
intervals; at the same intervals  profiles from other processes are received and the local population's progress is checked against the global average. the curve formed by the average process profiles exhibits properties of  optimization graphs  and  learning curves   used in other frameworks. 
　initially  an off-line model was constructed: each process's progress is checked against a static  predetermined  global progress profile  without any communication or dynamic recalculations of the curve. this off-line curve is obviously different from that of the online model  where a process's execution may be termi-
nated because of sub-average performance  changing the curve considerably. 
　it was decided to have a process's profile values carry the average improvement since the beginning of the execution  instead of since the last restart. in other words  a process's profile is not reinitialized on restart; this allows for more information to be utilized. 
while termination condition is f a l s e : 
{ 
	every 	interval evaluations: 
{ 
get  store profiles from other processes 
update  send my profile to a process 
check my progress against the global average: if unsatisfactory  restart 
} 
do an inner reproduction loop of figure 1  
	figure 1: 	dga 	with profile communication 
　the initial approach observed the local process's bestof-generation cost against the  sleeve  defined by the offline cost curve and its flanking standard deviation curves. however  this means each process communicating the standard deviations at each point as well as the profiles. it was thus decided to restart the process if its 
maresky  etal 

cost at any point was more than some constant percentage worse than that of the offline curve; the resulting algorithm is shown in figure 1  and replaces the inner loop of figure 1. 
this requires four new parameters: 
  when to begin profiling: the first few evaluations may not provide a sufficiently good indication of the future potential of the execution. 
  how often to profile: while higher granularity of profiling provides better information  this involves a tradeoff with lower communication rates. this parameter also determines the amount of profiles to store. 
  how often can the process stray outside the sleeve: once may be too easily misled by the stochastic behaviour of the execution; more may limit the effectiveness of the approach. 
  how wide is the sleeve determined by the cost curve and the upper bound percentage: a small percentage  and narrow sleeve  disadvantages some functions; similarly high percentages and wider sleeves. 
1 	results 
1 	the mosix-1 platform 
while most experimental executions were run on sun 
sparcstations  all timing results were obtained on a 
1-node intel 1-pc configuration running under the mosix operating system  barak  et al  1 . mosix is a unix based multicomputer operating system that incorporates the cpu resources of a network of workstations by supporting dynamic process migration and loadbalancing  which are transparent to the application level  for efficient utilization of the network-wide resources and balanced workload distribution. 
1 	problems 
two problems are selected for testing. one  bal-lj  is a quadratic assignment problem  and j ml is a dynamic control problem. 
　the highly inseparable quadratic assignment problem  davidor  1  involves 1 dimensional quadratic minimization  which has many applications in dynamics  though the dimensionality may vary . 
　at low dimensions  the problem may be solved using the simplex method which guarantees optimality. however  numerical problems are encountered at high dimensions which cause convergence to a local optimum and a ga approach becomes attractive. 
   each individual is coded as containing a chromosome of 1 real numbers  a total mass  moment  cost and a fitness value. the solution space size is of the order of 1. 
　the dynamic control problem is from  janikow and michalewicz  1 : 

where 
where xo is the initial state  is a state  and u 
is the solution vector. 
　we call the following problem jmv. a fixed domain of  -1  is assumed for each   with = 1 and n = 1. in similar fashion to the bal~1 problem  each individual is represented by a 1-ary vector of real numbers  a cost and a fitness value. this problem is highly separable and responds very well to traditional methods of distributed communication. 
1 	results and discussion 
in order to compare the performance of the dga to both the sequential ga and the dga without communication described in 1  the performance of the algorithm is measured in reaching some acceptably good solution. the approximate comparison is on the basis of measuring function evaluations  while the actual comparison refers to the actual time taken for execution on the mosix-1 described in 1. all results are taken over 1 executions. 
　it is clear that the more difficult the problem or the goal cost of the good-enough approach  the longer the execution and the more advantage to the dga communicating profiles. a short execution does not enable the processes to build up sufficient knowledge about the average cost improvement curve. a short execution also implies fewer process restarts as a result of this greater knowledge due to the communication of profiles. 
   additionally  the execution until the first restart is hardly affected by the communication of profiles  for two reasons. firstly  the information  or knowledge  gained is not statistically useful as not enough data has been collected: each process can have at most n cost values for each profile position  for n processes. secondly  the faster processors do not receive any useful information at all until after they restart for the first time. 

1. acceptably good solution cost 
1. optimal communication interval - no. of evaluations 
1. dga with profiling: # evaluations  std. deviation  
1. approximate % improvement over the non-communicating dga 
1. approximate speedup over the sequential ga  actual speedup  
figure 1: 	profiling results for 1 processes  1 executions  

invited speakers 

　some results are shown in figure 1. for each problem  the performance of the profiling dga is measured 

against the core sequential ga  and against the dga without communication. the comparison is on the basis of number of function evaluations needed to reach a specific solution quality  specified in the second column . the fourth column shows the contribution of the new communication to the core dga  without communication   and the last column presents approximate  in terms of function evaluations  and actual  in terms of time elapsed  speedup results over the core sequential ga. note the close correlation between the function evaluation speedup and the actual time speedup. 
　the quadratic assignment problems are most strongly responsive to the new approach  see figure 1 . while reasonably good results are obtained for a cost value of 1  a closer observation reveals that the problem is not difficult enough to provide advantage to the communication: on average  less than two restarts are needed to find a good solution. setting a harder cost  namely 1  results in significant speedups of over 1 at optimal parameter settings. 
　the new parameters introduced are particularly robust. a brief analysis of the effects of changes in the parameters on the results of the dga reveals that an early start to profiling does not overly hinder the process  while starting late  for example  after 1 evaluations  is less effective. for bal-1  acceptable results are obtained with a profiling frequency of up to 1 evaluations - equivalent to a communication probability of 1. a lower rate of communication does not provide sufficient information  while much higher rates are too expensive in terms of communication overhead. the parameter of two or three consecutive intermediate results outside of the sleeve is optimal here - one  hit  is too random  and four or more hits implies too slow a response. in terms of the width of the sleeve  a value of 1% is most effective - wider sleeves result in fewer restarts. 
   these parameter settings are not universal. different settings produced optimal results for the other problem  jml. this showed very little improvement over the noncorrimunicating dga. the problem is monotonic and does not readily benefit from having executions prematurely terminated. it conforms less to the discussed relation between speed of improvement and quality of final result. additionally  one of the main reasons behind the profiling dga's effectiveness  for the hal-1 problem  is due to the shape of the probability distribution defined by the dga without communication. here  a strong  right-sloping tail is evidence of the noncommunicating dga's tendency towards long executions which search unprofitable regios before eventually terminating. the probability distribution of the noncommunicating dga for the jm1 problem has no such tail  that is  almost all executions terminate within some bound. numerous attempts at parameter setting were tried  without success. 
   in response to the questions of section 1  the results from the dga communicating profiles  in figure 1  for the bal-1 problem  are similar to those results already presented. the sequential ga is executed  using 1  1 evaluations; the dga with profiling is executed for 1 processes  each using 1 evaluations. thus  after using the same total number of function evaluations  there is an improvement  in the best value found  over the sequential ga. this is analogous to the achieving of a superlinear speedup in the previous analyses. the improvement is slightly less than expected - this can be explained by the design of the profiling approach to communication: the additional information about the average improvement curve is present fairly early in the execution. the execution continues for 1  1 evaluations  which lessens the advantage of distribution and imposes the partial information  gathered early in the execution  on the later stages of the execution. this also results in very varied expected costs. 

figure 1: scaling effects for the dga communicating profiles  1 executions  
　the influence of a harder good-enough cost is clearly seen: the easier problem does not benefit greatly from the profiling. a dga communicating profiles on this problem returns different results depending on the goodenough cost. note also the consistent superlinear speedup on the harder problem  which improves until a specific level  where increasing the number of processes does not improve the quality of global convergence information. 
maresky etal 

   an attempt was made to combine the profiling communication with the traditional communication discussed in section 1. the results  for the bal-1 problem  improved on those of the dga with traditional communication  but were worse than those presented above. this suggests that the dga communicating genetic information benefits from restarting populations which are not providing fast improvement  while the communication of emissaries is detrimental to the dga communicating profiles. no fine-tuning of profile or emissary communication was attempted  because of the relatively poor results.note that this hybrid approach would imply greater communication overhead than the previous approaches. 
　the profiling approach is novel and inspires interesting modifications and extensions to distributed gas. for example  profiling plays a similar role to restart: both operators renew the ga search in a new area of the problem space. in both operators  the probabilistic decision is based on perceived less-than-optimal performance and is easily fooled by erratic or volatile improvement curves. it is necessary to investigate the distributed profiling approach as an alternative to the restart function  using the average profile generated by parallel executions to determine the worth of continuing an execution instead of restarting. it is also necessary to reduce the dependence on the additional parameters introduced. 
1 	conclusions 
the profiling approach to communication between the concurrently evolving populations of a dga is an alternative attempt to utilize the additional information generated by these parallel processes. this approach is motivated by the relationship between the speed of execution improvement and the execution's resulting solution quality. new parameters are introduced  many of which are robust  in the sense that varying their values does not affect the dga's performance. 
　the populations communicate their improvement history  and a process decides on its own viability according to the global average improvement curve. this learning curve is also useful in determining the optimal number of processes to use  and in setting parameters. 
   problems for which a dga with traditional communication is less effective  and consistently returns sublinear speedups  are shown to produce superlinear results using this approach. this benefit is highly dependent on the correlation between the speed of improvement and the quality of an execution. this dependence  which is influenced by the problem  the ga and its parameter settings  can be measured and may constitute an important factor in determining a priori the success of the profiling effect on a specific problem. 
　the profiling approach also provides a positive answer to the question of parallel versus sequential search quality  given a fixed execution time. 
