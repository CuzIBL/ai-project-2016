ensemble bagging boosting successfully classification ensemble construct ensemble combine classification heterogeneous data classification heterogeneous data homogeneous reliable accurate classification homogeneous examine forming homogeneous subset novel data time homogeneous ensemble learning empirical benchmark datasets datasets classification show heterogeneous data classification ensemble bagging boosting successfully many classification dietterich bauer kohavi idea ensemble construct classifier training data classify data taking vote prediction thus ensemble accurate diverse classification combine ensemble classification diverse classifier good ensemble quinlan emphasis heterogeneous data classification heterogeneous data classification refers data widely distributed mode arises training data collected heterogeneous data classification classification labeled acquired resource exhibit disparate black white colorful widely used constructing ensemble sample subset training data classification subset bagging briemann adaboost schapire singer bagging draw sample training data adaboost sample training data dynamically distribution putting misclassified classified clearly treat homogeneous data heterogeneous data differently ensemble work effectively heterogeneous data intuitive divide heterogeneous data homogeneous data classifier built homogeneous good diversity ensemble realize employ clustering hartigan wong clustering celeux govaert gaussian mixture clustering cluster membership clustering cluster membership mutually exclusive data belong cluster even clustering soft membership data resulting cluster data belongs cluster witten frank clustering data cluster subset training data formed clustering mutually disjoint cluster data lead unreliable classification data fragmentation occurred tree induction quinlan subset training data produced bagging adaboost mutually disjoint bootstrap sampling subset around training data unbalanced cluster size clustering control cluster size unbalanced cluster size resulting clustering corrected resulting cluster size classifier built cluster unreliable thus degrade ensemble forming final ensemble classification contrary bagging adaboost data sample size learning note balancing size cluster particularly spectral clustering normalized melta control cluster size come indirectly resulting cluster unbalanced size clustering homogeneous data size like bagging equally sized homogeneous need novel partitioning data homogeneous subset size ensemble learning heterogeneous data classification goal work divide heterogeneous data homogeneous subset size reliable accurate classification focusing homogeneous subset data belong subset ensuring size data subset classification built data hiss homogeneous data size specially heterogeneous data classification hiss user size subset user subset containing data bootstrap sampling procedure subset percentage training data covered cluster specified varied differs bootstrap sampling procedure data subset bootstrap sampling selects data form subset property ensemble learning classifying heterogeneous data stratum homogeneous data subset data resulting sampling work many ensemble constructing ensemble categorized five dietterich bayesian creates ensemble sampling distribution sampling training creates subset training train classifier subset sampling feature creates subset feature classifier built subset feature code ecoc convert binary injecting randomness generates ensemble classifier injecting randomness learning five work closely creates classifier sampling training bagging brieman adaboost schapire singer classification take heterogeneous data hiss construct homogeneous stratum heterogeneous data maintains nice property boostrap sampling procedure stratum data line closely work clustering clustering categorized parametric parametric find parametric minimizes cost assignment mixture celeux govaert cost minimized merging cluster dividing cluster agglomerative divisive clustering data belongs cluster ultimate goal clustering data uncertain assign data cluster assigning cluster probabilistic fuzzy clustering uncertainty cluster membership exploited process resulting cluster data cluster clustering control size cluster resulting cluster unbalanced size cluster size useless learning hiss probabilistic clustering hiss probabilistic clustering hiss idea probabilistic clustering data mixture generative optimal parameter maximizing likelihood data mixture data cluster data data data mixture likelihood data likelihood generating likelihood data cluster data belong cluster probabilistic clustering gaussian mixture parameterized cluster mean variance matrix cluster expectation maximization dempster used optimal parameter removing data belong homogeneous cluster stratum optimization subject constrained maintain probability easy optimal mean data stratum avoid trivial enforce percentage training data covered cluster predefined data stratum aroundn membership data belong stratum stratifying data belong stratum data allowed stratum simultaneously ensures stratum balanced data clustering ensures size stratum particularly goal generating reliable accurate ensemble heterogeneous data reasonably work stratum sufficiently statistical learning refer clustering hiss stand homogeneous data size optimization hiss putting subject gaussian distribution idea rithm likelihood data consecutive iteration thus optimal mean variance gaussian distribution optimal difficult optimizing equality apparently nonnegative nonnegative optimal maximizes initialization cluster probability mass optimal fletcher efficiently adjust idea reset violates adjustment recompute procedure adjusting recomputing continue violates show step optimal optimality classifying heterogeneous data classification heterogeneous data many data acquired many case training data acquired data distribution data merged heterogeneous classification outdoor scene training collected type news story advertisement high thus widely disparate merged data heterogeneous data converting binary binary classification case need data feature ecoli pendigit glass yeast vehicle datasets heterogeneous data classification convert classification binary coding ecoc dietterich process grouped subset data subset used remaining used pool comprised data heterogeneity binary intuitive classifying heterogeneous data classification classifier built homogeneous stratum data combine classifier final prediction clustering task unbalanced clustersizes data fragmentation hiss avoid parameter classify heterogeneous data hiss homogeneous stratum classification stratum form ensemble refer empirical next stacking wolpert used combine final prediction ensemble answer classifying heterogeneous data bagging adaboost classifying heterogeneous datasets hiss generating reliable address hiss probabilistic clustering training data build classification data baseline adaboost bagging ensemble bagging stacking adaboost stacking ecoli pendigit glass yeast vehicle classification baseline adaboost bagging ensemble column stacking refers case ensemble bagging combined stacking column stacking variance classification listed parenthesis seven datasets used five datasets machine learning repository blake merz binary datasets classification seven datasets listed datasets heterogeneity data converting multipleclass binary used remaining data expect degree heterogeneity inside datasets classification binary classification heterogeneity data fact seven clip clip clip type varied expect heterogeneity data baseline used vector machine burger ensemble generates svms stacking wolpert also employed combine form final prediction ensemble data training remaining testing repeated time classification used final variance classification heterogeneous data classification show classification baseline data hiss cluster cluster ecoli pendigit glass yeast vehicle classification clustering refers cluster data vector machine ensemble learning bagging adaboost baseline well comparing bagging adaboost seven heterogeneous datasets difficult ensemble learn ensemble baseline ensemble datasets substantial ensemble stacking combining used adaboost bagging address conduct stacking combine bagging adaboost listed side titled stacking stacking substantial classification stacking combine ensemble learning seven datasets ensemble hiss best stacking much diverse bagging adaboost applying classification combine distinguishable stacking able take full best ensemble classifying heterogeneous data ensemble ensemble hiss clustering hiss data stratum thus data distributed stratum size sufficiently clustering hiss classifying heterogeneous datasets observe tradeoff stratum data stratum stratum cluster clustering cluster datasets clustering unable full twenty cluster clustering used probabilistic clustering hissbased ensemble stacking used combine clustering clustering construction listed titled cluster cluster suggested cluster lead degraded cluster form cluster data insufficient reliable classification hand indicated ditterich able relatively success ensemble hiss need introducing substantial overlapping cluster outperforms ensemble substantially datasets noticeable case classification clustering ensemble ensemble learning heterogeneous data classification conclusion work examine generating ensemble data homogeneous subset subset clustering like suitable task partitioning data cluster data fragmentation address novel hiss data overlapping cluster stratum promise cluster empirical seven heterogeneous datasets well heterogeneous data classification hiss assumes size stratum cluster examine alternative balance size cluster enforcing cluster size constrain size cluster specified flexibility maintaining high homogeneity cluster
