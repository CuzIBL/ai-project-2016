linear discriminant feature extraction statistical suffers sample size dealing high dimensional data guaranteed find best gaussian density covariance matrix fail density nonparametric feature extraction stepwise nearest neighbor discriminant snnda view nearest neighbor classification snnda find discriminant density belong parametric family depend nonsingularity scatter matrix demonstrate snnda outperforms variant face datasets feret face database curse major practical limitation many text classification past many dimensionality reduction linear discriminant fukunaga supervised linear dimensionality reduction many proven powerful maximize scatter simultaneously minimizing scatter formulated fisher criterion linear transformation matrix betweenclass scatter matrix scatter matrix acknowledged major drawback suffers sample size dealing high dimensional data training sample difficult vector face system dimension training data nonsingular belhumeur chen yang address variant lose discriminative high dimensional disadvantage assumes gaussian density covariance matrix guaranteed find best distribution unimodal separated scatter mean distribution multimodal mean fails find discriminant fukunaga besides rank extracted feature unless posteriori probability feature suboptimal bayes sense optimal regard fisher criterion fukunaga feature extraction stepwise nearest neighbor discriminant snnda snnda linear feature extraction optimize nearest neighbor classification nearest neighbor classification duda nonparametric classification used classification classifier close bayes classifier nearest neighbor classification carried feature nearest neighbor away causing bias degrading rule hastie hastie tibshirani hastie tibshirani discriminant adaptive nearest neighbor dann stretch neighborhood probability much also suffers sample size snnda regarded nonparametric discriminant fukunaga mantock depend nonsingularity scatter matrix snnda find discriminant density belong parametric family rest give review variant stepwise nearest neighbor discriminant variant face give conclusion review variant maximize scatter simultaneously minimizing scatter scatter matrix scatter matrix mean vector priori probability mean vector covariance trix find vector maximizing ratio determinant argmax dimensionality data transformation transformation matrix must constituted eigenvectors ofcorresponding largest eigenvalue fukunaga sample size distribution multimodal mean sample fail find discriminant fukunaga many subsection give review aimed singularity year many noticed singularity tried overcome computational difficulty avoid singularity used belhumeur used high dimensional face data dimensional feature subspace obviously suboptimal discarding much discriminative modified fisher criterion scatter matrix denominator proven modified criterion exactly fisher criterion modified criterion reach namely transformation null thus transformation separability maximized besides need calculate inverse matrix time consuming chen chen suggested null spanned eigenvectors zero eigenvalue discriminative nlda null chooses vector maximizing zero discard discriminative outside null show null probably discriminant thus obviously suboptimal maximizes scatter null besides nlda drop significantly close dimension sample dimensionality null much lost yang dlda remove null discriminative unfortunately incorrect demonstrates optimal discriminant vector necessarily subspace spanned nlda show discriminant vector dashed line nlda discriminant show discriminant vector dashed line dlda constrained fisher criterion optimal discriminant solid line aimed limitation density multimodal separability poor case mean fails find discriminant scatter mean fukunaga rank extracted feature unless posteriori probability feature suboptimal bayes sense optimal regard fisher criterion fukunaga fact classification ultimate goal need density well near hastie fukunaga mantock fukunaga mantock nonparametric discriminant overcome limitation nonparametric discriminant scatter nonparametric scatter matrix full rank thus loosening extracted feature dimensionality also nonparametric matrix inherently lead extracted feature preserve relevant classification bressan bressan vitria explored nexus nonparametric discriminant nearest neighbor classifier gave slight modification extends nonparametric overcomes limitation depend singularity rank must stepwise nearest neighbor discriminant feature extraction stepwise nearest neighbor discriminant snnda snnda also nonparametric withinclass scatter matrix depend singularity scatter matrix improves classifier nearest neighbor discriminant criterion nearest neighbor sample fashion nearest neighbor nonparametric nonparametric scatter matrix sample control parameter zero infinity sample introduced deemphasize sample give emphasis sample near sample ratio nonparametric undesirable influence scatter matrix sample take close near classification drop zero move control parameter adjusts fast happens thatrepresents sample nearest neighbor represents sample nearest neighbor training sample nearest neighbor classification examining nonparametric intraclass zero classified classified false accurately sample classified extract feature linear matrix identity matrix projected sample xnew projected nonparametric expect find optimal make projected subspace argmax optimization find linear transform maximizes minimizing sample considering projected nnda solid dashed four artificial datasets trace matrix nonparametric scatter matrix argmaxtr call nearest neighbor discriminant criterion nnda matrix must constituted eigenvectors largest eigenvalue give nnda density unimodal nnda approximately case density multimodal mean nnda outperforms greatly stepwise dimensionality reduction nearest neighbor discriminant criterion calculate nonparametric high dimensional dimensional exactly agree nonparametric subspace orthonormal transformation case warranty preservation find matrix stepwise dimensionality reduction step nonparametric dimensionality thus keep consistency nonparametric process dimensionality reduction give stepwise nearest neighbor discriminant give dimensional sample expect find dimensional discriminant subspace find matrix step reduce dimensionality sample step meet calculate nonparametric scatter matrix dimensionality calculate matrixmatrix sample matrix final transformation matrix stepwise nearest neighbor discriminant snnda need calculate inverse matrix stable snnda optimizes classification easy extend case drawback snnda computational inefficiency neighbor data high dimensionality used reduce dimension data rank scatter matrix removing null scatter matrix snnda transformed yang yang yang show discriminant lost transformed face variant face turk pentland belhumeur nlda chen bressan vitria bayesian moghaddam repeated time independently calculated datasets robustness snnda datasets face database samaria harter feret face database phillips datasets dataset dataset face database formerly database face person person time varying lighting slightly facial facial linearly stretched full pixel show face database person partitioned training subset test training used learn test face database feret dataset dataset subset feret database subject subject lighting neutral lighting facial mostly smiling lighting mostly neutral operation manually registered normalized cropped size mask template used remove background hair histogram equalization face photometric normalization person training rest used test feret dataset dataset subset feret database feret data used face person dataset overlap training feret protocol phillips training remaining used testing testing face gallery probe feret dataset show rate feature datasets snnda outperforms rate snnda reach dataset rate snnda reached feret dataset surprisedly dimensionality sample poor dimensionality snnda suffer overfitting snnda rate dimensionality continuously show cumulative rate datasets none cumulative rate reach snnda dataset lighting feret dataset snnda also obviously dataset feret dataset label training testing ferer dataset overlap training feret protocol phillips subject training unknown subject thus feret dataset convincing robust snnda also give best feret dataset major displayed snnda stable high rate datasets unstable conclusion feature extraction stepwise nearest neighbor discriminant snnda find discriminant density belong parametric family depend nonsingularity scatter matrix datasets feret face database demonstrate snnda outperforms variant face greatly snnda accurate robust work extend snnda discriminant kernel extend snnda case
