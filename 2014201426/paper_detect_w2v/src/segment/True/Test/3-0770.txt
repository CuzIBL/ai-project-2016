well unidentifiable bayes likelihood accurate distribution huge computational cost empirical bayes part parameter regarded hyperparameters call subspace bayes theoretically analyze linear neural network show subspace bayes asymptotically positivepart type shrinkage behaves bayes case unidentifiable parametric neural network mixture wide singularity parameter learning regular statistical hold unidentifiable theoretically clarified likelihood asymptotically linear neural network proved regular dimension parameter redundant learn true distribution fukumizu hand bayes neural network linear neural network mixture proved regular watanabe aoyagi watanabe yamazaki watanabe bayes distribution seldom exactly realized markov monte carlo mcmc used distribution huge computational cost alternative variational bayes correlation parameter parameter correlation parameter hidden neglected hinton camp mackay attias ghahramani beal alternative call subspace bayes empirical bayes part parameter regarded hyperparameters regard parameter hyperparameters analytically calculate marginal likelihood threelayer consequently find hyperparameter maximizing marginal likelihood computational cost thus much distribution mcmc threelayer linear neural network type shrinkage james stein clarify also considering delicate statistical test divergence true distribution singularity comparable inverse training good bayes case neural network linear neural network briefly introduced framework bayes significance singularity delicate explained derived conclusion follow linear neural network column vector vector parameter vector neural network parametric family neural network hidden unit wheresummarizes parameter activation antisymmetric nonlinear like tanh transpose matrix vector noise subject normal distribution vector covariance matrix identity matrix distribution linear neural network activation linear simplest multilayer linear neural network parameter matrix parameter matrix transformdoes matrix parameterization trivial redundancy accordingly essential dimension parameter throughout framework learning bayes arbitrary training sample independently identically true distribution marginal likelihood distribution distribution predictive distribution distribution criterion divergence predictive distribution true distribution expectation training sample empirical bayes subspace bayes little distribution originally cope hyperparameters distribution distribution hyperparameter marginal likelihood also maximizing marginal likelihood slightly efron morris akaike steffey extending idea hyperparameters also distribution call part parameter regarded hyperparameters analyze regard parameter matrix hyperparameter marginalize likelihood parameter regard parameter matrix hyperparameter marginalize parameter unidentifiability singularity parametric unidentifiable parameter probability distribution neural network unidentifiable vice versa continuous denoting distribution singularity fisher matrix degenerate true singularity asymptotically affect prediction learning regular hold hand true singularity significantly affect extent denoting true distribution neighborhood flexibility imitating noise accelerates overfitting bayes entropy singularity distribution near true suppresses overfitting lnns former property acceleration overfitting largest matrix lnns latter property type shrinkage suppression overfitting accompanies insensitivity true amplitude ignored asymptotic true distinctly singularity also delicate divergence true distribution singularity comparable inverse training sample statistical test finite sample naturally true amplitude comparable neither smallest largest secondly affect subspace bayes hereafter distinguish hyperparameter parameter variance noise unity distribution distribution note true distribution true rank true parameter estimator parameter simplicity vector orthonormalized consequently central lead symmetric matrix matrix hereafter abbreviate largest matrix vector left vector find combining bhrq arbitrary estimator expectation distribution estimator independence make distribution localized lemma hold predictive distribution determinant matrix predictive distribution expectation distribution expand predictive distribution vector calculating expectation expanding logarithm arrive lemma comparing estimator baldi hornik find estimator asymptotically positivepart type shrinkage estimator virtue lemma substitute estimator predictive distribution asymptotically insignificant asymptotically shrinkage note variance distribution asymptotically upon prediction upon finite call degree shrinkage remember modify letting true transform arbitrary matrix orthogonal vector matrix orthogonal column vector accordingly orthogonality loss generality lemma divergence training sample contribution trace matrix ddimensional wishart distribution degree freedom scale matrix noncentrality matrix abbreviate central wishart distribution asymptotically expanded coefficient leading term coefficient indicator largest eigenvalue matrix subject pectation distribution eigenvalue estimator true estimator regular identifiability term contribution hand find redundant identifying affect estimator affect coefficient diagonalized matrix matrix decomposed orthogonal matrix diagonalized matrix matrix removing diagonal correspond true noise diagonalized matrix matrix independently subject subject redundant imitate term contribution last thus scale fashion fukumizu term analytically calculated scale infinity matrix subject eigenvalue empirical distribution eigenvalue dirac scale converges everywhere watcher calculating moment coefficient scale inverse delicate ordinary asymptotic considers amplitude true zero also hold mentioned last paragraph delicate true tiny hold replacing term regard true loss generality diagonal matrix diagonal arranged true submatrix removing column diagonalized matrix matrix subject coefficient true delicate largest vector left vector expectation distribution bayes show coefficient hidden unit horizontal axis true rank vertical axis coefficient normalized parameter dimension line correspond coefficient clarified clarified fukumizu bayes clarified aoyagi watanabe regular calculated scale also numerically calculated creating sample subject wishart distribution thus coincide hardly distinguish good bayes coefficient bayes arbitrary delicate true seem inconsistent proved superiority bayes learning true distribution suspicion cleared consideration delicate numerically calculate well delicate true distribution near singularity show coefficient hidden unit true delicate identical null horizontal axis bayes delicate previously clarified watanabe amari unfortunately lnns show coefficient solnn unit true indicated horizontal axis delicate property bayes suppression overfitting entropy singularity also delicate worse bayes show consistency superiority bayes case suppression singularity comparable sometimes stronger bayes fortunate much computational cost mcmc comparable bayes also property acceleration overfitting largest matrix subject distribution largest eigenvalue rangreater thandom matrix subject muchh eigenvalue shrinkage consequently atypical case actually coefficient case regular bayes coefficient never exceeds regular watanabe shrinkage linear estimator estimator solnn letting efron morris estimator derived unbiased estimator hyperparameter introduced estimator natural solnn transform make linear also distribution solnns paragraph bayes seem superior regardless true distribution asymptotic coefficient clue sign line corresponds coefficient regular bayes lead conjecture bayes superior watanabe amari expanding well lead conjecture well superior conjecture nakajima watanabe also find consistent proved superiority variational bayes variational bayes lnns clarified nakajima watanabe parameter subspace redundant distribution extends variance dimension parameter subspace distribution extends variance parameter hyperparameter find consequently asymptotically work work consideration nonlinearity activation expect extend conclusion introduced subspace bayes empirical bayes part parameter regarded hyperparameters derived linear neural network also clarified concluded property bayes good bayes case acknowledgment like thank reviewer gave meaningful advice motivates comment also like thank kazuo ushida masahiro nobutaka magome nikon corporation encouragement arbitrary orthogonal vector orthogonal column vector case probability maximized accordingly loss generality optimum orthogonal column vector consequently marginal likelihood well distribution factorizes substituting well derive marginal likelihood well distribution const whereis stochastic marginal likelihood const nbhrsh hereafter separately considering imitating true redundant minimize abbreviate true probability minimize leading term dominates determination cosine lead term norm term thus optimal hyperparameter distribution estimator true hand redundant find cosine term approximated substituting differentiation norm find fact diverges infinity arbitrary optimum hyperparameter thus estimator redundant selecting largest minimizes combining estimator also derive estimator exactly
