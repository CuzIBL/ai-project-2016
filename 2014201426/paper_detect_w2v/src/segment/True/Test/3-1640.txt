network formalism expressing learning grounded predictive form sutton tanner partially observable markov process efficiently learned network extend network process answer network depend history show enables network historybased network significantly previously show network learn much egocentric gridworld domain perception network formalism expressing learning grounded dynamical system sutton tanner network dynamical system vector prediction prediction probability prediction probability seeing next time step prediction time step thought answer asked network encode dynamical system vector prediction predictive littman rosencrantz predictive relatively area answering possibility limitation encouraging linear predictive linear psrs markov partially observable markov process pomdp littman showed size scale well linear compact pomdp markov network linear psrs inherit representational network successfully partially observable network expressive accurately show learning insufficient learning explore previously learned network learn review network specification examine unable learn specification network augment specification applying augmented network domain network history text instantiation network specification instructive work specification network reader work sutton tanner addressed network learning predict agent dynamical system series discrete time step agent take responds generating work network experience interested predicting next experience work partially observable sufficient statistic make optimal prediction experience uniquely identify network learn accurate maintained time network network node representing scalar prediction node interconnected link representing target relationship prediction node link asked data prediction accordingly network node network approximator prediction prediction made time step computation part network thought answer accordingly answer network show network node time next probability next node asks next node predict time desired relationship prediction also data unroll interpredictive relationship look extensive relationship data yield next probability observable markov natural network experimenter partiallyobservable network answer sufficient statistic accurately represents data discover network sufficient statistic tangental work network network like symmetric network network form symmetric tree branching label left clarity node label conditioned extraneous formally prediction node time step column vector prediction vectorvalued prediction modifiable parameter wtxt prediction corresponds answer network feature vector matrix logistic feature vector preceding node work network binary rest node additionally bias term also real valued feature complement prediction last time step learning wtij form parameter target network corresponds time counterexample experimentation network able testing success learning seem correlated work network able learn accurate deterministic walk well probability observable stochastic walk sutton tanner time discovered network unable learn accurate deterministic careful network used sufficient must somewhere network specification task network representable learnable network history four left system clockwise time network asks time step recall time calculated keep successive time step unfortunately never illustrate must look network remember specifies target answer network training incorrect feature network eventually answered anchored also note training node target target prediction grounded observable training progress agent interacts answer learned anchored grounded eventually reach distinguishes case case answer unfortunately target case cyclic dependency network temporal flow eliminates possibility network learning considering became apparent find augmentation network specification eliminate cyclic dependency dependency target node relies accurate prediction dependency eliminated feature network anchor network prediction incidentally good learned network consisting node clearly predictive node perfectly unusual network predicts approximately next time step network multiply prediction predict approximately next step predict step unfortunately stable continued training lead oscillation sort strictly predicting step network counterexample learning history left four cycled deterministically network feature final history history history history history history history history vector history predictive node left feature feature bias term next feature correspond distinct history final feature prediction time step middle vector sample vector learning prediction rightmost vector vector learning prediction accurate network history relationship experience learn relationship predict window history window history case window sufficient uniquely identify system thus able make accurate prediction incorporating history feature vector network network learn show vector time step history predictive node test hypothesis incorporating history vector network used like four size clearly illustrate effectiveness configuration history predictive node tested network previously specified history historybased network history used step size parameter best used step size network trained million time step prediction averaged final step show history network extend incorporate history line correspond network indicated numeric label well history exactly network history correspond data history history good network history also network able much shorter window illustrates combined simply history predictive leveraging history learn predictive history predictive node follow clear predictive node step history step verified history exactly predictive node history mean seen step history case network stumbling good introduced history network specification eliminate cyclic dependency learned network appeared tradeoff predictive network history clear combined superior potentially network finite history deterministic ring next next clockwise rotation rotation prediction finite history lose localization transition back forth uniquely identify refer ring indistinguishable keep subset eventually fill memory useless network never made forget network network history ring used case averaged million time step history window closely approximates seems diminish history window hampered fact history grows exponentially window predictive history predictive network time network learn history something puzzling seemed highly seemingly even ring fact inverse ring eliminates flow dependency existed ring agent incrementally learn early training agent anchor uniquely identifies time pass agent learn accurate prediction anchored also learn prediction leaving returning history ring history network history suffers diminishing size history window learning also slows considerably history grows exponentially diately process continue chaining allowed agent make accurate prediction network gridworld work network fewer final suggestive gridworld magnitude previously gridworld show chose agent perceptual indicating wall front agent also move forward rotate degree encourage reader analogous task suitable sitting button bulb told bulb turn button pressed unobservable process unobservable process learn familiar navigating around room time feel touching wall nothing sort type simplest touching wall walk forward touching wall also know consecutive degree turn started type learned gridworld used final agent triangle agent perceptual observes arrow pointing block arrow pointing open agent forward turn forward move agent arrow blocked turn rotate arrow degree environmental type harder learn history facing wall turn around degree observe wall walk forward prediction make know turning degree clear walking forward take back wall also know rotate degree time step process process remains intact nothing impossible learn fixed history exemplifies conceptual practical predictive facing wall turning degree going forward know wall turn clear turn clear forward clear predictive agent like turn turn forward network history million time step give opportunity learn causal time took control explore left show time agent agent prediction step prediction show agent learned great deal agent corner know wall left side wall behind dark represents prediction turning going forward twice turning time fact dark agent know something nearest interior blocked cell agent also predicts wall predicts gray show agent sample trajectory gridworld prediction time step agent prediction laid subjective area near agent colored correspond prediction agent agent belief observe wall going forward front triangle black agent belief clear white agent uncertain gray blocked chooses forward turn forward surely know blocked went forward white front agent belief clear forward next four step wall agent moved wall expectation seeing wall ahead moved closer left prediction wall agent moved wall note know many step wall ahead agent turned blocked agent know agent prediction reflect many inspection much gridworld agent agent know facing wall forward wall facing wall agent prediction told forward seems know changing agent know four consecutive turn leave prediction unchanged agent also seems sense rotational wall walk away rotation remembers wall navigated back network learn much perceptually deprived case agent learned rotation grounded primitive conclusion work straightforward network incorporate strength learning network learning putting combined stronger part many network deserve augmented network specification type learned network learn optimal stucture network manually expect explore work acknowledgment gratefully acknowledge idea encouragement work satinder doina precup michael littman mark ring eddie rafols vadim bulitko anna koop work part nserc icore
