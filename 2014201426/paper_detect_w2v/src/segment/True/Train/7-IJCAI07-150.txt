choosing good feature crucial success supervised machine learning good feature concentrate classification task feature constructed native feature pixel many nonlinear svms dilute classification necessitating many training hand searching even nonlinear intractable feature construction discriminative feature automatically constructed guided training domain show challenging task distinguishing handwritten chinese automatic particularly well difficult pair sensitivity feature crucial success supervised learning appropriateness feature relevance task relevance blum langley kohavi john statistical tool relevant feature hypothesis testing probe unfortunately feature construction feature subset filter almuallim dietterich kira rendell wrapper kohavi john embedded guyon predetermined feature construction operator markovitch rosenstein many training challenging domain native observable feature pixel encode mostly irrelevant statistical linear discriminant reduce dimensionality feature feature simplify task nonlinear native feature believe incorporate form gabrilovich markovitch utilizes largerepository open directoryproject natural classification address handwritten chinese derived relatively imperfect domain learning dynamically incorporating domain learning process explaining training task know pixel equally dejong used learn specialized feature kernel vector machine embody specially constructed automatically tailored learning task hand automatically discovers pixel helpful distinguishing feature kernel magnifies contribution know pixel intrinsically distinguish pixel stroke stroke distinguish telling learner relationship mean must moral inventing stroke repeated exposure pixel learning task artificially difficult system learns classifier operates native feature appreciates domain illustrated training make role explanation give illustrate feature construction chinese show concludes high feature criterion feature construction well feature retains discarding much irrelevant redundant mutual channel coding ratedistortion theoremshave battiti tishby torkkola randomvariables label feder merhav optimal bayes upperboundedby feature retains much label represents loss willing tolerate hand discarding irrelevant achieved minimizing satisfying intuitively label preserved irrelevant discarded show risk binary case regardless hypothesis used comparing alternative feature satisfying prefer smallest alternatively minimizing unfortunately probability distribution impossible accurately entropy empirically data training training simply feature nearest neighbor rule classifier empirically naive estimator believe feature resulting classifier generalize unseen sense feature hard classifier work inductive bias task feature priori feature capture reliable extract feature unlabeled constructing good feature viewed good detector feature training data detector detects feature high confidence resulting feature generalize well detector statistically many training many task domain used build explanation training used feature consistent show idea automatically construct feature informative part regard task feature construction classical explanation show label labeled derived weaker explanation identify evidence classification label training data calibrate strength evidence ideal stroke roughly sort obtains vector font stroke straight line finite width feature construction step abstractly chinese domain training association label native feature mediated domain step pixel stroke line made constrained line configuration match stroke identify feature highlevel feature form stroke confidently test stroke type dependent explanation statistically training keeping detected efficiently high confidence stroke unlabeled form frame guide high training optimize process feature feature identifies high informationimage stroke training variance stroke stroke tighter line problematic many line missed process done labeled learning phase thus know line find geometrical configuration greatly improves find stroke must classification task many feature able differentiate unnecessary next examine process chinese classifying handwritten chinese offline handwritten chinese remains challenging task variability style many structural suen former extract stroke match extracted stroke extracting stroke unreliable consequently modelmatching process problematic utilize statistic feature proven robust feature easy learning process difficult differentiate feature task distinguishing pair approachautomatically constructed feature tailored best differentiate pair chinese chinese identical leftmost radical extracting feature summarizes whole dilutes concentrated left informative identified much variability informative illustrates variability pair variability attempting absolute pixel left noisy feature risk missing stroke focused feature lost utilize long roughly vertical stroke serve stroke target accurately identified explanation graph node stroke edge relationship stroke stroke modeled line segment parameter denoting thickness need highly accurate explanation process relies structural used training parameter requisite stroke searching best parameter combinatorial graph acceptable size graph process done training graph tree employ dynamic explanation felzenszwalb huttenlocher automatically tree focusing horizontally vertically oriented stroke separately show explanation explained identifying pair graph identify stroke term process identification stroke match refer stroke show stroke detector feature extractor used step concerned line hough transform forsyth ponce performa hough transform look specified reflects variability stroke training data refer hough detector stroke reliably detected hough detector stroke dotted line stroke reliably detected explanation training used accurately hough detector detects stroke stroke empty stroke find offset thisstroke training explanation namely find smallest bounding rectangle width height hough arectangle centered width height training highest peak peak thresholddistance stroke orientation ratio percentage stroke detected specified parameter find highest detector window simplicity threshold hough optimized learning final feature stroke identified system informative relative parameter stroke informative stroke potentially informative stroke explanation know stroke training find smallest rectangle stroke overlapping stroke rectangle combined rectangle bounding stroke illustrates feature endpoint stroke receive edge target window combine mean window edge deviation stroke ideal target rectangle feature smallest none feature qualifies edge used target window illustrates target rectangle note left bottom edge stroke target window stroke parameterized offset hough detector target window parameterized parameter correspond left bottom window stroke target window form joint distribution training know explanation unlabeled hough detector localize stroke find window probability gaussian mean covariance gaussian mean covariance pair pair rate system pairwise classification difficult pair database database chinese japanese learn multiclass classifier linear discriminants identify difficult pair pair greatest confusion pair code histogram kimura feature feature best best handwritten chinese ding pair learn classifier linear vector machine observe vector machine significantly linear discriminants system classifier feature extracted target feature window detected stroke show challenging pair even robust presence irrelevant feature system managed many conclusion believe incorporate domain learning process show tailored discriminative feature constructed generative built domain particularly attractive training high domain demonstrated task classifying handwritten chinese acknowledgement upon work foundation award opinion conclusion recommendation expressed publication necessarily reflect view foundation show feature lead term rademacher case binary classification make bartlett mendelson probability distribution valued training sample drawn probability satisfies empirical risk rademacher lemma show lemma discriminative feature take rademacher concavity entropy label call training sample rademacher rademacher supposethat hypothesisspace hypothesis attains rademacher regardless label probability wrongly labeled labeled cancel rademacher discriminative feature take probability satisfies lemma discriminative feature take sufficiently rich hypothesis risk minimized minimized risk term hand side empirical risk minimized sufficiently rich minimizing equivalently minimizing term hand side minimized minimizing note meaningful practice achieved near zero suggests domain data play role construction feature eventually ideal motivates
