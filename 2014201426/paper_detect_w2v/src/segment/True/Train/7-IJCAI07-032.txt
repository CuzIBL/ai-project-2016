multiagent distributed resource allocation agent localized communication overhead optimize distribution resource dynamic learning agent accomplishing learning observe past outcome agent memory assumed must decide window investigate influence agent system distributed resource allocation namely dispersion game show dispersion game minority game agent correlated memory size agent kept unchanged explanation showing downward causation take natural involving distributed resource allocation modeled dispersion game agent prefer agent stock load balancing network iterated game learning decisionmaking process agent learn agent task agent system unknown agent indistinguishable idea behind agent yield best case joint agent outcome computational cost analyzing outcome much analyzing outcome produced agent importantly cost depend agent computation feasible even repeated dispersion game agent learn series past outcome natural window agent memory assumed paucity explanation established tackle specialized dispersion game minority game finite agent decide also finite smallest agent rewarded game repeated agent chance learn round considering finite window past outcome finite memory learn temporal contribution twofold systematically simulate case composed agent memory size fixed agent fixed memory size learning show clear access agent unveiling case translates gain case harmful relate system explanation show size outcome match system memory size thus agent memory size remainder follow discussing relevant work terminology next learning analyze work work focused relating homogeneous memory size system little memory size agent homogeneous agent assumed emphasis system dynamic agent argued agenda learning asks best learning fixed agent game construction agent follow little work directed concerned agent genetic agent outperform little investigation happens done learning homogeneous agent assumed property heterogeneous memory size studied evolutionary used best memory size game agent agent evolve independently used concern memory size alternative explanation stated agent memory agent nonetheless varying agent endowed extra memory show memory lead multiagent market minority game initially econophysics formalization farol main type interacting rational agent agent round agent must concurrently communication round made outcome calculated agent round agent wealth distributed sign sign used zero encodes minority agent rewarded majority penalized equilibrium agent profit expectation majority frustrated game many believe minority actually majority spite simplicity rich decentralized resource allocation financial market traffic commuter belong broader dispersion game main concern game agent winning game viewpoint system whole interested maximizing winner resource distributed originally introduced agent modeled inductive learning make simplified actually made widely used studied make straightforward refer learning agent access last outcome game hypothesis fixed hypothesis hypothesis past outcome next round memory size game hypothesis effectively binary learning keep effectiveness hypothesis held agent time aisign virtual agent hypothesis virtual argmaxjfi commit next round game broken coin toss learning agent unable explore outside overcome limitation learning learning agent hypothesis size memory size observe agent part agent homogeneous agent control agent sample hypothesis agent differing size hypothesis size agent memory size control work investigates fashion memory size systematically modified size observe resulting control agent hypothesis size varies also want wealth wealth agent control agent gain initialized game statistically tested significance confidence game round used literature parameter namely control agent gain lighter shade gain made evolutionary learning learning learning control agent agent show control agent gain seem adequate exponential hypothesis agent make experimentation memory intractable resulting topography observe unit gain hand observe fall unit showing target agent worse hypothesis unit gain exactly unitary observe happens sectioning topography case take control agent benefit hypothesis interestingly seem harm agent also observe transition case sharp gain logarithmic decrease wealth highest gain precisely spike case observe logarithmic drop decrease gain thus unit interestingly access window harmful agent loss access control agent gain solid line dashed line agent learning control agent gain varying harmful agent memory size observe phenomenon plot control agent gain varies made clear memory size agent observe gain high unit reaching converge slightly unit worse accessing seem argue hypothesis make good hypothesis harder even part explanation observe relationship gain hypothesis size investigate evolutionary learning argued peculiar learning used main limitation inability explore hypothesis game agent hypothesis address concern repeated learning agent explore hypothesis chose simplicity good hypothesis foreach fitness game window size past outcome fitness commit outcome foreach outcome fitness fitness else fitness fitness probability worst hypothesis best hypothesis probability flip evolutionary learning elaborated used game closely presenting learning able depicted agent hypothesis round probability discard worst hypothesis replaces copy best copy flipped probability agent hypothesis continually introducing game note differently evolutionary learning ordering agent agent retain autonomous relying central decide hypothesis agent replaced thus distributed game show agent learning clearly learning taking decrease oscillation even long round observe steady system show control agent gain agent learning observe case memory beneficial extra memory size harmful target agent logarithmic decrease tested agent control agent gain lighter shade gain learning considerable loss gain analyzing dynamic game stated main concern many agent winning game measuring temporal resource distribution mean statistical variance variance waste resource system variance agent game homogeneous memory size keep agent fixed control unitary memory size agent show agent learning plot high variance thus characterize system system precisely variance agent deciding case game correlated variance last case main subject agent able target agent gain solid line dashed line evolutionary learning comparing plotted gain observe unit gain high variance gain unit variance gain follow variance correlation system exploitation possibility agent memory beneficial system behaving inefficiently worse memory harmful evolutionary also observe variance curve smooth transition variance inefficient expect analogous reasoning agent agent actually relate system whole exploitation possibility mean memory existence stability system take evolutionary game agent memory allowed decrease memory size expect incentive memory leading system incentive stop system reach memory harmful thus stability conducted memory growth halting predicted memory size attributed game distinctive explanation relating agent gain system case downward causation game dynamic initially fixed agent dynamic fixing profitable agent mutual homogeneous memory size learning used show agent memory size solid line evolutionary dashed line probability probability binary inefficient actually informationally sense exactly agent memory size hand asymmetry probability distribution predictive focused case agent memory size peer wish access represents target agent memory size precise asymmetry distribution predictive hypothesis mutual outcome computing contained probability occurring probability occurring zero probability observing highest highest asymmetry probability indicating existence hypothesis predictive round recording outcome resulting binary mutual averaged hypothesis agent learning show observe remains close zero memory size explains agent memory gain observe substantial solid line dashed line learning lead logarithmic decrease accord target agent gain evidence agent creating memory size mutual plot also closely target agent gain plot highest precisely case highest followed logarithmic fall fall take highest hypothesis informative hypothesis previously spread hypothesis hypothesis detects hypothesis actually happening mutual good explanation target agent gain memory size worth observing case learning agent memory size inferred target agent exploitation possibility conclusion game round agent central dispersion game mean extensive simulation analyzed emerging resulting agent relating possibility exploitation access actually harmful learning memory size agent memory system gain agent gain also mutual outcome history showing agent system size memory size exploited agent memory hand make sparser resulting decreasing agent memory optimal size lead emergent multiagent learning informationtheoretic help choosing best memory size agent play well memory necessarily collective showed also true agent contributes construction take system deciding hypothesis acknowledgment work partly cnpq cape
