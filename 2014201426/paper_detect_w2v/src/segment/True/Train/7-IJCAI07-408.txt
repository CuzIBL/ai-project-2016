agent construct plan obey resource resource consumption characterized probability distribution time battery planning modeled continuous markov process mdps inefficient resulting novel solves planning approximating desired probability distribution resource consumption phasetype distribution exponential distribution block iteration resulting mdps exploiting property exponential distribution calculate convolution accurately efficiently resulting feasibility rover domain demonstrates substantial lazy leading continuous mdps robotics made aerial underwater terrestrial unmanned autonomous vehicle many domain unmanned vehicle constructed vehicle construct plan obey resource resource consumption characterized probability distribution time battery major construct good plan domain efficiently bresina resulting planning process younes simmons consume resource resource markov process mdps encoding resource resulting continuous approximately discretizing discretizing probability distribution applying dynamic iteration boyan littman major drawback discretizing combinatorial explosion discretization response resulting lagoudakis parr nikovski brand hauskrecht kveton lazy littman leading continuous mdps solves planning approximating probability distribution resource consumption piecewise iteration resulting mdps repeatedly approximating piecewise lazy runtime piecewise probability distribution closely need reapproximated iteration thus continuous mdps probability distribution novel solves planning approximating probability distribution resource consumption distribution exponential distribution block neuts iteration resulting mdps exploiting property exponential distribution calculate iteration accurately reapproximations efficiently lazy resulting substantially lazy feasibility rover domain planning time resource planning studied rover domain littman modeled mdps uncertainty duration outcome finite finite agent time unit away stop interrupted duration distributed probability distribution depend mean reached stop probability agent obtains transition repeat process beginning agent maximize stop rover domain used bresina planning rover maximize correspond rover site site site base rover deterministic outcome outside base move next site collect rock probe receives collecting rock probe site also move back base communication task drain thus make impossible rover receives communication task duration characterized exponential distribution also case duration characterized weibull normal distribution rover domain discrete discretizes time unit encodes planning encoding resulting continuous iteration boyan littman largest agent stop agent maximize explained incurs duration probability transition statewith probability obtains iteration calculates bellman iteration statesit hold thats nately iteration stated infinite iteration remedy viewing koenig make contribution show many iteration iteration stop show exactly vector real show bellman efficiently transform vector vector contribution step step approximates probability distribution duration exponential distribution resulting exponential distribution potentially neuts uniformization creates make identical changing stochastic process give step neuts younes simmons show deterministic outcome duration characterized normal distribution approximated distribution transformation normal distribution exponential distribution duration outcome probability phase uniformized yield exponential distribution loss generality duration distributed exponential distribution iteration finite iteration uniformized mdps show iteration stop iteration time step negligible analytic time step consideration next parameter refer breakpoints gamma simplification actually linear euler incomplete gamma piecewise gamma gamma vector piecewise gamma vector vector show rover domain four gamma step iteration thus piecewise gamma show induction piecewise gamma piecewise gamma also show bellman efficiently transform vector vector iteration calculates break four calculate induction piecewise gamma calculates lating calculate convolution show induction hold hold also hold lemma show gamma convert vector lemma integration transform vector consequently calculate breakpoints changing afterwards calculate breakpoints introduces breakpoints changing introduces dominance breakpoints intersection dominates breakpoints afterwards summarize piecewise gamma vector transformed automatically vector vector linearly iteration breakpoints automatically transformation exponentially practice stay merge iteration iteration reduce breakpoints transformation vector manipulation determines dominance breakpoints approximately bisection show experimentally transformation accurate feasibility rover domain lazy littman leading continuous mdps plot maxvalue vstart calculated runtime millisecond scale induction empirical lazy tightness lazy trade runtime planning horizon calculated rover domain duration rover domain distributed exponentially thus phasetype phase introduced approximating probability distribution duration distribution also distribution uniformization iteration finite iteration varied bisection determines dominance breakpoints lazy piecewise probability distribution duration show lazy magnitude lazy optimal corresponds rover domain lazy trade runtime duration rover domain characterized weibull distribution weibull normal distribution thus need fixed bisection varied phase used probability distribution show lazy magnitude five phase lazy optimal weibull distribution converged much planning horizon calculated suggests conclusion planning resource modeled continuous mdps despite continuous mdps inefficient littman resulting lagoudakis parr avoids shortcoming establish sound framework feasibility demonstrate work property analyze extend thoroughly domain domain extend handle resource handle replenishable resource lazy able reduce breakpoints
