multiagent form social learning teaching imitation transfer learner reinforcement learning recast imitation bayesian framework bayesian imitation learner smoothly pool data inferred agent integrates well bayesian exploration readily reinforcement learning flexible computationally challenging paradigm demonstrating sample reinforcement learning kearns tempered sober fact exponential defining learning interacting autonomous agent reinforcement learning increasingly multiagent task learning littman wellman examine reinforcement learning agent merely arbitrary actor actor like agent radically optimal learning agent like give learning agent relate imitation demiris hayes mataric learning watching kuniyoshi teaching demonstration atkeson schaal behavioral cloning sammut inverse forcement learning russell learning agent intuitive appeal explicit communication ities agent considerable infrastructure craig boutilier toronto toronto canada cebly toronto communication channel sufficiently expressive transformation possibly agent body incentive communicate dynamic competitive domain trading unrealistic expect agent compatible altruistic intention learning agent observes outward agent reduce need explicit communication implicit communication passive implicit imitation price boutilier agent agent control signal observable exploration part observer used adapt implicit agent learning agent need classic imitation learner duplicate agent recast implicit imitation bayesian framework principled elegant smooth pooling agent belief experience agent eliminates need tuning parameter imitation integrates well exploration bayesian exploration bayesian imitation readily partiallyobservable domain derivation considerably reported background reinforcement learning agent learning control markov process finite dynamic dynamic refers transition distribution subscripted distinguish agent throughout agent know dynamic thus adopt automatic perspective maximizing discounted infinite horizon used learn optimal multiagent system observer maintains experience suitable vals exactly approximately prioritized sweeping moore atkeson learning dynamic bayesian agent incorporate explore optimally employ density dynamic data letting history observer history used turn dearden render tractable convenient density transition distribution density dirichlet parameter parameter successor dirichlet straightforward data vector transition parameter thus factored family subset history composed transition dirichlet parameter bayesian natural incorporation transition parameter optimal bayesian exploration take structural dearden bayesian imitation multiagent agent used belief experience agent enormous agent part visited used bias exploration promising thereby reduce exploration cost convergence dramatically flexibility bayesian lead elegant principled incorporating agent price boutilier agent knowledgeable mentor naive observer acting simultaneously independently fixed like observer mentor controlling dynamic dynamic identical agent analogical mapping agent task multiagent system dependency evidence nehaniv dautenhahn full observability mentor observer identify simply observes transition make regarding mentor dynamic mentor stationary induces markov mentor distribution latter homogeneous observer duplicate mentor consequence treat dynamic agent note learner know priori duplicate mentor observer want duplicate agent learner observe mentor transition form mentor markov transition probability price boutilier used augment normal bellman backup treating distribution observer imitator augmented backup mentor learn much quickly mentor part overlap observer like kaelbling used suppress augmented backup confidence bayesian observer incorporates mentor augmented history mentor transition learner represents observer history illustrates imitator constrain belief probabilistic dependence observer know history mentor best weak mentor learner belief joint homogeneous relaxed price boutilier observer hypothesizes violation repaired roughly duplicate subsequence mentor repair observer discard mentor influence factored dirichlet form mentor influence learner maintain factored form updating independently tunately complication arise unobservability mentor show factored convenient term derive factored describing dynamic considering case case mentor unknown case mentor history employ bayesian regard mentor case mentor fact observer mentor relevant parameter vector observer transition mentor transition augmented density dirichlet parameter simply observer mentor observer know mentor expectation case factored usual conjugate form mentor distributed probability mentor chooses calculate mentor factored rule incorporating evidence mentor bayesian agent tackle last updating belief mentor mentor factored assumes observer mentor heterogeneous case term none distribution factored well history relevant computing difficulty evaluating integral dearden tackle sampling quantity sample factored dirichlet combine probability mentor likelihood tractable updating observer belief dynamic experience bayesian imitator thus proceeds observes transition mentor density used agent selects suitable repeat like agent imitator suitable exploration bayesian exploration dearden uncertainty captured dirichlet used distribution used optimal exploration computationally demanding captured training much heuristic bayesian exploration also eliminates parameter tuning like adapts locally instantly evidence fact make good combine imitation empirically characterize applicability benefit bayesian imitation domain literature domain bayesian imitation imitation price boutilier bayesian exploration prioritized sweeping bellman backup also investigate bayesian exploration combine imitation agent used oracle employ fixed optimized domain sampling need resampled time step scaling used prevent underflow term distribution little repaired efficiently prioritized sweeping fact bayesian learner cheaper full bellman backup multiagent system baseline observer egbs agent combine greedy exploration full bellman backup sweep time step generic modelbased learning egps agent agent exploration prioritized sweeping egps fewer backup applies predicted good egps fixed backup propagate step egbs agent employ bayesian exploration prioritized sweeping backup bebi combine bayesian exploration bayesian imitation egbi combine exploration bayesian imitation flagworld domain agent combine exploration bayesian imitation agent agent interact agent achieves goal reset beginning agent continue unaffected agent fixed step spread varying domain agent locally probability resulting neighbouring grid neighbour imitator observe oracle agent concurrently exploration reported collected last step sliding window integrates agent agent step integration window empty causing oracle plot jump zero optimal step bayesian agent sampled mdps estimating distribution sample estimating mentor dirichlet distribution exploration rate agent tuned experfigure flag imental domain test agent loop show benefit bayesian exploration dearden imitation agent identically optimal oracle agent separation seen amongst imitator challenging flagworld domain dearden meaningful amongst agent flagworld agent goal agent pick flag visiting upon reaching goal agent receives flag collected succeeds probability clear probability move agent perpendicular desired show collected preceding step agent oracle demonstrates optimal bayesian imitator bayesian exploration bebi achieves quickest convergence optimal bayesian flag moved goal imitator egbi next able locally well bebi imitator unassisted agent early fails multiagent system find optimal domain slower exploration rate decay agent find optimal also hurt early bayesian explorer fare poorly bayesian imitator outperforms remaining agent connectivity main agent show poor high exploration rate converge eventually bayesian imitation make best agent particularly combined bayesian exploration altered flag domain mentor learner goal oracle remained learner goal show transfer imitation qualitatively case identical imitation transfer robust modest mentor imitator readily explained tutoring domain fact mentor domain employed observer goal tutoring domain agent schedule presentation learner minimize training time simplify agent teach simulated student student modeled discretely approximated exponential forgetting curve agent agent receives student forgetting rate predefined threshold presenting forgetting rate leaving unpresented forgetting rate serve realistic cognitive student qualitatively tackle note grows linearly exponentially domain tation student egbs left fare poorly imitator learn quickly bayesian imitator bebi egbi outperforming egnbi converges suboptimal generic bayesian agent also chooses suboptimal agent prevent adequate exploration thus imitation mitigates drawback bayesian exploration mentor used overcome misleading also bayesian imitation also practical factored next domain insight bayesian imitation bayesian exploration grid agent move south column domain optimal oracle agent proceeds south bottom corner east goal bayesian explorer chooses path belief agent south exploration egnbi find optimal depresses term multiagent system guided long tube retrace step domain clearly differentiate early imitation agent bebi bayesian explorer learner constructed learner belief connectivity grid lead many lead dead costly misdirection exploration poor bayesian imitator bebi adapt mentor quickly agent generic exploration like mentor used great overcome misleading conclusion bayesian imitation like implicit imitation accelerates reinforcement learning presence agent relevant requiring explicit communication cooperation agent bayesian built elegant pooling optimally combine imitator experience derived agent bayesian imitation bayesian exploration eliminates parameter tuning yield agent rapidly mentor reduce exploration exploitation imitation overcomes drawback bayesian exploration possibility converging suboptimal misleading bayesian imitation mentor derivation also partially observable bayesian difficult reasonable tractable promising area benefit bayesian imitation obvious need extend heterogeneous incorporating feasibility testing repair price boutilier particularly excited prospect richer environmental also derived bayesian domain continuous hope extend work discovering correspondence agent also plan consideration imitation agent learn interacting task rewardoriented well reveals acknowledgement natural council iris multiagent system
