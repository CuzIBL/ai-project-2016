concerned modeling planning involving uncertainty stochastic automaton planning computing markov process classical markov process cope size encountered practice allernative investigate decompose planning separately combine solu tion decompose planning arbitrary markov process restricted subset relies constructing cision itcratively approximates parameter converge optimal show property specified affect time storage ihese concerned planning posed markov process spec lfically dynamical stochastic process markov discrete criterion minimize time cost reach goal construct plan mapping realizes specified criterion approximates specified tolerance work force vanced agency tense foundation agency ontract view dimensional spnce view representh unstructured stale middle view bottom view represents partitioning stales aggregate factoring cnallenges efficiently encoded factored system npact encoding stochastic professes achieved many size logarithmic size dean kanazawa faetored efficiently encoded tree branch tiher stochastic process encoded compact form like lime size representing fluents strip opualors fikes nilsson correspond factored dean dimensionality reduction subspace shaded dark grav factored boolean represents relevant stale dimensionality suffering statt relevant planning take walk southern florida neglect possibility snow lllustratis thru viws bottom view winch partitioned aggregate view interested dimensionality reduction domain partitioned subset size relevant word concerned subspace size size subspace automatically constructing addressed dean relevant twodimensiona subspace computing size papadimitriou tsitsiklis puterman impractical considering whole interested deal subspace combining framework case divide conquer markov process reformulate term markov process ubproblenib combine best case subproblems trivial manufacturing task assembling testing assembled independently case matter enter leave matter cost accrued case subproblems weakly coupled affect neighboring system staged manufacturing military planning robot navigation task associate topologically motivated param eters parameter summarize parameter construct markov process subspace markov process subproblem combining subproblems illustrated hierarchical construction considers parameter intuitive topological rameter give construct markov process considering markov process assigns thus yielding hierarchical construction optimal case relatively efficiently intuitive make particularly suitable robot navigation domain combining erative optimal parameter optimal iteration parameter resulting markov process examining resulting eies parameter guaranteed also tell optimal specified tolerance terminate procedure brief markov process describee parameter modeling construction markov process parameter hierarchical construction construction process process process construct process illustrates briefly address concerning convergence optimally dean dean ciated repository improves iteration verge optimal finite step proportion dean analyse reformulating term linear applying reduction kushner chen linear markov process briefly convergence rate time empirical experience suggests upon converges optimum fairly quickly tail convergence rate slow page bazaraa word iteration able good worthwhile continue reaching optimum computational task iteration subtasks deriving process subproblems maintaining repository previously periphery computational cost iteration critically affected coupling ompared process whole subtask achieved efficiently applying markov process natural trchniques divide suliprohlems traclable size subtask achieved maintaining matrix computational critically topology partilion subtask efficiently size relatively cost need combine subproblems word promising evenly divide whole many periphery also necessarily converge optimal intuitive computational testing benchmark lengthy howard iteration howard bellman iteration bellman markov process refer interested reader dean work work extensive area planning deterministic work macro operator horf hierarchy operator sacerdoti knoblock losely work decomposing discrete system modeled deterministic finite machine zhong wonham caines wang area reinforcement learning work deterministic continuous moore atkeson stochastic discrete kaelbling hierarcl ncal construction alternative kaelbling hierarchical learning kaelbling suggests moore atkeson handle discrete hinted thih borrows heavily work operation combinatorial optimization representing markov process epenoux erman rush kleinman decomposing teint dantzig wolfe lasdon markov process kushner chen dean dean represents case framework singleton envelope complement envelope conclusion benefit able deal subproblems size tradeoff extra combine subproblems leverage thogonal used case size valuable even avail able markov process arbitrary subproblems correspond markov process parameter combining subproblems hierarchical construction hierarchical construction quick intuitive guaranteed converge optimal finite iteration practical iteration suffi near optimal acknowledgement thank raig bontiher moises goldszinidt steve hank david smith mike williamson ments presentation idea
