goal transfer learning acquired task previously unseen target task multilayered architecturenamed reinforcement learner carl novel reasoning reinforcement learning transfer playing game madrtstm real time game demonstrate carl well task also exhibit gain allowed transfer task transfer learning transferring experience circumstance focused learn task interpolate extrapolate unseen task growing come transfer learning transfer learning like task seeing task transfer learning agent able show gain learning task imagine learning play checker learn play chess unseen game taxonomy transfer learning darpa eleven ranging simplest type transfer memorization form transfer differing transfer term reorganization scale note emphasize type transfer applies semantic five transfer achieving transfer learning real time game contribution novel architecture case reinforcement learner carl capture strategic tactical domain leverage modular transfer learning novel reasoning reinforcement learning approximator revision next briefly motivate game domain transfer learning demonstrating validity work ending recommendation real time game game family game player competing real time goal kill player game dominate territory game game game synthetic domain exhibit superior game characterized enormous asynchronous game also reasoning granularity expressed resource technological tactical skill combatconfrontation game even used military training system transfer memorization identical previously encountered training rapidly learning occurred parameterization identical memorization parameter quantitative qualitatively extrapolating identical memorization parameter qualitatively arise restructuring configuration previously encountered training extending encountered training transfer learning taxonomy eleven task left target task exhibiting transfer learning simpler demonstrates scale characterizes extending territory troop five task five eleven target qualitatively tactical game used madrtstm game military simulation show task left target task achieving transfer extending madrts much troop territory particularly interested applying transfer learning game architecture suited architecture learn strategic tactical architecture well reasoning reinforcement learning system architecture reinforcement learner carl realized architecture spirit architecture albus concerned ever finer distinction tactic granularity time scale reduces treated goal conceptually identical module planner make controller reactive module interface learner modifies used planner situ splitting merging updating feature strategic middle tactical reasoner reinforcement learner make tactical attack explore retreat conquer nearest territory lowest incorporates reactive planner scripted task predefined madrtstm responds task delegated tactical goal reactive planner feature avghealth agent troop alive agent alive troop percentage strength opponent troop killed percentage strength territory owned agent percentage territory owned opponent percentage feature representing game tactical carl time territory owned agent opponent neither playing side side owns territory sends troop territory leaf behind fixed troop patrolling transfer learning architecture carl architecture conceptually planner learner controller instantiated upon need reinforcement learning reinforcement learning natural interactive agent decisionmaking agent interacting uncertain modeled markov process mdps framework time step agent sens chooses agent perhaps uncontrolled stochastic agent receives possibly zero scalar agent goal optimal chooses maximize time horizon many learning good optimal agent experience high experience learn qvalues pair maximal achieved stateaction pair learned used stochastically probability many algorithmsuse formof stateaction feature distribution sutton barto extensive reasoning tackling unseen past experience kolodner leake formalized process retrieve reuse revise retain aamodt plaza view work lazy learning temporal assignment case case must utility case tuple four vector composed feature representing game system experienced list agent take architecture utility vector utility eligibility real reflecting cumulative contribution case time step eligibility used revision note agent need case suggestion carrying case enumerates feature used reported feature temporal side game note feature numeric case retrieval feature numeric euclidean case queried euclidean case queried smoothing parameter gaussian kernel determines relative contribution case utility queried utility retrieved case reuse planner chooses highest utility probability encourage exploration decrease monotonically game trial made planner trial passed goal noted lowest scripted reactive planner command series primitive affect madrts game engine tactic explore planner find subset idle troop instruct exploratory game engine revision revision phase utility agent temporal sutton ensures incorporated case utility agent time eligibility trace utility discount rate achieved linear temporal feature eligibility cumulative contribution time step factoring exploration final eligibility increased case combined form help utility case past contribution remainder case receive scaling eligibility retention case case closest neighbor dmin threshold parameter thus smoothing parameter controlling density case memory transfer learning agent madrtstmgame domain examining hypothesis agent well learning task madrts also able learn task transferring experience quantify learning done agent task game linear five feature remaining agent troop time elapsed trial enemy troop killed agent troop alive territory owned agent percentage respective strength learning curve representing agent acting target task transfer learning curve representing agent transferring task transfer learning jump mean data trial mean data asymptotic gain mean last data trial mean data gain mean data trial mean data fact parameter transfer curve gain transfer jump vastly transfer carried tile territory conquer nine troop fighting side exhibit transfer learning target consisted numberof territory enemy troop testing transfer learning mirroring ownership territory moving target part difficulty agent troop adjacent territory army target task territory separated coupled geographical obstruction force agent tactic force battalion troop army trial terminates agent troop dead opponent troop dead remaining agent troop conquered territory strength conquering territory requiresthat troop need reach territory kill opponent troop leave behind troop transfer learning respective learning curve five iteration agent target target transfer smooth fitting curve discount rate temporal exploration utility nearest neighbor task dependent smoothing parameter maintained density parameter enabling case contribute time ensuring domain covered fewer case analyze agent averaging five iteration task hundred trial worst case time trial curve agent completed game trial learning target learning learning target learning clarity also show line smooth curve show continual appearing vertical axis agent trial game target task avghealth timeelapsed quantity time scale game task guaranteed take time unit best anyone agent agent player trial show jump much summarizes rank test configure transfer learning jump asymptotic gain gain transfer learning statistically confidence fidence gain transfer learning resultant verified confidence asymptotic gain suggesting curve converged show jump transfer learning agent learns attack tactic gave agent valuable well even increased enemy troop target reusing conquering nearest territory tactic case worked well despite territory case agent benefit learned explore tactic proved player troop geographically separated battalion acting learning agent take trial discover exploration tactic unite force work transfer learning task hierarchy mehta transfer family variablereward markov process mdps learning demonstrated discretized game rosenstein investigate transfer attempted target task sufficiently best reasoning address transfer learning also used domain involving santamaria robot navigation gabel riedmiller robot soccer santamaria casebased approximatorto learn generalize longterm agent continuous decomposes task tactical applies tactical system defeat dynamic opponent lattice system capable transfer learning varying domain achieving transfer learning reasoning reinforcement learning architecture carl task agent learn tactical reused thereby accomplishing transfer learning demonstrate transfer learning continuous real time game real game testbed agent transfer learning speeding learning also lead final plan extend architecture replacing lowest module learns pass next middle strategic nontrivial reasoning tactic also expanded imagine feature used system learn time feature signify troop strength strategically goal also like refine approximator benefit mahalanobis indexing scheme case like task requiring form transfer target task recognized reformulated wellspecified transformation carl need discover acknowledgement like thank santi ontan valuable feedback ijcai reviewer suggestion acknowledge darpa also thank navy laboratory interface tielt used carl game well game maddoc madrtstm
