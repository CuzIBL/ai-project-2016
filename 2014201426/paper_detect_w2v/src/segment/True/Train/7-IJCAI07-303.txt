growing intelligent assistant organizing task helping dementia framework capture assistance observe agent assistive minimize cost assistant pomdp hidden corresponds agent unobserved goal domain estimating agent goal selecting assistive naturally handle uncertainty varying cost customization agent learning argue many domain myopic heuristic adequate selecting assistant pomdp heuristic domain subject task show assistant substantially reduces user modest computational intelligent assistant tremendous many domain used domain assistive disabled boger work calo work domain comprehensive framework intelligent assistant assistant observes goaloriented agent must assistive best help agent goal well assistant must able accurately quickly infer goal agent utility assistive toward achieving goal real assistant able handle uncertainty agent varying cost handle unforeseen adapt agent time partially observable markov process pomdps naturally handle feature formal intelligent assistant contribution work formulate selecting assistive assistant pomdp jointly agent hidden goal feature agent flexibility assisting unforeseen intractable must rely contribution suggest argue well suited assistant pomdp many domain explicit goal myopic heuristic goal bootstrapping usability assistant early lifetime myopic heuristic derived assistant mdps simulation rollout contribution framework novel subject assistant framework able significantly decrease user myopic heuristic well computationally intensive sparse sampling remainder next formal followed assistant pomdp next goal give empirical domain work refer entity attempting assist agent agent markov process tuple finite finite agent finite assistant transition distribution represents probability transitioning sometimes distributed assistant noop leaf unchanged distribution episodic beginning episode agent drawn selects goal finite goal goal dish agent left unassisted agent execute arrives goal upon episode assistant able observe changing agent unable observe agent goal agent trajectory assistant allowed execute ending noop agent performan episode agent assistant lead goal cost episode cost agent assistant episode note agent assistant need varying cost minimize cost episode formally agent unknown stochastic give probability selecting agent goal assistant stochastic give probability selecting trajectory beginning trajectory assistant depend serve evidence agent goal selecting good assistive agent assistant cost episode goal evolve process execute assistant noop execute agent achieved terminate else step work disposal goal assistant minimizes cost unknown distribution agent goal unknown agent simplicity assumed observable environmentand episodicsetting framework assistant pomdp pomdps framework partially observable stochastic pomdp tuple finite transition distribution cost distribution finite distribution pomdp assigns distribution preceding view pomdp infinite belief belief simply distribution case pomdp viewed mapping belief serve decrease uncertainty make progress toward goal pomdp address main selecting assistive infer agent goal good assistance capture goal uncertainty agent goal hidden pomdp belief correspond distribution agent goal even know agent goal must uncertain agent cost best pomdp capture transition cost reasoning goal distribution agent assistantpomdp pair agent goal distribution assigns probability process selecting goal agent beginning episode assistant reflecting assistant pomdp used transition assigns zero probability transition goal assistant agent goal noop transition probability noop simulates agent noop probability cost reflects cost agent assistant noop noop distributed cost noop cost ensuing agent distribution deterministic reflects fact assistant observe agent noop leading agent noop simplicity assumed encodes preceding agent assistant thus reflect episodic episode drawing pomdp arriving satisfies goal assistant pomdp assistant cost trajectory thus optimal assistant pomdp yield optimal assistant assistant pomdp disposal goal next assistant pomdp estimating assistive selecting assistive approximating assistant pomdp approximating assistant pomdp observe agent acting possibly assisted learn goal distribution done storing goal achieved episode pair agent episode frequency goal perhaps laplace correction likewise simply frequency agent goal converge yield true assistant pomdp practice convergencecan slow slow convergencecan lead poor early assistant lifetime alleviate bootstrap learning agent reasonably close optimal unrealistic many domain benefit intelligent assistant many task conceptually substantial agent biased toward optimal agent assistant removed give cost agent acting optimally goal agent agent boltzmann distribution good proxy agent assistant reflect peculiarity agent computationally main obstacle computing need done domain accomplish factored boutilier boutilier guestrin developing specialized beginning trajectory time previously assistant agent assistant pomdp goal best assistive unfortunately exactly assistant pomdp intractable simplest domain take heuristic motivate assistant pomdp importantly belief corresponds distribution agent goal agent assumed goal directed agent substantial evidence goal fact even assistant nothing agent goal rapidly revealed suggests assistant pomdp effectively observing agent relate goal also suggests many domain little selecting assistive gathering agent goal suggests effectiveness myopic avoid explicit reasoning gathering pomdp complexitiescomparedto mdps note case assistant pure informationgathering disposal asking agent mentioned believe handled shallow belief myopicheuristics abovemotivation alternate operation goal assistant pomdp agent goal distribution maintain goal distribution give probability agent goal conditioned note assistant affect agent goal agent relevant agent straightforward incrementally upon agent beginning episode goal distribution timestep episode agent leave distribution unchanged agent distribution normalizing distribution adjusted goal agent execute goal relies well learned assistant reflects true agent bootstrapping estimating episode agent close optimal domain lead rapid goal even early lifetime assistant assumed simplicity agent observable domain natural observable identity case observing agent transitioning fromwe transition marginalize agent yielding assistant pomdp distribution goal address selecting assistive idea anassistantmdprelative goal episode evolves drawing selecting assistant noop upon agent drawn achieving goal optimal give optimal assistive agent acting goal cost optimal myopic heuristic simply assistant mdps heuristic assistant greedily intuitively utility taking goal ambiguity resolved step thus heuristic gathering heuristic lead assistant make progress toward goal high probability avoiding moving away goal high probability goal highly ambiguous lead assistant noop computational computing assistant mdps goal technically transition assistant mdps depend agent must updating episode incremental dynamic prioritized sweeping moore atkeson alleviate much computational cost deploying assistant offline default agent boltzmann bootstrapping distribution deployment prioritized sweeping used incrementally qvalues learned refinement make practical assistant mdps resort replace user used computing assistant fixed default user eliminating need assistant step simulation policyrollout bertsekas tsitsiklis done simulating taking cost agent resulting assistant followed agent formally simulates trajectory achieving goal averaging trajectory cost heuristic identical replace expectation also combine heuristic case beneficial gathering combine myopic heuristic shallow belief assistant line sparse sampling tree kearns myopic heuristic used leaf node conducted user simulation domain doorman domain doorman domain agent goal collect wood food gold grid cell blocked cell four door agent open door move next cell door close time door open goal assistant help user reach goal opening door tuple stand agent cell door open agent open door move pickup whatever cell assistant open door noop assistant allowed push agent door agent assistant strictly alternate domain cost user open door cost assistant trial agent pick desired evaluated heuristic trial system chooses goal heuristic user goal user assistant open dooror nothing user door open door user achieves goal trial assistant user trajectory agent user doorman domain give cummulative user optimal cost trial user assistant cost assistant percentage cost trial seen slight edge doorman domain sophisticated sparse sampling kearns sample step leaf sparse sampling tree user time heuristic doorman domain half user half simulation evaluated conduct user high cost simulated user choosing learned bottom half sparse sampling increased time magnitude able reduction cost user surprising simulated sparse sampling able sample user sampling learned also used simulation remains seen benefit realized real user kitchen domain kitchen domain goal agent cook dish shelf ingredient dish recipe partially ordered plan ingredient mixed heated shelf door must opened fetching ingredient door open time kitchen domain user dish recipe assistant bottom frame recipe ingredient mixing temperature ingredient bowl door open also history preserve ordering plan recipe user open door ingredient pour bowl heat bake bowl replace ingredient back shelf assistant user pouring ingredient replacing ingredient back shelf cost conductedon subject doorman domain assistant wait alternative time step assistant continues noop best heuristic domainhas much domain heuristic default user word comparehd user half aggressive choosing wait goal distribution highly skewed toward goal trying user time heuristic kitchen domain half user half simulation sparse sampling heuristic simulated user trajectory domain well bottom half rollouts sparse sampling simulation showing myopic heuristic well sparse sampling much computation work much work intelligent assistant take email filtering posed supervised learning cohen travel planning combine gathering propagation ambite assistant system system formulated pomdps approximately offline coach system helped suffering dementia giving prompt daily boger plan graph keep track user progress user responsiveness best prompting distinct fixed goal washing hand hidden user responsiveness many goal goal hidden assistant note framework assistant infers agent goal relevant property user responsiveness electric assistant used reschedule meeting user miss system user regular radical belief pruned varakantham distinct work doshi interactive pomdps agent agent belief simpler assumes agent oblivious presence belief assistant relaxing sacrificing tractability work also plan naturally hierarchy hierarchical hmms pcfgs pynadath wellman blaylock allen statistical goal likelihood goal schema parameter blaylock allen cost incorporating plan natural assistance namely maximizing utility substantial area user modelling horvitz took bayesian user need assistance user used assistance user spreadsheet horvitz boutilier used idea assistance text editing boutilier dbns handcoded parameter infer type user utility assisting user explore kind user system user intention optimal assistant work assistant pomdp selecting assistive also iteratively estimating agent goal selecting myopic heuristic subject domain show significantly help user domain assistant able series parallel agent hierarchical goal user goal framework naturally case partially observable agent assistant recognizing gather opening fridge decide make extend work domain agent hard leverage work learning apprentice system learning mitchell user training system used learning acknowledgement upon work defense agency darpa interior acquisition service opinion conclusion recommendation expressed necessarily reflect view darpa
