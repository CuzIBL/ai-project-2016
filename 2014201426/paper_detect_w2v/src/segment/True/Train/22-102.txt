investigate learning tree concise tree test node representational overcome high test novel modifies bias primitive adaptively enlarging high show empirically outperforms tree learning noise drawn distribution goal system learns classification target observing relatively formulate explanation hypothesis training classified induced hypothesis simplest vector predefined comprises possibly relevant target reveals studied target learning target disjunctive normal form valiant haussler michalski learning subclass valiant open investigate learning tree breiman quinlan concise tree test node representational fact test satisfies term replicated tree call representational shortcoming eventually disappears show high test tree classification rule derived tree also addressed breiman quinlan learning high priori dynamically learning feature priori primitive fixed type size fixed size breiman valiant rivest feature meaningful learning percentage relevant feature hand hand feature learning system background target learning enlarge adaptively dynamic utgoff mitchell learning system schlimmer muggleton novel heuristic tree modify bias primitive dynamically introducing high learning fringe build tree primitive tree find feature redescribes primitive build tree process iterated fringe tested synthetic boolean domain show fringe improves upon classical tree target even presence noise target pagallo majority correlated classification parity fringe significantly poor classical formalize simplify presentation case boolean tree tree labelled node edge node defines binary test root node tree defines test edge represents outcome test left edge represents outcome edge represents outcome label leaf represents label tree reach node size simplicity mear sure size tree node terminology refer boolean literal complement term literal clause disjunction literal feature boolean applying boolean operator primitive term refer primitive feature boolean operator tree procedure learn tree successive subdivision sample process discover sizable subset sample belong tree derived refinement process sample initially empty tree sample test best sample breiman quinlan merit subdivision process mutual best root tree partitioned subset subtree root node procedure recursively subdivision process branch tree label zero mutual leaf labelled avoid overtraining tree grown subdivision process pruned back reduce pruning quinlan quinlan smallest tree tree boolean peculiar test leading leaf replicated tree illustrate boolean smallest tree test rightmost path tree shortest term path lead leaf corresponds truth term left branch node truth assignment falsifies shortest term duplicate truth term left branch node call representational shortcoming term duplication learning tree fragment term many subset subset give accurate probability subdivision process branch incorrectly terminates prematurely primitive literal node illustrate term test root node branch lead leaf corresponds term left branch lead term term disappeared feature term node feature learning priori primitive fixed type size breiman rivest discover learning tree schema used quinlan infer production rule tree quinlan quinlan generates production rule path tree simplifies removing irrelevant rule main fringe next quinlan simplification procedure find accurate production rule tree relevant view tree training sample fringe tree surface iteration proceeds quinlan maintains rule learning fringe learning feature fringe learning schema feature primitive creates tree choosing procedure generates feature boolean near fringe tree heuristic feature reexpressed expanded tree procedure repeated call process iteration process terminates feature reached heuristic originally discover relevant target observe tree defines path root node leaf defines term initially term node path form term node path proceeds node form term negation procedure defines feature leaf feature path leaf node path form feature node path proceeds form feature negation leaf node root feature heuristic simply defines feature applying term formation rule fringe tree heuristic tree feature feature twice correspond leaf node left iteration heuristic form namely literal creation term feature adaptively process initially iteration feature size iteration feature term size clause size negated feature clause size disjunction term size procedure generating boolean literal negation operator boolean operator illustrates learning fringe feature heuristic work feature heuristic iteration feature fringe work iteration graph show percentage size hypothesis iteration proceeds sample drawn distribution independently training sample size graph fringe iteration accurate hypothesis pagallo iteration fringe solid line fringe dashed line solid line hypothesis size fringe dashed line hypothesis size scale left scale hypothesis size node remaining step used reduce size introducing meaningful feature eventually process findfeature procedure discover feature iteration hypothesis guess heuristic successful fluctuation chance fringe learning form final hypothesis test target term smallest final tree node node exactly target final tree smallest absence noise term approximately term much final hypothesis tends final hypothesis accurate long term rare drawn distribution briefly findfeature procedure accommodate continuous tree test continuous defines binary breiman thought binary find feature procedure modification leaf feature dual heuristic conjunctive normal form looking leaf disjunction symmetric heuristic applying procedure well leaf last heuristic also used case applying feature formation rule leaf regardless label learning term classification unseen target term size final hypothesis goal test well fringe criterion well tree criterion tested five domain multiplexor parity majority tested presence noise classification concise test listing term term deviation term smallest target four test dnfl pagallo hausslcr mult multiplexor wilson parity four five pagallo hausslcr majll majority subutai tesauro prdsj hand quinlan test prdsj irrelevant test criterion sample used domain prdsj domain used specification quinlan facilitate learning testing task independently drawn distribution learning partitioned subset training pruning ratio breiman training used consistent hypothesis pruning used reduce size hypothesis hopefully classification target literal smallest target percentage wish testing task learning used represents roughly target time inverse approximately vapnik blumer suffice ideal learning considers hypothesis expressed target consistent hypothesis qualitatively training decrease used test classification tree fringe target percentage tree size percentage classification divided size test sample deviation tree fringe size tree node fringe discovered dnfl multill fact term much term rare drawn distribution fringe term final hypothesis majority parity hard tree majority hard term smallest term smallest tree parity hard drawn distribution correlated classification pagallo haussler fringe significantly poor formance tree poorly prdsj comparable reported quinlan sensitivity noise test summarizes noise noise percentage five noise mean probability true flipped noise corrupted independently noise learning testing noise free case five learning testing corrupted type noise show sensitive noise noise tree informative learning system classification varies learning learning curve learning curve tree percentage test five find target learning sample size size learning predicted conclusion view learning task discovering vocabulary hand novel pagallo tree determines vocabulary process accommodates target discrete well continuous used learn simultaneously also show empirically favorably boolean domain tree well noisy difficulty tree arise representational limitation expect reasonable give testing fringe natural domain mushroom schlimmer hypothyroid quinlan domain breiman latter noise hypothesis tree accurate domain close optimal breiman domain hypothesis fringe concise accurate acknowledgment like thank david haussler helpful also thank buntine dietterich schlimmer utgoff helpful comment preceded grant gratefully acknowledged
