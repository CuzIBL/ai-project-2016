reinforce merit learning learn heuristic shop scheduling scheduler schedule incrementally repair violation goal schedule poral tram neural network learn heuristic used lookahead procedure find good scheduling synthetic nasa shuttle load processing task trained involving tested proble sclied uler best repair simulated annealing suggest reinforcement constructing scheduling system many shop little hope generalpurpose domainspecific regularity exploited construct fast heuristic heuristic engineered hand process goal explore possibility applying reinforcement learning discover good heuristic automatically reinforcement learning learn task specifies learning learning system receives reinforcement signal learning thomas diettench oregon corvalhs oregon goal learning system find maxi mizes reinforce ment shop scheduling tell scheduling make next maximize final schedule domain shuttle payload processing nasa goal schedule task temporal resource also seeking minimize duration makespan schedule nasa scheduling also used schedule unforeseen diffi cult arises work task zweben colleague zwehen scheduling procedur combine heuristic simulaled annealing arch procedure resulting scheduling system flexible scheduling shuttle ground operation regular kennedy deale earning discover scheduling heuristic match exceed itera five repair remainder scheduling task briefly scheduler follow review reinforcement learning scheduling task formulated simulated reinforcement learning outperform repair scheduler realistic scheduling task learned reinforcement learning scheduling studied training suggest reinforcement learning role play developing scheduling system nasa domain repair nasa shuttle payload processing sspp domain scheduling task must install test payload cargo shuttle jobshop scheduling terminology shuttle mission task must task duration list resource task mission duration officer technician spcds tvpes resource many unit resource control officer technician resource resource pool control officer subdivided pool size task control officer must drawn pool resource pool work schedule must time task resource pool resource ment task satisfied sspp simultaneous scheduling shuttle mission cash mission task hencr sspp domain scheduling taming hundred task task must launch also take shuttle landed fach shuttle mission fixed launch date date ending date task launch time task landing readv time deadimes goal scheduling system minimize duration schedule much challenging simply schedule weben followingiteralive pair scheduling path schedule constructed backward forward launch landing date fach task launch scheduled late mporal permit task landing scheduled earl temporal ordtr permit resource ignored resource request resource pool path schedule constructed verv efficiently scheduling operator operator pool assignment resource task pool reassignment resource successfully satisfied operator move task time reschedules temporal dependent task path leaving resource pool assignment dependent unchanged operator move task time violated resource satisfied operator repair step earliest violation resource pool identified operator reduce move operator move offending task time pool assignment move task resource violation heuristic prefers move task amounl resource nearly allocated temporal dependent need moved onlv resource request control applies simulated annealing minimize resource pool violation operator violation resulting sche dule decreased resulting schedule schedule increased resuiting schedule willi probability violation temperature temperature grddu ally decreased sean proceeds violated schedule sveral tune shortest resulting schedule reinforcement learning temporal learning scheduling mforcement learning learn selecting pohev tell tpplied slate learning system receives reinforcement view scheduling reinforcemc learning must reinforcement employ zweben statt path schedule discusstd reinforcement give reinforcement schedule violation penalty scheduling movl intendi encourage reinforcement learning prefer quickly find good schedule schedule free violation mforcenient resource dilation scale schedule final reinforcement reinforcement iiing find final schedule reinforcement resulting stat fixed resource type combined resource pool resource time schedule resource type resource type overallocated time matter assign resource request resource pool type resource indez dietterich resource type time resource erwise fraction overallocation resource uttltttzatton trui schedule resource resource time resource dilation rationale behind note final schedule time schedule final schedule resource overallocated used ative reinforcement reinforcement learning reinforcement difficulty scheduling difficult simultaneous long schedule much shorter schedule resource schedule overallocation resource crude difficulty scheduling normalize final schedule resource dilation specified view scheduling reinforcement learning turn learning learning process best tell cumulative receive follow onward formally step schedule reinforcement learning work learn optimal learning learned optimal transform optimal lookahead best applying resulting maximizes note know certainly true repair scheduling operator learn temporal learning sutton learning network smoothing parameter combine gradient gradient learning rate learn stationary markov process fired reinforcemenl learning want learn optimal pohey employ form iteration reinforcement choosing learning conduct onestep lookahead resulting applying operator maximizes predicted resulting applying receiving reflect informed actually employ slightly plex procedure mean continually changing learning process fortunately converge sutton five modification made preliminary reinforcement learning kind exploration discover getting goal employed exploration probability recommended initially decreased reach final used neural network remember visited path final schedule network final backward experimentally work training backed employ experience replay learning best move goal remembered four training network best training learning significantly fourth emplo full lookahcad starch branching costly successor stites employ sample greedy generates operator evaluates resulting best operator size sample incrementally sample four resulting permitted desired confidence probability best sampled best continue sampling probabihtv xceeds sample greedy employed training final learning stales scheduling process neural network neural network accept fixed vector feature describing schedule schedule hand feature extract schedule neural network predict stale feature modest experimentation mean deviation free pool bottleneck pool showed technician logistics electrical gineer mechanical engineer control officer resource type became major bottleneck resource bottleneck pool unallocated unit free capacitv whole schedule mean deviation quantity feature pool mean deviation slaeks slack time task temporal prerequisite time prerequisite task scheduled time task slack task temporal prerequisite slack task mean deviation quantity task four feature modified used slightly modified resource dilation schedule numerator modified allocation resource type unit resource schedule divided unit resource schedule percentage window violation window maximal time scheduled task schedule segmented window percentage window violation also find earliest window lhat violation centage window violation percentage window violation resolved pool reassignment fraction window violation resource actually resource subdivided resource percentage time unit violation whole schedule pterod violated window normalized earliest window violation window feature violation repaired decrease zero window violation fach feature studying scheduling find quantity predict believe feature substantially goal ongoing consequence feature full learned enter infinite loop step prevent loop randomness introduced sample greedy procedure exploration process tends avoid loop even statf revisited visited recorded checked loop loop detected learned best loop detected backtrack preceeding take best loop also continue backtracking briefly training lest network architecture parameter employed learning constructed artificial specification nasa sspp artificial pool constructed scheduling choosing subset tended nasa shuttle configura scheduling shuttle mission shop scheduling dietterich scheduling synthetic task temporal task approximately pairwise precedence asserted next resource task type resource resource pool unit rapacity unit resource randomlv task unit resource tvpe pool training test constructed prob desired pool separated time unit sixteen feature schedule pool feature pool slack feature feature describing modified percentage window time unit violation percentage violated window violation resolved pool reassignment training training held validation halt training remaining repeatedly processed train network test test learned scale scheduling shuttle load processing task prob shuttle mission launch date month lach mission pavloads kind load long module mission peculiar equipment mpess pallet igloo pallet igloo task type resource five major bottleneck resource training test training contained four shuttle mission training held validation stop training test contained shuttle mission test thus learned scale shuttle feature used feature pool slack feature modified feature describing window violation percentage time unit violation firat violated window overallocation learning network architecture training procedure trained network sigmoidal hidden unit sigmoidaloutput unite unit encode predicted overlapping gaussian pomerleau unit represents artificial sspp training target activation unit normal probability densi mean deviation testinr predicted activation unit lrained eight network parameter learning rate exploration schedule preliminary showed well training processed fashion network network barkpropaga tion processing backward final pass training test conducted final schedule produced best network eight parameter retained network training continues network worse nine asured network testing best network cross validation retained final network retain final network compensate variance simulated annealing repair temperature synthetic scheduling task sspp task repair schedule temperature show four network trained horizontal axis give training processed show trained network improving plot repair network show reduction convert schedule final schedule temporal ference scheduling repair repair toir medium scale zweben vertical axis best schedule horizontal axis proxy game consumed horizontal axis give restarts simulatid annealing procedure vertical axis best schedule scheduler horizontal axis represents neural network employed network used soive scheduling sohed time cach network schedule best returned answer beet network deter mined used curve stop network used care must horizontal axis time fach step scheduler time step scheduler scheduler must sample lookahead loop spends time much time step hand fewer step find schedule iteration long iteration approximately iteration bearing mind curve scheduler alwav curve repair mean time find schedule network tains iteration schedule lasting year thousand dollar curve also show repair alwajs much time lter ations find schedule quahtv match show test even pronounced temporal ference scheduling scale belter even onlv trained show analogous temporal differ ence repair sspp horizontal axis lime maintains repair temporal scheduling find schedule repair note give whole test hide considerable reveals best schedule belter best schedule time said find schedule identical igurc plot fraction time cost eventually time slightly time concluding show temporal outperform best scheduling shultle payload processing dietterich clearly many feature need learning procedure capture domain also evidence suggest training procedure bradtke thrun schwartz boyan moore schraudolph pitfall neural network scheme reinforcement learning notable success tesauro backgammon system show pitfall encountered open work suspect success domain probably many good scheduling certainly many good path highly redundant smoothing adjacent final smoothing remove even poor predicting final ptoperties permit greedy find good schedule property repair simulated annealing also succeeds domain simulated annealing stochastic locally smoothing domain simulated annealing long find optimum able escape find acceptable learning spite industrial scheduling abound probably reinforcement learning quickly highquality scheduling goal must learning cost scheduling acknowledgement thank rich sutton monte zweben helpful gratefully acknowledge nasa grant nasa ames grant
