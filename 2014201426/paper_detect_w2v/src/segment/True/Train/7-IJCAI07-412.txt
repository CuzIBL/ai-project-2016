many interacting agent also duration inherent hierarchical family hidden markov hmms compositional time also recursive hierarchical inference parallel hidden markov hspahmm hierarchical parallel hidden hpahsmm hspahmm hmms agent hsmm hpahsmm hand hsmms markov learning decoding demonstrate synthetic time series data sign goal inferring sensory data natural hierarchical simpler form agent take parallel temporal spatial inference mathematical formalism recognizing take inherent hierarchical duration wide surveillance assistive like sign intelligent faced bridge limb joint high semantic need recognized handle duration style even person time uncertainty inherent sensory probabilistic reasoning natural probabilistic year hidden markov hmms widely used clear bayesian semantics learning inferencing natural domain hierarchical hidden markov hhmm inferring hongeng nevatia used hidden hsmm modeling duration duong switching hidden hierarchical well duration vogler metaxas introduced parallel hidden markov pahmm recognizing brand introduced coupled hidden markov chmm recognize well believe real need combine feature namely hierarchical multichannel hidden hierarchical semi parallel hidden markov hspahmm hierarchical parallel hidden hpahsmm decoding learning validate utility testing simulated data well real task continuous sign rest next parameter hspahmm hpahsmm formally decoding learning parameter defining tuple transition probability matrix probability distribution distribution straightforward generalize continuous like gaussian hierarchical hidden markov hhmm hierarchy hidden hhmm formally specified hierarchy hmms markov duration probability decay exponentially hidden hsmm alleviate introducing explicit duration thus hsmm specified parameter form probability duration represents system instant many interacting process hmms basically generalize collection form channel represents probability channel transition probability composite probability composite form learning well inferencing exponential also poor parameter learn simplifying help factorizing transition probability parallel hidden markov pahmm factorizing coupled hidden markov chmm hierarchical hidden combine form parameter form erarchy channel parameter channel formed channel also duration channel hierarchy maybe factorized pahmm chmm seen synthesis hspahmm hmms hsmm hspahmmlower qclower olowerc aclower blowerc lowerc hspahmmupper qupper oupper aupper bupper dupper hpahsmm hsmms markov hpahsmmlower qclower olowerc aclower blowerc dlowerc lowerc hpahsmmupper qupper oupper aupper bupper illustrates hsmm pahmm pahsmm hspahmm hpahsmm cussed hspahmm hpahsmm hspahmm duration pahmm hsmm hpahsmm duration hsmm thus hspahmm fewer parameter hpahsmm richer modeling real decoding channel frame channel channel hmms well transition hmms like sign word modeled transition word lexicon distinct hmms transition hmms giving transition thus hspahmm decoding decoding hspahmm work traversing hsmm time segment likelihood path pahmm hsmm traversing hsmm take time call pahmm take time giving reduce duration hsmm assumed normal case parameter toplevel hsmm need duration threshold case distribution mean variance normal distribution case need duration instant pahmm traversing toplevel hsmm take pahmm take giving inference even inference prohibitively varies around storing instant transfer transition transfer pahmms transfer transition inference illustrates decoding pseudocode decoding hspahmm hpahsmm decoding decoding hpahsmms traverse markov call lowlevel pahsmm procedure simplified stringing pahsmms also transition compound pahsmm traversing pahsmms transition compound pahsmm note transition duration channel compound pahsmm hsmm taking time decoding hspahmm decoding hsmm pahmms transition transition beam time duration probability path time probability transitioning probability observing probability spending duration maxpath calculate probability path pahmm time vogler metaxas beam fordo ifpaths time beam else remainder fordo path time beam probability beam take duration normal need duration pahsmm time storing compound pahsmm instant reduce illustrates decoding pseudocode hpahsmm embedded viterbi learning many like sign training sample segmented case hmms reestimate parameter combined thus segmented automatically profigure decoding hpahsmm constrained like transition procedure simplified calculating viterbi path iteration parameter histogram occupancy interested hmms adopted embedded training hspahmm hpahsmm pseudocode learning iteration call decoding parameter histogram occupancy learning decoding hspahmm hpahsmm conducted synthetic data real data sign task case pahmm duration beam time pentium window java benchmark synthetic data used discrete simulator synthetic channel time transition restricted transition gaussian mean distributed covariance gaussian duration mean variance built transition graph transition probability continuous walk transition graph noise well beginning illustrates procedure transition graph seen corresponds hpahsmm transition graph occurred time minth maxth path time beam probability beam producing chose training word occurred time training used rest test thus training contained test contained data discarded trained hpahsmm initialized pahsmms duration parameter accurately simulator parameter beamsize manually hspahmm initialized pahmms toplevel duration mean summing mean pahsmms simulator parameter manually pahmm initialized decoding viterbi beam trained embedded viterbi learning slope curve fell training iteration completed learned test test deletion substitution well decoding depend manually parameter hspahmm hpahsmm investigated embedded viterbi learning numtrain training sample probability transitioning channel probability observing channel probability spending duration channel numtrain jointhmm hmms forming training repeat maxpath probability path jointhmm decoding time channel maxpath time channel transition maxpath time channel maxpath time channel spends duration maxpath parameter convergence hmms hmms varied parameter iteration hspahmm hpahsmm parameter show seen hspahmm drop frame rate affect hand beam size cost slower hpahsmm beam size test comparing hspahmm hpahsmm pahmm summarizes thus hspahmm hpahsmm hspahmm pahmm duce huge jump plain pahmm affecting hspahmm hpahsmm time thus serf good mean hpahsmm pahmm continuous sign sign besides good domain test hierarchical simulator hspahmm sigma beam beam size hand simultaneously sign distinct duration hierarchical phoneme word sentence experimented test sentence dataset used vogler metaxas collected motionstartm system frame vocabulary sentence word long sign hand time instant calculate instantaneous velocity used vector time instant word pahmm hspahmm pahsmm hpahsmm liddell johnson break sign move hold move hand hold held also identifies hand configuration like chest chin body hand kind straight curved round encode sign word term constituent phoneme word signer chest finger closed chest encoded strtoward hpahsmm beam size cates hand inch front chest strtoward hand move straight perpendicular body hand chest transcription handed sign considering hand well hand probability hold normal distribution move modeled signum inflection signum gaussian variance intuition behind hold configuration hand remains noise move hand noise threshold instant specified duration move configuration ending configuration frame rate separated hand cluster around abdomen around chest around approximately initialized hold transition time looking sample transition time twice transition time modeled duration normal distribution centered around mean variance decoding reasonably hsmm hspahmm mean mean thus approximately parameter show word rate hpahsmm hspahmm pahmm word rate duration significantly improves hspahmm good alternative hpahsmm hspahmm pahmm hsmm restricts word transition reduces requiring training data feature continuous sign vogler metaxas starner training sign test sign bowden good isolated word word lexicon training word word test train much task continuous sign demonstrated conclusion hmms hierarchical explicit duration focused hspahmm hpahsmm decoding learning rigorously analyzed synthetic time series data also real task domain wide
