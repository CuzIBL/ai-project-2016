directed graph embedding embeds vertex directed graph vector considering link graph idea preserve property vertex directed graph embedded transition probability stationary distribution markov walk property turn exploring directed link graph walk optimal embedding vector preserve affinity inherent directed graph synthetic data page data page classification comparing embeds node directed graph euclidean vector inherent graph naturally directed graph retrieval hyperlink classification citation graph giles protein clustering pairwise alignment pentney meila work done deal ranking link pagerank brin page dean henzinger hard task data directed graph classification clustering zhou learning classification directed graph also directed graph pentney meila clustering protein data formulated directed graph asymmetric pairwise alignment work difficulty exploring directed graph hand data mining machine learning vector machine operating data vector embedding data directed graph vector appealing task data directed graph motivation task data mining directed graph link data unified framework embed link data vector utilize mature mining vector analyzing data directed graph hard data hard directed graph vector data well tool analyzing data huge directed graph link highly difficult perceive latent data inherent topological link embedding data vector help analyze latent visually work done embedding undirected graph manifold learning belkin niyogi data undirected graph manifold data assumed lying embed vertex graph dimensional edge graph reflect affinity node pair next optimal embedding achieved affinity directed case edge graph node necessarily symmetric used affinity motivated zhou formulate directed graph probabilistic framework walk affinity vertex directed graph embedding node directed graph vector walk rest give denotation used addressed work last part conclusion preliminary wide modeled directed graph page hyperlink vertex directed edge graph directed graph wide directed graph finite vertex vertex edge edge directed graph ordered pair vertex edge associate directed graph simply viewed edge vertex vertex mean directed link pointing directed graph transition probability matrix markov walk graph satisfies also stationary tribution vertexv guaranteed irreducible directed graph natural transition probability matrix walker node jump neighbor probability proportion edge directed graph slightly transition matrix back embed vertex directed graph vector property vertex neighbor mapping directed graph line optimization target vertex embedded dimension term used directed edge vertex vertex close embedded line term used vertex graph vertex neighbor emphasized minimizing target able optimized embedding graph dimensional embedding considers node pair relative node address embedding directed graph vertex relevant edge relevance strength edge vertex many relatively relevance vertex reasonable many task take page link page relevant page page pointing page relevant sense preserve embedded page many link home page page linked home page yahoo embedded feature page relatively transition probability walk property page many relatively transition probability meet page ranking page well studied area stationary distribution walk well good used many ranking pagerank emphasize page embedding feature stationary distribution walk weigh page optimization target taking rewrite optimization target thus embedding vertex line symmetric vertex pair probability walker jump vertex probability walker pass edge also deemed percentage flux flux stationary continuously import graph directed force manifest volume message conveys optimizing target property reflected edge node pair also reinforcement taking stationary distribution walk transition matrix diagonal matrix stationary distribution diag clearly combinatorial laplacian directed graph chung definite matrix reduces find argmin remove arbitrary scaling embedding matrix natural vertex graph eigendecomposition alternatively achieved vector eigenvector eigenvalue transition matrix primitive eigenvector eigenvector data minimizes optimization target eliminate trivial orthogonality argmin thus eigenvector smallest eigenvalue embedding graph matrix embedding vertex minimize rewrite eigenvector smallest eigenvalue eigenvalue adjacency matrix dimension target perturbation vector diagonal matrix degree eigenvalue normalized construct combinatorial laplacian directed graph eigenvector eigenvectors ordered eigenvalue smallest eigenvalue fact zero embedded dimensional irreducibility markov stationary distribution vector build markov primitive transition probability matrix directed graph matrix transition probability irreducible teleport walk langville meyer directed graph transition probability matrix adjacent matrix directed graph vector diagonal matrix degree stochastic irreducible primitive probability transiting adjacent vertex probability jumping graph vertex link jump graph viewed perturbation graph perturbation accurate practice need simply stationary distribution vector eigenvalue subject normalized embedding vertex directed graph vector summarized work belkin niyogi laplacian eigenmap nonlinear dimensional reduction undirected graph laplacian eigenmap case undirected graph transition probability undirected edge degree vertex graph stationary distribution vertex proved wherevol volume graph thus diag reduces laplacian eigenmap zhou zhou classification directed graph optimization smooth label vertex directed graph vertex closely minimize regularization risk smooth term data scattered complicated smooth hold classification hindered data away also contribute penalty optimization target thus considering imbalanced data side training data biased show zhou used classifier zhou also directed normalized eigenvector largest matrix seen eigenvector largest eigenvalue fact eigenvector smallest eigenvalue note cutting embedding data line threshold data show embedding real data preprocess procedure also directed graph embedding page classification test data edge binary show embedding directed graph plane node blue node node left four node property graph well preserved embedding reflects subgraph graph embedding directed graph consisting vertex subgraphs vertex directed edge subgraph drawn directed edge subgraphs drawn generating edge subgraph relatively graph directed graph graph data hardly latent data embedding dimensional tightly node directed graph clustered euclidean embedding data vector perceive clustered graph give insight latent directed graph classification dimension nonlinear dimension fixed labeled sample training linear page data address directed graph embedding task real data test webkb dataset subset containing page cornell texas wisconsin remove isolated page resulting page assign hyperlink textual anchor text interested much link adopt binary show embedding webkb data dimensional blue black node page cornell texas wisconsin embedding page relatively page well separated show analyzing link link denser embedding webkb data page classification used many classification clustering retrieval page classification task page four cornell texas washington wisconsin webkb dataset used binary edge adopted embed vertex euclidean train classifier classification task classification referred zhou zhou lkopf smola modified easy linear nonlinear tested nonlinear kernel used training data sampled data training sample conduct sampling labeled testing averaged time dimensional embedding also dimensionality embedded comparing binary classification page webkb data embed whole dataset classification task parameter linear nonlinear parameter kernel nonlinear parameter zhou case training sample varies used liner nonlinear consistently achieves zhou zhou applies risk graph convenient suitable regression case classification imbalanced data node away also contribute penalty embedding data vector able analyze carefully nonlinear show show training data sampled zhou zhou used parameter binary achieved zhou besides zhou smooth data scattered smooth well satisfied complicated case analyzing graph difficult task embedding data vector complicated geometry sophisticated alignment achieved nonlinear also test dimension classification task parameter used training dimensional show comparing nonlinear embedded vector dimension embedded varies embed data vector classification zhou work dimension show linear dimension ranging best achieved dimension data linear separable clear nonlinear work well case dimension data linear separable classification dimension data sparse train good classifier hinders classification suggest data directed graph latent dimension euclidean vector suitable conclusion embedding vertex directed graph vector explores inherent pairwise vertex directed graph transition probability stationary distribution markov walk embeds vertex vector optimally show effectiveness embedding classification task
