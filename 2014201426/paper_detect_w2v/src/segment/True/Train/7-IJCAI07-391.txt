novel induction markov network domain outcome independence test data work successively restricting consistent independence test shortcoming rigidly ordering test resulting inefficiency test committing test outcome resulting lack robustness case unreliable test address bayesian particle filtering population markov network maintain probability distribution outcome test fixed ordering greedily selects step optimally informative pool test gain maintains weighed probability make robust test outcome particle filtering domain independence test uncertain little data case data distributed data task learning markov network subclass graphical data discrete domain graphical bayesian network directed graph consist part undirected graph parameter markov network learning data interdependent learning network learned learning parameter work learning markov network node domain data challenging task encodes graphically independency domain independency valuable rely qualitative quantitative social markov network also used physic geman geman besag historically markov spatial data mining geography agriculture climatology ecology shekhar motivation work broad learning graphical heckerman spirtes conduct legal size domain discover rely fact graphical independency distribution domain thereforein data work conducting statistical independence test data successively restricting consistent test singleton inferring work belongs latter domain independence test uncertain case data relative domain case involving data data domain data heterogeneously distributed column data located geographically distinct sensor network weather modeling prediction traffic conducting independence test involving transfer data possibly slow network minimize test done work area learning undirected graphical learning decomposable also chordal srebro karger hofmann tresp independencebased learning gsimn bromberg pearl inference axiom pearl infer independence test actually gsimn disadvantage inefficiency regard test learn relatively rigid predefined test instability cascading test take bayesian maintains probability distribution test avoid inefficiency greedily selecting step optimally informative test gain decrease entropy distribution seen learning tong koller robust test outcome probability independenceinstead definite probability independence test permanently excluded probability rest next followed preliminary markov network domain undirected used independency domain domain size work capital letter domain bold letter independence test independence independency implied implied vertex separation separated graph removing node edge adjacent exactly independency hold probability distribution domain domain graph faithful faithfulness excludes distribution unlikely happen practice generative domain left assumed correctness graphical faithfulness work main maintain population time step slightly abusing population test assignment test independence dependence true false generative test data probability learn underlyingmodel explainedin next probability calculated principled need generative reflects independence test sufficient statistic data test concerned stem fact faithfully encodes independency domain note implicit generative formalizes make explicit generative encodes left test computation unsolved data abbreviated test data procedure discrete bayesian test margaritis practice data data test thus depicted used overcome lack show work well artificial real data modified probability must data abbreviate also entropy test data abbreviated parameter assumed test true consequence faithfulness learn domain data employ bayesian calculating probability data learning framework summarized step test cost faithfulness existence consistent test domain practice procedure considerable difficulty thus computationof entropyht intractable candidatetests also exponential size test test test address particle filtering step maintain population representing probability distribution outcome test quantity probability entropy averaging particle population choosing next test addressed greedy step next test minimizes entropy penalized proportional cost exponential size heuristic next explains pfmn algorithmis pfmn particle filter markovnetwork learner time step maintains containing particle initially selecting edge selecting edge picking pair permutation pair ensures size probability particle filter markov network pfmn pfmn sample particle distributed size text loop argmax argmaxs scoret test data test data time main loop line test optimizes pair conditioning exponential equaling optimization heuristic used procedure neighbor removal test cost take proportional test used discourage expensivetests entropy test derivation make generative omitted lack term gain test time data logpr test test true false bayes rule generative test vertex separation faithfulness kronecker delta consistent assignment quantity calculated equivalence consistent assignment represents imply test test intuitive time probability test true false assignment test probability mass equivalence consistent true false normalized probability mass gain also need explained bayesian test margaritis test calculates likelihood competing multinomial parameter namely true false generative bayes proportionality thus calculated explained like summation approximated summation population particle iteration completes test returning line calculate data likelihood optimal test used distribution particle line particle filter next pfmn terminates entropy population returning particle probability particle filter particle filter andrieu markovchain mcmc sample particle probability distribution step particle particle step distribution drastic reduction cost sampling distribution relative alternative sampling case domain particle correspond test data particle filter used line pfmn transform population probability distribution particle filter normalize resample particle sampling probability resample move particle time distribution ifthen reflected used probability resampling step line bias particle final step particle moved line pair step andrieu distribution parameter addressed many particle filtering distribution success pfmn next distribution previously must distribution mixture paqa consisting used walk generates sample iteratively inverting edge probability thus hamming node move chooses remove edge pfmn gsimn artificial domain left ratio cost middle test conducted pfmn gsimn edge remove edge probability edge complement edge missing removed edge pair removed resulting also move guaranteed hamming maximize acceptance move line evaluating true proposing move independenceequivalent provably probability ensures convergenceto distribution must also aperiodicity irreducibility andrieu satisfies aperiodic rejection irreducible experimentally pfmn gsimn bromberg artificial data gsimn pearl axiom test infer test actually conducting test test used time test conditioning size bromberg recovered network fraction unseen test test resulting vertex separation true test calculated vertex separation true artificial domain statistical test data domain procedure well network generalizes unseen test artificial evaluated algorithmin artificial domain true network allowed systematic varying domain size dependency reflect edge true network network true true network selecting pair permutation edge connectivity parameter show test conducted true network vertexseparation outcome test left show ratio cost test conducted pfmn gsimn domain size connectivity particle cost pfmn gsimn connectivity reaching case case explainedby fact numberof connectivity grows exponentially side clearly make task pfmn difficult middle show even pfmn particle exactly case gsimn independence test case thus omitted show pfmn much fewer test gsimn close optimal test dataset size cost real data pfmn haberman adult nursery baloons hepatitis bridge alarm flag dermatology data dataset dataset pfmn gsimn data left pfmn gsimn data size sampled data ratio cost pfmn gsimn pfmn gsimn real data correspond data distribution size show pfmn close optimal domain size also robustness pfmn gsimn uncertainty outcome test uncertainty data data size sampled true network connectivity left show pfmn gsimn size data pfmn clearly outperforms gsimn growing steadily data size also conducted substantial data archive newman merz cost pfmn gsimn show ratio cost pfmn gsimn show improvementof pfmn gsimn pfmn gsimn histogram show pfmn gsimn pfmn used data data pfmn cost reaching ratio data pfmn achieves reduction cost little reduction gsimn rest exhibit modest reduction conclusion pfmn learning markov network data domain independency explicit generative also showed experimentally pfmn resistant test conducted fewer test many case help domain data scarce test uncertain data abundant distributed potentially slow network
