behavioural stimulus followed subject learn full stimulus prediction modelled rule sequenceof trial prediction rule learned iteratively temporaldifferencelearning presenta closed prediction trial time trial show prediction converge real correlation type toeplitz matrix proven give learning rate optimally learning process temporal learning mathematical treatment behavioural biology dayan abbott learning predict pavlovian sense classical conditioning adressed series stimulus latency time followed series linear rule show subject able predict remaining rule repeating series trial review learning sutton barto correlate mathematical primate dopamine cell appetitive conditioning task psychological pharmacological rationale studying cell review schultz connection temporal learning montague mathematical constructive convergence giving explicit dependenceof prediction trial minimize learning time giving optimal learning rate contributes well temporal learning purely mathematical valuable also behavioural biology reinforcement learning also understood dynamic sense watkins work gordon szepesvari smart adopt dayan abbott stimulus predicted want trial duration time trial predicted stimulus time time stimulus overlap subject learn remaining time stimulus onset bracket refer stochastic exactly trial fluctuation stimulus give linear prediction sutton barto rule derived mean dayan abbott derivative made discrete step gradient rule obviously subject time subject prediction temporal rule time made sequentially time step parallel sampling time trial updating trial alternative substantially differ final many trial computational parallel rule learning schedule adopted widely dayan abbott trial superscript dynamic temporal learning parallel temporal rule gradient convergence guaranteed proven compact introduced proceed incorporatethe rule prediction yielding recursive prediction trial make closed show convergence optimal learning rate maximally fast convergence prediction trial recursive summation explicitely stimulus phase overlap restrict case interested subject make proper prediction stimulus restrict time giving matrix unit matrix minmax time real tmatrices refers full remaining triangle diagonal compact vector hurwitz stability matrix eigenvalue real part suitable vanish relying hurwitz matrix followed sutton hurwitz property matrix explicit establish property toeplitz matrix correlation show hurwitz property give convergenceis assured optimal continuing hold matter stimulus desired prof convergence full generality need show hurwitz matrix eigenvalue matrix real part want give convergence convergence literature temporal learning learning parameter refers exponential weighting recency learning convergence dayan dayan sejnowski framework mentioned literature concentrate convergence establishing property toeplitz matrix correlation proceeds show definite show eigenvalue real part established hurwitz property convergence definite nonzero real vector show xtgx extractfrom diagonalmatrix triangular matrix xtgx xtgdx xtgdx xtgdx keep summation easy understood zero padding toeplitz band stimulus shifting time arises stimulus xtgx rearranging vector dimension lead xtgxutx matrix band matrix symmetrizing matrix matrix term summation last convenience covering case summand nonzero note nonpositive extra term zero zero padding matrix term identical nonnegative nonpositive incorporating lead xtgxu matrix band matrix matrix vector dimension understood vector nonzero covariancematrices vector establishes rewrite xtgxutx certainly nonnegative show zero contradiction zero term must zero term zero proceed term used zero continuing vein step ukxn ukxn used mean contradiction must nonzero vector established xtgx established symmetric toeplitz matrix correlation definite turn showing eigenvalue real part look real real symmetric definite stronger nothing premise give sufficient sign real part eigenvalue show sign hand eigenvector eigenvalue real real case eigenvector eigenvalue conjugated transposed also real symmetric summation eqns give real symmetric definite real used case real real case real combining eqns give sign sign case eqns sufficient real symmetric definite matrix real matrix matrix definite real part eigenvalue turn matrix matrix definite matrix definite noting give desired completes hurwitz matrix learning rate fast convergence convergence behaviour temporal rule trial convergence dominated eigenvalue largest modulus convergence slowest eigenvalue eigenvalue used task eigenvalue dependent stimulus time note defines unsymmetric toeplitz matrix band well closed eigenvalue toeplitz matrix band symmetric asymmetric case beam warming closed must asymptotic eigenvalue beam warming modulus eigenvalue give convergence assured also serf good rough much computational note eigenvalue hurwitz eigenvalue eigenvalue lastly eigenvalue eigenvalue sketch behaviour clear eigenvalue rising computing eigenvalue give mink good convergent behaviour mean note eigenvalue identical need turn optimal fastest convergence argmin maxk optimization closed line find finitely many step idea reach process curve ensuring satisfies maxk decreasing slope choosing argmink ensures maxk satisfied procedure continuing curve reach everywhere maxk satisfied intersection curve inspection curve intersection inspect intersection closest argmink free stop else intersection reaching curve intersecting rising mean done actually reached stop else curve intersecting falling must continue curve satisfies continue falling curve modulus illustrates behaviour free boundedminimum changein falling curve modulus terminates finitely many step curve intersection falling rising curve clear possibility curve eventually rise stimulus look case stimulus take particularly form unit matrix free solid curve modulus circle falling curve dashed intersecting take role curve diamond well next intersection rising dotted curve importancesince vertical line solid curve dashed curve modulus next intersection rising dotted curve intersection dashed curve diamond vertical line convergence exponential decay time case choosing optimal learning rate case finitely many step convergence reached choosing optimal learning rate fact degenerate eigenvalue eigenvectors algebraic multiplicity conclusion closed prediction trial time trial convergence toeplitz matrix eigenvalue matrix derived utilized learning rate optimally learning process
