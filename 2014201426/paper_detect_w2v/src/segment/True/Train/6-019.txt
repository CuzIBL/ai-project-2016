kernel vector machine learning natural case incorporate domain kernel resolving prepositional phrase ambiguity kernel derived proved succesful learning overlap derive overlap kernel extend gain weighting combine kernel dimensionality feature closure property kernel kernel kernel achieves high classification time learning make clear kernel achieves classification natural resolution structural ambiguity sentence said structurally ambiguous syntactic zavrel prepositional phrase want disambiguate case uncertain attache verb noun sentence bought shirt pocket washed shirt soap nagao rely kind tackled memorybased learning like neighbour training stored memory classification done closest stored memory need dedicated kind natural memorybased learning veenstra zavrel daelemans vector machine tackle disambiguation central learning kernel kernel calculates feature goal combine svms probem deriving kernel straightforward deriving kernel trivial kernel must extra kernel much stronger show dedicated used kernel sequentially used learning case illustrate take overlap succesfully used learning zavrel give svms zavrel give learning shirt washed ratnaparkhi type ambiguity easy resolve stetina funded doctoral grant advancement technological flanders vector machine simplicity explanation case binary classification vector target reasoning sentence modifies noun shirt pocket describes shirt sentence kernel introduced give modifies verb washed soap describes conclusion work goal assign vector belonging arbitrary manifold ndimensional svms sidestep difficulty vapnik overfitting avoided choosing hyperplane hyperplanes data hyperplane maximizes closest data precise kernel maximal hyperplane linear convex quadratic linear zero vector port vector data closest hyperplane thus difficult classify classify xnew determines sign sign xnew belongs zero xnew note restricted summation vector zero anyway property kernel even know form feature used kernel modelled encoded vector brown kernel kernel arise naturally mercer must continuous definite vapnik construct kernel icristianini kernel kernel fact kernel closure property case mercer follow naturally closure property kernel kernel feature feature vector kernel feature vector case mercer follow naturally learning zavrel cost salzberg used learning look overlap next gain weighting learning machine learning training stored memory classification closest training stored memory learning neighbour classification literature reasoning reasoning reasoning reasoning force avoid classification choosing high overfitting dimensionality make linear separation seen comparing classification kernel also show kernel kpig outperforms conclusion kernel learning natural took used learning resulting kernel kpig achieves high classification data started vector mapping vector worked feature necesary kernel follow naturally used kernel show kernel actually kernel kpig show dimensionality feature yield increased dimensionality feature feature kernel take feature vector also take feature vector fact come taking extend wich word used resolvement ambiguity validate belief kernel kpig used wide natural kernel natural moment sang look promising early draw conclusion also extend kernel even many reported literature investigated applicable learning intend investigate derive kernel
