deriving joint agent maximize joint modeled decentralized partially observable markov process pomdp despite growing decentralized pomdp multiagents arena efficiently deriving joint locally optimal joint equilibriumbased jesp exhaustive jesp subsequently novel dynamic jesp reveals exponential dynamic verified empirical jesp globally optimal linear convexity pwlc property thus taking step developing continuous belief multiagent system move control need robust multiagent nearly optimal feasible increasingly resorted framework formulate multiagent agent deriving maximize joint modeled decentralized pomdp partially observable markov process decentralized pomdp bernstein mtdp markov team pynadath tambe pomdp case distributed agent basing framework multiagent formulate constitutes optimal multiagent system derive multiagent system deriving decentralized pomdps progress achieved pomdp monahan cassandra kaelbling unlikely carried decentralized case optimal decentralized pomdps bernstein pomdp pspacecomplete papadimitriou tsitsiklis bernstein note suggests decentralized treated pomdps agent transition agent many agent take domain possibility simplify agent chades restrict agent memoryless reactive transition thereby simplifying boutilier xuan derive decentralized pomdp centralized full communication gradually relaxed relies instantaneous noise free communication simplification reduce applicability decentralized pomdps peshkin take gradient find optimum memory find locally optimal subset infinite planning horizon find locally optimal unrestricted finite planning horizon thus remains need generating optimal distributed pomdps decentralized pomdps refer joint jesp jesp iterates agent optimal agent agent fixed iteration continues joint achieved thus jesp achieves optimum nash equilibrium exhaustive find best agent exhaustive even agent also improves dynamic incrementally derive empirical jesp globally optimal derives globally optimal full linear convexity pwlc property thus taking step developing continuous belief markov team mtdp pynadath tambe framework concrete illustration decentralized pomdp decentralized pomdp potentially also serve bernstein xuan team agent mtdp pynadath tambe tuple finite agent joint transition represents probability joint agent represents probability joint joint agent receive joint equally practical like mtdp agent thus expressed agent chooses mapping history thus time agent refers joint team agent note distributed planning centralized thus agent know know illustrative familiar capable bringing difficulty creating optimal mtdps multiagent classic tiger used illustrating agent pomdps kaelbling mtdp modified agent corridor facing door left behind door hungry tiger behind untold rich agent know thus indicating behind door tiger agent jointly individually open door agent independently listen presence tiger thus lopenright transition time agent open door reset probability regardless agent agent listen remains unchanged agent receives probability joint resulting agent listen tiger behind left door agent receives probability probability transition agent open door behind tiger attacked equally tiger injury sustained opened door tiger severe open door jointly open door receive wealth equally open door rich proportion agent opened door agent incur cost clearly acting jointly beneficial agent receive rich sustain damage acting agent receive need history agent multiagent system also case vary penalty jointly opening door tiger optimal joint agent must selecting sensitive teammate belief agent history facing team find optimal joint agent maximizes team optimal joint simply joint highest must able joint expectation projecting team branch computation generalize arbitrary team size time step joint team past multiagent system time step computation summation agent time computation joint specifies history agent joint agent thus correspond largest agent time optimal joint searching thus joint exhaustively searching optimal joint clear successful time restricted guaranteed find locally optimal joint refer jesp joint equilibriumbased like jesp nash equilibrium locally optimal partially observable identical payoff stochastic game poipsg peshkin idea find maximizes joint agent time keeping agent fixed process repeated equilibrium reached optimum optimum agent optimum encountered planning centralized exhaustive describes exhaustive jesp cooperative agent modify agent time keeping agent fixed joint maximizes joint keeping agent fixed exhaustively searching agent free iteration modified joint remain unchanged repeated equilibrium reached agent remains unchanged guaranteed joint iteration nondecreasing joint conv agent list bestpolicy policyspace prev conv conv else prev conv conv break best remain unchanged iteration convergence reached worst case joint best iteration worst case exhaustive globally optimal much practice illustrated optimum adequate like restarts simulated annealing perturb settle exhaustive step enumerates agent thus haustive incurs time step incur cost jesp mean call step payoff dynamic alternative exhaustive jesp next dynamic examine pomdp literature inspiration find dynamic incrementally construct best simply monahan cassandra kaelbling rely optimality optimal must also optimal word optimal history step last step must also optimal remaining step show analogous optimality property multiagent case construction optimal jesp must belief summarize agent history past agent ignore history past supporting construction optimal case belief distribution sufficient statistic agent optimal sondik multiagent case agent face normal pomdp agent fixed sufficient agent must also agent history agent thus time agent tuple joint history agent treating agent time transition agent pomdp agent novel multiagent belief agent distribution word reasoning agent agent maintain distribution simply show belief agent tiger domain show probability distribution history agent demonstrates multiagent belief construct dynamic incrementally construct optimal agent dynamic dynamic around finite horizon readability derivation dynamic multiagent system trace tiger case generalize case fixed agent represents team receive agent optimal step onwards belief time horizon work back beginning construct optimal maximizing recursively term refers term refers belief observing base case leaving break thus agent belief primitive mtdp computation term agent belief belief receiving derive well computing remaining term belief distribution multiagent system treat denominator normalizing bring numerator also enters computation term thus agent belief turn agent belief primitive mtdp also extract form optimal history dynamic line belief reachable belief possibly belief seauence agent reachable belief reachability belief procedure time invoked belief time thus reachability phase time line heart dynamic also time line translate resulting agent last phase time phase considers optimal agent thus time resulting reachable belief size belief piecewise linearity convexity computes belief reachable belief subset probability distribution dynamic must show piecewise linear convex pwlc agent faced agent pomdp agent fixed sondik showed agent pomdp pwlc pwlc thus supporting dynamic novel belief potentially dynamic gorithm continuous belief empirical tiger term time show globally optimal gorithm exhaustive jesp globally optimal slow doubly exponential finite horizon finite horizon jesp term scale seen jesp much fewer arrive equilibrium time globally optimal jesp even apparent globally optimal million jesp jesp succeeded globally optimal case jesp sometimes settle locally optimal globally optimal restarts used globally optimal exhaustive jesp exhaustive globally optimal time settle locally optimal sufficient locally optimal globally optimal imperative quickly alternatively jesp altered stuck optimum restarts exhaustive jesp dynamic also tiger domain show millisecond horizon seen time horizon time time increased horizon horizon conclusion growing decentralized pomdps multiagents arena generating joint multiagent system time pentium memory linux redhat allegro lisp cies lack novel contribution address shortcoming exhaustive doubly exponential agent time joint jesp optimum optimum exhaustive jesp dynamic jesp dpjesp illustrates exponential exhaustive jesp empirically verified agent linear convex pwlc belief pave family operate continuous belief attacked decentralized pomdps major work acknowledgment thank piotr gmytrasiewicz grant darpa award
