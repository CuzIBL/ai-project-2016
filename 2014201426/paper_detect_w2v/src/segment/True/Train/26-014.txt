many noted combining inductive analytical learning lack combined learning practice learning combine learning previously learned domain inductive learning neural network learning ebnn neural network domain explanation constructed chaining inference neural network learning extract weakest precondition explanation ebnn extract derivative target training feature derivative summarize dependency explanation used bias inductive learning target simulated robot control task show ebnn significantly fewer training inductive learning robust domain operating effectively broad spectrum weak domain analytical learning learning dejong mooney mitchell alize training data dramatically reduce training successful pure done carnegie mellon sponsored part avionics aeronautical system afsc force wrightpatterson arpa view conclusion contained representing official expressed implied government machine learning network learning learning mitchell school carnegie mellon pittsburgh mitchell combining inductive analytical learning ideal case learning system deal domain robust severe therein operates purely inductively domain domain purely analytically domain perfect form domain inductive learning rely many training guide syntactic inductive bias major open machine learning combine analytical inductive learning gain benefit training data robustness poor illustrates spectrum domain learning system able operate inductive learning operate well leftmost spectrum domain also operate well domain seek unified robust severe domain operate spectrum domain even worse desire system learns well purely inductive system perfect system comparably able employ background domain previously learned scratch well interested operate broad domain inductively learned dofigure episode final goal domain neural network used resulted achieving goal ebnn extract slope target derivative goal feature final feature explanation main also interested interleaving learning domain target noise tolerant able learn noisy data noise feature training classification learning ebnn learning utilizing neural network seek property ebnn domain collection artificial neural network target learned separately neural network alternative nearest neighbor scheme ebnn domain guide learning target explaining analyzing training target term domain domain learned scratch backpropagation rumelhart neural network learning procedure learning target neural network domain illustrate ebnn agent perhaps robot must learn choosing goal episode goal learning task case acquire lead eventually goal target case lead goal learned agent goal watkins barto explaining analyzing episode learning agent initially possessed perfect domain describing case robot previously learned domain collection neural network network characterising take arbitrary predicted resulting network represents ebnn applies network learn episode achieves goal precisely ebnn applies process episode explanation prediction episode domain explanation constructed neural network domain predict thus note predicted deviate inductively learned domain approximately analyze role explanation elucidate achieving final goal feature dependence used extract weakest precondition explanation produced outcome ebnn represents domain neural network difficult extract weakest precondition neural network differentiable ebnn dependency explanation extract derivative slope final goal feature feature ebnn examines neural activation explanation analytically extract derivative done last pair goal neural network differentiable last step explanation episode slope goal feature predicted final extracted computing derivative neural network slope dependence final infinitesimally final extraction slope chained back episode applying rule differentiation explanation step derivative slope target goal pair episode stated slope dependence target feature episode feature believed domain thrun mitchell irrelevant achieving final goal derivative zero slope presence strongly relevant feature refine slope extracted explanation training used refine learner target target ebnn neural network approximating sample sample slope target incrementally training inductively analytically iteratively true target episode pair episode lead goal thus training inductively analytically refining target network inductive learning corresponds updating target network target lead achieving goal inductive learning crucial compensating domain analytical learning corresponds updating network target slope extracted analytically explanation slope influence learned network overriding default bias interpolating analytical ebnn enables training data slope sufficiently accurate case target neural network backpropagation slope well simard summarize target iteratively approximated updating inductively empirically training target analytically analytically derived training slope explaining term previously learned domain accommodating imperfect domain domain learned inductively training arbitrarily process inductively learning domain confused learning target machine learning simulated robot squared domain network decrease monotonically training data nine alternative domain used poor resulting arbitrarily poor explanation extracted slope learner avoid damaging incorrect slope arising poor domain ebnn reduces undesired influence incorrect domain prediction estimating extracted slope predicted explanation prediction slope time domain used predicting prediction deviate prediction minus normalized prediction episode next step extracted slope step away episode posse desirable property learned domain perfectly decrease monotonically inference used ratio analytical inductive learning target step away episode analytically derived training slope time inductive reported promising generality open ebnn evaluated simulated robot navigation domain depicted learning task find greedy navigates agent goal circle arbitrary avoiding collision wall obstacle view agent term angle goal obstacle note deterministic sensor noise exploration robot compensate ebnn watkins sutton temporal learning sutton discount discrete modeled domain neural network used neural network backpropagation learning learning approximated modeling separately training slope memorized achieved fitting nearest neighbor memory slope outperform neural network representing target analytical ebnn domain initially allowed agent train modeling network form domain training fairly accurate imperfect domain show applying ebnn domain inductive learning test exhibit asymptotically learn desired control successfully omit lengthy essential ebnn mitchell thrun domain averaged ebnn domain differing training network bold gray line reflects learning curve pure inductive learning weighting analytical ebnn illustrating curve averaged also locally windowaveraged vertical axis test ever reduction training episode ebnn reach inductive learning ebnn learning curve steeper indicating data ebnn degrade progressively weaker domain repeated weaker domain trained training network show clearly ebnn outperforms purely inductive learning accurate domain steeper learning curve thus ebnn degrades gracefully pure inductive system domain decrease heuristic graceful degradation ebnn repeated weighting slope relative show domain learning curve affected domain decrease learning ebnn significantly worse pure inductive thrun mitchell learning justifies illustrates ebnn work produced combining inductive analytical learning combining inductive analytical learning machine learning none achieves final area matures find type used domain target domain prepositional target differ type domain imperfection accommodate domain target combine inductive analytical combining induction grouped roughly analytical inductive training analytically inductive hirsh ivsm hirsh applies explanationbased training combine inductive system explanation induction dietterich flann kedarcabelli inductive remaining unexplained feature catch relevant feature missed domain mooney ourston inductive analytical lebowitz lebowitz suggested statistical regularity data empirical regularity midwest congressman vote favor farm subsidy explained midwest many farmer congressman vote help voter refine guide variant regularity interleave inductive analytical process system interleave inductive analytical step bergadano giordana bergadano giordana construct explanation simultaneously considering system vanlehn vanlehn hall hall pazzani pazzani learn inductively filling incomplete explanation widmer widmer mahadevan mahadevan abstracted domain determination russell form explanation specialize domain oursten mooney system inductively refines domain noisy training data ourston mooney quinlan machine learning inductive like ebnn system able deal whole spectrum domain weak rosenbloom aasman rosenbloom aasman miller laird miller laird demonstrated induction achieved purely analytical learning inserting inductive rule domain ebnn fall explained extract explanation combined ebnn differs significantly neural network domain target lead property enables inductive learning domain noisy data backpropagation rumelhart ebnn natural incrementally refining learned target training inductive extracted explanation analytical neural network learning also noted learn training data simard colleague simard network training type target system recognizing constraining network translation work ebnn simard work must embed learning ebnn learns learned constrain learning shavlik towell shavlik towell mahoney mooney mahoney mooney domain bias neural network learning initializing network reflect domain used neural network topology infers exactly classification domain network refined inductively backpropagation ebnn differs ebnn construct distinct explanation compiling domain shot neural network ebnn selflearned domain neural network domain rule domain ebnn data refine domain target domain analytical step learning ebnn combine inductive analytical learning inductively learned domain used guide learning target combined inductive analytical process domain ebnn collection learned neural network robotic target approximator training training slope target fitting training purely inductive learning target fitting slope extracted explanation analytical ebnn demonstrated learn target fewer purely inductive learning degrade gracefully domain decrease heuristic mean decreasing contribution analytical training domain poor explanation ebnn partially fulfills robust part noise tolerant robust domain inaccurate slope resulting inaccurate domain identified inductive learning competes analytical learning priori domain learn domain inductively noise tolerant extent neural network capable dealing noisy training data suggest ebnn promising learning warrant many utilize domain ebnn domain expressed neural network propositional ebnn stochastic domain heuristic weighting analytical learning relies prediction deterministic prediction domain derivative slope kind analytically extracted explanation extract form well accelerate learning ebnn utilize representing target neural network collection learned rule lead scaling learning collection rule learner encounter slowdown arising rising cost learned rule target neural network slowdown learning proceeds scaling arises correctness target degrade learning target mitchell thrun ebnn domain learned scratch priori domain correspondence learned domain acknowledgment thank ryusuke masuoka invaluable help refining ebnn code jude shavlik paul rosenbloom robot learning contributed idea correspondence neural network thank lonnie chrisman rich goodwin comment draft
