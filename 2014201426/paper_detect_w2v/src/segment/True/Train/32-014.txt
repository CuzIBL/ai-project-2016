open reinforcement learning assure convergence compact hypothesis learning converge hypothesis linear fixed diverge nonlinear hypothesis describes bridge reinforcement learning show converges optimum agnostically learnable hypothesis convergence demonstrated learning fails weak identified bridge converges hypothesis connection made reinforcement learning hypothesis reinforcement learning widely used learning make uncertain agent perceives reeei ving indication agent goal maximize work learning describes alternatively learn describing used make learning sutton used family reinforcement learning operate adjusting locally consistent used approximators neural network compact parameterized realworld like know guaranteed converge optimal divide exploration coverage mination find corresponds concentrate work jaakkola established convergence machine learning probability compact parametric interested converge closest true form agnostic learning gordon proved conveiges sense averagers contraction tsitsiklis proved convergence established linear fixed nonlinear neural network give suboptimal bertsekas tsitsiklis even diverge serious real nonlinearity baird introduced residual convergence proved combined gradient learning used neural network unfortunately resulting arbitrarily visit sampled describes bridge establish convergence agnostically learnable explains nonconvergence outline bridge sketch convergence show solves fails briefly convergence optimum mention alternative necessarily technically tense restriction broad machine learning markov process transition probability distribution next distribution distribution distribution upon discount interested determination fixed fixed actually markov also transition probability distribution able stationary distribution resulting markov also distribution true discounted determination true good classical made backup operator take operator said contraction norm said nonexpansion contraction fixed tsitsiklis repeated process converges operator time transition probability distribution expectation case observing markov form unbiased observe followed unbiased formally probability density backedup distribution thus density probability density even infinite infeasible tabulate must resort scheme hypothesis representable learning operator arbitrary approximately process practice mapping exactly even access expectation exactly infeasible thus mapping sample take sample distribution stationary distribution exactly generating sample sample distribution passing learning joint probability density sample simply combine sample probability density agnostic learning case learning operator seek hypothesis best match target even target hypothesis learning operator agnostic learning mentioned case access learned draw sample sample distribution distribution sample whatever distribution used agnostic learning minimizing risk risk hypothesis distribution practice approximately generating sample sample distribution able risk well thus able hypothesis risk distribution exactly hypothesis certainly trivial briefly case learning step agnostic learning step goal best seek minimizes relative absolute nonconvergence examine used approximators reconsider bridge next mentioned process papavassiuou russll norm make contraction composite operator contraction process converge relative tsitsiklis linear hypothesis simply nonlinear hypothesis nonexpansion process diverge stuck arbitrarily give demonstrating fail used nonlinear hypothesis probability going also deterministic stationary distribution discount hypothesis suboptimal fixed oscillation modify slightly true best reach suboptimal fixed around even repeated type failure oscillation approaching relative bridge high followed convergence look main bridge valuedet determines repeated call bridgestep invocation bridgestep metaphorically throwing bridge treacherous terrain hypothesis side optimal bridge land somewhere close aimed able walk productive contraction bridge land target know near taiget bridge landed made precise lemma next tocreate vnew webasically tool work seen combine operator vnew stuck creatively progress establish stuck main bridgevaluedet call bridgestep know tell turn restricted hypersphere term made precise lemma next hypersphere depicted inside bridge aimed operator identity operator simply amplifies bellman residual seen side hypersphere throw bridge bridge anywhere goal true somewhere motivation sense jump ideally able want representable must operator bridge line throw bridge aiming determines actually land bridge established practice mapping generating sample distribution passing learning sample distribution feature distribution density final step walk bridge bridge line vnew line projecting onto line parameter refinement yield guaranteed contraction thus vnew necessarily calculating risk need risk distribution relative practice timate true risk empirical risk haussler calculate sample drawn distribution invocation bridgestep represents iteration main iteration build bridge generic iteration iteration generic iteration linear thus final tall tree leaf insist final final mapping summarized bridge summarized generic iteration bridgestep convergence bridge main convergence bridge limitation lemma used geometric relationship lemma contraction contraction norm fixed word know inside hypersphere radius centered hypersphere simply closer note furthest hypersphere lemma fine hypersphere inside true must lemma used mainly lemma characterizes bridgestep meat convergence lemma parameter andj bridgestep approximapapavassiliou russell tion vnew satisfies intuitively bridge land close aimed contraction goal bridge land away relative quantity determines happens angle formed bridge line close bridge close hypersphere able walk bridge make progress walking bridge take closer goal able close show case angle previously hypersphere represents closer applying lemma operator think bridgestep operator take parameter bridgestep closer applying lemma defines much hypersphere depicted case arcsin arcsin note hypersphere hypersphere thus also inside hypersphere closer hold arcsin arcsin achieved contraction even show case angle find hypothesis close fact closest hypothesis rest must away must outside hypersphere depicted closest hypothesis know must inside hypersphere thus separation separation relative noted know lemma vnew satisfies know satisfies lemma satisfies relative vnew achieves contraction decrease thus successive relative also give main guaranteed convergence relative absolute invocation bridgestep thus hypothesis linear specified desired relative absolute desired iteration bridgevaluedet consisting linear hypothesis satisfies relative absolute lemma true absolute iteration contraction absolute requested iteration failed contraction achieved relative iteration last requested relative know lemma iteration satisfies know final answer satisfies relative absolute know satisfies letv bridgevaluedet linear hypothesis firm ping back satisfies relative absolute revisited reconsider main bridgevaluedet take parameter computes lookahead step requested also iteration chooses parameter determines contraction achieved relative established iteration parameter passed bridgestep iteration examine repeated bridgestep iteration repeated bridgestep true relative infinite lemma step achieves contraction converges true revisited bridge repeated bridgestep looking step closely dotted line bridge bridge bridge lemma linear demonstrates lemma fifth bridgestep note contraction exceeds desired relative achieved fact show resulting linear step extend many relying agnostic learning operator practical briefly learning operator hope significantly case learning step done exactly learning step papavassiliou russell actually iteration learning step iteration optimal appealing considering agnostic learning sample unfortunately learn risk stationary distribution markov simply sample steadystate computing sample risk agnostic learning step extending case sample markov expect sample depend mixing time markov variance sample distribution form also extent sample reused risk step iteration even iteration suboptimal learning converge learning operator convergence bridge hold learning operator agnostic learning unfortunately lack agnostic learning risk step intractable beneficial extend learning system optimal weaken learning operator give convergence bridge hold satisfies nondecreasing modification bridge relative errbound note duce fact property agnostic learning used derive intuitively nonexpansion close mapped close papavassiliou russell otter close mapped away mapped opposite obviously weaker requiring success outcome disallows case learned well close learned poorly searching learning unfortunately seems practical learning briefly alternative bridge well mention alternative convex agnostic learning operator nonexpansion verge nonconvex alternative bridge learn convex hull iteration resulting iterated procedure converges nonexpansion unfortunately rithm many agnostic learning step iteration seems practical noniterative optimal answer reduce determination supervised learning operator unlimited lookahead contraction generates iteration looked distribution mean unfortunately empirical evidence suggests sample distribution hard learn many sample perhaps high variance strictly speaking backup even yield sample distribution much variance practical offset need learning step lemma establish convergence rate iterated procedure probably much lookahead step used bridge expect sample many tool used constructing used constructing powerful geometric relationship established lemma geometric intuition proving think many throw bridge many kind bridge throw establish bridge learning arbitrary picked simplify learning little closer establish throw linear bridge learn close line learning linear hypothesis establishing bridge establishing establishing learning strategically located side hypersphere lemma throw planar bridge close onto plane continue considering establish hyperplane learn look like learns full convex hull close averaging closest hypersphere lemma bridge effectively learning close linear namely conclusion reduces determination agnostic learning requesting halt fewer iteration push learning step effectively force infinite lookahead extend bridge suspect convex hull learning thus thought versatile hopefully alternative aggressive feature characterize complication learning abstracted learning operator operator restricted backup operator form linear hypothesis lemma convergence modified endless bridge well missing ingredient justifying sample know sample lookahead case properly trade parameter best stated determination operator contraction norm samplable distribution determination operator backup operator contraction norm stationary distribution markov stated previously distribution sampled exacdy hurdle practical implementable lack agnostic learning applying used developing bridge hope bridge supervised learning theoretically justified ment learning
