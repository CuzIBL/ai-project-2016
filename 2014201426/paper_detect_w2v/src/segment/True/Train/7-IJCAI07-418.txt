show dirichlet process mixture generative data transfer learning hierarchical classic naive bayes classifier couple naive bayes classifier placing dirichlet process parameter show inference dirichlet process mixture inference resulting meeting domain system decides learned user accept reject request behalf outperforms naive bayes data user influence prediction machine learning confronted data asked make prediction spam filtering data thousand labeled email belonging collection user sense data user combine data ignore knowledgethat user labeled email combine data user roughly agree spam increased training data make prediction preference population user heterogeneous expect simply collapsing data undifferentiated collection make prediction worse process data unrelated partially task transfer learning learning growing literature baxter guestrin thrun effortlessly experience task novel task machine must precise make connection statistical task cluster data task cluster identically distributed ultimately sharing must evaluated real data resulting meeting domain learned system decides training data user accept reject request behalf data outperforms counterpart data user influence prediction faced classification task data abound boser lafferty classifier work well practice despite simplicity naive bayes classifier maron extend classifier training classifier cluster latent handle uncertainty cluster membership generative process data induces clustering heart process dirichlet process couple parameter naive bayes classifier attached data extends applicability naive bayes classifier domain learning task bayesian inferenceunderthis clustered naive bayes combine contribution data weighing probability intractable employ work heller ghahramani inference transfer learning concentrate classification feature label drawn finite goal learn relationship feature label predict label unseen feature task training composed label feature vector make concrete task user task feature vector label user collection data user data user data labeled data user data feature take parentlabel take form probability mass data conditioned parameter naive bayes expanded term data reflecting data independentconditioned parameterization step assumes data exchangeable pair parameterization step made naive bayes feature conditionally label step used fact distribution multinomial likelihood parameterizations data parameterized separately surprise likelihood parameterization data data data induce sharing must somehow constrain parameterization user bayesian distribution used enforce resulting joint distribution data introduced specified distribution parameter naive bayes type sharing baseline seen parameterizationof naive bayes ignores data bayesian density parameter density user parameter sharing equivalentto parameter user parameter user graphical clustered naive bayes user parameterization parameter clustered naive bayes drawn dirichlet process integrated independence training collection identical training separately data call specified parameter distribution user must parameter distribution user reasonable tractable distribution multinomial parameter dirichlet distribution conjugate multinomial distribution take distribution take resulting compactly generative discrete discrete baseline alternative induce sharing turn induces sharing clustered naive bayes plausible collection data clustered make precise task data task identically distributed coarse relatedness lead predictive training data step must distribution task property like distribution want exchangeability task user probability depend ordering identity task user want exchangeability cluster probability depend cluster want consistency priori hypothetical existence unobserved task affect probability task clustered chinese restaurant process stochastic process induces distribution satisfies aldous metaphor used process imagine restaurant countably infinite indistinguishable sits arbitrary empty occupied probability proportional seated arbitrary probability proportional parameter resulting seating chart expectation occupied logn antoniak navarro task cluster parameterization extending generative imagine user enters restaurant sits draw parameterization naive bayes base distribution parameterization user sits occupied adopt parameterization everyone rule predicting generative process corresponds well dirichlet process mixture used successfully latent ferguson dirichlet process parameter mixing parameter corresponds parameter base distribution parameter drawn draw parameterization feature distribution decided marginal distribution interested relating feature label compactly generative process discrete discrete discrete draw dirichlet process practice marginalized task clustered clustered naive bayes distribution parameter fcnb make prediction training data inference labelled training data task unlabeled feature vector task like distribution label bayes rule ignoring normalization data imagine data label bayesian inference marginalize parameter latent dirichlet process conjugate base distribution analytically marginalized make inference dirichlet process mixture intractable markov monte carlo variational bayesian hierarchical clustering heller ghahramani approximates greedily generating hierarchical clustering task efficiently summing exponential consistent hierarchy lead achieving transfer rooted binary tree task leaf convenient identify node leaf descending node task subset correspondsexactly nodein graph seen rooted tree strict subset inference marginalize latent requiring work efficiently computing exponential combine subtree intuitively tree carefully capture mass find tree combining bayesian greedy heuristic classic agglomerative clustering duda cluster merges cluster implicitly inconsistent node left collection leaf leaf representable node forming tree merges merging nearest cluster merges cluster maximize statistical hypothesis test step must pair cluster merge next cluster task calculates probability cluster fact cluster hypothesis data identically distributed base case naive bayes probability data cluster simply marginal likelihood data alternative hypothesis data fact cluster computing probability hypothesis normally task clever trick restrict treeconsistent probability data probability data tree probability cluster recursively probability sufficient bayesian prediction data density cluster find pair highest probability merge heller ghahramani show lead inference scheme parameter calculate probability cluster tree built leaf node dleftkdrightk dknk built tree approximates distribution tree probability unseen label unlabeled task node path node root tree note correspond cluster task participates treeconsistent predictive distribution predictive distribution predictive distribution base combining data task cluster computational computation quadratic task heller ghahramani nlogn variant utility type sharing clustered naive bayes assessed real data evaluated prediction meeting classification data collected rosenstein data user industry military training exercise labeled meeting request meeting request user meeting acceptance task predict user accept reject unseen meeting request feature meeting clustered assessed predictive transfer learning predicting label user sparse data labeled data remaining user calculated curve trained training user conditioned label remaining user curve twenty user data training testing plot area curve classification training area curve training size five user varies wrong chance label cluster user user belongs cluster remains omit mention illustrate predictive last demonstrate drop baseline mmmmmmmmppppsspsspppp mmmmmmmmppppppppspsss mmmmmmmmppppppsppspss mmmmmmmmpppppppsspsps progression tree user vertical edge task strongly long vertical edge task unrelated ilitary rofessor user five sample user show able user data make prediction labeled data user military personnel user step make prediction averaging listed largest contribution user step superior predictive user chooses stick user user grouped user initially roughly user witnessed tapered grew fourth user illustrates case performancefor user sample good user cluster last show four case prediction clustered lead worse case user user sample recovers mistake achieves show tree recovered training user increased inspecting fall understandable line military personnel clustered area curve data training data match clustered dotted line grouped military personnel grouped data warrant splitting show relative clustered naive bayes clustered variant outperforms faced roughly equivalently enjoys slight grow work earliest work transfer learning focused transfer neural network network trained data bias learning network novel task caruana pratt idea supervised learning like vector machine dietterich work must done connection kind sharing expect clustered naive bayes work body transfer learning conducted hierarchical bayesian framework distribution used data clustered seen rosenstein achieving transfer naive bayes work dirichlet distribution parameter user unfortunately dirichlet distribution arbitrary bimodal distribution cannothandle cluster parameter handle user modelling density parameter dirichlet process loosely interpret resulting clustered naive bayes grouping task marginal likelihood viewpoint work task relevant attempting transfer thrun ferguson dirichlet process show simply speaking distribution arbitrarily closely dirichlet process successfully generative blei gene dahl scene sudderth introduced hierarchical dirichlet process achieves transfer modeling corpus work closest spirit investigate coupling parameter logistic regression dirichlet process derive variational inference clustered naive bayes dirichlet process parameter naive bayes transfer learning logistic regression discriminative distribution distribution label conditioned take unlabeled data clustered naive bayes data clustered generative defines probability distribution clustered naive bayes used implicit feature distribution predictive distribution must judged task meeting acceptance task generative sharing lead improvedresults conclusion central goal clustered naive bayes meeting acceptance task showed clustered user data prediction even clustered naive bayes dirichlet process couple parameter task applicable collection task data modelled parameterized family distribution generative discriminative suggests clustering parameter dirichlet process worthwhile prediction task deserves next step investigate sharing sophisticated base relax user exactly identical
