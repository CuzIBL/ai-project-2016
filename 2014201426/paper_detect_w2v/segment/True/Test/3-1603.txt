planning agent find desired goal assumed domain explores subjective planning learned agent requiring domain embedding respecting embedding used construct extract agent operator learned learned operator combined find goal efficacy demonstrated challenging domain planning essence searching appropriately consequence agent strip fikes nilsson markov process puterman assumed domain planning find goal built domain studied learning agumenting strip operator wang transition peng williams intuition domain learning planning agent call subjective learned extracted agent ence domain solves learning learning agent agent subjective experience semantic used step process review respecting embedding dimensionality reduction make temporal learns manifold capture dynamic data much fewer dimension addressing next describes learning operator learned addressing learned operator semantic sometimes extracted show planning resulting learned operator resulting plan learned applying plan domain respecting embedding data characterized process generating data data correspond degree freedom moving camera ideal planning capture goal take temporal data find planning nonlinear manifold learning used dataset dimensional semidefinite embedding weinberger saul learns kernel matrix represents closely resembles work learning predictive james rosencrantz work augmenting operator transition probability implicitly dimensionality reduction semidefinite embedding data linear kernel scholkopf smola feature kernel extract data kernel matrix learned semidefinite encode dimensionality reduction nonlinear embedding preserve word nearby remain nearby resulting feature construct neighbor graph semidefinite neighbor preserved optimization maximizes variance learned feature minimize dimensionality take piece data temporal ordering vector label spatially nearby feature also necessarily respecting embedding bowling extends make exactly type data construct neighbor maximize subject kernel learned kernel formally take vector temporal discrete computes vector correspondence vector meaningful embedding dimension modifies temporal build neighborhood graph temporal neighbor constrains embedding label adjacent pair ensures resulting feature enhancement construct neighbor bowling maximize subject kernel learned kernel respecting embedding feature subjective planning constrains learned manifold labeled correspond consisting rotation must preserve learned feature letting feature transformation must case term kernel matrix simply usual arrive optimization imagebot synthetic domain used imagine virtual robot observe patch also take move patch around robot excellent domain subjective planning demonstrated imagebot viewing patch displayed imagebot eight distinct four translation zoom rotation allowed translation forward back left pixel zoom scale rotation rotates left radian distinct data looked imagebot data imagebot imagebot path look like translation imagebot substituting zoom left zoom imagebot move back forth line note move half much zoomed zoomed note opposite used imagebot correspondingly seen data note know label corresponds semantic label effectiveness demonstrated previously bowling evidence capturing planning show manifold test imagebot path show manifold learned test clearly captured path imagebot learned view cylindrical manifold learned data show view side view manifold learned data manifold rotating black line moving forward line circled clear case manifold clearly distinctly capturing path dimension capturing capturing domain extracted obvious manifold learned make resulting planning intuitive operator learns explicit correspond transformation plan need discover transformation collection data pair thinking need learned aaxt recall transformation form encode translation vector rotation scaling matrix learned linear regression scaling scale turn orthonormal procrustes schoenemann carroll scaling regression derived matrix column matrix column goal learn rotation matrix translation formally optimization need minimize baet subject column vector lagrangian aaxa baet aaxa baet matrix lagrangian multiplier stand trace matrix yataaxa ebta ebta aaxa take derivative lagrangian unknown zero translation vector give multiplying aaxatxaata yaxatata baetxatata left hand side symmetric hand side must also symmetric substituting hand side last term symmetric thus rest must also symmetric simplified symmetric transpose satisfies demonstrating operator learned swtwv wtwstv orthonormal diagonal thus dual also feasible regard primal duality hold even show solid arrow show path resulting operator learned clearly operator intuitively capturing essence used data note semantic derived tested pair opposite also tested orthogonality independence learned capture data learned operator maintain relationship successfully hypothesized data note opposite facet data successfully captured learned consequently learned manifold note zoomed zoomed zoomed half never learned operator capture fact scale scale planning operator learned piece planning learned operator learned transition domain data dimensionality drastically demonstrating operator learned label learned give resulting learning orignal intractable imagebot even attain success find shortest path even traverse unobserved part find find shortest path learned operator operator corresponds label orginal list label desired path returned used path final closest desired goal returned path demonstrated imagebot applying showing resulting test show learned data shortest path labelled triangle pointing goal labelled triangle pointing left left show highlighted dotted show goal solid highlight resulting show goal final path note shortest path successfully even moving never seen planning show path learned show outline resulting goal show goal final path note path successfully identifies must jump desired halfway next show goal final path close recall data opposite mean path must rotate around step forward rotate around fairly path conclusion used learn subjective planning lowdimensional capture dynamic operator reflect dynamic recovered procedure used find operator goal learned operator correspond plan plan accurate even unobserved part acknowledgment thank finnegan southey dale schuurmans poupart insight thank wesley helping acknowledge alberta ingenuity fund alberta ingenuity centre machine learning
