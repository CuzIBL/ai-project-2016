game payoff form data sample profile game generalizing data address regression provision capturing symmetry multiagent learning relative utility prescribed payoff demonstrate effectiveness auction analytical form marketbased scheduling game strategic game priorquestion determiningwhat gameactually database game experience specification target learning game shoham agent outcome deterministic game identified systematic exploration agent play profile joint payoff joint nondeterminism handled sampling coordinating exploration joint pose difficult brafman tennenholtz address carefully case commoninterest stochastic game brafman tennenholtz well maintaining equilibrium learning brafman tennenholtz difficulty posed intractably infinite make tractable profile agent allowed play come cost transforming game game entirely seek identify full game restrictive game data entailing approximating payoff supervised learning regression deal continuous agent payoff arbitrary profile adopt form consistent game also admit bias toward form facilitating game equilibrium investigation approximating payoff employing regression explore game incomplete sealed auction player symmetric distribution game krishna analytical form prof benchmarking learning scheduling game reef time slot allocated simultaneous ascending auction milgrom game work identified equilibrium discretized subset preliminary generic normal form game formally expressed unumberi whereof refers player andsi availableis payoffto playerfunctioni siiof andplayertheusetii whens isplayersthe simplexsmjointly mixed play agent payoff mixed profile psmixeds splayerm ingj toiseacha pure addsj probability probability agent jitwill softenj convenient refer pure mixed player separately remaining player player joint player accommodate nash equilibrium concerned game player make simultaneously accrue payoff upon game seem preclude learning experience fact repeated episode allowed long affect opportunity game payoff data also agent playing game simulation hypothetical game case learning relevant despite fact game played faced game agent ideally play best played agent configuration agent play best response constitutes nash equilibrium profile constitutes nash equilibriumof game applies mixed allowed profile constitutes nash equilibrium game uuii devote game exhibit symmetry payoff ssgameji iand usii symmetric game relatively compact computational symmetric game subclass symmetric equilibrium arguably natural kreps avoid need role fairly symmetric game posse symmetric equilibrium nash payoff data describing agent played profile realized deterministic game simply incomplete stochastic outcome randomvariable draw distribution payoff task functiondeviationu fromfroma candidatethe true payoffset minimizingfunction somebecausemeasurethe trueof unknown must base evidence data goal approximating payoff predicting payoff assessing strategic assessing term term dictated evaluated appeal nash equilibrium profile constitutes equilibrium game employ evaluating learning straightforward bestresponse correspondence snashargmax ofsigame letgamesclarityi nash sexposition ithen xswe takeforequilibrium equilibrium true unknown amenable estimating data remainder case restrict symmetric game hypothesis form aggregation agent symmetry adopt remainder payoff agent playing regression considerare played agentsi representsother thansomei aggregationfor thegames simply identity refer form separable lack term combining sthe quadraticwe also term note coincide case employ simpler quadratic take quadratic form analytically nash equilibrium nonseparable quadratic theaggregationseparable ithis interior derive explicit symmetric equilibrium equilibrium necessarily separable guaranteed case learned quadratic concave follow learned quadratic pure nash equilibrium arbitrary symmetric pure profile nash equilibrium difficulty arises degree nash equilibrium case equilibrium arbitrarily regression explored learning regression locally locally quadratic regression atkeson regression infer coefficient data weigh training data case payoff profile data used gaussian training data training case locally simply take payoff training data payoff arbitrary profile locally quadratic regression hand quadratic regression data vector machine regression learning used vector machine svms regarding learning refer interested reader vapnik used package joachim classification regression mixed equilibrium case regression able find analytic robust numeric computing pure nash equilibrium regression learning fortunate access learning interested mixed approximateequilibria ourpolynomialmodelsand yield pure equilibrium learned amenable learned game finite grid find equilibrium resulting finite game employed replicator dynamic fudenberg levine symmetric mixed equilibrium evolutionary treat fixed iteration nash equilibrium learned game aggregation noted payoff dimensional strategyas longprofilesas istheinvariantin sform functionstheunderu payoffsi sdifferent permutation tion symmetric payoff game also symmetric constrain thatin variant preserve symmetry game compact wheresum sthej orderedstrategies inthe thirdpairvariant unaggregated form identity take enforce symmetry last case sort auction fpsb auction game krishna agent valuation good sale simultaneously price representing purchase good bidder naming highest price good offered price agent receive nothing classic analyzed vickrey agent identical valuation distribution distribution bayesian nash equilibrium game agent valuation good note game game oftionsincompleteof restricted case constrained form bactioni kixi thiscorrespondingconstraint transformsto choicetheof real parameter restricted equilibrium full game also equilibrium restricted game agent constrained form case equilibrium fpsb also derive payoff facilitates learning summarized form varying training size separable quadratic training size independently draw training comprises find best separable quadratic find nash equilibrium calculate profile equilibrium payoff repeat process time averaging draw plotted epsilon training form learned payoff agent play learned separable quadratic sample form tried well game quadratic regression outperforms labeled sample best payoff approximated discrete training derived equilibrium simply nash equilibrium discrete training success quadratic surprising payoff piecewise differentiable discontinuity smooth well approximated quadratic apparently overfit data indicated inferior learning displayed game game optimistic view well regression discretization game easy learning payoff well captured lowerdegree eliminated noisy payoff employing payoff scheduling game game investigate significantly difficult learning symmetric game analytic characterization theoretically game hinge incomplete training data simulator sample distribution game scheduling reef agent simultaneous auction resource agent completing note full dependent preference well price history time slot fpsb transform real constraining parametrized form myopic straightforward bidding milgrom modify scalar parameter sunk awareness control agent tendency stick slot winning motivation sunk awareness inessential tradeoff dependent agent optimal investigate learning game collected data theforfor wediscretesymmetry thisof valuesrepresentsk distinct treat sample discrete profile true payoff grid empirical game reef payoff discrete grid profile assembled approximatewe thereforenash training data sample profile regressed quadratic form calculated empirical data computing benefit deviation data maxii maxset ofsiplayersi isrepresented withini wherethe issincethe game symmetric player dropped agent identical nash equilibrium learned close produced replicator dynamic grid post profile simulation agent playing agent deviate equilibrium separable quadratic quadratic replicator dynamic symmetric equilibrium game payoff quadratic trained profile confined comprehensivetrial collected million sample profile learning training discrete grid training profile five twentyone agent grid case profile data estimating pure symmetric equilibrium symmetric game mixture neighbor test designate pure symmetric equilibrium approximated game closest neighbor symmetric data neighbor mixed probability playing note symmetry compact ofdistance neighbor payoff agent thus payoff toagents symmetricplay probabilitym agentssieach sthen bility exactly thus mixed estimating data regression simply selects training pure profile smallest refer sample best differentiating case symmetric pure profile labeled sample best symmetric pure profile labeled sample best separable quadratic effectiveness learning separable quadratic form separable quadratic effectiveness learning quadratic form regression separable quadratic considerably equilibrium size training relatively show quadratic relatively insensitive degree aggregation agent regression employed yield nash equilibrium evaluated four equilibrium regression learning gaussian radial kernel training data mixed equilibrium applying replicator dynamic discrete learned payoff mixed equilibrium produced data equilibrium locally work data five additionally locally regression replicator dynamic four data size consistently beat replicator dynamic data surprising irregular regression irregularity expect even size training data equilibrium necessarily follow effectiveness learning symmetric equilibrium conclusion muchwork gametheoryattemptingto game payoff little approximating data work address payoff introducing regression learning applying game fpsb scheduling game suggest data sparse used replicator dynamic used fixed grid discretized learned game regression noise data mixedstrategy profile exhibit simply smoothing mixture term discrete data regression extend even infinite experience selecting target tractable equilibrium render analytically convenient adopting form capture payoff symmetry facilitate learnability evidence sometimes find serving criterion work expect challenging domain
