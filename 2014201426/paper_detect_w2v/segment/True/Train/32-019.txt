dependency find rule capture statistical dependency multivariate time series categorical data oates cohen rule strength statistic wickens descendant node msdd pruned worst case explore exponentially many rule empirically evaluates addressing size msdd collected process msdd distributes computation machine network dependency msdd rule capture statistical dependency database past dependency time series oates cohen learning probabilistic planning operator oates cohen acquiring rule correlating predicting asynchronous oates size msdd considers empirically utility dmsdd distributes rule machine network remainder core msdd describes reduction summarizes empirical work summarizes database containing token alphabet token vary exactly machine learning rule also dependency pair precursor successor rule construct contingency describes frequency database negated must contingency describes frequency rule strength statistic statistical association indicating expect chance wickens independence probability database time database probability occurrence probability occurrence probability joint independence dependency indicated capture database tell relationship constituent occurrence msdd pair strongest dependency supplied user perhaps msdd rule msdd reported previously rule much rule exactly retained regardless rule root msdd tree empty rule property child node token cursor successor node despite fact msdd highly optimized code capable processing rule database size exponential simply explored exhaustively msdd list strongest dependency rule descendant prune none descendant rule best rule rule pruned work derived msdd find strongest dependency exponential oates cohen good rule early thus pruning early well msdd deepening also memory relatively meager improving rule msdd size fringe dataset vote dataset irvine collection fringe node initially rise sharply reaching peak node nine fall sharply competing force work causing size msdd prune size grows dramatically shallow good rule msdd pruning stop growth eventually reached best rule vast majority rule presence extraneous token pruned take phenomenon msdd stop deepening size fringe fall fraction size limitation fact size fringe peaked resulting final iteration five iteration deepening terminate fifteen fringe node vote dataset rule msdd considers reordering operator fixed child node case msdd operator rule child operator ordered operator child last token expanded child token ordered rule high rule early pruning early token appeared best rule continue token reorder token used token lowest final enhancement take fact size msdd exponential token final best rule priori token eliminated leading potentially reduction size impossible searching identify iteratively looking subset even exhaustive shallow feasible token best rule serve hereafter token oates schmill cohen shallow procedure repeated fixed time deepening remove best rule step fast much many iteration procedure time normally unless true best rule individually token rule containing subset token procedure outlined eventually converge convergence practice iteration procedure empirical show well term find good rule searching utility enhancement msdd datasets irvine collection dataset msdd five time iteration ordering enhancement turned fringe switching deepening fringe fall size reordering sample five iteration sampling five token applying fringe sample time alpha case datasets irvine repository list datasets token dataset show mean node find best rule rule returned mean token constituent reported disparity true best rule rule disparity mean token rule true rule differs best match rule returned note fringe guaranteed find optimal rule thus disparity zero machine learning datasets feature relevant msdd time vote dataset expanded nearly quarter billion node requiring little hour time interestingly virtually identical dataset fringe sample magnitude test comparing mean mean node expanded confirm highly despite fact sample guaranteed find rule unfailingly disparity zero promoter dataset expanded million node requiring little minute time fringe sample significantly indicated test requiring rule sample differed rule dataset substantial overlap mean rule returned former mean true best rule rule returned sample differed optimal rule token lymphography dataset show disparity token rule flare mushroom datasets virtually identical fringe significantly case sample significantly worse made obvious inspecting final rule token list rule returned rapidly causing iteration sampling procedure costly work attempting proceeds stop iterating sampling procedure distributed node msdd node operator msdd enhancement datasets list operator dataset build contingency list best node prune list best node dynamically distribute machine network long machine access best list best list underestimate priming threshold suffer loss admissibility copy list lazily centralized communication distributed server communication user control client connecting computational resource distributed server initiating distribution data server expands root distributes client work searching machine soon node evaluated continues participating searcher processed workload decide rule list rule rating broadcast major distributing dependency computing resource obvious ideal case computation requiring millisecond computing time take millisecond machine message passing overhead idealized difficult goal parallel distributed computation come close realizing goal keep distributed resource busy message passing overhead load balancing made provably optimal loadbalancing priori msdd enumerated reasoned pruning actually searched priori optimality tree sweep procedure many load balancing optimality cook load balancing distinguished distinction made partitioned subsequently distributed computational data functioned distinct computational distributed processing dements data data distributed msdd systematic disjoint node evaluated independently process data partitioned searcher operate independently host need synchronized host oates schmill cohen partitioning take dmsdd distinction distributed made static load dynamic load balancing static load balancing divide data beginning distributed computation static load balancing equates dividing distributed processing dynamic load balancing take progress dynamic load balancing processor agenda offloading work processor node agenda good static make dynamic load balancing unnecessary communication overhead idle explored utility static load balancing sensitive ensures searcher receives node proportional processing consulting database client architecture containing processing database reflect mean node expanded fixed trial take child node parent call operator rule rank rank used size pruned parented rule spacesize node searcher expand rule workload certainly work searcher much work datasets rank spacesize statistic priori spacesize balance sensitive spacesize allocates searcher dynamic load balancing scheme load balancing work dynamic load balancing initiated client detects agenda empty client sends message server indicating take work referred receiver initiated load balancing eventual recipient initiate transfer work server receives work request agenda work offload node server invokes static load balancing rebalance load client server node offload waiting client agenda empty broadcast request work client invoke static load balancing message passing dynamic rebalancing also opportunity load balancing time searcher expended agenda processing machine learning solar flare data dynamic load balancing time unloaded machine mean chess data dynamic load balancing time unloaded machine mean lookup sent server request work msdd term rule discovers oates cohen goal evaluating test hypothesis proportionally computing resource gain loss four node expanded time message node computational expense time millisecond system user time spent behalf msdd reported machine load percentage real time open list machine mean node well message simply tally message sent searcher datasets used ware solar flare dataset chess endgame dataset irvine repository case machine varied five alpha alpha sparclo network message dynamic load balancing turned solar flare dataset chess dataset noted built msdd lisp time node expanded msdd impossible believe qualitatively msdd dynamic load balancing rank static load balancing graph mean show hoped solar flare chess datasets mean show slight decrease processor exhibited case mean time decrease apparently linear fashion processor recall machine processor case alpha approximately time machine processor case ideal case around rank load mean trial solar flare chess data dynamic load balancing scheme achieves high despite relatively poor scheduling static show network message dynamic load balancing scheme message searching solar flare chess datasets linear searcher thousand core msdd capable dependency exponential demonstrated utility rule msdd considers extent database case resulted reduction time willing forgo msdd optimaiity final rule reduction time node expanded magnitude high rule demonstrated distribute msdd networked machine linear machine used acknowledgement government reproduce distribute reprint governmental notwithstanding copyright hereon view conclusion contained herein necessarily representing official endorsement expressed implied defense agency force office government
