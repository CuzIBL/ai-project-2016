bayesian network classifier considerable machine learning bncs demonstrate promise show learning lead many additive bayesian network classifier transfer learning additive learning series framework adopt learn combining parameter thus construct powerful classifier suite benchmark data outperforms many bncs naive bayes achieves comparable performancein boosted bayesian network classifier bayesian network also probabilistic graphical graphically joint probability distribution independence compact directed acyclic graph node correspond domain edge correspond probabilistic dependency pearl bayesian network classifier characterize distribution predict label highest probability bncs successfully many area naive bayesian langley simplest dependence feature ignores dependence feature well data violate independence many bncs overcome limitation sahami framework dependence feature bayesian network friedman tree augmented naive bayes learning learns spanning tree graph learns classification cooper herskovits bncs learning learning task graph best characterizes true density data many criterion bayesian scoring independence test cheng inevitable encounter graph close sense pointed theoretic friedman koller true joint distribution natural aggregating yield much accurate distribution work done thiesson mixture jing boosted bayesian network classifier aggregate series framework additive hastie tibshirani adopt learn combining parameter thus construct powerful learning machine suite benchmark data demonstrate effectiveness rest briefly bncs learning additive bayesian network classifier effectiveness extensive conducted concluding bayesian network classifier bayesian network directed acyclic graph encodes joint probability distribution parent node joint distribution network data bncs characterize joint distribution convert distribution predicting label bayesian network classifier naive bayesian network assumes illustrates graph ignores dependency feature well data violate independence many bncs dependence feature sahami framework dependence bayesian network bayesian classifier bayesian classifier bayesian network feature feature parent mean sahami adopts mutual dependence feature mutual dependence feature employ heuristic rule construct network maximize optimal criterion learning yield keogh pazzani bayesian network spbn assumes acting public parent super parent obvious spbn case illustrates graph spbn spbn adopts classification criterion best network friedman tree augmented naive bayes also case edge naive bayesian network computes mutual feature thus full adjacency matrix employ spanning tree adjacency matrix optimal sense many show significantly outperforms illustrates graph graph cooper herskovits adopts exhaustive learn learning training data learning task directed edge best characterizes true density data learning categorized graph need choosing best avoid overfitting bayesian scoring descriptive friedman learning care edge graph existed case employ independence test edge cheng case face graph edge close used criterion encounter someone natural practice show even case fact sense pointed theoretic friedman koller show many data reasonably well make arbitrary besides grows want learning hope aggregating series simpler weaker much accurate distribution process note scheme learning mixture thiesson ensemble bayesian network averaging rosset segal webb briefly averaging bayesian network true distribution averaging natural combine accurate distribution mixture mdag defines mixture parameter graph bayesian network mdag learns mixture maximizing likelihood data mdag combining mixture learning parameter learning webb case mdag classification dependenceestimation aode aode adopts series fixstructure mixture assumes mixture mdag mixture coefficient practice show aode outperforms naive bayes boosted bayesian network boosting used combining rosset segal employed gradient boosting friedman combine density jing boosted bayesian network classifier adopted adaboost learn coefficient series construct final linear additive coefficient relaxed kept case binary classification loss adaboost friedman additive bayesian network novel scheme aggregate series accurate density true process considerputting framework additive hastie tibshirani additive bayesian network classifier gabn framework linear additive link gabn extensible framework many link link defining taking side expi fact also probabilistic distribution normalization normalization expi likelihood optimization maximizing additive parameter make meaningful tractable parameter final optimization turn lagrange multiplier adopted transfer unconstraint inequation classical interior employed utilizes barrier transfer inequation series unconstraint optimization boyd vandenberghe adopt used logarithmic barrier unconstraint optimization rklog vector barrier step iteration lagrange multiplier iteration step need maximize unconstraint adopted unconstraint optimization unconstraint must gradient gradient easy gradient summation term term gradient summation term computational cost consideration derivative adopted bishop procedure nocedal employed task training interior feasible sequentially adjusts barrier iteration solves series unconstraint training training gabn training training convergence maximal step interior series step optimization calculate employ procedure maxl test barrier term jump else continue loop optimal parameter final series bayesian network unresolved listed step series weak learner many take super parent weak learner reader data public parent node depicts kind mutual removing lowest mutual adopt weak learner gabn parameter probabilistic learning thus omitted note robust parameter laplacian correction mestimate cestnik adopted gabn linear additive boosted gabn much computational sample training hard computational gabn iteration step contrary sequentially learning boosting step lead boosting step magnitude gabn dominates scalable learning task practice also demonstrates gabn combining weaker learner highly extensible framework logarithmic link hard adopt link framework thus many property optimization seamlessly adopted aggregate powerful learning machine evaluates bncs spbn averaging aode tree cart breiman benchmark data machine learning repository newman indicated forbncs data continuous feature adopted discretization transfer discrete feature dougherty employed kept fold final java machine learning toolbox weka witten frank statistical meaningful conducted paired gabn last show significance test illustrates scatter plot gabn classifier gabn outperforms bncs achieves comparable specially note spbn column show best worse gabn demonstrates meaningful aggregating conclusion additive bayesian network classifier gabn gabn avoid nonnegligible bayesian network learning transfer learning additive learning series bayesian network framework adopt learning combine thus construct powerful classifier suite benchmark data demonstrate outperforms many bncs naive bayes achieves comparable boosted bayesian network classifier work gabn framework
