distributed heuristic show admissible give informal load balancing scalability scheduling butterfly multicomputer processor empirically test capable achieving linear processor relatively size heuristic used many artificial intelligence opera feature heuristic high computational significantly practical domain flexible manufacturing strategic planning past many parallel architecture commercially parallel offered greatly computation combinatorial heuristic scale parallelism potentially explored heuristic mainly come intelligent guidance heuristic parallel heuristic multicomputers face tradeoff faithfulness heuristic high communication cost serializes slows computation easy dilemma distributed heuristic parallel show admissible give informal load balancing scalability empirically test flowshop scheduling butterfly multicomputer processor capable achieving linear processor relatively size reader familiar hart work parallel heuristic parallelized storing open list storage accessible processor mohan huang davis queueing show linear processor suddenly matter many processor used kumar concurrent heap data organizing open list data processor interleave operation open improves extent congestion near root concurrent heap kumar substitute blackboard open list processor maintain open list unfortunately blackboard eventually bottleneck processor distributed also tried early work anderson chen distributed hypercube multicomputers balance workload cost distribution open list neighboring processor quinn four hypercubes four tried computation processor communication cost failed effectively time proceeds repetitive synchronized iteration iteration processor synchronized twice procedure node procedure node transfer procedure operation largely processor node huang davis procedure node transfer procedure data distributed avoid bottleneck node node node ordering successor distribution operation parallelized processor processor best heuristic synchronized stop soon reduce overhead node must expanded owing parallelism processor synchronization speculative computation contingently processor trying keep processor productively busy reduce synchronization overhead unnecessary communication avoided long processor worthwhile work reduce communication overhead symmetric successor node distribution used load balancing termination facilitated scalable parallel architecture used architecture pair communicate unspecified communication channel communication channel realized memory message parsing memory referencing memory completed unit time remote communication channel logp time normal balanced traffic processor belief architecture subsume scalable multicomputers commercially butterfly intel hypercube intel connection machine llillis forward reader need sors synchronize node transfer procedure successor node next iteration node procedure also computes broadcast processor cost successor tool node procedure iteration operates processor expands node successor node reception list long processor expanding node processor continues expand best speculative node node expanded synchronization digress processor synchronization node procedure efficiently need barrier synchronization processor processor meet barrier allowed proceed barrier case processor finished expanding unproductive waiting barrier processor continues expand best speculative node waiting memory barrier synchronization processor waiting barrier processor arrived barrier barrier removed atomic operation spot butterfly barrier suggested brook processor synchronize processor pairwise synchronize processor remove spot desired scalability suitable architecture hypercubes well successor successor node processor multiplex fashion precisely successor node processor next successor node processor iteration processor sends successor symmetric help attain desired load balancing successor next iteration optimization made architecture message successor distribution asynchronous computation communication overlapped architecture communication time successor node distributed cached memory sent message size architecture reached node transfer procedure node procedure processor empty node form priority queue next iteration note node transfer procedure communication processor relationship expressed speculative node processor node procedure iteration idle time processor synchronization node goal node processor message broadcast inform processor terminate speculative node goal node node simply optimal goal node terminate failing reach goal node recognized broadcast processor node transfer procedure summarized loop goal node reached empty node procedure processor expand node successor multiplex successor distribution processor expanding node expand best speculative node successor multiplex successor distribution node transfer procedure processor node node speculative node discriminated comparing cost threshold node node speculative node initially successive node procedure huang davis tool attain good load balancing linear main feature contribute load balancing symmetric processor maintains type data type operation interacts processor symmetry probabilistically node tend distribute evenly cost processor plot node expanded processor node left work list processor processor used distribution even processor iteration synchronized procedure node procedure node transfer procedure load balancing procedure load balancing processor kept constantly busy node procedure speculative computation additionally processor waiting time processor synchronization arrangement node expanded nearly processor productive speculative computation iteration evenly distributed processor speculative node argued probabilistically owing symmetric node processor best node processor work list time iteration speculative node node iteration eventually expanded well speculative computation expands type speculative node also productive speculative node expanded tended processor used node node speculative node expanded tend zigzagging attributed parallel anomaly iteration tended decrease processor used empirically show speculative computation productive multiplex successor distribution deterministic worst case size grow linearly processor probability worse case occurring processor fact priori unavailable symmetry close zero recause node expanded final size work list processor expect size node transfer procedure approximately iteration note processor iteration expanded node node expanded iteration load balancing scalability computational combinatorial grow quickly size difficult find million processor scale accordingly multicomputer scalable fxcept successor distribution processor synchronization operation butltrflu barrier suggested brook synchronization scale well increased processor successor distribution accomplished help reception list processor reception list accessed processor legitimate concern contention lead degradation bottleneck reception list processor processor probability placing node reception list recause list reception list huang davis protected expect contention reception list processor practice seriousness processor huang davis elementary queueing expectation proceeds iteratively analyze iteration processor normally ratio time processor processor work processor processor node expanded note fraction work successor processor used work converted nonlocal successor distribution operation assumed scalable multicomputer used converted communication network multicomputer also computation cost processor synchronization butterfly barrier used processor need communicates processor cost expressed plog show communication overhead introduced successor distribution operation processor synchronization overhead affect operation successor distribution fraction heuristic significance processor synchronization overhead inversely proportional synchronization overhead processor expands node iteration exponential argue normally many node iteration traveling salesman size used cost cost cost time processor used fewer node expanded iteration tool processor used huang davis node expanded size benchmarking time reasonable barely effectively utilize processor prom parallel size central queue machine summarized time sign increased processor memory limitation unable processor butterfly tested time time processor close expand node node expanded goal node reached vary widely many node cost optimal cost also parallelization overhead size note processor used remote memory reported time memory butterfly central queue concluding distributed heuristic proved admissible gave informal load balancing scalability scheduling butterfly multicomputer processor encouraging seems linear processor relatively size expect efficiently scalable mult icomputers combinatorial optimization extensively tested many type mult icomputers limitation carefully evaluated test roughly memory fails exponential quickly effectively combined memory multicomputer also vulnerable memory shortage trying exponential developing linear variant investigating connection machine sequel acknowledgement like deeply thank richard korf reviewed critiqued early draft vipin kumar comment early valuable thanks perry thorndyke encouraged
