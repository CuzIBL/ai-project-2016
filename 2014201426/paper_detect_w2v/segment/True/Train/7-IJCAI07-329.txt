learning heuristic controlling forward beam planning domain draw framework structured classification syntactic parsing learning optimization laso laso discriminative learning optimize heuristic computation structured promising domain arise planning tend qualitatively structured classification raise difficulty applying laso planning discriminative learning heuristic planning domain give convergence benchmark domain show discriminatively trained heuristic outperform used planner learning planner idea forward heuristic bonet geffner hoffmann nebel nguyen success progress defining work well domain remain many domain heuristic deficient leading planning failure applicability robustness planningsystems learningmechanisms automatically tune heuristic domain planning experience work applicability machine learning planning target domain discriminative learning acquiring heuristic controlling beam despite benefit learning forward planning heuristic reported success substantial body work learning heuristic control boyan moore dietterich buro virtually work focused optimization cost configuration combinatorial much flavor type domain encountered benchmark planning system demonstrated benchmark domain planning work yoon made progress toward learning heuristic planning domain work focused improvingthe heuristic used hoffmann nebel used linear regression learn heuristic training plan contribution work generic feature procedure allowed learning good regression planning domain showed promising learning shortcoming importantly heuristic learning learning purely approximating training data even learned heuristic poorly used learner make heuristic response learning tightly couple learning procedure iteratively updating heuristic response discriminative sense learn heuristic discriminates good well find goal attempting precisely many area machine learning discriminative outperform counterpart main goal work demonstrate benefit planning learning framework learning optimization laso daume marcu structured classification mapping structured sentence structured syntactic classification posed guided heuristic laso discriminative learning heuristic demonstrated good structured classification structured classification qualitatively planning domain structured classification path planning equally good utility laso clear main contribution learning heuristic convergence empirical planning domain empirical show able learn heuristic heuristic planner show discriminativelearning appearsto havean advantageover give learning planning heuristic next give laso framework structured classification followed laso variant convergenceanalysis learning planning heuristic planning domain planning domain defines term type fact fact name type precondition fact fact representing usual applicable applicable planning domain planning tuple fact representing goal plan planning lead goal view planning directed graphswhere vertex representstates edge transition planning reduces graph path goal learning plan learning heuristic highly successful framework forward statespace planning goal learn heuristic quickly beam beam width training planning domain solves potentially learn heuristic guide width beam hope learned heuristic quickly practically learning heuristic learning heuristic linear feature node feature node feature defining generic feature feature learned must rich capture property wide domain also amenable searching property draw work yoon feature property relaxed plan feature investigation feature work heuristic yoon used learning tuned linear regression predict node training showed promise oblivious heuristic used even heuristic poor guidance training learning main work investigating sophisticated learning tightly integrated process iteratively adapting heuristic response work structured classification upon learning heuristic structured classification structured classification learning mapping fromstructured structuredoutputs tagging goal learn mapping word sentence progress structured classification lafferty perceptron collins optimization taskar alternative daume marcu view structured classification learns heuristic training data structured labeling structured treated searching exponentially tagging word word node pair labeling word learning corresponds inducing heuristic quickly directs node desired framework learningassearch optimization laso demonstrated structured classification serf work laso assumes node descriptive feature tagging feature indicator word labeled time followed labeling heuristic linear feature vector laso guide target integrating learning process training laso conduct guided heuristic made avoid type process repeat convergence stopping convergence stated daume marcu type learning heuristic planning success laso structured classification wider planning recall learning plan training planning target viewed structured classification training planning plan applying laso learn heuristic guide forward find straightforward planning laso framework obvious work well arising planning tackled laso notably good even optimal planning take path goal simply reordering step plan block many good next matter goal tower constructed despite possibility many good laso learn heuristic strictly prefers equally good training raise learning impossible difficult many good inherently identical case simply clear converge good overcoming difficulty many training practical enormous good plan studying computing compact plan laso work continue target much like laso noting practical arise interestingly able derive convergence good relative target variant laso used planning variant beam captured laso planning refer modified procedure laso beam beam beam beam width step resulting beam node step node beam expanded child scored heuristic next beam process continues goal node beam plan beam width many node pruned away resulting inability find beam width tend time linearly beam width leading practical limitation goal work learn heuristic beam replicate viewed form learning discriminative learning learner pair training target planning domain plan training procedure find contained beam said case give learning procedure repeatedly training passing laso arrive procedure terminates remain unchanged cycling user stopping training laso conduct beam beam node empty plan generating beam beam case make preferred heuristic ideally remain beam next time updating rule perceptron daume marcu learning rate parameter feature vector node beam intuitively rule move decrease heuristic preference desired node heuristic node beam beam replaced node continues note call laso guaranteed terminate step generating training heuristiclearn repeat unchanged iteration laso laso planning trajectory vector beam desired node beamexpand everycandidatesn successor returnfor everyhb node lowest heuristic valuenn candidatesw heuristic discriminative learning convergence laso laso guaranteed converge finite iteration solves training extend convergenceresults laso case good used convergence perceptron structured classification collins training node desired path also node reached step node beam beam thatwhere feature vector node stated term existence vector achieves training suited beam framework meaningful vector rank target strictly best look good beammargin triple beam vector beam training size vector beam rank target node node rank node satisfied guaranteed beam width training case corresponds also used laso target ranked node considering case show convergence case dominating vector vector training show laso beam width relative beam guaranteed converge finite mistake vector beam training beam width mistake made laso sketch mistake made mistake made beam target node fact derive induction next beam derive combining noting implying dominating vector mistake reduces depend beam width match stated daume marcu also case beam width allowed thus mistake computational laso computational iteration linearly beam width mistake decrease beam width agrees intuition computation time willing planning time need learn five strip domain block pipesworld philosopher time minute unsolved training trajectory runningboth beam beam width taking best training trajectory block used feature learned work yoon fern yoon domain used learned yoon yoon case heuristic feature used laso learn learning rate philosopher laso iteration learning beam width domain laso iteration learning beam width beam width work well philosopher learning time varied domain trajectory time processing iteration domain domain block bwstates slaney thiebaux thirty block used training data block used testing feature domain heuristic four domain fourth planning computation domain roughly ordered difficulty used training remaining testing heuristic feature pipesworld feature feature feature philosopher beam size give beam domain beam width column correspond four beam heuristic beam heuristic feature laso beam heuristic learned laso learning beam width specified beam heuristic learned linear regression done yoon corresponds beam width show test plan thesolvedproblems beam width decrease beam beam width chance pruning trajectory computational time memory thus fixed time expect decrease laso learning laso tended significantly beam beam block beam width laso solves twice many plan also significantly beam width beam width laso decrease laso solves comparable pipesworld laso best beam width beam width decrease laso consistently solves domain solves slightly laso beam width block plan laso laso pipesworld plan laso laso plan laso laso plan laso laso philosopher plan laso laso five planning domain laso significantly improves block pipesworld block laso improves beam width worse philosopher show laso able heuristic majority domain learning beneficial best laso achieved beam width close used training comparing laso linear regression learning work learned linear regression done yoon utilizing weka linear regression tool resulting learned heuristic column labeled block solves fewer laso beam width solves laso beam width pipesworld laso solves laso beam width slightly worse beam width philosopher outperforms laso beam width laso significantly learning regression utility integrating learning also laso fail converge good domain regression happens work well particularly philosopher domain arbitrarily permuted huge inherently identical laso make training look problematic technically inherently identical mean threshold suggesting poor convergence property reasonably beam width plan laso significantly success rate beam width main goal plan width suboptimal beam ideally like success rate paying price plan investigating improvelaso also note difficulty planning simply find path goal path significantly incomplete plan plan rewriting rule used significantly prune plan ambite thus laso quickly find goal followed fast plan optimization work difficulty applying laso planning qualitative planning structured classification nevertheless preliminary investigation show planning domain laso variant able significantly heuristic plan learning yoon good promise learning heuristic control forward planner also demonstrated failure discriminative significantly worse linear regression suggest work plan extend automatically induce feature investigate sensitivity laso training data guaranteed converge sufficient convergence also interested determiningthe computational learning linear heuristic controlling beam also investigate plan laso convert totally ordered training plan plan help deal many inherently identical experienced domain philosopher plan planning planning probabilistic planning acknowledgment work grant darpa
