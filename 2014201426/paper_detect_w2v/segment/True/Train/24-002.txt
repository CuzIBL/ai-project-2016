spite popularity learning probably approximately learning domain formalizes form learning prof sufficient success form macro caching serial parsing exhibit distinct bias sparseness decomposability show exponential achieved bias suitable domain surprisingly also show computing precondition confirmed domain eight puzzle work suggests best address utility bias domain interested learning learning treat learning improving dejong mooney mitchell system inefficient learning taking pair producing distribution eliminate need satisfactory formal empirical learning variant probably approximately learning valiant haussler system theoretically wellunderstood practical attributed lack adequate firstly clear success system rational decide stop learning satisfactory formalization mean succeed recognize success secondly system lead learning learning rule face utility learned minton utility outweigh reduction learning successful formalization take characterize sufficient guaranteed introduces formal framework learning natarajan tadepalli call framework probably approximately framework analyze form macrooperator learning namely macro caching serial parsing main explication bias exhibited form macro caching serial parsing distinct bias sparse bias macro bias sparse bias domain operator macro bias constructed serially composing series subproblems show domain hypothesis learning system bias lead exponential surprisingly also reveals precondition prediction confirmed serial parsing domain eight puzzle main contribution successful integration work learning also extends korf work learning korf incremental learning work also suggests utility learning bias domain rest introduces macro caching serial parsing eight puzzle domain work final summarizes contribution probably approximately formally analyze need precisely mean learning succeed mitchell sufficient address learning draw formal framework natarajan tadepalli purely empirical learning system also domain form goal operator domain inefficient operationality mitchell viewed defining hypothesis target view learning domain target hypothesis domain tuple choosing operator best suited domain constrained need learning secondly goal operator parameterized glance seriously surprisingly case domain instantiation parameterized operator must cost instantiating exorbitant mean parameterized operator replaced operator take domain like chess parameterized operator move pawn replaced nonparameterized operator move pawn chess show formalization ignores sample size learning time time operator parameterized parameterized proved tadepalli simplicity exposition considers operator deterministic take computes hypothesis domain pair domain learning take specification domain target computes learning protocol domain specification learner teacher selects distribution allowed distribution target hypothesis learning access routine call chooses domain solves target pair learning must domain specification explicit operator need strip formalism goal need fact need declaratively procedure time reasonably thus learning framework learning operator operator applicable lead dead mate high probability seeing reasonable need approximately sense fail probability formally learning hypothesis distribution domain distribution target take specification domain tadepalli parameter confidence parameter call ford probability oracle call time must distribution probability approximates sense fails succeeds size step time size time framework introduced natarajan tadepalli main idea hypothesis natarajan tadepalli powerful oracle oracle natarajan tadepalli capable generating optimal also insist must target hypothesis learning must terminate reasonable computational time probability learning domain sense allowed fail find probability target succeeds tested distribution used training note find necessarily target framework subsumed learning final learning scale reasonably well call framework probably approximately macro caching macro caching characterize sufficient learning macro operator macro caching verifying operator solves explanation step storing operator goal macro domain specification parameter confidence parameter solvable else reset learning stochastic testing scheme rely precondition computation thus macro viewed must tested time work applying macro testing succeeds macro succeeds achieving goal macro fails idea pick extracting macro reasonably learned probably approximately difficulty remains successful learning macro priori know stochastic testing used angluin adapted idea stochastically learning testing tested trained learning terminated soon succeeds consecutive testing scheme slightly test angluin domain distribution satisfies sparse bias operator size intuitively sparse bias operator remembering trying work well operator probability sparseness distribution goal high density goal give case goal block clear block achieved macro null macro macro block held hand macro pick block tower work exponential fact exponential also goal sparse bias domain distribution stochastic testing macro caching learning sketch learner succeed test learner terminate probability learner succeeds test macro fact adequate probability turn terminates prodability probability failure sparse bias macro domain lack macro failure failure satisfies iteration loop seen time macro caching main limitation macro work domain like rubik cube eight puzzle macro distribution sparse serial parsing describes succeed arbitrary distribution exploiting serial decomposability korf make representable vector discrete valued feature feature take rubik cube cubie name cubie eight puzzle tile tile note make difficult domain block domain serially decomposable ordering feature operator domain feature feature feature precede korf rubik cube serially decomposable ordering feature also totally decomposable eight puzzle operator tile tile blank eight puzzle serially decomposable ordering blank feature note serial decomposability property domain well eight puzzle tile serially decomposable fixed goal korf defines macro macro used solvable feature thru goal feature resulting guaranteed goal feature thru korf showed domain serially decomposable reachable solvable also solvable macro korf domain serially decomposable feature ordering move take used macro feature thru goal depend feature full macro appropriately ordered feature used construct backtracking korf satisfies macro bias domain feature ordering serially decomposable construct macro feature macro successively feature applying macro macro feature thru goal solvable macro korfs learning build macro exhaustively searching cell korf thus korfs work characterized learning serial parsing extends work incremental learning macro macro caching stochastic testing call serial parsing extract macro goal serial parsing proceeds beginning varying thru applying operator explanation step collecting operator subsequence parameterization tadepalli storing macro domain serially decomposable feature ordering guaranteed yield macro note macro eliminates need precondition macro eight puzzle primitive operator moving tile left macro made letter notational ease feature tile labeled standing blank tile macro represents move tile goal tile blank numbered tile goal assumed fixed goal serial parser break amples system construct macro work fails macro missing macro stated proved next macro bias domain drrdludruuldrdluuldrurdllurdurdl training eight puzzle distinct feature size feature ordering target learner stochastic testing serial parsing learning sketch stochastic testing terminates probability probability success time polynomially imply existence macro size macro serial parser learn missing macro fails also learner time never need backtrack time relevant parameter show serial parsing serial decomposability compress potentially exponential size macro macro bias teacher composed macro serial parser learn macro macro true composing macro macro fact violated teacher give optimal optimal eight puzzle intractable ratner warmuth macro learned optimal macro learner allowed teacher carefully learn macro time irrespective teacher solves cell macro storing macro eight puzzle serial parsing eight puzzle domain serial parser trained selecting solvable distribution constructing macro giving learner trained stochastic testing training session also tested test rate represents training system time column show column show used last macro learned column show used stochastic testing last macro learned fourth column show used fifth column show macro learned sixth column show rate learning averaged test final column show msec learning averaged sparcstation real full macro macro case macro learned even high increased decreasing system able learn full macro approximately training macro caching macro many perfect learning clear last column suffer utility time fairly decreasing learning able solvable msec time main linear operator goal efficiently avoid overhead work formal framework capture learning cohen analyzes path caching show organizing tree restricting tree improves high probability path caching macro caching learning domain sparse bias defining learning producing opposed simply stringent successful learning framework path caching like macro caching serial parsing fails learn domain like eight puzzle greiner likuski formalize redundant learned rule base hasten greiner likuski recursive domain subramanian feldman learning domain profitable unless made distribution macro caching consistent conclusion also show exploited make learning profitable domain serial decomposability etzioni describes kind nonrecursive explanation explains successful prodigy domain size explanation control heuristic surprisingly etzioni also prodigy successful etzioni etzioni static match prodigy statically analyzing thus even etzioni explains prodigy work fails role system learning show gain well play role distribution determines macro worth learning help learner avoid macro serial parsing subgoals achieved system like soar successfully learn macro goal ordering implicitly defining subgoals laird tadepalli batch parsing learns subgoal ordering macro subgoals idea learn macro column column disambiguate feature corresponds column ichalasani describes serial tadepalli decomposability experimentation consequence formalization blur distinction empirical learning extent also empirical showed system also syntactic bias target main empirical explanationbased seems system also semantic bias hypothesis also constrained consistency domain conclusion main contribution integration formal machine learning explication bias thought work declarative operator crucial hand problemspace distribution also integrated korf work learning work work suggests best utility bias domain worthwhile investigate kind bias natural domain learning empirical learning mean suitable domain bias think best address generality build learning system domain acknowledgment indebted balas natarjan generous help advice throughout work thank prasad char lasani dietterich oren etzioni nick flann sridhar mahadevan mitchell balas natarajan armand prieditis many fruitful also thank barney pell reviewer comment thank walter rudd generous encouragement
