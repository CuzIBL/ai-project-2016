bayesian network widely used discriminative prediction task classification parameter maximization joint likelihood unclear find parameter maximizing supervised likelihood show discriminative learning efficiently bayesian network naive bayes treeaugmented naive bayes showing network discriminative learning exactly logistic regression unconstrained convex parameter hitherto naive bayes logistic regression concave surface optimization year recognized discriminative prediction task classification learning likelihood maximization friedman kontkanen greiner zhou nevertheless bayesian network parameter customarily ordinary maximization joint unsupervised likelihood main discrepancy difficulty likelihood show long bayesian network meet satisfied many bayesiannetwork naive bayes kontkanen domain find likelihood parameter logarithmic reparametrization bayesian network mapped logistic regression likelihood surface concave case parameter logistic regression allowed vary freely word bayesian network corresponds subset logistic regression full main network bayesian network mapped full logistic regression freely varying parameter parametrization concave parameter allowed vary freely convex find likelihood surface optimization hill climbing leaf open possibility network likelihood surface make superfluous show case network likelihood exhibit viewing bayesian network subset logistic regression done heckerman meek greiner zhou also concavity surface logistic regression main contribution supply bayesian network correspond logistic regression freely varying parameter likelihood surface consequence show time supervised likelihood naive bayes bayesian network alternative lparametrization show bayesian network logistic regression logistic regression supervised loglikelihood concave main giving parametrizations correspond exactly learning learning precisely logistic regression dependent covariates distribution configuration indicator thus lexicographically ordered renamed show bayesian network formally identical logistic dependent covariates network lmodel logistic logistic transformation transformation network turn lparametrization concave parameter parameter convex concave strictly concave part obvious parameter take concavity consequence fact logistic regression exponential family mclachlan showing strictly concave wettig proven concavity pose optimization avoided assigning strictly concave parameter maximizing grunwald wettig likelihood also prune weakly parameter arrive strictly concave likelihood surface wettig suggest data sample done case avoid also leave parameter convex subspace full likelihood surface mclachlan therein case strictly concave discusssed likelihood parameter training data used prediction data heckerman meek used competing criterion heckerman meek stated bayesian network difficult used locate show network find even likelihood reparametrizing lmodel optimization thus crucial address next continuous calculus concave likelihood lparameterization also parametrization nevertheless likelihood surface unpleasant property wettig concave worse mean convex subset likelihood surface exhibit nonglobal suggests computationally preferrable optimize empirical evidence reported greiner zhou main distribution also suggests reverse transformation also show distribution also distribution violate lparameterization redundant many distribution case distribution indexed turn network distribution expressed parameter vector case main case satisfies must node child node learning bayesian network satisfying left network naive bayes satisfying left network even case moral node network bayesian network depicted leftmost network satisfies rightmost network show likelihood surface implying case network naive bayes naive bayes friedman latter former child allowed form satisfied naive bayes naive bayes naive bayes child parent child parent case child parent parent also child also automatically satisfied incoming kontkanen bayesian network hold arrive hold rightmost network subset hold main satisfies show suffices likelihood surface easy case likelihood parameter even analytically likelihood surface optimization case hold proven case network depicted data sample likelihood thus superfluous network violate plan address intriguing open work concluding showed effectively find parameter maximizing supervised likelihood many bayesian network showing network satisfies ensures distribution logistic regression unconstrained parameter arbitrary network made thus embed bayesian network independence satisfies test naive bayes case wettig maximizing likelihood usual practice maximizing joint unsupervised likelihood feasible yield greatly classification reported greiner zhou conclusion also data sometimes joint likelihood optimization outperforms likelihood apparently inclined overfitting conjecture case resorting maximizing joint likelihood preferable simpler simplify prune restrict hand parameter discriminative fashion subject
