learning interleaf planning acting agent learn trial respond quickly deployed learning prioritized sweeping learning area magnitude made neighboring empirical test game show substantial learning prioritized learning prioritizes learning competing interleave planning acting time also koenig priori learn transition interacting refining heuristic trial property used pathplanning game virtual reality trainer dini robotics koenig simmons domain agent plan potentially unknown identical task must succession agent opportunity learning task resource collection patrolling learning process learning take minimize learning time converging rapidly build learning realtime make learning experienceefficient prioritizing moore atkeson deemed magnitude made neighboring prioritizing heuristic learning motivated asynchronous dynamic barto time depend upon judicious ordering make affect neighbor giving priority neighbor computation worthwhile rest formally next examine identify shortcoming motivate comprehensive novel property next justify conduct empirical considering tuple finite deterministic transition cost agent said blocked blocked discovered agent visibility radius agent sense transition agent reach goal upon reaching goal agent teleported back commences trial learning agent converged completes trial updating heuristic agent incurs cost cost lowerbounded used safely explorable insomuch goal reachable agent deal uncertainty blocked unblocked belief freespace koenig agent explores learn remember plan accordingly work agent situated time taking incurring cost agent reach goal agent plan leading goal agent plan incompletely execute plan repeat reach goal review agent repair silver plan path goal plan path optimal agent discover planned path blocked stop plan hart time move nlogn dynamic stentz lite koenig likhachev efficiently plan reproduce reduce computation move trial delay negatively affect agent responsiveness interactive game robotics simplest form korf learning neighbor refer heuristic converges optimally korf travel trial learning oscillate unpredictably causing seemingly irrational heuristic weighting learning reduces path instability shimbo ishida bulitko suboptimal neighbor planning move look neighbor deeper lookahead give agent decide next korf lrts bulitko considers radius alternatively koenig goal updating planning learning backtracking help keep close proximity agent shue zamani shue bulitko lrts bulitko physically previously visited potentially trial convergence possibility travel cost alternatively hernandez meseguer mental backup decrease convergence trial difficult combine demonstrates fragile highly combining mental backup sigmundarson bjornsson whiledo stateupdate repeat ifthen stateupdate queue neighbor lowest agent many queue parameter user agent take greedy move repeat process reaching goal koenig koenig heuristic move accelerate convergence process relaxation procedure highly informed heuristic process size used realtime domain koenig likhachev reduce convergence cost prlrts bulitko build hierarchy constrains lowerlevel promising exploration convergence travel move delay cost computation maintain hierarchy exploration line considers sophisticated scheme dynamic barto bradtke note subset cost backed subset determines precise prioritized sweeping reinforcement learning priority moore atkeson high priority queue prioritized sweeping experience moore atkeson core influence novel combine ranked prioritized sweeping deterministic heuristic algorithmic comment agent planning phase acting phase interleaved agent reach goal planning phase agent gain knowlstateupdate find neighbor lowest neighbor addtoqueue lowest cost traveling goal neighbor enqueued addtoqueue queue queuefull find queue smallest queueremove queueinsert else queueinsert inserted queue room queue priority previously enqueued enqueued inserted time queue edge navigate updating heuristic acting phase agent simply greedy next move phase beginning planning phase agent considering neighbor stored next neighbor slated queue priority queue full lowest priority removed spread unseen freespace heuristic series prioritized specified user queue procedure queue remain queue used next planning phase completed planning phase agent move acting phase agent take moving neighboring cost traveling cost traveling closest goal property make feature make learning realtime next convergence well time feature prioritized sweeping parameter restricts potentially entering queue specifies queue size strict memory computational time used enabling process arbitrarily specifies degenerate korf korf size queue agent disallows duplicate queue retains queue acting phase realtime hernandez meseguer koenig koenig agent necessarily contiguous dependent agent property beneficial heuristic affect heuristic many potentially remote empirically limiting propagate unexplored significantly specifies prioritized learning process greedy modified incorporates increased lookahead specified radius bulitko heuristic weighting shimbo ishida bulitko preferentially taking take agent koenig korf korf viewed case barto realtime dynamic rtdp outline trialbased rtdp hold time converges optimal goal heuristic meet criterion convergence barto barto trialbased rtdp converges optimal undiscounted shortest path goal take agent goal probability time time step size queue time come specified potentially queue branching queued hash high priority queued ordered balanced tree memory size memory environmental queue learning priori unknown necessitates keeping track connection also duplicate disallowed queue exceed used system response time user experience time agent make move term touched move last trial agent converged line enables suboptimality final final path optimal path planning time unit traveled planning step producing time step game planning time term touched unit traveled memory consumed heuristic stored heuristic memory used learning heuristic learn trial convergence cost physically traveled agent learning process term traveled agent path converges term cost traveling next note keep planning time touched touched heuristic accessed linear correlation touched wall time five game testbed enabled data resulting path planning competing parameterizations learning agent incurs unit cost moving cardinal cost moving diagonally experimented octile bulitko heuristic precise cost incurred agent obstacle goal initially unknown agent uncertainty handled aforementioned freespace visibility radius agent know planning five lrts base lrts lrts parameter convergence cost size koenig strict parameter queue size koenig size convergence cost averaged plotted optimal convergence cost convergence cost comparable tabulated demonstrate smallest convergence cost heuristic greatest plan goal largest convergence cost simplistic procedure planning heuristic memory suboptimality lrts koenig koenig koenig koenig visibility radius lrts bulitko move planning cost parameterization comparable convergence cost even sophisticated routine show convergence cost convergence cost heuristic learning expense learning heuristic scale expense learning priori unknown queue size convergence cost used explore parameter reveals queue size move exhibit independence affect fixed queue size convergence cost decrease happens queue size fixed demonstrates parameter changing meet time work prioritized invite experimentation explore insight also like extend dynamic parameterization beneficial extra memory convenient take free memory queue size dynamically adjusted benefit sophisticated actionselection scheme purely greedy process simplicity make easy convergence time successfully heuristic bulitko combine prioritized routine powerful extend handle dynamic focused exploration heuristic decrease conclusion incremental meet incremental converge quickly suffer arbitrarily long delay responding work strict computational long interactive learning process reduces applicability good response time fastest meanwhile learning process converges time scale mere agent learn twice fast agent learns step toward learn quickly heuristic combine aggressive heuristic prioritized sweeping ranking priori well suited virtual reality trainer game believable agent acknowledgment like thank nathan sturtevant developing hierarchical open graph simulation framework used empirical also like thank mitja lustrek david thue mous reviewer helpful comment work nserc icore
