                          Exploiting Image Contents in Web Search

                                  Zhi-Hua Zhou     and  Hong-Bin Dai
                          National Laboratory for Novel Software Technology
                               Nanjing University, Nanjing 210093, China
                                  {zhouzh, daihb}@lamda.nju.edu.cn


                    Abstract                          topic using different information modalities with different ad-
                                                      vantages; a user would like to exploit the most convenient and
    Web search is a challenging task. Previous research prominent information modality to comprehend a Web page.
    mainly exploits texts on the Web pages or link in- For example, an author has put a picture of tiger to the Web
    formation between the pages, while multimedia in- page shown in Figure 1; when a user browses this page, even
    formation is largely ignored. This paper proposes without reading the texts on the page, he or she would quickly
    a new framework for Web search, which exploits    understand that the page is about the animal tiger,since
    image contents to help improve the search perfor- the ﬁrst impression of the page comes from a ﬁrst glimpse
    mance. In this framework, candidate images are re- at the vivid image. However, although the importance of
    trieved at ﬁrst by considering their associated text information modalities other than text and link has been
    information. Then, images related to the query are well recognized, only a few works [Woodruff et al., 2001;
    identiﬁed by analyzing the density of the visual fea- Xue et al., 2006] have tried to use them in Web search. In
    ture space. After that, an image-based rank of the particular, few works address the issue of exploiting visual
    Web pages is generated, which is combined with    contents of images to help improve Web search performance.
    the traditional keyword-based search result to pro-
    duce the ﬁnal search result. Experiments demon-
    strate the promise of the proposed framework.

1  Introduction
Web has become the largest information repository over the
world. Due to its huge volume, users easily feel lost and difﬁ-
cult to achieve what they need from the repository. In conse-
quence, research on Web search has attracted more and more
attention.
  Earlier works on Web search mainly focused on exploit-
ing text information since most Web pages contain abundant
text contents. In general, each Web page is treated as a text
document and Web is considered as a huge document collec-
tion. Thus, techniques from conventional text retrieval, such
as Vector Space Model (VSM) [Raghavan and Wong, 1986]             Figure 1: A Web page on tiger.
and TFIDF [Salton and Buckley, 1988],wereemployedto
search for documents with text contents similar to the query. This paper is motivated by the fact that if a Web page
Later, considering that Web is a hyperlinked environment and is judged to be relevant to a query in multiple information
the links between Web pages encode the importance of the modalities simultaneously, then the page has bigger chance
pages to some extent, link information is utilized in many to be really relevant than another page which is judged to be
approaches, such as PAGERANK [Brin and Page, 1998] and relevant in only the text modality. For example, when a user
HITS [Kleinberg, 1999], as a helpful evidence to make the searches for the animal tiger, a Web page containing a tiger
pages which are relevant to the query stand out.      photo as well as the word ‘tiger’ would have a higher chance
  It is noteworthy that in addition to text and link, other to satisfy the query than a page containing the word ‘tiger’
modalities of information, such as image, video and audio, without a tiger picture. In other words, related images in Web
also convey rich and important information about contents of pages are regarded as additional evidence in judging the rele-
Web pages. In fact, Web is a multimedia environment. When vance of those pages in the search process.
possible, the author of a Web page would like to describe the In the proposed WEBSEIC (Web Search Exploiting Image

                                                IJCAI-07
                                                  2928Contents) framework, candidate images are retrieved from one of the images in the page that is both representative of the
Web pages by considering the text information associated to theme of the page and at the same time closely related to the
them at ﬁrst. Then, by analyzing the visual contents of these query. Note that those works mainly use the image modality
images, some images which have a high chance to be relevant to help present the search results, while few works have ad-
to the query are identiﬁed. Based on these related images, dressed the issue of exploiting visual contents of images in
an image-based rank of the Web pages is generated, which the Web search process.
is then merged with a traditional keyword-based rank of the As images and texts in the same Web page are often re-
Web pages to produce the ﬁnal search result.          lated, there are usually some text information partially de-
  The rest of this paper is organized as follows. Section 2 scribing the image contents, such as image names or words
brieﬂy introduces some related works. Section 3 presents the around images, which can be regarded as natural descriptions
WEBSEIC  framework. Section 4 reports on the experiments. for images in Web pages [Harmandas et al., 1997]. Many
Finally, Section 5 concludes.                         works have tried to exploit the relationship between texts and
                                                      images in the same page to identify related images. Coelho et
                                                      al. [2004] extended a Bayesian network for this purpose. By
2  Related Works                                      combining distinct sources of textual descriptions associated
Traditional Web search is based on query term matching since with images, their method achieves better performance than
queries are composed of textual keywords while Web pages using only a single source of textual descriptions. Wang et al.
usually contain abundant texts. Statistics such as term oc- [2004] regarded web images as one type of objects and the
currence frequency are often calculated to examine the text surrounding texts as another type. By constructing the link
contents of Web pages and many techniques from text re- structure and exploiting the mutual reinforcement between
trieval such as VSM [Raghavan and Wong, 1986] and TFIDF them, both visual content and text description are combined
[Salton and Buckley, 1988] have been utilized. Several new for identifying related Web images.
techniques have been developed recently. Considering that
typical documents may contain multiple drifting topics and 3TheWEBSEIC    Framework
have varying lengths, Cai et al. [2004] took a block of a Web
                                                      The WEBSEIC   framework is shown in Figure 2. Given a
page as a single semantic unit instead of the whole page and
                                                      query, WEBSEIC  executes a typical keyword-based search
proposed a block-based Web search strategy. Ntoulas et al.
                                                      1 to obtain a traditional keyword-based rank of Web pages.
[2005] proposed a new Web search engine called Infocious
                                                      Then, it retrieves candidate images from Web pages. Images
which improves the Web search through linguistic analysis to
                                                      having good chance to be relevant to the query are identi-
resolve the content ambiguity of Web pages and to rate the
                                                      ﬁed and used to generate an image-based rank of Web pages.
quality of the retrieved Web page.
                                                      Finally, the image-based and keyword-based ranks are com-
  The links between Web pages have also been utilized in
                                                      bined to produce the ﬁnal rank of the Web pages.
Web search. Page et al. [1998] indicated that Web is a hyper-
                                                        The basic process of WEBSEIC is similar to that of tradi-
linked environment and the links between Web pages encode
                                                      tional Web search except that some additional operations are
the importance of the pages to some extent. Based on this
                                                      required, as highlighted in the grey boxes in Figure 2. The
recognition, the PAGERANK [Brin and Page, 1998] algorithm
                                                      following subsections will describe how to realize these op-
has achieved great success. Kleinberg [1999] investigated the
                                                      erations.
symmetric relationship between Web pages and indicated that
‘good’ pages should have a lot of links coming from ‘good’ 3.1 Retrieving Candidate Images
pages. Based on this recognition, the HITS algorithm [Klein-
berg, 1999] searches for ‘good’ pages recursively. Silva et Several existing approaches can be used to retrieve the candi-
al. [2000] have shown that Web search performance can be date related images. In this paper, the approach developed by
                                                                  [   ]
improved by using both the text and link information simul- Coelho et al. 2004 is employed. This approach attempts to
taneously.                                            retrieve images related to a query from Web pages by combin-
  Multimedia information retrieval has been studied for ing distinct sources of textual descriptions, which generalizes
many years. In particular, many researchers have inves- a Bayesian network-based text retrieval method presented by
                                                                           [    ]
tigated image retrieval from Web [Frankel et al., 1996; Ribeiro-Neto and Muntz 1996 .
                                                            q =(w   1,w 2, ···,w )
Smith and Chang, 1996; Sclaroff et al., 1997; Mukherjea et Let     q   q       qt denote the query which is
                                                                     t                            I (i =
al., 1999]. However, only a few works have been done in represented as a -dimensional textual vector, and i
                                                      1, ···,N)
exploiting the image modality in Web search. Woodruff et       denote the images for which the distinct pieces
al. [2001] proposed to use an enhanced thumbnail to help the of evidence are combined through a disjunctive operator.
                                                          d (i =1,  ···,N)
user quickly ﬁnd the Web pages he or she expects. This en- Let i           denote the text evidences extracted
hanced thumbnail is an image, where the whole Web page is from description tags including ﬁlenames, ALT attribute of
                                                                              s  (i =1, ···,N)
resized to ﬁt into this image and important text is highlighted IMG tag and anchors, and i      denote the
                                         [    ]
in order to be readable for the user. Xue et al. 2006 pro- 1Here we use keyword-based search to denote current search
posed to present image snippets along with text snippets to strategies where a user inputs some keywords to express his/her in-
the user such that it is much easier and more accurate for the formation requirements. Note that keyword-based search usually
user to identify the Web pages he or she expects and to refor- uses text as well as link information and is not an equivalence to the
mulate the initial query. An image snippet of a Web page is simple query term matching.

                                                IJCAI-07
                                                  2929                                                      Figure 3: The top 10 Web images retrieved for the query tiger
          Figure 2: The WEBSEIC framework.
                                                      animal after executing the process described in Section 3.1.

text evidences extracted using surrounding passages. d
                                                  i   mation while the contents of Web pages are rather complex
and s  are all t-dimensional textual vectors, i.e. d =
     i                                        i       and the text descriptions are often ambiguous. For example,
(w  1,w  2, ···,w  ) and s =(w   1,w  2, ···,w  ).
  di,  di,      di,t     i     si,  si,      si,t     an image with the ﬁle name ‘tiger’ could be a photo of an
  Given q, the conditional probability of each source of evi-
                                                      animal, a mask like tiger face, a bottle of tiger-brand beer, or
dence being observed can be computed according to Eq. 1.
                                                      even a picture of a team named ‘tiger’. Figure 3 shows the
                        
                          t   w  w                    top 10 images retrieved according to the above process for
                         k=1 jk qk
         P (ej|q)=                            (1)   the query tiger animal. It can be seen that there are lots of
                       t    2     t    2
                       k=1 wjk    k=1 wqk             irrelevant images. So, in the WEBSEIC framework, the above
                                                      process is only used to retrieve candidates of related images.
where ej could be dj or sj, each representing the correspond-
ing source of text evidences associated with image Ij.For 3.2 Identifying Related Images
convenience, denote these conditional probabilities by Pdjq Given a query, a rank of Web images can be generated by
and Psjq, respectively. Then the conditional probability of
     I                     q                          executing the process described in Section 3.1. Among the
image j being observed, given , can be calculated accord- top-ranked images, such as the top 400 images, there should
ingtoEq.2,whereη  is a normalization factor.          be some relevant images though as indicated above, they may
        (I |q)=   × [1 − (1 −    )(1 −    )]          not rank high due to the ambiguity of text descriptions and
      P   j     η           Pdjq      Psjq      (2)   their complex relationship with images. At the same time,
  In this paper, description tags associated with images and there are also many irrelevant images whose associated text
40 surrounding words are used as sources of text evidences, descriptions looks relevant to the textual query. Since the rank
as recommended by Coelho et al. [2004]. For simplicity is only generated by considering the text information, it is an-
and efﬁciency, only the keywords in the query are considered. ticipated that further analysis on the visual contents of these
Moreover, considering that tiny images are usually advertise- images can help make the relevant images stand out. Tech-
ments or tips, images whose height or width is less than 60 niques from the area of content-based image retrieval (CBIR)
pixels are ﬁltered out.                               [Smeulders et al., 2000] are helpful for this purpose.
  Note that in the original form of Coelho et al.’s approach, In CBIR, each image is represented by a feature vector
text evidences extracted using metatags of Web pages are also which can be regarded as a point in an image feature space.
used. However, Coelho et al. [2004] found in experiments The query image can also be represented by a point in the
that combining description tags and surrounding passages space, which expresses the target concept required by the
only would gain higher precision than including metatags at user. Then, similarities between images and the query image
the same time in Web image retrieval. So, here we do not use can be measured, which yields a rank where the higher the
metatags.                                             rank, the more relevant the image to the target concept. How-
  It is evident that Eq. 2 can be used to estimate the rele- ever, in Web search the query is not an image and therefore
vances of Web images to the query. However, such an esti- the point corresponding to the target concept is not known.
mation is not very reliable since it only utilizes the text infor- Fortunately, considering that all the relevant images should

                                                IJCAI-07
                                                  2930                                                      and 4 it can be found that after executing the process de-
                                                      scribed in this section, the quality of the retrieved images
                                                      have been apparently improved. Greater improvements can
                                                      be anticipated by using stronger features.

                                                      3.3  Generating Image-Based Rank
                                                      After obtaining D, a set of images with the highest densities,
                                                      the center y can be derived by averaging the corresponding
                                                      feature vectors, which is then regarded as the point corre-
                                                      sponding to the target concept.
                                                        On this basis, the visual contents of images in Web pages
                                                      can be exploited as information evidences for Web search.
                                                      For a page containing candidate image, the image-based rel-
                                                      evance of the page to the query can be computed according
                                                      to Eq. 4, where x denotes the d-dimensional feature vector
                                                      corresponding to the image, and σj denotes the standard de-
                                                      viation of the j-th dimension on D.
                                                                             
                                                                                              
                                                                             d                2
                                                                                    1
                                                              ImageRel(x)=            |x  − y |       (4)
Figure 4: The top 10 Web images retrieved for the query tiger                       σ   j    j
animal after executing the process described in Section 3.2.                    j=1  j
                                                        If a Web page contains multiple candidate images, then
be related to the target concept while the irrelevant images its image-based relevance is the biggest ImageRel value of
may be related to different themes though some associated those images; if a Web page does not contain any image, then
texts look similar, the distribution of the top-ranked images its image-based relevance is set to a default value. Then, by
obtained by executing the process described in Section 3.1 ranking the Web pages according to their image-based rele-
can be exploited. Generally, since all the relevant images are vances, an image-based rank of the Web pages is obtained.
related to the target concept, the feature vectors correspond-
ing to them should be relatively close in the feature space; 3.4 Producing Final Rank
while the feature vectors corresponding to the irrelevant im-
                                                      Now we have two ranks for the Web pages, i.e. a keyword-
ages should be relatively scattered since they are related to
                                                      based rank and an image-based rank. The smaller the rank,
different themes. Thus, looking for high density region in
                                                      the higher the relevance. It is evident that since these ranks
the image feature space could be helpful to identify related
                                                      are generated using different information, the combination of
images.
                                                      them would be more accurate and reliable.
  Let C = {x1, x2, ···, x|C|} denote the set of top-ranked
                                                            R (g)    R (g)
candidate images each is represented by a d-dimensional fea- Let k and i   denote the keyword-based rank and
                                                                                   g
ture vector, and z denotes a point in the feature space. This image-based rank of a Web page , respectively. Then, the
                                                                 g
paper employs a simple method to estimate the density [Fuku- ﬁnal rank of can be computed according to Eq. 5, where
                                                      AdaR       AdaR
naga and Hostetler, 1975],asshowninEq.3.                   k and      i are calculated according to Eqs. 6 and 7,
                                                      respectively.
                              d
                        |C| −   |z −x |2
                                 j  ij                                 AdaRk  (g)+AdaRk   (g)
                              j=1                                R(g)=
           Density(z)=     e                    (3)                               2                   (5)
                        i=1
                                                                   
                   
           
  In WEBSEIC, the density of every top-ranked candidate                      1      −1       1
image is estimated according to Eq. 3. Then, the images are AdaRk(g)=                                 (6)
sorted according to their densities and half of the candidate          g Rk(g)+αk        Rk(g)+αk
images with lower densities are ﬁltered out. This process is
repeated until a speciﬁed number of images remain, and these
                                                                   
              −1 
           
images are regarded as relevant images.                                       1              1
                                                        AdaRi(g)=                                     (7)
  Figure 4 shows the top 10 images retrieved for the query              g Ri(g)+αi       Ri(g)+αi
tiger animal after executing the process described in this sec-
tion. Here C contains the top-400 images generated through The ﬁrst terms at the right end of Eqs. 6 and 7 are nor-
the process described in Section 3.1. RGB color histogram malization terms. Note that instead of directly combining the
is used as visual features and each top-ranked candidate im- keyword-based and image-based ranks, αk and αi are used to
age is represented as a feature vector with 3 × 64 dimensions tradeoff their relative contributions. The values of αk and αi
where 64 bins are used for each color. Comparing Figures 3 can be determined empirically.

                                                IJCAI-07
                                                  2931                   Table 1: Precisions of the compared techniques (B: BASELINE,W:WEBSEIC).

  Retrieved  jaguar aircraft     jaguar animal      peafowl bird       penguin shoe       rose ﬂower
  pages     B    W   improv.   B    W   improv.   B    W   improv.   B    W   improv.   B   W    improv.
  Top 10   .700 .800 14.3%    .600 .900 50.0%    .700 .900 28.6%    .400 .500 25.0%    .500 .700 40.0%
  Top 20   .400 .800 100.0%   .600 .900 50.0%    .800 .800  0.0%    .400 .550 37.5%    .550 .650 18.2%
  Top 30   .400 .733 83.3%    .633 .833 31.6%    .667 .800 20.0%    .300 .433 44.4%    .567 .667 17.6%
  Top 40   .400 .725 81.3%    .600 .750 25.0%    .625 .725 16.0%    .325 .400 23.1%    .600 .650 8.3%
  Top 50   .460 .740 60.9%    .600 .780 30.0%    .600 .720 20.0%    .280 .400 42.9%    .560 .600 7.1%

4  Experiments
In the experiments, the Google search engine [Brin and Page,
1998] is used as the baseline for comparison. Moreover, it is
used as the keyword-based search module in the WEBSEIC
framework shown in Figure 2. In other words, we want to see
whether the powerful Google search engine can be improved
by exploiting image contents.
  Fifteen queries are conducted, including albacore ﬁsh, ap-
ple computer, apple fruit, bongo shoe, dove chocolate, eagle
bird, geneva watch, shark ﬁsh, sunset landscape, tiger ani-
mal, jaguar aircraft, jaguar animal, peafowl bird, penguin
shoe,androse ﬂower. The former ten queries are used as
training set on which the parameters αk and αi in Eq. 5 are
determined, while the last ﬁve queries are used as test set.
  For each test query the precision of the compared tech-
niques are evaluated, which is the fraction of the number
of retrieved related page to that of all the retrieved pages. Figure 5: The average test performance of WEBSEIC and
Whether a retrieved page is really related to the query or not BASELINE.
is examined by a human volunteer. Note that the conventional
precision-recall graph is not used here since few users would environment, this paper advocates to exploit multimedia in-
be patient enough to browse more than the top 50 pages. The formation in the Web search process. In particular, this paper
precisions on the top 10, 20, 30, 40, and 50 retrieved Web proposes a new Web search framework, in which the visual
pages are tabulated in Table 1. Here ‘improv.’ denotes the contents of images are exploited to help improve the search
improvement brought by exploiting image contents, which is performance. Experiments show that this direction is promis-
computed by dividing the difference between the precisions ing for designing powerful Web search engines.
of WEBSEIC and BASELINE by that of BASELINE.            Since preparing the experimental data requires substantive
  It can be seen from Table 1 that exploiting image contents human endeavors in determining whether the retrieved pages
in the way of WEBSEIC can apparently improve the Web  are really related to the query or not, in this paper the experi-
search performance. In about 75% cases the improvement is ments are conducted on a limited number of queries. A large
bigger than 25%. Considering that the comparison baseline empirical study involving more human volunteers and more
is the powerful Google search engine, such a result is quite search queries will be executed in the future. Comparing the
impressive.                                           proposed framework with other Web search frameworks is
  Figure 5 depicts the average test performance of the com- also left for future work.
pared techniques. It can be found that for the top two retrieved Note that all the operations in the WEBSEIC framework,
Web pages there is no difference between the precisions of such as retrieving candidate images, identifying related im-
WEBSEIC  and BASELINE. This is easy to understand since ages, generating image-based rank and producing the ﬁnal
the earliest retrieved Web pages are the most relevant pages rank, can be realized in many forms other than those de-
which can usually be easily identiﬁed by pure keyword-based scribed in this paper. In fact, the main purpose of the pa-
search. It can be found from Figure 5 that for later retrieved per is to show that exploiting image contents can bring gains
Web pages, the precision of WEBSEIC is apparently higher to Web search, and therefore the current operations have not
than that of BASELINE, which veriﬁes the helpfulness of the been ﬁnely polished. For example, the current process for an-
exploitation of image contents.                       alyzing the images is not fast enough. Another example is the
                                                      lack of a mechanism to adaptively tradeoff the contributions
5Conclusion                                           of keyword-based and image-based ranks. So, it is evident
In previous research on Web search, the information exploited that investigating effective and efﬁcient realizations of WEB-
were mainly the texts in the Web pages and the link structure SEIC is an interesting issue for future work.
between the pages. Considering that Web is a multimedia Moreover, the current technique is less helpful on abstract

                                                IJCAI-07
                                                  2932