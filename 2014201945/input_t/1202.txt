               TimeML-Compliant Text Analysis for Temporal Reasoning

                              Branimir Boguraev and Rie Kubota Ando
           IBM T.J. Watson Research Center, 19 Skyline Drive, Hawthorne, NY 10532, USA
                             bran@us.ibm.com,        rie1@us.ibm.com


                    Abstract                          sions [Mani & Wilson, 2000], time stamping of event clauses
                                                      [                     ]
                      1                                Filatova and Hovy, 2001 , and temporal ordering of events
    Reasoning with time needs more than just a list   in news [Mani et al., 2003]. Operational question answering
    of temporal expressions. TimeML—an emerging       (QA) systems can now (under certain conditions) answer e.g.
    standard for temporal annotation as a language cap- ‘when’ or ‘how long’ questions [Prager et al., 2003].
    turing properties and relationships among time-     Beyond manipulation of temporal expressions, advanced
    denoting expressions and events in text—is a good content analysis projects are beginning to deﬁne operational
    starting point for bridging the gap between tempo- requirements for, in effect, temporal reasoning. More sophis-
    ral analysis of documents and reasoning with the  ticated QA, for instance, needs more than just information de-
    information derived from them. Hard as TimeML-    rived from ‘bare’ temporal markers [Pustejovsky et al., 2003;
    compliant analysis is, the small size of the only Schilder & Habel, 2003]. Intelligence analysis typically han-
    currently available annotated corpus makes it even dles contradictory information, while looking for mutually
    harder. We address this problem with a hybrid     corroborating facts; for this, temporal relations within such
    TimeML annotator, which uses cascaded ﬁnite-state an information space are essential. Multi-document sum-
    grammars (for temporal expression analysis, shal- marisation crucially requires temporal ordering over events
    low syntactic parsing, and feature generation) to- described across the collection.
    gether with a machine learning component capable
                                                        A temporal reasoner requires a framework capturing the
    of effectively using large amounts of unannotated
                                                      ways in which relationships among entities are described in
    data.
                                                      text, anchored in time, and related to each other. Related are
                                                      questions of deﬁning a representation that can accommodate
1  Temporal Analysis of Documents                     components of a temporal structure, and implementing a text
                                                      analysis process for instantiating such a structure.
Many information extraction tasks limit analysis of time
to identifying a narrow class of time expressions, which This paper describes an effort towards an analytical frame-
literally specify a temporal point or an interval. For in- work for detailed time information extraction. We sketch the
stance, a recent (2004) ACE task is that of temporal ex- temporal reasoning component which is the ultimate ‘client’
pression recognition and normalisation (TERN; see http:// of the analysis. We motivate our choice of TimeML,an
timex2.mitre.org/tern.html). It targets absolute date/ emerging standard for annotation of temporal information in
time speciﬁcations (e.g. “June 15th, 1998”), descriptions of text, as a representational framework; in the process, we high-
intervals (“three semesters”), referential (relative) expres- light TimeML’s main features, and characterise a mapping
sions (“last week”), and so forth. A fraction of such expres- from a TimeML-compliant representation to an isomorphic set
sions may include a relational component (“the two weeks of time-points and intervals expected by the reasoner.
since the conference”, “a month of delays following the dis- We develop a strategy for time analysis of text, a syn-
closure”), making them event-anchored; however, the major- ergistic approach deploying both ﬁnite-state (FS) grammars
ity refer only to what in a more syntactic framework would be and machine learning techniques. The respective strengths
considered as a ‘temporal adjunct’. The TERN task thus does of these technologies are well suited for the challenges of
not address the general question of associating a time stamp the task: complexity of analysis, and paucity of examples of
with an event.                                        TimeML-style annotation. A complex cascade of FS gram-
  Deeper document analysis requires awareness of tempo- mars targets certain components of TimeML (time expres-
ral aspects of discourse. Several applications have recently sions, in particular), identiﬁes syntactic clues for marking
started addressing some issues of time. Document summari- other components (related to temporal links), and derives fea-
sation tackles identiﬁcation and normalisation of time expres- tures for use by machine learning. The training is on a Time-
                                                      ML annotated corpus; given the small—and thus problematic
  1This work was supported by the ARDA NIMD (Novel Intelli- for training—size of the only (so far) available reference cor-
gence and Massive Data) program PNWD-SW-6059.         pus (TimeBank), we incorporate a learning strategy developed                                                       <SIGNAL sid="s1"> On </SIGNAL> <TIMEX3 tid="t1" type="DATE" value=
to leverage large volumes of unlabeled data.           "1998-08-09"> 9 August </TIMEX3> Iran <EVENT eid= "e1" class= "I ACTION">
  To our knowledge, this is the ﬁrst attempt to use the rep- accuses </EVENT> the Taliban of <EVENT eid="e4" class="OCCURRENCE"> taking
                                                       </EVENT> 9 diplomats and 35 truck drivers hostage in Mazar-e-Sharif. The <EVENT
resentational principles of TimeML for practical analysis of eid="e8" class="OCCURRENCE"> crisis </EVENT> <EVENT eid="e12" class=
time. This is also the ﬁrst use of a TimeML corpus as refer- "ASPECTUAL"> began </EVENT> <SIGNAL sid="s2" type="DATE" mod="START"> with
                                                       </SIGNAL> that <EVENT eid="e16" class="I ACTION"> accusation </EVENT>.
ence data for implementing temporal analysis.          <MKINSTANCE eiId="ei1" evId="e1"/> <MKINSTANCE eiId="ei2" evId="e8"/>
                                                       <MKINSTANCE eiId="ei3" evId="e12"/> <MKINSTANCE eiId="ei4" evId="e16"/>
                                                       <TLINK eiId="ei1" relToTime="t1" relType="IS INCLUDED"/>
2  Motivation: Reasoning with Time                     <TLINK eiId="ei4" relToEIId="ei1" relType="IDENTITY"/>
                                                       <ALINK eiId="ei2" relToEIId="ei4" relType="INITIATES"/>
We are motivated by developing a useful, and reusable, tem-
poral analysis framework, where ‘downstream’ applications TimeML is described in Section 3. Essentially, it promotes
are enabled to reason and draw inferences over time elements. explicit representation and typing of time expressions and
  A hybrid reasoner [Fikes et al., 2003], to be deployed in in- events, and an equally explicit mechanism for linking these
telligence analysis, maintains a directed graph of time points, with temporal links, using a vocabulary of temporal relations.
intervals deﬁned via start and end points, and temporal re- In addition to in-line mark-up, explicit links are marked.
lations such as BEFORE, AFTER, and EQUAL POINT. The   Event instance identiﬁers, ei1, ei2, and ei4 refer to, respec-
graph is assumed generated via a mapping process, exter- tively, the accusation in the ﬁrst sentence, the crisis, and the
nal to the reasoner, from a (temporal) text analysis. Rela- reference to “that accusation” in the second sentence. The
tions are operationalised, and temporal algebra evaluates in- relType attributes on the link descriptions deﬁne temporal re-
stances, draws inference over goals, and broadens a base of lationships between event instances and time expressions; in
inferred assertions on the basis of relational axioms. An ex- this particular example, an IDENTITY link encodes the co-
ample within the reasoner’s inferential capability is: referentiality between the event instances (mentions) in the
                                                      two sentences of the accusation event of the earlier example.
 (ﬁnd instances of ?int such that (during ?int 2003)).
                                                        It is the combination of event descriptors, their anchoring
  Reasoning with relations such as during (associating an to time points, and the semantics of relational links, which
event with an interval), costarts (associating two events), in- enable the derivation of during and costarts associations that
stantiated for the example fragment: “On 9 August Iran ac- the reasoner understands.
cuses the Taliban of taking 9 diplomats and 35 truck drivers
hostage in Mazar-e-Sharif. The crisis began with that accu-
sation.” would infer, on the basis of predicates like: 3  TimeML: a Mark-up Language for Time
   (during Iran-accuses-Taliban-take-hostages August-9-1998)
                                                      Most content analysis applications to date do not explicitly
 (costarts Iran-accuses-Taliban-take-hostages Iran-Taliban-Crisis)
                                                      incorporate temporal reasoning, and their needs can be met
that the answer to the question “When did the Iranian-Taliban by analysis of simple time expressions (dates, intervals, etc).
crisis begin?” is “August 9, 1998”.                   This is largely the motivation for TERN’s TIMEX2 tag; at the
  Details of this inferential process need not concern us here. same time it explains why TIMEX2 is inadequate for support-
We gloss over issues like enumerating the range of tempo- ing the representational requirements outlined earlier. 3
ral relations and axioms, describing the reasoner’s model of TimeML aims at capturing the richness of time information
events (e.g. Iran-accuses-Taliban-take-hostages), and elabo- in documents. It marks up more than just temporal expres-
rating its notion of ‘a point in time’ (subsuming both lit- sions, and focuses on ways of systematically anchoring event
eral expressions and event speciﬁcations). Operationally, predicates to a time denoting expressions, and on ordering
a separate component maps temporal analysis results to a such event expressions relative to each other.
suitably neutral, and expressive, ontological representation TimeML derives higher expressiveness from explicitly se-
of time (DAML-Time [Hobbs et al., 2002]). This allows parating representation of temporal expressions from that of
for a representation hospitable to ﬁrst-order logic inference events. Time analysis is distributed across four component
formalism—like the one assumed in Hobbs et al.—to be kept structures: TIMEX3, SIGNAL, EVENT, and LINK; all are ren-
separate from surface text analysis: much like the traditional dered as tags, with attributes [Saur´ı et al., 2004].4
separation along the syntax-semantics interface.
  We start from the belief that the representation for the rea-
                                                         3For a notable extension to TIMEX2, see [Gaizauskas & Setzer,
soner is derivable from a TimeML-compliant text analysis. 2
                                                      2002]. An attempt to codify some relational information linking the
TimeML  is a proposal for annotating time information;e.g.
                                                      TIMEX with an event, it is still limited, both in terms of scope (only
the ﬁrst example sentence above would be marked up as: links with certain syntactic shape can be captured) and representa-
                                                      tional power (it is hard to separate an event mention from possibly
  2We are not alone: work on temporal reasoning from formal in- multiple event instances); see [Pustejovsky et al., 2003].
ference point of view reaches a similar conclusion: “... the [TimeML] 4Additionally, a MKINSTANCE tag embodies the difference be-
annotation scheme itself, due to its closer tie to surface texts, can be tween event tokens and event instances: for example, the analysis
used as the ﬁrst pass in the syntax-semantics interface of a temporal of “Max taught on Monday and Tuesday” requires two different in-
resolution framework such as ours. The more complex representa- stances to be created for a teaching EVENT. Even if typically there
tion, suitable for more sophisticated reasoning, can then be obtained is a one-to-one mapping between an EVENT and an instance, the
by translating from the annotations.” [Han & Lavie, 2004]. language requires that a realisation of that event is created.  TIMEX3 extends5 the TIMEX2 [Ferro, 2001] attributes: (EVENT-TIMEX3) TLINK6 and EVENT  types [Saur´ı et al.,
it captures temporal expressions (commonly categorised as 2004]. TLINK examples are particularly sparse; the data also
DATE, TIME, DURATION), both literal and intensionally spec- shows highly uneven distribution of examples of different
iﬁed. SIGNAL tags are (typically) function words indicative types.
of relationships between temporal objects: temporal prepo- In comparison, the Penn TreeBank corpus for part-of-
sitions (for, during, etc.) or temporal connectives (before, speech tagging contains >1M words (> 16 times larger than
while). EVENT,inTimeML  nomenclature, is a cover term TIMEBANK); the CoNLL’03 named entity chunking train-
for situations that happen or occur; these can be punctual, ing set (at http://cnts.uia.ac.be/conll2003/ner/)
or last for a period of time. TimeML posits a reﬁned typol- has over 200K words with 23K examples (15 times more
ogy of events [Pustejovsky et al., 2003]. All classes of event than TLINK examples) over just 4 name classes (compared
expressions—tensed verbs, stative adjectives and other modi- to the 13 TLINK classes deﬁned by TimeML). TERN’s train-
ﬁers, event nominals—are marked up with suitable attributes ing set—almost 800 documents/300K words—is considered
on the EVENT tag. Finally, the LINK tag is used to encode a to be somewhat sparse, with over 8K TIMEX examples.
variety of relations that exist between the temporal elements
in a document, as well as to establish an explicit ordering of tlink type # occurrences event type # occurrences
events. Three subtypes to the LINK tag are used to represent IS INCLUDED 866      OCCURRENCE  4,452
strict temporal relationships between events or between an   DURING   146              STATE  1,181
event and a time (TLINK), subordination between two events    ENDS    102          REPORTING  1,010
or an event and a signal (SLINK), and aspectual relationship SIMULTANEOUS 69         I ACTION  668
                                                           ENDED BY                   I STATE
between an aspectual event and its argument (ALINK).                  52                       586
                                                             AFTER    41           ASPECTUAL   295
  TimeML’s richer component set, in-line mark-up of tempo-   BEGINS   37          PERCEPTION    51
ral primitives, and non-consuming tags for temporal relations BEFORE  35
across arbitrarily long text spans, make it highly compatible INCLUDES 29
with the current paradigm of annotation-based encapsulation BEGUN BY  27
                                                             IAFTER
of document analysis.                                                  5
                                                           IDENTITY    5
                                                            IBEFORE    1
4  TimeML and Temporal Analysis                              Total : 1,451             Total : 8,243
TimeML’s annotation-based representation facilitates integra-
tion of time analysis with the analysis of other syntactic and/ 4.2 Analytical strategy
or discourse phenomena; it also naturally supports exploita- Minimally, the reasoner would require that the analytical
tion of larger contextual effects by the temporal parser proper framework supports time stamping and temporal ordering of
(see 4.4) . This is a crucial observation, given that the promi- events; thus we target the analysis tasks of ﬁnding TIMEX3’s,
nently attractive characteristic of TimeML—its intrinsic rich- assigning canonical values, marking and typing EVENTs, and
ness of expression—makes it challenging for analysis. associating (some of them) with TIMEX3 tags.
  There are two broad categories of problems for develop- TIMEX3 expressions are naturally amenable to FS descrip-
ing an automated TimeML analyser: of substance and of in- tion. FS devices can also encode some larger context for time
frastructure. Substantive issues include normalising time ex- analysis (temporal connectives for marking putative events,
pressions to a canonical representation (TIMEX3’s value at- clause boundaries for scoping possible event-time pairs, etc;
tribute), identifying a broad range of events (e.g. event nom- see 4.4). To complement such analysis, a machine learn-
inals and predicative adjectives acting as event speciﬁers), ing approach can cast the problem of marking EVENTsas
linking time-denoting expressions (typically a TIMEX3 and chunking. Recently, [Ando, 2004] has developed a frame-
an EVENT), and typing of those LINKs.                 work for exploiting large amounts of unannotated corpora
  The infrastructure problems—small size and less than con- in supervised learning for chunking. In such a framework,
sistent mark-up of the TimeBank corpus—are due to the fact mid-to-high-level syntactic parsing—typically derived by FS
that this, ﬁrst, version is largely a side product of a small num- cascades—can produce rich features for classiﬁers.
ber of annotators trying out TimeML’s expressive capabilities. Thus, we combine FS grammars for temporal expressions,
TimeBank is thus intended as a reference, and not for training. embedded in a general purpose shallow parser, with machine
Our hybrid approach to temporal parsing, combining ﬁnite- learning trained with TimeBank and unannotated corpora.
state (FS) recognition with machine learning from sparse data
(4.2), is largely motivated by this nature of TimeBank. 4.3 FS-based parser for temporal expressions
4.1  The TimeBank corpus                              Viewing TIMEX3 analysis as an information extraction task,
                                                      a cascade of ﬁnite-state grammars with broad coverage (com-
TimeBank has only 186 documents (68.5K words). If we  piled down to a single TIMEX3 automaton with 500 states and
held out 10% of the corpus as test data, we have barely over 16000 transitions) targets abstract temporal entities such
over 60K words for training. Below we show counts of
                                                         6In all of our experiments we exclude TIMEX3 markup in meta-
  5TIMEX2 and TIMEX3 differ substantially in their treatment of data; the TLINK counts only reﬂect links to temporal expressions in
event anchoring and sets of times.                    the body of documents.as UNIT, POINT, PERIOD, RELATION, etc; these may be fur- Most of the above is self-explanatory, but we emphasise a
ther decomposed and typed into e.g. MONTH, DAY, YEAR (for few key points. The analysis captures the mix of syntactic
a UNIT); or INTERVAL or DURATION (for a PERIOD).      chunks, semantic categories, and TimeML components used
  Fine-grained analysis of temporal expressions, in-  for feature generation. It maintains local TIMEX3 analysis;
stantiating attributes like granularity, cardinality, the time expression is inside of a larger clause boundary, with
ref direction, and so forth, is crucially required for nor- internal grammatical function identiﬁcation for some of the
malising a TIMEX3: representing“the last ﬁve years” as il- event predicates. The speciﬁcs of mapping conﬁgurational
lustrated below facilitates the derivation of a value for the information into feature vectors is described in Section 5.
TIMEX3 value attribute.
          [timex : [relative   : true ]               4.5  Machine learning for TimeML components
                  [ref_direction : past ]             TimeML parsing is thus a bifurcated process of TimeML com-
                  [cardinality : 5 ]                  ponents recognition: TIMEX3’s are marked by FS gram-
                  [granularity : year ] ]             mars; SIGNALs, EVENTs and LINKs are identiﬁed by clas-
  Such analysis amounts to a parse tree under the TIMEX3. siﬁcation models derived from analysis of both TimeBank
(Not shown above is additional information, anchoring the and large unannotated corpora. Features for these models
expression into the larger discourse and informing other are derived from common strategies for exploiting local con-
normalisation processes which emit the full complement of text, as well as from mining the results—both mark-up and
TIMEX3 attributes—type, temporalFunction, anchorTimeID, conﬁgurational—from the FS grammar cascading, as illus-
etc). TimeBank does not contain such ﬁne-grained mark-up: trated in the previous section. (More details on feature gener-
the grammars thus perform an additional ‘discovery’ task, for ation follow in Section 5 below.)
which no training data currently exists, but which is essen- Classiﬁers and feature vectors
tial for discourse-level post-processing, handling e.g. ambigu-
                                                      The classiﬁcation framework we adopt for this work is based
ous and/or underspeciﬁed time expressions or the relationship
                                                      on a principle of empirical risk minimization. In particular,
between document-internal and document-external temporal
                                                      we use a linear classiﬁer, which makes classiﬁcation deci-
properties (such as ‘document creation time’).
                                                      sions by thresholding inner products of feature vectors and
4.4  Shallow parsing for feature generation           weight vectors. It learns weight vectors by minimizing clas-
In principle, substantial discourse analysis can be carried out siﬁcation errors (empirical risk) on annotated training data.
from a shallow syntactic base, and derived by means of FS For our experiments (Section 6), we use the Robust Risk
cascading [Kennedy & Boguraev, 1996]. Our grammars in- Minimization (RRM) classiﬁer [Zhang et al., 2002], which
terleave shallow parsing with named entity extraction. They has been shown useful for a number of text analysis tasks
specify temporal expressions in terms of linguistic units, as such as syntactic chunking, named entity chunking, and part-
opposed to simply lexical cues (as many temporal taggers to of-speech tagging.
date do). This point cannot be over-emphasised. One of the In marked contrast to generative models, where assump-
complex problems for TimeML analysis is that of event iden- tions about features are tightly coupled with algorithms,
tiﬁcation. A temporal tagger, if narrowly focused on time ex- RRM—as is the case with discriminative analysis—enjoys
pressions only (cf. [Schilder & Habel, 2003]), offers no clues clear separation of feature representation from the underlying
to what events are there in the text. In contrast, a tempo- algorithms for training and classiﬁcation. This facilitates ex-
ral parser aware of the syntax of a time phrase like “during perimentation with different feature representations, since the
the long and ultimately unsuccessful war in Afghanistan” is separation between these and the algorithms which manipu-
very close to knowing—from conﬁgurational properties of a late them does not require change in algorithms. We show
prepositional phrase—that the nominal argument (“war”)of how choice of features affects performance in Section 6.
the temporal preposition (“during”) is an event nominal. Word proﬁling for exploitation of unannotated corpora
  Ultimately, syntactic analysis beyond TimeML components In general, classiﬁcation learning requires substantial amount
is used to derive features for the classiﬁers tasked with ﬁnding of labeled data for training—considerably more than what
EVENTs and LINKs (Section 5).                         TimeBank offers (cf. 4.1). This characteristic of size is poten-
  Feature generation typically relies on a mix of lexical prop- tially a limiting factor in supervised learning approaches. We,
erties and some conﬁgurational syntactic information (de- however, seek to improve performance by exploiting unan-
pending on the complexity of the task). Our scheme addi- notated corpora, with their natural advantages of size and
tionally needs some semantic typing, knowledge of bound- availability. We use a word proﬁling technique, developed
aries of longer syntactic units (typically a variety of clauses), specially for exploiting a large unannotated corpus for tag-
and some grammatical function. An example (simpliﬁed) of ging/chunking tasks [Ando, 2004]. Word proﬁling identiﬁes,
the FS cascade output is:                             and extracts, word-characteristic information from unanno-
[Snt [svoClause                                       tated corpora; it does this, in essence, by collecting and com-
  [tAdjunct In [NP [timex3 the 1988 period timex3] NP] tAdjunct], pressing feature frequencies from the corpus.
  [SUB [NP the company NP] SUB]                         Word proﬁling turns co-occurrence counts of words and
  [VG [GrmEventOccurrence earned grmEventOccurrence] VG] features (e.g. ‘next word’, ‘head of subject’, etc) into new
  [OBJ [NP [Money $20.6 million Money] NP] OBJ] svoClause] ... Snt] feature vectors. For instance, observing that “extinction” and
                                                      “explosion” are often used as syntactic subject to “occur”,and that “earthquakes” “happen”, helps to predict that “ex- between an EVENT and a TIMEX3, we ask whether it is a cer-
plosion”, “extinction”, and “earthquake” all function like tain type of TLINK. This deﬁnes a ( +1)-way classiﬁcation
event nominals. Below (6.1) we demonstrate the effective- problem, where  is the number of TLINK types (BEFORE,
ness of word proﬁling, speciﬁcally for EVENT recognition. AFTER, etc; Section 4.1). The adjustment term ‘+1’ is for
                                                      the negative class (not-a-temporal-link).
5  Implementation                                       The relation-extraction nature of the task of posting
                                                      TLINKs requires a different feature representation, capable
To use classiﬁers, one needs to design feature vector repre-
                                                      of encoding the syntactic function of the relation arguments
sentation for the objects to be classiﬁed. This entails selection
                                                      (EVENTs and TIMEX3’s), and some of the larger context of
of some predictive attributes of the objects (in effect promot-
                                                      their mentions. To that end, we consider the following ﬁve
ing these to the status of features) and deﬁnition of mappings
                                                      partitions (deﬁned in terms of tokens): spans of arguments
between vector dimensions and those attributes (feature map-
                                                      (P 1orP 2); two tokens to the left/right of the left/right argu-
ping). In this section we describe the essence of our feature
                                                      ment (P left/P right); and the tokens between the arguments
design for EVENT and TLINK recognition. 7
                                                      (P middle). From each partition, we extract tokens and parts-
5.1  EVENT  recognition                               of-speech as features.
Similarly to named entity chunking, we cast the EVENT
recognition task as a problem of sequential labeling of tokens
by encoding chunk information into token tags. For a given
class, this generates three tags: E:class (the last, end, token We also consider segments (syntactic constructions derived
of a chunk denoting a mention of class type), I:class (a to- by FS analysis: ‘when-clause’, ’subject’, etc) in certain re-
ken inside of a chunk), and O (any token outside of any target lationship to partitions: contained in P 1, P 2, or P middle;
chunk). The example sequence below indicates that the two covering P 1 (or P 2) but not overlapping with P 2 (or P 1);
tokens “very bad” are spanned by an event-state annotation. occurring to the left of P 1 (or the right of P 2); or covering
                                                      both P 1 and P 2. We use uni- and bi-grams of types of these
 ···another/O very/I:event-state bad/E:event-state week/O ···
                                                      segments as features.
  In this way, the EVENT chunking task becomes a (2k +1)- In this feature representation, segments play a crucial
way classiﬁcation of tokens where k is the number of EVENT role by capturing the syntactic functions of EVENTs and
types; this is followed by a Viterbi-style decoding. (We use TIMEX3’s, as well as the syntactic relations between them.
the same scheme for SIGNAL recognition.)                Thus in the example analysis on p. 4, svoClause is the
  The feature representation used for EVENT extraction ex- smallest segment containing both an EVENT and a TIMEX3,
periments mimics the one developed for a comparative study indicative of a direct syntactic relation between the two. In
of entity recognition with word proﬁling [Ando, 2004]. The the next example, the TIMEX3 and EVENT chunks are con-
features we extract are:                              tained in different clauses (a thatClause and a svoClause,
 ◦ token, capitalization, part-of-speech (POS) in 3-token respectively), which structurally prohibits a TLINK relation
   window;                                            between the two.
 ◦ bi-grams of adjacent words in 5-token window;       [Snt
 ◦ words in the same syntactic chunk;                   Analysts have complained
 ◦ head words in 3-chunk window;                        [thatClause that [timex3 third-quarter timex3] corporate earnings
 ◦ word uni- and bi-grams based on subject-verb-object and have n’t been very good thatClause]
   preposition-noun constructions;                      [svoClause , but the effect [event hit event] ... svoClause] Snt]
 ◦ syntactic chunk types (noun or verb group chunks only); Thus our feature representation is capable of capturing this
 ◦ token tags in 2-token window to the left;          information via the types of the segments that contain each of
 ◦ tri-grams of POS, capitalization, and word ending; EVENT  and TIMEX3 without overlapping.
 ◦ tri-grams of POS, capitalization, and left tag.
                                                      6   Experiments
5.2  TLINK recognition
                                                      We present here performance results on EVENT and TLINK
TLINK is a relation between events and time expressions
                                                      recognition only. This is largely because the primary focus of
which can link two EVENTs, two TIMEX3’s, or an EVENT and
                                                      this paper is to report on how effective our analytical strategy
a TIMEX3. Presently (see 4.2) we focus on TLINKs between
                                                      is in leveraging the reference nature of the small TimeBank
events and time expressions.
                                                      corpus for training classiﬁers for TimeML. Of these, SIGNAL
  As a relational link, TLINK does not naturally ﬁt the tag-
                                                      was brieﬂy mentioned earlier (see footnote 7), and TIMEX3
ging abstraction for a chunking problem, outlined above. In-
                                                      recognition, driven by FS grammars, belongs to a different
stead, we formulate a classiﬁcation task as follows. After
                                                      paper. Since this is the ﬁrst attempt to build a TimeML-
posting EVENT and TIMEX3 annotations (by the event classi-
                                                      compliant analyser (cf. Section 1), there are no comparable
ﬁer and the FS temporal parser, respectively), for each pairing
                                                      results in the literature.
  7We do not discuss SIGNAL recognition here, as the signal tag The results (micro-averaged F-measure) reﬂect experi-
itself contributes nothing to EVENT or TLINK recognition, beyond ments with different settings, against the TimeBank corpus,
what is captured by a lexical feature over the temporal connective. and produced by 5-fold cross validation.