                         Relational    Object   Maps    for  Mobile   Robots

                          Benson   Limketkai   and  Lin Liao  and  Dieter Fox
                           Department  of Computer   Science and Engineering
                                       University of Washington
                                           Seattle, WA 98195

                    Abstract                            Recently, Anguelov and colleagues made important steps
    Mobile robot map building is the task of generat- toward building such maps by developing techniques for de-
                                                                                                [
    ing a model of an environment from sensor data.   tecting and labeling objects in metric maps. In Anguelov
                                                                 ]
    Most existing approaches to mobile robot mapping  et al., 2002 , they showed how to learn models of non-
    either build topological representations or generate stationary, free-standing objects such as rectangular or round
    accurate, metric maps of an environment. In this  boxes. To overcome the limitations of this technique, they
    paper we introduce relational object maps, a novel then developed a generative Bayesian approach for detect-
                                                                                              [
    approach to building metric maps that represent in- ing doors and walls in a hallway environment Anguelov et
                                                              ]
    dividual objects such as doors or walls. We show  al., 2004 . While this approach yields good results for la-
    how to extend relational Markov networks in or-   beling line segments extracted from laser range-scans, it has
    der to reason about a hierarchy of objects and the limited capabilities in modeling context information. Even
    spatial relationships between them. Markov chain  though the approach can express information such as all doors
    Monte Carlo is used for efﬁcient inference and to share the same width and color, it can not model more com-
                                                                                               [
    learn the parameters of the model. We show that the plex, spatial relationships between objects. As Murphy et
                                                             ]
    spatial constraints modeled by our mapping tech-  al., 2003 showed for scene analysis in computer vision, such
    nique yield drastic improvements for labeling line context information can be extremely useful for distinguish-
    segments extracted from laser range-ﬁnders.       ing between different types of objects. In mobile robot map
                                                      building, for example, an object standing in the middle of a
                                                      hallway cannot be a door, even if it has the same width and
1  Introduction                                       color as other doors in the hallway.
Building maps of indoor spaces is an extremely important
task in mobile robotics. Over the last years, the SLAM (si- In this paper, we show how to reason about the appear-
multaneous localization and mapping) community has made ance of and spatial relationships between objects so as to
tremendous progress in the development of efﬁcient and build metric maps with object representations. We denote
highly accurate map building techniques. Most of these the resulting mapping paradigm Relational Object Maps, RO-
techniques focus either on capturing the metric layout of Maps for short. RO-Maps build on Relational Markov Net-
an environment with high accuracy [Eliazar and Parr, 2003; works (RMN) to represent hierarchical structure and the re-
Konolige et al., 2005] or on representing the topological lationships between objects. RMNs are undirected graphical
structure of an environment [Kuipers, 2000]. While metric models that are learned discriminatively [Taskar et al., 2002].
maps have the advantage of being well suited for robot nav- They provide an extremely ﬂexible framework for describing
igation tasks, they are typically unstructured and contain no and reasoning about relations. Our RO-Maps detect objects
information about the different types of places or objects in such as doors and walls by a combination of features, includ-
an environment. Topological approaches, on the other hand, ing appearance features such as the width of a door, neigh-
are more compact and expressive in that they describe signif- borhood features describing what type of objects are next to
icant places in an environment. However, these techniques each other, and spatial features such as the indentation of a
often ignore valuable metric information and they still lack door relative to the wall. In our experiments we show that the
the ability to describe individual objects in an environment. parameters of RO-Maps can be learned from a set of hallways
  Our goal is to build on the progress made in metric map- and then be successfully applied to labeling the objects in a
ping and to enhance metric maps with semantic informa- hallway of a different environment.
tion about different objects in an environment. Object-based
representations have much higher expressive power in that This paper is organized as follows. After providing back-
they combine metric accuracy with a semantic description of ground on RMNs, we will show how RO-Maps model object
an environment. In addition to allowing more natural inter- appearance and the spatial relationships between them. Infer-
faces between humans and robots (“take the third door on the ence and parameter learning will be discussed in Section 3.
right”), they enable robots to perform better reasoning, espe- Experimental results are presented in Section 4, followed by
cially about dynamic objects such as doors.           conclusions and a discussion of future work.                                                                        1
2  Relational  Map   Building                                      =                 exp{wT  · f (v )} (2)
                                                                       Z(x) Y    Y         C  C   C
This section describes RMNs and several extensions that                     C∈C vC ∈C
make them applicable to the problem of mobile robot map                 1
                                                                   =        exp{wT · f},              (3)
building. We denote the resulting framework RO-Maps, short             Z(x)
for relational object maps.
                                                      where  the  normalizing partition function Z(x)  =
2.1  Relational Markov  Networks                                            0
                                                         0   ∈C   v0 ∈ φC (v ).  (3) follows by moving the
                                                      Py  QC    Q  C C      C
We  will now brieﬂy review the basic ideas of relational products into the exponent and combining all summations
Markov networks, more detailed information can be found into w and f.
  [                ]
in Taskar et al., 2002 . RMNs are an extension of Condi- For efﬁcient inference in RMNs, [Taskar et al., 2002] sug-
tional Random Fields (CRFs), which are undirected graphical gest using (loopy) belief propagation. However, because of
                                              [
models that were developed for labeling sequence data Laf- the extensions described below, we cannot apply belief prop-
              ]
ferty et al., 2001 . CRFs are discriminative models that have agation directly. Instead, we will show how to perform efﬁ-
been shown to out-perform generative approaches such as cient inference and learning using MCMC.
HMMs   and Markov random ﬁelds in areas such as natural
                 [                 ]
language processing Lafferty et al., 2001 and computer vi- 2.2 Relational Object Maps
sion [Kumar and Hebert, 2003]. RMNs extend CRFs by
providing a relational language for describing clique struc- In the most general form, RO-Maps represent an environment
tures and enforcing parameter sharing at the template level. by a hierarchical collection of objects and relations between
Thereby RMNs are an extremely ﬂexible and concise frame- them. RO-Maps estimate the types of objects under the as-
work for deﬁning features and relationships that can be used sumption that their locations are known. This assumption
in our map building context.                          is justiﬁed by the progress made by the SLAM community,
  Speciﬁcally, an RMN consists of three parts: a schema E which focuses on the problem of concurrently estimating the
for the domain, a set of relational clique templates C, and pose of a robot and the locations of sensor measurements.
corresponding potentials Φ. The schema E speciﬁes the set Such techniques generate well aligned laser range-scans even
of classes (i.e., entity types) and the attributes in each class. for large scale environments (e.g., [Eliazar and Parr, 2003;
In the map building context, the classes are types of objects, Konolige et al., 2005]).
such as walls or doors, and the attributes describe their phys- We introduce an extension of the relational framework of
ical properties. An instantiation I of a schema speciﬁes the RMNs to reason about physical objects in RO-Maps. The
set of entities for each class and the values of all attributes RO-Map of a speciﬁc environment is modeled by an unrolled
for each entity. In our case, I is an RO-Map consisting of Markov network. Each node in such a network corresponds to
line segments extracted from laser range-scans. A relational an object or geometric primitive, and the links between nodes
clique template C ∈ C is similar to a query in a relational represent relations between these objects.
database. It selects tuples from an instantiation I; the query
                                                      Objects: The basic building blocks of RO-Maps are geo-
                 C(I)
result is denoted as  . In an RO-Map, for example, a      metric primitives such as line segments extracted from
clique template can select all wall or door objects on one side sensor data. These primitives typically describe objects
of a hallway.                                             such as doors or wall segments. More complex objects
                    C
  Each clique template is associated with a potential func- can be generated from existing ones by a process we call
   φ  (v  )              v
tion C  C  that maps values C of variables in the clique to physical aggregation. This process ﬁrst selects all ob-
non-negative real numbers. Using a log-linear combination jects with a certain property (just like relational clique
of feature functions to deﬁne these potentials, we get the fol-
                                   T                      templates do in RMNs), and then computes the param-
lowing representation: φC (vC ) = exp{wC ·fC (vC )}, where
                                  T                       eters of the aggregated object. For example, physical
fC () deﬁnes a feature vector for C and wC is the transpose of aggregation generates a wall object by selecting all wall
the corresponding weight vector. For instance, a feature could segments on one side of a hallway, followed by the com-
be the indentation of a door, deﬁned on a clique template se- putation of the line parameters and color distribution de-
lecting a door and wall objects on one side of a hallway. scribing the wall. The left and right wall of a hallway
  For a speciﬁc instantiation I, an RMN deﬁnes a condi-   can be aggregated into a hallway object, which has pa-
tional distribution p(y|x) over labels y given observations rameters such as orientation and width.
x. To compute the conditional distribution of a label vec-
tor y, the RMN generates an unrolled Markov network, in Relations between objects can be spatial, such as “distance
which the nodes correspond to the entities. The cliques of the from each other”, or appearance based, such as “similar
unrolled network are built by applying each clique template color”. Relations can be deﬁned on basic objects and ob-
C ∈  C to the instantiation, which can result in the genera- jects generated by (multiple) physical aggregations. Re-
tion of several cliques per template. All cliques that originate lational clique templates of RMNs can be used to de-
from the same template must share the same weights wC .   ﬁne RO-Map  relations. For example, to consider the
The resulting cliques factorize the conditional distribution as similarity between the widths of the doors in a hallway,
                                                          RO-Maps  use a clique template C that ﬁrst selects all
                  1
   p(y | x) =                  φ (v  )          (1)       objects that are labeled as doors (such selections are de-
                Z(x)  Y    Y    C  C
                     C∈C  vC ∈C                           ﬁned via SQL queries on the objects [Taskar et al., 2002;                                                               Width
                                                      Width     Width


                                           Indent     Indent

                                            Wall object

Figure 1: Upper graph: Endpoints of laser range-scans observed in a hallway. The points line up very accurately due to the position correction
performed by a scan matching procedure. Middle graph: Line segments extracted from the scans. Wall segments are shown as dashed lines,
doors as solid lines, others as thin black lines. Lower ﬁgure: Markov network with example cliques generated for this speciﬁc labeling. Thin
solid lines deﬁne neighborhoods. The doors in the upper part of the hallway are linked by the door variance clique template. The wall object
is generated by physical aggregation (dashed lines). It is linked to doors by the door indentation clique template (solid lines).

    Liao et al., 2005]). The widths of the selected doors de- speciﬁc cliques, we use Gibbs sampling, an MCMC tech-
    ﬁne the value vector vC of this clique, which is then nique, for inference [Gilks et al., 1996]. Whenever the la-
    fed into the feature function fC () that computes the vari- bel of an object is changed during sampling, we determine
    ance. The potential of the clique, φC (vC ), is given by all (aggregated) objects and cliques that could be affected by
    exp{wC · fC (vC )}, where wC is the feature weight. this change and re-compute their parameters and potentials.
                                                      To initialize a Markov chain, we randomly assign labels to
RO-Maps  are illustrated in Figure 1. The upper plot shows
                                                      the basic objects in the RO-Map. Based on these labels, we
laser range-scans observed by a robot traveling down a hall-
                                                      generate all aggregate objects and their parameters. Finally,
way; the middle plot shows the labeled line segments ex-
                                                      the relational clique templates generate the cliques of the un-
tracted from these scans; and the lower plot shows the nodes
                                                      rolled, fully instantiated Markov network.
in the corresponding RO-Map along with some of the undi-
                                                        At each MCMC   step, we update the label of a randomly
rected links generated by the clique templates for this label-
                                                      selected object by sampling from the conditional distribution
ing. Among others, the ﬁgure shows two cliques generated
                                                                                    T
by the template that measures the indentation of doors. The p(yk | y−k, x, w) ∝ exp{w · f(x, y−k ∪ yk)} (4)
template generates pairs of doors and the corresponding wall where k is the index of the object, yk is one of its possible
object. The potential of the clique is then based on the dis- labels, and y−k are the labels for the other objects. To com-
tance of the door from the line representing the wall. More pute the probabilities of the different labels yk, we update the
details on features for detecting doors and walls will be given cliques and the parameters of aggregated objects involving
in the experimental results section.                  the object k. Even though this process can become inefﬁcient
                                                      for highly complex RO-Maps, inference on our current test
3  Inference  and  Learning                           hallways is very efﬁcient, as we will describe in Section 4.
                                                      We  expect further efﬁciency gains by more elaborate sam-
3.1  Inference: Labeling objects in RO-Maps           pling techniques.
The goal of inference is to estimate the labels (types) of the
objects represented in an RO-Map. Inference in RO-Maps 3.2 Learning:  Determining feature weights
is more complicated than in regular RMNs. This is due to The parameters of RO-Maps are the weights w of the fea-
the fact that the clique structure of the Markov networks gen- tures that deﬁne the clique potentials. The key idea of our
erated by RO-Maps depends on the unknown labels of ob- technique is to learn these parameters from a set of labeled
jects, and thus changes during inference. Since it is not clear environments, and then apply the learned weights when the
how (loopy) belief propagation can be applied to such label- robot explores a new environment.Figure 2: Examples of hallways used for learning and testing. Line segments were labeled manually as Door, Wall, or Other.

  The details of our learning technique are beyond the scope Physical aggregation Wall objects are the only physically
of this paper, more information is given in [Liao et al., 2005]. aggregated objects in our current system. Wall objects
In a nutshell, the weights are learned by minimizing the neg- are lines that are generated from line segments that are
ative log-likelihood of the labeled training data collected in labeled Walls and are on the same side of a hallway
N environments:                                           (see Figure 1). The Wall object parameters can be com-
                                                          puted efﬁciently from the parameters of the line seg-
                N                     wT w
       L(w)  ≡     − log p(y | x , w) +         (5)       ments.
               X           j  j       2σ2
               j=1                                    Local features describe appearance properties of objects. In
                                                          RO-Maps,  such features are modeled by generating a
     j                  m       y
Here,  is the index of map j , and j are the labeled ob-  clique for each object and the corresponding attribute.
          j
jects in the -th map. The rightmost term avoids overﬁtting We use the length of line segments as a feature. The cor-
by imposing a zero-mean, Gaussian shrinkage prior on each responding feature functions return the log-likelihood of
                           [                ]
component of the weight vector Taskar et al., 2002 . Since a speciﬁc length given a Gaussian representing the distri-
(5) is convex, we can determine the global minimum using a bution over lengths, conditioned on the object type. The
                                              L(w)
quasi-Newton method, where the value and gradient of      means and variances of the Gaussians for Doors, Walls,
                              [              ]
are determined by MCMC sampling Liao et al., 2005 .       and Others were estimated from the labeled maps. In
  The outcome of the learning procedure is a set of feature our framework it is straightforward to add other features,
weights that best represent the appearance and spatial con- such as the color of objects [Anguelov et al., 2004]. Un-
straints of the training maps by maximizing the classiﬁcation fortunately, the Radish data sets do not contain camera
rate. RO-Maps inherit the important beneﬁt from RMNs of   information.
automatically enforcing parameter sharing between (aggre-
gated) objects and relations of the same type. This “smooth- Aggregated Wall objects have a feature that measures
ing” over instances of classes provides a very powerful tool the alignment of the line segments that make up the wall
for dealing with sparse training data.                    object. Alignment is measured by the average distance
                                                          of the line segments from the aggregated Wall line. This
                                                          feature helps RO-Maps to label line segments as Walls
4  Implementational    Details and  Experiments           only when they are well aligned with other Wall seg-
We evaluated RO-Maps on the task of labeling line segments ments.
extracted from laser range-ﬁnder scans collected by a robot
                                                                           describe which object types are lo-
traversing a hallway. The data sets were taken from the Neighborhood features
                                                          cated next to each other. For example, it is common to
Radish robotics data set repository [Howard and Roy, 2003].
                                                          observe a Wall segment next to a Door, but uncommon
We took two to three hallways from ﬁve different environ-
                                                          to ﬁnd many Doors in close proximity to one another.
ments each and manually labeled the extracted and aligned
                                                          We  compute a line segment’s neighborhood by deter-
line segments into the three categories Door, Wall, and Other.
                                                          mining all other segments with endpoints within 40 cm.
Line segments were extracted using the technique described
                                                          Neighborhood features are then modeled by binary indi-
in [Gutmann and Konolige, 1999]. Some of the test hallways
                                                          cator functions on the possible label pairs (e.g., “WW”,
are shown in Figure 2. To perform the labeling, we relied
                                                          “WD”,  “DO”).
on our experience in typical layouts of hallways. In several
cases, we were not sure about the labeling or were only able Spatial features describe the relative position of objects.
to label doors based on the fact that we knew the real build- The indentation of a Door object is computed relative to
ings represented by the maps.                             the aggregated Wall object on the same side of the hall-
                                                          way. Indentation is given by the minimum distance be-
4.1  Features                                             tween the Door line endpoints and the Wall line, thereby
To label the line segments in the hallways, we implemented estimating indentation at the hinge point of a door. As
various features. The features were represented by the log- with line width, the indentation feature function returns
likelihood of the measured values under a generative model. the log-likelihood under a Gaussian indentation model
This approach allows our technique to automatically take  estimated from the training maps.
variability between different features into account.      Unless an object is a Wall segment, it is highly unlikely                                   Doors labeled as Other

Figure 3: Hallway with the highest classiﬁcation error. The doors in the lower half of the hallway are wide double doors with very large
indentations. Since none of the other training environments contained such doors, our approach labeled them as Other. Some of the open
double doors were detected as doors. All doors in the upper half and all walls (dashed lines) are labeled correctly.

    to be both very close and well-aligned with a Wall ob- curacy rates of the labels, averaged over the two hallways of
    ject. RO-Maps detect Other objects by considering the each test environment. The leftmost result column gives the
    distance and angle alignment of such objects relative to accuracy rates achieved when using only the lengths of line
    the closest Wall object. To compute the likelihood of segments to distinguish between the different object types.
    speciﬁc distances and angles, we estimate discrete dis- The next column summarizes results obtained when consid-
    tributions from the training maps (these distributions are ering length and neighborhood features. The resulting models
    typically non-Gaussian).                          are similar to standard HMMs or MRFs in that they consider
Global features depend on multiple objects that are poten- local appearance features (length) and connect neighboring
    tially far apart. In our experiments, we measure the sim- objects. As can be seen, object neighborhood improves the
    ilarity of the indentations of all doors in a hallway by results signiﬁcantly. Furthermore, these results indicate that
    computing their variance.                         the labeling task is by far not trivial. The last column presents
                                                      the accuracy rates achieved when using all features discussed
4.2  Experiments  and Results                         in the previous section. The results show that the additional
To test the performance of our learning method, we used 5- consideration of spatial constraints such as door indentation
fold cross-validation on the ﬁve environments extracted from improves the classiﬁcation performance by a large margin.
the Radish repository. To do so, the model parameters were Figure 3 shows the hallway with the highest classiﬁcation
trained on labeled hallways from four environments and then error (environment 5). As can be seen, most of the doors
tested on the remaining one. Training on a set of 10 hall- along the lower wall of the hallway are mislabeled as Other.
ways took 2-3 hours. To generate the statistics needed for However, this is not surprising given that the indentation of
each iteration of the quasi-Newton optimization technique, these doors is far larger than in the other training maps. Fur-
we ran a Gibbs sampler for 1,000 iterations on each training thermore, most of these double doors are closed, which re-
map. The ﬁnal 200 samples from each chain were used to sults in very long line segments. Thus, the labels are very
compute differences between the sampled feature values and reasonable, given the training data available to the approach.
the feature values extracted from the labeled maps. These
differences were then used to compute the relative, negative
log-likelihood (5) and the gradient.                                         Inferred labels
  Testing, that is, labeling of the objects in an unknown map,     Truth  Wall   Door  Other
was very efﬁcient and took around one minute or less on av-        Wall   221     5      8
erage. For each environment, the labeling error rate was de-       Door    1     122     21
termined by comparing the most probable assignment to the          Other   10     12     93
manually generated label. Most probable assignments were         Table 2: Confusion matrix (counts).
extracted from the Markov chains by counting the different
labels for each object. The label with the highest count was Table 2 shows the confusion matrix summarized over all
compared to the ground truth. To gauge the importance of test environments using all features. The table shows that
different features for labeling the objects in these hallways, most errors are due to confusion between Others and Walls,
we varied the set of features we used.                and Others and Doors. Walls and Doors are rarely confused.
                                                      The overall accuracy rate is 88.4%. This is a very encourag-
 Environm.  Lengths   Lengths + Neighbors   All
                                                      ing result, especially since several maps contained objects for
     1       62.6%          88.5%          90.7%      which even humans were uncertain about the correct labeling.
     2       58.7%          63.0%          93.5%
                                                        It should be noted that [Anguelov et al., 2004] achieved rel-
     3       59.0%          79.2%          89.7%
                                                      atively high accuracy using a hierarchical Bayesian approach
     4       51.8%          96.5%          97.7%      without spatial constraints. This is due to the fact that they
     5       60.0%          68.5%          77.9%      trained model parameters in the same environment and took
Table 1: Average accuracy rates on maps using different fea- visual color information into account. Adding such appear-
tures.                                                ance information to RO-Maps is straightforward and we ex-
  Table 1 summarizes the results. The numbers give the ac- pect strong improvements from such additional information.