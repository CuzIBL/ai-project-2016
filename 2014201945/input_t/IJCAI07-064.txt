     Some Effects of a Reduced Relational Vocabulary on the Whodunit Problem

                             Daniel T. Halstead and Kenneth D. Forbus
                                      Qualitative Reasoning Group
                                        Northwestern University
                              2145 Sheridan Rd., Evanston, IL 60208 USA


                    Abstract                          to express the same information. Unless all such language
                                                      redundancies are detected ahead of time, relational learning
    A key issue in artificial intelligence lies in finding
                                                      algorithms will suffer.
    the amount of input detail needed to do successful
                                                        The issue is also particularly relevant whenever a learning
    learning. Too much detail causes overhead and     system is to be deployed in any sort of real-world environ-
    makes learning prone to over-fitting. Too little de-
                                                      ment. Such environments tend to be brimming with unre-
    tail and it may not be possible to learn anything at
                                                      lated observations. Robotic systems for example, will
    all. The issue is particularly relevant when the in-
                                                      wisely choose to focus on only a few sensory inputs, which
    puts are relational case descriptions, and a very ex-
                                                      they can analyze carefully, rather than a cursory analysis of
    pressive vocabulary may also lead to inconsistent
                                                      many inputs which would only confuse the picture. A simi-
    representations. For example, in the Whodunit     lar application is the automatic extraction of knowledge
    Problem, the task is to form hypotheses about the
                                                      from text. This is becoming more popular as the internet
    identity of the perpetrator of an event described us-
                                                      grows, and it is crucial to identify which relationships are
    ing relational propositions. The training data con-
                                                      useful to know, and which convey practically the same in-
    sists of arbitrary relational descriptions of many
                                                      formation.
    other similar cases. In this paper, we examine the
                                                        This paper, which was motivated by just such an attempt
    possibility of translating the case descriptions into to improve knowledge extraction from text, is an analysis of
    an alternative vocabulary which has a reduced
                                                      the contrasting effects between using a large, very detailed
    number of predicates and therefore produces more
                                                      but often redundant vocabulary, and a small, consistent, but
    consistent case descriptions. We compare how the
                                                      extremely simplified one. The two different vocabularies
    reduced vocabulary affects three different learning
                                                      are applied to the Whodunit Problem, which tries to learn
    algorithms: exemplar-based analogy, prototype-
                                                      how  to predict the perpetrator of a terrorist event, given
    based analogy, and association rule learning. We  many descriptions of similar events expressed by proposi-
    find that it has a positive effect on some algorithms
                                                      tional assertions. The descriptions are currently entered by
    and a negative effect on others, which gives us in-
                                                      hand but will eventually be extracted from text, which
    sight into all three algorithms and indicates when
                                                      makes the choice of vocabulary especially relevant. Each
    reduced vocabularies might be appropriate.
                                                      vocabulary is used by three different learning algorithms, in
                                                      order to better understand the effects of the vocabulary size
1  Introduction                                       and to find the best overall combination.
One problem that is consistent across nearly every applica- Section 2 begins by introducing the Whodunit Problem.
tion of machine learning is identifying the appropriate Following that, each of the three learning algorithms for
amount of detail in the input data. As tempting as it is to solving the problem are explained in Section 3. Section 4
learn from all of the available data, in a real-world applica- describes how the original, large vocabulary was reduced,
tion most of it will be irrelevant or redundant. Including and Section 5 presents our results. Finally, we conclude
such extraneous detail in an analysis will not only slow with a discussion of related work.
down the process, but may also lead to over-fitting and
hence learning of an incorrect model. Clearly though, a 2 The Whodunit Problem
balance must be found, since with too little data it becomes
                                                      An important task for analysts is coming up with plausible
unlikely that anything can be learned at all.
                                                      hypotheses about who performed an event. Recall the pre-
  The problem is perhaps even worse when dealing with re-
                                                      election bombing in Madrid, Spain. While the Spanish gov-
lational data. Since most relational learning algorithms
                                                      ernment originally claimed that the Basque Separatist group
operate by comparing across instances of the relation itself, ETA was the most likely suspect, evidence quickly mounted
redundant relations become particularly dangerous. The
                                                      that Al Qaeda was very likely responsible. Multiple, highly
more expressive a vocabulary, the more ways there may be


                                                IJCAI-07
                                                   411coordinated attacks, for example, are more similar to Al 5,000 functions, all constrained by 1.2 million facts. The
Qaeda's modus operandi than previous ETA actions. This is descriptions of terrorist attacks ranged in size from 6 to 158
an example of what we call the Whodunit problem.      propositions, with the average being 20 propositions.
  Stated more formally, given some event E whose perpe- The Whodunit problem is an excellent domain for explor-
trator is unknown, the Whodunit problem is to construct a ing relationships between similarity and probability. The
small set of hypotheses {Hp} about the identity of the per- input data consists entirely of arbitrarily high order sym-
petrator of E. These hypotheses should include explanations bolic relations with arbitrary structure between them. This
as to why these are the likely ones, and be able to explain on means we will have to pay careful attention to structure in
demand why others are less likely.                    order to get probabilities over the correct statements (i.e.
  We define a more restricted class of Whodunit problems those which uniformly correspond to the same concept
to begin with:                                        within each case). There is a very large number of records
  Formal inputs. We assume that the input information is of terrorist attacks on which to train, but there is also a large
encoded in the form of structured descriptions, including number of possible perpetrators (67) to choose from during
relational information, expressed in a formal knowledge testing.
representation system. Note that we do not require uniform
representations in each input; that is, we treat each case as 3 Learning Algorithms
simply a collection of arbitrary predicate calculus statements
rather than as an object with predefined slots that may or We used three different algorithms to try to solve the Who-
may not be filled.                                    dunit problem. Since the contribution of this paper is on the
  Accurate inputs. We assume that the input information is effects of vocabulary reduction and not the learners them-
completely accurate, i.e., that there is no noise.    selves, we have only selected algorithms which have been
  One-shot operation. Once the outputs are produced for a previously published. Here then, we present only a terse
given E, the system can be queried for explanations, but it description of each learner and the implementation details
does not automatically update its hypotheses incrementally particular to the domain.
given new information about E.                          All three algorithms utilized structural analogy in some
  Passive operation. The hypotheses are not processed to fashion, in order to make comparisons between and across
generate differential diagnosis information, i.e., "tells" that cases.
could be sought in order to discriminate between the small Our approach to analogy is based on Gentner's [1983]
set of likely hypotheses.                             structure-mapping theory of analogy and similarity. In
  Supervised learning. We allow the system to train on a structure-mapping, analogy and similarity are defined in
set of pre-classified examples {D}. For some algorithms, terms of structural alignment processes operating over struc-
this involves forming non-overlapping generalizations {G} tured representations. The output of this comparison proc-
over those examples.                                  ess is one or more mappings, constituting a construal of how
  The assumption of formal inputs is reasonable, given that the two entities, situations, or concepts (called base and
producing such representations from news sources is the target) can be aligned. For the purposes of this paper, a
focus of considerable research in the natural language com- mapping consists of a set of correspondences and a struc-
munity these days. The assumptions of accurate inputs, of tural evaluation score. A correspondence maps an item
one-shot, passive operation, and of supervised learning are (e.g. an entity or expression) from the base to an item in the
good starting points, because if we cannot solve this re- target. The structural evaluation score indicates the overall
stricted version of the problem, it makes no sense to try to quality of the match.
solve harder versions.                                  We used the Structure-Mapping Engine (SME) to imple-
                                                      ment this theory of analogical mapping [Falkenhainer, For-
Table 1. Example of a Whodunit case description       bus, & Gentner, 1986]. SME uses a greedy algorithm to
                                                      compute approximately optimal mappings in polynomial
  (ISA ATTACK-1 TERRORISTATTACK )                     time [Forbus & Oblinger, 1990].
                                                        Formally, the task of each learning algorithm is, given
  (EVENTOCCUREDAT ATTACK-1 FALLUJAH)
                                                      descriptions to train on {D}, and input event E, to produce n
  (CITYINCOUNTRY FALLUJAH IRAQ)
                                                      hypotheses about the identity of the perpetrator of event E.
  (THEREEXISTATLEAST 2?X
   (AND (CITIZENOF ?X IRAQ)(WASINJURED ATTACK-1 ?X))) 3.1 Exemplar-based Analogy: MAC/FAC
  The corpus we use in our experiments is an independ- The first algorithm operates purely on exemplar retrieval.
ently-developed knowledge base of terrorist incidents, pro- That is, it is designed to find a small number of input cases
vided to us by Cycorp. The version they provided consists which are most similar to the probe case E. For each such
of 3,379 descriptions of different terrorist attacks, each case, it hypothesizes that the perpetrator of E is the same as
hand-entered and checked by domain experts. These attacks the perpetrator of the similar case. The process can be iter-
were all expressed using the symbolic representation vo- ated until n unique hypotheses are generated. MAC/FAC
cabulary of the Cyc KB, which (in our subset) consists of [Forbus, Gentner, & Law, 1994] is an algorithm which per-
over 36,000 concepts, over 8,000 relationships and over forms this similarity-based retrieval in two stages.


                                                IJCAI-07
                                                   412 The first stage uses a special kind of feature vector, called overlap. However, SEQL has been shown to be substan-
a content vector, which is automatically computed from tially faster than connectionist algorithms when compared
each structural description. A content vector consists sim- head-to-head [Kuehne et al., 2000]. Moreover, this was
ply of the counts of each predicate in the corresponding de- done using the same input representations as the
scription. Their dot product then is an estimate of how connectionist models, and the SEQL-based simulation con-
many correspondences SME will generate when considering tinued to work when given noisy versions of the data.
possible mappings between two descriptions, and therefore One potential drawback with SEQL is that generaliza-
an estimate of the quality of the match. Content vector tions – the union of many case descriptions – can grow
computations are used to rapidly select a few (typically quickly in size, but SME has polynomial memory require-
three) candidates from a large memory.                ments. Therefore SEQL must often pare down the facts in a
  Inthesecondstage,SMEisusedtodoananalogical          generalization (it culls those with lowest probability),
comparison between the subset of {D} which was returned throwing away information to preserve a higher level of
by the first stage and the probe description E. It returns the abstraction within a reasonable space requirement.
one (or more, if very close) most similar of the cases in
memory as what the probe reminded it of.              3.3 Rule Learning
  As deployed  performance systems, both SME   and    The third method that we applied was more statistical in
MAC/FAC have been used successfully in a variety of dif- nature. It learns a list of association rules for predicting
ferent domains, and as cognitive models, both have been each possible perpetrator. In order to do this, it must con-
used to account for a variety of psychological results [For- vert the structured relational data of {D} into a feature-value
bus, 2001].                                           representation. We used a case flattening approach intro-
                                                      duced by Halstead & Forbus [2005] to accomplish this.
3.2 Prototype-based Analogy: SEQL                     Namely, SEQL was applied to all of the input cases at once
The second algorithm is designed to also use analogy. in order to build one very large generalization. This gener-
However, it first builds generalizations of the cases to serve alization was then used as the framework for building a fea-
as prototypes. Each generalization is constructed from the ture set, with each assertion in the generalization corre-
cases of only one perpetrator at a time. This way, each gen- sponding to one feature. The generalization and feature set,
eralization serves as a prototypical description of the events taken together, form an invertible mapping from relational
associated with that single perpetrator. Then instead of case descriptions to features and back again.
comparing E to every case in {D} (as the first algorithm For interpretation of the results, it is important to note
does), this algorithm compares E to every prototype.  here that features come in two types. The first, an existen-
  The generalizations are built by using analogy to deter- tial feature, is the default type. It simply takes the value
mine which concepts in one case best correspond to the true or false depending on whether the assertion it repre-
concepts in another case. We use a probabilistic implemen- sents is present in a given case or not. A characteristic fea-
tation of the SEQL algorithm to do this. SEQL [Kuehne, ture on the other hand, can be used when more is known
Forbus, et al., 2000], which stands for Sequential Learner, is about the structure of the assertion, and so more information
designed to produce generalizations incrementally from a can be conveyed. For example, the English sentences “the
stream of examples. It uses SME to compare each new ex- attack killed someone” and “it was an ambush” are existen-
ample to a pool of prior generalizations and exemplars. If tial features – they are either true or false. The sentences
the new example is sufficiently similar to an existing gener- “the attack killed three people” and “it happened in Bagh-
alization, it is assimilated into that generalization. Other- dad” are characteristic features, which have the values 3 and
wise, if it is sufficiently similar to one of the prior exem- Baghdad, respectively. As we will show, the conciseness of
plars, it is combined with it to form a new generalization. a reduced relational vocabulary makes it easier to extract
  A generalization of two cases is done by taking the union characteristic feature values from the data.
of the expressions in the two descriptions, and adjusting the For rule learning, we use the definition of association rule
probability of each expression according to whether or not it introduced by Agrawal, et al. [1996]. Hence, each associa-
was in both descriptions. Matching entities that are identi- tion rule is a conjunction of feature-value pairs (a.k.a. liter-
cal are kept in the generalization, and non-identical entities als, such as <location . Iraq>) which implies another such
are replaced by new entities that are still constrained by all conjunction.
of the statements about them in the union.              The actual rule learning is done using an ad-tree to cache
  SEQL provides an interesting tradeoff between traditional the joint probabilities of the input data [Anderson & Moore,
symbolic generalization algorithms like EBL [Dejong & 1998]. Adopting Anderson & Moore’s algorithm, we start
Mooney, 1986] and statistical generalization algorithms, with a list of candidate hypotheses (antecedents) H, initially
such as connectionist systems. Like EBL, it operates with empty, and perform a breadth-first search with a beam-
structured, relational descriptions. Unlike EBL, it does not width of 10 over the space of possible hypotheses. On each
require a complete or correct domain theory, nor does it iteration of the search, we further specify each hypothesis in
produce a generalization from only a single example. Like H by adding literals from the set of possible literals L. We
most connectionist learning algorithms, it is conservative, then re-evaluate each hypothesis, choose the best 10 again,
only producing generalizations when there is significant


                                                IJCAI-07
                                                   413and re-iterate until H is empty or the rules are 5 terms long. Each new predicate corresponds to any of a set of old
One example of a rule learned looks like:             predicates. These relationships were easily hand-coded into
  (IF (AND (LOCATION ?ATTACK PHILIPPINES)             a list of 38 translation rules, which were used for the actual
          (AGENTCAPTURED ?ATTACK ?AGENT))             data reduction. For example, the following rule handles
    (PERPETRATOR ?ATTACK MOROISLAMICLIBERATIONFRONT)) intentional actions:
                                                        (TRANSLATE
  Finally, for every possibly perpetrator, the algorithm ac- (OR (DONEBY ?EVENT ?AGENT)
tually learns a rule-list by recursively calling the rule-   (EVENTPLANNEDBY ?EVENT ?AGENT))
learner. For any perpetrator P, it begins by learning a sin- (AND (AGENT ?EVENT ?AGENT)(GOAL ?AGENT ?EVENT)))
gle rule H1 ⇒ P. On the next iteration, it tries to learn a
rule for H2 ⇒ P^  H1.  This process continues until it  The above rule fires on any facts in the original Cyc rep-
reaches a maximum of 5 rules or no more rules can be  resentation whose predicates are either doneBy or event-
found.                                                PlannedBy, or are specializations of doneBy or event-
  Once a list of rules RP is learned for every perpetrator P, PlannedBy. Each such fact is translated into two new facts:
then the input case E is applied to every RP,toseewhich the first describing that the agent played some causal role in
rules fire. The n rules which fired with the highest confi- the event, and the second describing that the event was in
dence have their consequents returned as the hypothesis to fact a goal of the agent. Some facts are actually translated
the identity of the perpetrator.                      by the application of more than one rule. An example of
  Whereas the other two learners are limited to reductive this translation process can be seen in Table 3.
learning, the rule learner learns simple, higher-level pat-
terns.                                                  Table 3. Translation Example
                                                       Cyc     (THEREEXISTEXACTLY 3?AGENT
4   Reduced Vocabulary                                           (AGENTCAPTURED ATTACK ?AGENT))
The original human-encoded input data consisted of 581
                                                               (TRANSLATE
predicates, drawn from a vocabulary of over 8,000. This Rule 1
was translated into only 22 predicates, a 96% reduction in      (THEREEXISTEXACTLY ?NUMBER ?VARIABLE ?FACT)
vocabulary size and knowledge compression ratio of 26.4.        (AND (MEASURE ?VARIABLE ?NUMBER)?FACT))
  The reduced vocabulary that we used was a subset of the      (TRANSLATE
vocabulary designed by Language Computer Corporation            (OBJECTACTEDON ?EVENT ?OBJECT)
for their Polaris system (Bixler, Moldovan, & Fowler,  Rule 2   (AND (THEME ?EVENT ?OBJECT)
2005). Their vocabulary consisted of 40 predicates, chosen         (PREDICATE ?OBJECT ?PREDICATE)
for their usefulness in natural language processing, the fea-      (RESULT ?EVENT ?PREDICATE)))
sibility of their automatic extraction from text, and of par-
ticular importance to this research, the broadest semantic     (MEASURE ?AGENT 3)
coverage with the least amount of overlap. LCC explains:       (THEME ATTACK ?AGENT)
                                                               (PREDICATE ?AGENT AGENTCAPTURED)
    While no list [of predicates] will ever be perfect… Polaris
                                                               (RESULT ATTACK AGENTCAPTURED)
    this list strikes a good balance between being too
    specific (too many relations making reasoning dif-
    ficult) and too general (not enough information to
    be useful).
  The subset of 22 predicates which we selected from this Note that since the original Cyc vocabulary is much
vocabulary was based simply on those Polaris predicates richer, many of the facts in the original data must be repre-
which were needed to represent the information already sented by more than one fact upon translation. Specifically,
present in the Whodunit training cases. The final list of the average translation rule turns one fact into 1.3 new facts.
predicates is provided in Table 2.                    The average number of facts in a case increased by 70%.
                                                      5Results
  Table 2. All relations in the reduced vocabulary    We used three criteria for bounding the size of the set of
  Agent        Goal        Result        Theme        hypotheses n. The most restrictive is producing only a sin-
  Predicate    Purpose     Location      Time         gle perpetrator, i.e., guessing directly who did it. The least
  Measure      Property    Part          Cause        restrictive is a "top 10" list, rank ordered by estimated like-
  Instrument   Topic       Belief        Associated   lihood. The middle ground is the "top 3" list, which has the
  Reason       Source      Experiencer   Recipient    virtue of providing both the best and some (hopefully mind-
  Possible      Entails                               jogging) alternatives.


                                                IJCAI-07
                                                   414Chart 1. Results under old and new vocabularies, resp.  We were surprised by how well all three strategies per-
                                                      formed, even the non-statistical ones, given the difficulty of
                                                      the problem. Consider that although each case contains an
                                                      average of only 24 facts, there are over 100 features in the
                                                      dataset. This means that for any given record, over 75% of
                                                      the features will be missing. This makes for a very sparse
                                                      dataset. Fortunately, the closed world assumption seems to
                                                      have held up. Yet, when we consider that the arity of the
                                                      output attribute is 67, it seems that those 100 features may
                                                      not be enough. A random algorithm would select the cor-
                                                      rect perpetrator 1.5% of the time, and would get it right with
                                                      ten guesses only 15% of the time. Therefore, we believe
                                                      that success rates of 60% are quite good.
  The results turn out to be very different for each algo- In conclusion, given that researchers tend to use larger re-
rithm. Chart 1 shows that under the conditions of the origi- lational vocabularies, it is extremely interesting that a re-
nal vocabulary, the rule learner performs the best. It is able duced relational vocabulary can improve two out of three
to return the correct answer on its first guess more than 50% learners tested. Certainly, since these experiments only test
of the time. SEQL finds as many correct answers in the one reduced vocabulary in one domain, some caution in
long run, but is less certain in the beginning, providing the interpreting the results is warranted. It also seems that re-
correct answer in its first guess only 30% of the time. Fi- duced vocabularies are dangerous to use in a learning algo-
nally, MAC/FAC does a little better than SEQL on its first rithm that already relies heavily on abstraction (e.g. SEQL),
guess. Interestingly though, continuing to construct hy- since it may lead to too much data and/or too much loss of
potheses from MAC/FAC beyond that point proved useless. information. However, vocabulary reduction does trade
  Under the new vocabulary, the exemplar-based algorithm away smaller case descriptions and some information for
improved (p-value .045). SEQL though, performed worse added conciseness. Learning algorithms which are known
(p-value .004). Perhaps stranger still, the rule learner, which to do well with large amounts of data (high dimensionality)
depends on the generalization algorithm provided by SEQL, and which can take advantage of this extra conciseness
performed even better than it had before (p-value .015). It (such as the rule learner, which pays attention to the greater
gets the correct answer on its first guess 60% of the time. number of extractable feature values) appear likely to do
  Closer examination reveals that the SEQL algorithm was better under a well-chosen reduced relational vocabulary.
hard-pressed. In the original vocabulary, SEQL generalized
from case descriptions which contained an average of 20
facts each. However, 16% of those facts had to be discarded 6 Related Work
to preserve memory as dimensionality (case description At first glance, this work appears to tie in strongly to forms
size) increased with abstraction. Under the reduced vocabu- of dimension reduction, such as feature selection. However,
lary, which is already an abstraction of the original data, this the task in feature selection is to automatically select a sub-
information loss is compounded. When the average descrip- set of concepts, a form of filtering. Reduced relational vo-
tion size increases by 70%, so does the number of facts dis- cabularies abstract and transform more than they filter.
carded by SEQL during generalization, which rises to 28%. Other forms of dimension reduction do perform a transfor-
Furthermore, the facts which remain carry less information mation on the data, such as Principal Component Analysis.
than they did under the original vocabulary (the average However, the result of this transformation has often lost any
reduced predicate corresponds to 106 different predicates real-world meaning. Furthermore, all of these techniques
from the original vocabulary).                        are typically automated within a given domain. This par-
  So, how did the rule-learner improve in performance? ticular reduced vocabulary, in contrast, was manually con-
One possible explanation may be because of the leap it takes structed (by other researchers), based on needs of natural
from reductive to higher-order learning. However, this language processing, to work under any domain. Finally,
seems to be only part of the story. More important is that although the number of relations in the data decreases under
the rule learner is able to take advantage of the conciseness vocabulary reduction, the dimensionality of the data actually
in the reduced vocabulary. This conciseness allows the flat- increases, since the simpler relations must be used in many
tening process to generate many more characteristic values different sentences to convey the same information.
for the features than before: the average arity increases by Many different ontologies have also been developed in an
250%. This plethora of feature values gives the rule learner effort to balance language expressiveness with computabil-
more grist by having more relevant options to consider than ity. OWL is a common example targeted for use with the
before. Further analysis shows that when features are world wide web. Work has also been done on computing
treated as existential and allowed only two values again (as the expressiveness of a given ontology. For example, Cor-
84% of them had under the original vocabulary), the rule- cho and Gomez-Perez [2000] establish a common frame-
learner reverts to almost SEQL-like levels of performance. work for comparing the expressiveness and reasoning cap-


                                                IJCAI-07
                                                   415