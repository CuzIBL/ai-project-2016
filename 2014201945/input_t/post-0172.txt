              fMRI Analysis via One-class Machine Learning Techniques
                                          David R. Hardoon
                         University of Southampton, ECS, ISIS Research Group
                           Southampton, UK SO17 1BJ. drh@ecs.soton.ac.uk
                                          Larry M. Manevitz
                         University of Haifa, Department of Computer Science
                              Haifa, Israel 31905. manevitz@cs.haifa.ac.il

                    Abstract                          assumption. For the fMRI classiﬁcation described above, this
                                                      problem is particularly non-trivial as we expect the data to
    We show how one-class compression Neural Net-     be of very high dimension and extremely noisy, as the brain
    works and one-class SVM can be applied to fMRI    concurrently works on many given tasks. It is also quite nat-
    data to learn the classiﬁcation of brain activity as- ural to assume that there is only representative data of the
    sociated with a speciﬁc motor activity. For com-  task of interest; and not necessarily representative data of the
    parison purposes, we use two labeled data and see negation of this task thus making the one-class learning tech-
    what degree of classiﬁcation ability is lost com- niques appropriate. In this work, we use two major one-class
    pared with the usual two-class SVM.               learning techniques - ”bottleneck” or compression neural net-
                                                      works [Manevitz and Yousef, 2001] and a common version of
1  Introduction                                       the one-class Support Vector Machine (SVM) [Scholkopf et
                                                              ]
Functional magnetic resonance imaging (fMRI) allows the al., 1999 . We point out that we use the entire brain slice,
carrying out of speciﬁc non-invasive studies within a given with no pre-ﬁltering - i.e. the data is the entire slice, labeled
subject while providing an important insight to the neural ba- with the task.
sis of brain processes. Neurons, which are the basic func-
tional unit of the brain, consume a higher level of oxygen 2 Experiments
when active, hence blood with a higher level of oxygenation The fRMI scans are of a volunteer1 ﬂexing their index ﬁnger
is supplied to those active neurons. fMRI makes indirect use on the right hand inside a MR-scanner while 12 image slices
of this effect by detecting areas of the brain which have an of the brain were obtained from a T2∗-weighted MR scanner.
elevated consumption of oxygen. This effect can be used to The time-course reference of the ﬂexing is built from the sub-
identify areas of the brain associated with speciﬁc functions. ject performing a sequence of 20 total actions and rests con-
  The current methodology used to identify such regions is sisting of rest, ﬂex, rest, . . . ﬂex. Two hundred fMRI scans
to compare, using various mathematical techniques, the ele- are taken over this sequence; ten for each action and rest. The
vation of oxygen consumption during a task with that used individual fMRI images are dicom2 format of size 128 × 128.
during a resting state. [Mitchell et al., 2004] applied ma- Each image is labelled as either 1 (active) or −1 (inactive).
chine learning techniqes to this problem, when considering Thus, in our data we have 100 positive and 100 negative
the classiﬁcation of the cognitive state of a human subject. images for each of the 12 slices. For the bottleneck neural
Thus, in order to determine the elevation of oxygen consump- network 80 positive samples were chosen randomly and pre-
tion during a task, images acquired during a resting state are sented for training and 40 samples, consisting of the remain-
required. In order to keep the alternation between activity, ing 20 positive and 20 random negative samples, were used
a reference time-course is needed, where the resting and ac- for testing. This experiment was redone with ten independent
tive states are embedded. In this paper we further consider random runs. The limitation to 20 negative samples out of a
the problem of identifying fMRI scans that have only been possible 100 was chosen to keep the testing fair between the
acquired during the “active” state, i.e. scans acquired during positive and negative classes. We manually cropped the non-
the duration when the human subject has performed the given brain background from the scans; resulting in a slightly dif-
task. The basic intuitions are that, if available, two-class clas- ferent input/output size for each slice of about 8, 300 inputs
siﬁcation should perform better; although not always. How- and outputs. The compression percentage arising from the
ever, as is the case under consideration here, often we have bottleneck was chosen by experimenting with different pos-
some reasonable sampling of the positive examples; i.e. the sible values. A uniform compression of about 60% gave the
distribution of positive examples can be estimated; while the best results for the hidden layer. The irrelevant (non-brain)
negative examples are either non-existent or episodic; i.e. not image data was cropped for each slice resulting in a slightly
necessarily representative.
  Obtaining good results under this assumption is known to 1Provided by Ola Friman [Friman, 2003].
be quite challenging; nonetheless it is often the most realistic 2For information regarding dicom see http://medical.nema.org/different input/output size for the network for each slice. The the one-class. This is expected as the one-class methods make
network was trained to the identity using 20 epochs on the no use of the negative samples and eminently will have a
above chosen data. Following training the network was used lower ability in classifying it. Additional experiments have
as a classiﬁcation ﬁlter, with an input value being classiﬁed
as positive if the error level was lower or equal to a threshold
chosen heuristically from training and classiﬁed as negative.       Table 3: Methods Statistics
We used the same protocol in a one-class SVM. Additionally,
we used the two-class SVM where we randomly selected 160   Method       True-Positive False-Negative   std
training images and the remaining 40 for testing. This was BN - NN        78.96%         21.04%      ±3.15%
also repeated 10 times.                                One-class SVM      72.83%         27.17%      ±1.98%
                                                                          71 55%         28 45%      ±3 21%
2.1  First Experimental Results                        Two-class SVM        .              .           .
The obtained results are an average over all the slices. Each          True-Negative  False-Positive
                                                                          33 42%         66 58%      ±3 45%
slice was averaged over 10 repeats where in each repeat a ran- BN - NN      .              .           .
                                                                          39 25%         60 75%      ±3 25%
dom split of training testing was selected. Both SVM classi- One-class SVM  .              .           .
ﬁers were used in their default setting as set by the OSU- Two-class SVM  65.64%         54.46%      ±3.02%
SVM  3.00 package3. In addition, the two-class SVM was
used with the unnormalised data as we have experimentally
                                                      been performed on visual instead of motor tasks with very
found that with normalised data the overall results were sig-
                                                      similar results.
niﬁcantly worse. In Table 1 we are able to observe that while
the one-class SVM performs better with the RBF kernel, the
two-class SVM is better with the linear kernel. In Table 2 3 Conclusions
                                                      We have found that one class classiﬁcation can be done, even
                                                      with the ”noisy” data and with the full slices of the brain scan.
           Table 1: SVM Results (success).            Comparable results (about 58% accuracy) were obtained un-
     Method        Linear kernel     RBF kernel       der both one-class SVM and Compression-Based NN tech-
  One-class SVM  49.12% ± 0.86%   59.18% ± 1.47%      niques. For future work we would further investigate auto-
 Two-class SVM   68.06% ± 2.10%   44.70% ± 1.12%      mated feature reduction as it might be fruitful, compare scans
                                                      of the same individual across different fMRI sessions. The
                                                      work presented here was for one individual. We intend to
we compare the one-class to two-class techniques. As ini- compare training and classiﬁcation across individuals.
tially expected we are able to observe that the two-class ap-
proaches outperform those of the one-class. The one-class Acknowledgments
SVM is slightly better then the bottleneck compression NN.
                                                      This collaboration was supported by the Caesarea Rothschild
We further analyse the statistics of the methods i.e. the sepa-
                                                      Foundation, and by the HIACS Reseach Center, the Univer-
                                                      sity of Haifa. The ﬁrst author is funded by the European
           Table 2: Methods success results.          project LAVA num. IST-2001-34405 and PASCAL network
                                                      of excellent num. IST-2002-506778. We also thank Ola
             Method       Result on slices
                                                      Friman of Harvard Medical School for his generous sharing
             BN - NN      56.19% ± 1.26%
                                                      of his data.
          One-class SVM   59.18% ± 1.47%
          Two-class SVM   68.06% ± 2.10%              References
                                                      [Friman, 2003] Ola Friman. Adaptive Analysis of Functional
ration of the classiﬁed samples to their true classes. In Table MRI Data. PhD thesis, Linkoping Studies in Science and
34 we compute and show the statistics of the fMRI images of Technology, 2003.
the Positive samples that were classiﬁed as positive, denoted [Manevitz and Yousef, 2001] Larry Manevitz and Malik
as true-positive, and the positive samples that were classiﬁed Yousef. One-class svms for document classiﬁcation. Jour-
as negative, denoted as false-negative and the statistics of the nal of Machine Learning Research 2, pages 139–154,
negative fMRI images samples that were classiﬁed as nega- 2001.
tive, denoted as true-negative, and those that were classiﬁed
as positive, denoted as false-positive. We are able to observe [Mitchell et al., 2004] T.M. Mitchell, R. Hutchinson, R.S.
in that the compression NN is able to ﬁnd a higher rate of Niculescu, F. Pereira, X. Wang, M. Just, and S. Newman.
true-positive fMRI images then the one-class SVM and the Learning to decode cognitive states from brain images.
two-class methods even though they have obtained an higher Machine Learning, 1-2:145–175, 2004.
overall success rate. Also we observe with regard to the neg- [Scholkopf et al., 1999] B. Scholkopf, J. Platt, J. Shawe-
ative samples that the two-class methods perform better then Taylor, A. J. Smola, and R. C. Williamson. Estimating
  3                                  ∼                   the support of a high-dimensional distribution. Technical
   OSU SVMs Toolbox http://www.ece.osu.edu/ maj/osu svm/ Report 99-87, Microsoft Research., 1999.
  4std stands for Standard Deviation