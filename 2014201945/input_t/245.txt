         A Multi-Agent Computational Linguistic Approach to Speech 
                                                   Recognition 

                        Michael Walsh, Robert Kelly, Gregory M.R O'Hare, 
                                Julie Carson-Berndsen, Tarek Abu-Amer 
                                        University College Dublin, Ireland 
          {michael.j.walsh, robert.kelly, gregory.oharc, julie.berndsen, tarek.abuamer}@ucd.ie 

                        Abstract 

     This paper illustrates how a multi-agent sys•
     tem implements and governs a computational 
     linguistic model of phonology for syllable recog•
     nition. We describe how the Time Map model 
     can be recast as a multi-agent architecture 
     and discuss how constraint relaxation, output 
     extrapolation, parse-tree pruning, clever task 
     allocation, and distributed processing are all 
     achieved in this new architcture. 

 1 Introduction and Motivation 
 This paper investigates the deployment of multi-agent 
 design techniques in a computational linguistic model 
of speech recognition, the Time Map model [Carson-
 Berndsen, 1998]. The architecture of the model is il•
 lustrated in Figure 1. In brief, phonological features are 
                                                                     Figure 1: The Time Map model architecture 
extracted from the speech signal using Hidden Markov 
Models resulting in a multi-tiered representation of the 
utterance. A phonotactic automaton (network represen•          to maintain, essentially desires and a set of computa•
tation of the permissible combinations of sounds in a          tional states which the agent seeks to achieve, that is 
 language) and axioms of event logic are used to inter•        intentions. 
pret this multilinear representation, outputting syllable         The agents are created through Agent Factory [O'Hare 
hypotheses [Carson-Berndsen and Walsh, 2000]. In what          et al., 1999], a rapid prototyping environment for the 
follows, we firstly introduce the multi-agent paradigm         construction of agent based systems. Agents created 
and discuss the use of agents equipped with mental mod•        using Agent Factory are equipped with a Mental State 
els. Secondly we illustrate how the model can be recast        model and a set of methods (the actuators). Agents used 
within a multi-agent architecture. The paper concludes         in speech techonology in the past [Erman et al., 199G] ex•
 by highlighting the benefits of such an approach.             hibited only weak agenthood. However, the agents deliv•
                                                               ered through Agent Factory are intentional agents with 
2 The Multi-Agent paradigm                                     rich mental states governing their deductive behaviour; 
                                                               they exhibit strong notions of agenthood. The model 
The Multi-Agent paradigm is one which promotes the             presented below is both pioneering and in stark contrast 
interaction and cooperation of intelligent autonomous          to prior research in that it represents the first attempt 
agents in order to deal with complex tasks (see [Ferber,       to explicitly commission a multi-agent approach in sub-
 1999] for an overview of the area). The agents used to        word processing. The benefits of this model are discussed 
recast the Time Map model are deliberative reasoning           in section 4. 
agents which use mental models.The particular architec•
ture chosen to recast the Time Map model is known as           3 The Time Map Model as a 
the Belief-Desire-Intention (BDI) architecture [Rao and 
                                                                    Multi-Agent System 
Georgeff, 1991].According to the BDI paradigm an agent 
is equipped with a set of beliefs about its environment        A number of agents are required in order to recast the 
and itself, a set of computational states which it seeks       Time Map model accurately, namely the Feature Extrac-


POSTER PAPERS                                                                                                        1477  tion Agents, the Windowing Agent, the Segment Agents,         content of the window. Potential segments can be iden•
 and the Chart Agents. These agents are detailed below.        tified by using a resource which maps phonemes to their 
 The architecture is illustrated in Figure 2.                  respective features. Priority is placed on attempting to 
                                                               recognise predicted segments first. Therefore, the Win•
 The Feature Extraction Agents                                 dowing Agent spawns a Segment Agent for each potential 
 Numerous Feature Extraction Agents, operating in par•         segment that is also predicted by a Chart Agent, before 
 allel, output autonomous temporally annotated features        spawning a Segment Agent for potential segments not 
 (i.e. events). These events are extracted from the utter•     predicted by a Chart Agent. The incremental spawn•

 ance1 using Hidden Markov Model techniques, for more          ing of Segment Agents for potential segments is depen•
 details see [Abu-Amer and Carson-Berndsen, 2003].The          dent on the progress made by Segment, Agents already 
 feature output is delivered to the Windowing Agent.           activated. In Figure 2 the Windowing Agent has re•
                                                               ceived predictions from the Chart Agent. Having placed 
 The Chart Agent                                               an initial window over the feature-extracted multilinear 
 Chart Agents have a number of roles to play in the syl•       representation of the utterance, the Windowing Agent 
 lable recognition process. One role is to inform the Win•     identifies a number of potential segments in the win•
dowing Agent of all phonotactically anticipated phoneme        dow. Segment Agents are spawned, two of which are 
segments for the current window. This information is ex•       illustrated, one for the predicted potential segment [p], 
tracted from all transitions traversable from the current      and one for the unpredicted potential segment |bj. The 
position in the phonotactic automaton. For example in          Segment Agent is discussed below. 
Figure 2 an fs] segment has already been recognised at 
                                                               The Segment Agent 
the onset of a syllable. Based on this the Chart Agent 
can predict a number of subsequent segments, including         Each Segment Agent, spawned by the Windowing Agent 
a [p] as illustrated. Thus, it communicates its segment        has a specific phonemic segment which it seeks to recog•
predictions, along with their constraint, rank, thresh•        nise. Segment Agents for segments which were not, pre•
old and corpus-based distributional information, to the        dicted have default information from the resource which 
Windowing Agent.                                               maps phonemes to their respective features. For exam•
                                                               ple, according to Figure 2 a Segment Agent attempt•
   Chart Agents also monitor progress through the 
                                                               ing to recognise a [b] requires that voiced (voi-f), stop 
phonotactic automaton by maintaining records of the 
                                                               and labial features all overlap in time. However, Seg•
contiguous transitions that have been traversed as a re•
                                                               ment, Agents for segments which were predicted may 
sult of recognising phonemic segments in the input. The 
                                                               have altered rankings, provided by the Chart Agent and 
Chart Agent is informed of which segments have been 
                                                               founded on corpus-based distributional information or 
recognised by Segment Agents. If the segment is one 
                                                               cognitive factors. A Segment Agent, attempts to satisfy 
which was anticipated (i.e. a phonotactically legal seg•
                                                               each of its overlap relation constraints by examining the 
ment) by the Chart Agent then the associated transi•
                                                               current, window. Each time a constraint is satisfied its 
tion is traversed.Chart Agents begin tracking the recog•
                                                               rank value is added to a running total known as the 
nition process from the initial state of the phonotactic 
                                                               Segment Agent's degree of presence. If the degree of 
automaton. If a Chart Agent reaches a final state in 
                                                               presence reaches the threshold then the Segment, Agent 
the phonotactic automaton then a well-formed syllable 
                                                               is satisfied that its segment has been successfully recog•
is logged. It is also possible that the segment recognised 
                                                               nised. For predicted segments certain constraints may 
is not one anticipated by the Chart Agent. In this case 
                                                               be relaxed, i.e. not all constraints need to be satisfied in 
an ill-formed structure is logged and the Chart Agent 
                                                               order to reach the threshold. Rather than all Segment, 
returns to the initial state of the automaton in anticipa•
                                                               Agents reporting back to the Windowing Agent, each 
tion of a new syllable. In certain cases the Chart Agent 
                                                               Segment Agent communicates its degree of presence to 
receives recognition results from Segment Agents based 
                                                               the other Segment Agents in the environment. Only if a 
on underspecified input. In these cases the Chart Agent 
                                                               Segment Agent identifies that it has the greatest, degree 
can augment the results by adding anticipated feature 
                                                               of presence and has reached its threshold will it ask the 
information provided that there is no conflicting feature 
                                                               Windowing Agent to proceed to the next window. It will 
information in the input. This is known as output, ex•
                                                               also inform Chart Agents that its segment has been suc•
trapolation. 
                                                               cessfully recognised. When a Segment, Agent finds that 
                                                               one of its constraints is satisfied it can share this result 
The Windowing Agent 
                                                               with other Segment Agents. Thus a Segment Agent at•
As previously mentioned the Windowing Agent receives           tempting to satisfy the same constraint may not have to 
segment predictions from Chart Agents for the current          do so. 
window. The Windowing Agent also takes the current 
output produced by the Feature Extraction Agents, con•
                                                               4 Benefits of the Multi-Agent Approach 
structs a multilinear representation of it, and proceeds 
to window through this representation. For each win•           The recasting of the Time Map model results in an inno•
dow examined it identifies potential segments that may         vative multi-agent system for speech recognition which is 
be present based on partial examination of the feature         significantly different from more traditional approaches. 


1478                                                                                                   POSTER PAPERS This new architecture provides a principled means of dis•                [Carson-Berndsen, 1998] J. Carson-Berndsen. Time 
tributing a computationally heavy work load among sev•                     Map Phonology: Finite State Models and Event Log•
eral task-specific agents, operating in parallel, and col•                 ics in Speech Recognition. Kluwer Academic Publish•
laboratively, thus alleviating the computational strain.                   ers, Dordrecht, 1998. 
The use of agents facilitates information sharing, search                [Carson-Berndsen and Walsh, 2000] J. Carson-
space pruning, constraint relaxation and output extrap•                    Berndsen and M. Walsh. Interpreting Multilinear 
olation. From a computational linguistic viewpoint this 
                                                                           Representations in Speech. In Proceedings of the 
architecture allows an explicit separation of the declara•
                                                                           Eight International Conference on Speech Science 
tive and procedural aspects of the model. In this way the 
                                                                           and Technology, Canberra, December 2000. 
knowledge sources can be maintained independently of 
the application which is particularly important in speech               [Erman et al, 199G] L.D. Erman, F. Hayer-Roth, V.R. 
recognition applications to ensure scalability to new task                 Lesser, and D.R. Reddy. The Hearsay-II Speech Un•
domains and migration to other languages.                                  derstanding System: Integrating Knowledge to Re•
                                                                           solve Uncertainty. Comp. Surveys Vol. 12, pp 213-253, 
                                                                           June, 1980. 
Acknowledgments 
                                                                        [Ferbcr, 1999] J. Ferber. Multi-Agent Systems - An 
This research is part-funded by Enterprise Ireland under                   Introduction to Distributed Artificial Intelligence. 
Grant No. IF/2001/021 and part-funded by the Science                       Addison-Wesley, 1999. 
Foundation Ireland under Grant No. 02/IM/I10. The                       [O'Hare et al., 1999] G.M.P O'Hare, B.R. Duffy, R.W. 
opinions, findings, and conclusions or recommendations                     Collier, C.F.B Rooney, and R.P.S. O'Donoghue. 
expressed in this material are those of the authors and do                 Agent Factory: Towards Social Robots. First Inter•
not necessarily reflect the views of either granting body.                 national Workshop of Central and Eastern Europe on 
                                                                           Multi - agent Systems (CEEMAS'99), St.Petersburg, 
References                                                                 Russia, 1999. 
                                                                        [Rao and Georgeff, 1991] A.S. Rao and M.P. Georgeff. 
[Abu-Amer and Carson-Berndsen, 2003] T. Abu-Amer 
                                                                           Modelling Rational Agents within a BDI Architecture, 
   and J. Carson-Berndsen. Multi-linear HMM Based 
                                                                           Prin. of Knowl. Rep. & Reas.. San Mateo, CA., 1991. 
   System for Articulatory Feature Extraction. In Pro•
   ceedings of 1CASSP 2003, Hong Kong, April 2003. 


POSTER PAPERS                                                                                                                         1479 