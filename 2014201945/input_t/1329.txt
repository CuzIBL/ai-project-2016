                            Learning     Forward     Models    for Robots

                                  Anthony  Dearden,   Yiannis  Demiris
                          Department  of Electrical and Electronic Engineering
                                        Imperial College London
                                  Exhibition Road,  London,  SW7  2BT
                         E-mail:  {anthony.dearden, y.demiris}@imperial.ac.uk

                    Abstract
    Forward models enable a robot to predict the ef-
    fects of its actions on its own motor system and its
    environment. This is a vital aspect of intelligent be-
    haviour, as the robot can use predictions to decide
    the best set of actions to achieve a goal. The ability
    to learn forward models enables robots to be more
    adaptable and autonomous; this paper describes a
    system whereby they can be learnt and represented
    as a Bayesian network. The robot’s motor system
    is controlled and explored using ‘motor babbling’.
    Feedback about its motor system comes from com-
    puter vision techniques requiring no prior informa-             Figure 1: A forward model
    tion to perform tracking. The learnt forward model
    can be used by the robot to imitate human move-
    ment.
                                                      its own forward models. Forward models of dynamic and un-
                                                      certain environments, and how they can be learnt, is the topic
1  Introduction                                       which is investigated in this paper. Although forward mod-
                                                      els are used in a different context, there are similarities here
The purpose of any robot is to interact with its environment. to work on calibrating action-sensor models in robotics e.g.
There is, however a separation between the effects a robot can [Roy and Thrun, 1999]. A robot learning about itself and its
produce in the environment and its mechanisms for produc- environment is in the position of being an active part of the
ing them, its motor commands. To overcome this, inverse and system it is trying to learn about; this situation draws inter-
forward models can be used [Jordan and Rumelhart, 1992]. esting parallels with learning in human infants, with mech-
In robotics, forward models enable a robot to predict the con- anisms such as babbling (issuing random motor commands)
sequences of its actions: given the current state of the robot used by infants to learn how to control their own motor sys-
they predict how a set of motor commands will inﬂuence the tem [Meltzoff and Moore, 1997].
state of the robot or its environment, or how the observa-
tions will be perceived by the robot’s sensors, as shown in A system is presented here that enables a robot to au-
ﬁgure 1. Conversely, inverse models are used to output the tonomously learn a forward model with no prior knowledge
necessary motor commands to achieve or maintain a desired of its motor system or the external environment. Informa-
goal. Both these internal models have been hypothethised tion about the effects of the robot’s actions are captured via
to be used in human motor control [Wolpert et al., 1998]. a vision system that clusters low-level image features to au-
The ability to predict the consequence of actions has several tomatically ﬁnd and track moving objects in a scene. The
uses in robotics, such as allowing mental rehearsal of possi- robot sends out random motor commands to its motor system
ble actions or imitating the actions of humans or other robots and receives information back from the vision system. This
[Demiris, 2002].                                      set of evidence is used to learn the structure and parameters
  Practically any environment a robot works in will change, of a Bayesian network, which represents the forward model.
or have properties which cannot be modelled beforehand. This model can then be used to enable the robot to predict the
Even if the environment is assumed to be completely pre- effects of its actions. By observing the gestures of a human
dictable, endowing the robot with this knowledge may be with its own vision system, the robot can imitate the human
beyond the abilities or desires of its programmer. A truly au- gesture using the forward model it has learnt of its own motor
tonomous robot, therefore, needs to be able to learn and adapt system.2  Representing   forward  models  with  Bayesian     variables are all hidden nodes, because the robot’s knowledge
   networks                                           of itself only comes from noisy observations of the state, O[t].
Bayesian networks [Pearl, 1988] are an ideal method for rep-
resenting forward models that can be learnt. They offer a way 3 How a robot can learn and use forward
of representing the causal nature of a robot’s control system models
within a rigorous probabilistic framework. The system here is The structure for a forward model described in section 2 re-
aimed at learning and representing the causal associations be- quire several aspects to be learnt. Firstly, a representation of
tween the robot’s motor commands, the robot’s state, and the the state of the robot or the environment is needed. The rich-
observations of the robot’s state that are received from the vi- est source of this information comes from the robot’s own
sion system. The motor commands and state of the robot are vision system. However, this is also the most challenging
represented as random variables in the Bayesian network, and source: information comes in the low-level format of pixels.
the causal relationships between them are shown with arcs. Furthermore, if the robot is seeking to learn its forward mod-
The Bayesian network represents a learnt probability distribu- els it has no prior information about what to track, because
tion across the previous N motor commands, M1:N [t−d], the the environment is unknown. To extract information from a
P current states S1:P [t], and the P observations of the state, scene, a method is needed of automatically initialising and
O1:P [t]. The variable d represents the delay between a mo- tracking the objects in it. The system presented here works
tor command being issued and robot’s state changing; in real by clustering tracked low-level features in the image accord-
robotic systems it cannot be assumed that the effect of a mo- ing to their position and dynamics. This allows the position
tor command will occur after just one time-step, so this is a of objects in the scene to be tracked without any knowledge
parameter that must be modelled and learnt. Figure 2 shows of the objects having to be supplied.
this structure.


Figure 2: The ‘template’ Bayesian network of a forward
model. The question marks represent the part of the struc-
ture which needs to be learnt: the causal association between
the motor commands and the state of the robot, and which ob-
servations are associated with each object in the scene. Rect-
angular nodes correspond to observed nodes.

  The N motor random variables represent speciﬁc low-level Figure 3: The vision system ﬁnds moving objects in the scene
motor commands of the robot. They could be discrete, e.g. by clustering together optical ﬂow points.
‘open’ or ‘close’ robot’s gripper, or continuous, e.g. to set
the height of the gripper. When the robot is issuing these The low-level point features used are tracked using the
commands there is no uncertainty as to their value, so they Lucas-Kanade optical ﬂow algorithm [Lucas and Kanade,
can be modelled as observed nodes. Alternatively, when the 1981]. The tracked points are clustered using the k-means
robot is observing the actions of another robot, or a human, algorithm according to their position and velocity. One draw-
whilst using its own forward model, they will be hidden nodes back of this method of clustering is that the number of clus-
because the Bayesian network will receive no direct evidence ters must be known beforehand. This is overcome by ﬁrst ex-
of their value.                                       cluding stationary points and extracting increasing numbers
  The P observations of the state-space O[t] are represented of clusters. The error of a particular number of clusters is
with square nodes descended from S[t] on ﬁgure 2. The then taken to be the average squared distance of the optical
model treats O[t] as noisy observations of the actual state ﬂow points from the centre of the cluster they are part of.
space so that noise from the vision system and other uncer- The cluster number used is the one at which the curvature of
tainty can be modelled. Evidence about the actual state of the this error with respect to the number of clusters is minimised
robot therefore enters the system here. How the state space, [Hoppner et al., 1999]. The positions, velocities and sizes of
S[t], of the robot will be represented depends on the infor- each of these clusters can now be used as the observations,
mation received from the computer vision system. The state O[t], of objects for the forward model learning system. The                                                      known, how should the data be used to learn the structure and
                                                      parameters of the network? Most methods for learning struc-
                                                      ture from data are based on performing a search through the
                                                      space of possible structures, with the goal of ﬁnding the one
                                                      that maximises the log-likelihood of the model given the data
                                                      [Friedman, 1997; Neapolitan, 2004]; the higher the log likeli-
                                                      hood, the more accurate a particular network is at predicting
                                                      the data. This is subject to a constraint on the complexity of
                                                      the model, as the structure with the highest likelihood will be
                                                      the one with connections between every node. In this paper
                                                      the network structure is learnt as part of the experiment by
                                                      performing a search through the set of possible structures and
                                                      choosing the one which maximises the log-likelihood. This
Figure 4: How the robot can learn about its environment. The search is performed online by training and evaluating simul-
stages 1-5 involved in the experiment are outlined in the text. taneously a set of candidate models. The search space is the
                                                      set of models with different delays in motor commands and
actual state of the motor system, S[t], is taken to be a hidden different observation nodes for each possible object.
discrete node for each object in the scene found by the vision The second issue is how particular motor commands and
system, and this will be connected to a continuous observa- their values should be chosen so as to learn the most ac-
tion.                                                 curate forward model. Unlike most machine learning situa-
  With all the possible nodes in the Bayesian network spec- tions, with a forward model the robot is an active part of the
iﬁed, the ﬁnal task is to learn how the motor commands in- Bayesian network structure it is attempting to learn. This sit-
teract with the state, and train the parameters of the Bayesian uation, referred to as active learning, has received relatively
network so that its predictions are as accurate as possible. To little attention in Bayesian networks literature. Active learn-
train a Bayesian network, a set of evidence is required: a data ing for Bayesian networks has been discussed for unknown
set containing actual observed values of the observed nodes in parameters and unknown structure [Tong and Koller, 2000;
the network. This is a set of N motor commands executed at 2001]. The method of choosing motor commands in the ex-
each time step, M1:N [t − d], together with the P observations periment in this paper was inspired by the idea of babbling in
of the state O1:P [t], the size, position or velocity of an object. infant motor skill learning [Meltzoff and Moore, 1997]; the
The problem now is how to use this data to learn the struc- motor commands were chosen from a random walk through
ture and parameters of the Bayesian network. An inspiration a Markov model.
for solving the problem of how to learn this Bayesian net-
work can be taken from developmental psychology. Gopnik 4 Experiments   to learn a forward  model
and Meltzoff compare the mechanism an infant uses to learn
to that of a scientist: scientists form theories, make observa- An experiment was carried out to show how forward models
tions, perform experiments, make generalisations and revise can be autonomously learnt and used. The robot used was an
existing theories [Gopnik and Meltzoff, 1998]. The notion of ActivMedia PeopleBot, as shown in ﬁgure 5. The task was
forming theories about the world is already dealt with here: to learn the forward model for the movement of the robot’s
a forward model can be seen as a theory of the robot’s own grippers; the robot needed to learn to predict the effects of
world. The process a robot uses to obtain its data and infer a the motor commands. No prior information about the appear-
forward model from it is its experiment. An outline of what a ance of the grippers or the nature of the motor commands
robot’s experiment involves is as follows, and is highlighted was speciﬁed. The robot was to perform an experiment: it
in ﬁgure 4:                                           babbled with its motor commands, observed what happened,
                                                      and then learnt the relationship between the motor command
 1. A particular motor command, M1[t] is chosen;      and the observation using a Bayesian network; this process
 2. A value for this motor command is sent to the robot’s was repeated until an accurate model had been learnt.
    motor system;                                       The motor command  in this case was limited to just one
 3. The vision system returns a set of observations of the degree of freedom: the robot’s grippers, which could be ei-
                                                 -1   ther opened, closed or halted. The motor commands were
    scene, O1:P [t+d], for example, moving forward v ms decided at random using a random walk through the Markov
    in direction x;                                   model shown in ﬁgure 6. Motor commands were sent accord-
 4. This training set of data, M1[t] and O1:P [t+d], is used to ing to the current state of the Markov model, and the state
    train the Bayesian network to develop a forward model; would change each time-step according to the transition prob-
                                                      abilities shown on the ﬁgure. The parameters of the Markov
 5. The whole process is repeated, either with a different
                                                      model were chosen so that the motor system stays in one bab-
    value for the current motor command, or a different mo-
                                                      bling state just long enough to get enough information to train
    tor command altogether.
                                                      its forward model before moving to the next state.
The open issues here relate to the last two stages. Firstly, When the motor commands were sent, the grippers moved;
if the structure of the Bayesian network is not completely the vision system correctly calculated and tracked the posi-          Figure 5: An ActivMedia PeopleBot.

                                                      Figure 7: The tracking system working on the grippers. The
         Open gripper         Close gripper           system has correctly identiﬁed two moving objects, which are
                                                      identiﬁed as grouped primitives shown with the same colour.

              0.05   0.4    0.05  0.3

                   Stop gripper


Figure 6: Markov model of gripper babbling. The values on
the arcs represent the transition probabilities of going from
one state to the next; self transitions are not shown.

                                                              The template Bayesian network for the gripper for-
tions of the moving grippers in the scene: ﬁgure 7 shows the Figure 8:
two grippers being located and tracked. The tracking sys- ward model. The vision system has supplied the information
tem worked well in this situation: black objects are automat- that two objects can be interacted with: the two grippers. The
                                                      robot still has to learn what the delay, , is from action to ef-
ically being tracked even against the black background of the                         d
robot’s base.                                         fect and which of the observations the change of state of each
                                                      object represents, a translation or a change in velocity, and
  The vision system provided the random variables for the
                                                      all the parameters that specify the Bayesian network.
states S[t] and observations O[t] in the Bayesian network
for the forward model. In this situation the two objects, the
grippers, were automatically added to the Bayesian network. one to use as part of the forward model: the velocity, posi-
Each gripper was represented as a discrete node for the state, tion or size. The task of the structure learning algorithm here
and a set of continuous nodes for the observation, both of is therefore to maximise the log-likelihood of the data given
which were represented as a Gaussian distribution. The set the model, which in this case is log (P (M, O | G)), where M
of possible observations, O[t], was the velocity, VEL[t], the is the set of motor commands over the experiment, O the set
position, POS[t], or size, SIZE[t] of the tracked objects. The of corresponding observations and G is the directed acyclic
basic template for the structure of the forward models to be graph representing the structure of the model, together with
learnt is shown by the Bayesian network in ﬁgure 8.   the parameters of the model. This value is calculated as part
  Even though the forward model of the robot’s gripper was of the parameter learning process, as a particular model is
relatively simple, this example highlighted how much the trained to the data.
robot needed to learn: all the parameters and two important For each model, the parameters of the Bayesian network
properties of the structure needed to be learnt. Firstly, it is were learnt using the expectation maximisation (EM) algo-
not known how long the delay is between the motor com- rithm, with the inference stage being performed with the
mand being issued and the gripper changing state. This is junction-tree algorithm [Pearl, 1988]. In this experiment,
shown in ﬁgure 8 as the multiple possible motor commands the search space is small enough for the robot to consider
connected to each state; only the four previous commands each possible candidate structure simultaneously. If the pre-
are shown to keep the diagram simple. Secondly, it was not vious 20 motor commands are considered and 6 possible
known which observation from the vision system is the best combinations of observation variables (VEL[t], POS[t] and                                                        10


                                                         8
                                                                            Left gripper observation
                                                         6


                                                         4

                                                                           Predicted left observation
                                                         2


                                                         0


                                                        −2                 Predicted right observation


                                                        −4
                                                        Actual  Gripper Velocities

                                                        −6


                                                        −8
                                                                            Right gripper observation

                                                        −10
                                                         0     10    20    30    40    50    60    70    80
                                                                                Time

                                                      Figure 11: Evaluating the predictive abilities of a learnt for-
                                                      ward model. The predicted gripper movements (dashed) are
                                                      close to the actual ones (solid). The differences are princi-
Figure 9: How the log-likelihoods of the Bayesian networks pally because the variation in gripper velocities for each of
using VEL[t] as the observation node evolve over the course the three motor commands are modelled as noise in the for-
of a typical experiment. The maximum log-likelihood is for ward model.
the Bayesian network with a motor delay of 11 time steps, or
550 ms

SIZE[t], for each gripper), the search space contains 120 pos-
sible models. Figure 9 shows how the log-likelihoods for the
Bayesian networks with varying motor delays and the veloc-
ity observation change over time. As the ﬁgure shows, the
motor delay which maximise the log-likelihood, d, was 11
time-steps, which is about 550 ms. Following the search, the Figure 12: Using the learnt Bayesian network as an inverse
learnt forward model for the grippers is shown in ﬁgure 10. model. Evidence is supplied to the observations or the state,
The motor command was learnt to be M[t-11], and the best and the task is to infer the probability distribution of motor
observation was learnt to be the velocity of the grippers. This commands.
was correct since the motor commands do control the grip-
pers’ velocities.
                                                      means of the observations, VEL1[t] and VEL2[t]. The in-
                                                      ference algorithm used to calculate this marginal distribution
                                                      was the junction-tree algorithm [Pearl, 1988]. To evaluate the
                      M[t-11]
                                                      quality of the learnt forward model the grippers were babbled
                                                      in a similar way as before, using a different Markov model.
                                                      Figure 11 shows how the most likely predicted observation
                  S1[t]     S2[t]                     compares with the actual observation. Only the x-coordinate
                                                      predictions are plotted because the grippers’ movements are
                                                      predominantly in this plane. The prediction is shown to be
                                                      very accurate.
                 VEL1[t]   VEL2[t]                      The learnt Bayesian network can also be used as an in-
                                                      verse model by calculating the most likely motor command
   Figure 10: The learnt forward model of the grippers. given the current velocity observation for each time-step, as
                                                      shown in ﬁgure 12. One use of this inverse model is for imi-
                                                      tation: by replacing the robot’s observations of its own move-
                                                      ment with its observations of a human’s hand movements in
   Using the Bayesian network as a forward model
5                                                     the inverse model, the robot is able to reproduce the motor
Once the Bayesian network in ﬁgure 10 has been learnt, it commands that would be most likely to recreate that human
can be used as a forward model to give a prediction of the movement in its own gripper system. The same principle is
consequences of the motor command. For the forward mod- used by Demiris to switch from imitation to recognition, al-
els of the grippers, the predicted output is the velocity of the beit in a multiple paired inverse and forward model system
grippers, calculated from the conditional probability distri- [Demiris, 2002]. Figure 13 shows the results of the imitation
bution: P(VEL[t]|M[t-4]=m). Because the observations here experiment: the robot is able to imitate a simple hand wav-
are modelled as Gaussians, the most likely values will be the ing motion. The human’s hand movements are tracked and