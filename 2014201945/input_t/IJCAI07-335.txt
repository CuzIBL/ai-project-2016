                     Fast Image Alignment Using Anytime Algorithms

          Rupert Brooks   ∗                    Tal Arbel                       Doina Precup
   Centre for Intelligent Machines   Centre for Intelligent Machines    School of Computer Science
         McGill University                 McGill University                 McGill University
          Montreal, Canada                 Montreal, Canada                  Montreal, Canada
      rupert.brooks@mcgill.ca             arbel@cim.mcgill.ca              dprecup@cs.mcgill.ca

                    Abstract                          maximize the chosen similarity measure. A number of op-
                                                      timization techniques for smooth functions, such as gradient
    Image alignment refers to ﬁnding the best transfor-
                                                      descent, have been used for this problem, and provide good
    mation from a ﬁxed reference image to a new image
                                                      solutions on a wide range of image types. However, these
    of a scene. This process is often guided by similar-
                                                      approaches can be slow, which reduces their usefulness in
    ity measures between images, computed based on
                                                      time-sensitive applications such as real-time video registra-
    the image data. However, in time-critical applica-
                                                      tion (e.g. [Wildes et al., 2001]) and medical image registra-
    tions state-of-the-art methods for computing simi-
                                                      tion during surgery(e.g. [Pennec et al., 2003]). It is possible
    larity are too slow. Instead of using all the image
                                                      to increase the speed of processing by using only a subset of
    data to compute similarity, one can use a subset of
                                                      the pixels to compute D, but this can easily lead to a reduc-
    pixels to improve the speed, but often this comes
                                                      tion in accuracy and reliability. Determining the size of the
    at the cost of reduced accuracy. This makes the
                                                      subset to use is typically done in an ad-hoc fashion, or using
    problem of image alignment a natural application
                                                      heuristics which are applicable only to certain domains. Fur-
    domain for deliberation control using anytime al-
                                                      thermore, since a different number of pixels may be needed
    gorithms. However, almost no research has been
                                                      at different stages in the optimization, a ﬁxed subset is neces-
    done in this direction. In this paper, we present
                                                      sarily a compromise.
    anytime versions for the computation of two com-
    mon image similarity measures: mean squared dif-    In this paper, we propose a deliberation control frame-
    ference and mutual information. Off-line, we learn work using anytime algorithms [Dean and Boddy, 1988;
    a performance proﬁle speciﬁc to each measure,     Horvitz, 1987] to arrive at a principled solution to the speed
    which is then used on-line to select the appropri- vs. accuracy trade-off in this problem. The ﬁrst step is to
    ate amount of pixels to process at each optimiza- learn the properties of the similarity measure under consider-
    tion step. When tested against existing techniques, ation, in terms of accuracy vs. computation time, by training
    our method achieves comparable quality and ro-    off-line on image pairs for which the transformation param-
    bustness with signiﬁcantly less computation.      eters are known. Given a new pair of images to align, we
                                                      then use this knowledge to determine the number of pixels
1  Introduction                                       that need to be considered at each step of the optimization.
The need to align, or register, two images is one of the ba- In this paper, we explore the effectiveness of this approach
sic problems of computer vision. It can be deﬁned as the using two common similarity measures, mean squared dif-
task of ﬁnding the spatial mapping that places elements in ference and mutual information, and a gradient descent opti-
one image into meaningful correspondence with elements in mizer. We tested the algorithm on several types of images:
a second image. It is essential for data fusion tasks in medical images of everyday scenes, multi-modal medical images and
imaging [Hajnal et al., 2001] and remote sensing (e.g. [Cole- earth observation data (i.e. Landsat and Radarsat images). In
Rhodes et al., 2003]). It is also widely applied in tracking and all cases, using a deliberation control approach is faster than
automatically mosaicking photographs [Szeliski, 2004]. computing the transformation using all the image data and
  One of the most straightforward and widely used ap- gives more reliable results than simply performing the opti-
proaches is referred to as direct image alignment. It works mization using an arbitrary, ﬁxed, percentage of the pixels.
by deﬁning a similarity measure, D, as a function of a refer- The remainder of this paper is organized as follows. In Sec-
ence image, and a template image warped by a transforma-
                        φ                             tion 2 we review the image alignment problem and in Section
tion with some parameters, . The computation of D typi- 3 we review methods of deliberation control using anytime
cally requires examining all pixels in each image. The align-
                                             φ        algorithms. The details of how deliberation control has been
ment problem becomes that of ﬁnding the values of that implemented in the context of image alignment are given in
  ∗Mr. Brooks was partially supported by an National Science and Section 4. Finally, Sections 5 and 6 describe our experimental
Engineering Research Council Post-Graduate Studies award. setup, results and conclusions.

                                                IJCAI-07
                                                  20782  Image Alignment                                    support partial evaluation, and knowledge about how those
Direct approaches to image alignment work by deﬁning a algorithms perform after different amounts of computation.
function D that measures the similarity between a ﬁxed ref- A class of algorithms supporting partial evaluation are any-
erence image, R(x) and a new image T (W(x,φ)). Here, we time algorithms [Horvitz, 1987; Dean and Boddy, 1988],
consider the images R(x) and T (x) to be continuous func- which provide a solution when run for any length of time. The
tions of position, x, deﬁned on some space of coordinates X. solution quality is guaranteed to improve with the amount of
The coordinate space is warped by W(x,φ) which is a map- computation performed. Deliberation control strategies us-
ping from X to X, parameterized by φ (e.g., a translation or ing anytime algorithms have been applied to both theoreti-
rotation). Since our images are actually sets of pixels located cal and practical problems including robot control [Vlassis et
at integer coordinate positions, we use linear interpolation as al., 2004], constraint satisfaction [Wah and Chen, 2000] and
needed to determine the values of T (W(x;φ)) when W (x;φ) shape extraction in image processing [Kywe et al. , 2006].
is not an integer. The similarity measure, D, is thus a func- To formulate an effective deliberation control strategy us-
tion of the transformation parameters φ, and the problem of ing anytime algorithms it is necessary to have meta-level
image alignment becomes an optimization problem, which knowledge of their performance as a function of the amount
can be solved using many standard techniques, e.g., gradi- of computation performed [Dean and Boddy, 1988; Horvitz,
ent descent, second-order methods, stochastic programming 1987]. This knowledge is stored in a performance proﬁle.
etc. All these techniques require the repeated calculation of Performance proﬁles may be based on theoretical knowledge
D, and/or its gradient, ∇φD, at different points in the space of the algorithm, on empirical testing of its performance at
of possible transformations. This is by far the most computa- different computation levels, or a combination of the two.
tionally intensive part of the process.               In any case, the decision to continue computation will be
  Recently, feature based approaches to alignment have seen based on an estimate of the accuracy of the current result,
considerable success, and can operate faster than direct ap- and an estimate of the potential improvement if the algorithm
proaches for many applications. Nevertheless, the direct ap- continues to run [Dean and Boddy, 1988; Horvitz, 1987;
proaches can yield higher overall accuracy and continue to Larson and Sandholm, 2004].
be used as a ﬁnal adjustment step [Szeliski, 2004].Further- The simplest type of performance proﬁle is a static one,
more, it is difﬁcult to match features reliably when the im- which predicts accuracy as a function of the amount of com-
ages in question are not of the same modality. Hence, direct putation completed. However, for our problem of interest,
approaches are the method of choice in applications such as this is equivalent to simply using a ﬁxed, arbitrary percent-
medical imaging [Hajnal et al., 2001] and geomatics [Cole- age of the pixels. If feedback about the current run of the
Rhodes et al., 2003], where high precision is required and algorithm is available, it can be incorporated in a more so-
multimodal imagery is common.                         phisticated approach. A dynamic performance proﬁle [Lar-
  It has long been known that numerical optimization ap- son and Sandholm, 2004] uses feedback to estimate the accu-
proaches can be signiﬁcantly accelerated by using only a sub- racy as the algorithm progresses. It is described by two func-
                                                             =      ( , )
set of the pixels in the images to estimate the similarity func- tions:a ˆ Pfwd f p , maps the percentage of computation
tion. For example, many implementations of mutual infor- completed, p, and the feedback parameter, f , to an expected
                                                                            =     ( , )
mation (e.g. [Ibanez et al., 2005]) use a random subset of the accuracy,a ˆ. The other,p ˆ Prev f a ,mapsa and f to the
image data. It has been suggested that it may be more efﬁ- expected percentage of computation required,p ˆ. Conceptu-
cient to include only pixels with high derivatives in the calcu- ally, these two functions are inverses. However, both have to
lation [Szeliski, 2004]. However, the size of the subset to be be maintained in general, to facilitate the decision making.
used is ﬁxed in an ad-hoc fashion. Unfortunately, any ﬁxed A controller can use these functions to gradually increase the
size is usually too much for some regions of the parameter amount of computation performed, until the estimated accu-
space and too little for others. Furthermore, different types of racy is adequate for the task.
images behave differently, so it is difﬁcult to come up with a
subset size that is appropriate for all cases. Instead, we will 4 Deliberation Control in Image Alignment
use a deliberation control mechanism to choose how much
                                                      As mentioned in Section 2, the most computationally inten-
computation to perform at each step of the optimization.
                                                      sive part of image alignment is the repeated evaluation of the
                                                      similarity measure D and its gradient ∇D. The optimization
3  Deliberation Control with Anytime                  algorithm needs this information in order to take a step in
   Algorithms                                         parameter space towards the optimal setting. Note that the
In many artiﬁcial intelligence tasks, e.g. planning, the quality calculation only has to be accurate enough to ensure that the
of the solution obtained depends on the amount of time spent next step is correct; determining these values exactly is not
                                                                                                      ∇
in computations. Hence, trade-offs are necessary between the necessary. Therefore, we propose to implement D and D
cost of sub-optimal solutions and the cost of spending time as anytime algorithms, and to learn performance proﬁles de-
doing further computation. This process, called deliberation scribing their accuracy at different levels of computation.
control, has been investigated in the context of real-time ar-
tiﬁcial intelligence and a number of approaches have been 4.1 Anytime similarity measures
proposed [Horvitz and Zilberstein, 2001]. Deliberation con- We implemented two popular image similarity measures as
trol methods rely on two key components: algorithms that anytime algorithms. The resulting implementations have to

                                                IJCAI-07
                                                  2079be able to support partial evaluation, as well as to continue This is true because B-splines satisfy the partition of unity
an interrupted calculation efﬁciently. To achieve this, we re- constraint. The mutual information can then be computed
deﬁne each similarity measure, D(φ), as a function D(φ, p) using the usual formula:
of both the parameters, φ, and the percentage of pixels to be
                                                                 K  L    (φ, )           α   (φ, )
used, p. To avoid biasing the computation towards one area            Pkl   p             Pkl   p
                                                      DMI(φ, p)= ∑  ∑         log
                                                                               (∑    (φ, ))(∑   (φ, ))
of the image, the pixels are processed in a random order.        k=1 l=1 pN        k Pk l  p    l Pkl  p
Mean Squared Difference                               Note that the second factor in the denominator above is just
The negative mean squared difference DMSD is one of the the intensity histogram of the original image, which is com-
most common similarity measures [Szeliski, 2004],andis puted only once, before the optimization process.
suitable for images of the same modality. In its original form, Because a 3rd order B-spline is differentiable, the gradient
DMSD is simply an average of the negative squared differences
                                                      of the joint histogram, ∇φPkl(φ, p), can be computed in the
in intensity between corresponding pixels (the negative here usual way as well, and stored in |φ| tables, each of dimension
is simply to get a similarity, rather than a distance measure). K × L.In[Th´evenaz and Unser, 2000] it is shown that when
                         
                         pN                           using the above formulation the derivative of DMI is:
                    1                       2
     DMSD(φ, p)=−       ∑  (R(xi) − T(W (xi,φ))
                   pN                                                 K L
                        i=1                                                                 Pkl(φ, p)
                                                          ∇φDMI(φ, p)=∑∑γ∇φPkl(φ,    p)log
where N is the total number of pixels in the image. The gra-                              ∑K    (φ, )
                                                                        k  l               k Pk l p
dient of this similarity measure is also easy to compute:
                                                                                                −1
                                                    where γ is the normalization factor γ =(d pN) . Thus,
                  2   pN                                                                  T
  ∇φD    (φ, p)=      ∑  [(R(x ) − T(W(x ,φ)))        when the derivative is required, we can compute it from the
      MSD       pN         i         i
                      i=1                            joint probability distribution, and its gradient.
                                                        The algorithm maintains the unnormalized probability dis-
                     ·∇W T (W (xi,φ))∇φW(xi,φ)
                 (φ, )    ∇      (φ, )                tribution, and its unnormalized partial derivatives, as de-
Note that both DMSD p and  φDMSD    p can be updated  scribed above, which can be easily updated when more pixels
incrementally in the usual fashion.                   are added, because the table entries are simple sums. The dis-
Mutual Information                                    tance measure and its gradient are then computed as needed
The mutual information (MI) image similarity measure [Viola from this table.
and Wells III, 1995] is useful for images of different modal-
ities. Our anytime implementation is based on the efﬁcient 4.2 Performance proﬁles
mutual information implementation proposed in [Th´evenaz Exploiting the partial evaluation possibilities of the anytime
and Unser, 2000], which relies on a B-spline windowed rep- similarity measures requires dynamic performance proﬁles
resentation of the joint probability distribution of the inten- describing their expected accuracy at different computation

sity levels in the two images. Speciﬁcally, let bRk ,where levels and feedback values. The notion of accuracy must be
k = 1...K,beasetofK   bins of width dR for the intensity developed in terms of the optimization method being used.
                                  R =     ( )
values in the reference image starting at b0 minR x . Simi- In this paper, we used a simple steepest descent optimizer,
                                       x                                 [                ]1
larly, let b be the bins for the intensity values in the template which is described in Ibanez et al., 2005 . Carter (1993)
        Tl                                            has analyzed a similar class of optimizers and has proven their
image, where l = 1...L, the bins begin at bT = minT (x) and
                                    0    x            convergence using the following measure of relative error:
have width dT . Then the unnormalized joint distribution is an
             ×                                                          ||∇  D − ∇      D||
array of size K L.TheentryPkl is equal to the number of             ε =   true    measured            (1)
pixels in R for which the intensity falls in bin k and the in-               ||∇trueD||
tensity of the corresponding pixels in the transformed image
falls in bin l:                                         A dynamic performance proﬁle requires a feedback param-
                                              eter which indicates the progress of a particular calculation
         pN             R                       T
                   R(xi) − b        T (W (xi,φ)) − b  run and based on the above equation the gradient magnitude
P (φ, p)= ∑  δ k,         0    δ l,               0
 kl                                                   is an ideal candidate. Thus, we designed our performance
          i=1         dR                  dT
     δ                                                proﬁles to be tables mapping computation level and gradi-
where  is equal to 1 if its two arguments are equal, and zero ent magnitude to accuracy. To construct them we sampled
otherwise. Th´evenaz and Unser (2000) use instead a soft ver- the gradient at different computation levels at many points in
sion to compute the entries in the table, based on B-spline the transformation space. For each computation level, p,we
Parzen windows. Similarly to their work, we will use: grouped the gradient magnitudes into bins and computed the
                                               
          pN         (  ) − R          (  ( ,φ)) − T  expected accuracy, E¯p, of the gradient for each bin as follows:
                    R xi   b0         T W  xi     b0
Pkl(φ, p)= ∑ β0  k −           β3  l −
          =            dR                   dT                            ||∇   D(φ ) − ∇ D(φ )||
          i 1                                                  E¯ = 1 − ∑   100%   i    p    i ,      (2)
     β      β                                                   p             ||∇     (φ )||
where  0 and 3 are 0th and 3rd order B-spline Parzen win-               i        100%D  i
dows respectively. The normalization factor of Pkl is:
                                                         1
                    K  L                                 More speciﬁc information may be found in the class documen-
                                                      tation http://www.itk.org/Doxygen/html/classitk
           α(φ, p)=∑   ∑ Pkl(φ, p)=pN
                   k=1 l=1                            1 1RegularStepGradientDescentOptimizer.html

                                                IJCAI-07
                                                  2080(where the φi are the sampled points in the transform space).
  The optimizer uses this table to progressively increase the
amount of computation performed until the estimated ac-
curacy reaches its criterion for acceptability. The analy-
sis in [Carter, 1993] indicates that signiﬁcant computational
gains can be made, with a small (ε ≈ 10%) reduction in ac- (a) boat-1      (b) boat-2       (c) boat-3
curacy. Therefore we choose to have the optimizer seek an
expected accuracy of 90% for each gradient that it computes.
  A simple example of how the table can be used to control
computation is shown in Figure 1. This table can act as a
performance proﬁle where two functions,a ˆ = Pfwd( f , p) and
pˆ = Prev( f ,a) are implemented through simple lookup. For
example, suppose an optimizer requires an accuracy of 98%. (d) grafﬁti      (e) mri-1       (f) mri-2
On an initial probe, f (which is in our case the current esti-
mated performance) is 0.55. By examining the row applying
to 0.6 and less, we get a prediction that with p = 8%, we will
obtain the desired accuracy level (arrow 1). After perform-
ing 8% of the computation, however, suppose f is now 0.1.
Thus the accuracy is only 93% (arrow 2) meaning more com- (g) Landsat-1   (h) Landsat-2    (i) Landsat-3
putation is required. The required p is now estimated as 16%
(arrow 3), and so on. In our case, the parameter p will be the
percentage of pixels processed in the image. The feedback
parameter is the magnitude of the gradient.

                                                          (j) Radar-1      (k) Radar-2     (l) Radar-3


Figure 1: Dynamic performance proﬁle example: Values in
the table represent the expected accuracy of the results.
                                                          (m) MRI T1       (n) MRI T2        (o) CT
5  Experiments                                               Figure 2: Images used for the experiments 1
To test the anytime algorithm approach, a number of per- 5.1 Generating performance proﬁles
formance proﬁles were generated, and alignments were per-
formed. Four classes of images (shown in Figure 2) with at Before performing any alignments, performance proﬁles for
least two image pairs each were used in the testing process. each combination of image class and similarity measure were
The ﬁrst image class was typical digital photos (DP) (images generated off-line. These proﬁles were constructed using
a-d). Both a) and d) were self-aligned and a) was aligned training image pairs of the same modalities as the ones to
                                                      be aligned. This training data was separate from the test-
afﬁnely against several images of the same scene taken from                                           ∇
different camera positions (images b,c) using both similarity ing data used later. For each training pair, the value of D
measures. The second class of images (M1) (images e,f) were was computed at 4000 points in the transform space, at 12
slices from T1-weighted magnetic resonance imaging (MRI) different computation levels, and the proﬁle was constructed
                                                      using the method described in Section 4.2. The resulting per-
volumes which were self-registered using the DMSD measure.
The third class of images (EO) are patches from georefer- formance proﬁles are shown in Figure 5.1. Note that each
                                                      proﬁle has a roughly similar shape. At large values of the
enced, orthorectiﬁed Landsat 7 and Radarsat imagery that                ||∇  ||
were registered to each other using the mutual information feedback parameter, φD , little computation is needed to
measure (rows 3 and 4). The ﬁnal class of images (M2) are get a good result. For smaller values, however, progressively
slices from previously registered volumes in different medical more computation is needed. This agrees with our intuition;
imaging modalities, including T1 and T2 weighted MRI, and since the image noise level remains constant, small values are
computed tomography (CT) (last row). These images were progressively harder to measure. It is the curved shape of
aligned to each other using the mutual information measure. these graphs that allows us to realize important performance
                                                      gains. A constant fraction of pixels would inevitably be too
  1Images 2a, 2b, 2c, and 2d from K. Mikolajczyk http://www. many for some feedback values and too few for others.
inrialpes.fr/lear/people/Mikolajczyk/.      Landsat     Despite their basic similarity, however, there are important
and Radarsat images (2g,2h,2i,2j, 2k,2l) from Natural Resources differences between the proﬁles. For example, note that for
Canada http://geogratis.gc.ca. Medical images (2e, 2f, both similarity measures, the medical images require a much
2m, 2n, and 2o) courtesy Montreal Neurological Institute greater percentage of computation for an accurate result for

                                                IJCAI-07
                                                  2081     Image                RMS (pixels)                    Run time (s)              Failure Rate
      Pair     GD100    GD50      GD30     AGD     GD100  GD50  GD30   AGD   GD100  GD50  GD30  AGD
    a)-a) (DP) 0.01±0.01 0.01±0.01 0.01±0.01 0.01±0.01 48.0 24.3 15.2  31.8   1.7%  3.3%  1.7%  1.7%
    d)-d) (DP) 0.02±0.02 0.01±0.02 0.01±0.01 0.02±0.02 37.7 20.6 13.1  28.2   0.0%  0.0%  1.7%  1.7%
    a)-b) (DP) 0.60±0.14 0.57±0.13 0.58±0.15 0.59±0.11 106.0 40.7 22.0 35.8   8.3%  5.0%  8.3%  5.0%
    a)-c) (DP) 0.34±0.12 0.35±0.09 0.35±0.11 0.33±0.08 59.1 36.8 21.1  27.7   5.0%  3.3%  8.3%  6.7%
    e)-e) (M1) 0.02±0.04 0.02±0.02 0.02±0.02 0.03±0.04 4.6 2.6    1.7   4.5   0.0%  0.0%  0.0%  0.0%
    f)-f) (M1) 0.12±0.54 0.03±0.04 0.03±0.05 0.05±0.07 2.9 1.5    1.0   2.7   1.7%  1.7%  1.7%  1.7%
    MSD-Avg   0.18±0.32 0.16±0.23 0.16±0.23 0.16±0.23 41.9 20.5  12.0  21.5   2.8%  2.2%  3.6%  2.8%
                                        (a) Results for the MSD measure
    Image                RMS (pixels)                    Run time (s)             Failure Rate (%)
    Pair     GD100     GD50      GD30     AGD     GD100  GD50   GD30  AGD   GD100  GD50   GD30   AGD
  m)-o) (M2) 0.41±0.17 0.57±0.30 0.72±0.72 0.55±0.33 9.9   4.5   3.4   9.5  11.7%  25.0%  40.0%  5.0%
  n)-o) (M2) 0.96±0.33 1.13±0.53 1.22±0.59 1.10±0.31 10.7  4.8   2.7  10.6  16.7%  31.7%  43.3%  11.7%
  m)-n) (M2) 0.17±0.00 0.19±0.03 0.21±0.08 0.17±0.01 6.2   3.6   2.3   5.4   3.3%  31.7%  36.7%  5.0%
  g)-j) (EO) 1.69±0.38 1.89±0.39 1.90±0.65 1.84±0.74 13.9  7.2   4.1   7.6  28.3%  45.0%  51.7%  35.0%
  h)-k) (EO) 1.19±0.02 1.19±0.05 1.19±0.05 1.19±0.01 42.8 25.4  16.2  39.6  13.3%  30.0%  51.7%  18.3%
  i)-l) (EO) 0.06±0.01 0.07±0.01 0.08±0.02 0.07±0.01 72.4 37.4  24.1  50.3   6.7%  21.7%  41.7%  6.7%
  a)-a) (DP) 0.01±0.01 0.01±0.01 0.01±0.02 0.01±0.01 115.3 62.9 37.5  14.7   5.0%   5.0%  8.3%   5.0%
  d)-d) (DP) 0.04±0.10 0.01±0.01 0.01±0.01 0.02±0.05 110.6 52.4 32.7  19.8   0.0%   5.0%  1.7%   0.0%
   MI-avg   0.42±0.59 0.47±0.67 0.50±0.73 0.46±0.67 60.7  30.9  19.1  18.2  10.6%  24.4%  34.4%  10.8%
                                        (b) Results for the MI measure
Table 1: Experimental Results: Results by image pair, and combined for each measure (bottom rows)
Algorithms: GDX - standard algorithm, using X% of pixels; AGD - Anytime algorithm. Entries shown in plain font are not signiﬁcantly
different from GD100; those in italic are ambiguous (see text) and items in bold signiﬁcantly differ from GD100.

   Performance Profiles (MSD) Performance Profiles (MI) to test the algorithms over the capture range of the optimizer.
  100                   100
               Digital Photos                         For each combination of image, similarity measure and algo-
               MRI slices
  80                     80                           rithm, the true transform was composed with these starting
                                                      positions, and the result was used to initialize the alignment
  60                     60                           process. Alignments were performed using the standard ap-

  40                     40                           proach (labeled GD100 in the graphs), the standard approach


 %  Pixels Required     %  Pixels Required            using only a speciﬁed percentage of pixels (labeled GDx, if
  20                     20
                               Digital Photos         x% of the pixels is used) and our anytime approach. The com-
                               Medical Imagery
                               Landsat−Radar          putational efﬁciency was measured in terms of running time.
   0                     0
    −3      −2       −1    −4      −2       0
   10      10       10   10       10       10         Each reported time was obtained on a 1.9GHz AMD Athlon
        Gradient Magnitude    Gradient Magnitude      machine with 3GB of RAM.
Figure 3: Performance proﬁles: The percentage of computa- To determine if any observed reductions in runtime came
tion required to achieve Ep = 90%.                    at the expense of performance, we also measured the qual-
                                                      ity and reliability of the algorithms. The quality of a result
a given gradient magnitude. The alignment tests, discussed was measured by the root-mean-square (RMS) position er-
below, reveal that these images require more computation to ror compared to the true transformation position. To calcu-
                                                      late this, 50 randomly placed points in the unit square were
align successfully. Also note that the DMI performance pro-
ﬁles for both geographic data and medical images indicate scaled to the image extent. These were transformed both us-
that no less than 30% of the pixels will ever be used for these ing the known true transformation and the computed transfor-
classes of images using this method.                  mation. The reported RMS is the square root of the mean of
                                                      the squared coordinate differences for these points.
5.2  Alignment tests                                    The reliability of each method was measured by the num-
We implemented our approach by extending an existing, well- ber of failed alignments. A particular run was considered to
tested, image alignment implementation. Speciﬁcally, we have failed when the registration converged to a transforma-
used an implementation similar to the example MultiResIm- tion that lead to RMS pixel position errors greater than 5 pix-
ageRegistration1 in [Ibanez et al., 2005], pp. 257–63, with els, or when the registration failed to converge to an answer
appropriate transforms, and with extensions added to the op- at all. In practice, we found that this criterion was rarely am-
timizer and measures to support deliberation control. The ex- biguous. The alignment would either yield results that were
perimental procedure was as follows. Three sets of 20 ran- much better than this RMS value, or much worse. Failed runs
dom starting positions were created. Each set was at a dif- were not calculated in the average times or registration error.
ferent effective distance from the identity transform in order Since each algorithm being tested was run on the same set

                                                IJCAI-07
                                                  2082