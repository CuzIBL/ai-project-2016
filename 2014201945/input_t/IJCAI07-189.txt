        An Empirical Study of the Noise Impact on Cost-Sensitive Learning
              Xingquan Zhu1, 3, Xindong Wu2, Taghi M. Khoshgoftaar1, Yong Shi3
    1Dept. of Computer Science & Eng., Florida Atlantic University, Boca Raton, FL 33431, USA 
       2Department of Computer Science, University of Vermont, Burlington, VT 05405, USA 
            3Graduate University, Chinese Academy of Sciences, Beijing, 100080, China 
               {xqzhu, taghi}@cse.fau.edu; xwu@cems.uvm.edu; yshi@gucas.ac.cn

                  Abstract                      rithm behaves in noisy environments and how to handle
                                                data errors in supporting effective CS learning. In this paper,
   In this paper, we perform an empirical study of the we report our empirical study on the impact of noise on CS
   impact of noise on cost-sensitive (CS) learning, learning. It is hoped that our observations will be beneficial
   through observations on how a CS learner reacts to 
                                                to any real-world applications with cost concerns.
   the mislabeled training examples in terms of mis-
   classification cost and classification accuracy. Our 
   empirical results and theoretical analysis indicate 2 Related Work
   that mislabeled training examples can raise serious The problem of learning from noisy data has been a focus of
   concerns for cost-sensitive classification, especially much attention in data mining (Quinlan 86b), and most al-
   when misclassifying some classes becomes ex- gorithms have a mechanism to handle noise in the training
   tremely expensive. Compared to general inductive data. For example, pruning on a decision tree is designed to
   learning, the problem of noise handling and data reduce the chance that the tree is overfitting to noise in the
   cleansing is more crucial, and should be carefully training data (Quinlan 86). In real-world applications, many
   investigated to ensure the success of CS learning. learning algorithms rely on a data cleaning model for data
                                                enhancement (Brodley & Friedl 99). Although the problem
1 Introduction                                  of error handling in supervised learning has been well stud-
Recently, a body of work has been attempted to address ied, research in the area has been mainly focused on general
cost-related inductive learning issues, with techniques inductive learning for the minimization of zero-one loss or
known as cost-sensitive learning (Tan 93, Turney 95, Paz- error rate. In reality, many applications are not only charac-
zani et al. 94), where the “cost” could be interpreted as mis- terized by error rate, but also by various types of costs (Tur-
classification cost, training cost, and test cost (Turney). ney), such as misclassification cost and test cost.
Among all different types of costs, the misclassification cost Among all different types of costs, the misclassification
is the most popular one. In general, misclassification cost is cost is the most popular one. Assume that examples of a 
described by a cost matrix C, with C(i, j) indicating the cost dataset are drawn independently from a distribution, d, with
of predicting that an example belongs to class i when in fact domain XYC, where X is the input space to a classifier, Y
it belongs to class j. With this type of cost, the objective of a is an output space, and C  [0, ) is the importance (mis-
CS learner is to form a generalization such that the average
                                                classification cost) associated with misclassifying that ex-
cost on previously unobserved instances is minimized. Ob-
                                                ample. The goal of cost-sensitive (CS) learning, from the
viously, this minimal cost is determined by two most impor-
tant factors: (1) the inductive bias of the underlying CS misclassification cost perspective, is to learn a classifier h: X
learner; and (2) the quality of the training data. Existing Y which minimizes the expected cost (Zadrozny 03)
research has made significant progress in exploring efficient  Ed (x, y,c) [c I(h(x) y)]  (1)
CS learning algorithms (Bradford et al. 98, Zuberk & Diet-
                                                  Two important issues determine the minimization of the
terich 02, Tan 93, Geibel & Wysotzki 03, Brefeld et. al. 03,
                                                expected cost: the total number of misclassifications and the
Domingos 99, Chan & Stolfo 98, Zadrozny 03, Abe & 
Zadrozny 04), with assumptions that the input data are cost of each single misclassification. To minimize overall
noise-free or noise in the datasets is not significant. In data- costs, a compromise is often made by sacrificing cheap ex-
driven application domains, many potential problems, such amples and enhancing the accuracy on classes containing
as unreliable data acquisition sources, faulty sensors, and expensive instances. This is distinct from general inductive
data collection errors, will make data vulnerable to errors. It learning, because the latter is biased towards larger classes
is therefore important to understand how a CS learning algo- (likely the cheap examples in a CS scenario). To enhance a 
                                                CS learner trained from noisy data environments, Zhu and
                                                Wu (04) have proposed a Classification Filter for data
    The support of the National Science Foundation of China un- cleansing. But the study of CS learners in noisy environ-
der Grant No.60674109 is acknowledged.          ments still lacks in-depth empirical and theoretical analysis.


                                           IJCAI-07
                                            1168 3 Experiment Setting                            Table 1. Class distributions of the benchmark datasets 
                                                        Dataset     Class Distribution Separability c4.5
 An empirical study needs a full control over noise levels in                            (   )
                                                  Credit Screening (Credit)  0.56:0.44 82.8%
 the data, so that we can observe the behaviors of the under- Wisconsin Diagnostic
 lying CS learners. For this purpose, we implement two Breast Cancer (WDBC) 0.63:0.37 93.3%
 manual corruption mechanisms, Total Random Corruption Thyroid disease (Sick) 0.94:0.06 98.7%
 (TRC) and Proportional Random Corruption (PRC). With Table 2. Major symbols used in the paper
TRC, when the users specify an intended corruption level Symbol         Description
x 100%, we will randomly introduce noise to all classes. I.e., 
                                                 E, T,      E: Training set, T: Test set, E : Noise corrupted
an instance with its label i has an x 100% chance to be mis- E, E training set, E : Noise cleansed training set
labeled as another random class (excluding class i). TRC, CS_X The average misclassification cost from dataset X
however, changes the class distribution in the dataset after Ac_Cs_X The average classification accuracy of a CS and a
noise corruption, which raises a big concern in CS Learning, Ac_Nm_X normal classifier on dataset X respectively
 because modifying the class distribution may change the h(t) vs H(t) A CS classifier vs a non-CS classifier
                                                            x: an input instance, y: class label of x, c: the cost
 average cost considerably. We then propose PRC, which x, y, c     associated to mislabeling x
 keeps the class distribution constant during the noise corrup-
                                                     r    The cost ratio between the minor class and the major
 tion. Given a dataset with Y classes, assume the original                class
                              Y                                The number of instances in the test set T
 class distribution is 1, 2,.., Y, with i i =1, where 1 and
   are the percentage of the most and least common classes  The cost of predicting that an example belongs to
  Y                                                C (i, j)    class i when in fact it belongs to class j.
respectively. For any user specified corruption level, say 
                                                     1, 2 The distribution of the major class vs the minor class
x100%, we proportionally introduce random noise to differ- The classification error rate on the whole test set, the
ent classes with instances in class i having a ( Y / i)  x 100% , 1, 2 major class examples and the minor class examples
 chance of being corrupted as another random class. That is,            respectively
                                                           The cost of classifying a major class example into
 we use the least common class as the baseline, and propor- CS
                                                      min              the minor class
 tionally introduce noise to different classes. It is obvious
                                                    CSAvg  The average misclassification cost on the test set T
 that the actual noise level in PRC is less (or even much less) CSUpper_bound The upper bound of a CS classifier
than the intended corruption level.                d(x,y,c)   The distribution of the noisy training set E
  For each experiment, we perform 10 times 3-fold cross-    The distribution of a new set constructed by sam-
                                                  d (x,y,c)              pling E
validation. In each run, the dataset is divided into a training 
                                                   Ed(x,y,c) The expected average misclassification cost of the
set E and a test set T. We introduce a certain level of noise [cI(h(x) y)] instances drawn from the distribution d
to E and generate a noisy dataset E . Meanwhile, assuming a
noise cleansing technique is able to remove all noisy in- 4 Noise Impact
stances from E , we can therefore build a cleansed dataset
E . We observe CS learners trained from E, E , and E  to 4.1 Misclassification Costs
 study noise impact (assessed by using T as the test set). The In Figs. 1 to 2, we report the noise impact on the cost of CS
 empirical study is made by the observation on three bench- learners trained from the benchmark datasets, where Figs.
 mark two-class datasets, Credit Screen Dataset (Credit), 1(a) and 1(b), and Figs. 2(a) and 2(b) represent the results
 Wisconsin Breast Cancer Dataset (WDBC), and Thyroid from different noise corruption models of the WDBC and
 disease dataset (Sick) (Blake & Merz 98), with their class Sick dataset respectively. Fig. 2(c) reports the results from
 distributions varying from almost even to extremely biased the Credit dataset (because the class distributions of the
 (as shown in Table 1). We use two-class datasets as our test Credit dataset are almost even, we only report its results on 
 bed, because a two-class problem can explicitly reveal the the TRC model). In all figures, the first and the second rows
 impacts of noise and cost-ratio on CS learning, whereas for of the x-axis represent the intended and actual noise levels
 multiple-class problems, issues such as costs among classes, in the dataset. The y-axis indicates the average cost of CS
 class distributions, and errors in each class often make it classifiers. CS_E  and CS_E  represent the average cost of a 
 difficult to draw comprehensive conclusions. We use the CS classifier trained from E  and E  (before and after noise
 C5.0 CS classification tree (Quinlan 97) in all experiments. cleaning).
  To assign misclassification cost matrix values, C(i, j), ij, As we can see from Figs. 1 to 2, for both noise corruption
 we adopt a Proportional Cost (PC) mechanism: for any two models, the average cost of a CS classifier proportionally
 classes i and j (ij), we first check their class distribution i increases with the value of r, even if the dataset is noise-
 and j. If ij, which means that class j is relatively rarer free. This does not surprise us, because we fix the cost of
than i, then C(j, i)=100 and C(i, j) equals to 100 r; otherwise C(i, j) to 100 and set the cost of C(j, i) to 100 r. So raising
C(i, j)=100 and C(j, i)= 100 r, where r is the cost-ratio, as the value of r will surely increase the average cost. When
defined by Eq. (2).                              noise is introduced to the dataset, the average cost will in-
              r  C (i, j) C ( j, i)       (2)    evitably increase, regardless of the noise corruption model
                                                 and the value of r. On the other hand, removing noisy in-


                                            IJCAI-07
                                             1169 stances can keep average costs almost the same as that of r=10 (3.5/10) is significantly larger than the increase from 
 the noise-free dataset (E). This indicates that data cleansing r=2 (0.56/2). It is obvious that given the same amount of
 is an effective way to reduce the impact of noise on CS noise in the dataset, even if noise does not change the class
 learning.                                       distribution, a dataset with a large cost-ratio tends to be 
  Although noise increases the cost of a CS classifier re- more error prone and therefore may receive a large misclas-
 gardless of the cost-ratio (r), when comparing the results sification cost. These observations indicate that when the 
from three r values, we can find that their patterns of in- dataset has a large cost-ratio value, the existence of noise
crease are different. As shown in Fig. 1(a), Fig. 2(a), and becomes fatal, and a small portion of noise can corrupt the 
Fig. 2(c), when r is small, increasing noise levels will results significantly. Because of its sensitivity to minor data
gradually raise the average cost, and the impacts of noise are errors, a dataset with a large cost-ratio will experience more
less significant for low noise level data. On the other hand, difficulties in data cleansing, if the overall goal is to mini-
for large r values, introducing a small portion of noise will mize the misclassification cost.
elevate the average cost greatly, and increasing the noise Another interesting finding in Figs. 1 to 2 is that when
level further does not show significant extra impacts. How- applying CS learners to a noisy dataset, it seems that the
ever, TRC in Fig. 1(a), Fig. 2(a), and Fig. 2(c) have already trained CS classifiers have a saturation point in reacting to 
changed the class distribution of the dataset, it is not clear the actual noise in the dataset, regardless of whether errors
that given the same amount of noise in the dataset which change the class distribution or not. When the noise level is
one is responsible for the increase of the cost: the change of below this point, it will continuously impact the CS classi-
the class distribution or the large cost-ratio r. We then turn fier. But once the noise level is beyond this point, the classi-
to Fig. 1(b) and Fig. 2(b) for answers, where the class distri- fier becomes insensitive to noise. The following analysis
bution is constant during noise corruption.      will reveal that this saturation point is determined by two
  As shown in Figs. 1(b) and 2(b), depending on the bias of most important factors: the class distribution and the cost-
the class distribution of the dataset, the actual noise level in ratio r. Given a two-class dataset, assuming its class distri-
the dataset is lower (or much lower) than the intended cor- bution is 1: 2, with 1 and 2 denoting the distribution of
ruption level. For example, in Fig. 2(b), when the intended the major class and the minor class respectively. The cost of 
noise level is 0.1, the actual noise level in the database is predicting a minor class instance as the major class is 
just about 0.012 (please refer to Section 3 and Tab. 1 for the CSmin r, with CSmin indicating the opposite cost (from the 
reason). At this noise level, the cost increase for r=2 is 0.56 major class to the minor class). Assuming that we have built
(from 1.91 to 2.47), but for r=10 the increase is about 3.5 a CS classifier from the dataset and, for a test set T with
(from 5.8 to 9.31). One may argue that this increase may be examples, the classification error rates of this classifier on 
incurred by increasing the class-ratio r, because raising r
                                                 the whole test set and the major class are  and 1
will make the minority class more expensive. Nevertheless,
                                                 respectively. The error rate for the minor class 2
even if we assume that the classification accuracy remains is the number of incorrectly classified minor class examples
the same, we can still see that the average increase from 

                                                      65
           65                        CS_E' (r=2)                                CS_E' (r=2)
           55                                         55
                                     CS_E'' (r=2)                               CS_E'' (r=2)
           45                                         45

           35                        CS_E' (r=5)      35                        CS_E' (r=5)
                                                      25
           25                        CS_E'' (r=5)                               CS_E'' (r=5)
                                                     Avg. Costs Avg.
         Avg. Costs Avg.
           15                                         15
                                     CS_E' (r=10)                               CS_E' (r=10)
           5                                           5
                                     CS_E'' (r=10)      0   0.1  0.2  0.3 0.4
            0   0.1  0.2  0.3  0.4                                              CS_E'' (r=10)
             0  0.1 0.2  0.3  0.4                      0   0.07  0.15 0.22  0.29
                   Noise Level                                Noise Level

            (a) WDBC dataset, total random noise (TRC) (b) WDBC dataset, proportional random noise (PRC)
                    Fig. 1. Impacts of class noise on the average cost of a CS classification algorithm

 100
                       CS_E' (r=2) 17                   CS_E' (r=2) 60                  CS_E' (r=2)
 80                               15
                                                                  50
                       CS_E'' (r=2) 13                  CS_E'' (r=2)                    CS_E'' (r=2)
 60
                                  11                              40
                                   9
 40                    CS_E' (r=5)                      CS_E' (r=5)                     CS_E' (r=5)
                                                                  30
                                   7
Avg. Costs Avg.
                                                                 Avg. Costs Avg.
                                  Avg. Costs Avg.
 20                    CS_E'' (r=5) 5                   CS_E'' (r=5) 20                 CS_E'' (r=5)
                                   3
  0
                                   1                              10
   0  0.1 0.2 0.3 0.4  CS_E' (r=10)                     CS_E' (r=10)                    CS_E' (r=10)
                                    0  0.1 0.2 0.3 0.4             0   0.1 0.2 0.3 0.4
    0  0.1 0.2 0.3 0.4
                                     0   0.012 0.025  0.036 0.047   0  0.1 0.2 0.3 0.4
       Noise Level     CS_E'' (r=10)    Noise Level     CS_E'' (r=10)    Noise Level    CS_E'' (r=10)

  (a) Sick dataset, total random noise (TRC) (b) Sick dataset, proportional random noise (PRC)  (c) Credit dataset, total random noise (TRC)
                    Fig. 2. Impacts of class noise on the average cost of a CS classification algorithm


                                            IJCAI-07
                                             1170 divided by the total number of minor class instances, as s- From Section 3 and Tab. 1, we know that 1:
 hown in Eq. (3). Then, the average misclassification cost in 2=0.627:0.373 (r > 1/ 2 for any r=2, 5, 10) and
 T, CSAvg, is denoted by Eq. (4).                CSmin=100 for the WDBC dataset. So according to Eq. (5) 
                             (    )              CS       is 62.7, which is consistent with the results in
       (       1  1 ) (  2 )  1   2    1  1  (3)   Upper_bound
     2                                           Fig. 1(a). Now the interesting results come from the results
              1  2    1   1         2
                                                 in Fig. 2(a), which also clearly poses a saturation point of
            1  1          2  2
    CS Avg (       CS min        r CS min )      the misclassification cost. According to Table 1 and Eq. (5),
             1   2         1   2           (4)   we know that for the Sick dataset 1: 2=0.94:0.06, so the

       1  1 CS min (  1    2   1  1 ) r CS min   ratio between 1/ 2 is far larger than the value of r. As a
                                                 result, the CSUpper_bound should be r CS ( ) 6 r
                      1   2                                                    2   min 1 2
  When the average error rate  increases, it normally raises (corresponding to the second item in Eq. (5)). Unfortu-
                                                 nately, the results in Fig. 2 (a) indicate that the real CSUp-
the average misclassification cost CSAvg, with its value
bounded by an upper bound given by Eq. (5).      per_bound we got is about 94, which actually equals the value
                                                 of having all instances classified into the minor class (the 
                1   CS       if  r    1
                       min                 (5)   first item in Eq. (5)). In reality, it is understandable that the
              1   2                   2

  CS Upper _ bound                               underlying CS learners are reluctant to stick to the major
                2
                    r  CS min   Otherwise        class for minimal misclassification cost, especially when
              1   2                              noise has changed the apriori class distributions signifi-
  Actually, the upper bound in Eq. (5) is the average cost of cantly. Instead, the CS learners will tend to stick to the mi-
 predicting all instances belonging to the minor class when r nor classes in high uncertainty environments. As a result,
   1/ 2, or predicting all instances belonging to the major the results from this seriously biased dataset are consistent
 class when r < 1/ 2 (which is the optimal solution for a CS with the conclusion drawn from the first item in Eq. (5). 
 classifier with low confidence, because any cost higher than Based on the above observations, we know that given
 this upper bound is not necessary). It is understandable that datasets with the same noise level but a different cost-ratio 
 CSAvg CSUpper_bound holds most of the time, which eventu- value r, the larger the cost ratio r, the smaller the value of
 ally produces the inequality denoted by Eq. (6). Since *, then the dataset is more likely to approach to a satura-
                    (           ) r   if r       tion point, where the misclassification cost appears to reach
 CS  CS         1 1   1    2 1 1    1      1 2
   Avg Upper_bound  (           ) r r  Otherwis  the maximum. Meanwhile, class noise does not continu-
                1 1   1    2 1 1     2           ously make an impact on the CS classifier all the time, and
      (1  1 ) 1  1  1 r
so                      if r   1  2     (6)      after noise reaches a certain level, the CS classifier may
          r (     )
              1  2                               simply stick to the minor class. As a result, the impact of the 
      (        ) r
        2   1 1     1  1 Otherwise               noise in the system becomes constant. Given a dataset with 
           r (     )
              1   2                              r   /   (which is pretty common in reality), the higher the
  For two class problems + =1, so Eq. (6) becomes    1 2
                     1  2                        cost-ratio, the more likely the classifier tends to do so. For
                   {(1  )   } r if r
         *    1  1      1  1           1  2  (7) situations r < 1/ 2, the conclusions will also likely hold.
              2  (1 1 r) 1 1   2 Otherwise
  With the inequality in (7), we can finally analyze the rela- 4.2 Classification Accuracies
tionship between the class distribution 1, 2, the cost ratio The above observations conclude that a dataset with a
r, and the error rate , and reveal the following facts: higher cost-ratio is sensitive to data errors, and learners built
 1. Given a test set T, the average misclassification error from such data are most likely cost intensive. This conclu-
    rate  of a CS classifier, which is trained from a training sion does not, however, solve the concerns like: (1) why is a 
    set equivalent to T, is bounded by a critical value * de- learner built from noisy data with large cost-ratio cost inten-
                                                 sive? and (2) given any noisy dataset D, if users were able to
    fined by Eq. (7). When r / , the higher the value of
                         1 2                     build both a normal classifier or a CS classifier, which one 
    the cost-ratio r, the lower the *, and the more likely the
                                                 of them is more trustworthy in identifying noisy examples?
    classifier tends to approach the saturation point.
                                                 Now, let’s refer to the theoretical proof and empirical com-
 2. In theory, when r < / , * becomes        ,
                    1 2           2  (1 1 r) 1 1 parisons of the classification accuracies between a normal
    which can be approximated as 2. This means that the classifier and a CS classifier for answers.
    larger the number of minor class instances (a larger ),
                                            2    The following analyses are based on an existing Folk Theo-
    the higher the *, and the less likely the classifier tends
                                                 rem* (Zadrozny et. al. 03), which states that if we have
    to approach the saturation point. However, this conclu-
                                                 examples drawn from the distribution:
    sion crucially relies on the fact that the underlying CS
    learner is “optimal” and indeed knows that sticking to
    the major class will lead to the lowest cost, which is not * It was called “folk theorem” in the literature, because the authors con-
    always the case in reality (as we will analyze next). cluded that the result appears to be known, although it has not been pub-
                                                 lished yet. 


                                            IJCAI-07
                                             1171                         c                       Because h(t) was built on a biased distribution d  sampled
          d'(x, y, c)          d(x, y, c)  (8)   from d, therefore Err (H (t)) Err (h(t)) ; otherwise, there
                     E      [c]                                  d         d
                       d ( x, y, c)              is no need for H(t) to exist (we can directly use h(t) on d for
where d(x,y,c) represents the distribution of the original normal classification). Therefore, we have Eq. (14) and the
dataset E, then the optimal error rate classifiers built for statement of Theorem 1 is true.
newly constructed distribution d are the optimal cost mini-
                                                                Err (H (t))   Err (h(t))   (14)
mizers for data drawn from d. This theorem states that if we      d              d
sample from the original distribution, d, of dataset E and Now let’s turn to the experimental results in Fig. 4 to
constructing another distribution d , the efforts which try to evaluate whether the empirical results indeed support our
learn an optimal error rate classifier on d  actually leads to a theoretical analysis (the meaning of each curve in Fig. 4 is
classifier which optimizes the misclassification cost for d. denoted in Fig. 3). In Fig. 4, Ac_Cs_E and Ac_Nm_E  indi-
                                                 cate the classification accuracies of a normal and a CS clas-
THEOREM 1: For a dataset E with a distribution d, assum- sifier trained from E  respectively. As shown in Fig. 4, when 
ing we are able to use an optimal learning theory to build a the cost-ratio is small (r=2), the differences between the
CS (h(t)), and a normal classifier (H(t)) respectively. Then accuracies of the normal and CS classifiers are trivial, with
h(t) is inferior to H(t) in terms of the average classification the accuracy of the CS classifier slightly worse. This is un-
accuracy. That is, Errd(H) Errd(h), where ErrX( ) represents derstandable, because a CS classifier likely sacrifices the 
the classification error rate of the classifier on X. accuracy for minimal costs. When the cost-ratio gets larger
Proof:                                           (r=5 or higher), the accuracy of the CS classifier becomes
Assume a CS classifier h(t) was built from d. Then with the significantly worse than the normal classifier. If we compare
CS learning formula in Eq. (1), the expected cost of h(t) on Fig. 4(a) with Fig. 1(a) and Fig. 4(c) with Fig. 2(a), we can
d can be denoted by Eq. (9).                     find that this is actually the reason a dataset with a large
                                           (9)
   Ed (x, y,c)[c I(h(x) y))] d(x, y,c) c I(h(x) y) cost-ratio is more willing to approach to the saturation
                      x, y,c                     point. In this situation, a small portion of noise will make
 With the folk theorem in Eq. (8), we know that  the CS classifier ignore the classification accuracy and stick
              c            , where d   is the sam- to the “optimal” class.
 d ( x , y , c )    d ( x , y , c )
           E d ( x , y , c ) [c ]                  Theorem 1 together with the results in Fig. 4 clearly indi-
 pled distribution from d. Then Eq. (9) becomes. cates that in general situations, a CS classifier is inferior to a
                                                 normal classifier, in terms of classification accuracy. Be-
 E    [c I (h(x) y))] E [c] d (x, y,c)I (h(x) y)
  d ( x, y,c)       d ( x, y,c)           (10)   cause removing mislabeled training examples was shown to
                          x, y ,c
                                                 lead to a better CS learner (as shown in Figs. 1 to 2), class 
                    E    [c] E  [I (h(x) y)]
                     d ( x, y ,c) d ( x, y,c)    noise handing for effective CS learning will crucially de-
 We can transform Eq. (10) as follows.           pend on accurate noise identification mechanisms. As a re-
                                                 sult, in noisy environments, if we want to adopt a noise
                      1
    Ed (x,y,c)[I(h(x) y)] Ed (x,y,c)[c I(h(x) y)] identification mechanism for data cleansing, we shall trust a 
                   Ed (x,y,c)[c]          (11)   normal classifier rather than a CS classifier, because the
                     c                           former always has a higher accuracy in determining the
                         E    [I(h(x) y)]
                          d (x,y,c)              right class of an instance. 
                   Ed (x,y,c)[c]

                                                       Ac_Cs_E' (r=2) Ac_Nm_E' (r=2) Ac_Cs_E' (r=5)
                                                        95
 BecauseE    [c] arg max {(x, y,c) d} , Eq. (11)        75
                                                        55

         d ( x,y,c)    c                               Accuracy
                                                        35
                                                        0  0.1 0.2 0.3 0.4
 becomes                                               Ac_Nm_E' (r=5)Noise Level Ac_Cs_E' (r=10) Ac_Nm_E' (r=10)
                                          (12)
    Ed ( x,y,c)[I(h(x) y)] Ed ( x,y,c)[I(h(x) y)]        Fig. 3. The meaning of each curve in Fig. 4 

 That is Errd    (h(t))     Errd (h(t))  (13)


    95                      95                    100                    99
                            85                                           98
    85                                             80
                                                                         97
    75                      75
                                                   60                    96
    65                      65                                           95
                                                   40
                            55                                           94
                          Accuracy


   Accuracy 55
                                                                        Accuracy
                                                 Accuracy                93
                            45                     20
    45                                                                   92
    35                      35                     0                     91
     0   0.1  0.2 0.3 0.4    0   0.1 0.2 0.3 0.4    0   0.1 0.2 0.3 0.4   0   0.1 0.2  0.3 0.4
        0 0.1 0.2 0.3  0.4     0  0.07 0.15 0.22  0.29   0  0.1 0.2  0.3 0.4   0  0.012 0.025 0.036  0.047
           Noise Level             Noise Level            Noise Level           Noise Level

    (a) WDBC Dataset (TRC)  (b) WDBC Dataset (PRC) (c) Sick Dataset (TRC) (d) Sick Dataset (PRC)
             Fig. 4. Impacts of class noise on the classification accuracy of normal and CS classification algorithms


                                            IJCAI-07
                                             1172