              Call-Graph Caching: Transforming Programs into Networks 
                                            Mark Perlin 
                                     School of Computer Science 
                                     Carnegie Mellon University 
                                        Pittsburgh, PA 15213 

                 Abstract*                          caching call-graphs. 
                                                      In this paper, we present a new program transformation 
    There are computer programs that use the same   Call-Graph Caching (CGC) that partially evaluates and then 
    flow of control when run on different inputs. This reuses a program's control structure. We: 
    redundancy in their program execution traces can    1. Provide applicability conditions for the use of 
    be exploited by preserving suitably abstracted        CGC. 
    call-graphs1 for subsequent reuse. We introduce a   2. Present a working prototype EVAL' which 
    new programming transformation Call-Graph             performs partial evaluation of LISP programs 
    Caching (CGC) which partially evaluates the con•      into executable call-graphs. 
    trol flow of sets of such programs into a network 
    formed from their call-graphs. CGC can              3. Show how CGC helps in the conceptual and 
    automatically generate efficient state-saving         implementational derivation of efficient state-
    structure-sharing incremental algorithms from         saving structure-sharing incremental network 
    simple program specifications. As an example,         algorithms. 
    we show how a straightforward, inefficient LISP 
    program for conjunctive match is automatically      4. Illustrate how CGC exploits the fixed call-
    transformed into the RETE network algorithm.          graph structure to reverse the flow of com•
    Simple and understandable changes to elegant          putation: data can flow up the call-graph, in•
    functional (and other) programs are automatically     stead of always moving top-down from the 
    translated by CGC into new efficient incremental      program. Thus program execution can be 
    network algorithms; this abstraction mechanism is     driven from incremental changes in input data, 
    shown for a class of conjunctive matching al•         instead of being rigidly preset. 
    gorithms. We establish criteria for the appropriate The utility of CGC is demonstrated by: 
    application of CGC to other AI methods, such as     1. Using CGC to transform a simple, inefficient 
    planning, chart parsing, consistency maintenance,     LISP program for conjunctive matching into 
    and analogical reasoning.                             the classic RETE match algorithm [Forgy, 
                                                          1979]. This also demonstrates the use of our 
1 Introduction                                            automatic transformation prototype EVAL\ 
                                                        2. Showing other applications of CGC in AI, 
Caching is a general efficiency mechanism for exploiting  such as indicating how small changes in our 
redundancy in computation by reusing previously computed  conjunctive match LISP program can 
information. For example, AI systems often cache problem  mechanically generate alternative network join 
solving experience learned over time, or knowledge, as a set topologies. Such transformations enable 
of programs. Intelligent interactive systems apply this   researchers to spend minutes modifying short 
program set over repeated cycles of interaction with external functional programs, instead of months 
data input. We define as persistent those intelligent inter• engaged in low-level network programming. 
active systems that apply all knowledge to all data on every 
                                                        3. Suggesting that CGC is uniquely suited to AI, 
cycle. Straightforward implementations of persistent sys• in that it potentially increases the efficiency of 
tems are often inefficient, since only some programs in the persistent knowledge-based systems. 
knowledge base are relevant each cycle, and potentially 
reusable intermediate computations are discarded.     CGC differs from ordinary data or instruction 
  We have identified a key source of computational redun• caching [Baer, 1980] in that control decisions, not data or 
dancy: a program's flow of control, or "call-graph" struc• actions, are stored Unlike function caching [Pugh, 1988], 
ture. This control-flow redundancy can be exploited by CGC caches network traces, not computed function values. 
                                                    CGC observes, records, and removes the control decisions 
                                                    of a program (executing on some input), whereas program 
                                                    dependence graph methods [Ferrante, 1987] do not diminish 
                                                    control flexibility. 
  This work was supported in part by grant R29 LM 04707 from After first introducing the CGC transformation (Section 
the National Library of Medicine, and by the Pittsburgh NMR 2), we show how to transform matching programs into 
Institute.                                          RETE networks (Section 3). We then present a number of 
  1A call-graph is a trace of an executing program's flow of other uses of CGC in AI (Section 4). 
procedural control. With recursive languages like LISP, this is the 
explicit tree of a program's dynamic procedure calls. 


122 Tools 2 Call-Graph Caching                                               tion, directed from just the changes to their input.4 When 
                                                                   coupled with finite differencing, state-saving incremental 
Call-graph caching is a program transformation from ar-           algorithms result. 
bitrary programs2 into network programs. After defining              The price for this efficiency is inflexible control structure: 
our notion of "program", and establishing what "network           NETWORK program DAGs have the restricted form of 
programs" are, we motivate how the control flow of a              basic blocks [Aho, 1986]. Despite this limitation, NET•
program can be cached into a netwoik. We then present the         WORK finds extensive application. Efficient incremental 
mechanics of the transformation, and describe an implemen•        spreadsheets use the algorithm sketched above. Conjunctive 
tation.                                                           matching programs are often cast in network form for ef•
                                                                  ficiency. Other potential applications include the represen•
2.1 Programs                                                      tation of dependency relations, multiple inheritance, consis•
Programming languages provide action constructs that              tency maintenance reasoning [Doyle, 1979], and incremen•
operate on input data, sequenced according to some control        tal attribute grammar evaluation [Reps, 1983]. 
organization. The actions are applied to the data by an 
evaluator (such as LISP's EVAL), which may also partially         2.3 Caching Control Flow 
determine the control sequencing. Program execution               Let P(x,y) be a program in some language, having ar•
proceeds by traversing the program's actions according to         guments x and y. Suppose that P's control structure is inde•
the control organization, and evaluating the actions on the       pendent of y. Then partial evaluation [Futamura, 1971] of 
data. For example, LISP's control mechanism is recursion,         P(x,y) with respect to some fixed xo will yield a new 

which coordinates the --expression actions on data ar•            program P'x0(y) of one argument having a unique call-
guments, such as symbols and lists. Traversal of a LISP           graph. 
program's code tree recursively executes EVAL on the                 An interactive program's input either depends on external 
X-expressions and arguments at each node in the tree.             factors, or is independent of external interactions. Now sup•
                                                                  pose that program P(x,y) is interactive, and its argument x is 
2.2 Network Programs 
                                                                  independent of external factors. Then P\y) 
There are programs that operate by traversing an acyclic               1. completely characterizes P(x,y)'s interactions 
network. The actions of such programs reside and are ex•                  with the external environment, and 
ecuted at network nodes, while their control organization is 
represented by netwoik links. The links of the directed                2. has a unique call-graph. 
acyclic3 graph (DAG) encode a partial ordering of the             We define an interactive program P(x,y) to be basic when x 
nodes. Programs whose netwoik traversals are guaranteed           is independent of external factors, and P's control structure 
to respect this partial ordering belong to the class NET•         is independent of y. 
WORK. Partial order enumeration is usually implemented               P'(y) has a unique call-graph which can be cached as a 
with some version of topological ordering [Knuth, 1973],          NETWORK program for later reuse. The program's actions 
and assures that every DAG node is visited exactly once:          are encoded in the call-graph nodes; each node is allocated 
after each of its predecessors have been visited.                 local memory. The program's control flow decisions are 
  When input data is presented to the leaves, computations        recorded as call-graph edges. Applying input data to the 
propagate through the network. The results of local node          call-graph leaves, a bottom-up graph traversal (respecting 
computations can be locally stored in node memory. A              the nodes' partial ordering represented by the edges) can 
node uses memories of predecessor nodes in bottom-up              correctly execute the program. We therefore have a new 
NETWORK computation similarly to a stack frame's use of           NETWORK program operationally equivalent to the par•
recursive return values in usual programming languages.           tially evaluated P, as illustrated in Figure 1. 
Since the netwoik persists between cycles, finite 
differencing [Paige, 1982] can reduce redundant computa•
tions at a node. To implement this incremental strategy, 
node memory is divided into a short-term buffer and a 
longer-term store, the use of which is shown below. 
  NETWORK programs are very efficient, with overhead at 
most linear in IDAGI, the number of nodes and 
edges [Hoover, 1987]. Propagating from all the leaves, and 
keeping newly computed values in nodes' buffer memory, 
topological ordering assures that each node is recomputed 
exactly once [Perlin, 1988a]. If changes are made to only a 
subset of DAG leaves, using the store memory (which per•
sists between change cycles) the computation need only be 
propagated to the transitive closure DAG subset AF•
FECTED, IAFFECTEDI < IDAGI. This produces 
state-saving algorithms that perform minimal recomputa-


  2Our initial focus in Sections 2 and 3 is on functional-style LISP 
programs. In Section 4 we look at other programming language 
styles, such as rules. 
                                                                    4Further efficiency gains are possible by restricting the DAG 

  3Graphs with cycles are also admissible, as long as the cycles  traversal to the subgraph influencing only select node computa•
are broken at run time; i.e., the graph acts like a DAG.          tions. 

                                                                                                                 Perlin 123  2.4 The Transformation                              with the partially evaluated P'(y) preserved as a call-graph. 
 We describe the Call-Graph Caching (CGC) transformation The second step of Control-Flow Caching connects the ex•
 in several loosely coupled steps. The first step assembles ternal input y to the program's graph. As shown in Figure 
 the call-graph from its subgraph components. The second 2, step 2, the resulting call-graph of the complete program is 
 collects a set of call-graphs into a network. The resulting a DAG6. 
 cached call-graph network structure is used (and reused) as The third step operationalizes the call-graph into a us•
 a data cache. Pedagogical examples on simple polynomials able data structure. For example, graph nodes can be aug•
 are detailed in [Perlin, 1988b].                   mented with the requisite buffer and store memory with a 
                                                    system-specific representation. 
 2.4.1 Building the Call-Graph                        At this point, saving and reusing just this single call-
   Control-Flow Caching is an algorithm which builds the graph provides a fully functional state-saving NETWORK 
 call-graph of a program on some input. The construction program. Directing input y through the graph in a partially 
 takes as                                           ordered node enumeration, with the node memories as a 
                                                    data cache, will perform the computations of P(xo,y). More 
    • input either                                  efficient incremental evaluation via finite differencing is ef•
          1. the compile-time text of a program,    fected by using the local buffer memory to (1) record in-
           together with its partial input, or      tracycle computations and (2) differentially update the local 
         2. the run-time program executing on its   intercycle store memory. 
           complete input, and                      2.4.2 Collecting Call-Graphs 
    • outputs the call-graph of that program.         The Call-Graph Caching transformation is completed by 
 The procedure employs an auxilliary data structure, the collecting a set of P(xo,y) call-graphs, for a variety of P's 
 Conxrol-Flow Cache, which is used in the assembly of the and xo's. This set is called the Call-Graph Cache, and, like 
 final call-graph structure. There is also an optional ar• other caches, usually employs efficient cache management 
 gument specifying the key execution steps to cast into graph strategies. For example, spreadsheets and conjunctive 
 nodes.                                             matchers exploit common shared prefix structure, with 
   Control-flow caching proceeds as three separate steps. trie-like [Aho, 1983] merging of call-graphs into a single 
 First, with a program, (partial) input, and a user-definable connected network. In allocating the often limited resource 
 set of the key steps to abstract5 a trace is formed of the of space, another common strategy is to perform a 
 program's execution. Each node in the resulting call-graph cost/benefit analysis, detemiining which call-graphs stay in 
 represents one (key) step in the program's trace. The actual the cache, and which are removed. 
 formation of the call-graph is facilitated by specific control-
 flow cache management strategies. One such strategy is the 2.43 Using the Call-Graph Cache 
 above abstraction mechanism of recording only the "key" After building the call-graphs of {P(xiy) I ie 1} and col•
 steps as nodes. Another strategy, used in chart    lecting them into a call-graph cache, the resulting network is 
 parsing [Winograd, 1983], Ls exploiting the constraints used (and reused) as a data cache. Values or sets of values 
 posted in the control-flow cache to help reduce the execut• of y propagate bottom-up through the network, employing 
 ing program's computation, i.e., dynamic programming. the buffer memory within each propagation cycle, and store 
 Yet another, say for a LISP program, would be to passively memory between cycles. For efficiency and correctness, the 
 cache the succession of execution branches into a full call network traversal control mechanism is partial order 
 tree. Regardless of the specific strategies, the resulting call- enumeration (implemented with a topological sort). 
 graph captures (in space) the program's execution over time, This completes the transformation of a finite set of basic 
 as shown in Figure 2, step 1.                      programs (in any programming language) into an efficient 
                                                    state-saving NETWORK program. 
                                                    2.5 An Implementation 
                                                    To demonstrate the workability of Call-Graph Caching, we 
                                                    implemented in Common LISP a simple partial evaluator 
                                                    EVAL\ which transforms a large class of LISP programs 
                                                    into their corresponding call-graphs. The input to EVAL' is 
                                                    the symbolic LISP expression representing "P(xo,y)'\ for 
                                                    some P and XQ, and a set of labels denoting the key execu•
                                                    tion steps to cache. The output is a call-graph, where each 
                                                    node specifies 
                                                        • the label of the node type; 
         (1) (2) (3)                                    • a lambda expression containing all the infor•
                                                         mation required to execute the node's computa•
   Figure 2: Control-Row caching: assembling the call-graph. tion when applied to the values of its immediate 
                                                         predecessor nodes; 
   Program P(x,y) has thus far been evaluated on input XQ, 


                                                      6This is because the caching of the program's execution over 
  5This user-definable set ranges from the empty set to all possible time breaks (i.e., unravels) any cycles present in the flow of con-
 steps.                                             trol. 

124 Tools      • recursively, the nodes of its immediate                    which applies a set of tests to a set of objects, producing a 
      predecessors.                                               filtered set of n-tuple instantiations. 
   EVAL' performs the following computations:                        Production systems are persistent, in that they 
     1. Arrive at (the label of) a key node (i.e., LISP                 1. maintain their knowledge in a finite set of ex-
        function or symbol) to be abstracted.                             perientially derived programs (the rule set), 
                                                                          and 
     2. Perform EVAL' on the unevaluated arguments 
        to the function.                                                2. apply all programs to all available data on 
                                                                          each interactive cycle. 
     3. Substitute these values into the function, and 
                                                                  They are also inefficient. Consider just one rule having n 
        then execute EVAL' on the LISP function's 
                                                                  conditions matching against only two data objects- the set of 
        code tree. 
                                                                  candidate instantiations Dn grows exponentially in n. In 
This delayed evaluation is done recursively, caching the          fact, conjunctive rule matching is NP-hard [Minton, 1988]. 
control structure into a call-graph. The call-graph's nodes       Generally, however, only a small fraction of the object set 
abstract out the set of labelled functions, preserving the lo•    changes each cycle. So instead of rigidly applying all rule 
cal actions required for later execution.                         programs to the data, perhaps the incremental changes to 
   We have also developed a variety of network structure-         data should drive the matching computation. 
sharing programs for merging call-graphs, and a partial or•          For each rule program in the rule set specifying some 
der network traversal toolkit for executing these cached          tests in TESTS, Atoc/i(tests,D) is the computationally ex•
Call-Graph networks as programs. Our working implemen•            pensive subprogram. Observe that with 
tations have demonstrated the efficacy of transforming 
                                                                       P = Match, x = tests, and y = D, 
simple LISP specifications into efficient incremental net•
work programs on AI examples such as RETE matching.                     1.x is independent of the external data input D, 
                                                                          and 
3 RETE Networks: An Example of Call-Graph                              2. the conjunctive matcher P(x,y) is programm•
Caching                                                                   able so that P's control is independent of y 
                                                                          (e.g., Section 3.2). 
RETE matching is a state-saving structure-sharing in•             Therefore P is basic, and Call-Graph Caching will generate 
cremental algorithm used in OPS-5 and other production            an efficient state-saving structure-sharing incremental 
systems for conjunctively matching many patterns against          Matching algorithm. 
many objects. Because it provides excellent average-case 
behavior for an important NP-hard AI problem, it has been         3.2 Transforming Rule Matching into RETE Networks 
extensively studied and varied. It is also a good example of      We illustrate the use of Call-Graph Caching by generating 
the Call-Graph Caching program transformation, illustrating       the RETE network from a simple functional programming 
nontrivial usage of the Control-How Cache and the Call-           specification of the matching function. 
Graph Cache. 
                                                                        1. We stan from an easily specified, though in•
                                                                          efficient, set of functional programs. 
3.1 Rule Matching 
Forward-chaining Rule Systems (or "production systems")                2. Using an auxilliary Control-Flow Cache, par•
such as OPS-5 are programming languages with match as                     tial evaluation of the basic program 
their control element. Program data is organized into a set               match(T0X>) produces a call-graph capturing 
of rules, having left-hand-side (LHS) tests and RHS actions.              match9(D)'s control flow. This call-graph is 
External input (often called "working memory") comes from                 usable as an incremental data-driven 
a slowly varying set D of data objects. If a rule's tests                 state-saving NETWORK program which can 
match objects, the rule becomes a candidate for firing; when              store processed input data as intermediate 
executed, its actions serve to modify D.                                  matching results. 
   Following common practice, we fix the form of the rules'             3. The Call-Graph Cache merges the individual 
LHSs to be a set of conjunctive conditions, each condition                call-graphs in order to conserve space, and 
containing tests restricting the set of matchable objects. An             achieve some speedup. This is done by test 
instantiation of a rule having n LHS conditions is an n-tuple             sharing: nodes with common test prefixes are 
of objects satisfying the rule's LHS tests. On every inter•               combined to form a single trie data structure. 
action cycle, the rule evaluator must try to match each rule 
against all possible combinatioas of objects in D, forming        We now detail this construction of the RETE network algo•
its set of instantiations                                         rithm. 
                                                                  3.2.1 Rule Matching as LISP Programs 

                                                                     A rule specifies a fixed set of tests T0 for its match com•
                                                                  ponent. The conjunctive match program Match(T0,D) can 
                                                                  be formulated so that its control is independent of working 
                                                                  memory D. We now write such a filter Match as a 
                                                                  functional-style LISP program. 
                                                                     For efficiency on a serial processor, we first impose a 
                                                                  fixed ordering on the rules' conditions. Each test examines 

                                                                  one or more objects in a candidate n-tuple e Dn; these 
                                                                  objects are now ordered by the condition ordering. We now 
                                                                  order the test set: associate to each test the number of the 

                                                                                                                  Perlin 125  last object it examines, and arrange the tests with respect to 
 this index. For efficiency, the match is performed by a 
 conditional AND, testing a candidate n-tuple against the 
 first test subset, then the second, and so on through the nth. 
 Within the kth test subset, k < n, the tests may be further 
 grouped into two classes: 
     A. alpha tests on a single object e D, and 
     B. beta tests on more than one object, i.e., k-
        tuples € Dk. 
   There are many ways to write the LISP code for this 
 simple filter (e.g., as one function, iteratively, recursively, 
 etc.). While the CGC transformation is independent of pro•
 gramming style, for clarity, we present Match using linear 
 recursion. 
 ; Match rule's tests against the data, 
 (define match (tests data) 
     (beta-join 
         (first tests) 
         (second tests) 
         data)) 
 ; Join together the preceding sift and 
 ; join sets with a filtering beta test, 
 (define beta-join (A B D) 
     (if (null A) 
         MO) 
         (filter (first B) 
             (set-product 
                 (alpha-sift (first A) D) 
                 (beta-join 
                     (rest A) (rest B) D))))) 
 ; Sift the objects with alpha tests, 
 (define alpha-sift (A D) 
     (set-filter A D))                                       Figure 3: CGC on a linearly recursive conjunctive matcher. 
   Match takes a preordered set of tests, and a set of data 
 objects as its arguments. The key interesting function is changes to the object set AD are needed for computing fur•
 beta-join, which merges the simple alpha-sift filter with fur• ther instantiations. That is, the call-graph is a incremental 
 ther recursive calls to beta-join; this produces a linearly state-saving data-driven NETWORK program for comput•
 recursive call-graph. Note how the tests in match's tests ing the state of a single rule's match. 
 argument are deposited locally at each level of filtering, and This is not surprising: Figure 3 D shows the RETE net•
 that no control decisions are made using the data argument. work beta join topology, which is isomorphic to the Match 
   The auxilliary function set-filter returns the subset satis• call-graph in Figure 3 C. 
 fying some predicate tests, while the function set-product 
 operates similarly on a pair of sets.                     3.23 Collecting Call-Graphs 
                                                             A rule system is comprised of a finite set of rules; we 
 3.2.2 Building the Call-Graph                             therefore form the corresponding set of call-graphs, one for 
   STEP 1. For any mle r, calling EVAL' on                 each rule's match component. This set is the Call-Graph 
 matchitcsts. ,D) with the set of labels (match, alpha-sift, Cache. One cache management strategy for conserving 
 beta-join) will save the calling structure of the rule's tests. cache space (with some associated speedup) is to merge the 
The control-flow cache is used with the functional program call-graph DAGs into one connected network. The 
 match to store to the growing call tree. As shown in Figure matcher's behavior is unchanged if, proceeding from the 
 3 A, the call-graph has a linear spine, with the appropriate data input source, nodes are merged based on prefix sharing 
 tests localized at each node.                             of tests. A succession of call-graphs merging into a com•
   STEP 2. In Figure 3 B, the free input variable data is  mon beta-join node trie is depicted in Figure 4. 
 attached to the call-graph as an input source, turning the call When an alpha discrimination net is added to the beta join 
 tree into a DAG.                                          trie, the classical RETE match network is generated. We 
   STEP 3. The graph structure of this single rule's match implemented this addition by modifying the alpha-sift LISP 
 component can now be completed. Memory for the intra-     function to perform its tests tail recursively. This illustrates 
 cycle buffer and the inter-cycle store (and other         how CGC readily produces new desired network topologies 
 information) can be specialized into a specific graph     from small changes in LISP program specifications. 
 representation. This call-graph can be reused as a bottom-
 up NETWORK filtering program. In Figure 3 C, the          3.2.4 Using the Call-Graph Cache 
 domains of the filtered objects are shown.                  Partial Order traversal of the RETE network will perform 
   Using the buffer memory, partial order traversal of the the match of the rule set (cached as a shared set of call-
 call-graph from the data computes the filtered instantiation graphs) against working memory input D. The intracycle 
 subset of Dn. If the nodes' longer-term store memories are buffer and intercycle store memories at each node are used 
 initially loaded with D (and then continually updated), only as a data cache to preserve the partial match computations 

126 Tools 