            Optimal    and   Suboptimal     Singleton    Arc  Consistency     Algorithms

                    Christian  Bessiere                         Romuald    Debruyne
       LIRMM    (CNRS   / University of Montpellier)     Ecole´ des Mines de Nantes  / LINA
             161 rue Ada,  Montpellier, France           4 rue Alfred Kastler, Nantes, France
                    bessiere@lirmm.fr                        romuald.debruyne@emn.fr


                    Abstract                          consistency [Freuder, 1978], etc. Finally, implementing it can
                                                      be done simply on top of any AC algorithm.
    Singleton arc consistency (SAC) enhances the        Algorithms enforcing SAC were already proposed in the
    pruning capability of arc consistency by ensuring past (SAC1 [Debruyne and Bessiere,` 1997b], and SAC2
    that the network cannot become arc inconsistent af- [Bartak´ and Erben, 2004]) but they are far from optimal time
    ter the assignment of a value to a variable. Algo- complexity. Moreover, singleton arc consistency lacks an
    rithms have already been proposed to enforce SAC, analysis of its complexity. In this paper, we study the com-
    but they are far from optimal time complexity. We plexity of enforcing SAC (in Section 3) and propose an algo-
    give a lower bound to the time complexity of en-  rithm, SAC-Opt, enforcing SAC with optimal worst-case time
    forcing SAC, and we propose an algorithm that     complexity (Section 4). However, optimal time complexity is
    achieves this complexity, thus being optimal. How- reached at the cost of a high space complexity that prevents
    ever, it can be costly in space on large problems. the use of this algorithm on large problems. In Section 5, we
    We then propose another SAC algorithm that trades propose SAC-SDS, a SAC algorithm with better worst-case
    time optimality for a better space complexity. Nev- space complexity but no longer optimal in time. Neverthe-
    ertheless, this last algorithm has a better worst-case less, its time complexity remains better than the SAC algo-
    time complexity than previously published SAC al- rithms proposed in the past. The experiments presented in
    gorithms. An experimental study shows the good    Section 6 show the good performance of both SAC-Opt and
    performance of the new algorithms.                SAC-SDS  compared to previous SAC algorithms.

1  Introduction                                       2   Preliminaries
                                                      A constraint network P consists of a ﬁnite set of n variables
Ensuring that a given local consistency does not lead to a
                                                      X  =  {i, j, . . .}, a set of domains D = {D(i), D(j), . . .},
failure when we enforce it after having assigned a variable
                                                      where the domain D(i) is the ﬁnite set of at most d val-
to a value is a common idea in constraint reasoning. It has
                                                      ues that variable i can take, and a set of e constraints C =
been applied (sometimes under the name ’shaving’) in con-
                                                      {c , . . . , c }. Each constraint c is deﬁned by the ordered
straint problems with numerical domains by limiting the as- 1 e                  k
                                                      set var(ck) of the variables it involves, and the set sol(ck)
signments to bounds in the domains and ensuring that bounds of combinations of values satisfying it. A solution to a con-
                      [             ]
consistency does not fail Lhomme, 1993 . In SAT, it has straint network is an assignment of a value from its domain
been used as a way to compute more accurate heuristics for
                                                      to each variable such that every constraint in the network is
DPLL  [Freeman, 1995; Li and Ambulagan, 1997]. Finally,
                                                      satisﬁed. When var(c) = (i, j), we use cij to denote sol(c)
in constraint satisfaction problems (CSPs), it has been intro- and we say that c is binary.
duced under the name Singleton Arc Consistency (SAC) in
                                                        A value a in the domain of a variable i (denoted by (i, a))
[Debruyne and Bessiere,` 1997b] and further studied, both
                                                      is consistent with a constraint c iff there exists a support
theoretically and experimentally in [Prosser et al., 2000;                        k
                                                      for (i, a) on c , i.e., an instantiation of the other variables
Debruyne and Bessiere,` 2001].                                    k
                                                      in var(c ) to values in their domain such that together with
  Some nice properties give to SAC a real advantage over the k
                                                      (i, a) they satisfy ck. Otherwise, (i, a) is said arc inconsis-
other local consistencies enhancing the ubiquitous arc consis- tent. A constraint network P = (X, D, C) is arc consistent
tency. Its deﬁnition is much simpler than restricted path con-
                                                      iff D does not contain any arc inconsistent value. AC(P ) de-
       [              ]
sistency Berlandier, 1995 , max-restricted-path consistency notes the network where all arc inconsistent values have been
[                          ]
Debruyne and Bessiere,` 1997a , or other exotic local con- removed from P . If AC(P ) has empty domain, we say that
sistencies. Its operational semantics can be understood by a P is arc inconsistent
non-expert of the ﬁeld. Enforcing it only removes values in
domains, and thus does not change the structure of the prob- Deﬁnition 1 (Singleton arc consistency) A constraint net-
lem, as opposed to path consistency [Montanari, 1974], k- work P = (X, D, C) is singleton arc consistent iff ∀i ∈X, ∀a ∈ D(i), the network P |i=a = (X, D|i=a, C) obtained Algorithm 1: The optimal SAC algorithm
by replacing D(i) by the singleton {a} is not arc inconsis- function SAC-Opt(inout P : Problem): Boolean;
tent. If P |i=a is arc inconsistent, we say that (i, a) is SAC /* init phase */;
inconsistent.                                         1 if AC(P ) then PendingList ← ∅ else return false;
                                                      2 foreach (i, a) ∈ D do
3  Complexity   of SAC                                3    Pia ← P /* copy only domains and data structures */;
                                                      4    Dia(i) ← {a};
Both SAC1  [Debruyne and Bessiere,` 1997b] and SAC2   5    if ¬propagAC(Pia, D(i) \ {a}) then
[Bartak´ and Erben, 2004] have an O(en2d4) time complexity 6  D  ← D \ {(i, a)};
on binary constraints. But it is not optimal.         7       if propagAC(P, {(i, a)}) then
                                                      8           foreach Pjb such that (i, a) ∈ Djb do
Theorem 1 The best time complexity we can expect from an 9           Qjb ← Qjb ∪ {(i, a)};
                                                3
algorithm enforcing SAC on binary constraints is in O(end ). 10      PendingList ← PendingList ∪ {(j, b)};
Proof. According to [McGregor, 1979], we know that check- 11  else return false;
ing whether a value (i, a) is such that AC does not fail in /* propag phase */;
P |i=a is equivalent to verifying if in each domain D(j) there 12 while PendingList 6= ∅ do
is at least one value b such that ((i, a), (j, b)) is “path con- 13 pop (i, a) from PendingList;
sistent on (i, a)”. (A pair of values ((i, a)(j, b)) is path con- 14 if propagAC(Pia, Qia) then Qia ← ∅;
sistent on (i, a) iff it is not deleted when enforcing path con- 15 else
sistency only on pairs involving (i, a).) For each variable j, 16 D ← D \ {(i, a)};
we have to ﬁnd a value b ∈ D(j) such that ((i, a), (j, b)) is 17 if D(i) = ∅ then return false;
                                                      18      foreach (j, b) ∈ D such that (i, a) ∈ D do
path consistent on (i, a). In the worst case, all the values b in                           jb
                                                      19          Djb(i) ← Djb(i) \ {a}; Qjb ← Qjb ∪ {(i, a)};
D(j) have to be considered. So, the path consistency of each 20   PendingList ← PendingList ∪ {(j, b)};
pair ((i, a), (j, b)) may need to be checked against every third
                                                      21 return true;
variable k by looking for a value (k, c) compatible with both
(i, a) and (j, b). However, it is useless to consider variables
k not linked to j since in this partial form of path consis-
                                                      from scratch in each subproblem P |j b each time a value
tency only pairs involving i, a can be removed. By using an                           =
                      (  )                            (i, a) is found SAC inconsistent. (Which represents n2d2
optimal time path consistency technique (storing supports), potential arc consistency calls.) To avoid such costly repe-
we are guaranteed to consider at most once each value (k, c) titions of arc consistency calls, we duplicate the problem nd
when seeking compatible value on k for a pair i, a , j, b .
                                       ((  ) (  ))    times, one for each value (i, a), so that we can beneﬁt from
The worst-case complexity of proving that path consistency
                                                 2    the incrementality of arc consistency on each of them. All
on (i, a) does not fail is thus Σ ∈ Σ ∈ Σ ∈  = ed .
                         b D(j) ckj C  c D(k)         generic AC algorithms are incremental, i.e., their complexity
Furthermore, enforcing path consistency on (i, a) is com- on a problem P is the same for a single call or for up to nd
pletely independent from enforcing path consistency on an- calls, where two consecutive calls differ only by the deletion
other value (j, b). Indeed, a pair ((i, a), (j, b)) can be path of some values from P .
consistent on i, a while becoming path inconsistent after the
           (  )                                         In the following, P is the subproblem in which SAC-
deletion of a pair k, c , j, b thus being path inconsistent              ia
               ((  ) (   ))                           Opt stores the current domain (noted D ) and the data
on (j, b). Therefore, the worst case time complexity of any                               ia
                                   2         3        structure corresponding to the AC enforcement in P |i=a.
SAC algorithm is at least in O(Σ ∈ ed ) = O(end ). 2
                           (i,a) D                    propagAC(P, Q)  denotes the function that incrementally
                                                      propagates the removal of set Q of values in problem P when
4  Optimal   Time  Algorithm   for SAC                an initial AC call has already been executed, initialising the
SAC1 has no data structure storing which values may become data structure required by the AC algorithm in use. It returns
SAC inconsistent when a given value is removed. Hence, it false iff P is arc inconsistent.
must check again the SAC consistency of all remaining val- SAC-Opt is composed of two main steps. After making the
ues. SAC2 has data structures that use the fact that if AC problem arc consistent (line 1), the loop in line 2 takes each
does not lead to a wipe out in P |i=a then the SAC consis- value a in each domain D(i) and creates the problem Pia as
tency of (i, a) holds as long as all the values in AC(P |i=a) a copy of the current P . Then, in line 5 the removal of all
are in the domain. After the removal of a value (j, b), SAC2 the values different from a for i is propagated. If a subprob-
checks again the SAC consistency of all the values (i, a) such lem Pia is arc inconsistent, (i, a) is pruned from the ’master’
that (j, b) was in AC(P |i=a). This leads to a better average problem P and its removal is propagated in P (line 7). The
time complexity than SAC1 but the data structures of SAC2 advantage of propagating immediately in the master problem
are not sufﬁcient to reach optimality since SAC2 may waste the SAC inconsistent values found in line 5 is twofold. First,
time re-enforcing AC in P |i=a several times from scratch. the subproblem Pkc of a value (k, c) removed in line 7 before
  Algorithm 1, called SAC-Opt, is an algorithm that enforces its selection in line 2 will never be created. Second, the sub-
            3
SAC in O(end ), the lowest time complexity which can be problems Pjb created after the removal of (k, c) will beneﬁt
expected (see Theorem 1).                             from this propagation since they are created by duplication
  The idea behind such an optimal algorithm is that we don’t of P (line 3). For each already created subproblem Pjb with
want to do and redo (potentially nd times) arc consistency a ∈ Djb(i), (i, a) is put in Qjb and Pjb is put in PendingListfor future propagation (lines 9–10).                  such as AC-6 the lists will be used as they are. If we use
  Once the initialisation phase has ﬁnished, we know that a coarse-grained algorithm such as AC-3 [Mackworth, 1977]
PendingList contains all values (i, a) for which some SAC or AC2001, only the variables from which the domain has
inconsistent value removals (contained in Qia) have not yet changed are needed. The modiﬁcation is direct. We should
been propagated in Pia. The loop in line 12 propagates these bear in mind that if AC-3 is used, we decrease space complex-
removals (line 14). When propagation fails, this means that ity to O(n2d2), but time complexity increases to O(end4)
(i, a) itself is SAC inconsistent. It is removed from the do- since AC-3 is non optimal.
main D of the master problem in line 16 and each subproblem
Pjb containing (i, a) is updated together with its propagation 5 Losing Time Optimality to Save Space
list Q for future propagation (lines 18–20).
    jb                                                SAC-Opt cannot be used on large constraint networks because
  When PendingList is empty, all removals have been propa-       2
gated in the subproblems. So, all the values in D are SAC. of its O(end ) space complexity. Moreover, it seems dif-
                                                      ﬁcult to reach optimal time complexity with smaller space
Theorem 2 SAC-Opt  is a  correct SAC algorithm with   requirements. A SAC algorithm has to maintain AC on nd
     3                                2                                                    2
O(end ) optimal time complexity and O(end ) space com- subproblems P |i=a, and to guarantee O(ed ) total time on
plexity on binary constraints.                        these subproblems we need to use an optimal time AC algo-
Proof. Soundness. A value a is removed from D(i) either in rithm. Since there does not exist any optimal AC algorithm
line 6 or in line 16 because Pia was found arc inconsistent. requiring less than O(ed) space, we obtain nd · ed space for
If Pia was found arc inconsistent in the initialisation phase the whole SAC process.
(line 5), SAC inconsistency of (i, a) follows immediately. Let We propose to relax time optimality to reach a satisfac-
us proceed by induction for the remaining case. Suppose all tory trade-off between space and time. To avoid discussing in
values already removed in line 16 were SAC inconsistent. If too general terms, we instantiate this idea on a AC2001-based
Pia is found arc inconsistent in line 14, this means that Pia SAC algorithm for binary constraints, but the same idea could
cannot be made arc consistent without containing some SAC be implemented with other optimal AC algorithms such as
inconsistent values. So, (i, a) is SAC inconsistent and SAC- AC-6, and with constraints of any arity. The algorithm SAC-
Opt is sound.                                         SDS (Sharing Data Structures) tries to use as much as possi-
  Completeness. Thanks to the way PendingList and Qia are ble the incrementality of AC to avoid redundant work, with-
updated in lines 8–10 and 18–20, we know that at the end of out duplicating on each subproblem P |i=a the data structures
the algorithm, all Pia are arc consistent. Thus, for any value required by optimal AC algorithms. This algorithm requires
(i, a) remaining in P at the end of SAC-Opt, P |i=a is not arc less space than SAC-Opt but is not optimal in time.
inconsistent and (i, a) is therefore SAC consistent.    As in SAC-Opt, for each value (i, a) SAC-SDS stores the lo-
  Complexity. The complexity analysis is given for networks cal domain Dia of the subproblem P |i=a and its propagation
of binary constraints since the optimality proof was given for list Qia. Note that in our AC2001-like presentation, Qia is a
networks of binary constraints only. (But SAC-Opt works on list of variables j for which the domain Dia(j) has changed
constraints of any arity.) Since any AC algorithm can be used (in SAC-Opt it is a list of values (j, b) removed from Dia).
to implement our SAC algorithm, the space and time com- As in SAC-Opt, thanks to these local domains Dia, we know
plexities will obviously depend on this choice. Let us ﬁrst which values (i, a) may no longer be SAC after the removal
discuss the case where an optimal time algorithm such as of a value (j, b): those for which (j, b) was in Dia. These
AC-6 [Bessiere,` 1994] or AC2001 [Bessiere` and Regin,´ 2001; local domains are also used to avoid starting each new AC
Zhang and Yap, 2001] is used. Line 3 tells us that the space propagation phase from scratch, since Dia is exactly the do-
complexity will be nd times the complexity of the AC algo- main from which we should start when enforcing again AC
rithm, namely O(end2). Regarding time complexity, the ﬁrst on P |i=a after a value removal. By comparison, SAC1 and
loop copies the data structures and propagates arc consistency SAC2 restart from scratch for each new propagation.
on each subproblem (line 5), two tasks which are respectively But the main idea in SAC-SDS is that as opposed to SAC-
in nd · ed and nd · ed2. In the while loop (line 12), each sub- Opt, it does not duplicate to all subproblems Pia the data
problem can be called nd times for arc consistency, and there structures of the optimal AC algorithm used. The data
are nd subproblems. Now, AC-6 and AC2001 are both incre- structure is maintained only in the master problem P . In
mental, which means that the complexity of nd restrictions the case of AC2001, the Last structure which maintains
on the same problem is ed2 and not nd · ed2. Thus the total in Last(i, a, j) the smallest value in D(j) compatible with
cost of arc consistency propagation on the nd subproblems is (i, a) on cij is built and updated only in P . Nevertheless, it
nd · ed2. We have to add the cost of updating the lists in lines is used by all subproblems Pia to avoid repeating constraint
8 and 18. In the worst case, each value is removed one by checks already done in P .
one, and thus, nd values are put in nd Q lists, leading to n2d2 SAC-SDS (Algorithm 2) works as follows: After some
updates of PendingList. If n < e, the total time complexity is initialisations (lines 1–4), SAC-SDS repeatedly pops a value
O(end3), which is optimal.                       2    from PendingList and propagates AC in Pia (lines 6–9). Note
                                                      that ’Dia=nil’ means that this is the ﬁrst enforcement of AC
Remarks.  We chose to present the Qia lists as lists of values in P , so D must be initialised (line 8).1 If P is arc in-
to be propagated because the AC algorithm used is not spec- ia   ia                            ia
iﬁed here, and value removal is the most accurate informa- 1We included this initialisation step in the main loop to avoid
tion we can have. When using a ﬁne-grained AC algorithm, repeating similar lines of code, but a better implementation will put Algorithm 2: The SAC-SDS   algorithm                  problems faster (lines 19–20) since we know that there is
 function SAC-SDS-2001(inout P : problem): Boolean;    no support for (i, a) on cij lower than Last(i, a, j) in P ,
 1 if AC2001(P ) then PendingList ← ∅ else return false; and so in any subproblem as well. But this data structure is
 2 foreach (i, a) ∈ D do                               shared by all subproblems. Thus it must not be modiﬁed by
 3    Dia ← nil ; Qia ← {i};                           propagSubAC.  Otherwise, Last(i, a, j) would not be guar-
 4    PendingList ← PendingList ∪ {(i, a)};            anteed to be the smallest support in the other subproblems and
 5 while PendingList 6= ∅ do                           in P . When achieving AC in P , propagMainAC does update
 6    pop (i, a) from PendingList ;                    the Last data structure. The only difference with AC2001 is
 7    if a ∈ D(i) then                                 line 24 where it needs to store in Deleted the values removed
 8       if Dia = nil then Dia ← (D \ D(i)) ∪ {(i, a)};
                                                       from D during the propagation. Those removals performed
 9       if propagSubAC(Dia, Qia) then Qia ← ∅;
10       else                                          in P can directly be transferred in the subproblems without
11          D(i) ← D(i) \ {a} ; Deleted ← {(i, a)} ;   the effort of proving their inconsistency in each subproblem.
12          if propagMainAC(D, {i}, Deleted) then      This is done via function updateSubProblems, which re-
13             updateSubProblems(Deleted)              moves values in Deleted from all the subproblems. It also
14          else return false;                         updates the local propagation lists Qia and PendingList for
15 return true;                                        future propagation in the subproblems.
 function Propag Main/Sub AC(inout D: domain; in Q: set ; Theorem 3 SAC-SDS is a correct SAC algorithm with
                                                       O(end4) time complexity and O(n2d2) space complexity on
                          inout Deleted: set ): Boolean;
                                                       binary constraints.
16 while Q 6= ∅ do
17    pop j from Q ;                                   Proof. Soundness. Note ﬁrst that the structure Last is up-
18    foreach i ∈ X such that ∃cij ∈ C do              dated only when achieving AC in P so that any support
19       foreach a ∈ D(i) such that Last(i, a, j) 6∈ D(j) do of (i, a) in D(j) is greater than or equal to Last(i, a, j).
20          if ∃b ∈ D(j), b > Last(i, a, j) ∧ cij (a, b) then The domains of the subproblems being subdomains of D,
21              Last(i, a, j) ← b                      any support of a value (i, a) on cij in a subproblem is also
22          else                                       greater than or equal to Last(i, a, j). This explains that
23             D(i) ← D(i) \ {a} ; Q ← Q ∪ {i} ;       propagSubAC  can beneﬁt from the structure Last without
24              Deleted ← Deleted ∪ {(i, a)} ;         losing any support (lines 19–20). Once this observation is
25       if D(i) = ∅ then return false;                made, soundness comes from the same reason as in SAC-Opt.
26 return true;                                          Completeness. Completeness comes from the fact that
   /* · · · : in propagMainAC but not in propagSubAC */; any deletion is propagated. After initialisation (lines 2-4),
 procedure updateSubProblems(in Deleted: set);         PendingList = D and so, the main loop of SAC-SDS pro-
                                                       cesses any subproblem P    at least once. Each time a
27 foreach (j, b) ∈ D | Djb ∩ Deleted 6= ∅ do                                |i=a
28    Qjb ← Qjb ∪ {i ∈ X / Djb(i) ∩ Deleted 6= ∅} ;    value (i, a) is found SAC inconsistent in P because P |i=a
29    Djb ← Djb \ Deleted;                             is arc inconsistent (line 9) or because the deletion of some
30    PendingList ← PendingList ∪ {(j, b)} ;           SAC-inconsistent value makes it arc inconsistent in P (line
                                                       23 of propagMainAC  called in line 12), (i, a) is removed
                                                       from the subproblems (line 29), and PendingList and the local
 consistent, (i, a) is SAC inconsistent. It is therefore removed propagation lists are updated for future propagation (lines 28
 from D (line 11) and this deletion is propagated in the master and 30). At the end of the main loop, PendingList is empty,
 problem P using propagMainAC (line 12). Any value (i, a) so all the removals have been propagated and for any value
 removed from P is put in the set Deleted (lines 11 and 24). (i, a) ∈ D, Dia is a non empty arc consistent subdomain of
 This set is used by updateSubProblems (line 13) to pass P |i=a.
 the values removed from P on to the subproblems, and to up- Complexity. The data structure Last requires a space in
 date the lists Qjb and PendingList for further propagation in O(ed). Each of the nd domains Dia can contain nd values
 modiﬁed subproblems.                                  and there is at most n variables in the nd local propagation
                                                                          2
   At this point we have to explain the difference between lists Qia. Since e < n , the space complexity of SAC-SDS-
 propagMainAC,  which propagates deletions in the mas- 2001 is in O(n2d2). So, considering space requirements,
 ter problem P , and propagSubAC, which propagates dele- SAC-SDS-2001 is similar to SAC2.
 tions in subproblems Pia. The parts that are in boxes be- Regarding time complexity, SAC-SDS-2001 ﬁrst duplicates
 long to propagMainAC and not to propagSubAC. Function the domains and propagates arc consistency on each subprob-
 propagSubAC, used to propagate arc consistency in the sub- lem (lines 8 and 9), two tasks which are respectively in nd·nd
                                                                 2
 problems, follows the same principle as the AC algorithm. and nd · ed . Each value removal is propagated to all P |i=a
 The only difference comes from the fact that the data struc- problems via an update of PendingList, Qia and Dia (lines
 tures of the AC algorithm are not modiﬁed. When using 27–30). This requires nd · nd operations. Each subproblem
 AC2001, this means that Last is not updated in line 21. In- can in the worst case be called nd times for arc consistency,
 deed, this data structure is useful to achieve AC in the sub- and there are nd subproblems. The domains of each subprob-
                                                       lem are stored so that the AC propagation is launched with
 it in a former loop as in SAC-Opt.                    the domains in the state in which they were at the end of the                                                      1E+4
  cpu time (in sec.)                                     cpu time (in sec.)            1500
  n=100, d=20, and density=.05                           n=100, d=20, and density=1 (complete constraint networks) 1400
1E+1
                                                                                       1300

                                                                                       1200

                                                      1E+3                             1100
                                                                                       1000

                                                                              Zoom with a non 900
                                                                              logarithmic scale 800

                                                                                       700

1E0                                                   1E+2                             600

                                                                                       500

                                                                                       400
                        16
                                                                                       300

                        14                                                             200
                                                      1E+1
                        12                                                             100
                                                                                         0
                        10                                                               .38 .39 .40 .41 .42 .43 .44 .45
1E-1

                         8

                         6                            1E0
                                    Zoom with a non 
        SAC-Opt-2001 SAC-SDS-2001 4
                                    logarithmic scale         SAC-Opt-2001 SAC-SDS-2001
        SAC-1-2001 SAC-2-2001
                         2                                    SAC-1-2001 SAC-2-2001
        SAC-1-6   SAC-2-6                                     SAC-1-6   SAC-2-6
                         0
        SAC-1-4   SAC-2-4                                     SAC-1-4   SAC-2-4
                         .67 .69 .71 .73 .75 .77 Tightness                                         Tightness
1E-2                                                  1E-1
  .10 .15 .20 .25 .30 .35 .40 .45 .50 .55 .60 .65 .70 .75 .80 .85 .90 .10 .15 .20 .25 .30 .35 .40 .45 .50 .55 .60 .65 .70 .75 .80 .85 .90

Figure 1: cpu time with n = 100, d = 20, and density= .05. Figure 2: cpu time with n = 100, d = 20, and density= 1.
previous AC propagation in the subproblem. Thus, in spite
of the several AC propagations on a subproblem, a value will ing to Model B [Prosser, 1996]. All algorithms have been im-
be removed at most once and, thanks to incrementality of arc plemented in C++ and ran on a Pentium IV-1600 MHz with
consistency, the propagation of these nd value removals is in
    3                                       2         512 Mb of memory under Windows XP. SAC1 and SAC2 have
O(ed ). (Note that we cannot reach the optimal ed com- been tested using several AC algorithms. In the following,
plexity for arc consistency on these subproblems since we do we note SAC-1-X, SAC-2-X and SAC-Opt-X the versions of
not duplicate the data structures necessary for AC optimal- SAC1, SAC2 and SAC-Opt based on AC-X. Note that for SAC2
ity.) Therefore, the total cost of arc consistency propagations the implementation of the propagation list has been done ac-
        3                              4         2
is nd · ed . The total time complexity is O(end ).    cording to the recommendations made in [Bartak´ and Erben,
  As with SAC2, SAC-SDS  performs a better propagation 2003]. For each combination of parameters tested, we gener-
than SAC1 since after the removal of a value (i, a) from ated 50 instances for which we report mean cpu times.
D, SAC-SDS checks the arc consistency of the subproblems
P |j=b only if they have (i, a) in their domains (and not all the
subproblems as SAC1). But this is not sufﬁcient to have a bet- 6.1 Experiments on sparse constraint networks
ter worst-case time complexity than SAC1. SAC2 has indeed
the same O(en2d4) time complexity as SAC1. SAC-SDS im- Fig. 1 presents performance on constraint networks having
proves this complexity because it stores the current domain of 100 variables, 20 values in each domain, and a density of
each subproblem, and so, does not propagate in the subprob- .05. These constraint networks are relatively sparse since the
lems each time from scratch.2 Furthermore, we can expect variables have ﬁve neighbours on average.
a better average time complexity since the shared structure For a tightness lower than .55, all the values are SAC. On
Last reduces the number of constraint checks required, even these under-constrained networks, the SAC algorithms check
if it does not permit to obtain optimal worst-case time com- the arc consistency of each subproblem at most once. Storing
plexity. This potential gain can only be assessed by an exper- support lists (as in SAC2) or local subdomains (as in SAC-
imental comparison of the different SAC versions. Finally, Opt and SAC-SDS) does not pay-off. A brute-force algorithm
in SAC1 and SAC2 each AC enforcement in a subproblem  such as SAC1 is sufﬁcient. SAC-1-2001 shows the best per-
must be done on a new copy of D built at runtime (potentially formance.
nd · nd times) while such duplication is performed only once
                                                        On problems having tighter constraints, some SAC incon-
for each value in SAC-SDS (by creating subdomains D ).
                                             ia       sistent values are removed and at tightness .72 we can see
                                                      a peak of complexity. However, as mentioned in [Bartak´
6  Experimental    Results                            and Erben, 2003], the improved propagation of SAC2 is use-
We compared the performance of the SAC algorithms on ran- less on sparse constraint networks and SAC2-X (with X∈
dom uniform constraint networks of binary constraints gener- {4, 6, 2001}) is always more expensive than SAC1-X on the
ated by [Frost et al., 1996], which produces instances accord- generated problems. Around the peak of complexity, SAC-
                                                      SDS-2001 is the clear winner. SAC-Opt-2001 and SAC1-2001
  2This is independent on the AC algorithm used and so, enforcing are around 1.7 times slower, and all the others are between 2.1
                           4
AC with AC-3 preserves this O(end ) time complexity.  and 10 times slower.