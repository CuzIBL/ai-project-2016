                    Scaling    up  WA*    with  Commitment        and  Diversity∗

                       David  Furcy                                 Sven  Koenig
             University of Wisconsin  Oshkosh             University of Southern California
              Computer   Science Department                Computer   Science Department
                 Oshkosh,  WI  54901-8643                   Los Angeles,  CA  90089-0781
                    furcyd@uwosh.edu                              skoenig@usc.edu

                    Abstract                          values. KWA*  tackles this problem by adding a breadth-
                                                      ﬁrst component to WA* (diversity) to make its search less fo-
    Weighted A* (WA*) is a popular search technique that
                                                      cused. It expands the K 1 states with the smallest f-values
    scales up A* while sacriﬁcing solution quality. Recently,              ≥
    researchers have proposed two variants of WA*: KWA* in the OPEN list (rather than just one) in parallel during each
    adds diversity to WA*, and MSC-WA* adds commitment iteration [Felner et al., 2003]. Thus, KWA* has two param-
    to WA*. In this paper, we demonstrate that there is bene- eters, namely W and K. If K = 1, then KWA* reduces
    ﬁt in combining them. The resulting MSC-KWA* scales to WA*. Larger values of K increase the probability that
    up to larger domains than WA*, KWA* and MSC-WA*,  WA*  selects a state on the shortest path from the start state
    which is rather surprising since diversity and commit- to the goal state during the next iteration at the risk of gener-
    ment at ﬁrst glance seem to be opposing concepts. ating more states than necessary during each iteration. MSC-
                                                      WA*:  WA*  focuses the search more than A*. However, the
1  Introduction                                       state that WA* expands next can be any state in the OPEN list
                                                      (depending on the f-values). Multi-State Commitment WA*
Weighted A* (WA*) is a popular search technique that scales (MSC-WA*) increases the focus of WA* even more by fo-
up A* while sacriﬁcing solution quality, by weighing the cusing the search on a subset of the states in the OPEN list
heuristic values more strongly than A*. In this paper, we (commitment) [Kitamura et al., 1998]. MSC-WA* splits the
study how to scale up WA* to even larger domains, building OPEN list into a COMMIT list of at most C states and a RE-
on two variants of WA* that have been proposed recently: SERVE list. Thus, MSC-WA* has two parameters, namely
First, WA* expands only one state per iteration. KWA* is W and C. The COMMIT  list plays the role of a smaller
a variant of WA* that expands several states per iteration, OPEN list, whereas the RESERVE list stores the remaining
which adds diversity to WA* to give it a stronger breadth- states of the original OPEN list. MSC-WA* expands the state
ﬁrst component. Second, WA* considers all states in the with the smallest f-value in the COMMIT list. MSC-WA*
OPEN  list as candidates for expansion. Multi-State Commit- never re-expands a state, even if it ﬁnds a shorter path from
ment WA*  (MSC-WA*)  is a variant of WA* that considers the start state to the state in question. The number of states in
only a small number of states in the OPEN list as candidates the COMMIT list can thus get smaller than C. In this case,
for expansion, which adds commitment to WA* to give it a MSC-WA* uses the states with the smallest f-values in the
stronger depth-ﬁrst component. In this paper, we demonstrate RESERVE list to reﬁll the COMMIT list. If C = , then the
that there is beneﬁt in combining them. Our experimental re- RESERVE list remains empty and MSC-WA* reduces∞ to a
sults, for example, show that the resulting MSC-KWA* with variant of WA* that never re-expands a state. Smaller values
the Manhattan heuristic scales up to the 48-Puzzle, whereas of C make MSC-WA* focus the search on a smaller subset of
WA*, KWA*  and MSC-WA*   do not.                      the states in the original OPEN list.

2  WA*,   KWA*    and MSC-WA*                         3   Comparison
WA*:  WA*  is a variant of A* that scales it up by making Table 1 reports the results of our experiments with WA*,
its search more greedy and thus more focused [Pohl, 1970]. KWA* and MSC-WA* on the N-Puzzle with N = 15, 24, 35
While A* calculates the f-value of a state s as f(s) = g(s) + and 48, using the Manhattan distance as the heuristic func-
h(s), WA* calculates it as f(s) = (1 W )g(s) + W h(s), tion. The goal state has the blank in the upper left corner. For
where 1  W     0.5 is the only parameter− of WA*. KW× A*:
       ≥    ≥                                         each combination of parameters, we average over 50 experi-
Due to its strong focus, WA* is likely to be led into goal-free ments (100 experiments for N = 15) with a memory capacity
regions of the search space by misleadingly small heuristic of six million states. (For W , for example, we use the values

  ∗We thank Richard Korf for providing us with WA* code and 0.50, 0.56, 0.60, 0.67, 0.75, 0.80, 0.86, 0.90, 0.95 and 0.99.)
acknowledge funding from NSF under contracts IIS-0098807 and Each row of the table then reports the parameter combinations
IIS-0350584. The views and conclusions contained in this document that optimize the average performance for each one of four
are those of the authors and not of NSF.              performance measures, namely the solution cost, the num-                Table 1: Comparison of WA*, KWA*, MSC-WA*, and MSC-KWA*   for the N-Puzzle
   N      Performance     WA*               KWA*                 MSC-WA*                MSC-KWA*
           Measure   Value W   Best  Value W     K   Best  Value W      C  Best   Value W    K = C  Best
        Solution Cost 63.51 0.67     53.85 0.67 50,000 X    56.29 0.60 80,000      53.89 0.99 50,000 X
   15   Stored States 6,050 0.99     6,028 0.99   8         4,113 0.95  20         3,223 0.99    5  X
        Generated States 6,972 0.99  6,704 0.99   8         4,191 0.95  20         3,259 0.99    5  X
        Runtime (Seconds) 0.003 0.99 0.003 0.99   5         0.002 0.99  6          0.001 0.95    3  X
        Solution Cost 165.16 0.75    113.56 0.99 20,000 X  164.56 0.75 90,000     116.32 0.99 20,000
   24   Stored States 44,097 0.99    32,567 0.99  5        36,907 0.99 300        16,178 0.99    6  X
        Generated States 56,070 0.99 43,578 0.99  4        37,832 0.99 300        16,331 0.99    6  X
        Runtime (Seconds) 0.027 0.99 0.021 0.99   4         0.021 0.99 50,000      0.007 0.99    6  X
        Solution Cost                236.50 0.99 7,000 X   472.10 0.90 3,000      244.14 0.99 7,000
   35   Stored States               417,675 0.95 20       456,777 0.99  90        56,807 0.99    5  X
        Generated States            652,100 0.95 500      467,586 0.99  90        57,291 0.99    5  X
        Runtime (Seconds)            0.377 0.95  500        0.297 0.99  90         0.033 0.99    5  X
        Solution Cost                                                            18,379.32 0.60  5  X
   48   Stored States                                                             275,293 0.80   4  X
        Generated States                                                          277,282 0.80   4  X
        Runtime (Seconds)                                                          0.181 0.80    4  X

ber of stored states, the number of generated states, and the one of them by setting K = C to simplify the experimen-
actual runtime. A check mark indicates that the algorithm is tal conditions, which is reasonable since decreasing K and C
within one percent of the optimal performance reported in the both increase the focus of MSC-KWA*. Table 1 shows that
row. An empty cell indicates that the algorithm does not solve MSC-KWA* has a smaller number of stored states, a smaller
all of our random instances. The table shows the following number of generated states, and a smaller actual runtime than
trends: First, all runtimes are small because the algorithms WA*, KWA* and MSC-WA*. The savings are signiﬁcant and
quickly either solve a search problem or run out of mem- increase with N. For example, the number of stored states of
ory. Second, KWA* has a smaller solution cost than WA* and MSC-KWA* is at least a factor of seven smaller for the 35-
MSC-WA*.  The solution cost of MSC-WA* remains roughly Puzzle than the ones of WA*, KWA* and MSC-WA*. The
the same as the one of WA*, whereas the one of KWA* im- small memory consumption of MSC-KWA* allows it to solve
proves with N compared to the one of WA*, which can be at- all of our random instances of the 48-Puzzle, which WA*,
tributed to the breadth-ﬁrst component (diversity) of KWA*. KWA* and MSC-KWA* cannot. (KWA* solves only 76 per-
Third, MSC-WA*  has a smaller number of generated states cent and MSC-WA* solves only 78 percent of our random
than WA* and KWA*, which can be attributed to the depth- instances, even if their parameter values are optimized.) Fur-
ﬁrst component (commitment) of MSC-WA*. Fourth, both  thermore, the solution cost of MSC-KWA* is always within
KWA*  and MSC-WA*   store a smaller number of states than about three percent of the solution cost of KWA*, the algo-
WA*  although neither KWA* nor MSC-WA* dominates the  rithm with the smallest solution cost. Additional experiments
other one in this respect. (KWA* stores a smaller number are reported in [Furcy, 2004]. For example, MSC-KWA*
of states than WA* only for large values of N.) The small (with K = C) solves all of our random instances of the 4-Peg
memory consumption of KWA* and MSC-WA*  allows them   Towers of6 Hanoi, which WA*, KWA* and MSC-WA*  can-
to solve all of our random instances of the 35-Puzzle, while not. Note that beam search is a special case of MSC-KWA*
WA*  solves only 98 percent of our random instances, even (namely, with K = C and no RESERVE list) and thus can
for the best possible value of W . For KWA*, this result is be understood as a variant of best-ﬁrst search with commit-
partly due to our improved implementation of KWA* that ment and diversity, not just commitment (the current view).
stores each state at most once on the OPEN and CLOSED It is future work to determine the best parameters values of
list. However, it turns out that the low memory consumption MSC-KWA* automatically.
of our implementation of KWA* is not a systematic effect but
due to noise since it requires one to hit the correct value of K References
precisely, which is not possible in practice.         [Felner et al., 2003] A. Felner, S. Kraus, and R. Korf. KBFS: K-
                                                        best-ﬁrst search. Annals of Mathematics and Artiﬁcial Intelli-
4  MSC-KWA*                                             gence, 39:19–39, 2003.
Although the concepts of diversity and commitment seem to [Furcy, 2004] D. Furcy. Speeding Up the Convergence of Online
be opposing at ﬁrst glance, we now combine them: MSC-   Heuristic Search and Scaling Up Ofﬂine Heuristic Search. PhD
WA*  splits the OPEN list into a COMMIT list of C states thesis, College of Computing, Georgia Institute of Techmology,
and a RESERVE  list. This makes MSC-WA* even more fo-   Atlanta (Georgia), 2004.
cused than WA*, and thus makes it more likely that MSC- [Kitamura et al., 1998] Y. Kitamura, M. Yokoo, T. Miyaji, and
WA*  is led into goal-free regions of the search space by mis- S. Tatsumi. Multi-state commitment search. In Proceedings of
leadingly small heuristic values. We alleviate this problem by the International Conference on Tools for Artiﬁcial Intelligence,
adding to MSC-WA* the mechanism used by KWA*. MSC-      pages 431–439, 1998.
KWA*,  the resulting algorithm, expands in parallel during [Pohl, 1970] I. Pohl. First results on the effect of error in heuristic
each iteration all K C states with the smallest f-values in search. In B. Meltzer and D. Michie, editors, Machine Intelli-
the COMMIT  list (rather≤ than just one). Thus, MSC-KWA* gence, volume 5, pages 219–236. American Elsevier, New York,
has three parameters, namely W , C and K. We eliminate  1970.