                   Active Learning with Ensembles for Image Classification 


                       H.Liu and A.Mandvikar1 and P. Foschi2 and K. Torkkola3 
                      department of Computer Science & Engineering, PO Box 875406, 
                   Arizona State University, Tempe, AZ 85287. {huanliu,amitm}@asu.edu 

           2Romberg Tiburon Center, 3152 Paradise Drive, Tiburon, CA 94920. tfoschi@sfsu.edu 

           3Human Interface Lab, Motorola Labs,Tempe, AZ 85284. kari.torkkola@motorola.com 


                        Abstract                               the number of uncertain image regions and is better than a 
                                                               single ensemble for the task of object detection. 
     In many real-world tasks of image classification, 
     limited amounts of labeled data are available to 
     train automatic classifiers. Consequently, extensive      2 Class-Specific Ensembles 
     human expert involvement is required for verifica•        We may tend to use as many classifiers in an ensemble as 
     tion. A novel solution is presented that makes use        possible because (1) each classification algorithm may have 
     of active learning combined with an ensemble of           a different view of the training image and capture varied as•
     classifiers for each class. The result is a significant   pects of the image, as different classification algorithms have 
     reduction in required expert involvement for uncer•       different biases and assumptions; and (2) no single classifier 
     tain image region classification.                         can cover all aspects. In other words, some algorithms may 
                                                               succeed in capturing some latent information about the do•
1 Introduction                                                 main, while others may fail. However, problems can result 
                                                               from using too many classification algorithms: e.g., (1) us•
Multimedia contents arc rapidly becoming a major target for    ing more classification algorithms can result in longer overall 
data mining research. This work is concerned with image        training time, especially so if some of the algorithms are time-
mining, discovering patterns and knowledge from images for     consuming to train; and (2) some algorithms may be prone to 
the purpose of classifying images. The specific problem        overfitting. If these algorithms are included in the ensemble, 
we address is image region classification. Egeria Densa is     there may be a high risk of allowing the ensemble to over-
an exotic submerged aquatic weed causing navigation and        fit some training image(s). The above analysis suggests the 
reservoir-pumping problems in the Sacramento-San Joaquin       necessity of searching for a relevant set of classifiers to form 
Delta of Northern California. As a part of a control program   ensembles. Exhaustive search for the best combination is im•
to manage Egeria, classification of regions in aerial images   practical because the search space is exponential in the total 
is required. This problem can be abstracted to one of clas•    number of classification algorithms for consideration. Thus 
sifying massive data without class labels. Relying on hu•      we need an efficient methodology to find the optimal combi•
man experts for class labeling is not only time-consuming      nation of classifiers for the class-specific ensembles. 
and costly, but also unreliable if the experts are overburdened  We adopt three performance criteria for this work: Preci•
with numerous minute and routine tasks. Massive manual         sion, Recall, and number of uncertain regions (UC). The first 
classification becomes impractical when images are complex     two standard measures are defined in terms of the instances 
with many different objects (e.g., water, land, Egeria) under  that are relevant and the instances that are classified (or re•
varying picture-taking conditions (e.g., deep water, sun glint). trieved). The third one is the number of instances (regions 
The main objective of the project is to relieve experts from go• in an image) the class-specific ensembles cannot be certain 
ing through all the images and pointing out locations where    about their class predictions. High precision or high recall 
Egeria exists in the image. We aim to automate the process     alone is not a good performance measure as each describes 
via active learning to limit expert involvement to decisions   only one aspect of classification. Together they provide a 
about which the automatic classifier is uncertain.             good measure: for example, the product of precision and 
   The contributions of this work are a novel concept of class- recall (PR). If both values are 1, their product is 1, which 
specific ensembles, and learning class-specific ensembles. We  means all and only positive instances are classified as posi•
notice that different types of classifiers are better suited to de• tive. Hence, PR is a measure for both generality and accuracy. 
tecting different objects such as Egeria, land, water. Since it F measure can be used for the same purpose. 
is impractical to train one classifier for each object (as experts 
need to provide training instances for all objects), we propose 3 Learning Class-Specific Ensembles 
a novel approach to class-specific ensembles. We also discuss 
how to combine individual classifiers to learn class-specific  In order to learn class-specific ensembles, we need a data set 
ensembles. We show that this approach significantly reduces    that links classifiers to the label of each image region. This 


POSTER PAPERS                                                                                                        1435                                                                is uncertain, follow the certain one; if both are uncertain, the 
                                                               instance is uncertain. 

                                                               4 Experiments and Evaluations 
                                                               With the principal goal of reducing the burden on experts, we 
                                                               use only one image for training and apply the learned results 
                                                               to another 16 testing images of different areas for detection. 
                                                               Among the classification algorithms available in the machine-
                                                               learning package WEKA [Witten and Frank, 2000], we select 
                                                               all that can be applied to the image domain to ensure a variety 
                                                               of classification algorithms. We apply the algorithm in Fig•
                                                               ure 1 with the complete set of classification algorithms as in•
                                                               put. The class-specific ensembles found by association rules 
                                                               are: Class = yes Decision Trees C4.5, Alternating De•
                                                               cision Trees, Decision Trees (PART), PRISM, Hyper Pipes, 
                                                               Kernel Density, Logistic, Decision Tables; and Class = no 
                                                                  Id3, Alternating Decision Trees, Decision Trees (PART), 
                                                               PRISM, Kernel Density, Instance Based 1, Decision Tables. 
                                                                 We design 3 experiments and provide the summarized re•
                                                               sults here (the details will be provided upon request). 
                                                                 Experiment 1. We compare the use of dual ensembles 
                                                                                    with that of single ensembles (either 
 new data set can be obtained by applying all the classifica•                    The average UCincrease (increase in un•
 tion algorithms to the training image so that each classifier certain regions) is almost 53% and the average PRgain is -
 is a feature (i.e., a column) and its value is the prediction of 1.04%. It is observed that in general, dual ensembles are not 
 the classifier. For each image region (one instance in the new only more accurate, but also separate certain and uncertain 
 data set), there are predictions of all the classfiers and also instances better than single ensembles. 
 the class label 'Egeria' or 'non-Egeria' given by experts. We   Experiment 2. We compare the learned dual ensembles to 
 are concerned only with those rules that have the class label 10 randomly selected dual ensembles. Each classifier is ran•
 Egeria or not as the consequent. We will restrict our search to domly chosen and learns from the training image. Although 
such rules and obtain rules with the maximum number of fea•    the average PRgain is only decreased by 2.01%, the UCin•
tures (classifiers) in the precedent without a significant loss crease increases significantly by 846.6%'. Hence, it is nec•
in support or confidence. The best rule for each class label   essary to search for relevant dual ensembles, as random dual 
 indicates the best combination of classifiers for the ensemble. ensembles work poorly in reducing UC. 
   Among many learning algorithms for classification, clus•      Experiment 3. We compare the learned dual ensembles to 
tering, and association rules, we observe that association rule results obtained by the classification rules of domain experts. 
algorithms LAgrawal and Srikant, 19941 can search the at•      The experts' rules outperform the learned dual ensembles in 
tribute space to find the best combination of attributes associ• terms of PRgain by 14.6%, but the number of uncertain in•
ated with a class. Our algorithm is presented in Figure 1. It  stances (UC) increases by 408.4% The high PRgain and high 
takes as input the entire set of classification algorithms E and UC for the expert classification rules is due to the fact that an 
                                                               expert can only directly work on the former (designing highly 
training data Tr with class labels /TR, and produces as output 
two ensembles for class label yes and class label no.          general and accurate rules), but not on the latter (finding low 
                                                               UC rules). Our system is particularly designed to compensate 
   The next task is to use the dual ensembles (Ei=    and 
                                                   yes         in this shortcoming. 
El-no) to determine certain and uncertain instances. We need 
to decide the maximum number of classifiers in an ensemble     5 Conclusion 
that should agree on a prediction to reach a decision of "cer•
                                                               We present a novel approach to active learning with ensem•
tain" or "uncertain" for each ensemble. An ensemble with all 
                                                               bles of classifiers. One ensemble is trained for each class. 
classifiers being required to agree on a prediction would lead 
                                                               Extensive experiments were conducted in the real-world do•
to high precision, but low recall; an ensemble with few classi•
                                                               main of detecting seaweed in aerial images. 
fiers being required to agree would lead to high recall and low 
precision. We need to find a balanced number of classifiers    References 
with which the ensemble gives the best estimated precision     lAgrawal and Srikant, 19941 R. Agrawal and R. Srikant. 
and recall. The training image is used again for this task.      Fast algorithms for mining association rules. In Proc. 20th 
   The dual ensembles El-yes and El=no work together to          Int. Conf. VLDB, pages 487-499, 1994. 
decide if an instance's prediction is certain or not following 
                                                               [Witten and Frank, 20001 1. Witten and E. Frank. Data Min•
the rule of majority. In predicting an instance, if both E
                                                       l=yes     ing: Practical Machine Learning tools and techniques 
and E      are certain with their predictions, follow the one 
       l=no                                                      with java implementations. Morgan Kauffmann, 2000. 
with more agreeing classifiers; if one is certain and the other 


1436                                                                                                   POSTER PAPERS 