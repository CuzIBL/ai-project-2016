    Using the Probabilistic Logic Programming Language P-log for Causal and
                 Counterfactual Reasoning and Non-naive Conditioning
                                  Chitta Baral   and  Matt Hunsaker
                           Department of Computer Science and Engineering
                                        Arizona State University
                                         Tempe, Arizona 85281
                                      {chitta,hunsaker}@asu.edu

                    Abstract                          1994; Dekhtyar and Dekhtyar, 2004; Lukasiewicz, 1998],
                                                      dynamically ordered probabilistic choice logic programming
    P-log is a probabilistic logic programming lan-   [De Vos and Vermeir, 2000], and the recent langauge P-log
    guage, which combines both logic programming      [Baral et al., 2004; 2005]. Our focus on this paper is on P-
    style knowledge representation and probabilistic  log.
    reasoning. In earlier papers various advantages of
                                                      Earlier it was shown that P-log has many advantages over the
    P-log have been discussed. In this paper we further
                                                      other languages. In particular, P-log allows a wide variety of
    elaborate on the KR prowess of P-log by showing
                                                      updates compared to the other approaches; it allows explicit
    that: (i) it can be used for causal and counterfactual
                                                      speciﬁcation of background knowledge; and it allows logical
    reasoning and (ii) it provides an elaboration toler-
                                                      reasoning to dynamically decide on the range of values that a
    ant way for non-naive conditioning.
                                                      random variable can take. In this paper we show how P-log
                                                      can also do causal and counterfactual reasoning of the kind in
1  Introduction and Motivation                        Pearl’s probabilistic causal models. We give an encoding of
                                                      probabilistic causal models in P-log and state the correspon-
In recent years there has been a lot of progress in logical dence. Our correspondence shows that while the computation
knowledge representation and reasoning as well as proba- of causal and counterfactuals in PCMs is algorithmic in na-
bilistic knowledge representation and reasoning. There have ture, in the encoded P-log it is automatically captured by the
been some attempts at developing formalisms that allow both semantics of the language. We then show that P-log’s abil-
logical as well as probabilistic knowledge representation. ity to allow logical reasoning to dynamically decide on the
One such approach is Pearl’s probabilistic causal models range of values that a random variable can take leads to a
[Pearl, 2000]. While Pearl’s formalism is an improvement elaboration tolerant way to perform non-naive conditioning
over traditional propositional probability representations such [Halpern, 2003]. We illustrate this with respect to Halpern’s
as Bayes’ nets, there are still the limitations that are asso- second-ace puzzle example.1
ciated with propositional representation as well as classical
(and hence monotonic) reasoning. In recent years approaches 2 Background
to overcome both have been proposed. Proposed approaches
                                                      In the next two subsections, we will brieﬂy review the syntax
to overcome the limitations of propositional representation
                                                      of a simpliﬁed version of P-log [Baral et al., 2004] and the
include probabilistic relational models [Koller, 1999; Getoor
                                                      syntax and semantics of probabilistic causal models [Pearl,
et al., 2001], various probabilistic ﬁrst-order logics [Nilsson,
                                                      2000].
1986; Bacchus, 1990; Bacchus et al., 1996; Halpern, 1990;
2003; Pasula and Russell, 2001; Poole, 1993],andap-   2.1  P-log lite: an overview
proaches based on assigning weights to ﬁrst-order formu-
                                                      For simplicity, we will deﬁne a subset of the probabilistic
las [Paskin, 2002; Richardson and Domingos, 2006].There
                                                      logic programming language P-log, which we will call P-log
have been also many formalisms that integrate logic pro-
                                                      lite. We use logic programming terminology of terms, atoms
gramming with probability such as Poole’s Probabilistic Horn
                                                      and literals. A P-log lite program Π consists of (i) a set of
Abduction (PHA) [Poole, 1993], his Independent Choice
                                                      boolean attributes {p, ¬p : p is an atom }, (ii) a regular part,
Logic (ICL) [Poole, 1997; 2000], the LPAD formalism [Ven-
                                                      (iii) a set of random selection rules,(iv)aprobabilistic infor-
nekens et al., 2004], Bayesian logic programming [Kerst-
                                                      mation part, and (v) a set of observations and actions.Inthe
ing and Raedt, 2000], ALTERID [Breese, 1990; Wellman
                                                      following by t we denote a vector of parameters consisting of
et al., 1992], probabilistic knowledge bases [Ngo and Had-
                                                      terms, and by ¬p we refer to p and by p˜ we refer to ¬p.
dawy, 1997], stochastic logic programs [Muggleton, 1995;
Cussens, 1999], probabilistic constraint logic programs [Rie- 1Earlier work on P-log [Baral et al., 2004] hinted at this with
zler, 1998; Santos Costa et al., 2003], interval based prob- respect to the Monty Hall example. However no general methodolo-
abilistic logic programming [Ng and Subrahmanian, 1992; gies for “non-naive” conditioning were proposed.

                                                IJCAI-07
                                                   243(ii) Regular part: The regular part of a P-log lite program If for any attribute literal l, we do not have pr-atoms for either
                                                          ˜
consists of a collection of logic programming rules (without l or l, l ∈ W and W does not contain intervene(l) then
                                                                            ˜
disjunction and under the stable model semantics).    P (W, l)=0.5,andP (W, l)=0.5.
(iii) Random Selection:Arandom selection is a rule of the
                                                      Now we are ready to deﬁne the measure, μΠ, induced by the
form                                                  P-log lite program Π.
                   random(a(t)).                (1)
                                                      Deﬁnition 1. (Measure) (i) The unnormalized probability,
Statement (1) says that one of a(t) or ¬a(t) is selected at ran-
                                                      μˆΠ(W ), of a possible world W induced by Π is μˆΠ(W )=
dom. In P-log with non-boolean attributes the random state-  P (W, l), where the product is taken over literals for
ment is more general and is of the form:                l∈ W
                                                      which P (W, l) is deﬁned.
random(Attr : {X  : p(X)}).
                                                      (ii) The measure (or the normalized probability), μΠ(W ),ofa
(iv) Probabilistic Information: Information about probabil-        W           Π
ities of random attributes taking particular values is given by possible world induced by is the unnormalized probabil-
                                                      ity of W divided by the sum of the unnormalized probabilities
probability atoms (or simply pr-atoms) which have the form:                                   μˆΠ(W )
                                                                           Π     μΠ(W )=  P
                                                      of all possible worlds of , i.e.,         μˆΠ(Wi)
                     pr(l)=v.                   (2)                                         Wi∈Ω
                                                      When the program Π is clear from the context we may simply
where l is a(t) or ¬a(t),andpr(a(t)) = v would cause a(t) write μˆ and μ instead of μˆΠ and μΠ respectively. 2
              v
with probability .                                    The truth and falsity of propositional formulas with respect to
(v) Observations and actions: Observations and actions are possible worlds are deﬁned in the standard way. A formula A
statements of the respective forms: obs(l) and do(l). is true in W is denoted by W  A.
Observations are used to record the outcomes of random Deﬁnition 2. (Probability)
events, i.e., random attributes and attributes dependent on The probability with respect to program Π of a formula A,
                 do(a(t))           a(t)
them. The statement      indicates that is made true  PΠ(A), is the sum of the measures of the possible worlds of
as a result of a deliberate (non-random) action.      Π in which A is true, i.e. PΠ(A)= W A μΠ(W ).   2
Semantics of P-log lite:                              When  Π is clear from the context we may simply write P in-
The semantics of a P-log lite program Π is given by a collec- stead of PΠ. Conditional probability in P-log lite is deﬁned
tion of the possible sets of beliefs of a rational agent associ- in the usual way. Moreover, under certain consistency con-
ated with Π, together with their probabilities.       ditions (which hold for the examples discussed in this paper)
                                                                         T          A                  B
We start with translating the logical part of a P-log lite pro- on P-log lite programs ,formulas , and a set of literals
                                                              P  (B) =0        P  (A|B)=P          (A)
gram Π to an Answer Set Prolog program τ(Π) as described such that T    ,wehave  T          T ∪obs(B)
below.
                                                      2.2  Probabilistic causal models
(a) τ(Π) contains the regular part of Π.
                                                                                              [         ]
(b) For each attribute atom a(t), τ(Π) has the rules: In this section we present many deﬁnitions from Pearl, 2000
                                                      and give our deﬁnition of a PCM-probabilistic query.
intervene(a(t)) ← do(a(t))
                        .                                                                  M  =  U, V, F 
intervene(a(t)) ← do(¬a(t)).                          Causal model: A causal model is a triple
                                                      where
(c) For each random(a(t)) in Π, τ(Π) has the Smodels rule:
                                                         U
1{a(t), ¬a(t)}1 ← not intervene(a(t)).                (i)  is a set of background variables, (also called exogenous),
                                                      that are determined by factors outside the model;
The left hand side of the above rule means that one of a(t)
                                                      (ii) V is a set {V1,V2,...Vn} of variables, called endoge-
and ¬a(t) must be in the answer set.
                                                      nous, that are determined by variables in the model - that is,
(d) τ(Π) has all the actions and observations of Π.   variables in U ∪ V ;and
               l τ(Π)
(e) For all literals , has the rules:                 (iii) F is a set of functions {f1,f2,...fn}, such that each fi
← obs(l),notl.                                        is a mapping from U ∪ (V \ Vi) to Vi, and such that the entire
l ← do(l).                                            set F forms a mapping from U to V . In other words, each fi
                                                                      V
An answer set of τ(Π) is called a possible world of Π.The tells us the value of i given the values of all other variables in
                                                      U ∪V                 F                      V
set of all possible worlds of Π is denoted by Ω(Π).        , and the entire set has a unique solution for ,given
                                                      a realization of U. Symbolically, the set of equations F can
Let W be a possible world of a P-log lite program Π.IfΠ
                                                      be represented by writing Vi = fi(PAi,Ui),i=1,...,n,
contains a random selection rule of the form random(a(t)),
                                                      where PAi (connoting parents) is a subset of variables in V \
then we say that both a(t) and ¬a(t) are possible in W with
                                                      Vi and Ui stands for a subset of variables in U.
respect to Π.ForeveryW ∈ Ω(Π) and every literal l possible
in W we now deﬁne the corresponding probability P (W, l). We will refer to the realization of a set of variables Y ⊆ V
                                                      given the causal model M and the background variable real-
For each l possible in W :
                                                      ization of U = u as YM (u). Y (u) will be used as shorthand
  l ∈ W Π             pr(l)=v     W
If     ,  has a pr-atom        and   does not contain for YM (u), but we will explicitly use the subscript Mx for
                                    ˜
intervene(l) then P (W, l)=v,andP (W, l)=1− v.        realizations of submodels deﬁned below.

                                                IJCAI-07
                                                   244Example 1. We have a simple causal model consisting of a The ﬁring squad PCM: The PCM of the ﬁring squad has two
background variable U, endogenous variables A and B,and background variables U and W , and endogenous variables
the set of the following causal functions:            A, B, C,andD; which stand for
A = U ∧ B.          B  = U ∨ A.                       U = court orders the execution; C = captain gives a signal;
               U                          A     B     A = riﬂe A shoots; B = riﬂe B shoots; D = the prisoner dies;
For each value of , there is a unique solution for and . W
That is, for U =1, A = B =1and for U =0, A = B =0.       = riﬂe A pulls the trigger out of nervousness.
2                                                     The causal relationships between the variables are described
                                                      by the functional equations C = U; A = C ∨ W ; B =
Submodel: Let M be a causal model, X be a set of variables C; D = A ∨ B. In addition the probabilities of the back-
in V ,andx be a particular realization of X.Asubmodel Mx ground variables are given as P (U)=p and P (W )=q.
of M is the causal model Mx = U, V, Fx where Fx = {fi :
Vi ∈ X}∪{X  = x}.                                    3.1  Example of an observation assimilation query
Submodels are useful for representing the effect of local ac- Consider the query that asks the probability that B shot given
tions and hypothetical changes. Mx represents the model that that the prisoner is dead? In PCM formalism this will be ex-
results from a minimal change to make X = x hold true un- pressed as P (B|D).
der any realization of U.                             To translate this query to an equivalent P-log lite query we
Effect of Action: Let M be a causal model, X beasetof will use a program Π1 that captures both the causal rela-
variables in V ,andx be a particular realization of X.The tionships and the probabilistic arguments found in the ﬁring
effect of action do(X = x) on M is given by the submodel squad PCM. The program Π1 will have explicit rules for the
Mx.                                                   positive and negative boolean variables. The P-log lite pre-
                                                      dictive query is not conditioned on the fact that the prisoner
Potential Response: Let X and Y be two subsets of vari-
                                                      is dead. Instead, the fact that the prisoner is dead is added to
ables in V .Thepotential response of Y to action do(X = x),
                                                      Π1 as an observation rule obs(D). The P-log lite program Π1
denoted YM (u), is the solution for Y of the set of equations
          x                                           consists of the following:
Fx,whereu is a particular realization of U.
                                                        1. Declarations for each background variable:
Counterfactual: Let Xi and Y be two subsets of variables
in V .Thecounterfactual sentence “The value that Y would  U  : boolean.        random(U).
                                                          W   : boolean.       random(W   )
have obtained, had Xi been forced to be xi” is interpreted as                             .
                          YM   (u)      u
denoting the potential response xi ,where is a partic-  2. Declarations for each endogenous variable:
ular realization of U.                                    C  : boolean.        A : boolean.
Probabilistic causal model: A probabilistic causal model  B  : boolean.        D  : boolean.
              M,P(u)       M
(PCM) is a pair        where    is a causal model and   3. Pr atoms and logic programming rules
P (u) is a probability function deﬁned over the domain of U.
                                                          pr(U)=p.           pr(W )=q.
Because the set of functional equations forms a mapping from
U to V , the probability distribution P also induces a proba- 4. Reminder of the logic programming rules
bility distribution over the endogenous variables.        C  ←  U.                     ¬C  ←¬U.
Foreverysetofvariables Y ⊆ V ,wehave:P (Y =  y)=         A  ←  C.    A  ←  W.         ¬A  ←¬C    ∧¬W.
  {u | Y (u)=y} P (u)                                     B  ←  C.                     ¬B  ←¬C.
                                                          D  ←  A.     D ←   B.        ¬D   ←¬A   ∧¬B.
The probability of a counterfactual statement is deﬁned us-
                      Y   (u)                                  P (B|D)  P          (B)=       p
ing the potential response, Mx , induced by the submodel Result 1.     =  Π1 ∪ obs(D)    1−(1−p)(1−q)
M                                    P (Y   = y)=
x. It can be expressed in a similar manner: Mx
               P (u)                                  3.2  Example of an intervention query
  {u | YMx (u)=y}
PCM  probabilistic query: Joint probabilities of counter- Now let us consider the following intervention query: What
factuals that are conditional on observations will be the fo- is the probability that the prisoner is dead given that A is not
cus of our counterfactual reasoning. Let YM = y1,..., allowed to shoot? In PCM formalism this is expressed as
                                        x1            P (D    )
Y     = y                       B     C                   M¬A  .
 Mxm     m be counterfactuals and let and be subsets of
                                      Y      y
V. A PCM probabilistic query is of the form P( Mx1 = 1,..., To translate this query to an equivalent P-log lite query we
Y     = y  B     | C = c                              will use a program Π2 which is similar to Π1 with respect
 Mxm     m,   =b       ), and its value is given by:
                                                     to the parts (1)-(3) of Π1, but differs on part (4) by having
     P (Y    = y ,...,Y    = y  ,B = b | u)P (u | c)
        Mx1     1     Mxm     m                       rules which are blocked when an intervention is done. In this
   u                                                  the nonmonotonic operator not of logic programs comes in
                                                      handy.
3  Encoding Pearl’s ﬁring squad in P-log lite         Part (4) of Π2
In this section we will consider Pearl’s ﬁring squad example C ← U, not do(C),notdo(¬C).
and show how one can encode this example in P-log lite and A ← C, not do(A),notdo(¬A).
ask counterfactual queries.                           A  ←  W, not do(A),notdo(¬A).

                                                IJCAI-07
                                                   245B  ←  C, not do(B),notdo(¬B).                           • Declarations for each endogenous variable:
D  ←  A, not do(D),notdo(¬D).                             C : index → boolean.     A : index → boolean.
D  ←  B, not do(D),notdo(¬D).                             B  : index → boolean.    D : index → boolean.
¬C  ←¬U, not do(C),notdo(¬C).                           • Rules that allow us to reason about the model M.
¬A  ←¬C,   ¬W, not do(A),notdo(¬A).
¬B  ←¬C, not do(B),notdo(¬B).                             We use the index 0 for the endogenous variables. The
¬D  ←¬A,   ¬B, not do(D),notdo(¬D).                       background variables do not have an index as they re-
                                                          main unchanged with respect to the original model and
         P (D    )  P          (D)=p
Result 2.    M¬A  =  Π2 ∪ do(¬A)                          its sub-models.
3.3  Example of a counterfactual query                    C(0)  ←  U.        ¬C(0)  ←¬U.
                                                          A(0)  ←  C(0).     ¬A(0)  ←¬C(0)   ∧¬W.
We now consider the following counterfactual query from   A(0)  ←  W.
[Pearl, 2000]: “What is the probability that the prisoner B(0)  ←  C(0).     ¬B(0)  ←¬C(0).
would be alive if A had not shot given that the prisoner is D(0) ← A(0).     ¬D(0)  ←¬A(0)   ∧¬B(0).
in fact dead?”                                            D(0)  ←  B(0).

In PCM  this counterfactual query is expressed as either • Rules that allow us to reason about the model M¬A.
P (¬DM¬A | D) or as P (¬DM¬A | DM ),whereM is the orig-
inal causal model.                                        Since doing an action (as an assignment to a variable)
                                                          necessitates surgery to the model so that the parents of
Thus the PCM counterfactual query has two causal models in
                                                          the variable that is assigned no longer affect the variable;
the probabilistic query. The conditional variable DM ,which
                                                          we do it logically by adding “not do” in the bodies of the
is an equivalent representation of variable D, is a member of
                                                          rules. As a result we have the following rules:
the original causal model M, while the variable YM¬A is a
member of the submodel M¬A.                               C(1) ←  U, not do(C(1)),notdo(¬C(1)).
                                                          A(1) ←  C(1),notdo(A(1)),notdo(¬A(1)).
Our encodings in Π1 refers to the model M and our encod-
     Π                   M                                A(1) ←  W, not do(A(1)),notdo(¬A(1)).
ing in 2 refers to the model ¬A. Now we need both. We     B(1) ←  C(1),notdo(B(1)),notdo(¬B(1)).
achieve this by carefully using the indices 0 and 1 for the D(1) ← A(1),notdo(D(1)),notdo(¬D(1)).
endogenous variables. We do not use any index for the ex- D(1) ←  B(1),notdo(D(1)),notdo(¬D(1)).
ogenous variables as they remain the same in both models.
                                                          ¬C(1)  ←¬U, not do(C(1)),notdo(¬C(1)).
Note that in Π1 we do not apply do() rules to the original
model M, since by deﬁnition submodels are the result of an ¬A(1) ←¬C(1)  ∧¬W, not do(A(1)),
effect of action do() on the original model M. Therefore all              not do(¬A(1)).
variables that are members of the M do not need intervention ¬B(1) ←¬C(1),notdo(B(1)),notdo(¬B(1)).
rules in the translation.                                 ¬D(1)  ←¬A(1)  ∧¬B(1),notdo(D(1)),
                                                                          not do(¬D(1)).
The P-log lite encoding of the above example will consist of
                                                               P                      (¬D(1))
the program Π3 given below. To ask the query all one needs To answer Π3 ∪ obs(D(0)) ∪ do(¬A(1)) all one needs
to do is to add obs(D(0)) and do(¬A(1)) to Π3 and compute to do is to add the intervention and observation facts
                                                         ¬
the probability of ¬D(1). In the syntax of P-log lite this is do( A(1)), and obs(D(0)), respectively and compute the
           P                     (¬D(1))              probability of ¬D(1) with respect to the resulting theory.
expressed as Π3 ∪ obs(D(0)) ∪ do(¬A(1)) .
                                                               P (¬D    | D)
The intuition behind adding obs(D(0)) is that D is observed Result 3. M¬A   =
                            M                         P                      (¬D(1))    (1−p)× q
with respect to the original model which is encoded by the Π3 ∪ obs(D(0)) ∪ do(¬A(1)) = 1−(1−p)(1−q)
index 0. The intuition behind adding do(¬A(1)) is that ¬A
is established (through an action) resulting in a new model 4 A general encoding of PCM to P-log lite
M¬A  which is encoded by the index 1. The intuition behind
asking the probability of ¬D(1) is that the query is asked We now generalize the encoding illustrated in the previous
about the model M¬A which, as we mentioned earlier, is en- section to arbitrary PCM theories and for queries that may
coded by the index 1. Now we describe the program Π3.Its refer to multiple hypothetical models. We will refer to our
constituents are as follows:                          encoding2 as T . To accommodate multiple submodels, the P-
                                                                                       S        S =0
  • Declarations for each background variable:        log lite rules will use an index variable ,where will
                                                      correspond to the original model of the PCM theory and, S =
    U  : boolean.       random(U).                    1 ...m                    m
    W  : boolean.        random(W  )                        , will correspond to the sub-models necessitated by
                                    .                 the probabilistic query. The encoding T will consist of the
  • Probability atoms corresponding to the background vari- following.
    ables U and W.
                                                      Step 1: Enumerate the models and submodels necessitated by
    pr(U)=p.          pr(W )=q.                       the probabilistic query 0,...,m. ThevariableSusedinthe
  • Indices to enumerate the models M and M¬A:
                                                         2Our encoding of a PCM theory and a query will be independent
    index = {0, 1}.                                   of each other.

                                                IJCAI-07
                                                   246endogenous variables rules is in the domain of index: Having unique solution does not necessarily mean that it can
index = {0,...,m}                                     be obtained using the above mentioned three valued iteration.
                                                                                3
Step 2: For each background variable u ∈ U, for which the Following is a counterexample :
PCM has the probability p(u)=q, T will have the following: Let A = ¬B ∨¬C ∨ U, B = ¬A ∧¬C,andC = A ∨¬B.
                                                            U
u : boolean.       pr(u)=q.         random(u).        When    is false we can not derive the value of A, B, or C
                                                      by a three valued iteration. But, there is the unique solution
Step 3: For each endogenous variable v, with x1,...,xn ∈ A = true B = false  C =  true
U ∪ (V \ v)                          f (x ,...,x )            ,          ,and         that satisﬁes the causal
          and with the associated function v 1  n ,   functions.
we do the following:
                                                      Theorem 1.  Given a PCM M  = M,P(U),letP   denote
 1. Add the following declaration:                    the probabilistic query with respect to it and let the P-log lite
    v : index → boolean.                              program T be obtained by the encoding of M as described in
                                                      the previous section. Let b, c, y1,...,ym and x1,...,xm be
 2. Let the disjunctive normal form of fv(x1,...,xn) be
                                                      realizations of subsets of the endogenous variables V .Also
    c1 ∨ ... ∨ cn, where each ci is a conjunction of liter-
                                                      let YMx =  xi be counterfactual statements, where Mxi is
    als made up of from x1,...,xn. In the translation the    i
                                                      a submodel of M. If all realizations of U = u give unique
    parameter S is added to each endogenous variable xi of
                                                      solutions for endogenous variables in the submodels Mxi and
    x1,...,xn, such that xi becomes xi(S). The P-log lite
                                                      the unique solutions can be computed in an iterative fashion
    program T will have the following rules:
                                                      starting from the background variables we have the following:
    v(S) ←  c ,notdo(v(S)),notdo(¬v(S))               P (b, Y   = y ,...,Y    = y  |c)=
             1                           .                  Mx1    1      Mxm    m
    .                                                 PT ∪obs(c(0))∪do(x (1))∪...∪do(x (m)))
    .                                                                1         m
                                                        (b(0),y1(1),...,ym(m)).
    v(S) ←  cn,notdo(v(S)),notdo(¬v(S)).
 3. Let the disjunctive normal form of ¬fv(x1,...,xn) be Discussion on the theorem and its proof:
    d1 ∨ ...∨ dn, where each di is a conjunction of liter- Here the encoding has three main aspects: (i) the encoding
    als made up of from x1,...,xn. In the translation the of the PCM equations, (ii) taking into account the severing of
    parameter S is added to each endogenous variable xi of connections between variables when an action is performed,
    x1,...,xn, such that xi becomes xi(S). The P-log lite and (iii) considering models and submodels in parallel during
    program T will have the following rules:          counterfactual reasoning. For part (i) the notion of “unique
    ¬v(S) ←   d1(S),notdo(v(S)),notdo(¬v(S)).         solutions being computed in an iterative fashion” is impor-
    .                                                 tant as that leads to a correspondence between the unique so-
    .                                                 lutions and the answer sets. To do (ii) we use the negation
    ¬v(S) ←   dn(S),notdo(v(S)),notdo(¬v(S)).         as failure operator “not” and to do (iii) we introduce multiple
                                                      time lines. Overall, the proof is based on splitting the logic
                        P (b, YM  = y1,...,YM    =
Step 4: Encoding the query     x1             xm      programming translation of T to many layers, where the bot-
ym|c)                                                 tom layer consists of the enumeration of the background vari-
                                YM     yi             ables.
4.1: For each counterfactual statement xi = :
For each variable v ∈ V that is a member of the realization of 4.1 PCM, PAL and P-log lite
Xi = xi:ifv is positive, we add do(v(S = i)); else (i.e., v is
                                                                      [                  ]
negative) we add do(¬v(S = i)).                       A related work is Tran and Baral, 2004 , where an encod-
                                                      ing of PCM in an action language PAL is given. The en-
                     w ∈  c    w
4.2: For each variable     :if   is positive, we add  coding here to a probabilistic logic programming language
obs(w(0))         w                 obs(¬w(0)).  2
        ; else (i.e., is negative) we add             P-log lite is different from the encoding in [Tran and Baral,
Before presenting a theorem that formally relates PCM the- 2004]. There the key issue was to encode the severing of con-
ories and queries with our encoding, we need to consider a nection between variables when an action is performed. It
notion of “being able to compute unique solutions of a causal was achieved by introducing an ab predicate and having ef-
model using three valued iteration”. Consider the causal fect axiom make(vi) causes {ab(vi),vi} and a static causal
model from Example 1 which had the functions: A = U ∧ B. law ¬ab(vi) causes vi ⇔ fi(PAi,ui) to capture the PCM
B =  U ∨ A. In Example 1 we showed that for each value equation vi = fi(PAi,ui).
of U, there is a unique solution for A and B. In this case,
these unique solutions can be computed in an iterative fash- 5 Non-naive conditioning in P-log
ion. Suppose we initially assign the value false to U.We
then assign unknown to A and B. We now use 3-valued logic We now show how P-log provides an elaboration tolerant
on the causal functions and compute the values of A and B. way to perform non-naive conditioning in that it shows a
                    A          false    B
After the ﬁrst iteration has value  and   has value      3                                         [
unknown                                                  This has signiﬁcance beyond AI, as the recent thesis Riedel,
        . After the second iteration we reach a ﬁxpoint 2003] (awarded the best Ph.D thesis of Electrical Engineering at the
where A and B are both assigned to false. This is what California Institute of Technology for the year 2003) mentions three
we refer to as “being able to compute unique solutions of a valued iteration but does not point out that the iteration does not
causal model using three valued iteration.”           necessarily lead to the unique solution.

                                                IJCAI-07
                                                   247