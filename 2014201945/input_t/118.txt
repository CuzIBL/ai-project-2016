                                  Hierarchical Semantic Classification: 
                      Word Sense Disambiguation with World Knowledge* 

       Massimiliano Ciaramita Thomas Hofmann Mark Johnson 
            Brown University Brown University Brown University 
         massi@brown.edu th@cs.brown.edu mark.j ohnson@brown.edu 


                        Abstract                               in number. It thus seems intuitive to supplement task-specific 
                                                               training data, for example, sense-annotated training instances 
     We present a learning architecture for lexical se•        for a specific word, with background data encoding general 
     mantic classification problems that supplements           "world knowledge". The latter are typically available in suf•
     task-specific training data with background data en•      ficient quantities and need not to be generated separately for 
     coding general "world knowledge". The model               each classification task. To carry out this idea two crucial is•
     compiles knowledge contained in a dictionary-             sues need to be addressed: How exactly can world knowledge 
     ontology into additional training data, and inte•         be compiled into additional training data, and how can task-
     grates task-specific and background data through          specific and background data be systematically integrated? 
     a novel hierarchical learning architecture. Experi•         To address the first challenge, we propose to generate ad•
     ments on a word sense disambiguation task provide         ditional training data about broader semantic categories by 
     empirical evidence that this "hierarchical classifier"    extracting training sentences from a hierarchically structured 
     outperforms a state-of-the-art standard "flat" one. 
                                                               ontology, WordNet1 [Fellbaum, 1998]. We assumed that each 
                                                               example sentence associated with a lexical entry provides ev•
1 Introduction                                                 idence for the kind of contexts in which that specific concept 
                                                               and all its ancestors in the hierarchy can appear. As far as the 
There is an increasing interest in natural language pro•       second challenge is concerned, we introduce a novel hierar•
cessing (NLP) and information retrieval (IR) for research      chical learning architecture for semantic classification. More 
on lexical semantics, in particular with respect to word       specifically, we present a simple and efficient on-line training 
sense disambiguation [Yoong and Hwee, 2002], informa•          algorithm generalizing the multiclass perceptron of [Cram•
tion extraction [Riloff and Jones, 1999], named entity         mer and Singer, 2002]. 
recognition [Collins, 2002], and automatic thesaurus exten•      Finally, we carry out an experimental evaluation on a word 
sion [Hearst, 1992]. In general terms, the goal in these tasks sense disambiguation task, providing empirical evidence that 
is that of automatically associating words in text with seman• the hierarchical classifier outperforms a state-of-the-art stan•
tic labels. In information extraction and named-entity recog•  dard "flat" classifier for this task. 
nition noun phrases or proper nouns are assigned to semantic     The paper is structured as follows. Section 2 introduces the 
categories such as "organization", "person", or "location". In main idea in more detail. In Section 3 we introduce WordNet 
word sense disambiguation and thesaurus extension the goal     and the simplified ontology derived from it that we used as 
is to assign words to finer-grained categories defined by ex•  the source of world knowledge. Section 4 deals with the ba•
isting dictionaries and ontologies.                            sic multiclass perceptron and the proposed hierarchical mul-
   Lexical semantic information can be useful in many NLP      ticomponent classifier. Finally, Sections 5 and 6 describe the 
and IR applications such as text categorization, parsing, and  data set used and the empirical results, respectively. 
language modeling for speech recognition. Furthermore it 
can be crucial for tasks that require complex inferences in•   2 Word Sense Disambiguation and World 
volving world knowledge, such as question answering. 
  One of the main difficulties in learning semantic annota•        Knowledge 
tions stems from the fact that training instances are often nar• Word sense disambiguation is the task of assigning to each 
rowly focused on very specific class labels and relatively few occurrence of an ambiguous word in a text one of its possible 
   *Wc would like to thank our colleagues in the Information Re• senses. A dictionary is used to decide if a lexical entry is am•
trieval and Machine Learning Group (IRML) and Brown Labora•    biguous or not, and to specify its set of possible senses. The 
tory for Linguistic Information Processing (BLLIP), as well as Jesse most widely used lexical resource for this task is WordNet, 
Hochstadt for his editing advice. This material is based upon work which we describe in detail in the next section. 
supported by the National Science Foundation under Grant No. 
0085940.                                                          1 In this paper we always refer to WordNet version 1.71. 


NATURAL LANGUAGE                                                                                                      817                                Figure 1. The simplified two-layer hierarchy for the noun chair. 

   As an illustration consider the noun "chair", which accord• not know whether something is a person or an artifact we 
 ing to WordNet is ambiguous. Two possible senses are ex•      cannot learn reliable information about those more general 
 plained in the following WordNet entries:                     concepts. One way of addressing these problems is offered 
                                                               by WordNet itself. 
   • chairi - a seat for one person, with a support for the 
     back; 
   • chairi - (president, chairman, chairwoman, chair,         3 The Ontology 
     chairperson), the officer who presides at the meetings    3.1 WordNet 
     of an organization; 
                                                               WordNet is a broad-coverage, machine-readable dictionary 
   Word sense disambiguation is often framed as a multi-       widely used in NLP. The English version contains around 
 class pattern classification task. Useftil features include co- 150,000 entries, mostly nouns, but also verbs, adjectives, and 
 occurring words, word bigrams or trigrams, and properties of  adverbs. WordNet is organized as a network of lexical ized 
the syntactic context that contains the target word. Most com• concepts, called synsets, that comprise sets of synonyms. For 
monly systems are trained on labeled data for a specific word, example, the nouns {president, chairman, chairwoman, chair, 
for each and tested on unseen items of the same word. The set chairperson} form a synsct. A word that belongs to several 
of possible labels is the set of senses of the ambiguous word. synsets is ambiguous. Synsets are linked by semantic rela•
One limitation of such a strategy is that the system bases its tions, the most important of which for nouns and verbs is the 
decision exclusively on what it has been able to learn about a is-a relation, or hyponymy; e.g., "car" is a hyponym of "ve•
few very specific concepts; e.g., chair i and chair2. Further• hicle". The verb and noun databases form is-a hierarchies 
more, since manually sense-tagging words for the required     with a few general concepts at the top and several thousand 
training data is slow and expensive, the data is quite sparse. specific concepts at the leaf level. 
   A great deal of information about objects like "chairs"       The hierarchical structure of the database has aroused some 
is indirect and can be derived from more general world        interest in NLP, because it can support interesting compu•
knowledge through generalization and inference processes.     tational language learning models, for example, in learning 
Suppose that the task is to disambiguate between the two      predicate selectional preferences [Light and Greif, 2002]. We 
simple senses of chair in the following context:              aim to use the hierarchy to improve lexical classification 
                                                              methods. The model we present here can in principle make 
 1) "Here the quality of the finest chair components is       use of the full hierarchy. However, for the sake of simplicity 
merged with art."                                             we have focused on a less complex hierarchy, which has been 
                                                              derived from WordNet as described below. 
In this sentence components is a useful hint that we are 
dealing with the sense chairi. Chairs are artifacts, and 
                                                              3.2 A simple two-level hierarchy 
artifacts can have components. Conversely, even though 
in principle people could "have components" as well, this     WordNet was built, and is regularly updated, by lexicogra•
sounds a little odd. Intuitively, if a word sense disambigua• phers. Lexicographers group words together in synsets and 
tion system had access to this type of information - that     individuate the relevant semantic relations between synsets. 
"chairs" are subordinates of broader concepts like "artifacts" This process includes the classification of lexical entries into 
and "people" - and some knowledge about these broader         one of 26 broad semantic classes. In this paper we refer to 
semantic categories, it might achieve a higher accuracy in    these broad classes with the term supersenses. A few exam•
disambiguating words. Notice that the system might never      ples of supersense labels are person, animal, artifact, food, lo•
have previously observed any instance of the noun "chair",    cation, time, plant, process, attribute, substance, and relation. 
in either sense, as "having components".                      This set of labels is fairly general and therefore small. At 
   The goal hence is to complement specific but limited       the same time the labels are not too abstract. In other words, 
knowledge about narrow classes with richer, if less specific, these classes seem natural and easily recognizable, and that 
knowledge about more general classes. We can easily recover   is probably why lexicographers use them. In fact the level of 
the fact that chairs are kinds of furniture or people from dic• generality is very close to that used in named-entity recogni•
tionaries and hierarchically organized ontologies like Word-  tion ("location", "person", "organization", etc.). 
Net. Learning information about such general concepts, how•      Each synset in WordNet is associated with one supersense 
ever, is complicated. One source of complication is the very  label. As a result the database implicitly defines, in addition 
problem we are trying to solve, lexical ambiguity. If we do   to the full hierarchy, a simpler two-layer hierarchy. Figure 


818                                                                                               NATURAL LANGUAGE 1 above illustrates the synsets and supersenses chair belongs Algorithm 1 Multiclass Perceptron 
to.                                                            l: 
                                                               2: 
3.3 The hierarchy as a source of world knowledge 
                                                               3: 
For a few thousand concepts WordNet lists, among other         4: 
types of semantic information, one or more example sen•        5: 
tences. For the sense of chair above the example sentences     6: 
are the following:                                             7: 
  • chairi - "he put his coat over the back of the chair and   8: 
     sat down"                                                 9: 
                                                               10: 
  • chair2 - "address your remarks to the chairperson" 
                                                              11: 
Overall there are 9,258 of these sentences. Since each one     12: 
is associated with one synset, that is in fact a sense-tagged 
instance of the word. In other words, WordNet provides a 
few thousand potential sense-tagged training instances.          In general, a multiclass classifier for word it; is a function 
  Unfortunately, this additional data in itself would not be of                    that maps feature vectors to one of 
much help: for most of the synsets there are no sentences2,   the possible senses of . In the multiclass perceptron, one 
and typically the sentences are very short and do not provide introduces a weight vector for every and 
much context. However, the situation appears in a different   defines implicitly by the so-called winner-take-all rule: 
light if we take into account the hierarchy. Considering an ex•
ample sentence for a synset also as an example sentence for                                                          (1) 
its ancestors (synsets at higher levels in the hierarchy), the 
number of sentences grows larger at the superordinate lev•    Here refers to the matrix of weights, every col•
els. If we consider the supersense level, the set of example 
                                                              umn corresponding to one of the weight vectors  
sentences constitutes in fact a small corpus of supersense-
                                                                 The learning algorithm works as follows: Training patterns 
annotated data. Our hypothesis is that the several hundred 
                                                              arc presented one at a time in the standard on-line learning 
sentences associated with each supersense can provide a use•
                                                              setting. Whenever an update step is per•
ful source of general world knowledge. In the next section we 
                                                              formed; otherwise the weight vectors remain unchanged. To 
describe a general multicomponent learning architecture that 
                                                              perform the update, one first computes the error set E  con•
can be used to exploit this supplementary training data.                                                           l
                                                              taining those class labels that have received a higher score 
                                                              than the correct class: 
4 Multicomponent Learning Architecture 
                                                                                                                     (2) 
The idea of using the hierarchical structure of a domain to 
overcome sparseness problems has been explored in text cat•   An ultraconservative update scheme in its most general form 
egorization. These methods show improved accuracy and ef•     is then defined as follows: Updatewith learn•
ficiency [Toutanova et al., 2001; Dumais and Chen, 2000].     ing rates fulfilling the constraints  
In NLP the hierarchical structure of WordNet has been used    and Hence changes are lim•
to overcome sparseness data problems for estimating class     ited to . The sum constraint ensures 
distributions [Clark and Weir, 2002], and to exploit morpho•  that the update is balanced, which is crucial to guaranteeing 
logical information to improve lexical acquisition [Ciaramita, the convergence of the learning procedure (cf. [Crammer and 
2002].                                                        Singer, 2002]). We have focused on the simplest case of uni•
                                                              form update weights, . The algorithm 
4.1 Multiclass perceptron 
                                                              is summarized in Algorithm 1. 
The architecture we propose is a generalization of "ultra-       Notice that the presented multiclass perceptron algorithm 
conservative" on-line learning [Crammer and Singer, 2002],    learns all weight vectors in a coupled manner, in contrast to 
which is itself an extension of perceptron learning to the mul• methods that perform multiclass classification by combining 
ticlass case. We describe this "flat" version of the classi•  binary classifiers, for example, training a classifier for each 
fier first. For each noun w we are given a training set S = 
                                                              class in a one-against-the-rest manner. 
          , where each instance and  
Y(w) is the set of synsets that WordNet assigns to w. Thus    4.2 Hierarchical multiclass perceptron 
5 summarizes n instances of noun w, where each instance       The hierarchical multiclass perceptron is inspired by the 
i is represented as a vector of features X{ extracted from the framework for learning over structured output spaces intro•
context in which w occurred; d is the total number of features duced in [Hofmann et al., 2002]. The key idea is to intro•
and yi is the true label of                                   duce a weight vector not only for every (leaf-level) class, but 
                                                              also for every inner node in a given class taxonomy. In the 
   2Therc are in total around 75,000 synsets in the noun database. 
                                                              current application to word sense disambiguation, the inner 
   3Since some instances are labeled with multiple senses, in cases 
where the taggers were uncertain, y» may actually be a set of labels. nodes correspond to the 26 supersenses 5 and we will hence 


NATURAL LANGUAGE                                                                                                     819 introduce additional weight vectors for , where                  The second part concerns training on the task specific data 
S(w) refers to the subset of supersenses induced by                   . If the classifier makes a mistake on pattern error 
We will use the notation to refer to the supersense corre•     sets are computed for its individual components both at the 
sponding to a synset y. Then discriminant functions            synset and supersense levels (lines 15 and 19 above), which 
can be defined in an additive manner by                        are updated according to the standard multiclass update rule. 
                                                        (3)      As an example, suppose that given a pattern Xi of chair the 
                                                               synset error set is 
If one thinks of/ in terms of a compatibility function between while the correct label is  
an observation vector x and a synset y, then the compatibility PERSON. The update vector is subtracted from the 
score is simply the sum of two independent contributions, one 
                                                               vectors relative to the labels in E  while is added to 
stemming from the supersense level and the other one coming                                     i
                                                               If at the supersense level the error set Ef = {ARTIFACT}, 
from the more detailed synset level. The multiclass classifier 
                                                               X  is subtracted from the vector for ARTIFACT and added 
is then again defined using the winner-take-all rule,           i
                                                               to . Therefore, through the supersense weight vectors, the 
                                                               background data affects classification at the synset level. 
                                                        (4) 
                                                               5 Data Set and Features 

Algorithm 2 Hierarchical Multiclass Perception                 5.1 The Senseval data 
                                                               We tested our system on a standard word sense disambigua•
                                                               tion data set. The training and test data are those used in the 
                                                               last Senseval workshop (Senseval-2/ACL-01, 2001), which 
                                                               focused exclusively on word sense disambiguation. The train•
                                                               ing set consists of 8,611 paragraphs that contain an ambigu•
                                                               ous word whose sense has been manually annotated. The 
                                                               inventory of senses is taken from WordNet. Similarly, the 
                                                               test set consists of 4,328 unlabeled pairs. We only ran ex•
                                                               periments on the noun data, which consists of 3,512 training 
                                                               instances and 1,754 test instances. Each instance consists of 
                                                               a short passage taken from one of various sources: e.g., the 
                                                               Wall Street Journal, British National Corpus, and web pages. 

                                                               The task-specific training data, Ty, is typically smaller than 
                                                               the general one, Ts> The average ratio is equal to 
                                                               20.3. 

                                                               5.2 Features 
                                                               We used the same feature set described in [Yoong and Hwee, 
                                                               2002], which is compact but includes most of the features 
                                                               that have been found useful in this task: surrounding words, 
                                                               bigrams and trigrams, and syntactic information. Yoong and 
                                                               Hwee report results for several classifiers broken down by 
                                                               part of speech, which makes it possible to compare our sys•
                                                               tem's performance with that of several others. 
                                                                 There are four types of features. The following sentence 
                                                               serves to illustrate them: "the dinner table and chairs are ele•
                                                               gant yet comfortable". The feature set is described in greater 
                                                               details in [Yoong and Hwee, 2002]: 
                                                                 •part of speech of the neighboring words:= CC, 
                                                                       = NNS, P    = AUX,... 
   The complete algorithm is summarized in Algorithm 2.                         +1
The first part of the algorithm concerns the different nature    • single words in the surrounding context: C == elegant, 
of the two types of training data. As we explained in Sec•          C = dinner, C = table, C = the,... 
tion 3, the supplementary data derived from WordNet only         • bigrams and trigrams: C_i,+i = and.are, 
provides annotations at the supersense level. We cannot use 

this information to perform updates for weight vectors vy, but 
only to adjust the weights . Hence for supersense-annotated      • head of the syntactic phrase that governs the tar•
training instances we compute the error set on the                 get: 
                                                                   G_RELP0S = left. 
supersense level as and 
perform the standard multiclass update step tor all with         Syntactic features and part of speech tags were extracted 
                                                               from the syntactic parse trees of the Senseval-2 training and 


820                                                                                                NATURAL LANGUAGE  Figure 2. Test accuracy of the flat multiclass perceptron     Figure 3. Test accuracy of the hierarchical (continuous line) 
 (dashed line) and the hierarchical multiclass perceptron (con• vs. flat (dashed line) multiclass perceptron. The hierarchical 
 tinuous line) on the word sense evaluation data set.          multiclass perceptron was trained using supplementary super-
                                                               sense training data. 

 test data produced using Charniak's parser LCharniak, 2000]. 
 In this way we created the training data Ty from the Senseval   Figure 3 plots the performances of the flat and the hierar•
 data. In exactly the same way we extracted features from      chical perceptron when also trained on Ts- The two patterns 
 the example sentences in WordNet to produce the additional    are very different. The hierarchical model converges only af•
 training set for the supersense-level classes, Ts. Overall there ter more than 350 iterations. 
 are around 250,000 features. 

 6 Experiments 
 6.1 Experimental setup 
 We tested two models described in Section 4: the flat multi-
 class perceptron, trained and tested at the synset level, and the 
 hierarchical one, trained on both the standard synset data and 
 the training data for the supersenses extracted from WordNet.     Table 1. Test accuracy on the Senseval-2 test data. 
 We also trained and tested a simple "flat" naive Bayes clas•
 sifier. A different classifier was trained and tested for each  This might be due to several facts. First, the amount of 
 word. We treated compounds such as easy chair and chair as    data is much greater due to the addition of Ts, and it takes 
 different words.                                              longer to learn. Second, the supersense data and the synset 
   All the results we report are given as accuracy:            data are probably very different and noisy; as a consequence 
                                                               the weight vectors are continually readjusted, possibly along 
                                                               very different dimensions. The interesting thing, though, is 
                                                               that even in the midst of very wide oscillations there is a clear 
                                                               improvement, particularly between 50 and 100 iterations. 
 6.2 Results                                                     We present also a comparative table. Table 1 illustrates the 
 Figure 2 shows the performance of the flat perceptron (dotted results of our systems and other state-of-the-art word sense 
 line) during each iteration. The perceptron in fact converges disambiguation ones. We set the number of iterations to a 
very quickly. This is probably due to the fact that there are  fixed number for all words equal to 100. Given that we set 
relatively few training items: Normally the size of Ty is be•  this value "knowing" that it is a good one for both our sys•
 tween one and two hundred. To check whether an improve•       tems, our results and those of other systems are not really 
 ment was due to the algorithm alone and not to the combina•   comparable. However, it is reasonable to expect that it is 
 tion of the algorithm and the additional, supersense data set, possible to set this stopping criterion well enough using held 
 we also trained a hierarchical perceptron exclusively on the  out data. Thus this comparison gives us an approximate idea 
 synset data. Figure 2 also plots the performance of the hier• of where our systems stand with respect to state-of-the-art 
 archical perceptron trained only on Ty. The two curves are    ones in terms of performance. AdaBoost is the classifier that 
virtually indistinguishable, meaning that without additional  gave the best result on nouns in [Yoong and Hwee, 2002], 
 information not much can be gained from using the hierarchi•  Best S2 [Mihalcea and Moldovan, 2001] refers to the best-
cal classifier alone. In other words, with "flat" data a "flat" performing system on nouns among the Senseval-2 workshop 
 classifier is as good as a "hierarchical" one.                systems. These results show that our systems' performance is 


 NATURAL LANGUAGE                                                                                                    821 