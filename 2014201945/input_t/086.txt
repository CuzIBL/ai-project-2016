                        Does a New Simple Gaussian Weighting Approach 
                                 Perform Well in Text Categorization? 

                    Giorgio Maria Di Nunzio                               Alessandro Micarelii 
              Dip. di Ingegneria dell'Informazione                 Dip. di Informatica e Automazione 
                Universita degli Studi di Padova                   Universita degli Studi "Roma Tre" 
           Via Gradenigo 6/b, 35131 Padova - Italia Via della Vasca Navale 79,00146 Roma - Italia 
                      dinunzio@dei.unipd.it micarcl@dia.uniroma3.it 

                        Abstract                               expert human being in front of the problem of classifying new 
                                                               unknown documents. 
     A new approach to the Text Categorization prob•
                                                                 Starting from this idea of simplicity, we decided to design 
     lem is here presented. It is called Gaussian Weight•
                                                               a training algorithm that corresponds to the action of finding 
     ing and it is a supervised learning algorithm that, 
                                                               two information parameters: given a set of categories C of 
     during the training phase, estimates two very sim•
                                                               documents, for each term t of a category c C we calcu•
     ple and easily computable statistics which are: the 
                                                               late its Presence P, that is, the percent of documents of the 
     Presence P, how much a term / is present in a cate•
                                                               category c in which the term / appears at least once; and its 
     gory c\ the Expressiveness E, how much / is present 
                                                               Expressiveness E", that is, how much the term / is absent in 
     outside c in the rest of the domain. Once the system 
                                                               the other categories of the domain. Then, we model a Gaus•
     has learned this information, a Gaussian function is 
                                                               sian Function with the two parameters above, whose value 
     shaped for each term of a category, in order to as•
                                                               in the abscissae equal to 1 is used as the weight of the term 
     sign the term a weight that estimates the level of its 
                                                               /. We called this learning approach Gaussian Weighting. It 
     importance for that particular category. We tested 
                                                               is important to stress the fact that we don't use any stemming 
     our learning method on the task of single-label clas•
                                                               algorithm or Feature Selection function (see [Yang and Peder-
     sification using the Reuters-21578 benchmark. The 
                                                               sen, 1997]). An eventual reduction of the number of features 
     outcome of the result was quite impressive: in dif•
                                                               per category is done using only two thresholds named ThresP 
     ferent experimental setups, we reached a micro-
                                                               and ThresE, relative to the parameters P and E. 
     averaged Fl-measure of 0.89, with a peak of 0.899. 
     Moreover, a macro-averaged Recall and Precision             To make the evaluation of Gaussian Weighting comparable 
     was calculated: the former reported a 0.72, the lat•      to most of the published results on TC, we chose the Reuters-
     ter a 0.79. These results reach most of the state-        215781 corpus as benchmark for the single-label classifica•
     of-the-art techniques of machine learning applied         tion task. Three different tests have been performed with a 
     to Text Categorization, demonstrating that this new       complete automated learning approach: the first run has been 
     weighting scheme does perform well on this partic•        done without the use of a Gaussian Function, but simply giv•
     ular task.                                                ing a weight proportional to P and E: the second and the third 
                                                               test runs have been done with the Gaussian Weighting ap•
                                                               proach proposed here. 
1    Introduction                                                The outcome of the results was quite surprising: through•
Consider the problem of automated classification of text doc•  out the different experimental setups, we repeatedly reached 
uments. This problem is of great importance as the accessible  a micro-averaged Fl -measure around the 0.89, with a peak of 
textual information increases and the volume of online texts   0.899. Then, since the micro-average is known to be highly 
available through the Internet expands rapidly. One solution   influenced by frequent categories (see [Yang and Liu, 1999]), 
is to categorize documents according to their topics before•   we decided to compute the macro-averaged Recall and Pre•
hand or in real time.                                          cision. Again, the results reached a satisfactory macro-
   A number of different Machine Learning methods have         Recall around 0.72 and a macro-Precision of 0.79. These 
been applied and to Text Categorization (TC), including prob•  results reach most of the state-of-the-art techniques of ma-
abilistic classifiers, decision trees, regression methods, neu• chine learning applied to Text Categorization (see [Dumais 
ral networks and support vector machines (see [Sebastiani,     et al., 1998]), demonstrating that this new weighting scheme 
2002]). Most of these methodologies share a common factor      does perform well on this particular task. Moreover, the low 
of high level complexity, that, often, makes a classifier design computational cost of the algorithm we propose, makes this 
difficult to understand.                                       approach particularly preferable when the computing power 
  The question addressed in this paper is if it is possible to is low. 
find a simple learning algorithm that uses naive, human com•
prehensible parameters, in such a way as to act like a non-        www.daviddlewis.com/resources/testcollcction/reuters21578 


LEARNING                                                                                                              581  2   The Algorithm                                             Locality of Presence and Expressiveness 
 In this section we present our supervised algorithm. First, we The approach uses a weighting method for terms per each 
 will analytically define the two parameters: Presence P and   class, which is in a sense a local type of weighting/modeling 
 Expressiveness E. Then, we will explain how the training al•  scheme of classes. This idea is similar to the Local LSI rep•
 gorithm works and how the system classifies new documents     resentation [Hull, 1994] where, in order to characterize the 
 at run-time.                                                  term space, the singular value decomposition is applied to a 
                                                               matrix consisting only of the known relevant documents (in 
 2.1   Presence P and Expressiveness E                         our case the documents belonging to a class). 
 A central key of this naive approach is the computation of two  There are substantial differences with the weight-
 easy human understandable parameters that we call: Pres•      ing scheme. counts the number of occurrences of a term / 
 ence P, and Expressiveness E. The former captures how much    in a document, while P counts the documents in which / ap-
 a term t appears at least once in the documents belonging     pears at least once. computes the number of documents 
 to a category c, the latter estimates how much the same       in which t appears over the whole collection, meanwhile E 
 term t does not appear in the documents of the other cat•     calculates, according to which class we are computing the 
 egories. Given a set of categories                            weights, the partial averaged Presence of/ in the domain. 
    , each category having a number of documents m, (e.g. 
                                     we give the following     2.2   Learning the Gaussian Weights (GW) 
 definitions:                                                  In this paragraph we explain how we shape a Gaussian func•
                                                               tion using the values P and E. Starting from the definition of 
     The number of documents D    of the i-th category is: 
                                 i                             a generic Gaussian function: 

                                                        (1)                                                           (5) 

     the number of documents of category / in which the term   we estimate the parameters and as follows: 
     / is present: 
                                                                                                                      (6) 

                                                        (2)                                                           (7) 
                                                                 Then, the Gaussian Weighting GW for a term t of a cate•
                                                               gory i is defined, substituting (6) and (7) in (5), as: 
 Note that we use the symbol *|" to denote the presence of 
 a term inside a category or a document. This is not to be 
 confused with the same symbol when used for the conditional                                                          (8) 
 probability (P(x|y)). 
   Then, the Presence P of a term t in the i-th category is,   The GW calculated for x = 1, returns a real value belonging to 
 using (1) and (2):                                            the (0,1] interval. In particular, the maximum weight can be 
                                                               reached only when the Presence of a term is equal to 1, that 
                                                               is to say, when it appears in each document of the category 
                                                               of interest. Figure 1 shows an example of a GW with P = 0.5 
 while, the Expressiveness E of term t in the i-th category is 
                                                               and E = 0.5 (continuous), and another one with P = 0.5 and E 
 calculated using 1, 2): 
                                                               = 0.9 (dashed); when two terms have the same Presence, the 
                                                               one with a higher Expressiveness has a higher weight too. 
                                                               Computing the parameter P 
It is important to stress that the same term in different cat• The algorithm to compute P is the following: 
egories has different values of expressiveness. This fact is 
                                                                 1. For each category 
better explained in Table 1. A term t is present in all the three 
categories with presence shown in the first row. The sec•        2. 
ond row is the expressiveness of the same term for each          3.   For each document 
category. Note how / of category c  has a greater expressive•
                                 1                              4. 
ness given the relatively smaller presence of the term in the 
rest of the domain.                                              5.     For each unique term t in 
                                                                 6.      if t is in 
                                                                 7.      then 
                                                                 8.      else Add 
                                                                9.      end For 
Table 1: A numerical example of Presence and Expressive•
ness.                                                           10.   end For 
                                                                11.  For each term in 


582                                                                                                           LEARNING                                                                  1. For each  
                                                                2. output  
                                                                 3.   For each term in  
                                                                4.     if t is in test 
                                                                   And  
                                                                 5.    then output 
                                                                   Nterm = Nterm + 1 
                                                                6.    end For 
                                                                7. 
                                                                8. end For 
                                                                9. Assign the document to the with the highest output  
                                                               For each category, the algorithm calculates, the mean of the 
                                                               activated Gaussian functions of the terms whose and 
                                                               are greater than two fixed thresholds, respectively ThresP and 
 Figure 1: Example of a GW. The continuous line is a GW        ThresE. The computational cost of this algorithm is  
 with P = 0.5 and £ = 0.5. The dashed line is a GW with P = 
 0.5 and E = 0.9. For the same P, the higher expressiveness a 
 term possesses, the bigger the output GW gives.               3   Experimental Setup 

 12.                                                           3.1  Test Collection 
 13.   end For                                                 To make the evaluation of GW comparable to most of the 
                                                               published results on TC, we chose the Reuters-21578 corpus 
 14. end For                                                   as benchmark. During the last few years this corpus has been 
 If we assume we can use a HashMap HM to store the results     used as a standard benchmark on which many TC methods 
 of such that any update or search in the HM has a con•        have been evaluated, although the results are sometimes dif•
stant cost K, in the worst case the algorithm to compute the   ficult to compare as slightly different version have been used. 
parameter P has a computational cost of                        For this paper we used the ModApte split of Reuters-21578 
Computing the parameter E                                      in which 75% of the stories (9603) are used as training doc•
                                                               uments to build the classifier and the remaining 25% (3299) 
The algorithm to compute E is the following: 
                                                               to test the accuracy of our single-label classifier. Now, the 
   1. For each category                                        Reuters-21578 is known to be quite unbalanced on the distri•
  2. sum- 0                                                    bution of stories per category. Therefore, of the 135 poten•
                                                               tial topics categories only the 10 most frequent are here used; 
  3.    For each term t in 
                                                               these 10 categories account for almost the 75% of the training 
  4.     For each category where i =£ j                        instances, while the remainder is distributed among the other 
  5.       if tin                                              115. Table 2 shows the number of training and test samples 
                                                               for each category. 
  6.       then sum =• sum + 
  7.     end For 
  8. 

  9.   end For 
 10. end For 
Again, if we assume that is a HashMap with a constant 
cost k of access and search, the computational cost of this 
second algorithm is , which is quadratic cost 
with respect to the number of categories C. 
2.3   Categorizing a new document 
Once the system has been trained and the parameters P and E 
have been found for each term of the domain, it is possible to 
                                                              Table 2: Number of Training and Test documents for the ten 
feed the system with an unknown document and, according 
                                                              most frequent categories of Reuters-21578 ModApte split 
to the value of a couple of optional thresholds ThresP and 
ThresE, classify it with the following algorithm: 


LEARNING                                                                                                             583 3.2   Parameters Setting                                       [Yang and Pedersen, 1997]), we have decided to calculate 
We performed three different test runs on our system:          the Macro-Recall (MRe) and the Macro-Precision (MPr)), as 
                                                               well: 
  1. The 'what if?' test run: what if we didn't use a Gaus•
     sian function? we tried to run our system with the most 
     simple function we could use:  
  2. The GW test run: uses the GW function defined in equa•
     tion (8) 
  3. The simple GW test run: we simplified the Gaussian 
     function with a variance equal to                         4   Results 
All the tests maintained ThresE equal to 0.6, that is to say, a 4.1 The 'What if?' test run 
term in a category should have an Expressivity value greater   In this test, the weight of each term / of a category i is com•
than 0.6. This value permitted to achieve the highest perfor•  puted as: 
mance during the test phase. ThresP has been varied in the 
range between 0.0 (all the terms of the categories were used) 
and 0.5 (only the terms present in the 50% of the training    The 'What if?' test run results are shown in Figure 2. 
documents were used). 
  The number of terms per category according to the value P 
is reported in Table 3. 


                                                              Figure 2: The 'What if?' test run. The x-axis represents the 
                                                              values of Presence P. 

Table 3: The table shows the number of terms per category 
according to the threshold of Presence P. The last row reports 
the average of features per category. 

  A stoplist of 331 terms has been used to remove the most 
frequent words of the English Language, but no stemming or                  Table 4: The 'What if?' test run. 
Feature Selection have been performed. 
  In order to evaluate the accuracy of the classifier we have    In this particular test we did nOt expect so remarkable a 
computed the standard 1R measures, such as Recall and Pre•    performance. Considering the weight of a term proportional 
cision, and the following averaging measures: micro-Recall    to the parameters P and E seems to be another possible solu•
       micro-Precision and micro-averaged Fl mea•             tion to investigate. The performance of the system seems not 
sure (micro-Fl):                                              to be influenced significantly when the threshold ThresP is 
                                                              set either to 0.0 or 0.1. It is worth stressing that this test per•
                                                              formed better when all the terms (except those belonging to 
                                                              the stoplist) were used. 

                                                              4.2 The GW test run 
                                                              The results of this run are shown in Figure 3, while numerical 
                                                              values are reported in Table 5. 
                                                                 This test has been performed using equation (8) to calcu•
                                                              late the weight of each term of the category. The best results 
In particular we have reported the values of the Fl-measure   have been obtained with Thres Macro-Recall and 
in order to directly compare our results with the ones in the macro-Precision are quite high, and they indicate that the sys•
literature. But, since the micro-averaged measure is known    tem works well for every category. The performance of the 
to be highly influenced by the most frequent category (see    system starts to decrease sensibly when Thres  


584                                                                                                           LEARNING                                                                           Table 6: The simple GW test run. 

                                                             category decreases from almost 90 to almost 20. This sharp 
                                                             decay influences the macro-averaged performance of the sys•
                                                             tem. In fact, while the macro-Recall retains the same values, 
                                                             the macro-Precision is cut-off by almost 10%. This fact in•
                                                             dicates that the system is incorrectly assigning the stories to 
Figure 3: The GW test run. In this test the function 8 is used 
                                                             all the categories of the domain rather that to the biggest ones 
to weight each term. 
                                                             only. As the ThresP gets bigger, the performance of the sys•
                                                             tem shows the classic behavior in which the Recall tends to 0 
            1 0.0    0.10    0.20   [ 0.30   0.40    0.50 
                                                             and the Precision to 1. 
1 micro F1   0.892   0.893   0.876   0.856   0.832   0.748     For the 'what if?' test run we didn't expect such good re•
( macro Re   0.726   0.725   0.692   0.666   0.613   0.532   sults. The simple proportional weight assignment performed 
1 macro Pr   0.794   0.797   0.789   0.810   0.809   0.804   as well as the other approaches, nevertheless the performance 
                                                             decays slightly more rapidly. This test was very important for 
Table 5: The GW test run. Each column reports the values of  us to confirm the idea of using a simplified learning approach 
micro F1, macro Recall and macro Precision for each ThresP.  to solve the problem of TC. 
                                                               The second and the third test runs show almost the same 
4.3 The Simple GW test run                                   values. The one-per-thousand differences are not to be con•
                                                             sidered relevant. At the moment, we cannot draw any con•
The results of this second run are shown in Figure 4. Numer•
                                                             clusion about which of the three learning approaches will 
ical values are reported in Table 6. 
                                                             perform better in general. We plan to investigate this mat•
                                                             ter testing on the complete Reuters-21578 and on other test 
                                                             collections. 

                                                             Comparative Results 
                                                             Dumais et al. tested a number of inductive learning algo•
                                                             rithms on the same Reuters-21578 ModApte split we used 
                                                             ([Dumais et ai, 1998]). These results arc briefly summi-
                                                             rized in Table 7 for the 10 most frequent categories. The 


Figure 4: The simple GW test run. In this test the variance of 
the GW is equal to  

  This test has been performed using a simplified version of Table 7: Microavcraged Fl-measure of the 10 most frequent 
equation (8) to calculate the weight of each term of the cat• categories of Reuters-21578, reported by Dumais 
egory. The variance of the Gaussian function is set to  
     The best results have been obtained with Thresp=        FindSim method is a variant of Rocchio's method for rele•
    there does not seem to be any particular difference with vance feedback([Rocchio, 1971]). The Naive Bayes classifier 
the GW test run, except in cases when ThresP equals 0.2,     is constructed by using the training data to estimate the prob•
where the macro Precision is sensibly lower.                 ability of each category given the document feature values of 
                                                             a new instance. A discussion of the indipendence assump•
4.4 Discussion                                               tion of naive bayes classifier can be found in ([Lewis, 1998]). 
The results reported above are satisfactory. In many situa•  BayesNets is a bayesian network, that uses 2-dependence 
tions the system reached an accuracy comparable to the ones  Bayesian (see [Sahami, 1996] for another example of Bayes 
in the state-of-the-art systems. Some aspects need to be dis• nets for classification). Tree is a Decision Tree approach de•
cussed here: the performance of the system in all the test   scribed in ([Chickering et al, 1997]). Meanwhile, Linear 
runs decades when ThresP exceeds the 0.2, that is to say,    SVM is a linear hyperplane that separates a set of positive 
looking back to Table (3), when the number of features per   examples from a set of negative ones ([Joachims, 1998]). 


LEARNING 