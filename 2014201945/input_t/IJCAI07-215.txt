                         Mechanism Design with Partial Revelation

                                Nathanael¨  Hyaﬁl  and  Craig Boutilier
                              {nhyafil,cebly}@cs.toronto.edu
                                    Department of Computer Science
                                         University of Toronto
                                   Toronto, ON, M5S 3H5, CANADA

                    Abstract                          are bot fully revealed (thus relieving agents of some of the
                                                      computational and communicational burden) has become an
    Classic direct mechanisms require full utility revelation important problem in computational mechanism design.
    from agents, which can be very difﬁcult in practical
    multi-attribute settings. In this work, we study par- In this paper we consider the design of one-shot mech-
    tial revelation within the framework of one-shot mecha- anisms that make decisions using partial type information.
    nisms. Each agent’s type space is partitioned into a ﬁnite In Section 2, we present a model of partial revelation and
    set of partial types and agents (should) report the partial survey those models and results that inﬂuence our approach,
    type within which their full type lies. A classic result with emphasis on the tension between partial revelation and
    implies that implementation in dominant strategies is im- dominant strategy implementation. In Section 3, we show
    possible in this model. We ﬁrst show that a relaxation that relaxing implementation to Bayes-Nash or ex-post does
    to Bayes-Nash implementation does not circumvent the
    problem. We then propose a class of partial revelation not allow for the design of “useful” partial revelation mech-
    mechanisms that achieve approximate dominant strategy anisms. We therefore consider approximate dominant incen-
    implementation, and describe a computationally tractable tive compatibility, in which the potential gain from misreport-
    algorithm for myopically optimizing the partitioning of ing one’s partial type in bounded. We deﬁne a class of regret-
    each agent’s type space to reduce manipulability and so- minimizing mechanisms (Section 4) that chooses an outcome
    cial welfare loss. This allows for the automated design of that minimizes the worst-case loss (w.r.t. social welfare) over
    one-shot partial revelation mechanisms with worst-case all possible types in the declared partial types. We then de-
    guarantees on both manipulability and efﬁciency.  ﬁne several payment schemes, describe the important proper-
                                                      ties of our mechanisms (speciﬁcally, approximate efﬁciency,
                                                      rationality and incentive compatibility) and argue for their
1  Introduction                                       suitability. While these results hold for any partial types, the
An important challenge facing AI is the design of protocols quality of the approximation depends critically on the choice
through which self-interested agents might interact to achieve of partial types. In Section 5 we deﬁne an algorithm to opti-
some desirable outcome (such as negotiating an outcome that mize the choice of partial types that allows one to tradeoff the
maximizes social welfare). As a consequence, mechanism amount of elicitation with the degree of efﬁciency and incen-
design [17]—which studies precisely this problem from an tive compatibility loss. Taken together, regret-based mech-
economic and game-theoretic point of view—has become an anisms and the optimization algorithm provide a framework
important area of study within AI and computer science more for the automated design of partial revelation mechanisms
broadly. Roughly speaking, a mechanism is a game intended in which one can explicitly address such tradeoffs. Prelim-
to implement some social choice function (SCF), i.e., a func- inary computational experiments conﬁrm the efﬁcacy of our
tion that selects some outcome as a function of the prefer- approach. We defer all proofs to a longer version of the paper.
ences of the participating agents.
  A key result in mechanism design, the revelation princi-
ple, states that mechanisms can be restricted to incentive com-
patible, direct mechanisms, in which agents fully reveal their 2 Background and Deﬁnitions
true type (i.e., utility function over outcomes). For instance,
Vickrey-Clarke-Groves (VCG) is such a mechanism for so- We begin with some essential background. To motivate our
cial welfare maximization.                            deﬁnitions, we will use a simple running example of a buyer
  Unfortunately, direct type revelation is problematic in prac- wishing to purchase a car from a seller. We wish to facilitate
tice, since utility functions can be extremely difﬁcult for the negotiation: they must agree on the car (from the seller’s
agents to even compute effectively or communicate to the inventory) and the price to be paid; but buyer’s valuation for
mechanism, especially in settings with large, multiattribute different cars and the seller’s cost is not known to us. Ideally,
outcome spaces (a familiar example is combinatorial auctions we would identify the car that maximizes surplus (the differ-
[7]). Thus the design of mechanisms where utility functions ence between the buyer’s valuation and the seller’s cost).

                                                IJCAI-07
                                                  13332.1  Mechanism Design                                 nant strategies: it is characterized by any efﬁcient allocation
                                                      function, and the Groves payments [11]:
We adopt a standard quasi-linear environment with n agents
                                                           p  t   p t  , x∗   h  t   − SW    x∗ t
in which the aim is to choose an outcome or allocation x    i( )=  i( −i  )=   i( −i)     −i(  ; −i)  (1)
from the set X of all possible allocations. Each agent i ≤ n for any functions hi : T−i → R. In non-trivial settings, the
has type ti drawn from set Ti, and valuation function vi : Groves scheme is the only class of mechanisms that can im-
X×Ti  →  R, with vi(x; ti) denoting the value of allocation x plement any SCF in dominant strategies. This follows from
if i has type ti. In many cases, we can view ti as encoding i’s two famous results: Roberts [22] showed that if X contains
utility function over X.LetT = i Ti be the set of full type at least 3 outcomes and all valuations are possible, then an
vectors. The social welfare of x given t ∈ T is SW (x; t)= SCF is implementable in dominant strategies iff it is an afﬁne
  i vi(x; ti).Lett−i denote a type vector over all agents but welfare maximizer (i.e., afﬁne transformation of social wel-
i,andSW  −i(x; t)=   j=i vj(x; tj ). In our example, the fare); while Green and Laffont [10] proved that to implement
buyer’s type tb would determine its valuation vb(x; tb) for any an afﬁne welfare maximizer one must use Groves payments.
transacted vehicle x (and similarly for the seller, its cost). Thus, to implement social welfare maximization in dominant
The space of possible types Tb could be deﬁned in a number strategies, one must not only elicit enough information to de-
of ways. For instance, if |X| = n, Tb could be the set of termine the efﬁcient allocation but generally also enough fur-
                                                                                                 3
n-vectors 0 ≤ v ≤ c for some constant c (with vi denoting ther information to determine the Groves payments.
the utility of the ith vehicle). However, valuations can often
be represented more compactly. For instance, if a buyer’s 2.2 Partial Revelation Mechanisms
utility is known to be linear with respect to a small set of car We deﬁne a partial type θi ⊆ Ti for agent i to be any subset
                                                        i                         θ
features, then a Tb may be k-dimensional (for some k<n), of ’s types. A partial type vector includes a partial type for
and any type captured by a set of k parameters.      each agent. A (direct) partial revelation mechanism (PRM)
                                                      is any mechanism in which the action set Ai is a set of partial
  A mechanism consists of a set of actions A = i Ai,an
allocation function O : A → X and n payment functions types Θi (i.e., the agent is asked to declare the partial type
pi : A →  R. Intuitively, the mechanism offers the action in which its true type lies). Since agents only reveal partial
set Ai to i, and chooses an allocation based on the actions types, the notion of truth telling must be relaxed somewhat:
taken by each agent. We assume quasi-linear utility;that Deﬁnition 1. A PRM is incentive compatible (IC)—under
is, an agent i’s utility for an allocation x and payment ρi the relevant equilibrium concept—if it induces equilibrium
is ui(x,ρi,ti)=vi(x; ti) − ρi. Mechanism m induces a  strategies πi for each agent i such that ti ∈ πi(ti).
(Bayesian) game assuming probabilistic beliefs over types: In other words, an IC PRM will induce each agent to re-
each agent i adopts a strategy πi : Ti → Ai associating an port a partial type that contains its true type. In our ex-
action with its type.1                                ample, we might deﬁne the partial type space of the buyer
  The goal of mechanism design is to design m to imple- by deﬁning a set of rough bounds on the valuation for each
ment some SCF f : T → X. For instance, f may be social car, with some cars having a more precise range than others.
welfare maximization (i.e., f(t) = arg max SW (x; t)). In For instance, one partial type might assert that vb(car 1) ∈
this work, we focus on social welfare maximization or efﬁ- [17, 000, 20, 000], vb(car 2) ∈ [23, 000, 24, 000], and so on.
cient allocation. Implementation then depends on the equi- Limiting revelation to partial types of this form allows the
librium concept used; speciﬁcally, if m induces strategies πi buyer to negotiate without having to precisely determine its
for each agent in equilibrium such that O(π(t)) = f(t) for valuation for each car, but simply estimate it roughly.
all t ∈ T , we say that m implements f. Standard equilibrium Partial types may or may not be overlapping or exhaustive.
concepts lead to dominant strategy, ex post,andBayes-Nash If they are not exhaustive, incentive compatibility is not gen-
implementation.2 The revelation principle allows one to fo- erally possible. If they are overlapping, more than one truth-
cus attention on direct, incentive compatible mechanisms in ful report may be possible, and an agent can reason strategi-
which Ai = Ti and each agent will reveal his type truthfully cally to choose among them while maintaining truthfulness,
in equilibrium. In our example, this would allow restriction to something that is not possible if types do not overlap. Our
mechanisms in which we ask the car buyer and seller to report key results, speciﬁcally incentive and efﬁciency guarantees,
their complete valuation and cost functions, respectively. do not require non-overlapping types. We will, however, as-
  The Groves scheme is a famous class of mechanisms for sume in what follows that partial types are exhaustive.
quasi-linear environments (of which VCG is an instance) in In general, given a partial type vector θ, a mechanism will
which social welfare maximization is implemented in domi- not be able to determine an efﬁcient allocation x—the allo-
                                                      cation x∗(t) that maximizes social welfare for type t may be
  1Without priors, the game is in pre-Bayesian form [12] or has different for various t ∈ θ. A corollary of Roberts’ result
strict type uncertainty [13].                         is that a one-shot PRM cannot be used for dominant strategy
  2If each agent has a dominant strategy (i.e., a strategy that is implementation: unless the partitioning of each agent’s type
optimal no matter what others do) in the induced game, then we space is such that each joint partial type θ determines a unique
have dominant strategy equilibrium and implementation. An ex post maximizing x∗ for all t ∈ θ, dominant strategy implementa-
equilibrium is a vector of strategies π such that πi is optimal for i tion will not be realized (in general).
even when the types of others are known to i (assuming strategies in
                                                         3
π). A Bayes-Nash equilibrium is such that πi maximizes i’s utility In auction-like settings, this result holds for any SCF satisfying
in expectation over others’ types.                    the independence of irrelevant alternatives [15].

                                                IJCAI-07
                                                  13342.3  Related Work                                     allocations selected by the mechanism. For each x deﬁne:
                                                                          
                                                        θi
Recent research has examined methods involving limited or xi (x)=Pr(x|θi)=   Pr(θ−i|θi) · Pr[O(θiθ−i)=x]

incremental elicitation of types to circumvent the difﬁculties            θ−i
of full type revelation (especially in single-good and com-
binatorial auctions). Most work on incremental elicitation In this section, we restrict ourselves to partitions of the type
involves techniques that elicit “just enough” information to space that are “grid-based”: each parameter’s space of values
                                                      is split into a ﬁnite number of intervals of the form [lb, ub),
determine the VCG outcome fully, both allocation and pay- lb < ub
ments fully, thus maintaining incentive properties (e.g., in with . We can derive the following results:
CAs [5; 20]). Such mechanisms, being incremental, do not Theorem 1. If all valuation functions are possible, in a
ﬁt precisely into our framework, and generally allow only ex Bayes-Nash IC grid-based PRM, we have:
                                                                                     θ
post implementation; issues pertaining to approximate efﬁ-                     θi   i
                                                                  ∀i, ∀θi,θi : xi = xi =def xi         (2)
ciency are avoided altogether. Furthermore, the sequential
                                                                      ∀i, j : xi = xj                  (3)
approach is critical to avoiding full revelation. Unfortunately,
the amount of information required to fully determine the Property 2 states that, regardless of its report, agent i has
VCG outcome may be considerable [19] (and enforcing IC the same posterior xi over outcomes. Property 3 states that
over and above just implementing an SCF itself induces sig- this distribution is also the same for all agents. If the alloca-
niﬁcant cost [8]).                                    tion function is deterministic, then it selects the same alloca-
  Alternatively one can elicit enough information to deter- tion for each report vector. We call such a mechanism trivial.
mine an approximately optimal outcome, a common approach Triviality may be avoided if allocations are probabilistic, but
in single-agent elicitation [4], sacriﬁcing decision quality to even then, these properties are very restrictive:
reduce elicitation effort. We adopt this perspective here. Proposition 1. No Bayes-Nash IC grid-based PRM has
Recently, we used this approach in the design of sequen- higher expected social welfare than the trivial mechanism
tial PRMs [14], leading to approximate ex-post implementa- that always picks the allocation with highest ex ante social
tion. The one-shot mechanisms presented in this paper have welfare.
stronger incentive properties (approximate dominant imple- Proposition 2. If ex-interim (or, a fortiori ex-post) individual
mentation), and allow for more interesting payment schemes. rationality (IR) is required, the expected sum of payments of
Another class of approaches to PRMs is exempliﬁed by prior- any Bayes-Nash IC grid-based PRM is zero.
ity games [3; 2]. In these models, partial types are elicited and
exact (not approximate) dominant strategy implementation is In a sense, though partial revelation Bayes-Nash imple-
realized. However, these PRMs are designed only to deal mentation is not strictly trivial, it is useless since it achieves
with agents having one-dimensional (or “single-parameter”) the same result as a mechanism with no revelation. Given
types, for example, agents in a single-item auction where val- that an ex-post equilibrium is a vector of strategies that are in
uation for an outcome can be speciﬁed by one parameter. In- Bayes-Nash equilibrium for all possible probabilistic priors,
deed, Roberts’ result is escaped only by restricting the space the above results imply that any ex-post IC PRM is trivial.
of preferences in this severe fashion. Combinatorial auctions Note that the grid-based restriction is a sufﬁcient condition
with single-minded agents are similarly restricted [16].Un- for the above results to hold. We are currently looking into
like our model, these mechanisms do not generalize to more identifying necessary conditions. For example, we strongly
realistic valuation structures [15].                  suspect that any partitioning of type space into convex partial
                                                      types will lead to the same negative results. We do not have
  Approximate IC has been considered before from several
                                                      such results at present however.
perspectives. Nisan and Ronen [18] show that computational
approximation of VCG can destroy truth-telling, but manip-
ulation of approximate VCG can be made computationally 4  Regret-based PRMs
difﬁcult [23], thus inducing “practical” incentive compatibil- A partial revelation mechanism must choose an allocation
ity. IC in expectation or with high probability can also be x(θ) for each reported partial type θ ∈ Θ, but cannot gen-
demanded [1]. Finally, one can attempt to bound the gain an erally do so in a way that ensures efﬁciency. We propose the
agent can achieve by lying (e.g., as proposed for exchanges use of minimax regret [4; 14] to choose the allocations asso-
in [21]). It is this latter view of approximate IC that we adopt ciated with each partial type vector.
here. Our class of partial revelation mechanisms, along with Deﬁnition 2. The pairwise regret of decision x with respect
our partitioning algorithm provide the ﬁrst approach to auto- to decision xˆ over feasible type set θ is
                                    [ ]
mated partial revelation mechanism design 6 .                R(x, xˆ,θ)=maxSW(xˆ;     t) − SW(x; t),   (4)
                                                                            t∈θ
                                                       This is the most the mechanism could regret choosing x in-
3  Bayes-Nash and Ex-Post Implementation              stead of xˆ (e.g., if an adversary could impose any type vector
                                                        θ                               x
In the Bayes-Nash context, each agent has a probabilistic in ). The maximum regret of decision and the minimax
                                                      regret of feasible type set θ are respectively:
prior over the types of the others, Pr(t−i|ti). If truth-telling
                                                                   MR(x,θ)=maxR(x,       xˆ,θ)         (5)
is a Bayes-Nash equilibrium in a PRM, this deﬁnes a distri-                      xˆ
bution over the reports (partial types) of other agents; hence     MMR(   )=minMR(x        )
                                            θi                           θ               ,θ            (6)
for each of its reports θi, agent i has a distribution, xi , over                x

                                                IJCAI-07
                                                  1335  A minimax-optimal decision for θ, denoted x∗(θ),isany Theorem 2. Let m be a regret-based partial revelation mech-
allocation that minimizes Eq. 6. Without distributional infor- anism with partial type space Θ and partial Groves payment
                                                                         ∗
mation over the set of possible utility functions, choosing (or functions pi.IfMR(x (θ),θ) ≤ ε for each θ ∈ Θ,thenm is
recommending) a minimax-optimal decision x∗ minimizes ε-efﬁcient and ε-dominant IC.
the worst case loss in efﬁciency with respect to possible real- In other words, truth telling is an ε-dominant strategy equi-
izations of the types t ∈ θ. We refer to the regret maximizing                                        ε
x                        x                            librium (i.e., truth telling for any agent has utility within of
ˆ in Eq. (6) as the witness for .                     optimal regardless of the reports of others).
  Recent approaches to minimax regret optimization have We can specialize partial Groves payments to partial
shown it to be practical when utility models are factored into Clarke payments:
a convenient functional form such as generalized additive in- ∗        ∗                      ∗
dependence (GAI) [9], and utility uncertainty is expressed in pi(θ−i, x )=SW(x−i(θ−i); fi(θ−i)) − SW−i(x ; fi(θ−i))
the form of linear constraints on such factored models [4].In ∗
                                                       where x  :Θ−i  → X  is an arbitrary function that chooses
this setting, minimax regret optimization can be formulated   −i
                                                      an allocation based only the reports of agents other than i.
as a linear, mixed-integer program (MIP) with exponentially
                                                      This restriction allows the following IR guarantee:
many constraints, but can be solved using an iterative con-
straint generation procedure that, in practice, enumerates only Theorem 3. Let m be a regret-based partial revelation mech-
a small number of (active) constraints [4].           anism with partial type space Θ and partial Clarke payments
                                                                ∗
                                                      pi.IfMR(x  (θ),θ) ≤ ε for each θ ∈ Θ,thenm is ε-efﬁcient,
Deﬁnition 3. A regret-based partial revelation mechanism is ε                ε
any mechanism in which the allocation function chooses an -dominant IC and ex-post -IR.
outcome that minimizes max regret given the revealed partial In other words, no agent has incentive greater than ε not to
type vector; that is, O(θ)=x∗(θ) for all θ ∈ Θ.       participate in the mechanism.
  Assume we have a PRM m  in which each agent declares  We have provided some intuitive justiﬁcation above for the
a partial type θi ∈ Θi,andthatm is regret-based, i.e., O use of minimax regret to determine the allocation associated
chooses x∗(θ) with minimax regret w.r.t. social welfare for with any revealed partial type proﬁle. We can also provide
any declared type vector θ:                           formal justiﬁcation for the use of minimax regret with respect
                  m                                   to incentive properties of PRMs. Speciﬁcally, under the par-
Observation 1. Let  be a regret-based partial revelation tial Groves and Clarke payment schemes, worst-case manip-
mechanism with partial type space Θ.IfMR(x∗(θ),θ) ≤ ε
       θ ∈       m    ε                               ulability (over possible type proﬁles) is exactly equal to the
for each   Θ,then   is -efﬁcient for truth-telling agents. greatest minimax regret-level (again, over possible type pro-
  This simply formalizes the obvious fact that since max re- ﬁles). Thus one can show:
gret for any mechanism choice is bounded by ε,thenifall
                                                      Proposition 3. Let be a ﬁxed partial type space, and M
agents reveal their partial types truthfully we are assured to         Θ
                                                      a regret-based PRM (w.r.t. Θ) using the partial Clarke pay-
be within ε of maximizing social welfare.                                          
                                                      ment scheme. Any other PRM M  (w.r.t. ) using the par-
  With PRMs we cannot generally guarantee efﬁciency: dif-                                 Θ
                                                      tial Clarke scheme, will have worst-case manipulability, efﬁ-
ferent type proﬁles within a partial type vector θ may require
                                                      ciency loss and rationality violation at least as great as that of
a different allocation choice to maximize social welfare. As
                                                      M. There exist non-regret-based PRMs where this inequality
a consequence, the result of Roberts means we will be unable
                                                      is strict.
to implement our “approximate” choice function in dominant
strategies. Instead, we relax the implementation concept in In other words, no non-regret based scheme can perform
a natural fashion and derive a payment scheme that ensures better than a regret-based scheme with respect to efﬁciency
approximate IR and IC in dominant strategies.         loss (obviously), gain from misreporting one’s partial type,
  Consider the following generalization of Groves payments. and incentive for non-participation. The analog of this propo-
Given joint report θ =(θi,θ−i) of all agents, and the corre- sition holds regarding manipulability and efﬁciency when us-
sponding choice x∗, agent i’s payment is:             ing the partial Groves payment scheme.
               ∗                    ∗                   Even with the “Clarke-style” restriction above, our pay-
 pi(θ)=pi(θ−i, x )=hi(θ−i) − SW−i(x  ; fi(θ−i))                                  ∗
                                                      ment scheme is quite general: x−i and fi are arbitrary func-
where hi :Θ−i → R is an arbitrary function and fi :Θ−i → tions. The choice of these will not affect the worst-case prop-
Ti is any function that, given partial type vector θ−i, selects a erties above, but it can be used to: (a) reduce the likelihood
type vector t−i from that set (i.e., fi(θ−i) ∈ θ−i).  (if any) of a rationality violation; and/or (b) maximize rev-
  Recall that under full revelation, fi(θ−i) is the complete enue of the mechanism. If reducing or removing a rationality
type vector t−i reported by the other agents and hi must take violation implies revenue loss, then a trade-off can be made
that particular t−i as an argument. Our partial Groves pay- between the two criteria. An attractive feature of our PRMs
ment scheme, however, can select an arbitrary type for each is the considerable scope for optimization of the payment
agent consistent with their declared partial types and apply scheme due to the nature of the partial type revelation.
standard Groves payments (Eq. 1) to these. The selected types When dealing with approximate incentive properties, one
can differ for each payment function pi, and the arbitrary hi must be aware that a small deviation from the truth by one
functions also depend only on the partial types revealed. Par- agent can cause major changes in the mechanism’s alloca-
tial Groves payments can thus require signiﬁcantly less reve- tion (leading, say, to large losses in efﬁciency). But with par-
lation. Together with regret-based allocation, they give: tial Groves payments, an agent can gain at most ε compared

                                                IJCAI-07
                                                  1336                                                                           (θ1,...θi,...θn)
to revealing its partial type truthfully. In most settings, the              node 1
computational cost of ﬁnding a good lie, especially given the

considerable uncertainty in the value of any lie (due to un-     (θ'1,...θi,...θn)   (θ''1,...θi,...θn)
certainty about others’ types), will be substantial (see, e.g.,    node 2               node 3
[23]). Thus, if ε is small enough, it will not be worth the cost:
our formal, approximate incentive compatibility is sufﬁcient
to ensure practical, exact incentive compatibility.
                                                           (θ'1,...θ'i,...θn) (θ'1,...θ''i,...θn) (θ''1,...θ'i,...θn) (θ''1,...θ''i,...θn)
  To develop a sense of the difﬁculty associated with manip-  node 4    node 5     node 6    node 7
ulating such a mechanism, consider that an agent must be able
to compute an untruthful strategy (or lie) with greater utility Figure 1: Example of a mechanism tree.
than truth-telling in order to exploit our approximate incen- 5.1 Partial Type Optimization Algorithm
tive guarantee. To do this one must ﬁrst determine the true
value of a lie (incurring the valuation or cognitive costs sim- We describe an ofﬂine, iterative, myopic approach to the op-
ilar to revealing truthfully). However evaluating a lie also timization of agent type space partitions. It is myopic in the
requires considerable (and accurate) information about the following two senses: (a) at each step, it focuses on reducing
types and strategies of the others; even with decent priors, the minimax regret of the joint partial type with greatest regret
the costliness of such computations (e.g., in time, cognitive, by reﬁning (or splitting) it, without considering the impact on
or computational resources) implies that manipulation is not other partial types; and (b) it only considers the immediate
worthwhile unless the bound ε is quite loose, and incentive effects of this reﬁnement, with no look-ahead to future splits.
compatibility will thus, in practice, be exact.         To simplify the presentation, we ﬁrst describe a naive, com-
  A similar argument can be made regarding approximate putationally intensive method, formulated in terms of deci-
IR: determining whether you gain from not participating will sion tree construction, and then show how it can be modiﬁed
be very difﬁcult. Thus a potential small loss will be worth- to be made much more tractable. The algorithm uses a heuris-
while for an agent given the savings our mechanism provides tic function which, given a partial type vector, selects an agent
in revelation and computational costs (relative to the full rev- whose partial type will be split. It is important to realize that
elation alternative). Finally, given the complexity of many these splits are not “queries” to the agent—the mechanism is
mechanism design settings, when cognitive, computational not sequential. Rather, splitting a partial type further will in-
and communication costs are accounted for, the potential loss crease the number of partial types from which an agent must
in efﬁciency will be an acceptable trade-off, given the high choose when the mechanism is actually executed. Once all
level of revelation required by exactly efﬁcient mechanisms. splits to all agents are determined, the mechanism will ask
                                                      agents to select from the partial types induced by this reﬁne-
                                                      ment process. In other words, ofﬂine we construct the par-
                                                      tial types used by the one-shot mechanism. We discuss the
5  Construction of Partial Types                      heuristic function further below.
                                                        Figure 5.1 illustrates the creation of partial types for a PRM
So far we have focused on the design of regret-based PRMs in terms of decision tree construction. At the outset, the only
with a ﬁxed collection of partial types. However, the se- information available to the mechanism is the set of possible
lection of partial types is critical to the performance guar- types for each agent given by our prior, deﬁning the initial
antees above, since it is these types that determine the de- partial type vector (θ1,...,θn) with θi = Ti. This labels the
gree of regret incurred by the mechanism. The key design initial (root) node of our tree (node 1). We call the heuris-
issue is the construction of a suitable set of partial types that tic function on this vector, which selects an agent, say agent
minimizes both revelation and the maximum minimax regret 1, and a split of that agent’s partial type θ1 into two more
    ε                                                                         
(i.e., ) over that set. We describe a heuristic, but reason- reﬁned partial types θ1 and θ1 . The reasons for choosing a
ably tractable, approach to the automated optimization of the particular split are elaborated below, but intuitively, such a
type space partitioning. Although the class of mechanisms split should have a positive impact with respect to max regret
is ﬁxed and it is the partition that is being optimized by our reduction of the mechanism. This creates two child nodes
                                                                                       
algorithm, together these constitutes a tractable approach to corresponding to partial type vectors (θ1,...,θi,...,θn) and
                                                        
automated partial revelation mechanism design.        (θ1 ,...,θi,...,θn) (see nodes 2 and 3 in Figure 5.1). These
  In what follows, we assume an agent type is simply a two new leaves in the tree correspond to the partial type vec-
bounded n-vector with valuations for each allocation x ∈ X. tors to be used by the mechanism should the splitting process
When dealing with a multi-attribute outcome space, we al- terminate at this point. Thus, we update the partial type space
                                                                                               
low for an agent’s type/utility function to be factored us- Θi for agent 1 by removing θ1 and adding θ1 and θ1 .Wethen
ing a generalized additive independence representation [9], compute the minimax regret level, optimal allocation and wit-
in which utility parameterized with local sub-utility functions ness (in a single optimization) for these two new leaf nodes
over small sets of attributes. In a ﬂat (un-factored) model, the given their partial type vectors.
parameters are simply the valuations for allocations x.We With multiple leaves, the heuristic function must ﬁrst select
assume in what follows that the type space Ti is given by up- a leaf node for splitting before selecting a split. It does this by
per and lower bounds over the parameters of agent i’s utility selecting the partial type vector (leaf node) with greatest min-
model and focus on partial types speciﬁed similarly.  imax regret. The algorithm iterates in this fashion, repeatedly

                                                IJCAI-07
                                                  1337