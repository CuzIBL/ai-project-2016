  Characterizing Solution Concepts in Games Using Knowledge-Based Programs


                   Joseph Y. Halpern∗                               Yoram Moses
              Computer Science Department               Department of Electrical Engineering
                 Cornell University, U.S.A.           Technion—Israel Institute of Technology
              e-mail: halpern@cs.cornell.edu                     32000 Haifa, Israel
                                                           email: moses@ee.technion.ac.il

                    Abstract                                                   x 0

    We show how solution concepts in games such as                       .5        .5
    Nash equilibrium, correlated equilibrium, rational-
                                                             z     S  x               xzS       1
    izability, and sequential equilibrium can be given        0        1               2
    a uniform deﬁnition in terms of knowledge-based          2                                   2
    programs. Intuitively, all solution concepts are im-
    plementations of two knowledge-based programs,
                                                                     B                  B
    one appropriate for games represented in normal
    form, the other for games represented in extensive
    form. These knowledge-based programs can be                      x 3                x4
    viewed as embodying rationality. The representa-
                                                                   L        R    L         R
    tion works even if (a) information sets do not cap-
    ture an agent’s knowledge, (b) uncertainty is not           zz2        3       z 4      z 5
    represented by probability, or (c) the underlying              346          2
    game is not common knowledge.
                                                                Figure 1: A game of imperfect recall.
1  Introduction
                                                      a payoff of 2, or continue, by playing move B. If he contin-
Game theorists represent games in two standard ways: in ues, he gets a high payoff if he matches nature’s move, and a
normal form, where each agent simply chooses a strategy, low payoff otherwise. Although he originally knows nature’s
and in extensive form, using game trees, where the agents move, the information set that includes the nodes labeled x3
make choices over time. An extensive-form representation and x4 is intended to indicate that the player forgets whether
has the advantage that it describes the dynamic structure of nature moved left or right after moving B. Intuitively, when
the game—it explicitly represents the sequence of decision he is at the information set X, the agent is not supposed to
problems encountered by agents. However, the extensive- know whether he is at x3 or at x4.
form representation purports to do more than just describe It is not hard to show that the strategy that maximizes ex-
the structure of the game; it also attempts to represent the pected utility chooses action S at node x1, action B at node
information that players have in the game, by the use of in- x2, and action R at the information set X consisting of x3
                                                                                   
formation sets. Intuitively, an information set consists of a and x4. Call this strategy f.Letf be the strategy of choos-
set of nodes in the game tree where a player has the same ing action B at x1, action S at x2,andL at X. Piccione and
                              [    ]
information. However, as Halpern 1997 has pointed out, Rubinstein argue that if node x1 is reached, the player should
information sets may not adequately represent a player’s in- reconsider, and decide to switch from f to f .AsHalpern
formation.                                            points out, this is indeed true, provided that the player knows
  Halpern makes this point by considering the following at each stage of the game what strategy he is currently using.
single-agent game of imperfect recall, originally presented by However, in that case, if the player is using f at the infor-
                     [   ]
Piccione and Rubinstein 1997 : The game starts with nature mation set, then he knows that he is at node x4;ifhehas
                                           /                              
moving either left or right, each with probability 1 2.The switched and is using f , then he knows that he is at x3.So,
                                          S
agent can then either stop the game (playing move ) and get in this setting, it is no longer the case that the player does not
  ∗                                                   know whether he is at x3 or x4 in the information set; he can
   Supported in part by NSF under grants CTC-0208535 and ITR-
0325453, by ONR under grant N00014-02-1-0455, by the DoD infer which state he is at from the strategy he is using.
Multidisciplinary University Research Initiative (MURI) program In game theory, a strategy is taken to be a function from in-
administered by the ONR under grants N00014-01-1-0795 and formation sets to actions. The intuition behind this is that,
N00014-04-1-0725, and by AFOSR under grant F49620-02-1-0101. since an agent cannot tell the nodes in an information set

                                                IJCAI-07
                                                  1300apart, he must do the same thing at all these nodes. But this express with the formula doi(S)), and she believes that she
example shows that if the agent has imperfect recall but can would not do any better with another strategy, then she should
switch strategies, then he can arrange to do different things indeed go ahead and run S. This test can be viewed as em-
at different nodes in the same information set. As Halpern bodying rationality. There is a subtlety in expressing the
[1997] observes, ‘ “situations that [an agent] cannot distin- statement “she would not do any better with another strat-
guish” and “nodes in the same information set” may be two egy”. We express this by saying “if her expected utility, given
quite different notions.’ He suggests using the game tree to that she will use strategy S,isx, then her expected utility if
describe the structure of the game, and using the runs and sys- she were to use strategy S is at most x.” The “if she were
tems framework [Fagin et al., 1995] to describe the agent’s to use S”isacounterfactual statement. She is planning
information. The idea is that an agent has an internal local to use strategy S, but is contemplating what would happen
state that describes all the information that he has. A strat- if she were to do something counter to fact, namely, to use
egy (or protocol in the language of [Fagin et al., 1995])isa S. Counterfactuals have been the subject of intense study
function from local states to actions. Protocols capture the in the philosophy literature (see, for example, [Lewis, 1973;
intuition that what an agent does can depend only what he Stalnaker, 1968]) and, more recently, in the game theory lit-
knows. But now an agent’s knowledge is represented by its erature (see, for example, [Aumann, 1995; Halpern, 2001;
local state, not by an information set. Different assumptions Samet, 1996]). We write the counterfactual “If A were the
about what agents know (for example, whether they know case then B would be true” as “A  B”. Although this state-
their current strategies) are captured by running the same pro- ment involves an “if . . . then”, the semantics of the counter-
tocol in different contexts. If the information sets appropri- factual implication A  B is quite different from the material
ately represent an agent’s knowledge in a game, then we can implication A ⇒ B. In particular, while A ⇒ B is true if A
identify local states with information sets. But, as the exam- is false, A  B might not be.
ple above shows, we cannot do this in general.          With this background, consider the following kb program
  A number of solution concepts have been considered in the for player i:
game-theory literature, ranging from Nash equilibrium and for each strategy S ∈Si(Γ) do
correlated equilibrium to reﬁnements of Nash equilibrium     if Bi(doi(S) ∧∀x(EUi = x ⇒
such as sequential equilibrium and weaker notions such as                    
                                                                S∈S (Γ)(doi(S )  (EUi ≤ x)))) then S.
rationalizability (see [Osborne and Rubinstein, 1994] for an        i
overview). The fact that game trees represent both the game This kb program is meant to capture the intuition above. In-
                                                                                i
and the players’ information has proved critical in deﬁning tuitively, it says that if player believes that she is about to
                                                                     S                           x
solution concepts in extensive-form games. Can we still rep- perform strategy and, if her expected utility is ,thenif
                                                                                      S
resent solution concepts in a useful way using runs and sys- she were to perform another strategy , then her expected
                                                      utility would be no greater than x, then she should perform
tems to represent a player’s information? As we show here,                                Γ
not only can we do this, but we can do it in a way that gives strategy S. Call this kb program EQNF (with the indi-
                                                                                               Γ
deeper insight into solution concepts. Indeed, all the standard vidual instance for player i denoted by EQNFi ). As we
                                                                                   Γ
solution concepts in the literature can be understood as in- show, if all players follow EQNF , then they end up play-
stances of a single knowledge-based (kb) program [Fagin et ing some type of equilibrium. Which type of equilibrium they
al., 1995; 1997], which captures the underlying intuition that play depends on the context. Due to space considerations,
a player should make a best response, given her beliefs. The we focus on three examples in this abstract. If the players
differences between solution concepts arise from running the have a common prior on the joint strategies being used, and
kb program in different contexts.                     this common prior is such that players’ beliefs are indepen-
  In a kb program, a player’s actions depend explicitly on dent of the strategies they use, then they play a Nash equilib-
the player’s knowledge. For example, a kb program could rium. Without this independence assumption, we get a cor-
have a test that says “If you don’t know that Ann received the related equilibrium. On the other hand, if players have pos-
information, then send her a message”, which can be written sibly different priors on the space of strategies, then this kb
                                                      program deﬁnes rationalizable strategies [Bernheim, 1984;
   if ¬Bi(Ann received info) then send Ann a message.
                                                      Pearce, 1984].
This kb program has the form of a standard if ...then state- To deal with extensive-form games, we need a slightly dif-
ment, except that the test in the if clause is a test on i’s knowl- ferent kb program, since agents choose moves, not strategies.
                                                                Γ
edge (expressed using the modal operator Bi for belief; see Let EQEFi be the following program, where a ∈ PM de-
Section 2 for a discussion of the use of knowledge vs. belief). notes that a is a move that is currently possible.
  Using such tests for knowledge allows us to abstract away for each move a ∈ PM do
from low-level details of how the knowledge is obtained. Kb
                                                              if Bi(doi(a) ∧∀x((EUi = x) ⇒
programs have been applied to a number of problems in the                   
                                                                      (doi(a )  (EUi ≤ x)))) then a.
                           [               ]                     a ∈PM
computer science literature (see Fagin et al., 1995 and the        Γ
references therein). To see how they can be applied to under- Just as EQNF characterizes equilibria of a game Γ repre-
                                                                                 Γ
stand equilibrium, given a game Γ in normal form, let Si(Γ) sented in normal form, EQEF characterizes equilibria of
consist of all the pure strategies for player i in Γ. Roughly a game represented in extensive form. We give one example
speaking, we want a kb program that says that if player i here: sequential equilibrium. To capture sequential equilib-
believes that she is about to perform strategy S (which we rium, we need to assume that information sets do correctly

                                                IJCAI-07
                                                  1301describe an agent’s knowledge. If we drop this assumption, i cannot tell apart, player i must do the same thing. A joint
                                                             
however, we can distinguish between the two equilibria for strategy S =(S1,...,Sn) for the players determines a distri-
the game described in Figure 1.                       bution over paths in the game tree. A normal-form game can
  All these solution concepts are based on expected utility. be viewed as a special case of an extensive-form game where
But we can also consider solution concepts based on other each player makes only one move, and all players move si-
decision rules. For example, Boutilier and Hyaﬁl [2004] multaneously.
consider minimax-regret equilibria, where each player uses
a strategy that is a best-response in a minimax-regret sense to 2.2 Protocols, Systems, and Contexts
the choices of the other players. Similarly, we can use max- To explain kb programs, we must ﬁrst describe standard pro-
imin equilibria [Aghassi and Bertsimas, 2006]. As pointed tocols. We assume that, at any given point in time, a player in
out by Chu and Halpern [2003], all these decision rules can agameisinsomelocal state. The local state could include
be viewed as instances of a generalized notion of expected the history of the game up to this point, the strategy being
utility, where uncertainty is represented by a plausibility mea- used by the player, and perhaps some other features of the
sure, a generalization of a probability measure, utilities are player’s type, such as beliefs about the strategies being used
elements of an arbitrary partially ordered space, and plausi-
                                 ⊕     ⊗              by other players. A global state is a tuple consisting of a local
bilities and utilities are combined using and , generaliza- state for each player.
tions of + and ×. We show in the full paper that, just by inter-            i                       i
              u                                         A  protocol for player is a function from player ’s lo-
preting “EUi = ” appropriately, we can capture these more cal states to actions. For ease of exposition, we consider
exotic solution concepts as well. Moreover, we can capture only deterministic protocols, although it is relatively straight-
solution concepts in games where the game itself is not com- forward to model randomized protocols—corresponding to
mon knowledge, or where agents are not aware of all moves mixed strategies—as functions from local states to distribu-
                                     [    ]
available, as discussed by Halpern and Rˆego 2006 .   tions over actions. Although we restrict to deterministic pro-
  Our approach thus provides a powerful tool for represent- tocols, we deal with mixed strategies by considering distrib-
ing solution concepts, which works even if (a) information utions over pure strategies.
sets do not capture an agent’s knowledge, (b) uncertainty is A run is a sequence of global states; formally, a run is
not represented by probability, or (c) the underlying game is a function from times to global states. Thus, r(m) is the
not common knowledge.                                 global state in run r at time m.Apoint is a pair (r, m)
  The rest of this paper is organized as follows. In Sec-
                                                      consisting of a run r and time m.Letri(m) be i’s local
tion 2, we review the relevant background on game theory
                                                      state at the point (r, m);thatis,ifr(m)=(s1,...,sn),then
and knowledge-based programs. In Section 3, we show that r m  s
      Γ            Γ                                   i( )=   i.Ajoint protocol is an assignment of a protocol
EQNF    and EQEF    characterize Nash equilibrium, cor- for each player; essentially, a joint protocol is a joint strat-
related equilibrium, rationalizability, and sequential equilib- egy. At each point, a joint protocol P performs a joint ac-
rium in a game Γ in the appropriate contexts. We conclude
                                                      tion (P1(r1(m)),...,Pn(rn(m))), which changes the global
in Section 4 with a discussion of how our results compare to                                           P
other characterizations of solution concepts.         state. Thus, given an initial global state, a joint protocol
                                                      generates a (unique) run, which can be thought of as an ex-
                                                      ecution of P . The runs in a normal-form game involve only
2  Background                                         one round and two time steps: time 0 (the initial state) and
In this section, we review the relevant background on games time 1, after the joint strategy has been executed. (We as-
and knowledge-based programs. We describe only what we sume that the payoff is then represented in the player’s local
need for proving our results. The reader is encouraged to con- state at time 1.) In an extensive-form game, a run is again
sult [Osborne and Rubinstein, 1994] for more on game the- characterized by the strategies used, but now the length of the
ory, [Fagin et al., 1995; 1997] for more on knowledge-based run depends on the path of play.
programs without counterfactuals, and [Halpern and Moses, A probabilistic system is a tuple PS =(R,μ),whereR is
2004] for more on adding counterfactuals to knowledge- a set of runs and μ =(μ1,...,μn) associates a probablity μi
based programs.                                       on the runs of R with each player i. Intuitively, μi represents
                                                      player i’s prior beliefs. In the special case where μ1 = ···=
2.1  Games and Strategies                             μn =  μ, the players have a common prior μ on R.Inthis
Agameinextensive form is described by a game tree. Asso- case, we write just (R,μ).
ciated with each non-leaf node or history is either a player— We are interested in the system corresponding to a joint
                                                              
the player whose move it is at that node—or nature (which protocol P. To determine this system, we need to describe the
can make a randomized move). The nodes where a player i setting in which P is being executed. For our purposes, this
moves are further partitioned into information sets. With each setting can be modeled by a set G of global states, a subset G0
run or maximal history h in the game tree and player i we can of G that describes the possible initial global states, a set As
associate i’s utility, denoted ui(h), if that run is played. A of possible joint actions at each global state s,andn probabil-
strategy for player i is a (possibly randomized) function from ity measures on G0, one for each player. Thus, a probabilistic
i                                                 i                                              1
’s information sets to actions. Thus a strategy for player context is a tuple γ =(G, G0, {As : s ∈G},μ). A joint
tells player i what to do at each node in the game tree where
i is supposed to move. Intuitively, at all the nodes that player 1We are implicitly assuming that the global state that results from

                                                IJCAI-07
                                                  1302protocol P is appropriate for such a context γ if, for every 2.3 Knowledge-Based Programs
                             
global state s, the joint actions that P can generate are in As. A knowledge-based program is a syntactic object. For our
When P is appropriate for γ, we abuse notation slightly and purposes, we can take a knowledge-based program for player
                                                     i
refer to γ by specifying only the pair (G0,μ). A protocol P to have the form
and a context γ for which P is appropriate generate a sys-              if κ1 then a1
tem; the system depends on the initial states and probability            if κ2 then a2
measures in γ. Since these are all that matter, we typically             ...,
                                               G
simplify the description of a context by omitting the set of where each κj is a Boolean combination of formulas of the
                                              
global states and the sets As of global actions. Let R(P,γ) form Biϕ,inwhichtheϕ’s can have nested occurrences of B
denote the system generated by joint protocol P in context γ. operators and counterfactual implications. We assume that
                                                           κ  ,κ ,...
If γ =(G0,μ),thenR(P,γ)=(R,μ  ),whereR  consists of the tests 1 2   are mutually exclusive and exhaustive, so
        r                  s ∈G        r             that exactly one will evaluate to true in any given instance.
atherun  s for each initial state 0,where s is the run                Γ
                                                               EQNF
generated by P when started in state s,andμ (rs)=μi(s), The program  i can be written in this form by simply
                                      i                          for ... do
for i =1,...,n.                                       replacing the         statement by one line for each pure
                                                                                      Γ
  A probabilistic system (R,μ ) is compatible with a con- strategy in Si(Γ); similarly for EQEFi .
text γ =(G0,μ) if (a) every initial state in G0 is the initial We want to associate a protocol with a kb program. Unfor-
stateofsomeruninR, (b) every run is the run of some pro- tunately, we cannot “execute” a kb program as we can a pro-
tocol appropriate for γ,and(c)ifR(s) is the set of runs in tocol. How the kb program executes depends on the outcome
                                                           κ
R with initial global state s,thenμj(R(s)) = μj(s),for of tests j. Since the tests involve beliefs and counterfactuals,
                                                      we need to interpret them with respect to a system. The idea
j =1,...,n. Clearly R(P,γ ) is compatible with γ.
                                                      is that a kb program Pg for player i and a probabilistic sys-
  We can think of the context as describing background in-                i
                                                      tem PS together determine a protocol P for player i.Rather
formation. In distributed-systems applications, the context
                                                      than giving the general deﬁnitions (which can be found in
also typically includes information about message delivery.
                                                      [Halpern and Moses, 2004]), we just show how they work in
For example, it may determine whether all messages sent are
                                                      the two kb programs we consider in this paper: EQNF and
received in one round, or whether they may take up to, say,
                                                      EQEF.
ﬁve rounds. Moreover, when this is not obvious, the context
                                                        Given a system PS =(R,μ), we associate with each for-
speciﬁes how actions transform the global state; for exam-
                                                      mula ϕ aset[[ ϕ]] PS of points in PS. Intuitively, [[ ϕ]] PS is the
ple, it describes what happens if in the same joint action two
                                                      set of points of PS where the formula ϕ is true. We need a
players attempt to modify the same memory cell. Since such
                                                      little notation:
issues do not arise in the games we consider, we ignore these
facets of contexts here. For simplicity, we consider only con- • If E is a set of points in PS,letR(E) denote the set
texts where each initial state corresponds to a particular joint of runs going through points in E;thatisR(E)={r :
                    Γ                                     ∃m   r, m ∈ E }
strategy of Γ.Thatis,Σi is a set of local states for player i ((  )    ) .
                                Γ
indexed by (pure) strategies. The set Σi can be viewed as de- • Let Ki(r, m) denote the set of points that i cannot dis-
                                                                                                  
scribing i’s types; the state sS can the thought of as the initial tinguish from (r, m): Ki(r, m)={(r ,m):(ri(m )=
state where player i’s type is such that he plays S (although ri(m)}. Roughly speaking, Ki(r, m) corresponds to i’s
we stress that this is only intuition; player i does not have to information set at the point (r, m).
                        Γ    Γ         Γ
play S at the state sS). Let G =Σ × ...× Σn. We will be
                        0    1                          • Given a point (r, m) and a player i,letμ(i,r,m) be the
interested in contexts where the set of initial global states is a                                    i
           Γ                                              probability measure that results from conditioning μ on
subset G0 of G0 . In a normal-form game, the only actions pos-
                                                          Ki(r, m), i’s information at (r, m). We cannot condi-
sible for player i at an initial global state amount to choosing                   i
                                                          tion on Ki r, m directly: μ is a probability measure
a pure strategy, so the joint actions are joint strategies; no ac- (    )
                                                          on runs, and Ki(r, m) is a set of points. So we actu-
tions are possible at later times. For an extensive-form game,
                                                          ally condition, not on Ki r, m , but on R Ki r, m ,the
the possible moves are described by the game tree. We say                      (   )        (  (    ))
                                                          set of runs going through the points in Ki(r, m). Thus,
that a context for an extensive-form game is standard if the       i
                                                          μi,r,m = μ |R(Ki(r, m)). (For the purposes of this ab-
local states have the form (s, I),wheres is the initial state
                                                          stract, we do not specify μi,r,m if μi R Ki r, m .
and I is the current information set. In a standard context,                            ( (   (   ))) = 0
                                                          It turns out not to be relevant to our discussion.)
an agent’s knowledge is indeed described by the information
set. However, we do not require a context to be standard. The kb programs we consider in this paper use a limited
For example, if an agent is allowed to switch strategies, then collection of formulas. We now can deﬁne [[ ϕ]] PS for the
the local state could include the history of strategies used. In formulas we consider that do not involve counterfactuals.
such a context, the agent in the game of Figure 1 would know • In a system PS corresponding to a normal-form game
more than just what is in the information set, and would want Γ,ifS ∈Si(Γ),then[[ doi(S)]]PS is the set of initial
to switch strategies.                                     points (r, 0) such that player i uses strategy S in run r.
                                                        •            PS
performing a joint action in As at the global state s is unique and ob- Similarly, if corresponds to an extensive-form game,
vious; otherwise, such information would also appear in the context, then [[ doi(a)]]PS is the set of points (r, m) of PS at
as in the general framework of [Fagin et al., 1995].      which i performs action a.

                                                IJCAI-07
                                                  1303  • Player i believes a formula ϕ at a point (r, m) if the evaluate formulas only with respect to complete systems. In
    event corresponding to formula ϕ has probability 1 ac- a complete system PS,wedeﬁne[[ doi(S)  ϕ]] PS to consist
                                                                                                  
    cording to μi,r,m.Thatis,(r, m)  ∈  [[ Biϕ]] PS if of all the points (r, m) such that the closest point (r ,m) to
    μi(R(Ki(r, m)) =0 (so that conditioning on Ki(r, m) (r, m) where i uses strategy S is in [[ ϕ]] PS. The deﬁnition
    is deﬁned) and μi,r,m([[ϕ]] PS ∩Ki(r, m)) = 1.    of [[ doi(a)  ϕ]] PS is similar. We say that a complete sys-
                                                           R,μ        R,μ   μ     μ        R
  •              r                                    tem (     ) extends (  ) if j and j agree on (so that
    With every run in the systems we consider, we can as- 
                                                      μ (A)=μj(A))forallA   ⊆R)forj   =1,...,n.
    sociate the joint (pure) strategy S used in r.2 This pure j
                                                        Since each formula κ that appears as a test in a kb program
    strategy determines the history in the game, and thus de-
                                                      Pgi for player i is a Boolean combination of formulas of the
    termines player i’s utility. Thus, we can associate with
                                                      form Biϕ, it is easy to check that if (r, m) ∈ [[ κ]] PS,then
    every point (r, m) player i’s expected utility at (r, m),
                                                      Ki(r, m) ⊆ [[ κ]] PS. In other words, the truth of κ depends
    where the expectation is taken with respect to the prob-
                                                      only on i’s local state. Moreover, since the tests are mutually
    ability μi,r,m.Ifu is a real number, then [[ E U i = u]] PS
                               i                 u    exclusive and exhaustive, exactly one of them holds in each
    is the set of points where player ’s expected utility is ;                PS                      PS
    [[ E U i ≤ u]] PS is deﬁned similarly.            local state. Given a system , we take the protocol Pgi
                                                                     PS                       r, m   PS
  •             ϕ x                       ∀           to be such that Pgi ( )=aj if, for some point ( ) in
    Assume that  ( ) has no occurrences of .Then      with ri(m)=,wehave(r, m)   ∈ [[ κj]] PS.Sinceκ1,κ2,...
    [[ ∀xϕ(x))]]PS = ∩a∈IR[[ ϕ[x/a]]]PS,whereϕ[x/a] is
                                       x    ϕ    a    are mutually exclusive and exhaustive, there is exactly one
    the result of replacing all occurrences of in by . action aj with this property.
    That is, ∀x is just universal quantiﬁcation over x,where
    x                                                   We are mainly interested in protocols that implement a kb
      ranges over the reals. This quantiﬁcation arises for us                           P
         x                       ∀xϕ x                program. Intuitively, a joint protocol implements a kb
    when   represents a utility, so that ( ) is saying that                  
    ϕ                                                 program Pg in context γ if P performs the same actions as
      holds for all choices of utility.                
                                                      Pg in all runs of P that have positive probability, assuming
  We now give the semantics of formulas involving coun-                        
                                                      that the knowledge tests in Pg are interpreted with respect
terfactuals. Here we consider only a restricted class of such                              
formulas, those where the counterfactual only occurs in the to the complete system PS extending R(P,γ). Formally,
                                                                    
form doi(S)  ϕ, which should be read as “if i were to use a joint protocol P (de facto) implements a joint kb program
       S      ϕ                           S   ϕ       
strategy ,then  would be true. Intuitively, doi( ) is Pg [Halpern and Moses, 2004] in a context γ =(G0,μ) if
true at a point r, m if ϕ holds in a world that differs from    PS
            (    )                                    Pi()=Pgi    () for every local state  = ri(m) such that
(r, m) only in that i uses the strategy S.Thatis,doi(S)  ϕ  
                                                     r ∈ R(P,γ)  and μi(r) =0 ,wherePS is the complete sys-
is true at (r, m) if ϕ is true at the point (r ,m) where, in
                                                                  R  P,γ
run r ,playeri uses strategy S and all the other players tem extending ( ). We remark that, in general, there
use the same strategy that they do at (r, m). (This can be may not be any joint protocols that implement a kb program
viewed as an instance of the general semantics for coun- in a given context, there may be exactly one, or there may be
terfactuals used in the philosophy literature [Lewis, 1973; more than one (see [Fagin et al., 1995] for examples). This
Stalnaker, 1968] where ψ  ϕ is taken to be true at a world is somewhat analogous to the fact that there may not be any
w if ϕ is true at all the worlds w closest to w where ψ is equilibrium of a game for some notions of equilibrium, there
true.) Of course, if i actually uses strategy S in run r,then may be one, or there may be more than one.
r = r. Similarly, in an extensive-form game Γ, the closest
                                            
point to (r, m) where doi(a ) is true (assuming that a is an 3 The Main Results
action that i can perform in the local state ri(m)) is the point                    P nf
                                                     Fix a game Γ in normal form. Let i be the protocol that,
(r ,m) where all players other than player i use the same pro-             Γ                        nf
                                                    in initial state sS ∈ Σ , chooses strategy S;letP =
tocol in r and r,andi’s protocol in r agrees with i’s protocol             i
                                                       P nf ,...,Pnf
in r except at the local state ri(m),wherei performs action ( 1 n  ).LetSTRATi    be the random variable on
                                                                                                      s
a . Thus, r is the run that results from player i making a sin- initial global states that associates with an initial global state
                                                           i           r
gle deviation (to a at time m) from the protocol she uses in player ’s strategy in . As we said, Nash equilibrium arises
                                                                                             γ    G ,μ
r, and all other players use the same protocol as in r. in contexts with a common prior. Suppose that =( 0 ) is
                                                      a context with a common prior. We say that μ is compatible
  There is a problem with this approach. There is no guar-                     
antee that, in general, such a closest point (r,m) exists in with the mixed joint strategy S if μ is the probability on pure
the system PS. To deal with this problem, we restrict atten- joint strategies induced by S (under the obvious identiﬁcation
tion to a class of systems where this point is guaranteed to of initial global states with joint strategies).
exist. A system R,μ is complete with respect to context γ
             (    )                                                               S
if R includes every run generated by a protocol appropriate Theorem 3.1: The joint strategy is a Nash equilibrium of
         γ                                   r,m     the game Γ iff there is a common prior probability measure
for context . In complete systems, the closest point ( ) μ GΓ                 ,...,
is guaranteed to exist. For the remainder of the paper, we on 0 such that STRAT1   STRATn  are independent
                                                      with respect to μ, μ is compatible with S, and P nf imple-
  2                                                               Γ               Γ
   If we allow players to change strategies during a run, then we ments EQNF in the context (G0 ,μ).
will in general have different joint strategies at each point in a run.  
For our theorems in the next section, we restrict to contexts where Proof: Suppose that S is a (possibly mixed strategy) Nash
players do not change strategies.                     equilibrium of the game Γ.LetμS be the unique probability

                                                IJCAI-07
                                                  1304