                    Learning Subjective Representations for Planning

          Dana Wilkinson                   Michael Bowling                      Ali Ghodsi
    School of Computer Science     Department of Computing Science      School of Computer Science
       University of Waterloo             University of Alberta            University of Waterloo
       Waterloo, ON, Canada             Edmonton, AB, Canada               Waterloo, ON, Canada
     d3wilkinson@uwaterloo.ca           bowling@cs.ualberta.ca            aghodsib@uwaterloo.ca

                    Abstract                          quired input is a sequence of actions and observations from
                                                      the agent’s subjective experience, but no semantic meaning
    Planning involves using a model of an agent’s ac- (domain-speciﬁc or otherwise) is required. This input is used
    tions to ﬁnd a sequence of decisions which achieve in a three step process.
    a desired goal. It is usually assumed that the mod- First, Section 2 reviews Action Respecting Embedding
    els are given, and such models often require ex-  (ARE). ARE is a technique for dimensionality reduction that
    pert knowledge of the domain. This paper ex-      speciﬁcally makes use of a temporal sequence of observations
    plores subjective representations for planning that and actions. ARE learns manifolds that capture the important
    are learned directly from agent observations and ac- underlying dynamics of the high-dimensional data in much
    tions (requiring no initial domain knowledge). A  fewer dimensions (addressing the ﬁrst problem). Next, Sec-
    non-linear embedding technique called Action Re-  tion 3 describes a method for learning operators for each ac-
    specting Embedding is used to construct such a rep- tion that can be applied to any point in the learned represen-
    resentation. It is then shown how to extract the  tation (addressing the second problem). Examples of learned
    effects of the agent’s actions as operators in this operators are provided along with a discussion of how the se-
    learned representation. Finally, the learned repre- mantic meaning of the associated actions can sometimes be
    sentation and operators are combined with search to extracted. Finally, Section 4 shows the results of planning in
    ﬁnd sequences of actions that achieve given goals. the resulting representation using the learned operators. Both
    The efﬁcacy of this technique is demonstrated in a the resulting plan in the learned representation, and the result
    challenging robot-vision-inspired image domain.   of applying the plans in the original high-dimensional domain
                                                      are compared.
1  Introduction
Planning, at its essence, involves searching an appropriately 2 Action Respecting Embedding
deﬁned state space. This state space is a consequence of the High-dimensional data sets, such as sequences of images, can
agent’s model of the effects of its actions (e.g., STRIPS [Fikes often be characterized by a low-dimensional representation
and Nilsson, 1971], Markov Decision Processes [Puterman, that is related to the process generating the data. For example,
1994]). It is assumed that these models can be deﬁned from a low-dimensional representation for image data may corre-
domain experts and planning uses these models to ﬁnd se- spond to the degrees of freedom of a platform moving a cam-
quences of actions to achieve given goals. The problem is era. Such a representation is ideal for planning as it directly
that models are not always known or easily built for a do- captures the actions’ effects on the world. The goal here is
main of interest. Others have studied methods for learning or
                                                      to take a temporal sequence of data points, z1, . . . , zn, and
agumenting models, such as STRIPS operators [Wang, 1995]
                                                      associated actions, a1, . . . , an−1, and ﬁnd a low-dimensional
or MDP transitions [Peng and Williams, 1993]. All of these
                                                      representation for zi that is appropriate for planning.
techniques still require expert intuition about the domain to Recently, nonlinear manifold learning techniques have
provide, at the least, an appropriate state representation. been used to map a high-dimensional dataset into a smaller
  This paper focuses on learning an appropriate representa- dimensional space. Semideﬁnite Embedding (SDE) [Wein-
tion for planning, using only an agent’s observations and ac- berger and Saul, 2004] is one such technique. SDE learns
tions. We call this a subjective representation as the learned a kernel matrix, which represents a non-linear projection of
representation is extracted based only on the agent’s experi-
ence, and requires no expert knowledge of the domain. The closely resembles recent work on learning predictive representa-
approach solves two important problems: (i) learning an ap- tions [James and Singh, 2004; Rosencrantz et al., 2004; Jaeger,
propriate state-space representation, and (ii) learning the ef- 2000] than previous work on augmenting operators or transition
fects of the agent’s actions in this representation.1 The re- probabilities. This approach, though, is speciﬁcally designed for
                                                      very high-dimensional observation spaces as it implicitly involves a
  1The approach of learning a subjective representation more dimensionality reduction component.   Algorithm: SDE(|| · ||, (z1, . . . , zn))            Algorithm: ARE(|| · ||, (z1, . . . , zn), (a1, . . . , an−1))
     Construct neighbors, N, using k-NN with || · ||.     Construct neighbors, N, as in [Bowling et al., 2005].
                                 P                                                     P
     Maximize Tr(K) subject to K  0, ij Kij = 0, and     Maximize Tr(K) subject to K  0, ij Kij = 0,
                        T                                                    T
        ∀ij  Nij > 0 ∨ [N N]ij > 0 ⇒                          ∀ij Nij > 0 ∨ [N N]ij > 0 ⇒
                                      2                                                    2
             Kii − 2Kij + Kjj = ||zi − zj ||                      Kii − 2Kij + Kjj ≤ ||zi − zj || , and
                                                              ∀ij ai = aj ⇒
     Run Kernel PCA with learned kernel, K.                       K(i+1)(i+1) − 2K(i+1)(j+1) + K(j+1)(j+1) =
                                                                  Kii − 2Kij + Kjj
   Table 1: Algorithm: Semideﬁnite Embedding (SDE).
                                                          Run Kernel PCA with learned kernel, K.

the input data into a more linear representation. It then uses Table 2: Algorithm: Action Respecting Embedding (ARE).
Kernel PCA [Scholkopf and Smola, 2002], a generalization
of principle components analysis using feature spaces rep-
                                                      feature for subjective planning. ARE constrains the learned
resented by kernels, to extract out a low-dimensional rep-
                                                      manifold to be in a space where the labeled actions corre-
resentation of the data. The kernel matrix K is learned in
                                                      spond to distance-preserving transformations—those consist-
SDE by solving a semideﬁnite program with a simple set of
                                                      ing only of rotation and translation3. Therefore, for any two
constraints. The most important constraints encode the com-
                                                      inputs, z and z , the same action from these inputs must
mon requirement in dimensionality reduction that the non-     i     j
                                                      preserve their distance in the learned feature space. Letting
linear embedding should preserve local distances. In other
                                                      Φ(z ) denote input z ’s representation in the feature space,
words, nearby points in the original input space should re- i           i
                                                      action a’s transformation, f , must satisfy:
main nearby in the resulting feature representation. There-                  a
fore SDE requires a distance metric || · || on the original input ∀i, j ||fa(Φ(zi)) − fa(Φ(zj))|| =
space, and uses this metric to construct a k-nearest neighbors         ||Φ(zi) − Φ(zj)||.             (1)
graph. It then adds constraints into the semideﬁnite program
                                                       Now, let a = a and consider the case where a = a . Then,
to ensure that the distance between neighbors is preserved.        i                         j    i
                                                      f (Φ(z )) = Φ(z   ) and f (Φ(z )) = Φ(z  ), and Con-
The optimization maximizes Tr(K), i.e., the variance of the a i      i+1      a    j        j+1
                                                      straint 1 becomes:
learned feature representation, which should minimize its di-
mensionality. The SDE Algorithm is shown in Table 1.       ||Φ(zi+1) − Φ(zj+1)|| = ||Φ(zi) − Φ(zj)||. (2)
  SDE does not take into account two important pieces of In terms of the kernel matrix, this can be written as:
knowledge about the data: the temporal ordering of the in-
                                                          ∀i, j ai = aj ⇒
put vectors, zi, and the action labels, ai. Therefore, SDE
doesn’t guarantee that temporally-nearby input points will      K(i+1)(i+1) − 2K(i+1)(j+1) + K(j+1)(j+1) =
be spatially nearby in the feature representation. Also, SDE    Kii − 2Kij + Kjj                      (3)
won’t necessarily result in a space where actions have a sim-
ple interpretation. The recent Action Respecting Embedding
                                                        ARE simply adds Constraint 3 into SDE’s usual constraints
(ARE) algorithm [Bowling et al., 2005] extends SDE to make
                                                      to arrive at the optimization and algorithm shown in Table 2.
use of exactly this type of knowledge about the data.
  Formally, ARE takes a set of D-dimensional input vectors, Experiments. Here we deﬁne IMAGEBOT, a synthetic im-
z1, . . . , zn (e.g., images), in temporal order, along with asso- age interaction domain used for all experiments. Given an
ciated discrete actions, a1, . . . , an−1, where action ai was ex- image, imagine a virtual robot that can observe a small patch
ecuted between input zi and input zi+1. ARE then computes on that image and also take actions to move the patch around
a set of d-dimensional output vectors x1, . . . , xn in one-to- the larger image. This “image robot” provides an excellent
one correspondence with the input vectors. This provides a domain in which subjective planning can be demonstrated.
meaningful embedding in d < D dimensions. ARE modiﬁes   For these experiments, IMAGEBOT will always be view-
SDE in two key ways. First, it exploits the knowledge that the ing a 200 by 200 patch of a 2048 by 1536 image displayed
images are given in a temporal sequence. It uses this knowl- Figure 1. IMAGEBOT has eight distinct actions: four trans-
edge to build an improved neighborhood graph based on each lations, two zoom actions, and two rotation actions. The al-
input’s distances to its temporal neighbors using the provided lowed translations are forward (F ), back (B), left (L) and
local distance metric2. Second, it constrains the embedding right (R) by 25 pixels The zoom changes the scale of the
to respect the action labels that are associated with adjacent underlying image by a factor of 21/8 (i) or 2−1/8 (o). The
                                                                                              π
pairs of observations. This ensures that the actions have a rotation rotates the square left (l) or right (r) by 8 radians.
simple interpretation in the resulting feature space.   There are three distinct experimental data sets that are
  It is this second enhancement of ARE that is the critical looked at in this paper.
  2We have found that ARE is fairly robust to the choice of distance 3Notice this is not requiring the actions in the objective space
metrics, and use simple Euclidean distance for all of the experiments to be rotations and translations, since ARE is learning a non-linear
in this paper.                                        feature representation.       3      3      3      3      3      3      3      3      3      3      5      5      5      5


5      6      6      6      6      6      4      4      4      4      4      5      5      5      5


5      3      3      3      3      3      4      4      4      4      4      4      4      4      4

                       Figure 2: IMAGEBOT’s output (and ARE’s input) for the AT data set.


                                                                1          5          9
                                                                                             21
                                                                                25


                                                                                         13

                                                                            29

                                                                                             17

                                                                                   33

                                                                   45         41        37

                                                        Figure 3: The path IMAGEBOT follows to generate AT .
            Figure 1: IMAGEBOT’s world.

                                                                                   1

AT : IMAGEBOT  follows a path which looks like an “A” us-
    ing only the translation actions:                                      5
    F × 10, L × 5, R × 5, B × 5, L × 5, F × 5, B × 10
                                                                    9
AZ : IMAGEBOT  follows the same A pattern but substituting              25
    zoom in for left actions and zoom out for right actions:      21
    F × 10, i × 8, o × 8, B × 5, i × 8, F × 10, B × 20                        29
                                                                                            45
                                                                 13
F r: IMAGEBOT moves back and forth in a line, but only us-
                                                                               33
    ing F and r actions:                                                           41
    F × 10, r × 8, F × 10, r × 8, F × 5, r × 16, F × 5                   17
                                                                           37
  Note that in AZ the F and B actions only move half as
much when zoomed in as when zoomed out. Note that in F r Figure 4: The representation learned by ARE for AT .
there are no opposites for the two actions used. An example
of the output of IMAGEBOT, and correspondingly an input
for ARE, is shown in Figure 2. These are the images seen in Figure 5 shows a “top” view and a “side” view of the 3-
the AT data set. Note that while we know that, for example, dimensional manifold learned for the F r data set. here the
action label 3 corresponds to action F , ARE gets no such portion of the manifold corresponding to rotating to the right
semantic information—it gets as input only the images and (r) is a black line while the portion corresponding to mov-
the labels associated with them.                      ing forward (F ) is a light-gray line. The point corresponding
  The effectiveness of ARE has been demonstrated previ- to the ﬁrst image is circled. Although not as clear as in the
ously [Bowling et al., 2005]. Here evidence is shown of previous case, this manifold is clearly and distinctly captur-
its power in capturing useful representations for planning. ing the structure of the original path, with two dimensions
Figure 3 shows the actual manifold underlying the AT test capturing the r action and a third capturing the F action. In
set (i.e., IMAGEBOT’s path). Figure 4 shows the manifold Figure 3, the original domain was one in which the actions
learned by ARE on that test set. Clearly the structure has were distance-preserving and this structure was, indeed, ex-
been captured.                                        tracted. In Figure 5 it is not immediately obvious what man-         Figure 5: Two different views of the three-dimensional cylindrical manifold learned for the F r data set.

ifold will be learned which makes the resulting one all the where Λ is a matrix of lagrangian multipliers, and Tr(.) stands
more impressive—not just as a representation appropriate for for the trace of a matrix.
planning but as an aid to intuitive understanding of the origi-
                                                            L(Aa, ba, Λ) =
nal underlying structure.                                            T          T  T           T
                                                                 Tr(Ya Ya) + Tr(Xa Aa AaXa) + nba ba
                                                                        T              T
3  Distance Preserving Operators                                 −2Tr(Ya AaXa) − 2Tr(eba Ya)
                                                                        T               T
ARE learns a representation with explicit constraints that the   +2Tr(eba AaXa) + Tr(Λ(Aa Aa − I))
actions correspond to distance-preserving transformations in Now take the derivative of the Lagrangian function with re-
that representation. Before one can plan, though, one needs spect to the unknowns and set to zero:
to discover these transformations. For each unique action a
                                                              ∂L            T           T
there is a collection of data point pairs (xt, xt+1) which are     =   2AaXa  Xa − 2YaXa  +
connected by that action. Another way of thinking of this is ∂Aa
                                                                            T   T           T
that there is a function fa where fa(xt) = xt+1, and such a            +2bae  Xa + Aa(Λ + Λ  ) = 0    (4)
function needs to be learned for each action. Because of the  ∂L
distance-preserving constraints, fa can be represented as:         =   2nba − 2Yae + 2AaXae = 0       (5)
                                                              ∂ba
             fa(xt) = Aaxt + ba = xt+1                The translation vector from Equation 5 gives:

                                                                         (Ya − AaXa)e
  Recall that transformations of the above form encode trans-       ba =                              (6)
lation in the ba vector, and rotation and scaling in the Aa ma-                n
                                                                              T
trix. Aa and ba could be learned using simple linear regres- Multiplying Equation 4 by Aa /2 on the right:
sion but scaling is not distance preserving so there is the ad-        T     T            T  T
                                        T                          AaXa  XaAA  + Aa(Λ + Λ  )Aa /2 =
ditional constraint that Aa does not scale, i.e., Aa Aa = I. It
                                                                           T  T      T  T  T
turns out that this is similar to the extended orthonormal Pro-        YaXa Aa  − bae Xa Aa
crustes problem [Schoenemann and Carroll, 1970], but with- Since the left hand side is symmetric, the right hand side must
out allowing for a global scaling constant. Here the solution also be symmetric. Substituting Equation 6, the right hand
to the regression problem is derived.                 side can be written as:
  Let Xa be the d by n matrix whose columns are xt for all            T                   T 
                                                          T  T       ee      T T           ee     T  T
t such that at = a, and let Ya be the d by n matrix whose Y X A − Y        X  A  + A  X         X  A
                                                       a  a  a    a   n     a  a     a a    n     a  a
columns are xt+1 for the same t. The goal is to learn a
rotation matrix Aa and a translation ba which maps Xa to where the last term is symmetric. Thus the rest of the expres-
Ya. Formally, the following optimization problem needs to sion must also be symmetric. This can be simpliﬁed as:
be solved.                                                                 T     
                                                                           ee      T   T
                                 T                                  Ya  I −      Xa   Aa              (7)
          minimize:  ||AaXa + bae  − Ya||                                   n
                       T
          subject to: Aa Aa = I                       Since 7 is symmetric, it should be equivalent to its transpose:
                                                                T                       T     T
where e is a column vector with n ones.                         ee     T    T               ee     T
                                                        Ya  I −      Xa   Aa =  Aa  Ya  I −      Xa     (8)
  In order to obtain the least squares estimation of Aa and      n                           n
ba, write the Lagrangian function L:                  One can easily verify that the following satisﬁes Equation 8:
 L(A  , b , Λ) =                                                                       T    
     a  a                                                          T                   ee     T
                   T      T            T                      V SW    =   svd  Ya  I −      Xa
     Tr((AaXa + bae  − Ya) (AaXa  + bae  − Ya)) +                                       n
            T                                                                 T
     Tr(Λ(Aa Aa − I))                                             Aa  =   V W                         (9)                 R
               F
              F
            F      R
                    R
             L
                      R                                                    F
               L     B                                                    o
                   B    R                                              o o  F
                 L                                                            F
                                                                               F
                         R                                              B       F
                                                                                  F F F i
                                                                         B
                                                                           B        i
                                                                            B      i
                                                                              B
                                                                                 i

Figure 6: Demonstrating distance-preserving operators in the Figure 7: Demonstrating distance-preserving operators in the
representation learned for AT .
                                                      representation learned for AZ .

where svd(·) is the singular value decomposition, so,
                                                      from the action labels functions have been learned for each
         V SW T W V T = V W T W ST V T                unique action that explicitly give the resulting state when that
         T                                       T    action is applied from any state. Learning such a function in
because W W  =  I (since W is orthonormal) and S = S  the orignal space is not only intractable, but would require
(since S is diagonal). Thus Equations 6 and 9 are a solution to application of knowledge speciﬁc to IMAGEBOT (or even the
the dual function, D = minΛ L(Aa, ba, Λ). Since this solu- underlying image) in order to attain any success.
tion is also feasible with regards to the primal problem, strong Given any two images, one can ﬁnd a shortest path be-
duality holds even though the original problem is non-convex. tween them, even if it traverses unobserved parts of the space.
Results. Figure 6 shows the two-dimensional representa- First, ﬁnd the corresponding points in the low-dimensional
tion that ARE generated for AT . The solid arrows show a representation, then ﬁnd the shortest path between them us-
path which consists of new points resulting from the applica- ing traditional search methods and the set of learned opera-
tion of operators learned for each action (F , B, L and R) as tors. Since each operator in the low-dimensional space corre-
described above. Clearly, the operators are intuitively captur- sponds to an action label in the orginal space the list of action
ing the essence of the actions used to generate the data. labels that indicate the desired path can be returned. For the
  Note that while there is no semantic meaning given with following results, iterative-deepening depth-ﬁrst search was
the input actions, such meaning can now be derived. It can used and the path whose ﬁnal point was closest to the desired
easily be tested whether a pair of actions are opposites, such goal was returned. The quality of a path is demonstrated by
as (F, B) or (R, L). Also two actions can be tested for or- starting IMAGEBOT at the initial state, applying the sequence
thogonality or independence, such as F and R. If the learned of actions and showing the resulting image.
representation captures some underlying structure within the Results. For each of the three test sets, two sub-ﬁgures will
data, the learned operators will maintain that structure and, be shown. The ﬁrst shows the representation learned for that
from them, relationships can be successfully hypothesized. data set and the shortest path between a chosen initial state
  Figure 7 is similar to Figure 6, except the underlying rep- (labelled with a triangle pointing right) and a chosen goal
resentation is from the AZ data set. Here, note that while state (labelled with a triangle pointing left). The second ﬁgure
some actions are again opposite to each other, no actions are contains two images. The left image shows the image at the
orthoganal—the F and B actions are not independent of the initial state, the right image contains two highlighted boxes.
i and o actions. This critical facet of the original data set has The light-gray dotted box shows the image at the goal state,
been successfully captured in the representation learned by the darker-gray solid box highlights the image obtained after
ARE and consequently in the action functions learned in that executing the resulting sequence of actions.
manifold. Note, in particular, that when zoomed in all the Figures 4(a) and 4(b) show the results for A —the goal
    i × 8    F                       F                                                         T
way (    ) 10  actions are equivalent to 5 actions when state image and the image corresponding to the ﬁnal state in
                              F
zoomed out all the way. Although action when zoomed   our path in Figure 4(b) are the same. Note that the shortest
in half way was never observed, the learned operators cap- path was successfully found, even though it involves moving
                             F
ture the fact that between 7 and 8 actions at this scale are through portions of the space that we have never seen.
equivalent to 5 and 10 actions at the other scales.
                                                        Figures 4(c) and 4(d) show the results for AZ —the goal
                                                      state image and the image corresponding to the ﬁnal state in
4  Planning                                           the path in Figure 4(d) are the same. Note, the path found
Now that low-dimensional representations and operators in successfully identiﬁes that action B must occur before action
those representations can be learned, all the pieces are in o—if taken after then the B action would jump over the de-
place to perform planning. The points in the learned represen- sired end state to a state halfway between it and the next state.
tation are states, and the operators learned in Section 3 deﬁne Figures 4(e) and 4(f) show the results for F r—the goal
transitions between the states. This new domain has two ad- state image and the image corresponding to the ﬁnal state in
vantages over the original data set. First, the dimensionality the path in Figure 4(f) are very close to each other. Recall
has been reduced drastically (from 40,000 to 2 or 3). Second, that for this data set, unlike the others, the only actions were