                Mining Video Associations for Efficient Database Management 

                                              Xingquan Zhu and Xindong Wu 
                              Department of Computer Science, University of Vermont 
                                               Burlington, Vermont 05405, USA 
                                                    {xqzhu, xwu}@cs.uvm.edu 


                            Abstract                                     of each shot to form a shot cluster sequence. We mine sequential 
                                                                         associations from the sequence to find clusters with strong correla•
     To support more efficient video database manage•                    tions and take strongly correlated clusters as video associations. 
     ment, this paper explores the concept of video asso•
     ciation mining, with which the association patterns 
     are characterized by sequentially associated video 
     shots and their cluster information. Given a continu•
     ous video sequence V, the video shot segmentation 
     mechanism is first introduced to parse it into discrete 
     shots. We then cluster shots into visually distinct 
     groups and construct a shot cluster sequence by using 
     the class label of each shot. An association mining 
     scheme is designed to mine sequentially associated 
     clusters from the sequence. Those detected associa•
     tions will convey valuable knowledge for video data•
     base management. The experimental results demon•
     strate the effectiveness of our design. 

1 Introduction 

Since the 1990s, data mining has been a very active area for re•
search and applications. Many successful techniques have been 
implemented through academic research and industrial applications 
[Agrawal and Srikant, 1994][Agrawal and Srikant, 1995][Wu, 
1995] [Han and Kamber, 2000]. However, these approaches deal 
with various databases (like transaction datasets) in which the rela•
tionship between data items is explicitly given. Video and image 
databases are different from these databases. The most distinct 
feature of video and image databases is that the relationship be•
tween any two of their items cannot be explicitly (or precisely) 
figured out. This inherent complexity of the multimedia data has           Fig. 2 Some typical video scenes and video data transformation 
suggested that mining knowledge from multimedia materials is 
even harder than from general databases [Zhu et al,                      2 Video Association Mining 
2003][Thuraisingham, 2001][Zaiane, et al., 1998]. Generally, there 
are two types of video mining techniques: (1) special pattern detec•     Generally, most videos from our daily life are edited by editors, 
tion [Zhu et al, 2003], which detects some predefined special pat•       where various kinds of shots are packed as scenes to convey video 
terns; and (2) video clustering and classification [Oh et al.,           scenarios, as shown in Fig. 2. There are two typical video scenes: 
2002][Pan and Faloutsos, 2002], which clusters and classifies            (1) scenes that consist of visually similar shots, as demonstrated in 
video units into different categories.                                   Fig. 2(a); and (2) scenes that consist of visually distinct shots, as 
   Different from these two types of video mining schemes, we            shown in Fig. 2 (b). In the first type of scenes, most video shots are 
address a new research area of video mining, video association           visually similar. Take Fig. 2(a) as an example, if we denote each of 
mining, in this paper, where associations from video units are used      the shots by "A", all shots form a sequence "AAAAAAA", and the 
to explore video knowledge. We will present a definition for video       self-coherence of "A" indicates an association of itself. We name 
associations, and design a video association mining algorithm. As        this type of association as an intra-association, i.e., all items in the 
shown in Fig. 1, we first segment a video sequence into shots and        association are the same. In the second type of scenes, sequential 
cluster shots into groups. Then, we assemble the class information       associations exist too. In Fig.2(b), if we denote the actor by "A", 
                                                                         the actress by "B" and the shot containing both of them by "C", all 


1422                                                                                                                    POSTER PAPERS shots form a sequence "ABABACAB". The co-occurrence of "A"              3. Collection & Pruning Phase. This phase prunes and selects 
and "B" implies an association. We name this type of association        valuable associations from all L-LitemSets. 
as an inter-association, i.e., items in the association are different.      Since Phase 3 is quite obvious, we focus on Phases 1 and 2. 
    Based on the above observations, wc define a video association      Meanwhile, due to the fact that all items in intra-associations are 
as a sequential pattern with for any                                    the same, mining this type of associations is relatively easy, wc 
where X, is a video item (see definition below), L denotes the          hereby introduce mechanisms on mining inter-associations only. 
                                                                            In the transform phase, we adopt some video processing tech•
length of the association. X' denotes the temporal order of X„ 
                                                                        niques to segment a video sequence into shots, and execute shot 

and indicates that X, happens before Xj For an inter-                   clustering to explore relationships among shots. To detect video 
                                                                        shots, we use our existing algorithm in [Zhu et al., 2003]. For the 
association, and for an intra-association, 
                                                                        sake of simplicity, we select the 10  frame of each shot as its key•
                          For simplicity, we use {X} as the abbre•                                          th
                                                                        frame. After the shot segmentation, we adopt a modified split-and-
viation of an association. 
                                                                        merge clustering algorithm [Horowitz and Pavlidis, 1974] to clus•
    Due to the fact that the temporal information in a video se•        ter video shots into groups where visually similar shots are first 
quence plays an important role in conveying the video content, we       merged into groups and the groups with large visual variances are 
integrate traditional association measures {support and confidence)     split into two clusters. After shot clustering, each shot will receive 
and video temporal information to evaluate video associations.          a class label, we sequentially aggregate the class information of 
Some definitions are given as follows:                                  each shot by its original temporal order to form a shot cluster se•
• An item is a basic unit, which denotes a shot cluster.                quence D. As shown in Fig. 2, each icon image denotes one shot 
• Given a shot cluster sequence, the temporal distance (TD) be•         and the letter below it indicates its class label, and the acquired 
    tween two items is the number of shots between them. E.g,           shot cluster sequences are given in Fig. 2 (c). Table 2 gives an 
    given sequence "ABDEC", the temporal distance of "AB" is            example of the video association mining, where the first column 
    TD(AB)=0, and for "AC" is TD(AC) =3.                                presents the video shot cluster sequence. 
• An L-ltemAssociation is a video association that consists of L            In the L-LItcmSet phase, we use the large ItemSet from the 
    sequential items. E.g., "ABC" is a 3-ItemAssociation.               previous pass to generate the candidate ItemSet and then measure 
• The L-ItemSet is an aggregation of all L-ItemAssociations, with       their temporal support by making a pass over the database A as 
    each of its members being an L-ltemAssociation.                     shown in Fig. 3. At the end of the pass, the support of each candi•
• Given a temporal distance threshold (TDT) TDT=T, the tempo•           date is used to determine the L-LItemSet. The candidate generation 
    ral support {TS) of an association {X1...XL} is defined as the      is similar to the method in [Agrawal and Srikant, 1995]. It takes 

    number of times that this association appears sequentially in       the set of all k-1 -ItemAssociations in Lk-1 and all their items as 
    the sequence. In addition, each time this association appears,      input, and works as shown in Fig. 4. Take the 3-LItemSet L3 in the 
    the temporal distance between any two neighboring items of          fourth column of Table 2 as an example. If L3 is given as the input, 
    the association should be no more than T shots. That is, given      we will get the ItemSet shown in the fifth column after the join. 

    any X, and                                                          After pruning out sequences whose subsequences are not in L3, the 
• Given TDT=T, the confidence of an association is sequences shown in the sixth column arc left. E.g., {ABDC} is 
    defined as the ratio between the temporal support of {X} when       pruned out because its subsequence {BDC} is not in L3. 
    TDT=T and the number of maximal possible occurrences of the 
    association {X}. For an inter-association, the maximal possible     (1) 
    occurrence of the association is determined by the number of        (2) 
    occurrences of the item with the minimal support. Its confi•
    dence is defined by Eq.(l). For an intra-association, all items     (3)  
    are the same, the maximal possible occurrence of the associa•             Begin: 

    tion is determined by the support of the item and the associa•      (4) IK=New candidates generated from Lk-1 (see Fig. 5). 
    tion length (L), as defined by Eq.(2), where (x) indicates the      (5) For each k-ItemAssociation in /k, we count its temporal 
    maximal integer which is not larger than x.                                  support by considering the user's specification with TDT. 

                                                                (1)     (6) Lk=Candidates in Ik with the minimum temporal support. 
                                                                (2)           End 
• The L-LItemSet is an aggregation of all L-ItemAssociations that              Fig. 3 The L-LItemSet Phase of the mining algorithm 
    each of their temporal support is no less than a given threshold. 
                                                                        (1). Join the items of associations in Lk-1 
2.1 Association Mining Algorithm                                        (2). 
Our video mining algorithm consists of the following phases: 
1. Transform Phase. Given video V, this step transforms V from 
continuous frames into a sequence dataset D. 
                                                                        (3).  
2. L-LItemSet Phase. In this phase, we mine both intra-
associations and inter-associations from D. We first find the L-
ItemSet, and then use L-ItemSet and a user-specified threshold to                           Fig. 4 Candidate generation 
find L-LItcmSet. We will iteratively execute this phase until no 
more non-empty L-LItcmSet can be found.                                 In Fig. 3 and Fig. 4, Lk denotes the k-LItemSet and Ik the k-ItemSet. 


POSTER PAPERS                                                                                                                         1423  3 Experimental Results and Discussion                                   Table l. Video association mining results 
 Traditional video database systems use video shots as the units to 
 index and manage video data where the visual similarities among 
 shots are used to construct the index structure. Unfortunately, a 
 single shot which is separated from its context has less capability 
 to convey semantics; Moreover, the index considering only visual 
 similarities ignores the temporal information among shots. Conse•       4 Conclusions 
 quently, the constructed cluster nodes may contain shots that have      To facilitate video database management, we have explored a new 
 considerable variances both in semantics and visual content and         research area of video data mining. A video association mining 
 hereby do not make much sense to human perception. Accord•              algorithm has been proposed. Given video V, we first transform it 
 ingly, a semantic video database management framework has been          from sequential frames to a relational dataset by shot segmentation, 
 presented [Zhu et al, 2003] where video semantic units (events,         clustering, and constructing a shot cluster sequence. The video 
 scenes or other scenario information) are used to construct a data•     mining scheme mines sequentially associated video items from this 
base index. To facilitate this goal, one of the most important tasks     sequence. In addition to using the traditional association measures, 
 is to detect the video semantic units. In this section, our experi•     we have integrated temporal features among video shots into the 
 mental results will demonstrate that the proposed video association     video association evaluation. The experimental results have dem•
mining technique could be used to explore semantic units for the         onstrated the ability of our mined associations in addressing se•
management of video database systems.                                    mantic information for video database management. 
    To evaluate the ability of video associations in addressing local 
event and scenario information and figure out the relationship be•       Acknowledgments 
tween TDT and the mined associations, we set TDT with different 
                                                                         This research has been supported by the U.S. Army Research 
values T (T=l. 3, 5, 7, 9 and °°) and assess the associations. For 
                                                                         Laboratory and the U.S. Army Research Office under grant num•
each acquired association, we scan the datasct to check whether all 
                                                                         ber DAAD19-02-1-0178. 
items in the association belong to the same scene each time when 
the association appears. We define the Scene Coverage (SC) of an 
                                                                         References 
association as the ratio between the frequency of the association's 
items belonging to the same scene and the frequency of the asso•         [Agrawal and Srikant, 1994] R. Agrawal and R. Srikant, Fast algo•
ciation's appearance. The higher the SC, the better the association      rithm for mining association rules. Proc. of VLDB, 1994. 
addresses the scene and event information. On the other side, with       [Agrawal and Srikant, 1995] R. Agrawal and R. Srikant, Mining 
an adopted temporal support, the smaller the TDT, the less is the 
                                                                         sequential patterns. Proc. of 11th ICDE Conference, pp.3-14, 1995. 
number of mined associations. This indicates that the TDT also 
                                                                         [Han and Kamber, 2000] J. Han and M. Kambcr, Data Mining: 
acts as a factor for pruning associations. We hereby define the 
                                                                         Concepts and Techniques, Morgan Kaufmann, 2000. 
Pruning Rate (PR) as the ratio between the number of associations 
when TDT is T (7=1, 3, 5, 7, 9) and 00. We have performed our            [Horowitz and Pavlidis, 1974] S. Horowitz, T. Pavlidis, Picture 
experiments with 5 news videos and 20 medical videos (about 700          segmentation by a directed split-and-mcrgc procedure. Proc. of Int. 
minutes), and the results arc given in Table 2.                          Joint Conf. on Pattern Recognition, pp. 424—433, 1974. 
    Table 1 demonstrates that when the TDT increases, the                [Oh and Bandi, 2002] J. Oh and B. Bandi, Multimedia data mining 
mined associations become worse in addressing the local sce•             framework for raw video sequence. Proc. ofMDM/KDD, 2002. 
nario and event information. One reason for this declination is          [Pan and Faloutsos, 2002] J. Pan and C. Faloutsos, GeoPlot: Spa•
that the clustering process may cluster semantically unrelated           tial data mining on video libraries. Proc. of CI KM, 2002. 
shots into one group, and consequently, when evaluating the 
                                                                         [Thuraisingham, 2001] B. Thuraisingham, Managing and mining 
scene coverage, the items of an association would come from 
                                                                         multimedia database. CRC Press, 2001. 
different events. However, with relatively small TDT values, 
this type of errors can be reduced, because items with a small           [Wu, 1995] Xindong Wu, Knowledge acquisition from databases. 
temporal distance would more likely belong to one semantic               Ablex Publishing Corp., USA, 1995. 
unit. On the other hand, Table 1 also indicates that the smaller         [Zaiane et al., 1998] O. Zaiane, J. Han, Z. Li, S. Chee and J. 
the TDT, the less is the number of mined associations, but the           Chiang, MultimediaMiner: a system prototype for multimedia data 
better arc the mined associations in addressing event and sce•           mining. Proc. ofACMSlGMOD, 1998. 
nario information. Depending on the user's objectives of asso•           [Zhu et al., 2003] X. Zhu, W. Aref, J. Fan, A. Catlin, and A. Elma-
ciation mining, a balance between the number of associations 
                                                                         garmid, Medical video mining for efficient database indexing, 
and the SC is necessary to select a reasonable value for TDT. 
                                                                         management and access. Proc. of ICDE, Mar., 2003. 

 Table 2. An example of video association mining, where {x}C indicates an association, X denotes the items of the association, S and C 
  indicate the temporal support and confidence respectively. The sequential order in the first column is from left to right, top to bottom. 


1424                                                                                                                   POSTER PAPERS 