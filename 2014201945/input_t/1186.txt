   A Decision-Theoretic Approach to Task Assistance for Persons with Dementia
           Jennifer Boger                   Pascal Poupart                      Jesse Hoey
          IBBME, Univ. Toronto     School of Computer Science, Univ. Waterloo Dept. Computer Science, Univ. Toronto
       jen.boger@utoronto.ca           ppoupart@cs.uwaterloo.ca            jhoey@cs.toronto.edu

          Craig Boutilier                     Geoff Fernie                    Alex Mihailidis
   Dept. of Computer Science, Univ. Toronto Toronto Rehabilitation Institute Dept. of Occup. Therapy, Univ. Toronto
       cebly@cs.toronto.edu        Fernie.Geoff@torontorehab.on.ca     alex.mihailidis@utoronto.ca

                    Abstract                            Our objective is to design and develop systems that ac-
                                                      tively monitor a user attempting a task and offer assistance in
    Cognitive assistive technologies that aid people  the form of task guidance (e.g., prompts or reminders) when
    with dementia (such as Alzheimer’s disease) hold  it is most appropriate and in a form that will do the most
    the promise to provide such people with an in-    good. Such systems should tailor their guidance decisions
    creased level of independence. However, to real-  (w.r.t. both form and timing) to speciﬁc individuals and cir-
    ize this promise, such systems must account for   cumstances, based on what will work best for them. In this
    the speciﬁc needs and preferences of individuals. work, we extend the prototype COACH system [12] in which
    We argue that this form of customization requires behavioral monitoring of a handwashing task is realized with
    a sequential, decision-theoretic model of interac- a vision system. We extend COACH by modeling the guid-
    tion. We describe both fully and partially observ- ance decision process in a decision-theoretic fashion, more
    able Markov decision process (POMDP) models of    precisely, as a partially observable Markov decision process
    a handwashing task, and show that, despite the po- (POMDP). There are several important factors that should in-
    tential computational complexity, these can be ef- ﬂuence guidance decisions that strongly suggest the use of
    fectively solved and produce policies that are eval- this model, including perceptual noise, the stochastic nature
    uated as useful by professional caregivers.       of user behavior, the need to trade off various objective cri-
                                                      teria (e.g., task completion, caregiver burden, user frustration
1  Introduction                                       and independence), and the need to tailor guidance to speciﬁc
Dementia is a clinical syndrome characterized by the deteri- individuals and circumstances.
oration of a person’s memory and cognitive function. It is Our key contributions are as follows. First, we develop a
estimated that there are nearly 18 million older adults with POMDP model for a speciﬁc ADL (handwashing). While the
dementia worldwide, with this number expected to reach 35 model itself is of value for handwashing, the general form
million by 2050 [1]. Alzheimer’s disease is the most common of the model is appropriate for almost any ADL guidance
form of dementia and accounts for more than half of demen- or intervention module. Second, we show that these models
tia diagnoses [3]. Home care offers tremendous advantages exhibit considerable structure, allowing them to be speciﬁed
for such individuals (e.g., economically, quality of life) over easily, and the underlying decision problem to be solved ap-
placement in a long-term healthcare facility. However, sig- proximately by recent state-of-the-art algorithms. In particu-
niﬁcant barriers often prevent home care from being a viable lar, we obtain an exact solution for a fully observable MDP
option, including the physical and emotional burden placed simpliﬁcation of the POMDP; and an approximate solution
on family members and the cost of maintaining professional is obtained for the POMDP despite its size and complexity.
care in the home.                                     Third, controlled evaluation of the MDP policy by profes-
  A pressing need for people with advanced dementia arises sional caregivers demonstrates its signiﬁcant value as an as-
from the difﬁculty they have completing activities of daily sistive device. While MDP performance is not as good as that
living (ADLs). A caregiver generally must guide them, step of professional caregivers, it is more than adequate to serve as
by step, through such routine activities as handwashing, toi- the basis for a supplemental device which can relieve the bur-
leting, dressing, moving about, taking medication, etc. Cog- den on caregivers or family members. Finally, in simulation,
nitive assistive technologies that help guide users (i.e., care we show that the approximate POMDP policy outperforms
recipients) through ADLs can relieve some of the stress of the exact MDP policy. This suggests that accounting for par-
home care on family members and care professionals. How- tial observability and user customization via the POMDP ap-
ever, current monitoring and reminding devices cannot accu- proach offers considerable beneﬁts. These beneﬁts are cur-
                                                      rently being quantiﬁed in clinical trials which will be reported
rately track user behavior at a step-by-step level, nor adapt                    1
to speciﬁc users. Moreover, many devices require explicit in a longer version of this paper.
feedback (e.g., button presses), which cannot reasonably be
expected of people with moderate-to-severe dementia.     1Trials are not yet complete so cannot be reported here.2  Cognitive Assistive Technologies & COACH           automatically, deal with partial observability, and customize
                                                      behavior to speciﬁc users has led to the development of the
Assistive technology (AT) is increasingly used to offset the POMDP approach described here.
impact of impairments resulting from injury, disease, and the
aging process and related disorders. Typically these technolo-
gies have focused on assisting users with mobility impair- 3 A POMDP Approach
ments. Recent growth in the number of people with cogni- The decision problem faced by COACH is fraught with un-
tive disabilities, such as dementia, has resulted in consider- certainty, both with respect to the observability of the envi-
able research being conducted into developing cognitive as- ronment, and the effects of system actions. Furthermore, our
sistive technologies (CATs) to address the difﬁculties that this goal is to satisfy a number of different objective criteria that
population faces. In broad terms, CATs attempt to compen- often conﬂict and cannot be achieved with certainty. For this
sate for existing impairments by using devices, tools, or tech- reason, a POMDP provides the best formal framework for
niques that either compensate for a person’s impaired cogni- modeling the decision process. POMDPs allow one to model
tive ability, or translate a problem into one that matches the imprecise information about the current environment state,
user’s strengths. To date, computerized CATs have been of uncertainty in the effects of actions, and multiple, conﬂict-
limited scope, especially in the use of AI techniques. Proto- ing objectives. Optimal policies will proffer courses of action
types of cognitive aids include handheld devices that remind a that balance the importance of speciﬁc objectives with their
person to complete basic ADLs (e.g., taking medication [8]). odds of success; furthermore, they account for the long-term
However, most of these systems were not designed for older impact of decisions, including the value of information inher-
adults, particularly those with moderate-to-severe dementia, ent in an action, thereby allowing to the system to actively
and would likely not be acceptable for this population. learn about certain environment or user characteristics.
  Several intelligent systems that use AI and ubiquitous com- Many domain characteristics associated with ADL guid-
puting techniques are currently being developed for the older ance (handwashing being just one example) strongly suggest
adult. These include the Aware Home Project [13], the As- the use of a POMDP. These include:
                     [ ]                      [  ]
sisted Cognition Project 7 and the Nursebot Project 15 . • Sensing (e.g., vision in our system) is prone to noise,
These new projects are similar to the work described in   hence environment variables must be estimated proba-
this paper in the sense that they attempt to incorporate AI bilistically (e.g., the location of a user’s hands and body
and a decision-theoretic approach to overcome the shortcom- must be estimated due to sensor noise or occlusion). As
ings of current approaches. In particular, the Autominder a result, the task step the user is attempting to engage
       [ ]
System 17 , one aspect of the Nursebot Project, applies a must also be estimated.
POMDP in the development of the planning and scheduling •
aspect of the system [15]. These systems do not incorporate Successful completion of a task step given a speciﬁc
advanced prompting techniques and algorithms, but rather are form of guidance is generally stochastic (e.g., a user may
being developed as scheduling and memory aids.            react appropriately to an audio prompt only some per-
                                                          centage of the time).
  COACH, our ﬁrst prototype of an intelligent environment
                                                        •
for older adults with dementia, monitors progress and pro- Conﬂicting objectives need to be traded off against one
vides assistance during handwashing. It uses computer vision another and their odds of success (e.g., maximizing the
and simple AI techniques to learn to associate hand positions odds of task completion, maximizing the number of
(2D coordinates) with speciﬁc handwashing steps (e.g., turn- successful task steps without caregiver aid, minimizing
ing on the water, using the soap), and to adjust its parameters caregiver intervention, and minimizing user frustration).
and cuing strategies [12]. COACH uses audio prompts for • A given form of guidance may have different odds of
each of the possible plan steps, with each step associated with success for speciﬁc individuals, hence requiring cus-
a general,amoderate,oraspeciﬁc prompt. For example, a     tomization to speciﬁc individuals based on our current
general prompt to turn on the water simply states “Please turn estimates (e.g., a speciﬁc user may tend to get frustrated
on the water,” while a speciﬁc prompt uses the subject’s name with prompting that is too frequent).
and elaborates on the the process (“...byplacing your hands
on the tap in front of you . . . ”). Clinical trials with 10 sub- 3.1 The POMDP Model
jects with moderate-to-severe dementia showed that the num- We now describe a speciﬁc POMDP model for the handwash-
ber of handwashing steps that the subjects were able to com- ing ADL that captures the desiderata described above. We
plete without assistance from the caregiver increased overall also describe a fully observable counterpart of this model
by approximately 25% when the device was used [10].   that illustrates how MDPs can be applied. The core MDP
  Although this prototype and its algorithms showed some addresses stochasticity and multiple (long-term) objectives,
success, we have identiﬁed several remaining challenges. while the POMDP extension captures partial observability,
Limitations include the assumption of full observability (i.e., noise, and the ability to customize behavior to speciﬁc in-
that the environment and user context are fully represented by dividuals by estimation of hidden user characteristics. We
the data provided), inability to tailor its prompting strategy to take pains to describe several variants of each model. This
speciﬁc users, and the reliance on deterministic hand-coded is because the efﬁcacy study conducted using human care-
rules to make decisions (w.r.t. when and how to provide as- givers was based on an earlier version of the MDP. We wish
sistance). The ability to plan appropriate courses of action to evaluate our results using this baseline; but also describe                 Activity Started A                   step F is indicative of progress being made towards the com-
          E                    B                      pletion of step F despite the fact that the plan step hasn’t yet
           Use Soap     Turn on Water   C             been completed.
                                   Wet Hands
          F                    D                        System behavior variables provide a summary of the sys-
         Turn on Water   Use Soap                     tem history relevant to prediction of user responses to a
                                                      prompt. These are: NP or number of prompts issued for

                 Rinse Hands G                        the current plan step (with domain 0–3+); NW or number

         H                     J                      of time steps waited since last prompt (0–4+); LP, the type
         Turn off Water  Dry Hands                    of last prompt (see description of prompting actions below);
                                                      PL, the speciﬁcity of the last prompt (see actions below); and
          I                    K
          Dry Hands     Turn off Water                Rgr , the number of times the user has regressed in the plan
                                                      (0–3+), which is used as an (stochastic) indication of general
                         L
                 Activity Finished                    responsiveness of the user.
                                                        Finally, user variables reﬂect aspects of the user’s mental
        Figure 1: Plan graph for handwashing ADL.     state that impact their response to prompts. Our current pro-
                                                      totype uses only one variable, Resp (general responsiveness),
improvements to the model which will be used in upcoming taking values low and high, to provide a very crude char-
clinical trials.                                      acterization of user type. However, more sophisticated user
                                                      modeling can be incorporated into the POMDP, using tran-
  A discrete-time POMDP consists of: a ﬁnite set S of
                                                      sition and observation models of precisely the same form as
states; a ﬁnite set A of actions; a stochastic transition model
                                                      those described below.3
Pr : S ×A → ∆(S), with Pr(s, a, t) denoting the probability
of moving from state s to t when action a is taken; a ﬁnite ob- Actions and Dynamics
           Z                                Pr(s, z)
servation set ; a stochastic observation model with   The system has 20 actions, 18 of which comprise prompts for
                                 z       s
denoting the probability of observation in state ; and a re- six different plan tasks (water on/off, use soap, wet hands,
                          R(s, a, t)
ward function assigning reward    with state transition rinse hands, dry hands) at three levels of speciﬁcity (general,
s  t                a
 to  induced by action . Given a speciﬁc POMDP, our goal moderate, speciﬁc). General prompts gently cue the user,
is to ﬁnd a policy that maximizes the expected discounted while speciﬁc prompts are designed to get the user’s attention
sum of rewards attained by the system. Since the system state and provide a detailed description of the task. For example,
is not known with certainty, a policy maps either belief states a prompt to use the soap might be worded as “use the soap
                   S
(i.e., distributions over ) or action-observation histories into now” at a general speciﬁcity level, but might include refer-
choices of actions. We refer to [9] for a detailed overview of ences to the color or location of the soap at a speciﬁc level,
POMDP concepts and algorithms.                        such as “use the soap in the pink bottle on your left”. Us-
State Variables                                       ing the patient’s name is another strategy that is effective for
                                                      speciﬁc prompting. The wording of the prompts was cho-
Our state space is characterized by four classes of variables:
                                                      sen based on prior experience, and was ﬁxed for the duration
those that capture the state of the environment; those that
                                                      of the experiments we describe here.4 The other two actions
summarize the ADL plan steps completed thus far; those
                                                      are the “null” action and “call caregiver.” The latter action
summarizing system behavior; and those reﬂecting certain
                                                      ends the process and is presumed to result in successful task
hidden aspects of the user’s personality or mental state.
                                                      completion. This is an important aspect of our system, since
  Environment variables represent the underlying physical
                                                      our aim is to develop assistive technologies that supplement
state of the environment; these are HL (hand location: at tap,
                                                      rather than replace human caregivers. Our goal is to relieve
at soap, at towel, at sink, at water, away) and WO (water on:
                                                      stress and burden on caregivers by increasing the odds of suc-
boolean).2
                                                      cessful “independent” task completion and reducing the need
  Activity status variables capture the ADL steps that the for constant (human) monitoring. However, in the efﬁcacy
user has completed. Figure 1 shows the legitimate sequences study presented here, we remove this action temporarily to
of steps (any path from start to ﬁnish) that constitute success-
                        4                             ensure the integrity of our evaluations (as described below).
ful handwashing. There are activity status variables. PS, In the ongoing clinical trials, it plays a central role.
whose domain is the nodes (A-K) of the plan graph (L is
                                                        Transition probabilities describe the stochastic state
shown only for convenience), denotes the most recent step
                                                      changes induced by each action. These are speciﬁed by dy-
the user has completed. MPS denotes the maximum plan
                                                      namic Bayesian networks (DBNs) over the state variables,
step completed, since a user may regress in the plan graph.
We use this to reward progress in the graph without reward- 3Other user variables might characterize auditory and visual abil-
ing duplication of steps (see reward description below); PSR ity, overall dementia level, general level of independence, tendency
denotes that the current step has been repeated. Finally, Prg to frustration, etc. We have solved instances of the POMDP with
indicates whether “progress” is being made within the current additional user variables, but do not report these here, since they do
plan step; for example, hands moving to sink position prior to not correspond to the MDP used in our efﬁcacy study.
                                                         4Our current work includes clinical trials to assess the effective-
  2Other relevant aspects of the environment (e.g., hands wet) can ness of different wordings and prompting strategies. Visual prompts,
be inferred from plan step as discussed below.        played through a one-way mirror are being explored as well.with the conditional probability tables (CPTs) represented by
algebraic decision diagrams (ADDs) [6]. The considerable
structure in the domain leads to a very compact speciﬁcation
of the dynamics. The precise parameters of the model were
produced using a handcrafted prior reﬂecting our experience
with patients in earlier clinical trials using the hand-coded
prompting system and our interactions with caregivers.5                        water
  Space prevents a complete description of the dynamics, but
we mention some of the key intuitions underlying the model.
The probability of the user taking a speciﬁc “user action”
such as turning on the water—corresponding to a state change
in an environment variable (i.e., WO becoming true)—tends
to be higher at appropriate plan steps, but the probability de-
pends on the precise prompting history. For example, the          Figure 3: Possible hand locations.
longer the system waits for a response (modeled by NW ),
the less likely it is that the user will complete the current plan or predicted costs of completion too high.
step independently (i.e., without prompting). Furthermore, The design of the reward function is based on brief interac-
the more “unsuccessful” prompting has been for the current tions with caregivers, earlier clinical trials with patients using
step (modeled by PL and NP), the less likely it is that the hand-coded COACH, and evaluation of numerous versions of
patient will complete the step at all. Such “response” proba- MDP (rather than POMDP) policies. While the rewards seem
bilities vary formulaicly with Resp and Rgr . Higher values reasonable, ﬁne-tuning of the reward function is an ongoing
of Rgr are indicative of lower likelihood of eventual success, research project (see Section 5).
while success is more probable when Resp is high than when
it is low.6                                           Observations
  Activity status variables are updated deterministically as The handwashing task has two observables: the reported ﬂow
a function of environment variables (note that environment of water (on/off), and the reported location of the user’s
variables are themselves only partially observable) in the hand(s). The POMDP is designed to be integrated with a
obvious way. PS  may move back and forth through the  computer vision system that estimates hand position (and wa-
plan graph (since the user can regress, e.g., by re-wetting ter ﬂow indirectly) based on skin color [11]. The vision sys-
                                                                                     x, y
their hands), but MPS records the maximal step in the plan tem reports estimated hand position ( -coordinates) which
reached at any point, and never regresses. System variables is translated into one of six possible regions (see Fig. 3).
                                                                  25%
are updated deterministically as well (e.g., number of prompts We assume noise in the observation function that de-
NP is updated with each prompt for the current step, but reset tects hand position (i.e., the correct hand position is detected
                                                                     0.75
to zero when the plan step changes). Finally, the user variable with probability , while each incorrect position is de-
                                                                         0.05
Resp is static, and does not change value over time (though tected with probability . Similarly water ﬂow is detected
                                                                            0.75
our estimates of its value does).7                    correctly with probability . These probabilities are esti-
                                                      mated based on our prior experience, but a detailed empirical
Rewards                                               study is needed to assess these accurately.
Rewards are associated with various state transitions and
costs with speciﬁc actions. A large reward is given for full 3.2 A Fully Observable Model
task completion (+300) and smaller rewards (+3) are associ- The POMDP model can be made fully observable with two
ated with the (ﬁrst) achievement of each plan step to encour- simple changes. First, if we remove the hidden variable Resp,
age/reward even partial success (MPS is used to ensure re- a key source of partial observability disappears, though we
wards are not repeated). Action costs are also incorporated sacriﬁce the ability to customize behavior to speciﬁc individ-
to ensure that prompting only occurs when needed. Each uals.8 Second, if we assume the tracking system computes
prompt is given a small negative reward, with the more time- hand position and water ﬂow without error, the system be-
consuming speciﬁc prompts penalized slightly more than comes fully observable. The assumption of perfect observ-
simpler general prompts (the costs are -4, -5 and -7). The ability is not unreasonable if we use a switch sensor on the
cost of calling the caregiver should be set so that this action tap and additional cameras to disambiguate obscured views
only occurs if the predicted odds of completion are too low, and reduce the inherent noise in image processing.
  5Some versions of our model (see Section 5) include updates of 3.3 Computational Results
this prior using data produced by coding 21 hours of video capturing
600 trials of human caregivers interacting with patients. To study the feasibility of the model, we solved both the
  6The inﬂuence of Resp on user response is estimated based on MDP and POMDP formulations of the handwashing ADL.
the authors’ previous clinical experience. Planned clinical evalua- The cost of calling the caregiver in both trials was set very
tion of the POMDP policy will be used to assess this more precisely. high (−1000), to ensure that this action was never taken,
  7This is true for the time scales we currently consider, but certain
aspects of a user’s state, such as level of dementia, general respon- 8Customization based on other fully observable attributes, such
siveness, etc., can change (e.g., deteriorate) over longer periods. as hearing and visual ability, is still possible in an MDP. Time (s)     0         6         14         37557180104170

Key Frame

Plan Step    A          B         B          D         G          G         D          G          K
         "time to wash          "put some "rinse your         "pick up the "John, rinse "use the towel "thank you, John
 Prompt   your hands, John"     soap on    hands under         towel on   your hands" on your right" we’re all 
                                your hands" the water"         your right"                     done here"
Figure 2: Example sequence during a trial in which prompts were selected by the MDP policy. Prompts were read by a human caregiver.
The plan steps are those from Figure 1. The user turns the water on and off independently (at 6 and 160 seconds, respectively), but must be
prompted for all other steps. The user regresses at 71 seconds by putting more soap on his hands, which the system recognizes and thus gives
a second prompt to rinse hands.

as required by the evaluation procedure we describe in Sec- ing strategies for different users as beliefs about these users
tion 4. The version of the fully observable MDP we solved evolve.
has 12 variables (25,090,560 states) and 20 actions, rendering It is also interesting to note the customization of the
explicit state-based approaches impossible. However, due to POMDP policy based on its estimate of the Resp variable.
the DBN structure, we were able to solve this problem exactly When a patient tends to be slow to respond to prompts,
using the SPUDD algorithm [6]. An optimal policy was pro- it is better to wait several time steps before repeating the
duced in 64 minutes, and was represented using an ADD with prompt. For instance, when a patient has reached plan step
3, 284 internal nodes and 18 leaves. The optimal value func- G and was prompted to dry her hands two time steps ago, the
tion was an ADD having 139, 443 internal nodes and 106, 328 POMDP policy repeats the prompt when the probability of
leaves. We discuss evaluation of this policy below.   Resp =  high is sufﬁciently high, but waits when it is low.
  The POMDP model has one additional variable, hence a Similarly, when plan step J is reached and the patient was
state space of size 50,181,120, the same action space, and 12 prompted to turn off the water two time steps ago, the prompt
observations. It is far beyond the reach of any exact solu- is repeated only when responsiveness is believed to be high.
tion techniques or model-based approximation methods. As In contrast, the MDP policy doesn’t have the ability to esti-
a result, we developed a new approximation algorithm which mate the level of responsiveness since it is not directly ob-
exploits the structure in the system dynamics and rewards servable. As a result, in both cases it repeats the prompt at
(as represented by our ADDs). Perseus-ADD consists of the the risk of annoying a slower, less responsive patient.
Perseus algorithm [18], a randomized point-based version of
value iteration, reconstructed to take advantage of ADD struc- 4 Caregiver Evaluation
ture [16]. The algorithm results in a policy of 36 state-value While the evaluation of the MDP and POMDP policies in
functions (α-vectors), computed in 42.7 hours.        simulation is useful, the true value of the system can ulti-
  The relative quality of the MDP and POMDP policies  mately only be gauged in clinical trials. Clinical trials with
demonstrates the importance of accounting for noise and user Alzheimer’s patients are currently underway to test our re-
characteristics. While the POMDP policy is approximate, we sults. These trials are based on improved versions of the mod-
evaluated it in simulation from the starting state, using 500 tri- els (see Section 5). Results of these trials will be reported in
als of 60 steps, with Resp uniformly distributed in the initial a longer version of this paper.
belief state, and the speciﬁc value of Resp drawn randomly Before undertaking clinical trials, an efﬁcacy study of the
for each trial. The average value obtained by the POMDP MDP policy was undertaken to conﬁrm its plausibility be-
policy is 100.1 over 60 steps. The value of the optimal pol- fore applying it to dementia patients. In this study, an ac-
icy for the fully observable MDP (ignoring Resp) is 134.2 tor with considerable experience with dementia patients sim-
(which provides an upper bound on the value of the unknown ulated the behavior of a user in the handwashing ADL dur-
optimal POMDP solution). However, this MDP value cannot ing 33 trials, each of which was videotaped. This simulated
be realized in the partially observable environment. So we patient was guided using either the prompting strategy given
implemented the MDP policy in this environment by com- by the MDP policy, or by a professional caregiver with over
puting the most likely state at each stage of the simulation 30 years experience. During the caregiver trials, the caregiver
and applying the corresponding MDP policy choice. In sim- acted naturally, prompting using her own strategy. During the
ulation, this attains an average value of 95.6 over 60 steps. MDP trials, the same professional caregiver read (verbatim)
We see that the MDP model provides a reasonable approx- the prompts provided by the MDP policy, in order to prevent
imation for this POMDP despite its limitations. However, verbal distinction between caregiver and MDP trials. The HL
the full POMDP policy (despite only being solved approxi- and WO variables (describing the location of the actor’s hands
mately) outperforms the MDP policy by a signiﬁcant margin. and whether the water was on) were manually annotated by
The value of POMDP modeling is apparent when one consid- a researcher during the trials, thus fulﬁlling the perfect ob-
ers that the computational overhead in solving the policy is servability assumption of the MDP (note that using the vision
borne ofﬂine—once computed, the optimal policy is applied system would not have allowed accurate implementation of
in real-time without any signiﬁcant computation. All that the MDP policy). The videos were then viewed by 30 pro-
is required online is simple belief-state updating, the critical fessional caregivers (different from the prompter), who eval-
component in allowing the policy to choose different prompt- uated the performance of the prompting in each trial. These