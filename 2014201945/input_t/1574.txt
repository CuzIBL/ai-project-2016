                       The   COMPSET      Algorithm for Subset Selection

                                 Yaniv Hamo    and  Shaul Markovitch
                                   {hamo,shaulm}@cs.technion.ac.il
                     Computer Science Department, Technion, Haifa 32000, Israel


                    Abstract                          function which they try to optimize. It is therefore com-
                                                      mon to have modiﬁcations to these algorithms that trade be-
    Subset selection problems are relevant in many do- ing general for additional domain-speciﬁc knowledge. The
    mains. Unfortunately, their combinatorial nature  SAT domain is full of such variants [Gent and Walsh, 1993;
    prohibits solving them optimally in most cases. Lo- Hoos and Stutzle,¨ 2005] but they are common in other do-
    cal search algorithms have been applied to subset mains as well [Khuri and Back,¨ 1994; Evans, 1998].
    selection with varying degrees of success. This     In this paper we present a general modiﬁcation to known
    work presents COMPSET, a general algorithm for    local search algorithms which improve their performance on
    subset selection that invokes an existing local   SSPs. The idea behind it is to exploit attributes that are
    search algorithm from a random subset and its com- speciﬁc to search spaces of subset selection. Knowing that
    plementary set, exchanging information between    it is a subset search space allows us to infer which moves
    the two runs to help identify wrong moves. Prelimi- were likely to be wrong. By reversing these moves and try-
    nary results on complex SAT, Max Clique, 0/1 Mul- ing again, we start from a new context, and the probability
    tidimensional Knapsack and Vertex Cover prob-     to repeat the mistake is reduced. In experiments performed
    lems show that COMPSET improves the efﬁcient      on complex SAT, max clique, 0/1 multidimensional knapsack
    stochastic hill climbing and tabu search algorithms and vertex cover problems, the new method has shown to sig-
    by up to two orders of magnitudes.                niﬁcantly improve the underlying search algorithm.

                                                      2   The  COMPSET    Algorithm
1  Introduction
                                                      Subset selection can be expressed as a search in a graph. Each
The subset selection problem (SSP) is simply deﬁned: Given node (state) in the graph represents a unique subset. Edges
a set of elements E = {e1, e2, . . . , en} and a utility function correspond to adding or removing an element from the subset,
U : 2E 7→ R, ﬁnd a subset S ⊆ E such that U(S) is opti- thus there are n = |E| edges to every node. The following
mal. Many real-life problems are SSPs, or can be formulated ﬁgure shows the search graph for 3 elements.
as such. Classic examples include SAT, max clique, indepen-
dent set, vertex cover, knapsack, set covering, set partitioning,
feature subset selection (classiﬁcation) and instance selection
(for nearest-neighbor classiﬁers) to name a few.
  Since the search space is exponential in the size of E,
ﬁnding an optimal subset without relaxing assumptions is in-
tractable. Problems associated with subset selection are typ- A state S can be represented by a bit vector where bit S[i] is
ically NP-hard or NP-complete. Local search algorithms are 1 iff ei ∈ S. Moving to a neighboring state in the graph is
among the common methods for solving hard combinatorial equivalent to ﬂipping one bit.
optimization problems such as subset selection. Hill climb- Each state is associated with a utility value, which is the
ing, simulated annealing [Kirkpatrick et al., 1983] and tabu value of U on the subset it represents. Local search algo-
search [Glover and Laguna, 1993] have all been proven to rithms typically start from a random state and make suc-
provide good solutions in a variety of domains. The gen- cessive improvements to it by moving to neighboring states.
eral technique of random restarts is applicable to all of them, They vary from each other mainly in their deﬁnition of neigh-
yielding anytime behavior as well as the PAC property (prob- borhood, and their selection method.
ability to ﬁnd the optimal solution converges to 1 as the run- Using this representation, all local search algorithms are
ning time approaches inﬁnity).                        also applicable to subset selection. However, being general,
  The problem with these local search algorithms is, how- they overlook the speciﬁc characteristics of subset selection.
ever, that they are too general. The only heuristic they have COMPSET guides a given local search algorithm using knowl-
about the domain is in a form of a black-box, the utility edge speciﬁc to subset selection.2.1  Characteristics of Subset Selection              the above observations to try and identify wrong invocations
In a selection problem of n elements, there are n operators: of operators. It then cancels them (reverses their effect) and
                                                      resumes the run towards another local optimum or, hopefully,
F = {f1, f2, . . . , fn} where fi is the operator of toggling the the solution.
membership of element i in a set (if it was in the set remove
it , or add it if it was out). Applying fi is equivalent to ﬂip- Procedure COMPSET(S, LOCALSEARCHALG)
ping the ith bit in the bit vector representation. Throughout S ← S ; S ← S ; agree ← false
the following discussion we assume a single optimal subset 1     2
                        ∗                               loop until agree
(solution) which we donate S .                            LS ← LOCALSEARCHALG(S1)
  We make the following observations about subset search:
                                                          LS ← LOCALSEARCHALG(S2)
                   0
Observation 1. Let S be an arbitrary state (subset). From C ← σ(S, LS ) ∩ σ(S, LS )
any state S, there exists a subset of the operators, σ(S, S0) ⊆ if C is empty then
F , that when applied to S results in S0.                   agree ← true
                                                          else
Proof. Since S0, as S, is an n bits long vector, there are at S1 ← C(LS ) // apply all operators in C on LS
              0
most n bits of S that do not agree with S and need to be    S2 ← C(LS )
                                                        return the better between L and L
ﬂipped using an operator.                                                    S     S
                                                      end
Observation 2. Let S be the complementary state of S i.e.,
the state derived from S by ﬂipping all its bits. The subset of Given a start state S, COMPSET initiates two runs of
              ∗                             ∗
operators σ(S, S ) leading from S to the solution S , is the the given local search algorithm, one from S and one from
complementary subset of σ(S, S∗) in F . That is, σ(S, S∗) ∪ its complementary S. Once two local optima are achieved,
σ(S, S∗) = F and σ(S, S∗) ∩ σ(S, S∗) = ∅.             the series of operators that has led to each one is examined.
                                                      Every operator that appears in both series must be wrong
Proof. We need to show, that for every fi∈F either fi ∈ in one of them. We do not know which of the runs went
     ∗              ∗           ∗                ∗
σ(S, S ) or fi ∈ σ(S, S ). If S[i] = S[i] then fi ∈/ σ(S, S ) wrong, so we reverse the effect of such operators in both
                                            ∗
(it does not need to be ﬂipped). Moreover, if S[i] = S[i], then local optima. Once all obviously wrong operators are
                 ∗                                    undone, the local search is continued. The process repeats
necessarily S[i] 6= S[i], since in S all bits are ﬂipped. Thus,
          ∗              ∗                            upon encountering the next pair of local optima. When no
fi ∈/ σ(S, S ) → fi ∈ σ(S, S ). The same goes for the other
                           ∗                          conﬂicting operators exist, and the optimal solution was not
possible case, in which S[i] = S[i].                  found, COMPSET ends and returns the better of the two local
                                                      optima in hand.
  The inherent problem in ﬁnding σ(S, S∗) using local
                                                        The rational behind COMPSET is illustrated here:
search, is that operators are applied successively and their ef-
                                                                                         ∗  S
fect is not necessarily of monotonic improvement due to in-                          σ(S, S )
                                                                          LS
terdependencies between elements. Such non-monotonic be-                      S∗    S2
havior of U confuses local search algorithms and often makes
them trapped in local optima. In such a case, there are two                  ∗
                                                                S        σ(S, S )
                                                                     S1
options: either the search is progressing on the correct path                         L
to the solution (but the algorithm does not see a way of con-                          S
tinuing), or it is off the correct path altogether. It would be The solution S∗ is reachable by applying all operators from
beneﬁcial to distinguish between these two scenarios. σ(S, S∗) to S (in any order), and by applying all operators
  Consider two independent hill climbing runs, one from S
                                                      from σ(S, S∗) to S. The underlying search algorithm from S
and one from S. Given that the optimal solution is not found,
                                                      is in a correct path if it is using only operators from σ(S, S∗).
the two runs have stopped in local optima, LS and LS respec-
tively. We consider the subsets of operators leading from S However, a search can easily divert from this path, and it
to L and from S to L . By observation 2, it is not possible is often necessary for its overall convergence to the solution.
   S               S                                  Diversion occurs if an operator from σ(S, S∗) is applied to
that an operator fi appears in both operator subsets if they are               ∗
both on the path to S∗. If we do observe the same operator in S, or an operator from σ(S, S ) is applied S. The problem is,
both, it is a clear sign that one of them is wrong. This is the that since we do not know σ(S, S∗) or σ(S, S∗), it is difﬁcult
idea behind COMPSET, which is described next.         to detect such diversions. However, what we do know, is that
                                                      the solution S∗ conforms to σ(S, S∗) ∩ σ(S, S∗) = ∅. We
2.2  Description of the COMPSET  Algorithm            can use this fact to try and identify diversions.
Interdependencies between elements are distracting when Once stopped in local optima LS from S and LS from S,
searching for good solutions. Had all elements been inde- we check σ(S, LS) ∩ σ(S, L ). If the intersection is not
pendent, a simple linear search, which adds element after                      S
                                                      empty then by deﬁnition either LS or LS are off the path.
element as long as the utility value improves, would sufﬁce. Note, that if the intersection is empty, the local optima might
Local optima are an example where such interdependency
                                                      still be off path, because either σ(S, LS) uses an operator
brings the search to a full stop. It is likely that by applying  ∗                                    ∗
the operators in a different order, or eliminating some, the from σ(S, S ), or σ(S, LS) uses an operator from σ(S, S ).
local optimum would have been avoided. COMPSET uses   However, σ(S, LS) ∩ σ(S, LS) 6= ∅ means that for sure at least one of the local optima is off path.             resented by a conjunction of clauses (CNF) C1 ∧ . . . ∧ Cm.
   In general it is possible that the search algorithm would SAT is a classic SSP since we look for a subset of variables
 continue applying operators and ﬁnally return to the path, but that when assigned a true value, makes the entire formula
 being in a local optimum means that it has essentially ”given true. The utility function is the number of unsatisﬁed clauses
 up”. Elimination of all conﬂicting operators from both sides when assigning true to all variables in S:
 brings us to S1 and S2, LS → S1 and LS → S2. Since all
                                                             U(S)  ≡ |{Ci|Ci is false under S, 0 ≤ i ≤ m}|
 common operators were eliminated, σ(S, S1) ∩ σ(S, S2) =
 ∅ and thus S1 and S2 are on a possibly correct path. It is The global minimum for U is 0, for satisﬁed formulas. A
                                                  ∗
 still possible that σ(S, S1) contains operators from σ(S, S ) search algorithm using this utility function will attempt to
                                          ∗
 or that σ(S, S2) contains operators from σ(S, S ) thus still maximize the number of satisﬁed clauses, which is a general-
 being an obstacle for reaching the solution.           ization of SAT called MAX-SAT. Problem instances for SAT
   An important point to notice, is that S1 and S2 are not nec- were obtained from the SATLIB [Hoos and Stutzle,¨ 2000]
 essarily states that the algorithm has visited before. Groups of repository of random 3-SAT. We use problems from the sol-
 operators are simultaneously eliminated, an operation which ubility phase transition region1 [Cheeseman et al., 1991].
 interdependencies would prohibit had the operators were suc- • Max Clique - another classic SSP, where the goal is to
 cessively eliminated. COMPSET effectively switches to an- ﬁnd the maximum subset of vertices that forms a clique in
 other context which is mostly correct, in which the eliminated a graph. Given a graph G = (V, E) and a subset S ⊆ V , we
 operators can be tried again.                          deﬁne the following utility function:
                                                                ½
                                                                   |V | − |S|                 S is a clique
 3  Empirical Evaluation                                 U(S) ≡
                                                                   |V | − |S| + |V | + |S| · (|S| − 1) − |E | else
 The following algorithms were considered:                                                      S
•  Stochastic Hill Climbing (SHC) - starts from a random sub- A clique should be maximized but our implementation al-
 set, iteratively picks a neighboring subset (differs in exactly ways minimizes U, therefore we use |V | − |S|. Incomplete
 one element) in random and moves there if it has a better or solutions are penalized by the number of additional edges
 equal utility value. The simplicity of SHC often misleads; they require for being a clique (|S| · (|S| − 1) − |ES|), plus
 several works [Mitchell et al., 1994; Baluja, 1995] showed a ﬁxed value |V | that is used to separate them from the legal
 that SHC does not fall from the complex GA mechanism.  solutions. By striving to minimize U, the search algorithm
 In the SAT domain such stochastic local search (SLS) meth- ﬁnds feasible solutions ﬁrst, and then continues by minimiz-
 ods have been shown to be comparable with state-of-the-art ing their size. The global minimum of U corresponds to the
 domain-speciﬁc algorithms [Hoos and Stutzle,¨ 2005].   maximum clique. Problem instances were obtained from the
                                                                [    ]
•  Tabu Search (TS) [Glover and Laguna, 1993] - examines DIMACS  1993 benchmark for maximum clique.
 the neighborhood of the current state for the best replace- • 0/1 Multidimensional Knapsack (MKP) - the problem of
 ment. It moves to the chosen state even if it does not improve ﬁlling m knapsacks with n objects. Each object is either
 the current state, which might result in cycles. To avoid cy- placed in all m knapsacks, or in none of them (hence ”0/1”).
 cles, TS introduces the notion of a tabu list that stores the The knapsacks have capacities of c1, c2, . . . , cm. Each ob-
 last t (tabu tenure) operators used. TS is prevented from us- ject is associated with a proﬁt pi and m different weights,
 ing operators from the tabu list when it generates the neigh- one for each knapsack. Object i weighs wij when put into
 borhood to be examined, unless certain conditions called as- knapsack j. The goal is to ﬁnd a subset of objects yielding
                                                        the maximum proﬁt without overﬁlling any of the knapsacks.
 piration criteria are met. In this paper we use a common                               P
 aspiration criterion that allows operators which lead to better                          n
                                                        Knapsack j is overﬁlled in state S iff i=1 S[i] · wij > cj.
 state than the best obtained so far.                   Let k be the number of overﬁlled knapsacks. We deﬁne:
•  Simulated Annealing (SA) [Kirkpatrick et al., 1983] - be-             n   Pn
                                                                           −      S  · p  k=0
 gins at high temperature which enables it to move to arbitrary   U(S) ≡       i=0 [i]  i
                                                                           k              k > 0
 neighboring states, including those which are worse than the
 current one. As the temperature declines, the search is less The utility of feasible subsets is simply their proﬁt (with
 likely to choose a non-improving state, until it settles in a minus sign for minimization purposes). Infeasible solu-
 state which is a local minimum from which it cannot escape tions are penalized for each knapsack they overﬁll. Prob-
 in low temperatures.                                   lem instances for MKP were obtained from the OR-library
                                                        [Beasley, 1997].
   To test the effectiveness of COMPSET we have applied it to
 SHC and TS. COMPSET is not applicable to SA since SA be- • Vertex Cover - the goal is to ﬁnd the smallest subset of
 gins with a high temperature at which it randomly moves far vertices in a graph that covers all edges. Given a graph
 from the initial state. The concept of COMPSET is to set new G = (V, E), we deﬁne:
 start points for the underlying algorithm and by randomly         ½
                                                                     |S|                S covers all edges
 moving away from them SA defeats its purpose.              U(S) ≡
                                                                     |S| + |V | + |E\E | else
   The algorithms were tested in the following domains:                             S
•  Propositional Satisﬁability (SAT) - the problem of ﬁnding a 1Random 3-SAT problem with 4.26 clauses per variable that are
 truth assignment that satisﬁes a given boolean formula rep- the hardest to solve using local search.For legal vertex covers, U takes values less than or equal to COMPSET/SHC. The average success ratio of COMPSET/TS
|V |. Incomplete solutions are penalized by the number of is 85% and of COMPSET/SHC is 76%. For comparison, the
edges they do not cover, plus a ﬁxed value |V | that is used to success ratios for SA, TS and SHC are 37%, 23% and 28%
separate them from the legal solutions. The global minimum respectively. The speedup factor gained by using COMPSET
of U corresponds to the optimal vertex cover.         is as large as 462 for SHC (instance uf50-011) and as large
The complementary graphs of the instances from the original as 156 for TS (instance uf75-013). Note that these are lower
DIMACS benchmark were taken, so that the known maxi-  bounds since SHC and TS were terminated because of re-
mum clique sizes could be translated to corresponding mini- source limit for some of the runs.
mum vertex covers2.                                     The best performing algorithms in the Max Clique do-
                                                      main are COMPSET/SHC and SHC with average success
3.1  Experimental Methodology                         ratios of 94% and 80% respectively. The speed up fac-
We have tested ﬁve algorithms: SHC, TS, SA (with T =  tor of COMPSET/SHC over SHC is as large as 14 (instnace
100, α = 0.95), COMPSET over SHC and COMPSET over TS. sanr200 0.7).
TS was used with t = 5 for all domains other than SAT, and In the Knapsack domain, the best performing algorithm is
t = 9 for SAT. Each run was limited to 107 U evaluations. COMPSET/SHC with an average success ratio of 89%. For
  All algorithms use random restart to escape from local comparison, the success ratios for TS, SA, COMPSET/SHC
optima when they have still not exhausted their evaluations and SHC are 50%, 25%, 19% and 17% respectively. The
quota. They use random restart also when there is no im- speedup factor gained by using COMPSET is as large as 127
provement over the last k steps. We use k = 10 for domains for TS (instance WEISH07) and as large as 3.8 for SHC (in-
other than SAT, and k = 20 for SAT. SAT is characterized by stance WEISH04).
wide and frequent plateaus [Frank et al., 1997] therefore we The best performing algorithms in the Vertex Cover do-
chose higher values of t and k for it.                main are COMPSET/SHC and SHC with average success ra-
  100 runs of each algorithm were performed on each prob- tios of 94% and 77% respectively. SA is relatively close with
lem in the test sets. Each run started from a random state, that 71% but TS is far behind with 23%, improved by COMPSET
was common to all algorithms. We measured the number of to 28%. The speedup factor gained by using COMPSET is as
U evaluations needed to obtain the optimal solution in each large as 310 for TS (instance hamming6-2) and as large as 10
run, as well as the time taken.                       for SHC (instance sanr200 0.7).
                                                        Another interesting statistics is the number of random
3.2  Results                                          restarts required by the underlying search algorithm and
The results are summarized in Tables 1, 2, 3 and 4. For COMPSET, as well as the number of operator elimina-
brevity, we did not include the timing information in these tions performed by COMPSET and how many operators they
tables. The considered algorithms do not introduce a signif- spanned. We have collected this data throughout 100 runs on
icant overhead, so the execution time is a linear function of the p hat1000-1 vertex cover problem, a graph of 1000 ver-
the number of U evaluations. The tables show the charac- tices. SHC required 517.37 random restarts on average (in
teristics of the problem instance, followed by the number of each run), while COMPSET required only 3.13. COMPSET
successful runs (columns titled #ok) and the average number has performed 20.52 operator eliminations, reversing the ef-
of U evaluations for each algorithm. A successful run is a fect of 2.97 operators each time.
run in which the algorithm has found the optimal solution
within the limit. We tested the statistical signiﬁcance of the 4 Conclusions and Future Work
improvement introduced by COMPSET using the Wilcoxon
                                                      In this paper, we have provided useful insights into the do-
matched-pairs signed-ranks test with the extension by Etzioni
                                                      main of subset selection. We have realized that using lo-
and Etzioni [1994] to cope with censored data3. A ”+” sign in
                                                      cal search, paths from complementary subsets to the solution
the sg. column between SHC and COMPSET/SHC indicates
                                                      must be distinct in terms of the operators used. This has led
that COMPSET improved SHC with p < 0.05. A ”-” sign in-
                                                      us to conclude that if the paths contain common operators, it
dicates that SHC performed better with p < 0.05. A ”?” sign
                                                      may serve as an indication of a mistake. To test our conjec-
indicates that the difference is not signiﬁcant. Whenever it is
                                                      ture, we introduced COMPSET, a new guiding policy for local
not possible to draw deﬁnitive conclusions since there is too
                                                      search algorithms in the context of SSP. The results show a
much censored data, n/a appears. The same holds for the sg.
                                                      signiﬁcant improvement over both TS and SHC by up to two
column between TS and COMPSET/TS.
                                                      orders of magnitudes.
  The superiority of COMPSET over the other algorithms is
                                                        We currently in the process of running COMPSET on other
striking, both in the number of evaluations, and the num-
                                                      subset selection domains, progressing towards a better under-
ber and difﬁculty of instances solved. In the SAT do-
                                                      standing of its behavior. One interesting direction is to re-
main, the best performing algorithms are COMPSET/TS and
                                                      search for ways to incorporate knowledge of the entire search
  2Note that while it is possible to take the complementary graph, paths, instead of only the local minima at their end. In ad-
solve the Max Clique problem, and then translate back to Vertex dition, it is beneﬁcial to ﬁnd out how characteristics of a
Cover, none of the algorithms in this paper has done so. speciﬁc problem affect its performance. Overall, the general
  3The information about runs in which the solution was not found idea of incorporating such SSP speciﬁc insights seems to be
within the given bound is called truncated or censored. a promising lead to better subset selection algorithms.                                       3-SAT Instances                 SHC                  COMPSET/SHC                TS                  COMPSET/TS                SA
                                    name       vars   clauses    #ok       evals     sg.   #ok       evals      #ok      evals      sg.   #ok      evals      #ok       evals
                                  uf20-011       20        91    100          211     +    100          167     100          309     ?    100          275      82   1,800,168
                                  uf20-012       20        91    100          115     ?    100          102     100          190     ?    100          201    100          197
                                  uf20-013       20        91    100          576     ?    100          655     100        1,089     ?    100          940      57   4,300,196
                                  uf20-014       20        91    100          590     ?    100          596     100          872     ?    100          863      72   2,800,287
                                  uf20-015       20        91    100          243     ?    100          256     100          421     ?    100          361      98     201,003
                                  uf50-011       50       218      74   5,920,013     +    100       12,792     100      160,575     +    100       17,250      11   8,900,193
                                  uf50-012       50       218    100    1,162,273     +    100       10,624     100       36,955     ?    100       35,072      22   7,800,249
                                  uf50-013       50       218    100    1,682,981     +    100         3,803    100       45,616     +    100        9,275      65   3,501,795
                                  uf50-014       50       218    100    1,995,884     +    100         6,704    100       66,185     +    100       14,317      40   6,001,598
                                  uf50-015       50       218      99   1,005,804     +    100         2,547    100       33,894     +    100        7,335      68   3,201,009
                                  uf75-011       75       325       0            -    +    100       80,928      16    9,137,745     +    100      142,969      37   6,306,563
                                  uf75-012       75       325       0            -    +    100      409,036      12    9,375,096     +    100      579,683       5   9,500,223
                                  uf75-013       75       325       0            -    +    100         9,700     63    5,890,614     +    100       37,587      56   4,404,356
                                  uf75-014       75       325       0            -    +    100       22,677      50    7,364,576     +    100       77,866      41   5,904,975
                                  uf75-015       75       325       0            -    +    100       89,098      27    8,595,672     +    100      179,802      53   4,762,145
                                  uf100-011     100       430       0            -    +    100      289,359       0             -    +    100      450,070      16   8,404,825
                                  uf100-012     100       430       0            -    +    100      130,835       0             -    +    100      309,667      37   6,321,626
                                  uf100-013     100       430       0            -    +    100      158,180       0             -    +    100      376,166      40   6,011,208
                                  uf100-014     100       430       0            -    +    100      872,275       0             -    +    100      966,083      41   6,175,183
                                  uf100-015     100       430       0            -    +    100      283,024       0             -    +    100      361,632      19   8,110,739
                                  uf125-011     125       538       0            -    +    100      544,188       0             -    +    100      496,277      28   7,211,118
                                  uf125-012     125       538       0            -    +    100      786,882       0             -    +    100    1,048,369      21   7,908,011
                                  uf125-013     125       538       0            -   n/a     52   7,202,045       0             -    +     87    4,471,437      11   8,906,967
                                  uf125-014     125       538       0            -   n/a     46   7,653,790       0             -   n/a    67    6,388,535       4   9,601,212
                                  uf125-015     125       538       0            -    +    100    1,574,893       0             -    +    100    1,597,965      10   9,001,632
                                  uf150-011     150       645       0            -    +    100    1,129,916       0             -    +    100      650,899      66   3,458,095
                                  uf150-012     150       645       0            -   n/a      7   9,525,999       0             -   n/a    48    6,722,510      17   8,332,034
                                  uf150-013     150       645       0            -    +      82   4,429,762       0             -    +    100    1,037,124      64   3,750,319
                                  uf150-014     150       645       0            -   n/a     49   6,748,236       0             -    +     97    3,384,813      15   8,507,697
                                  uf150-015     150       645       0            -   n/a     11   9,373,759       0             -   n/a    48    7,193,000      15   8,517,484
                                  uf200-011     200       860       0            -   n/a      2   9,811,767       0             -   n/a     7    9,703,756      10   9,013,804
                                  uf200-012     200       860       0            -   n/a      0            -      0             -   n/a    24    8,434,746      14   8,642,899
                                  uf200-013     200       860       0            -   n/a      7   9,506,131       0             -   n/a    39    7,769,246      15   8,546,974
                                  uf200-014     200       860       0            -   n/a      2   9,857,446       0             -   n/a    41    6,907,585      40   6,121,901
                                  uf200-015     200       860       0            -   n/a      1   9,900,146       0             -   n/a     3    9,766,815       4   9,648,972

                                                   Table 1: SAT: average over all 100 runs, including censored data


                                             Graphs                     SHC                  COMPSET/SHC               TS                   COMPSET/TS               SA
                                      name           |V |   opt   #ok       evals     sg.   #ok      evals      #ok       evals     sg.   #ok      evals       #ok      evals
                                  brock200  1       200     21      41   7,953,200     +     98    2,485,541       0            -   n/a      0            -     24   8,880,969
                                  hamming6-2          64    32    100          659     ?    100          633      80   2,984,249     +    100       14,163     100        1,129
                                  hamming6-4          64      4   100          302     ?    100          275    100         1,794    ?    100        1,807     100         517
                                  hamming8-2        256    128    100         4,317    ?    100        4,519       6   9,402,266    n/a    14    8,612,975     100        6,486
                                  hamming8-4        256     16    100         8,924    +    100        6,609      45   5,514,223    n/a    54    4,619,182     100      18,546
                                  hamming10-2      1024    512    100       36,837     ?    100       38,312       6   9,438,856    n/a      6   9,438,856     100      54,520
                                  hamming10-4      1024     40      62   6,716,761    n/a    70    6,336,176       0            -   n/a      0            -     36   7,956,686
                                  johnson8-2-4        28      4   100            81    ?    100           90    100          299     ?    100          305     100         204
                                  johnson8-4-4        70    14    100         1,208    +    100          898      45   5,575,650     +     97    1,005,066     100        2,802
                                  johnson16-2-4     120       8   100          740     ?    100          631    100         6,470    ?    100        6,305     100         745
                                  johnson32-2-4     496     16    100         4,661    ?    100        4,661      83   1,798,068     +     85    1,600,804     100        4,843
                                  p hat700-1        700     11      38   8,029,518     +     92    3,471,758       1   9,902,542    n/a      1   9,902,542       6   9,658,510
                                  p hat700-2        700     44    100      361,250     +    100       92,712       1   9,902,564    n/a      1   9,902,564     100     639,270
                                  p hat700-3        700     62    100      912,534     +    100      224,936       0            -   n/a      0            -    100   1,513,576
                                  p hat1000-1      1000     10      92   3,764,601     +    100      891,693       4   9,619,971    n/a      4   9,619,971      69   6,161,992
                                  p hat1000-2      1000     46    100    1,177,655     +    100      211,710       0            -   n/a      0            -    100   1,645,523
                                  p hat1000-3      1000     68      43   7,490,258     +    100    1,253,011       0            -   n/a      0            -     31   8,610,929
                                  p hat1500-1      1500     12       0            -   n/a      3   9,926,760       0            -   n/a      0            -      0            -
                                  p hat1500-2      1500     65      99   2,215,890     +    100      369,480       0            -   n/a      0            -     98   2,629,112
                                  p hat1500-3      1500     94      86   4,982,543     +    100    1,943,943       0            -   n/a      0            -     73   5,884,335
                                  sanr200 0.7       200     18    100    2,189,803     +    100      151,344       0            -   n/a      1   9,900,505      91   3,530,091
                                  sanr200 0.9       200     42      96   2,871,830     +    100      530,846       0            -   n/a      0            -     73   5,535,066
                                  sanr400 0.5       400     13      26   8,561,953     +     86    4,167,521       0            -   n/a      0            -      7   9,683,128
                                  sanr400 0.7       400     21      37   8,029,818     +     95    3,493,629       0            -   n/a      0            -     11   9,252,956

                                        Table 2: Maximum Clique: average over all 100 runs, including censored data

References                                                                                                  [DIMACS, 1993]                 DIMACS. Challenge problems for maxi-
                                                                                                                 mum clique, dimacs.rutgers.edu., 1993.
[Baluja, 1995]            S. Baluja. An empirical comparison of seven
                                                                                                            [Etzioni and Etzioni, 1994]                    O. Etzioni and R. Etzioni. Statis-
     iterative and evolutionary function optimization heuristics.
                                                                                                                 tical methods for analyzing speedup learning experiments.
     Technical Report CMU-CS-95-193, School of Computer
                                                                                                                 Machine Learning, 14(1):333–347, 1994.
     Science, CMU, 1995.
                                                                                                            [Evans, 1998]            Isaac K. Evans. Evolutionary algorithms for
[Beasley, 1997]             J. E. Beasley. OR-library: a collection of test                                      vertex cover. In V. W. Porto, N. Saravanan, D. Waagen,
     data sets. Technical report, Management School, Imperial                                                    and A. E. Eiben, editors,                  Evolutionary Programming VII,
     College, London, 1997.                                                                                      pages 377–386, 1998.
[Cheeseman            et al., 1991]         P. Cheeseman, B. Kanefsky, and                                  [Frank      et al., 1997]         J. Frank, P. Cheeseman, and J. Stutz.
     W. M. Taylor. Where the really hard problems are. In                                                        When gravity fails: Local search topology.                              Journal of Ar-
     Proceedings of IJCAI-91, pages 331–336, 1991.                                                               tiﬁcial Intelligence Research, 7:249–281, 1997.