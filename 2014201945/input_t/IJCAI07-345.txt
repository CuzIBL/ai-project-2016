       Bayesian Tensor Inference for Sketch-based Facial Photo Hallucination

                          Wei Liu†       Xiaoou Tang†‡       Jianzhuang Liu†
         †Dept. of Information Engineering, The Chinese University of Hong Kong, Hong Kong
                  ‡Visual Computing Group, Microsoft Research Asia, Beijing, China
                      {wliu5, jzliu}@ie.cuhk.edu.hk and xitang@microsoft.com

                    Abstract                                              groundtruth 
                                                                       photo-sketch pair
    This paper develops a statistical inference ap-
    proach, Bayesian Tensor Inference, for style trans-
    formation between photo images and sketch im-
    ages of human faces. Motivated by the rationale
    that image appearance is determined by two co-
    operative factors: image content and image style,
    we ﬁrst model the interaction between these fac-
    tors through learning a patch-based tensor model.
    Second, by introducing a common variation space,
    we capture the inherent connection between photo     sketching                          hallucinating
    patch space and sketch patch space, thus building
    bidirectional mapping/inferring between the two
    spaces. Subsequently, we formulate a Bayesian ap-
    proach accounting for the statistical inference from
    sketches to their corresponding photos in terms
    of the learned tensor model. Comparative ex-
    periments are conducted to contrast the proposed
    method with state-of-the-art algorithms for facial
    sketch synthesis in a novel face hallucination sce-
    nario: sketch-based facial photo hallucination. The             (a) (b) 
    encouraging results obtained convincingly validate Figure 1: Bidirectional transforms on photo-sketch pairs. (a)
    the effectiveness of our method.                  Forward transform: synthesizing a sketch image from a photo
                                                      image; (b) backward transform: hallucinating a photorealistic
1  Introduction                                       image from a sketch image.
Recently, machine learning becomes more and more popu-
lar applied to the computer vision community. Various ap- For the particular image class of human faces, the trans-
plications and methods that learn low-level vision have been form between photo-realistic faces and their associative
proposed in the classical literature [Freeman et al., 2000].In sketch drawings has shown promising applications in the fu-
this paper, we focus on a fascinating vision topic: automatic ture. In recent years, some works have been done to ad-
image sketching which automatically generates alike sketch dress the issues of synthesizing sketches from photos [Chen
images from photo images. Sketches are the simplest form et al., 2001; Tang and Wang, 2004; Liu et al., 2005a]
of drawings because they consist of only drawing lines. The and sketch-based face recognition [Tang and Wang, 2004;
artists can distill the identifying characteristics of a photo and Liu et al., 2005a]. However, to the best of our knowledge,
highlight them with a small number of critical strokes. a more difﬁcult issue - the backward transform from sketches
  Implementing the great idea of learning vision, success- to photos - has not been seriously addressed. In this paper,
ful image sketching techniques try to observe and learn from we develop a novel research topic: hallucinating photorealis-
the artist’s works, and hence generate vivid and expressive tic faces from sketches, which is termed as sketch-based fa-
sketches. As a result, example-based methods are widely cial photo hallucination. We design a new face hallucination
studied in the latest years. Given a set of training images technique to fulﬁll the intractable backward transform. We
and their associated sketches drawn by artists, it is of interest also consider the forward and backward transforms together
to generate a sketch image automatically from an input image in order to explore the inherent relation between the bidirec-
with the help of machine learning techniques.         tional transforms shown in Fig. 1.

                                                IJCAI-07
                                                  2141  Considering the complexity of image spaces and the con- the higher-order tensor D as follows1
spicuous distinction between photos and sketches, global lin-
                                                          D   =   C×1 U1  ×2 U2 ×3 U3
ear models such as [Tang and Wang, 2004; Liu et al., 2005a]
tend to oversimplify this problem. Therefore, we try to ex-   =   C×1 Upatches ×2 Ustyles ×3 Ufeatures, (1)
tract the local relations by explicitly establishing the connec- where C, known as the core tensor, governs the interaction
tion between two feature spaces formed by a patch-based ten- between the mode matrices U1, ···, UN . Mode-n matrix Un
sor model. To hold the statistical dependencies between pair- contains the orthonormal vectors spanning the column space
wise patches with two styles more precisely and ﬂexibly, we of matrix D(n) resulting from mode-n ﬂattening (unfolding)
present a Bayesian Tensor Inference approach that incorpo- D. Deﬁning a tensor T = C×3 Ufeatures as TensorPatches,
rates the advantages of multilinear analysis techniques based then we have
on tensor into Bayesian statistics.
                                                                  D   T×   U       ×  U      .
  The rest of this paper is organized as follows. In Section 2,     =     1  patches 2  styles        (2)
we elicit a tensor model for a facial image ensemble. The de- So far, we succeed in decomposing the two-modal patch
tailed rationale and algorithm for Bayesian Tensor Inference feature space into the common variation space spanned by
                                                                  m×m
are presented in Section 3. Experimental results are shown in Upatches ∈ and the special variation space spanned
                                                                   2×2
Section 4 and conclusions are drawn in Section 5.     by Ustyles ∈   .
                                                        For any patch whether it is photo- or sketch-style, its cor-
2  Tensor Model                                       responding tensor representation is
                                                                             T     T
Recently, multilinear algebra and tensor modeling have at-        P = T×1   w  ×2 sk ,k=1,  2         (3)
tracted considerable attention in both computer vision and  w
computer graphics communities. Research efforts apply- where   contains patch parameters encoding the common
                                                      characteristics of pairwise patches, and sk, capturing style pa-
ing tensor cover a broad range of topics including face                                        k
                     [                                rameters reﬂecting the special properties of style (1 denotes
modeling and synthesis Vasilescu and Terzopoulos, 2002;                                   k
                                   ]                  photo-style, 2 denotes sketch-style), is the -th row vector of
Wang and Ahuja, 2003; Vlasic et al., 2005 , super-resolution U     wT      i              U
[             ]                                         styles.When   is the -th row vector of patches, the ten-
Liu et al., 2005b ,etc.                                                    i                   k
  Motivated by previous multilinear approaches, we make sor representation of the -th training patch with -th style is
                                                      obtained. Its vector representation can be derived via mode-
use of a novel tensor model to exclusively account for the                        P         f  P  T
representation of images with two styles: photo-style and 1(or 2, 3) ﬂattening the subtensor ,thatis,( 1( )) .
                                                        For a new patch pair (x, y), x represents the photo-style
sketch-style. As small image patches can account for high- y
level statistics involved in images, we take patches as con- and denotes the sketch-style. Their tensor representations
stitutive elements of the tensor model. Based on a corpus can be learned in line with eq. (3) by
                                                                               T     T          T
containing image patches with photo- and sketch-styles, we       P(x)=T×1    w   ×2 s1 = A1 ×1 w
arrange all these patches into a high-order tensor which will    P y    T×   wT  ×  sT   A  ×  wT ,
sufﬁce to encode the latent connection between the two styles.    ( )=      1     2  2 =  2  1        (4)
                                                                            T                T
                                                      where both A1 = T×2  s1 and A2 = T×2  s2 are constant
2.1  TensorPatches                                    tensors. Mode-1 ﬂattening eq. (4) results in
Based on the observation that both styles, i.e. photo- and                        T
                                                                      x =(f1(A1))   w =Axw
sketch-styles, share some common characteristics and each                         T
style possesses its special traits, we assume the existence           y =(f1(A2))   w =Ayw.           (5)
of decomposition of the patch feature space into the com- ∈d×m         ∈d×m
mon variation space, which reﬂects the commonalities shared Ax   and Ay         are called inferring matrices.
                                                      The shared parameter vector w, expected to be solved, exists
by both styles, and the special variation space. Relying on
                                                      in the common variation space. We solve it through mapping
this rationale, we employ multilinear algebra to perform ten-
sor decomposition on one large patch ensemble carrying two pairwise patches into the common variation space as follows
modalities.                                                                  w =Bxx
  Let us divide training pairwise images into overlapping                    w =Byy,                  (6)
small square patches which are assumed to be of the same
                                                                     T   −1  T              T   −1  T
size. m pairs of patches within a spatial neighborhood located where Bx =(Ax Ax) Ax and By =(Ay Ay) Ay are
in images are collected to form a high-order tensor. Follow- called mapping matrices. Fig. 2 illustrates the relations
ing the non-parametric sampling scheme [Chen et al., 2001], among x, y, w.
we allow m to be smaller than the length of each patch fea- When one of (x, y) is unknown, inferring the counterpart
ture vector d. Resulting from the conﬂuence of three modes style from the known style of a patch is the objective of image
related to patch examples, patch styles and patch features, a sketching or hallucination. Combining eq. (5) and eq. (6), a
3-order tensor D∈m×2×d   is built by grouping pairwise coarse estimation for y can be derived as
patches pertaining to the same neighborhood.
                                                                          y ≈ AyBxx,                  (7)
  This paper adopts the High-Order SVD [Lathauwer et al.,
2000] or N-mode SVD  [Vasilescu and Terzopoulos, 2002],  1Details for tensor decomposition can be found in [Lathauwer et
both of which are the generalizations of SVD, to decompose al., 2000; Vasilescu and Terzopoulos, 2002], we will not elaborate.

                                                IJCAI-07
                                                  2142                                                      d×d, and TensorPatches T is obtained by forming the prod-
                 Photo Patch Space
                                                      uct C×4 Ufeatures.
                                                        Signiﬁcantly, the two factors (people, position) are cru-
      Bx: mapping                   Ax: inferring     cial to determine a concrete patch and encoded in row vec-
                                                      tor spaces of mode matrices Upeople and Upositions.To
                      Common                          remove factor (people, position) redundancies and suppress
                      Variation                       the effects of noise, a truncation of the two mode matrices
                       Space                          is needed. In this paper, we adopt the N-mode orthogonal
                                                      iteration algorithm in [Vasilescu and Terzopoulos, 2003] to
      By: mapping                   Ay: inferring     perform factor-speciﬁc dimensionality reduction, outputting
                                                                                                n∗r
                                                      converged truncated mode matrices Uˆ people ∈ 1 (r1 <
                 Sketch Patch Space                                   m∗r2
                                                      n), Uˆ positions ∈ (r2 <m) along with the rank-reduced
                                                      approximation of tensor D
Figure 2: Illustration of relations among common variation  Dˆ  T×ˆ   Uˆ     ×  Uˆ       ×  Uˆ    .
space, photo patch space and sketch patch space.              =     1  people 2  positions 3  styles  (8)
                                                        In analogy to the last subsection, for a new patch pair
which coincides with the path shown in Fig. 2: mapping the (xj , yj) residing in the j-th spatial position of face images,
“Photo Patch Space” to the “Common Variation Space” from their tensor representations can be derived with the similar
which inferring the “Sketch Patch Space” .            form as eq. (4)
  Importantly, the coarse estimation offered by eq. (7) is              T     T     T            T
                                                         P(xj)=T×ˆ   1 w  ×2 v  ×3 s  = A1j ×1 w
consistent with sketch synthesis methods [Tang and Wang,                      j     1
                                                                        T     T    T            T
2004][Liu et al., 2005a] under particular conditions. Consid- P(yj)=T×ˆ 1 w ×2 vj ×3 s2 = A2j ×1 w ,  (9)
ering (x, y) as the holistic photo-sketch image pair of faces,
                                                            vT    sT      j      k
when Ax and Ay are sample matrices whose columns are vec- where j and k is the -th and -th row vector of the mode
tors recording the training sketch and photo images, eq. (7) matrix Uˆ positions and Uˆ styles, respectively. Both A1j =
is equivalent to the eigentransform method [Tang and Wang,   T     T                  T     T
                                                      T×ˆ 2 vj ×3 s1 and A2j =  T×ˆ 2 vj ×3 s2 are constant
2004] where w contains linear combination coefﬁcients w.r.t.
                                                      tensors. The people parameter vector w ∈r1×1 maintains
training faces. In the case that Ax contains K nearest neigh-
                                                      to be solved for new patch pairs.
bors of input photo patch x in the training set and Bx collects
associative sketches of these neighbors, eq. (7) resembles the Mode-1 ﬂattening eq. (9) results in
                             [              ]                                      T      j
local geometry preserving method Liu et al., 2005a .Fur-             xj =(f1(A1j))  w  =Axw
thermore, eq. (7) can be thought as the unconstrained solution                     T      j
of LLE [Roweis and Saul, 2000] where w is the weighting              yj =(f1(A2j))  w  =Ayw,         (10)

vector for locally linear reconstruction.                    j   j    d×r1
                                                      where Ax, Ay ∈     are position-dependent inferring ma-
2.2  TensorPatches for Facial Image Ensembles         trices. Note that the people parameter vector w is shared
                                                                       x , y m
Due to the structural characteristics of face images, we adopt in all patch pairs ( j j)j=1 appearing in the same per-
                                                      son. Deﬁning a concatenated photo feature vector Ix =
a higher-order tensor rather than the 3-order tensor modeled          md×1
                                                      [x1; ···; xm] ∈     whose sketch counterpart is Iy =
on generic images. For the facial image ensemble, it necessi-        md×1
                                                      [y1; ···; ym] ∈     and two enlarged md × r1 matrices
tates modeling both global structures and local details of face 1    m            1       m
images together.                                      Ax =[Ax;  ···;Ax ] and Ay =[Ay; ···;Ay ],wehave
  Given the multi-factor (people, spatial positions of patches)              I      w
and multi-modal (styles) natures of these patches, we develop                 x = Ax
a 4-order tensor model to explicitly account for both styles                 Iy = Ayw.               (11)
and constituent factors of facial patches. Suppose we have n
                                                      So we can solve the parameter vector w by the least square
pairs of face images available for training, of which each is di-
                                                      method
vided into m overlapping square patches. With two styles, the
                                                                              −1
length of each patch feature vector is d. Therefore, patches               T        T
                                                                    w =   Ax Ax    Ax Ix = BxIx
are inﬂuenced by four modes: people, patches, styles and fea-
                         n×m×2×d                                              
                   D∈                                                     T    −1  T
tures. A 4-order tensor           is naturally built by             w                 I      I ,
grouping all photo-sketch patches sampled from the training           =   Ay Ay    Ay  y = By y      (12)
faces. Perform tensor decomposition on D                          T        T
                                                      where both Ax Ax and Ay Ay are invertible because md >>
D      C×1  Upeople ×2 Upositions ×3 Ustyles ×4 Ufeatures
   =                                                  r1 which is always satisﬁed throughout this paper.
   =   T×1  Upeople ×2 Upositions ×3 Ustyles,
where the core tensor C governs the interaction between 4 3 Bayesian Tensor Inference
                                              n×n
modes encoded in 4 mode matrices: Upeople ∈      ,   The learned tensor representations eq. (9) model the latent
              m×m              2×2
Upositions ∈     , Ustyles ∈     and Ufeatures ∈    connection between Ix and w,orIy and w. The concluded

                                                IJCAI-07
                                                  2143relations eq. (5), (6), (11), and (12) originate from factor de- Signiﬁcantly, function (18) is quadratic, and consequently
composition which is implemented through tensor decompo- minimizing it is a quadratic optimization problem (uncon-
sition. Although eq. (7) gives a direct inference from x to y, strained) where a globally optimal solution exists.
we lack analysis in statistical dependencies between x and y. Taking the derivative of E with respect to w and a respec-
  Utilizing the merits of super-resolution techniques [Free- tively, the partial gradients of E can be calculated as
man et al., 2000; Baker and Kanade, 2002], we incorporate       T                  T                 
                                                      ∂E        Ay Ay    I          Ay Iy   BxUa  + Bxμ
the learned relations eq. (11) and (12) in which the tensor =2        +      w − 2        +               ,
model entails into a Bayesian framework. The entire infer- ∂w    λ1     λ2            λ1         λ2
ence process is thus called the Bayesian Tensor Inference.                        
                                                                    T  T                    T  T
                                                         ∂E        U  Bx BxU     −1      2U   Bx (w − Bxμ)
3.1  Formulation                                             =2               +Λ     a −                  .
                                                          ∂a           λ2                        λ2
We fulﬁll the backward transform Iy → Ix through the peo-
ple parameter vector w by taking these quantities as a whole By ∂E/∂w = 0 and ∂E/∂a = 0, we obtain a pair of solu-
                                                              ∗  ∗
into a global optimization formulation. Our inference ap- tions {w , a } that is unique, and so must be globally opti-
                                                                                  ∗
proach is still deduced from canonical Bayesian statistics, ex- mal. The optimal MAP solution a is hereby given as
                                           Ix                                        −1
ploiting PCA to represent the photo feature vector to be    ∗      T  T            −1      T  T
hallucinated. The advantage of our approach is to take into a =  U   Bx C BxU+λ2Λ        U   Bx
                                              l
account the statistics between the latent variable a ∈ and                     T           
I                                                                      λ2(I − C)A  Iy
 x. We write the eigenface-domain representation after per-                      y   −      μ  ,
                                      (i) n                                            C Bx          (19)
forming PCA on the training photo vectors {Ix }i=1                           λ1

             Ix =Ua  + μ + ε ≈ Ua + μ,         (13)   where the r1 × r1 matrix C is predeﬁned as
                                                                                      
where PCA noise ε may be ignored. The prior p(a) is easier                      T        −1
                                                                            λ2Ay Ay
to acquire                                                              −                   .
                            T  −1                                  C=I               +I              (20)
              p(a) ∝ exp{−a  Λ   a},           (14)                            λ1
where Λ is a l × l diagonal matrix with eigenvalues at its So far, we accomplish the task of backward transform, i.e.
                                                                                                     ∗
diagonal.                                             hallucinating the photorealistic photo feature vector Ix =
                                                         ∗
  Due to the Bayesian MAP (maximum a posterior) criterion, a μ                       Iy
                       ∗                         ∗    U   +  given a sketch feature vector basedonanavailable
we ﬁnd the MAP solution a for hallucinating the optimal Ix set of myriad training photo-sketch image pairs.
as follows
          ∗                                           3.2  Algorithm
         a   =argmaxp(w,     a|Iy)
                    w, a                              Our algorithm tackles the intractable problem: sketch-based
             =argmaxp(Iy|w,    a)p(w, a)              facial photo hallucination with a learning-based scheme.
                    w, a                              There have been several successful relevant efforts on facial
             =argmaxp(Iy|w)p(w|a)p(a).         (15)                                               [
                    w, a                              sketch synthesis. Example-based sketch generation Chen et
                                                      al., 2001] takes pixels as rendering elements, so the computa-
  We take the statistics between w and Iy into considera- tional efﬁciency is somewhat low. Linear methods [Tang and
tion. Due to the learned relation (see eq.(11)) Iy = Ayw, Wang, 2004; Liu et al., 2005a] tend to trivialize the synthe-
we assume the representation error of Iy w.r.t w is i.i.d. and sized results without any statistical consideration. The fact
Gaussian. The conditional PDF p(Iy|w) is thus obtained as that our work improves upon the existing techniques is that
follows                                               patch-based tensor learning and Bayesian inference are coor-
                                     
                                     2                dinated in our algorithm, which is illustrated in Fig. 3.
                          Iy − Ayw
          p(Iy|w) ∝ exp −               ,      (16)     Collect a large corpus of n training facial image pairs
                               λ1                       (n)  (n) N
                                                      {Ix  ,Iy }n=1 with two styles, and divide each image into
where λ1 scales the variance in the photo space. In analogy m overlapping patches. Because the sketch image space and
to above, we obtain the condition PDF p(w|a) in doing w = photo image space are disparate in terms of gray-level inten-
BxIx and using eq. (13)                               sities, to bring the two spaces into correspondence, we use
                                        
                                        2             the horizontal and vertical image derivatives as features of
                       w − Bx(Ua +  μ)
       p(w|a) ∝ exp  −                     ,   (17)   both photo- and sketch-style patches for learning the Tensor-
                               λ2                     Patches model. Concretely, we envision Bayesian Tensor In-
where λ2 scales the variance in common variation space. ference involving two phases: the training and testing phase.
  Substituting PDFs given in eq. (14), (16), and (17) into eq. Training Phase
                                                        1.
(15), maximizing p(w, a|Iy) is equivalent to minimizing the Based on the derivative feature representation, build a 4-
following object function                             order tensor on n ∗ m photo-sketch patch pairs sampled from
                                                      n
                       2                       2        training image pairs and learn the matrices Ay and Bx.
            Iy − Ayw        w − Bx(Ua  + μ)                                                   (i) n
  E w, a                                                2. Construct concatenated photo feature vectors {Ix } ,
    (   )=       λ        +           λ                                                              i=1
                  1                    2              and run PCA on them to achieve the eigen-system (U, Λ) and
                               T  −1
                          +   a Λ   a.         (18)   the mean vector μ.

                                                IJCAI-07
                                                  2144                                                      position of centers of eyes and mouths. Each 160 × 100 face
                                                      image is divided into 160 overlapping 13 × 13 patches in the
                                                      same way, and the overlap between adjacent patches is three
                                                      pixels.
                                                        To display the effectiveness of our Bayesian Tensor Infer-
                                                      ence, we compare it with the representative methods, which
             training sketch -photo pairs
                                                      have been applied in facial sketch synthesis, including the
                                                      global method– eigentransform [Tang and Wang, 2004] and
                                                      the local method– local geometry preserving (LGP) [Liu et
                Local Geometry (2)                            ]
                  Preserving                          al., 2005a . Fig. 4 and Fig. 5 illustrates the results of sketch-
                                                      based face hallucination for Asians and Europeans, respec-
                                                      tively. In both the two groups of results, patch-based meth-
  testing sketch face          initial result         ods (c), (d) consistently and notably outperform the global

          (1)                           (4)           method (b) in high ﬁdelity of local details, which indicates
                TensorPatches   Gradient 
                                Correction            that a local model is more suitable for modeling complex dis-
                                                      tributions such as images. By comparing the results yielded
                                                      by LGP (c) and those produced by our method (d), we can
                                         hallucinated face clearly see that our inference algorithm performs sharper and
                  Bayesian (3)
                   Tensor                             more realistic with higher image quality than LGP. One rea-
                  Inference                           son is that employing the patch-based tensor model can re-
                                                      cover both the common face structure and local details.
 input image derivatives    inferred image derivatives  We set the scale parameters λ1 and λ2 to be 0.02 and 0.2,
Figure 3: Architecture of our sketch-based facial photo hallu- respectively. We use standard SVD to do PCA on the train-
cination approach. (1) Learn the TensorPatches model taking ing photo feature vectors, with 97% of the eigenvalue total
image derivatives as features in the training phase; (2) ob- retained. When applying the LGP method to obtain the initial
tain the initial result applying the local geometry preserving hallucinated result in step 1 of the testing phase, we choose
method; (3) infer image derivatives of the target photo us- K =5to be the number of nearest neighbors.
ing the Bayesian Tensor Inference method, given input image From the quantitative perspective, Table 1 lists the average
derivatives extracted from the test sketch face; (4) conduct root-mean-square pixel errors (RMSE) for 4 different meth-
gradient correction to hallucinate the ﬁnal result.   ods. The baseline is the nearest neighbor method. As might
                                                      be expected, the performance of our method does improve
                                                      as the number of training sample pairs increases from 250
  Testing Phase                                       (Training Set I) to 500 (Training Set II). Although the RMSE
  1.                    I              m
    For a new sketch image y,divideitinto patches the of our method is larger than that of LGP, the hallucinated im-
same way as in the training phase. Using grayscale intensities ages look better, as detailed as that in the groundtruth face im-
for image features, apply the local geometry method [Liu et ages. To sum up, our sketch-based face hallucination method
                                          I0
al., 2005a] to estimate an initial hallucinated result x. acquires the best visually perceptual quality.
  2. Construct the concatenated sketch feature vector Iy us-
ing m overlapping patches, and exploit it and Ay, Bx, U, Λ,μ
                                ∗                          Table 1: Comparison of Hallucination Methods.
to infer the target photo feature vector Ix according to eq.(19).              Training Set I Training Set II
           ∗                                              Hallucination Method
  3. Break Ix into m patches and afterward integrate these                     RMSE   Red.  RMSE   Red.
                                   h     v
patches into two holistic derivative maps Ix and Ix , with pix- Nearest Neighbor 52.49 -    47.20   -
els in the overlapping area blended.                         Eigentransfrom    52.18 0.59%  43.14 8.60%
                                0
  4. Conduct gradient correction on Ix using the derivative Local Geometry Preserving 50.74 3.33% 44.24 6.27%
      h  v                                      f
maps Ix , Ix (i.e. gradient ﬁeld) to render the ﬁnal result Ix . Bayesian Tensor Inference 51.47 1.94% 44.90 4.87%
4  Experiments
                                                      5   Conclusions
Sketches often have many styles, for example, a cartoon
sketch often represents a person very exaggeratedly. In this In this paper, we present a statistical inference approach
paper, we only focus on sketches of plain styles without ex- called Bayesian Tensor Inference between the photo patch
aggeration, as for applications in law enforcement or photo space and the sketch patch space. Based on the principle that
search, no much exaggeration is allowed in sketch images so only commonalities contribute to the inference process and by
that the sketches can realistically describe the real subjects. virtue of the patch-based tensor model, we capture and learn
Some sketch examples are shown in Fig. 4 and Fig. 5.  the inter-space dependencies. The Bayesian MAP framework
  We conduct experiments on a database over 600 persons of integrates tensor modeling and statistical optimization to en-
which 500 persons are for training and the rest is for testing. sure the inference performance of the difﬁcult vision prob-
Each person has a frontal face photo image and a sketch im- lem: sketch-based facial photo hallucination. The potency of
age with a plain style drawn by an artist. All the training and our method is sufﬁciently shown in the comparative experi-
testing images are normalized by afﬁne transform to ﬁx the ments, achieving surprising photo rendering quality.

                                                IJCAI-07
                                                  2145