                        Formal Trust Model for Multiagent Systems∗

                              Yonghong Wang      and  Munindar P. Singh
                                    Department of Computer Science
                                    North Carolina State University
                                     Raleigh, NC 27695-8206, USA


                    Abstract                            For rational agents, trust in a party should be based sub-
                                                      stantially on evidence consisting of positive and negative ex-
    Trust should be substantially based on evidence.  periences with it. This evidence can be collected by an agent
    Further, a key challenge for multiagent systems   locally or via a reputation agency or by following a referral
    is how to determine trust based on reports from   protocol. In such cases, the evidence may be implicit in the
    multiple sources, who might themselves be trusted trust reports obtained that somehow summarize the evidence.
    to varying degrees. Hence an ability to combine   This paper develops a principled evidence-based approach for
    evidence-based trust reports in a manner that dis- trust that supports two crucial requirements of multiagent sys-
    counts for imperfect trust in the reporting agents is tems:
    crucial for multiagent systems.
    This paper understands trust in terms of belief and Dynamism. Practical agent systems face the challenge that
    certainty: A’s trust in B is reﬂected in the strength trust evolves over time, both as additional information is
    of A’s belief that B is trustworthy. This paper for-  obtained and as the parties being considered alter their
    mulates certainty in terms of evidence based on a     behavior.
    statistical measure deﬁned over a probability dis- Composition. It is clear that trust cannot be trivially propa-
    tribution of the probability of positive outcomes.    gated. For example, A may trust B who trusts C,but
    This novel deﬁnition supports important mathemat-     A may not trust C. However, we need to combine trust
    ical properties, including (1) certainty increases as reports that cannot themselves be perfectly trusted, pos-
    conﬂict increases provided the amount of evidence     sibly because of their provenance or the way in which
    is unchanged, and (2) certainty increases as the      they are obtained.
    amount of evidence increases provided conﬂict is
                                                      Traditionally, principled approaches to trust have been difﬁ-
    unchanged. Moreover, despite a more subtle deﬁ-
                                                      cult to come by because of the above requirements. With few
    nition than previous approaches, this paper (3) es-
                                                      exceptions, current approaches for combining trust reports
    tablishes a bijection between evidence and trust
                                                      tend to involve ad hoc formulas, which might be simple to im-
    spaces, enabling robust combination of trust reports
                                                      plement but are extremely difﬁcult to understand from a con-
    and (4) provides an efﬁcient algorithm for comput-
                                                      ceptual basis. The common idea underlying a solution that
    ing this bijection.
                                                      satisﬁes the above requirements is the notion of discounting.
                                                      Dynamism can be accommodated by discounting over time
1  Introduction                                       and composition by discounting over the space of sources
                                                      (i.e., agents). Others have used discounting before, but with-
In simple terms, an agent’s trust in another can be understood out adequate mathematical justiﬁcation. For instance, Yu and
as a belief that the latter’s behavior will support the agent’s Singh [2002] develop such a discounting approach layered on
plans. Subtle relationships underlie trust in social and organi- their (principled) Dempster-Shafer account.
              [                           ]
zational settings Castelfranchi and Falcone, 1998 . Without The best multiagent application of the present approach is
detracting from such principles, this paper takes a narrower in the work of Wang and Singh [2006a], who develop an al-
view of trust: here an agent seeks to establish a belief or dis- gebra for aggregating trust over graphs understood as webs
belief that another agent’s behavior is good (thus abstracting of trust. Wang and Singh concentrate on their algebra and as-
out details of the agent’s own plans and the social and orga- sume a separate, underlying trust model, which is the one de-
nizational relationships between the two agents). The model veloped here. By contrast, the present paper is neutral about
proposed here can, however, be used to capture as many di- the discounting and aggregation mechanisms, and instead de-
mensions of trust as needed, e.g., timeliness, quality of ser- velops a principled evidential trust model that would underlie
vice, and so on.                                      any such agent system where trust reports are gathered from
  ∗This research was partially supported by the National Science multiple sources.
Foundation under grant ITR-0081742.                     Following Jøsang [2001], we understand trust based on the

                                                IJCAI-07
                                                  1551probability of the probability of outcomes, and adopt his idea abilistic terms. Speciﬁcally, an agent can represent the prob-
of a trust space of triples of belief (in a good outcome), dis- ability of a positive experience with, i.e., good behavior by,
belief (or belief in a bad outcome), and uncertainty.Trustin another agent. This probability must lie in the real interval
this sense is neutral as to the outcome and is reﬂected in the [0, 1]. The agent’s trust corresponds to how strongly the agent
certainty (i.e., one minus the uncertainty). Thus the following believes that this probability is a speciﬁc value (whether large
three situations are distinguished:                   or small, we don’t care). This strength of belief is also cap-
  • Trust in a party (i.e., regarding its being good): belief is tured in probabilistic terms. To this end, we formulate a prob-
    high, disbelief is low, and uncertainty is low.   ability density function of the probability of a positive expe-
                                                      rience. Following [Jøsang, 1998],wetermthisaprobability-
  • Distrust in a party: belief is low, disbelief is high, and
                                                      certainty density function (PCDF). In our approach, unlike
    uncertainty is low.
                                                      Jøsang’s, certainty is a statistical measure deﬁned on a PCDF.
  • Lack of trust in a party (pro or con): uncertainty is high.
  However, whereas Jøsang deﬁnes certainty in an ad hoc 2.1 Certainty from a PCDF
manner, we deﬁne certainty based on a well-known statistical Because the cumulative probability of a probability lying
measure. Despite the increased subtlety of our deﬁnition, it within [0, 1] must equal 1, all PCDFs must have the mean
preserves a bijection between trust and evidence spaces, en- density of 1 over [0, 1],and0 elsewhere. Lacking additional
abling combination of trust reports (via mapping them to ev- knowledge, a PCDF would be a uniform distribution over
idence). Our deﬁnition captures the following key intuitions. [0, 1]. However, with additional knowledge, the PCDF would
Effect of evidence. Certainty increases as evidence in- deviate from the uniform distribution. For example, know-
    creases (for a ﬁxed ratio of positive and negative obser- ing that the probability of good behavior is at least 0.5,we
    vations).                                         would obtain a distribution that is 0 over [0, 0.5) and 2 over
                                                      [0.5, 1]. Similarly, knowing that the probability of good be-
Effect of conﬂict. Certainty decreases as the extent of con-
                                                      havior lies in [0.5, 0.6], we would obtain a distribution that is
    ﬂict increases in the evidence.
                                                      0 over [0, 0.5) and (0.6, 1],and10 over [0.5, 0.6].
  Jøsang’s approach satisﬁes the intuition about evidence In formal terms, let p ∈ [0, 1] represent the probability of
but fails the intuition about conﬂict. It falsely predicts a positive outcome. Let the distribution of p be given as a
                                                                                        1
that mounting conﬂicting evidence increases certainty—and function f :[0, 1] → [0, ∞) such that f(p)dp =1.The
equally as much as mounting conﬁrmatory evidence. Say Al-                               0
                                                      probability that the probability of a positive outcome lies in
ice deals with Bob four times or obtains (fully trustworthy)                    p2
                                                      [p1,p2] can be calculated by f(p)dp. The mean value of
                                                          R                    p1
reports about Bob from four witnesses: in either case, her 1 ( )
                                                           0 f p dp
evidence would be between 0 and 4 positive experiences. It f is 1−0 = 1. When we know nothing else, f is a uni-
seems uncontroversial that Alice’s certainty is greatest when form distribution over probabilities p.Thatis,f(p)=1for
the evidence is all in favor or all against and least when the p ∈ [0, 1] and 0 elsewhere. This reﬂects the Bayesian intu-
evidence is equally split. Section 3.2 shows that Jøsang as- ition of assuming an equiprobable prior. The uniform distri-
signs the same certainty in each case.                bution has a certainty of 0. As more knowledge is acquired,
  Yu and Singh [2002] model positive, negative, or neu- the probability mass shifts so that f(p) is above 1 for some
tral evidence, and apply Dempster-Shafer theory to compute values of p and below 1 for other values of p.
trust. Neutral experiences yield uncertainty, but conﬂicting Our key intuition is that the agent’s trust corresponds to in-
positive or negative evidence doesn’t increase uncertainty. creasing deviation from the uniform distribution. Two of the
Further, for conﬂicting evidence, Dempster-Shafer theory can most established measures for deviation are standard devia-
yield unintuitive results [Sentz and Ferson, 2002].SayPete tion and mean absolute deviation (MAD). MAD is more ro-
sees two physicians, Dawn and Ed, for a headache. Dawn bust, because it does not involve squaring (which can increase
says Pete has meningitis, a brain tumor, or neither with prob- standard deviation because of outliers or “heavy tail” distri-
abilities 0.79, 0.2,and0.01, respectively. Ed says Pete has a butions such as the notorious Cauchy distribution). Abso-
concussion, a brain tumor, or neither with probabilities 0.79, lute values can sometimes complicate the mathematics. But,
0.2,and0.01, respectively. Dempster-Shafer theory yields in the present setting, MAD turns out to yield straightfor-
that the probability of a brain tumor is 0.725, which is highly ward mathematics. In a discrete setting involving data points
                                                                                         1
counterintuitive, because neither Dawn nor Ed thought that 1                                n  |  −  |
                                                      x ...xn with mean xˆ,MADisgivenby  n Σi=1 xi  xˆ .In
was likely.                                           the present case, instead of n we divide by the size of the do-
  This paper contributes (1) a rigorous, probabilistic deﬁni- main, i.e., 1. Because a PCDF has a mean value of 1, increase
tion of certainty that satisﬁes the above key intuitions, (2) in some parts must match reduction elsewhere. Both increase
the establishment of a bijection between trust reports and ev- and reduction from 1 are counted by |f(p) − 1|. Deﬁnition 1
idence, which enables the principled combination of trust re-               1
                                                      scales the MAD for f by 2 to remove this double counting.
ports, and (3) an efﬁcient algorithm for computing this bijec-
tion.                                                 Deﬁnition 1 The certainty based on f, cf , is given by cf =
                                                      1  1 |   −   |
                                                      2  0 f(p)  1 dp
2  Modeling Certainty                                   Certainty captures the fraction of the knowledge that we do
The proposed approach is based on the fundamental intuition have. For motivation, consider randomly picking a ball from
that an agent can model the behavior of another agent in prob- a bin that contains N balls colored white or black. Suppose

                                                IJCAI-07
                                                  1552p is the probability that the ball randomly picked is white. If A trust space consists of trust reports modeled in a three-
we have no knowledge about how many white balls there are dimensional space of reals in (0, 1). Each point in this space
in the bin, we can’t estimate p with any conﬁdence That is, is a triple b, d, u ,whereb + d + u =1, representing the
certainty c =0. If we know that exactly m balls are white, weights assigned to belief, disbelief, and uncertainty, respec-
then we have perfect knowledge about the distribution. We tively. Certainty c is simply 1 − u. Thus c =1and c =0
               m
can estimate p = N with c =1. However, if all we know is indicate perfect knowledge and ignorance, respectively.
that at least m balls are white and at least n balls are black Combining trust reports is nontrivial. Our proposed deﬁni-
(thus m + n ≤ N), then we have partial knowledge. Here tion of certainty is key in accomplishing a bijection between
    m+n
c =   N  . The probability of drawing a white ball ranges evidence and trust reports. The problem of combining inde-
     m    −  n
from N to 1  N .Wehave                                pendent trust reports is reduced to the problem of combining
               ⎧                                      the evidence underlying them. (Deﬁnitions 2 and 4 are based
               ⎨             m
                  0,       [0 N )                     on [Jøsang, 2001].)
        f(p)=        N     p ∈ [ m , 1 − n ]
               ⎩  N−m−n         N     N                                                 {      |
                  0(1−          n , 1].               Deﬁnition 4 Deﬁne trust space as T = (b, d, u) b>0,d>
                                N                     0,u>0,b+   d + u =1}.
                                      m+n
Using Deﬁnition 1, we can conﬁrm that cf = :
                                       N              2.3  From Evidence to Trust Reports
        
       1  1                                           Using Deﬁnition 3, deﬁne certainty based on evidence r, s :
cf =       |f(p) − 1|dp
       2 0 m        n                  
       1            1−                    1                                 1  ( r(1− )s
          N           N    N    −                                         1    R x    x
   =   2 ( 0 1 dp + m   ( −  −    1)dp +  1− n 1 dp   Deﬁnition 5 c(r, s)=    | 1         − 1|dx
                    N    N  m n             N                             2 0    xr(1−x)sdx
       1 m   N−m−n      N           n                                          0
   =   2 ( +        (  −  −  − 1) +  )
        +N      N    N  m  n       N                    Throughout, r, s,andt = r + s refer to positive, negative,
       m  n                                                                                        +1
   =    N                                                                                         r
                                                      and total evidence, respectively. Importantly, α = t+2 ,the
2.2  Evidence and Trust Spaces Conceptually           expected value of the probability of a positive outcome, also
                                                      characterizes conﬂict in the evidence. Clearly, α ∈ (0, 1):
For simplicity, we model a (rating) agent’s experience with α approaching 0 or 1 indicates unanimity, whereas α =0.5
a (rated) agent as a binary event: positive or negative. Evi- means r = s, i.e., maximal conﬂict in the body of evidence.
dence is conceptualized in terms of the numbers of positive We can write c(r, s) as c((t +2)α − 1, (t + 2)(1 − α) − 1).
and negative experiences. In terms of direct observations, When α is ﬁxed, certainty is a function of t, written c(t).
these numbers would obviously be whole numbers. However, When t is ﬁxed, it is a function of α, written c(α). And, c(t)
our motivation is to combine evidence in the context of trust. and c(α) are the corresponding derivatives.
As Section 1 motivates, for reasons of dynamism or compo-
                                                        The following is our transformation from evidence to trust
sition, the evidence may need to be discounted to reﬂect the
                                                      spaces. This transformation relates positive and negative evi-
aging of or the imperfect trust placed in the evidence source.
                                                      dence to belief and disbelief, respectively, but discounted by
Intuitively, because of such discounting, the evidence is best
                                                      the certainty. The idea of adding 1 each to r and s (and thus
understood as if there were real (i.e., not necessarily natural)
                                                      2 to r + s) follows Laplace’s famous rule of succession for
numbers of experiences. Accordingly, we model the evidence
                                                      applying probability to inductive reasoning [Sunrise, 2006].
space as E = R × R, a two-dimensional space of reals. The
                                                      This reduces the impact of sparse evidence, and is sometimes
members of E are pairs r, s  corresponding to the numbers
                                                      termed Laplace smoothing. If you only made one observa-
of positive and negative experiences, respectively. Combin-
                                                      tion and it was positive, you would not want to conclude that
ing evidence is trivial: simply perform vector sum.
                                                      there would never be a negative observation. As the body of
Deﬁnition 2 Deﬁne evidence space E = {(r, s)|r ≥ 0,s ≥ evidence increases, the increment of 1 becomes negligible.
0,t= r + s>0}                                         More sophisticated formulations of rules of succession exist
                                                      [Ristad, 1995], but Laplace’s rule is simple and reasonably
  Let x be the probability of a positive outcome. The poste-
                                                      effective for our present purposes. Laplace’s rule is insen-
rior probability of evidence r, s  is the conditional probabil-
                                                      sitive to the number of outcomes in that 1 is always added.
ity of x given r, s  [Casella and Berger, 1990, p. 298].
                                                      The effect of this statistical “correction” (the added 1)de-
Deﬁnition 3 The conditional probability of x given r, s  is creases inversely as the number of outcomes being considered
                           (  | ) ( )               increases. More sophisticated approaches may be thought of
              |         R g r,s x f x
           f(x  r, s )=1    ( | ) ( )               as decreasing the effects of their corrections more rapidly.
                         0 g r,s x f x dx
                            r(1− )s
                         R x   x
                      =   1 r(1− )s
                         0 x   x  dx                  Deﬁnition 6 Let Z(r, s)=(b, d, u) be a transformation
                                                    from E to T such that Z =(b(r, s),d(r, s),u(r, s)),where
                   r + s                              b(r, s)=αc(r, s), d(r, s)=(1− α)c(r, s), and u(r, s)=
where g(r, s |x)=        xr(1 − x)s
                   r                                  1 − c(r, s).
  Traditional probability theory models the event r, s  by One can easily verify that c(0, 1) > 0. In general, because
(α, 1 − α), the expected probabilities of positive and negative t = r + s>0, c(r, s) > 0. Moreover, c(r, s) < 1: thus,
                                r+1                     −
outcomes, respectively, where α = r+s+2 . The traditional 1 c(r, s) > 0. This coupled with the rule of succession
                                                                                                     b
probability model ignores uncertainty.                ensures that b>0, d>0,andu>0. Notice that α = b+d .

                                                IJCAI-07
                                                  1553                                                               0.75
  Jøsang et al. [1998] map evidence r, s  to a trust triple
          1
  r   s                                                         0.7
( t+1 , t+1 , t+1 ). Two main differences with our approach
are: (1) they ignore the rule of succession and (2) in essence,
                     t                                         0.65
they deﬁne certainty as t+1 . They offer no mathematical jus-
tiﬁcation for doing so. Section 3.2 shows an unintuitive con-   0.6


sequence of their deﬁnition.                                   Certainty 0.55

3  Important Properties and Computation                         0.5
We now show that the above deﬁnition yields important for-     0.45

mal properties and how to compute with it.                      0.4
                                                                 0     0.2   0.4   0.6   0.8   1.0
                                                                              Conflict ratio
3.1  Increasing Experiences with Fixed Conﬂict
                                                      Figure 2: Certainty is concave when t is ﬁxed at 10;X-axis:
Consider the scenario where the total number of experiences r +1;Y-axis:c(α); minimum occurs at r = s =5
increases for ﬁxed α =0.70. For example, compare observ-
ing 6 good episodes out of 8 with observing 69 good episodes
out of 98. The expected value, α, is the same in both cases, Table 1: Certainty computed by different approaches for
but the certainty is clearly greater in the second. In general, varying conﬂict
we would expect certainty to increase as the amount of evi-           0, 4 1, 3 2,  2 3,  1 4,  0 
dence increases. Deﬁnition 5 yields a certainty of 0.46 from
                                                   Our approach    0.54   0.35   0.29   0.35   0.54
 r, s = 6, 2 , but a certainty of 0.70 for r, s = 69, 29 . Jøsang et al. 0.80 0.80   0.80   0.80   0.80
  Figure 1 plots how certainty varies with t when α =0.5. Yu & Singh     00000
Theorem 1 captures this property in general.

       0.8                                                                                    1
                                                      Theorem 2  c(α) is decreasing when 0 <α≤ 2 , increasing
                                                           1                                    1
       0.7                                            when 2 ≤ α<1   and c(α), and minimum at α = 2 .
                                                                                            ∈
       0.6                                            Proof idea: Show that c (α) < 0 when α   [0, 0.5) and
                                                      c(α) > 0 when α ∈ [0.5, 1.0).
       0.5
       Certainty
       0.4


       0.3
                                                              0.8

       0.2                                                    0.6


       0.1                                                    0.4
        0    5   10  15   20  25  30   35  40
                       # of total outcomes
                                                             Certainty
                                                              0.2
Figure 1: Certainty increases with t when conﬂict (α =0.5)
                                                               0
is ﬁxed; X-axis: t;Y-axis:c(t)                                 5
                                                                 4                               5
                                                                    3                         4
                                                                       2                  3
                                                                                      2
Theorem 1 Fix α.Thenc(t) increases with t for t>0.                        1       1
                                                                             0 0
                                                            # of negative outcomes    # of positive outcomes
Proof idea: Show that c(t) > 0 for t>0.
  The full proofs of this and other theorems of this paper are
included in a technical report [Wang and Singh, 2006b].     Figure 3: X-axis: r;Y-axis:s; Z-axis: certainty
3.2  Increasing Conﬂict with Fixed Experience           Putting the above results together suggests that the rela-
Another important scenario is when the total number of ex- tionship between certainty on the one hand and positive and
periences is ﬁxed, but the evidence varies to reﬂect different negative evidence on the other is nontrivial. Figure 3 con-
levels of conﬂict by using different values of α. Clearly, cer- ﬁrms this intuition by plotting certainty against r and s as a
tainty should increase as r or s dominates the other (i.e., α surface.
approaches 0 or 1) but should reduce as r and s are balanced
(i.e., α approaches 0.5). Figure 2 plots certainty for ﬁxed t 3.3 Bijection Between Evidence and Trust Reports
and varying conﬂict.                                  The ability to combine trust reports effectively relies on be-
  More speciﬁcally, consider Alice’s example from Sec- ing able to map between the evidence and the trust spaces.
tion 1. Table 1 shows the effect of conﬂict where t =4. With such a mapping in hand, to combine two trust reports,
  Theorem 2 captures the property that certainty increases we would simply perform the following steps: (1) map trust
with increasing unanimity.                            reports to evidence; (2) combine the evidence; (3) transform

                                                IJCAI-07
                                                  1554the combined evidence to a trust report. The following theo- Further, an evidence-based notion of trust must support im-
rem establishes that Z has a unique inverse Z−1.      portant properties regarding the effects of increasing evidence
                                                      (for constant conﬂict) and of increasing conﬂict (for constant
Theorem 3 The transformation is a bijection.
                           Z                          evidence). The theoretical validation provided here is highly
Proof sketch: Given (b, d, u) ∈ T , we need (r, s) ∈ E such valuable in a general-purpose conceptually driven mathemat-
that Z(r, s)=(b, d, u). As explained in Section 2.3, α = ical approach. The main technical insight of this paper is how
 b                                         −          to manage the duality between trust and evidence spaces in
b+d . Thus, we only need to ﬁnd t such that c(t)=1 u.The
existence and uniqueness of t is proved by showing that a manner that provides a rigorous basis for combining trust
                                                      reports.
 1. c(t) is increasing when t>0 (Theorem 1)             Let’s brieﬂy revisit the topic of trust dynamics from Sec-
 2. limt→∞ c(t)=1                                     tion 1. The foregoing showed how trust evolves with respect
                                                      to increasing outcomes under different conditions. The same
 3. lim →0 c(t)=0
       t                                              properties apply to the evolution of trust over time, that is, as
  Brieﬂy, Yu and Singh [2002] base uncertainty not on con- time passes and more evidence is obtained. A crucial obser-
ﬂict, but on intermediate (neither positive not negative) out- vation is that because of the bijection we established, the his-
comes. Let’s revisit Pete’s example of Section 1. In our ap- torical evidence at any point can be summarized in a belief-
proach, Dawn and Ed’s diagnoses correspond to two b, d, u disbelief-uncertainty triple. New evidence can then be added
triples (where b means “tumor” and d means “not a tumor”): as explained above. Moreover, we can discount the value of
(0.2, 0.79, 0.01) and (0.2, 0.79, 0.01), respectively. Combin- evidence over time if necessary, e.g., at every time step (cho-
ing these we obtain the b, d, u triple of (0.21, 0.78, 0.01). sen based on the domain: every hour or day, or after every
That is, the weight assigned to a tumor is 0.21 as opposed transaction). Thus new evidence would have a greater impact
to 0.725 by Dempster-Shafer theory, which is unintuitive, be- than older evidence.
cause a tumor is Dawn and Ed’s least likely prediction. A payoff of this approach is that an agent who wishes to
                                                      achieve a speciﬁc level of certainty can compute how much
3.4  Algorithm and Complexity                         evidence would be needed at different levels of conﬂict. Or,
No closed form is known for Z−1. Algorithm 1 calculates the agent can iteratively compute certainty to see if it has
Z−1 (via binary search on c(t)) to any necessary precision, reached an acceptable level.
>0.Heret      > 0 is the maximum evidence considered.
           max                                        4.1  Directions

       b                                              This work has opened up some important directions for fu-
1 α = b+d ;                                           ture work. An important technical challenge is to extend the
2 t1 =0;                                              above work from binary to multivalued events. Such an ex-
3 t2 = tmax;                                          tension will enable us to handle a larger variety of interactions
4 while t2 − t1 ≥  do                                among people and services. A current direction is to experi-
         t1+t2
5    t =  2  ;                                        mentally validate this work, doing which is made difﬁcult by
6    if c(t) <cthen t1 = t else t2 = t                the lack of established datasets and testbeds, but the situation
                                                      is improving in this regard [Fullam et al., 2005].
7 return r =((t +2)α − 1), s = t − r
    Algorithm 1: Calculating (r, s)=Z−1(b, d, u)      4.2  Literature on Trust
                                                      A huge amount of research has been conducted on trust, even
                                                      if we limit our attention to evidential approaches. Abdul-
Theorem 4 The complexity of Algorithm 1 is Ω(− lg ). Rahman and Hailes [2000] present an early model for com-
Proof: After the while loop iterates i times, t2 − t1 = puting trust. However, their approach is highly ad hoc and
     −i                                               limited. Speciﬁcally, various weights are simply added up
tmax2  . Eventually, t2 − t1 falls below , thus terminat-
ing the while loop. Assume it terminates in n iterations. without any mathematical justiﬁcation. Likewise, the term
                   −n             −n+1                uncertainty is described but without any foundation.
Then, t2 − t1 = tmax2  <≤   tmax2     . This implies
 n   tmax    n−1                                        The Regret system combines several aspects of trust, no-
2 >      ≥  2   .Thatis,n>(lg  tmax − lg ) ≥ n − 1.
                                                     tably the social aspects [Sabater and Sierra, 2002].Itinvolves
                                                      a number of formulas, which are given intuitive, but not math-
4  Discussion                                         ematical, justiﬁcation. A lot of other work, e.g., [Huynh et al.,
This paper is meant to offer a theoretical development of trust 2006], involves heuristics that combine multiple information
that would underlie a variety of situations where trust reports sources to judge trust. It would be an interesting direction
based on evidence are combined. In particular, it contributes to combine a rigorous approach such as ours with the above
to a mathematical understanding of trust, especially as it un- heuristic approaches to capture a rich variety of practical cri-
derlies a variety of multiagent applications. These include teria well.
referral systems and webs of trust in particular, in studying Teacy et al. [2005] develop a probabilistic treatment of
which we identiﬁed the need for this research. Such applica- trust. They model trust in terms of conﬁdence that the ex-
tions require a natural treatment of composition and discount- pected value lies within a speciﬁed error tolerance. An
ing in an evidence-based framework.                   agent’s conﬁdence increases with the error tolerance. Teacy et

                                                IJCAI-07
                                                  1555