              Robust Object Tracking with a Case-base Updating Strategy

                         Wenhui Liao, Yan Tong, Zhiwei Zhu, and Qiang Ji
                     Department of Electrical, Computer, and Systems Engineering
                     Rensselaer Polytechnic Institute, Troy, NY 12180-3590, USA


                    Abstract                          anymore thus the drifting issue becomes serious. In the sec-
                                                      ond group, the preceding frame is extracted as the template
    The paper describes a simple but effective frame- [Black and Yacoob, 1997; Papanikolopoulos et al., 1993;
    work for visual object tracking in video sequences. Ho et al., 2004]. In this case, the tracker can inevitably use a
    The main contribution of this work lies in the intro- wrong template due to partial occlusions or the accumulated
    duction of a case-based reasoning (CBR) method    errors from previous tracking steps [Nguyen et al., 2001].
    to maintain an accurate target model automati-    The third group online updates the template from a number of
    cally and efﬁciently under signiﬁcant appearance  previous frames or several key frames [Morency et al., 2003;
    changes without drifting away. Speciﬁcally, an au- Vacchetti et al., 2004; Lim et al., 2004; Lee and Kriegman,
    tomatic case-base maintenance algorithm is pro-   2005; Jepson et al., 2003]. It could overcome some disad-
    posed to dynamically update the case base, man-   vantages of the previous two groups, however, the issue is
    age the case base to be competent and representa- how to combine the multiple tracked objects appropriately to
    tive, and to maintain the case base in a reasonable generate the new template. Furthermore, most of them ig-
    size for real-time performance. Furthermore, the  nore the potential errors associated with each tracked object.
    method can provide an accurate conﬁdence mea-     Therefore once a tracked object view contains an error, it may
    surement for each tracked object so that the track- be integrated into the updated template, and errors accumu-
    ing failures can be identiﬁed in time. Under the  late throughout the tracking. Consequently, most of the ex-
    framework, a real-time face tracker is built to track isting tracking methods suffer from the well-known drifting
    human faces robustly under various face orienta-  issue, incapable of assessing the tracking failures or recover-
    tions, signiﬁcant facial expressions, and illumina- ing from the tracking error.
    tion changes.                                       In this paper, based on our previous work in [Zhu et al.,
                                                      2006], a robust object tracking framework based on case-
                                                      based reasoning (CBR) is proposed to automatically provide
1  Introduction                                       an accurate 2D tracking model at each image frame. Specif-
Object tracking in video sequences is important in appli- ically, the 2D tracking model in each frame can be online
cations such as video compression, surveillance, human- adapted dynamically by combining the object extracted from
computer interaction (HCI), content-based video indexing, current frame and the most similar image case retrieved from
and others. However, robustly and accurately tracking objects a case base. Unlike our previous work [Zhu et al., 2006],
remains challenging due to the various appearance changes where the case base is ﬁxed, the case base is constructed
caused by illumination changes, partial or full occlusions, and automatically maintained to be competent, representa-
pose variations, non-rigid shape deformations, camera view tive, and with a reasonable size to make sure that an image
changes, and so on. Therefore, a key task in object tracking case that is most similar to the tracked object can be retrieved
research is to design a ﬂexible and accurate model that can quickly for each frame. Under the framework, the appearance
automatically cope with appearance changes.           changes of the tracked object can be adapted dynamically via
  The template-matching based methods have been exten- an adaption mechanism of CBR. As an result, an accurate 2D
sively used for object tracking by searching the image re- tracking model can be maintained online and thus the drifting
gion that is most similar to an object template. In general, issue that plagues most of the tracking techniques can be well
the template-matching based methods could be classiﬁed into handled. Furthermore, under the CBR paradigm, since the
three groups based on how the template is constructed. The tracked view is always adapted from its most similar case in
ﬁrst group extracts the ﬁrst frame in a video sequence as the case base, an accurate similarity measurement can be eas-
the template [Hager and Belhumeur, 1998; Li and Chellappa, ily obtained to characterize the conﬁdence level of the tracked
2000; Matthews et al., 2004]. However, when new parts of region, so that the failure situations can be detected in time.
the object come into view or the appearance of the object Based on the proposed framework, we build a real-time
varies signiﬁcantly during tracking, the template doesn’t ﬁt face tracking system to track faces in video sequences. Such

                                                IJCAI-07
                                                   925a real-time face tracker can track faces robustly under sig- any unseen image view can be adapted from them with some
niﬁcant appearance changes in illumination, scale, facial ex- image adaption strategy. Therefore the obtained object model
                                                       t+1
pression, occlusion, and head movement. Experiments also IM  is able to adapt to the appearance changes in the image
demonstrate that the proposed case-base maintenance algo- frame It+1, and thus also includes essential information to
rithm is able to automatically update the case base to include infer the true object view.
                                                                t+1     (   )
enough representative face views and delete redundant ones, Finally, IM  and I Xt+1 are combined together to get the
so that to maintain the case base in a reasonable size with          (     )           t+1    (    )
                                                      ﬁnal image view I Xt+1 . Since both IM  and I Xt+1 con-
a good tracking performance. Compared to the existing tech- tain important information about the object view and comple-
niques, our proposed technique has the following advantages: mentary to each other, a more accurate 2D tracking model can
(1) handle the drifting issue well; (2) no need of a 3D model; be obtained at each image frame. Therefore, the drifting issue
(3) capable of tracking any object; (4) being able to assess accompanied with most of the visual tracking techniques can
the tracking failures with a conﬁdence level; and (5) automat- be alleviated.
ically update candidate templates based on a case base.
                                                      2.2  The CBR Visual Tracking Algorithm
2  The Mathematical Framework                         The above proposed solution can be well-interpreted and im-
2.1  The 2D Object Tracking Model                     plemented in a case-based paradigm. Case-based reasoning
                                                      (CBR) is a problem solving and learning approach that has
Assume that an object O is moving in front of a video cam-
                                              (   )   grown into a ﬁeld of widespread interests in both academics
era. At time t, the object is captured as an image view I Xt and industry since the 1990’s [Aamodt and Plaza, 1994].
at position Xt in the image frame It. Then the task of 2D vi- From a CBR perspective, the problem of visual object track-
sual tracking is to search the image view I(Xt) of the object
                                             t        ing in a video sequence can be solved by retrieving and adapt-
O in each image frame It by using an object model IM .Let
 (  )                                         Δ  t   ing the previously seen views of the object to a new view of
I Xt be the located image view, then the tracking error I0 the object at each image frame. In the following, we demon-
can be represented as the difference between the true image
     (   )                         ( )               strate the CBR-based tracking algorithm with a face tracking
view I Xt and the located image view I Xt of the object:
Δ  t =  (  ) −  ( )                       t          system. More detail can be referred from our previous work
 I0    I Xt    I Xt . Given the object model IM ,ifwe at [Zhu et al., 2006].
assume that its most similar image view can be successfully
                                                                      Probe Case           Similar Cases 
located in the image frame It, then apparently the tracking
       t                                                                         RETRIEVE
error ΔI0 is mostly caused by the inaccuracy of the utilized
            t
object model IM . Therefore, a key issue for a successful vi-
sual tracking technique is to obtain an accurate 2D tracking Problem                            R
model It of the object at each image frame I .                                                  E
      M                               t                        RETAIN                           U
  We thus propose a case-based reasoning algorithm to main-                                     S
                                                                                                E
tain an accurate tracking model for each image frame so that                   CASE BASE
                 t
the tracking error ΔI0 can be minimized during tracking. Fig-
ure 1 illustrates the major steps of the proposed algorithm.                     REVISE
                                                                                               ?
                                                            New Case
          t   t+1                       t+2
                                                                  Solution with Confidence New Solution
       I ( )   I(   )      CBR  I(   )
          t       t+1              t +1                    Figure 2: The CBR cycle of the face tracking system.

                     Case                               Figure 2 illustrates a general CBR cycle for the built face
                            I t+1
                     Base    M                        tracking system, which consists of four processes, Retrieve,
                                                      Reuse, Revise,andRetain.
      Figure 1: The diagram of the proposed algorithm   Case Retrieve: The Retrieval process searches the most
                                                      similar face images from a case base composed of the
  The ﬁrst step is to locate the object in the image frame It+1 collected representative face images with the located view
                       (   )                              
using the tracked 2D view I Xt as the initial object model. I(X +1). The magnitudes of a set of multi-scale and multi-
    (    )                                               t
Let I Xt+1 be the located object view in the image frame orientation Gabor wavelets as in [Lee, 1996] are used as the
                           (  )
It+1. Due to image variations, I Xt may not be an accurate feature representation of the image appearance. Thus the ob-
                          +1                                                      t+1
model for the image frame at t so that the located image ject searching is to ﬁnd a case I  that is most similar to
 (   )                                                                          M
I Xt+1  is not accurate enough to reﬂect the current object. I(X +1) in terms of the Gabor response vectors.
            (    )                                       t
Even though, I Xt+1 usually contains information about the Case Reuse: The reuse process reuses the information and
object appearance at the current time t +1partially or com- knowledge in the retrieved face image to reﬁne the previ-
                                 (   )
pletely. Thus, the located image view I Xt+1 represents an ously located face image by adapting to the face appearance
important information source that can be utilized to infer the changes. It consists of two steps. At the ﬁrst step, the se-
                                                                       t+1
true view of the object in the image frame It+1.      lected image view I  is utilized as a tracking model to per-
                         (    )                                       M     
  Then, in the second step, I Xt+1 is used to ﬁnd a new form a search starting at Xt+1 in the image frame It+1 for a
            t+1                                                                   
object model I  by searching a case base. The case base most similar image view, called Xt+1 . Subsequently, the sec-
            M                                                                                  (   )
contains a set of representative 2D views of the object, where ond step is to combine the tracked image views I Xt+1 and

                                                IJCAI-07
                                                   926 (   )                          (    )
I Xt+1  to obtain the ﬁnal image view I Xt+1 as follows: poses are collected. The similarity scores between any of two
                S               S                  images have to be small otherwise one of them is regarded as
      X    =     t+1   X   +     t+1   X
       t+1            t+1           t+1   (1)   redundant and is thus deleted. Overall, the cases in the initial
             St+1 + St+1      St+1 + St+1
                                                     case base are representative, accurate, and diverse. Each case
where St+1 is the cosine similarity measure between the Ga- is regarded as a cluster and itself is called key case,marked
                                                      ∗
bor response vectors of I(Xt) and I(X +1),andS +1 is the
                                 t        t           as Ii . During CBM, each existing cluster would be enriched
cosine similarity measure between the Gabor response vec- and new cluster would be added.
       t+1      (   )
tors of IM  and I Xt+1 . Intuitively, it can be seen as a The proposed CBM algorithm includes two processes:
minimization of the sum of two errors, the error between the case-updating and case-deleting. Case-updating is triggered
target view in the current frame and the tracked view in the after each tracking task if the tracking successful rate is
previous frame, as well as the error between the target view in lower than a predeﬁned threshold, where the successful rate
the current frame and the selected similar case view from the is deﬁned as the percentage of the image frames that have
case base. In other words, the tracked target view possesses high conﬁdence scores over the whole image frames. Case-
one important property: it must be similar to the tracked view deleting is triggered only when the size of the case base is
in the previous frame as well as the selected case view in the too large so that the tracking speed cannot reach the real-time
case base. When the tracked view satisﬁes this property, the requirement. In the following, we present the two processes
drifting issue can be well handled and thus the tracking has a respectively.
high chance to succeed.
  Case Revision: The revise process evaluates the tracking 3.1 Case-base Updating
result with a conﬁdence measure. Once the ﬁnal image view The case-updating procedure consists of several steps. First,
 (    )
I Xt+1  is obtained, another search will be conducted in the all the images with low conﬁdence scores during tracking are
case base to ﬁnd the most similar case. A similarity score put into a temporary database. Second, an off-line multi-view
St+1 is derived after the searching is done. In practice, if the face detector [Wang and Ji, 2005] is applied to identify all the
similarity score is high, tracking is usually successful; other- face images. The non-face images are then deleted. The third
wise, it may fail. Therefore, the derived similarity score St+1 step, also the key step, is to update the case base with the re-
is utilized as a conﬁdence measure to characterize the ﬁnal maining images in the temporary database since the faces in
           (     )
image view I Xt+1 . The system automatically reports the these images are not covered by the current case base. How-
conﬁdence measure and stores those image views with low ever, we cannot simply add all the identiﬁed face images into
conﬁdence level into a temporary database. Such a tempo- the case base due to the limitation of the case-base size. Also,
rary database will be used for case-base maintenance. it is not necessary to put all those images into the case base
  Case Retain: The retaining process enriches the case base because most of the images are very similar to each other. By
by adding new representative image views. To retain a new adding some of them into the case base is usually enough to
case, the image views in the temporary database have to be track the remaining images successfully.
reviewed periodically, so that only the useful image views are
                                                        Let Dt be the temporary database with only face images,
selected and added into the case base. Using this process, it
                                                      Do be the current case base. The goal of case-updating is to
is believed that the case base can include more and more rep-       ∗
                                                      ﬁnd a case set D from the union of Dt and Do that achieves
resentative 2D views of the objects. Such a process is one an optimal tradeoff between the tracking performance and the
important task in case-base maintenance, which will be pre- overall size of the case base.
sented in the next section.
                                                        ∗
                                                      D   = arg max{f(Di, (Dt ∪ Do) \ Di) − g(|Di|)|Di|} (2)
3  Case-Base Construction and Maintenance                       Di
                                                                                     ∪      (      )
For the proposed case-base reasoning system, it is crucial to where Di is any case subset in Dt Do, f Di,Dj is the
construct a good case base and maintain the case base au- tracking performance function, which is the tracking success-
tomatically and systematically in order to keep or improve ful rate of using Di as the case base to track the images in
                                                               ( )
the tracking performance in response to object changes in the Dj,andg x is the penalty function, which is deﬁned as
                                                          c                ( )
video sequences. For example, as time goes by, the case-base 1+e−a(x−b) . Basically g x is a modiﬁed sigmoid function.
size may become too large, so that it becomes slow to retrieval When the size of Di is very small or very large, the penalty
a similar case. In addition, some cases may become obso- increases little as the size of the case base increases; other-
lete so that they need to be replaced by more powerful cases. wise, the penalty increases more obviously as the size of the
Basically, case-base maintenance (CBM) can be referred as case base increases.
the task of adding, deleting, and updating cases, indexes and However, it is an NP-hard problem to ﬁnd such an optimal
other knowledge in a case base in order to guarantee the on- case base. In practice, we use a greedy approach as shown in
going performance of a CBR system [Zhu and Yang, 1999]. Table 1 to ﬁnd an optimal or near-optimal solution.
  Before we give the detailed algorithms for CBM, we ﬁrst The CaseUpdating function ﬁrst ﬁnds the most similar im-
introduce how to construct the initial case base. The ini- age I∗ among the key cases to the face images obtained from
tial case base is generated through a training process com- the temporary database. If the largest similarity score is still
bined with human intervention before the tracking system is not large enough (<Ts), it means that the tracking failure is
formally used. Speciﬁcally, around 150 face images com- caused by a new face that is not covered in the current case
ing from subjects of different ethnicity, gender, age, and face base. Thus the CaseAdding function is called to select a set of

                                                IJCAI-07
                                                   927images from the temporary database until the tracking perfor- cludes one case and such a case is the key case. And the
mance cannot be improved by adding more cases with Equa- testing pool is empty. As the updating goes on, more clusters
tion 2. These selected images are added into the case base as will be added. Also, some clusters will be enriched with more
a new cluster and the ﬁrst selected image during CaseAdding cases and the original key case may be replaced with another
is marked as the key case. And the unselected images are case or remain the same. In addition, each cluster is associ-
stored in the testing pool associated with the new cluster. ated with a group of images in the testing pool, which are the
  On the other hand, if the largest similarity score is large images that can be handled by this cluster.
enough (>Ts), it means the current case base may already With such an updating procedure, the new representative
have the similar faces, however, the new faces may be differ- images that are not covered by the case base can be added au-
ent because of the variation of pose, size, facial expressions, tomatically and timely. Also, the less representative cases in
or other factors. In that case, it is not necessary to add a new the case base can be replaced with more powerful cases. Fur-
cluster. Instead, the algorithm moves the images in the same thermore, since the updating procedure is guided by the per-
cluster of I∗ in the case base as well as the images in the test- formance of the tracking system, it guarantees that the newly
ing pool associated with I∗ into the temporary database. And added cases always improve the tracking system.
then, the CaseAdding function is called to select a new clus-
ter from the updated temporary database. Such a new cluster 3.2 Case-base Deleting
replaces the previous cluster and a new key case is also gener- Although the case-updating procedure performs both adding
ated for the updated cluster. Figure 3 illustrates how a cluster and deleting actions to the case base, it is still possible that the
is updated in the case base.                          overall size of the case base may become too large so that the
      CaseUpdating(Do ,Dt,Ts)                         tracking speed is affected and slows down. If that happens, it
      max ←−inf;                                      is necessary to delete some cases.
      for each Ii ∈ Dt
               ∗                                        The case base includes two types of cases: key case, and
         for each Ij ∈ Do
                      ∗
           if Similarity(Ii ,Ij ) >max                non-key case, as deﬁned in the updating procedure. We as-
                 ←       (   ∗)
              max  Similarity Ii ,Ij ;                sociate each case with a utility value. It is deﬁned as the
              ∗ ←  ∗
              I   Ij                                  frequency that the case is selected as the most similar case
      if max < Ts
         CaseAdding(Do,Dt);                           during tracking. For each newly added case, the utility is set
      else
                                          ∗           equal to the current lowest utility value in the case base (or 1
         Dp ← the image set in the testing pool associated with I ;
                                 ∗
         Di ← the images in the same cluster of I in Do; if the current minimal value is 0). Obviously, the higher the
          
         Do ← Do \ Di;                                utility is, the more desirable to keep the case in the case base.
          
         Dt ← Dt ∪ Dp ∪ Di;
                                                    The deletion procedure starts from the non-key case that has
         CaseAdding(Do,Dt);
      CaseAdding(Do,Dt)                               the lowest utility value. For the cases with the same utility
      R0 = f(Do,Dt) − g(|Do|)|Do|;                    value, the algorithm deletes them evenly from each cluster, to
      max ← 0;                                        avoid that one cluster is almost empty while another one is
      while max ≥ 0 & Dt = ∅
         max ← 0;                                     full of cases. In fact, since the searching algorithm and com-
         for each Ii ∈ Dt                             putational methods are efﬁcient in our system, the system can
           Do ← Do ∪{Ii};                             achieve a real-time performance even when the size of the
           R(Ii)=f(Do,Dt \ Ii) − g(|Do|)|Do|;
           if R(Ii) − R0 >max                         case base is around 750. Therefore the deletion procedure
             max ← R(Ii) − R0;
              ∗                                       rarely happens.
             I ←  Ii;
           Do ← Do \ Ii;                                Overall, with the proposed automatic CBM algorithms, the
                ∗
         R0 ← R(I );                                  case base tends to include all the representative face views
                   ∗
         Do ← Do ∪{I };
           ←    \ ∗                                   and delete redundant ones so that to maintain the case base in
         Dt  Dt  I ;                                  a reasonable size with a good tracking performance.
           Table 1: Algorithms of Case-updating

            ...                               ...
  I 1 ...                          I 1 ...            4   Experimental Results
                              Update


            ...


                                              ...
    ...                                               Based on the proposed CBR visual tracking framework, a


                                     ...
  I ...     ...         ...        I ...      ...
   i                               i                  real-time face tracking system is built. The whole system
                                                      runs at 26 frame per second (fps) in a machine with a 2.8GHZ


            ...


    ...


                                     ...
            ...                              ......
  I n ...                          I ...              CPU. When a person appears in the view of the camera,
                    Temporarydatabase n
  CaseBase TestingPool             CaseBase TestingPool the person’s face is automatically localized via the proposed
                                                      frontal face detector [Wang and Ji, 2005] and tracked subse-
Figure 3: An illustration of how a cluster in the case base is up- quently by our proposed face tracker. The initial case base
dated. Basically, the testing pool includes the images that the sys- includes 164 face images, which are automatically updated
tem fails to track in the past and the temporary database includes the as more and more video sequences are tested. To test the
images that the system fails to track recently. By considering the performance of the built face tracking system, a set of face
images from both the past and current, the updated cluster tends to video sequences with several new subjects are collected. We
achieve “global optimal” instead of “local optimal”.  ﬁrst demonstrate the performance of the proposed case-base
  Obviously, the structure of the initial case base changes maintenance (CBM) algorithm, and then demonstrate the per-
through the updating. In the beginning, each cluster only in- formance of the face tracker.

                                                IJCAI-07
                                                   9284.1  Case-base Maintenance                            4.2  Tracking Performance
                                                      We ﬁrst demonstrate the self-correction (drifting-elimination)
To test the performance of the proposed case-base mainte- capability of the proposed tracking scheme. Two other popu-
nance algorithm, 20 testing sequences from 13 novel subjects lar tracking techniques are implemented to compare to our
are collected. These subjects are not included in the initial method. The ﬁrst technique is the traditional two-frame-
case base, and with different races and gender. Each of the based tracking method [Matthews et al., 2004], which uti-
testing sequence consists of 600 frames.              lizes the previously tracked face image to update the tracking
  Figure 4 demonstrates the overall performance of the sys- model dynamically. The second one is the tracking technique
                                                                                         [              ]
tem with and without the CBM algorithm. As shown in the with the incremental subspace learning Lim et al., 2004 ,
ﬁgure, without the CBM algorithm, the successful rates for which dynamically updates the object model by incremental
most testing sequences are below 0.6 because the original learning its eigen-basis from a set of previously tracked faces.
case base cannot cover most of the new face images. With
the CBM algorithm, the case base is enriched with the new
faces gradually thus the system performance is continually
improved. After around 10 testing sequences, the average
successful rate is higher than 0.95, and the size of the case
base converges and becomes stable, which implies that the
current case base is competent for our current subject pool.


                                                                                                   (I)


                                                                                                   (II)
                                                         (a)     (b)     (c)      (d)     (e)


                                                                                                   (III)
Figure 4: Comparison of the face tracking performance with CBM (a.1) (b.1) (c.1)  (d.1)   (e.1)
and without CBM: the curve marked with stars represents the num-
ber of cases; the curve marked with diamonds represents the tracking
successful rate without CBM; the curve marked with squares repre-
sents the tracking successful rate with CBM.                                                       (IV)
                                                      Figure 5: (I) Comparison of the estimated conﬁdence measure-
  Figure 5(I) gives an example of how the CBM works in a ments before and after case updating; (II) the corresponding images
speciﬁc video sequence. The two curves represent the con- in the video sequence; (III) the most similar cases retrieved from the
ﬁdence measurements with and without CBM respectively. case base before updating; (IV) the most-frequently retrieved cases
In most sequences, the faces can be tracked successfully, from the case base during tracking.
which can be reﬂected by the fact that most of the conﬁdence
scores are higher than 0.5. Figure 5(IV) lists the three most-
frequently retrieved cases from the case base during the track-
ing. It shows that although the subjects in the three cases are
different from the subject in the video sequence, they can still
help to track the faces in most time, which demonstrates the
robustness of the CBR-based method of our system. How-
ever, for the frames around a, b, c, d, and e, the tracking fails
because the cases in the case base are not similar enough. Fig-
ure 5(II) lists the ﬁve images corresponding to a, b, c, d, and    (a)                    (b)
e in the video sequence, and Figure 5(III) lists the most sim-
ilar cases that are retrieved from the case base. After adding Figure 6: Comparisons of the tracked face position error between
the images in Figure 5(II) to the case base, all the faces are the proposed tracker and (a) the two-frame tracker; (b) the incre-
tracked well. Since the newly added cases are very different mental subspace learning tracker.
in facial appearances or face poses from the cases in the case Figure 6 compares the performance of the three face track-
base, they increase the representativeness of the case base and ers for a face sequence under signiﬁcant head movements and
thus can improve the system performance.              facial expressions. From Figure 6 (a), it is obvious that the

                                                IJCAI-07
                                                   929