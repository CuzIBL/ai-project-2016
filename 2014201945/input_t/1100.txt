                       Multi-agent Coordination using Local Search

                                 Boi Faltings and Quang-Huy Nguyen
                           Ecole Polytechnique Fed´ erale´ de Lausanne (EPFL)
                                 Artiﬁcial Intelligence Laboratory (LIA)
                                    CH-1015 Lausanne, Switzerland
                       {boi.faltings, quanghuy.nguyen}@epfl.ch

                    Abstract                          The solution of an MCOP is an assignment of values to all
                                                      variables that satisﬁes all constraints and maximizes the sum
    We consider the problem of coordinating the be-
                                                      of agent utilities as expressed by their relations. Note that
    havior of multiple self-interested agents. It in-
                                                      variables, domains and constraints are common and agreed
    volves constraint optimization problems that often
                                                      upon knowledge among the agents. On the other hand, rela-
    can only be solved by local search algorithms.
                                                      tions are speciﬁed by the individual agents, and they do not
    Using local search poses problems of incentive-   necessarily have to report them correctly.
    compatibility and individual rationality. We        An example of an MCOP problem is allocating capacity
    thus deﬁne a weaker notion of bounded-rational    in a public network, for example a train or pipeline network.
    incentive-compatibility where manipulation is     The network is a graph of connections, and only one agent
    made impossible with high probability through     can use any one connection at a given time. This can be
    computational complexity. We observe that in real represented by having one variable per link and time inter-
    life, manipulation of complex situations is often val whose domain ranges over the set of agents. Constraints
    impossible because the effect of the manipulation would enforce for example that successive links and times are
    cannot be predicted with sufﬁcient accuracy. We   assigned to the same agent.
    show how randomization schemes in local search
                                                        Agents serve customers’ transportation demands with dif-
    can make predicting its outcome hard and thus
                                                      ferent efﬁciency by using different combinations of links.
    form  a  bounded-rational incentive-compatible
                                                      Thus, each agent has utilities for being able to use certain
    coordination algorithm.
                                                      combinations of links, and reports these as relations. Agents
                                                      want to ﬁnd a combined assignment that maximizes the sum
1  Introduction                                       of their utilities. Such combinatorial optimization is NP-
There are many practical settings where multiple self- complete and thus can be solved exactly only for small prob-
interested agents have to coordinate their actions. This co- lems. For large instances, in many cases only local search
ordination often involves joint decisions about resource al- methods can be implemented. They can provide no optimal-
location, scheduling and planning that can be formulated as ity guarantees, but with high probability will ﬁnd a solution
constraint optimization problems. We thus extend the stan- that is very close to optimal.
dard deﬁnition of constraint optimization to the multi-agent Two additional considerations need to be addressed due to
setting as follows:                                   the multi-agent setting: individual rationality and incentive-
Deﬁnition 1.1 A discrete multi-agent constraint optimization compatibility. We say that a mechanism is individually ra-
problem (MCOP) is a tuple < A, X, D, C, R > where:    tional if and only if it is in the best interest of each agent to
                                                      participate in the mechanism, i.e if the expected utility that
  • A = {A1, .., Am} is a set of agents.              each agent gets when it participates in the mechanism is at
  • X =  {x1, .., xn} is a set of variables.          least as high as if it did not. This is important because other-
  • D  = {d1, .., dn} is a set of domains of the variables, wise, agents may choose not to participate in the mechanism.
    each given as a ﬁnite set of possible values.       We say that an optimization mechanism is incentive-
  • C  = {c , .., c } is a set of constraints, where a con- compatible if and only if each agent maximizes its expected
           1    p                                     utility when the protocol ﬁnds the truly optimal solution. De-
    straint ci is a function di1 ×..×dil → {0, 1} that returns
    1 if the value combination is allowed and 0 if it is not. pending on the protocol, incentive-compatibility often means
                                                      that each agent is reporting its relations truthfully, thus one
  • R =  {r1, .., ro} is a set of relations, where a relation also speaks of truthful mechanisms. Clearly, incentive-
    ri is a function di1 × .. × dil → < giving the utility of compatibility is important to obtain a meaningful solution
    choosing each combination of values.              to the MCOP. It is often achieved through tax or auction
  • Ri is the subset of R that gives the relations associated mechanisms such as the VCG mechanism ([Vickrey, 1961;
    with agent Ai.                                    Clarke, 1971; Groves, 1973]).  The seminal work of Ephrati and Rosenschein [1991] was utility of all relations for the assignment v is zero. This ﬁxes
the ﬁrst to propose applying VCG mechanisms to agent coor- the otherwise open utility of the initial assignment which has
dination. For constraint optimization, game theory has shown no inﬂuence on the optimization result.
that the only practical mechanism for incentive-compatibility Search then proceeds iteratively by local improvements.
in MCOP is of the form of a VCG  mechanism  ([Green   Function ChooseNeighbours provides a set of candidate as-
and Laffont, 1979]). However, it has also been shown that signments that are close to the current one and could possibly
VCG mechanisms require ﬁnding the provably optimal so- improve it. In our implementation, they are generated by ran-
lution ([Nisan and Ronen, 2000]). Many practical settings domly selecting a variable xi ∈ X and generating all assign-
                                                                           old
of optimization problems are too large for complete opti- ments that are equal to v but assign to xi different values
mization algorithms. We thus introduce a weaker concept in the domain of xi that are consistent with the rest of vold
of bounded-rational incentive-compatibility where manipu- and the constraints in C.
lation is hard through computational complexity. The uncer- In the second step of the iteration, the assignment v is up-
tainty created by randomized local search makes it computa- dated using the function LocalChoice. It chooses a new as-
tionally intractable to evaluate the outcome of an untruthful signment to optimize the combined utility according to the
behavior, thus rendering it uninteresting to agents.  relations in R. It also computes a vector of payments pay
  This paper is structured as follows: we ﬁrst present the lo- that agents must make or receive in the third step of the it-
cal search framework for solving MCOP and deﬁne bounded- eration. The payments sum up to zero and the way they are
rational incentive-compatibility. We show how incentive- derived is described in detail in Section 3.
compatibility can be achieved in each local search step, and The iteration continues until a termination condition is met,
then address the key issue of avoiding speculation through for example when there is no further improvement in the util-
the succession of local search steps. We report on experimen- ity of all agents for some number of steps. To avoid getting
tal results on randomly generated network resource allocation stuck in local optima, the performance of a local search proce-
problems that show their performance.                 dure is signiﬁcantly improved by randomization ([Kirkpatrick
                                                      et al., 1983; Selman et al., 1994]). This means that occa-
2  Assumptions and Deﬁnitions                         sionally LocalChoice chooses a value that may even decrease
                                                      agent utility.
2.1  Local search framework
Since ﬁnding the optimal solution for MCOP is computa- 2.2 Bounded-rational incentive-compatibility
tionally infeasible (NP-complete), in this paper we use local The local search procedure can only work correctly if agents
search algorithms (also called neighborhood search) to ﬁnd accurately report their utilities R. Using side payments, we
good, but not necessarily optimal solutions at a reasonable can create an incentive-compatible mechanism where agents
computational cost. Local search is widely used for solv- are motivated to truthfully report these valuations. Well-
ing large optimization problems. It has been particularly well known results in game theory ([Green and Laffont, 1979])
studied for satisﬁability problems, based on the GSAT proce- have shown that all mechanisms for MCOP that are incentive-
dure ([Selman et al., 1992]). The local search framework we compatible, individually rational and select the optimal so-
assume in this paper is given in Algorithm 1.         lution must be a kind of VCG mechanism. Furthermore,
                                                      Nisan and Ronen [2000] have shown that a VCG mecha-
Algorithm 1 Local search algorithm for MCOP           nism requires a provably optimal solution. Thus, there is
                                                      no mechanism that makes local search incentive-compatible
procedure LocalSearch(A,X,D,C)
                                                      while maintaining individual rationality.
  v ← SelectInitialSolution(X, D, C)                    We thus replace incentive-compatibility with a weaker
  for i ← 1 : m do                                    notion, called bounded-rational incentive-compatibility that
    Ri ← AskRelations(ai, v)                          uses computational complexity to rule out manipulation:
  end for
  repeat                                              Deﬁnition 2.1 (Bounded-rational agent): an agent is called
    vold ← v                                          bounded rational if it can examine at most C states of the
    N ←  ChooseNeighbours(vold, X, D, C)              local search before declaring its utilities Ri.
    (v, pay) ← LocalChoice(N, R)                      Deﬁnition 2.2 Let pt be a bound on the probability that a
    agents make/receive payments according to pay     bounded rational agent can predict whether it has an ex-
  until termination condition met                     pected utility gain from an untruthful utility declaration. A
  return v                                            mechanism is bounded rational incentive compatible if by
end procedure                                         varying a parameter, pt can be made arbitrarily close to 0.
                                                      Earlier work, such as ([Conitzer and Sandholm, 2003]), has
  The algorithm manipulates a complete assignment of val- proposed using NP-hardness as a protection against manipu-
ues to all variables, represented as a vector v. It is initially set lation. However, our deﬁnition goes further as it requires in
by function SelectInitialSolution to an assignment that satis- almost all cases, manipulation requires an amount of compu-
ﬁes all constraints and could be random. The algorithm then tation that is beyond the means of a bounded-rational agent.
asks each agent to state its set of relations Ri, where the utili- Any real computational agent is bounded rational for a sufﬁ-
ties should be relative to the initial assignment v such that the ciently high C.3  Local choice step                                  be left out of the optimization at a local choice step. It turns
We now consider incentive-compatibility and randomization out that a good way to select these relations is to take all the
of a single step in the local search, carried out by the func- relations belonging to a randomly selected agent ae. As we
tion LocalChoice. We consider that local changes are made show below, this way of randomizing allows us to simultane-
to an individual variable x only, but it is straightforward to ously guarantee budget-balance of the VCG tax mechanism.
generalize the mechanism to other neighbourhoods.     3.3  Payment budget balance and individual
  We assume that the number of possible alternatives is sufﬁ-
ciently small so that LocalChoice can apply a systematic and rationality
complete optimization procedure. We call vc the current as- One problem with the VCG mechanism is that agents gener-
                    ∗
signment to x, and let vS be the value that would be optimal ate a surplus of taxes that cannot be returned to them with-
for the set of agents S, i.e. would most improve the sum of out violating the incentive-compatibility properties. This not
their utilities.                                      only reduces their net utility gain, but also creates incentives
                                                      for whatever third party receives this gain.
3.1  Incentive-compatibility                            The randomization allows us to make the VCG tax scheme
As the local choice depends on the relations declared by the budget balanced by simply paying the payment surplus to the
individual agents, agents would normally have an incentive agent ae that was excluded from the optimization step. Each
to report excessive utility gains for their preferred changes so agent ai other than ae pays to ae the following tax:
that they impose them over those preferred by others. Thus,               X      £                     ¤
the optimal solution according to the declarations of a set of V CGtax−e(ai) =    r(vA\(ai∪ae)) − r(vA\ae )
                                             ∗                         r∈R\(r ∪r )
agents A, which we call vA, could be different from vA. We                   i e
counter this tendency by imposing side payments depending
                                                      and the mechanism chooses v   to implement. This can
on the utility declarations and the change chosen by the mech-                  A\ae
                                                      be seen as compensating the agent for the loss of utility it is
anism.
                                                      likely to incur as a consequence of having been left out of the
  As already mentioned earlier, the only side payments that
                                                      optimization, and does not affect the incentive-compatibility
achieve incentive-compatibility, individual rationality and
                                                      properties:
choose the optimal solution are VCG payments. For an agent
ai, the VCG payment is the “damage” it does the others, i.e. • for agents other than ae, it is still best to report their
the decrease in utility gain its presence causes to the remain- utilities truthfully since they follow a VCG mechanism
ing agents:                                               in a world where ae does not exist.
                                                        • for a , its declarations have no effect on the outcome or
        V CGtax(ai)                                           e
         X    £                                ¤          payments so any declaration is equally good. However,
    =          (r(vA\ai ) − r(vc)) − (r(vA) − r(vc))      it does not know in advance that it will be excluded, so

        r∈R\ri                                            it still has an interest to make a truthful declaration.
         X    £               ¤
                                                                                              [
    =          r(vA\a ) − r(vA)                       This mechanism is similar to the proposal in Ephrati and
                    i                                 Rosenschein, 1991], who proposed giving the surplus to
        r∈R\ri
                                                      agents that have no interest in the variable being considered.

Note that since vA\ai is optimized for A\ai, the sum of its We call such agents uninterested agents. The mechanism pro-
utilities for these agents will always be at least as large as posed here applies even when no uninterested agent exists.
that for vA and thus the V CGtax is never negative. Thus, When there are uninterested agents, optimization can be im-
the payments of all agents together leave a positive budget proved by selecting these to be chosen as excluded agents.
surplus.                                              More details on the mechanism can be found in [Faltings,
                                                      2004].
3.2  Randomization                                      In certain cases the sum of the taxes could be less than
Randomization has ﬁrst been proposed as simulated anneal- the utility loss of the excluded agent, and thus it would not
ing ([Kirkpatrick et al., 1983]), a technique inspired from the be individually rational for the agent to participate. In fact,
cooling of spin glasses. More recently, it has been studied no matter what payment scheme is used, whenever the local
more systematically, particularly in the context of satisﬁabil- search step leads to a reduction in total agent utility, there
ity problems. For example, the GSAT algorithm ([Selman et must be at least one agent for which individual rationality
al., 1992]) has been turned into the GWSAT algorithm ([Sel- is violated. Any randomized local search algorithm will oc-
man et al., 1994]) by adding a random walk strategy: with casionally make such moves, for otherwise it would be sus-
some probability, the strategy forces an improvement in a ceptible to getting stuck in local optima. Thus, no scheme
clause by ignoring the other clauses that would also be af- can guarantee individual rationality at every randomized lo-
fected. It has been shown that this randomization has the ef- cal choice step.
fect that the algorithm eventually ﬁnds the optimal solution As the algorithm on the whole improves utility for the com-
with high probability.                                munity of agents, this does not mean that the local search
  The random walk steps in GWSAT leave certain randomly process as a whole is not individually rational. No agent is
chosen constraints out of the local choice steps. We adopt a systematically disadvantaged by the randomization, and so in
similar scheme where we randomly select a set of relations to expectation the scheme is individually rational for all agents.This is conﬁrmed in our simulations, where individual ratio- 80000 
                                                                                                  n=1 
nality was always satisﬁed for all agents in all runs.       70000 
                                                                                                  n=2 
                                                             60000                                n=3 
4  Sequences of local choices                                50000                                n=4 
                                                             40000                                n=5 
                                                                                                  n=6 


A local search algorithm is in general incomplete and not   #states  30000 
                                                                                                  n=7 
                                                             20000 
guaranteed to ﬁnd a particular optimal solution. Thus, as                                         n=8 
pointed out by [Nisan and Ronen, 2000], non-truthful dec-    10000                                n=9 
larations can drive the local search algorithm to a solution    0                                 n=10 
that gives a manipulating agent (MA) a better utility than the    1  3  5  7  9  11  13  15  17  19  n=11 
truthful declaration. However, effectively using such manip-                #rounds 
ulation requires that the MA is capable of correctly predicting
the effect of a non-truthful utility declaration on the outcome,
and compare it against the utility loss it incurs by carrying Figure 1: New states discovered in successive cycles of a sim-
out the manipulation in one or several local choice steps. We ulation of local search, for several problem sizes.
now show that in a randomized local search algorithm and a
sufﬁciently large problem, with high probability (arbitrarily
close to 1), such prediction would require an amount of com- The local search algorithm contains several possibilities for
putation that is beyond the capabilities of a bounded-rational randomization that can make its outcome hard to predict:
agent.                                                  • random choice of neighbourhood,
  To obtain a worst-case result, we assume that a manipulat- • random choice of excluded agent a ,
ing agent (MA) has complete and accurate knowledge of the                              e
relations declared by all other agents. Furthermore, we as- • random choice of equivalent local choices.
sume that is has access to an oracle that provides it with the To make the effect of randomization easy to analyze, we con-
most promising manipulation.                          sider only randomizations whose outcomes can be regarded
  The remaining task of the MA is then to show that the ma- as independent. This is not the case of the random choice of
nipulation actually produces a better utility than truthful be-
                                                      neighbourhood, as it will often be the case that choosing n1
havior. As the local search algorithm is randomized, the MA
                                                      and then n2 will lead to the same states as choosing n2 and
can only predict an expected utility, obtained by considering
                                                      then n1, thus cancelling the randomization effect. Also, local
the probability of certain states and the utilities that the agent search has to ensure that all neighbourhoods are considered,
would obtain in each of them. The key idea of our argument placing limits on the amount of randomization that can be
is that with high probability, the number of states that need allowed. Furthermore, a manipulating agent could make dec-
to be considered in this calculation will grow exponentially larations to create symmetries that makes the randomization
with the size of the problem. Thus, for a certain problem size ineffective.
it will exceed the computational capacity of a bounded ratio- Fortunately, for the choice of excluded agent as well as
nal agent.                                            the choice among equivalent solutions, it does appear reason-
  To show this result, we ﬁrst argue that the MA has to exam- able to assume independence of subsequent random choices.
ine a signiﬁcant fraction of the probability mass of the states Furthermore, since the manipulating agent’s relations may be
to ensure success of the manipulation. This fraction depends excluded, it cannot render the randomization invalid through
on two factors:                                       its own declarations.
  • the utility distribution of the problem: if only few states To ﬁnd the global optimum, a local search algorithm has
    give a signiﬁcant utility, or if there are strong symme- to be able to reach the entire search space. However, even-
    tries so that the state space can be factored, it could be tually it will come close to the global optimum and then re-
    sufﬁcient to sample only a small subset of the states, and main within a much smaller subspace of nearly optimal states.
                                                      While it is possible to give a theoretical analysis that shows
  • the desired conﬁdence of the prediction: since a manip- that with arbitrarily high probability, the probability of reach-
    ulation will mean a certain utility loss to the agent in the ing any given state is bounded by an exponentially decreasing
    search step where it is applied, the manipulation needs value, such an analysis requires many independence assump-
    to succeed with a certain minimal probability in order to tions that may not hold in practice. Here, we present the fol-
    give an increase in expected utility. Depending on the lowing experimental measurements, obtained on the experi-
    utility distribution, this translates to a certain fraction of mental scenario given in the next section.
    the state probability mass that will need to be examined.
                                                        Figure 1 shows the number of new states discovered in
Note that both parameters are independent of the size of the successive cycles of a simulated randomized local search. It
search space. Thus, we can assume that the MA will have to initially grows exponentially, but eventually search stabilizes
examine a minimal number of states that corresponds to some on certain optimal outcomes and thus fails to discover new
fraction α of the probability mass of the entire search space. states. Importantly, however, the total number of states dis-
  Next, we show that with high probability, this probability covered, shown in Figure 2, still grows exponentially with
mass is distributed over a number of states that grows expo- problem size: in this example, it muliplies with a factor of
nentially with problem size.                          about 3 whenever the size increases by 1. Thus, the total     200000 
                                                                            Leeds 
     180000 
                                                                    Manchester 
                                                          Liverpool 
     160000                                                                     Nottingham 
     140000 
     120000                                                     Birmingham 
     100000 
                                                                                        Luton 

     #states  80000 
      60000                                                                   Oxford     London 

      40000                                                           Bristol 
                                                                                   Southampton  Brighton 
      20000 
         0 
          1  2   3   4  5   6  7   8  9   10  11      Figure 3: The transportation network used in the experiments
                         #variables 

                                                              1200 

Figure 2: Growth of the total number of states involved in a  1000 
local search simulation as a function of the problem size.
                                                               800 

number of states has exponential growth with problem size,     600 
                                                            utilities 
even though it does not reach the total state space because of 400 
                                                                                                 LOO 
the convergence of the algorithm.                              200                               SS 
  Another aspect that needs to be shown is that the MA can-                                      LS 
                                                                0 
not limit its consideration to only certain states in this space, 0  500  1000  1500  2000  2500  3000  3500  4000  4500  5000 
i.e. that the probability mass is distributed over a large subset                rounds 
of the states. We show this by considering the probabilities of
the resulting states at each randomized step. Let pm denote
the probability that at a random branch, each of the branches Figure 4: Average utility gain of different local search algo-
is taken with probability at most 1/m. We have measured pm rithms as a function of the number of steps.
experimentally (see later section) and have obtained for ex-
ample for p4 ' 0.908, showing that the search process has
a signiﬁcant branching factor. Thus, with high probability (London → Birmingham →  Manchester), the corre-
the probability mass is distributed among a large number of sponding variable x3 is assigned the value (a1, London →
states.                                               Birmingham   →  Manchester).
  A theoretical analysis with independence assumptions on The network capacity is modelled by binary constraints be-
this basis gives for example that in a local search with 1000 tween any pair of tasks whose routes share at least one arc that
variables, a stopping probability of 0.0001 (expected number rule out assigning it to such overlapping routes but different
of cycles = 10’000) and α = 0.1, the probability that an agent agents. Each operator has a different and randomly generated
would have to examine less than 1054 states is bounded by proﬁt margin for being assigned a demand/route combination,
       −9                                             and declares these through its relations. We randomly gener-
pt < 10  . This is certainly well beyond the capability of
any computational agent today.                        ated tasks and routes and simulated the problem starting from
  While we have so far only analyzed relatively simple mod- a situation where no task is assigned to any agent.
els, it seems clear that in general the probability mass is very We used the experiments to observe three properties: ef-
likely to be spread among a large set of states as the size of ﬁciency, branching probabilities and individual rationality.
the problem increases, and thus the method will be bounded- First, we want to show the efﬁciency of the randomized pro-
rational incentive-compatible with the parameter being the tocol with respect to straight hill-climbing to show that it in-
problem size.                                         deed escapes from local minima. Figure 4 compares the per-
                                                      formance of local search with randomization (LOO, shown
                                                      by the thick line) with stochastic search (SS, thin line) and
5  Experimental results                               strict hill-climbing (LS, dashed line) on 100 randomly gener-
We have implemented the mechanism we described for a net- ated problem instances. We see that local search gets stuck in
work resource allocation problem. It consists of allocating a local optimum and only reaches about half the total utility
tracks in the train network shown in Figure 3 to different op- that the randomized search gets. Thus, the scheme seems to
erators. To avoid collisions, each arc in the graph can only be effective at avoiding local minima.
be allocated to one operator who can then run trains on it. Second, we are interested in the average probability pm
At the same time, there are certain demands for transport-
ing goods. For each demand, 3 feasible routes are com-    m     1   2   3    4     5     6    7    ≥ 8
puted and it can take any of these routes. This is modelled r(m) 2 21   69  101   194   120  160   333
as an MCOP having a variable for each task whose domain
is the agent and route assigned to it. For example, if task 3
                                                                Table 1: Computational results for pm
(London, Manchester) is assigned to agent a1 on the path