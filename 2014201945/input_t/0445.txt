              A  Scalable    Method    for  Multiagent     Constraint    Optimization
                                    Adrian  Petcu  and  Boi Faltings
                                  {adrian.petcu, boi.faltings}@epﬂ.ch
                                    http://liawww.epfl.ch/
                                    Artiﬁcial Intelligence Laboratory
                           Ecole Polytechnique  Fed´ erale´ de Lausanne (EPFL)
                            IN  (Ecublens), CH-1015  Lausanne,  Switzerland

                    Abstract                          different variables. Every state change in a distributed back-
                                                      track algorithm requires at least one message; in the worst
    We present in this paper a new, complete method   case, even in a parallel algorithm there will be exponentially
    for distributed constraint optimization, based on many state changes [Kasif, 1986], thus resulting in exponen-
    dynamic programming. It is a utility propagation  tially many messages. So far, this has been a serious draw-
    method, inspired by the sum-product algorithm,    back for the application of distributed algorithms in the real
    which is correct only for tree-shaped constraint net- world, especially for optimization problems (also noted in
    works. In this paper, we show how to extend that  [Maheswaran et al., 2004]).
    algorithm to arbitrary topologies using a pseudotree This leads us to believe that other search paradigms, in par-
    arrangement of the problem graph. Our algorithm   ticular those based on dynamic programming, may be more
    requires a linear number of messages, whose max-  appropriate for DisCSP. For example, an algorithm that incre-
    imal size depends on the induced width along the  mentally computes the set of all partial solutions for all pre-
    particular pseudotree chosen.                     vious variables according to a certain order would only use
    We compare our algorithm with backtracking algo-  a linear number of messages. However, the messages could
    rithms, and present experimental results. For some grow exponentially in size, and the algorithm would not have
    problem types we report orders of magnitude fewer any parallelism.
    messages, and the ability to deal with arbitrarily  Recently, the sum-product algorithm [Kschischang et al.,
    large problems. Our algorithm is formulated for   2001] has been proposed for certain constraint satisfaction
    optimization problems, but can be easily applied to problems, for example decoding. It is an acceptable com-
    satisfaction problems as well.                    promise as it combines a dynamic-programming style explo-
                                                      ration of a search space with a ﬁxed message size, and can
                                                      easily be implemented in a distributed fashion. However, it is
1  Introduction                                       correct only for tree-shaped constraint networks.
Distributed Constraint Satisfaction (DisCSP) was ﬁrst stud- In this paper, we show how to extend the algorithm to arbi-
ied by Yokoo [Yokoo et al., 1992] and has recently at- trary topologies using a pseudotree arrangement of the prob-
tracted increasing interest. In distributed constraint satis- lem graph, and report our experimental results. The algorithm
faction each variable and constraint is owned by an agent. is formulated for optimization problems, but can be easily ap-
Systematic search algorithms for solving DisCSP are gener- plied to satisfaction problems by having relations with utility
ally derived from depth-ﬁrst search algorithms based on some either 0 (for allowed tuples) or negative values (for disallowed
form of backtracking [Silaghi et al., 2000; Yokoo et al., 1998; tuples). Utility maximization produces a solution if there is
Meisels and Zivan, 2003; Hamadi et al., 1998].        an assignment with utility 0.
  Recently, the paradigm of asynchronous distributed search The rest of this paper is structured as follows: Section 2
has been extended to constraint optimization by integrating presents the deﬁnitions and the notation we use, Section 3
a bound propagation mechanism (ADOPT - [Modi et al.,  presents an optimization procedure for trees, Section 4 the
2003]).                                               optimization for graphs, Section 5 proves the complexity to
  In general, optimization problems are much harder to solve be equal to the induced width, Section 6 compares theoreti-
than DisCSP ones, as the goal is not just to ﬁnd any solution, cally our algorithm with other aproaches, Section 7 presents
but the best one, thus requiring more exploration of the search experimental results, and we conclude in Section 8.
space. The common goal of all distributed algorithms is to
minimize the number of messages required to ﬁnd a solution. 2 Deﬁnitions & notation
  Backtracking algorithms are very popular in centralized
systems because they require very little memory. In a dis- A discrete multiagent constraint optimization problem
                                                                      <   , ,   >
tributed implementation, however, they may not be the best (MCOP) is a tuple X D R such that:
basis since in backtrack search, control shifts rapidly between • X = {X1, ..., Xm} is the set of variables/agents;  • D =  {d1, ..., dm} is a set of domains of the variables,
    each given as a ﬁnite set of possible values.

  • R = {r1, ..., rp} is a set of relations, where a relation ri
                                +
    is a function di1 × .. × dik → < which denotes how
    much utility is assigned to each possible combination of
    values of the involved variables.
  In this paper we deal with unary and binary relations, being
well-known that higher arity relations can also be expressed
in these terms with little modiﬁcations. In a MCOP, any value
combination is allowed; the goal is to ﬁnd an assignment X ∗
for the variables Xi that maximizes the sum of utilities.  Figure 1: Example of a pseudotree arrangement.
  For a node Xk, we deﬁne Rk(Xj ) = the relation(s) between
Xk and its neighbor Xj .                              4   Distributed  constraint optimization  for
                                                          general networks
3  Distributed  constraint  optimization  for         To apply a DTREE-like algorithm to a cyclic graph, we ﬁrst
   tree-structured  networks                          need to arrange the graph as a pseudotree (it is known that
                                                      this arrangement is possible for any graph).
For tree-structured networks, polynomial-time complete opti-
mization methods have been developed (e.g. the sum-product 4.1 Pseudotrees
algorithm [Kschischang et al., 2001] and the DTREE algo- Deﬁnition 1 A pseudo-tree arrangement of a graph G is a
rithm from [Petcu and Faltings, 2004]).               rooted tree with the same vertices as G and the property that
  In DTREE, the agents send UTIL messages (utility vectors) adjacent vertices from the original graph fall in the same
to their parents. A child Xl of node Xk would send Xk a vec- branch of the tree (e.g. X0 and X11 in Figure 1).
tor of the optimal utilities u∗ (vj ) that can be achieved by the
                      Xl  k                             Pseudotrees have already been investigated as a means
subtree rooted at Xl plus Rl(Xk) , and are compatible with
          j                                           to boost search ([Freuder, 1985; Freuder and Quinn, 1985;
each value vk of Xk (such a vector has |dom(Xk)| values). Dechter, 2003; Schiex, 1999]). The main idea with their use
  For the leaf nodes it is immediate to compute these valu- in search, is that due to the relative independence of nodes
ations by just inspecting the constraints they have with their lying in different branches of the pseudotree, it is possible to
single neighbors, so they initiate the process. Then each node perform search in parallel on these independent branches.
Xi relays these messages according to the following process: Figure 1 shows an example of a pseudotree that we shall
                                                      refer to in the rest of this paper. It consists of tree edges,
  • Wait for UTIL messages from all children. Since all of shown as solid lines, and back edges, shown as dashed lines,
    the respective subtrees are disjoint, by summing them that are not part of the spanning tree (e.g. 8−1, 12−2, 4−0).
    up, Xi computes how much utility each of its values We call a path in the graph that is entirely made of tree edges,
    gives for the whole subtree rooted at itself. This, to- a tree-path. A tree-path associated with a back-edge is the
    gether with the relation(s) between Xi and its parent Xj, tree-path connecting the two nodes involved in the back-edge
    enables Xi to compute exactly how much utility can be (please note that since our arrangement is a pseudotree, such
    achieved by the entire subtree rooted at Xi, taking into a tree path is always included in a branch of the tree). For
    account compatibility with each of Xj’s values. Thus, each back-edge, the higher node involved in that back-edge is
    Xi can send to Xj its UTIL message. Xi also stores its called the back-edge handler (e.g. the dark nodes 0, 1 and 2).
    optimal values corresponding to each value of Xj. We also deﬁne:

  • If root node, Xi can compute the optimal overall util- • P(X) - the parent of a node X: the single node higher in
    ity corresponding to each one of its values (based on all the hierarchy of the pseudotree that is connected to the
    the incoming UTIL messages), pick the optimal one, and node X directly through a tree edge (e.g. P (X4) = X1)
    send a VALUE message to its children, informing them • C(X) - the children of a node X: the set of nodes lower
    about its decision.                                   in the pseudotree that are connected to the node X di-
    Upon receipt of the VALUE message from its parent,    rectly through tree edges (e.g. C(X1) = {X3, X4})
    each node is able to pick the optimal value for itself (as
                                                        • PP(X)  - the pseudo-parents of a node X: the set of
    the previously stored optimal value corresponding to the
                                                          nodes higher in the pseudotree that are connected to the
    value its parent has chosen), and pass it on to its children.
                                                          node X directly through back-edges (P P (X8) = {X1})
    At this point, the algorithm is ﬁnished for Xi.
                                                        • PC(X)  - the pseudo-children of a node X: the set of
  The correctness of this algorithm was shown in the original nodes lower in the hierarchy of the pseudotree that are
paper, as well as the fact that it requires a linear number of connected to the node X directly through back-edges
messages, and linear memory.                              (e.g. P C(X0) = {X4, X11})  As it is already known, a DFS (depth-ﬁrst search) tree is Algorithm 1: DPOP  - Distributed pseudotree-
also a pseudotree (although the inverse does not always hold). optimization procedure for general networks.
So, a DFS tree obtained from the DFS traversal of the graph 1: DPOP(X , D, R)
starting from one of the nodes (chosen through a distributed
                                                            Each agent Xi executes:
leader election algorithm) will do just ﬁne. Due to the lack of 2:
space we do not present here a procedure for the creation of 3: Phase 1: pseudotree creation
                                          [
a DFS tree, and refer the reader to techniques like Barbosa, 4: elect leader from all X ∈ X
                     ]                                                         j
1996; Hamadi et al., 1998 .                              5: elected leader initiates pseudotree creation
4.2  The DPOP   algorithm                                6: afterwards, Xi knows P(Xi), PP(Xi), C(Xi) and PC(Xi)
                                                         7: Phase 2: UTIL message propagation
Our algorithm has 3 phases. First, the agents establish the
                                                         8: if |Children(Xi)| == 0 (i.e. Xi is a leaf node) then
pseudotree structure (see section 4.1) to be used in the fol- 9: UT IL (P(X )) ← Compute utils(P(X ), PP(X ))
lowing two phases. The next two phases are the UTIL and            Xi     i                    i      i
                                                        10:   Send message(P(Xi), UT ILXi (P(Xi)))
VALUE  propagations, which are similar to the ones from 11: activate UTIL Message handler()
DTREE  - section 3. Please refer to Algorithm 1 for a formal 12: Phase 3: VALUE message propagation
description of the algorithm, and to the rest of this section for 13: activate VALUE Message handler()
a detailed description of the UTIL and VALUE phases.    14: END  ALGORITHM
UTIL propagation                                        15:
As in DTREE, the UTIL propagation starts from the leaves 16: UTIL Message handler(Xk,UT ILXk (Xi))
of the pseudotree and propagates up the pseudotree, only 17: store UT ILXk (Xi)
through the tree edges. It is easy for an agent to identify 18: if UTIL messages from all children arrived then
                                                        19:   if Parent(Xi)==null (that means Xi is the root) then
whether it is a leaf in the pseudotree or not: it must have a    ∗
                                                        20:     vi ← Choose  optimal(null)
single tree edge (e.g. X7 to X13 in Figure 1).                                    ∗
  In a tree network, a UTIL message sent by a node to its par- 21: Send V ALUE(Xi, vi ) to all C(Xi)
ent is dependent only on the subtree rooted at the respective 22: else
node (no links to other parts of the tree), and the constraint 23: UT ILXi (P(Xi)) ← Compute utils(P(Xi), PP(Xi))
between the node and its parent. For example, consider the 24:  Send message(P(Xi), UT ILXi (P(Xi)))
                                                        25: return
message (X6 → X2). This message is clearly dependent only
                                                        26:
on the target variable X2, since there are no links between X6
                                                        27: VALUE  Message  handler(V ALUEXi    )
or X13 and any node above X2.                                                              P (Xi)
                                                                         ∗          Xi
  In a network with cycles (each back-edge in the pseudotree 28: add all Xk ← v ∈ V ALUE to agent view
                                                                         k          P (Xi)
produces a cycle), a message sent from a node to its parent       ∗
                                                        29: Xi ← vi = Choose  optimal(agent view)
may also depend on variables above the parent. This hap-                Xl
                                                        30: Send V ALUE    to all Xl ∈ C(Xi)
pens when there is a back-edge connecting the sending node              Xi
with such a variable. For example, consider the message 31:
                                                        32: Choose optimal(agent view)
(X8 →  X3) in Figure 1. We see that the utilities that the 33:
subtree rooted at X8 can achieve are not dependent only on
                                                              ∗
its parent X3 (as for X6 → X2). As X8 is connected with X1   vi ← argmaxvi    X    UT ILXl (vi, agent view)
through the backedge X8 → X1, X8 must take into account                    Xl∈C(Xi)
this dependency when sending its message to X3.                   ∗
  This is where the dynamic programming approach comes  34: return vi
                                                        35:
into play: X8 will compute the optimal utilities its subtree can
                                                        36: Compute  utils(P(Xi), PP(Xi))
achieve for each value combination of the tuple hX3, X1i. It
will then assemble a message as a hypercube with 2 dimen- 37: for all combinations of values of Xk ∈ P P (Xi) do
                                                        38:   let Xj be Parent(Xi)
sions (one for the target variable X3 and one for the back-
                                                        39:   similarly to DTREE, compute a vector UT ILX (Xj )
edge handler X1), and send it to X3 (see Table 1).                         ∗                         i
  This is the key difference between DTREE and DPOP:          of all {UtilXi (vi (vj ), vj )|vj ∈ Dom(Xj )}
                                                        40:
messages travelling through the network in DTREE always     assemble a hypercube UT ILXi (Xj ) out of all these
have a single dimension (they are linear in the domain size of vectors (totaling |P P (Xi)| + 1 dimensions).
                                                        41:
the target variable), whereas in DPOP, messages have multi- return UT ILXi (Xj )
ple dimensions (one for the target variable, and another one
for each context variable).                                                0           1              m−1
                                                        X8 →  X3     X3 = v3     X3 = v3   ... X3  = v3
                                                               0      ∗   0       ∗   0           ∗   0
Combining messages - dimensionality increase             X1 = v1     uX8 (v1)    uX8 (v1)  ...   uX8 (v1)
Let us consider this example: X5 receives 2 messages from  ...          ...        ...     ...      ...
its children X and X ; the message from X has X  as           n−1    ∗   n−1     ∗   n−1         ∗   n−1
            11     12                   11     0       X1  = v1     uX8 (v1 )   uX8 (v1 )  ...  uX8 (v1 )
context, and the one from X12 has X2 as context. Both have
one dimension for X5 (target variable) and one dimension Table 1: UTIL message sent from X8 to X3, in Figure 1
for their context variable (X0 and X2 respectively), therefore,their dimensionality is 2. X5 needs to send out its message connected). The induced width is the maximum number of
to its parent (X2). X5 considers all possible values of X2, parents of any node in the induced graph.
and for each one of them, all combinations of values of the It is shown in [Dechter, 2003] that the width of a tree (no
context variables (X0 and X2) and X5 are considered; the back-edges) is 1. Actually the back-edges are the ones that
values of X5 are always chosen such that the optimal utilities inﬂuence the width: a single backedge produces an induced
for each tuple < X0 × X2 × X2 > are achieved. Note that width of 2. From the construction of the induced tree, it is
since X2 is both a context variable and the target variable, the easy to see that several backedges produce increases in the
message collapses to 2 dimensions, not 3.             width only when their tree-paths overlap on at least one edge,
  One can think of this process as the cross product of mes- and their respective handlers are different; otherwise their ef-
sages X11 → X5  and X12 →  X5 resulting in a hypercube fects on the width do not combine. Thus, the width is given
with dimensions X0, X2 and X5, followed by a projection on by the size of the maximal set of back-edges which have over-
the X5 axis, which retains the optimal utilities for the tuples lapping tree-paths and distinct handlers.
< X0 × X2 > (optimizing w.r.t. X5 given X0 and X2).     During the UTIL propagation, the message size varies; the
                                                      largest message is the one with the most dimensions. We have
Collapsing messages - dimensionality decrease
                                                      seen that a dimension X is added to a message when a back-
Whenever a multi-dimensional UTIL message reaches a tar-                  i
                                                      edge with Xi as a handler is ﬁrst encountered in the propa-
get variable that occupies one dimension in the message (a gation, and travels through the tree-path associated with the
back-edge handler), the target variable optimizes itself out of back-edge. It is then eliminated by projection when the mes-
the context, and the outgoing message looses the respective
                                                      sage arrives at Xi. The maximal dimensionality is therefore
dimension.                                            given by the maximal number of overlaps of tree-paths asso-
  We can take the example of X1, which is initially present ciated with back-edges with distinct handlers.
in the context of the message X8 → X3: once the message We  have thus shown that the maximal dimensionality is
arrives at X1, since X1 does not have any more inﬂuence on equal to the induced width.                 2
the upper parts of the tree, X1 can ”optimize itself away” by
simply choosing the best value for itself, for each value of its Exponential size messages are not necessarily a problem in
parent X0 (the normal DTREE process). Thus, one can see all setups (depending on the resources available and on the in-
that a back edge handler (X1 in our case) appears as an extra duced width - low width problems generate small messages!)
dimension in the messages travelling from the lower end of However, when the maximum message size is limited, one
the back edge (X8) to itself, through the tree path associated can serialize big messages by letting the back-edge handlers
with the back edge (X8 → X3 → X1).                    ask explicitly for valuations for each one of their values se-
                                                      quentially, so each message can have customizable size.
VALUE  propagation                                      A workaround against exponential memory is possible by
The VALUE  phase is similar to DTREE. Now, in addition to renouncing exactness, and propagating valuations for the
                          Xj
its parent’s value, the V ALUE message a node Xj re-
                          P (Xj )                     best/worst value combinations (upper/lower bounds) instead
ceives from its parent also contains the values of all the vari- of all combinations.
ables that were present in the context of Xj’s UTIL message
                                   2        ∗
for its parent. E.g.: X0 sends X2 V ALUE0 (X0 ← v0 ), then 6 Comparison with other approaches
X       X  V ALUE5   X     v∗, X   v∗      X
 2 sends  5        2 ( 0 ←  0  2 ←  2 ), and 5 sends  Schiex [Schiex, 1999] notes the fact that so far, pseudotree
X   V ALUE11  X     v∗, X    v∗
 11         5 ( 0 ←  0   5 ←  5 ).                    arrangements have been mainly used for search procedures
                                                      (essentially backtrack-based search, or branch-and-bound
5  Complexity   analysis                              for optimization). As good examples, see the Distributed
By construction, the number of messages our algorithm pro- Depth-ﬁrst Branch and Bound (DDBB), Distributed Iterative
duces is linear: there are n − 1 UTIL messages - one through Deepening (DID), ADOPT, Synchronous Branch and Bound
each tree-edge (n is the number of nodes in the problem), and (SBB) and Iterative Distributed Breakout (IDB). All these
m linear size VALUE messages - one through each edge (m procedures have a worst case complexity exponential in the
is the number of edges). The DFS construction also produces depth of the pseudotree arrangement (basically because all
a linear number of messages (good algorithms require 2 × m the variables on the longest branch from root to a leaf have to
messages). Thus, the complexity of this algorithm lies in the be instantiated sequentially, and all their value combinations
size of the UTIL messages.                            tried out). It was shown in [Bayardo and Miranker, 1995] that
                                                      there are ways to obtain shallow pseudotrees (within a loga-
Theorem 1 The largest UTIL message produced by Algo-  rithmic factor of the induced width), but these require intri-
rithm 1 is space-exponential in the width of the pseudotree cate heuristics like the ones from [Freuder and Quinn, 1985;
induced by the DFS ordering used.                     Maheswaran et al., 2004], which have not yet been adapted
PROOF.  Dechter ([Dechter, 2003], chapter 4, pages 86-88) to a distributed setting, as also noted by the authors of the
describes the ﬁll-up method for obtaining the induced width. second paper.
First, we build the induced graph: we take the DFS traver- In contrast, our approach exhibits a worst case complexity
sal of the pseudotree as an ordering of the graph and process exponential in the width of the graph induced by the pseu-
the nodes recursively (bottom up) along this order. When a dotree ordering. Arnborg shows in [Arnborg, 1985] that ﬁnd-
node is processed, all its parents are connected (if not already ing a min-width ordering of a graph is NP-hard; however,the DFS traversal of the graph has the advantage that it pro- Algo/Scenario Test L Test Z Test T  Test H
duces a good approximation, and is easy to implement in a MCN , No Pass 626.4  1111.64  1841.28  1898.04
distributed context. This, coupled with the fact that the depth MLSP, No Pass 597.88 663.32 477.56 679.36
of the pseudotree is irrelevant to the complexity, means that MCN , Pass 95.67  101.90   94.93    258.07
our algorithm works well with a simple DFS ordering. To  MLSP , Pass   81.77     91.5    107.77    255.2
see this fundamental difference between the two approaches, DPOP         30      30        18       30
consider a problem that is a ring with n nodes. A DFS order-
ing of such a graph would yield a pseudotree with height n, Table 2: DPOP vs 4 ADOPT versions: number of messages
and one back edge, thus the induced width is 2. A backtrack- in sensor allocation problems.
ing algorithm is time exponential in n, whereas our algorithm
is linear, with message size O(|d|2). Since the exponential
complexity translates directly in the explosion of the number variables). The explanation is that our algorithm always pro-
of messages exchanged, these backtracking-based algorithms duces a linear number of messages.
have not yet been applied to large systems.             Regarding the size of the messages: these problems have
  Furthermore, it was shown by Dechter in [Dechter and Fat- graphs with very low induced widths (2), basically given by
tah, 2001] that the induced width is always less than or at the intersections between corridors. Thus, our algorithm em-
most equal with the pseudotree height; thus we can conclude ploys linear messages in most of the parts of the problems,
theoretically that our algorithm will always do at least as and only in the intersections are created 2 messages with 2
well as a pseudotree backtrack-based algorithm on the same dimensions (in this case with 64 values each).
pseudotree ordering. However, it is only fair to say that our This fact gives our algorithm the ability to solve arbitrarily
aproach can generate very big messages in the worst case, so large instances of this particular kind of real-world problems.
one has to ﬁnd a proper tradeoff between the number and the
size of the messages transmitted through the system.  7.2  Meeting  scheduling
                                                      We  experimented with distributed meeting scheduling in an
7  Experimental    evaluation                         organization with a hierarchical structure (a tree with depart-
Usual performance metrics for distributed algorithms are the ments as nodes, and a set of agents working in each de-
                                                                                                     [
number of messages and the number of synchronous cycles partment). The CSP model is the PEAV model from Ma-
                                                                         ]
required to ﬁnd the optimal solution. Both are linear in our heswaran et al., 2004 . Each agent has multiple variables:
case. For the number of messages, see section 5; the number one for the start time of each meeting it participates in, with
of synchronous cycles is two times the height of the pseu- 8 timeslots as values. Mutual exclusion constraints are im-
dotree (one UTIL propagation, and one VALUE propagation). posed on the variables of an agent, and equality constraints
We also introduce the maximal message size as a metric. are imposed on the corresponding variables of all agents in-
                                                      volved in the same meeting. Private, unary constraints placed
7.1  Sensor networks                                  by an agent on its own variables show how much it values
                                                      each meeting/start time. Random meetings are generated,
One of our experimental setups is the sensor grid testbed from each with a certain utility for each agent. The objective is
[Bejar et al., 2005]. Brieﬂy, there is a set of targets in a sensor to ﬁnd the schedule that maximizes the overall utility.
ﬁeld, and the problem is to allocate 3 different sensors to each Table 3 shows how our algorithm scales up with the size
target. This is a NP-complete resource allocation problem. of the problems. Notice that the total number of messages
  In [Bejar et al., 2005], random instances are solved by includes the VALUE messages (linear size), and that due to
AWC  (a complete algorithm for constraint satisfaction). The the fact that intra-agent subproblems are denser than the rest
problems are relatively small (100 sensors and maximum 18 of the problem, high-dimensional messages are likely to be
targets, beyond which the problems become intractable). Our virtual, intra-agent messages (not actually transmitted over
initial experiments with this setup solve to optimality prob- the network). To our knowledge, these are by far the largest
lems in a grid of 400 sensors, with up to 40 targets. optimization problems solved with a complete, distributed al-
  Another setup is the one from [Maheswaran et al., 2004], gorithm (200 agents, 101 meetings, 270 variables, 341 con-
where there are corridors composed of squares which indi- straints). The largest reported previous experiment is [Mah-
cate areas to be observed. Sensors are located at each ver- eswaran et al., 2004], with 33 agents, 12 meetings, 47 vari-
tex of a square; in order for a square to be ”observed”, all ables, 123 constraints, solved using ADOPT.
4 sensors in its vertices need to be focused on the respective
square. Depending on the topology of the grid, some sensors
are shared between several squares, and they can observe only 8 Conclusions and future work
one of them at a time. The authors test 4 improved versions We presented in this paper a new complete method for dis-
of ADOPT  (current state of the art for MCOP) on 4 differ- tributed constraint optimization. This method is a utility-
ent scenarios, where the corridors have the shapes of capital propagation method that extends tree propagation algorithms
letters L, Z, T and H. Their results and a comparison with like the sum-product algorithm or DTREE to work on arbi-
DPOP  are in Table 2. One can see the dramatic reduction trary topologies using a pseudotree structure. It requires a
of the number of messages required (in some cases orders of linear number of messages, the largest one being exponen-
magnitude), even for these very small problem instances (16 tial in the induced width along the particular pseudotree cho-