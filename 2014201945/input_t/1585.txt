                               Learning    Coordination      Classiﬁers

                      Yuhong   Guo       Russell  Greiner       Dale Schuurmans
                                   Department  of Computing   Science
                                          University of Alberta
                                 {yuhong,greiner,dale}@cs.ualberta.ca


                    Abstract                          explicitly represented in a directed graphical model [Getoor et
                                                      al., 2001; 2002]. Other approaches for learning multivariate
    We present a new approach to ensemble classiﬁca-  classiﬁers include conditional random ﬁelds (CRFs) [Lafferty
    tion that requires learning only a single base clas- et al., 2001], relational Markov networks (RMNs) [Taskar et
    siﬁer. The idea is to learn a classiﬁer that simulta- al., 2002], and maximum margin Markov networks (M3N)
    neously predicts pairs of test labels—as opposed to [Taskar et al., 2003]. All of these methods have led to sub-
    learning multiple predictors for single test labels— stantial progress on learning classiﬁers that make dependent
    then coordinating the assignment of individual la- predictions of test labels that are explicitly related.
    bels by propagating beliefs on a graph over the data.
    We argue that the approach is statistically well mo- Although learning multivariate predictors is an exciting
    tivated, even for independent identically distributed problem, we nevertheless focus on the classical iid case in
    (iid) data. In fact, we present experimental results this paper. However, we demonstrate what we believe is a
    that show improvements in classiﬁcation accuracy  surprising and counterintuitive connection: that learning mul-
    over single-example classiﬁers, across a range of tivariate dependent predictions is a beneﬁcial idea even in
    iid data sets and over a set of base classiﬁers. Like the iid setting. In particular, we develop a relational learn-
    boosting, the technique increases representational ing strategy that classiﬁes test patterns by connecting their la-
    capacity while controlling variance through a prin- bels in a graphical model—hence correlating the subsequent
    cipled form of classiﬁer combination.             predictions—even when it is explicitly assumed that all train-
                                                      ing and test examples are iid.
                                                        Before explaining the rationale behind our approach and
1  Introduction                                       explaining why dependent prediction still makes sense in
Supervised learning has been by far the most studied task in the iid setting, we note that standard relational learning ap-
machine learning research. The problem is to take a ﬁnite set proaches, such as PRMs, CRFs, RMNs and M3Ns, do not
of observed training examples (x1, y1), ..., (xn, yn) and pro- naturally correlate predictions on iid data. That is, these tech-
duce a classiﬁer f : X → Y that achieves small misclassiﬁ- niques only consider label dependencies that are explicitly as-
cation error on subsequent test examples. Most research has serted to hold in the true underlying model of the domain. In
tended to adopt a standard “iid” assumption that the training the iid case, since no dependencies are asserted between test
and test examples are independent and identically distributed. labels, these standard relational approaches reduce to single-
In fact, this assumption is fundamental to much of the theo- label learning techniques, such as univariate logistic regres-
retical research on the topic [Anthony and Bartlett, 1999] and sion and support vector machines. However, what we are
also characterizes most standard learning methods—as exem- proposing is different: we intentionally add dependencies be-
pliﬁed by the fact that most machine learning methods clas- tween test labels, even when all labels are explicitly assumed
sify each test pattern in isolation, independently of other test to be independent in the underlying data generation process.
patterns.                                             Surprisingly, we demonstrate that correlating predictions can
  Recently, however, increasing attention has been paid to still be advantageous.
problems where the training and test labels are not indepen- After introducing our basic approach below, we then mo-
dent, but instead strongly related. For example, in domains tivate and justify our technique in three separate ways. First,
such as part of speech tagging and webpage classiﬁcation, we show that predicting correlated test labels is statistically
each word-tag or webpage-label depends on the tag or label of justiﬁed in the iid setting, even when the independence as-
proximal words or webpages, in addition to just the features sumptions are explicitly taken into account. In fact, we show
of the immediate word or webpage. Various forms of “rela- that it is incorrect to conclude that a learned predictor can suf-
tional” learning models have been developed to handle these ﬁciently treat test cases as independent simply because they
kinds of problems over the last few years. A notable example come from an iid source. Second, we show that our pro-
is work on probabilistic relational models (PRMs), where the posed relational learning technique can be viewed as a nat-
correlation between the class labels of different instances is ural generalization of similarity-based learning techniques.Moreover, it can also be viewed as a simple form of ensem- (x1, y1), ..., (xn, yn) is given. First we construct a set of
ble learning method that has some advantages over standard pairs from the set {(xixj , yiyj)} and then supply these as
approaches. Third, we show empirically that our proposed a conventional training set for learning a predictive model
method can achieve improvements in classiﬁcation accuracy P (yiyj|xixj, φ) from data. (In our experiments below we
across a range of iid domains, for different base learning al- ignore duplicate pairs but otherwise include both orderings
gorithms.                                             of each distinct pair to ensure that the learned model is sym-
                                                      metric.) Once the training data is constructed, the parame-
2  Learning   Coordinated   Label  Predictors         ters of the model, φ, can then be estimated in the same way
                                                      as the univariate case, either by using a maximum (condi-
We begin by simply introducing our learning method, and tional) likelihood or maximum a posteriori estimation prin-
then attempt to motivate it more thoroughly below. Initially, ciple. For example, given a linear logistic representation for
we will focus on using probabilistic classiﬁers (although we P (yi|xi, θ), we use an analogous linear logistic representa-
brieﬂy consider an extension to nonprobabilistic classiﬁers in tion for P (yiyj |xixj, φ) but over the joint feature space xixj;
Section 5 below).                                     thus training the two models under the same estimation prin-
  In the iid setting, the standard approach to probabilistic ciple, but using different (although related) data sets.
classiﬁcation is to learn a univariate model P (y|x, θ) that as- A coordination model learned in this way will generally
serts a conditional probability distribution over a single clas- not make independent predictions of yi and yj, since the ex-
siﬁcation variable y given an input pattern x, where θ rep- tended parameters φ are not constrained to enforce indepen-
resents the parameters of the model. Given such a repre- dence.1 That is, we expect the model to learn to make de-
sentation, there are two key steps to building a univariate pendent, coordinated predictions of the two labels from the
classiﬁer: The ﬁrst is to learn a speciﬁc predictive model corresponding input patterns. Interestingly, learning a coor-
    x                    x          x
P (y| , θ) given training data ( 1, y1), ..., ( n, yn), based on dination classiﬁer has the advantage of potentially squaring
using a principle such as maximum (conditional) likelihood the number of available training examples, even though this
or maximum a posteriori estimation. Then, given a set of test advantage is mitigated by subsampling and the increase in the
       x∗    x∗                  x∗
patterns 1, ..., m, one classiﬁes each i independently by complexity of the model being learned.
computing the label yˆi that maximizes the estimated condi-
                                  x∗
tional probability, yˆi = arg maxy P (y| i , θ). Natural ex- 2.2 Classifying Test Data with Coordination
amples of this approach are learning naive Bayes classiﬁers Given a coordination classiﬁer, we require a principle for
[Friedman et al., 1997], logistic regression classiﬁers [Hastie classifying individual test patterns x∗. In fact, the problem of
et al., 2001], kernel logistic regression classiﬁers [Zhu and classifying test patterns becomes much more involved in this
Hastie, 2001], sigmoid network classiﬁers [Neal, 1996], and case. The approach we take is to consider the set of training
Bayesian network classiﬁers [Greiner and Zhou, 2002].          x         x                    x∗    x∗
                                                      examples ( 1, y1), ..., ( n, yn) and test patterns 1, ..., m as
  Our approach is different. Instead of learning a univari-                                         x∗
                                                      a whole. That is, rather than classify each test pattern i in
ate classiﬁer that predicts only a single label, we instead isolation, we instead seek to classify test patterns in a depen-
                                           x x
propose to learn a pairwise label classiﬁer P (yiyj| i j, φ) dent manner. To perform classiﬁcation, we proceed in three
                                      x     x
that takes an arbitrary pair of input patterns, i and j , and stages reminiscent of conditional random ﬁelds: First, we
asserts a conditional joint distribution over the pair of la- construct a graph over the test and training labels. Once the
bels yi and yj. For example, if there are two classes, say graph has been constructed, we then use the learned coordi-
0 and 1, then a pairwise classiﬁer would assert the condi- nation classiﬁer P (yiyj|xixj, φ) to assign “potentials” to the
tional probability of the four possible pair labelings (yi, yj ) ∈ possible labelings of each edge (y , y ). These potentials can
                                                x                                 i  j
{(0, 0), (0, 1), (1, 0), (1, 1)} given the two input patterns i then be used to deﬁne a Markov random ﬁeld over test label
   x
and j. In general the pairwise predictor does not assume that assignments, thereby establishing a joint probability distribu-
                           x     x
yi and yj are independent given i and j, even though they tion over the labelings. Finally, we compute a joint labeling
are indeed assumed to be independent in the true model (we ∗ ∗
                                                      y1 , ..., ym of the test examples that maximizes (or at least ap-
present a justiﬁcation of this in Section 3 below). We refer proximately maximizes) the joint label probability. We de-
to a pairwise label classiﬁer of this form as a “coordination scribe each of these three steps in more detail below.
classiﬁer” to highlight the fact that it attempts to model any
                                                        Deﬁning the graph First, to construct the graph, we only
coordination that might appear between the labels yi and yj                                     ∗  ∗
given the input patterns xi and xj. Given the alternative rep- consider edges that connect a pair of test labels (yi , yj ), or a
                                                                                 ∗
resentation P (yiyj|xixj, φ) we next describe the two main test label and a training label (yi , yj ). That is, after training
processes of, ﬁrst, training a coordination classiﬁer from data, we do not make any further use of edges between training
and then using it to label test patterns.             labels.
                                                        To classify test patterns, the simplest approach, concep-
2.1  Training a Coordination Classiﬁer                tually, is to consider the complete graph that connects each

A coordination classiﬁer doubles the number of input fea- 1Many readers are probably objecting at this point that, given the
tures and squares the number of output classes from an orig- iid assumption, there can be no new information to be gained from
inal univariate classiﬁer. Despite the increase in model com- the n2 example pairs that was not already present in the original n
plexity, training a coordination classiﬁer remains concep- examples. However, Section 3 argues that this conclusion is gener-
tually straightforward. Assume a standard training sample ally incorrect in a machine learning context.         ∗                                                                          test examples
test label yi to all other test and training labels. However,
we have found that it is usually impractical to consider all     true
m((m  − 1)/2 +  n) test pairs (ignoring duplicate pairs).     conditional         x1          x2
Therefore, we reduce the number of edges by adding a few        model
restrictions. The natural alternatives we consider below are:
(i) connecting each test label only to training labels (which,
as we will see, is analogous to standard similarity and kernel
based learning methods), (ii) connecting each test label only   learned
to other test labels (which, surprisingly, gives the best results conditional     y1          y2
in our experiments below), and (iii) connecting each test label model
to both training and test labels. To further reduce the overall
number of edges, we then uniformly subsample edges, sub-
                                                      Figure 1: In an iid setting, the true test labels y1 and y2 are
ject to these different restrictions.                 independent given the true conditional model. However, they
  Deﬁning the potentials Once a graph has been con-   are not independent given a learned estimate of the model.
structed, we then assign potentials to the conﬁgurations of
each edge. There are two cases depending on whether the   ∗  x∗x
                                                      P (yi yj| i j, φ) plays the role of a generalized similarity
edge connects two test labels, or a test label and a training              ∗            x         x
                                                      measure for classifying yi in terms of ( 1, y1), ..., ( n, yn).
label.
                                             ∗  ∗     The only difference is that the coordination model is learned
  For an edge that connects only two test labels, (yi , yj ), in an earlier training phase, rather than being ﬁxed before-
                            ∗  ∗       ∗ ∗ x∗x∗
we simply assign the potential ψ(yi , yj ) = P (yi yj | i j , φ) hand.
given by the learned coordination classiﬁer.            The remaining cases (ii) and (iii) are more difﬁcult because
  For an edge that connects a test and a training label, they introduce edges between test labels, which causes the la-
  ∗                                              ∗
(y , yj ), we assign a unit potential to the singleton node (y ) bels to become dependent. Surprisingly, we have found that
  i                               ∗              i
given by the conditional probability of yi given yj. That is, exploiting test label dependence can actually improve clas-
we assign                                             siﬁcation accuracy, even when the test data is known to be
                                      ∗    ∗          iid. (This is one of the main points of the paper.) For these
     ∗          ∗     ∗           P (y y |x x , φ)
ψ  (y )  =   P (y |y , x x , φ) =     i j  i j        models, computing the maximum probability assignment is
 yj  i          i  j  i j                  x∗x
                                   y P (yyj| i j, φ)  hard, because the graph can contain many loops. To cope
                                 P
                                                      with the problem of performing probabilistic inference in a
Once a potential has been assigned to the singleton (y∗) we
                    ∗                        i        complex graphical model, we use loopy belief propagation to
then remove the edge (yi , yj ) from the graph. Thus, the re- efﬁciently compute an approximate solution [Murphy et al.,
sulting graph only has edges between test labels, and possibly 1999]. Below we ﬁnd this gives adequate results.
a combination of singleton potentials on nodes (y∗) and pair-
                      ∗  ∗               i
wise potentials on edges (yi , yj ).
  Once all of the potentials have been assigned, we then de- 3 Rationale and Discussion
ﬁne a joint probability distribution over node labelings in the Before presenting our experimental results, it is important to
same manner as a Markov random ﬁeld, by taking the product explain the rationale behind our technique and suggest why
form                                                  coordinated classiﬁcation even makes sense in an iid setting.
                                                        Given the assumption that the training and test data are in-
                    m
    ∗    ∗        1             ∗        ∗  ∗     dependent, we are proposing to predict test labels by building
P (y , ..., y ) =          ψ  0 (y )     ψ(y , y )
    1    m        Z Y   Y    yj  i    Y     i  j      a graph, asserting joint potentials over pairs of labels (from
                    i=1  j0       j>i             a learned coordination classiﬁer), and using belief propaga-
                                                      tion to make dependent predictions. Why does it make sense
and normalizing by an appropriate constant Z.
                                                      to make dependent predictions of iid labels? It turns out that
  Computing the labeling Finally, given a joint probability this approach is justiﬁed even when taking the independence
distribution deﬁned by the Markov random ﬁeld, our goal is assumptions into account. Figure 1 illustrates the basic argu-
to compute the joint test pattern labeling that has maximum ment. In a standard machine learning setting, it is indeed true
probability. (Since we are only interested in computing the that, given the correct model for generating iid data, the label
maximum  probability assignment, we can ignore the normal- y1 for an input pattern x1 is independent of the label y2 for an-
ization constant above.) Depending on which edge model we other pattern x2. However, note that this requires knowledge
use, there are different implications.                of the correct model (or at least its correct structure), which is
  First, assuming model (i) (test labels only connect to train- rarely the case in classiﬁcation learning. Instead, given only
ing labels), there are no pairwise potentials and the Markov an estimate of the true model obtained from training data, y1
random ﬁeld becomes completely factored. In this case, and y2 remain dependent, as Figure 1 clearly shows. That is,
computing the maximum probability assignment is easy and in the context of supervised learning it is generally the case
can be determined independently for each test pattern. Es- that test labels are dependent given a learned model. In fact,
sentially, removing test-test edges reduces our technique it is obvious that supervised learning algorithms correlate the
to a classical method in which each test pattern is classi- labels on the training data. Our observation is simply that the
ﬁed independently. Here the learned coordination model same principle can also be applied to test data.  Although using a relational technique for an iid problem propagation) in order to label test instances. However, we
might still appear awkward, it has a well known precedent have still found the method to be robust to approximations,
in machine learning research: transductive learning [Vapnik, like running only a single iteration of loopy belief propaga-
1998; Zhu et al., 2003]. In transduction, the learner knows the tion, or even just taking local votes or products.
set of test patterns beforehand, and exploits this knowledge
to make predictions that are ultimately dependent. In fact, 4 Experimental Results
this idea has been exploited in recent approaches to semi-
supervised learning using Markov random ﬁelds [Zhu et al., We implemented the proposed coordination classiﬁcation
2003]. What we are proposing is a general framework for ex- technique for a few different forms of probabilistic classiﬁers
tending standard probabilistic learning algorithms to be trans- and using various standard iid data sets. Our intent was to
ductive in a similar fashion.                         determine whether the approach indeed had merit and was
  Our method can be further motivated by noting that it is also robust to alterations in classiﬁers and data sets. Our ex-
a natural extension of standard ideas in supervised iid clas- periments were conducted on standard two-class benchmark
siﬁcation. As observed, learning a coordination classiﬁer data sets from the UCI repository. The data sets used were:
P (yiyj|xixj, φ) is a natural generalization of learning meth- 1. australian, 2. breast, 3. chess, 4. cleve, 5. corral, 6.
ods that use a similarity measure k(xi, xj ) to classify test crx, 7. diabetes, 8. ﬂare, 9. german, 10. glass2, 11. heart,
        x∗                    x∗ x        x∗ x        12. hepatitis, 13. mofn-3-7, 14. pima, and 15. vote. All of
examples i based on similarities k( i , 1), ..., k( i , n) to
the training patterns. In fact, this corresponds to our graph our experimental results were obtained by 5-fold cross vali-
choice (i) above, which only connects test labels to training dation, repeated 10 times for different randomizations of the
labels. Coordination classiﬁcation extends the standard sim- graph structures. The tables and plots report averages of these
ilarity based approach by ﬁrst learning how patterns predict results, with standard deviations included in the tables.
dependencies between the labels (using standard methods ap- Table 1 and Figure 2 show the results of our ﬁrst exper-
plied in a novel way), and then correlating test predictions iment. In this case, we implemented a standard logistic re-
over a graph. Although there has indeed been recent work on gression model, using unaltered input features, to learn a base
learning kernels for classiﬁcation [Lanckriet et al., 2004], as coordination classiﬁer P (yiyj|xixj, φ). Classiﬁcation was
well as transductive learning with kernels [Xu et al., 2004], performed by running loopy belief propagation until the test
thus far these formulations have remained hard to extend and labels stabilized (usually after 2 to 8 iterations). In the ﬁrst
apply in practice.                                    experiment we used a graph over test labels only, to deter-
  Another interesting view of coordination classiﬁcation is mine whether introducing label dependency would have any
that it is a novel form of ensemble method. That is, the label beneﬁcial effect (see “edge” results). Here we subsampled
              x∗                                      test-test edges uniformly at random for an overall density of
for a test pattern i is computed by a combination of votes
from multiple predictors associated with different test (and 18 edges per test example. Table 1 and Figure 2 show the re-
                (∗)                                   sulting misclassiﬁcation error obtained by coordination clas-
training) patterns xj . In fact, even remotely connected pat- siﬁcation in comparison to learning a standard logistic regres-
terns can inﬂuence a classiﬁcation via belief propagation.
                                                      sion model, P (yi|xi, θ). Here we see a notable reduction in
  As an ensemble method, coordination classiﬁcation has overall misclassiﬁcation error (19%→16%), with a signiﬁ-
some useful features. First, it only requires the training of cant improvement on some data sets (Breast, -10%, Diabetes,
a single base classiﬁer P (yiyj|xixj , φ), rather than multiple -6%, MofN, -11%, Pima, -6%), and a minor increase on two
base classiﬁers trained from perturbed data. Second, as with data sets (Cleve, +1%, and Corral, +1%).
boosting and bagging, coordination classiﬁcation increases Table 1 also compares the error of coordination clas-
the representational capacity of an original (univariate) classi- siﬁcation to boosting the base logistic regression model
ﬁer. That is, given a classiﬁer representation for a single label P (y |x , θ). Here we used 18 rounds of Adaboost [Freund
    x                                                     i i
P (yi| i, θ), as mentioned previously, a coordination classi- and Schapire, 1996; 1997], thereby combining approximately
          x x
ﬁer P (yiyj| i j, φ) doubles the number of input features and the same number of votes per test pattern as coordination
squares the number of output classes. In addition, the pre- classiﬁcation. This experiment shows that as an ensemble
diction of a test label can, in principle, depend on all training method, coordination classiﬁcation performs competitively in
and test patterns. Of course, simply increasing the representa- this case. An advantage of coordination classiﬁcation is that
tional capacity of a base classiﬁer increases the risk of overﬁt- it only needs to learn a single base classiﬁer, as opposed to the
ting. However, the advantage of ensemble methods is that the multiple training episodes required by boosting. The need to
resulting classiﬁer, although more complex, is “smoothed” by run loopy belief propagation on the output labels is a disad-
a principled form of model combination, which helps avoid vantage however.
overﬁtting while exploiting added representational complex- To investigate the robustness of the method, we repeated
ity. That is, the process of model combination can be used the previous experiments using a different base classiﬁer. Ta-
to reduce the variance of the learned predictor. In our case, ble 2 and Figure 3 show the results of an experiment using
we base our model combination principle on inference in a naive Bayes instead of logistic regression as the base clas-
Markov random ﬁeld. We will see below that, in fact, coordi- siﬁcation method. Here the results are not as strong as the
nation classiﬁcation is competitive as an ensemble technique. ﬁrst case we tried, although they are still credible. Note that
  The biggest drawback of coordination classiﬁcation is the boosting obtains a few larger improvements, but also larger
need to perform probabilistic inference (via loopy belief losses. Classiﬁcation coordination appears to be fairly stable.Table 1: A comparison of average misclassiﬁcation error (%) Table 2: A comparison of average misclassiﬁcation error (%)
on UCI data using logistic regression as a base model. ∆ = on UCI data using naive Bayes as a base model. ∆ = aver-
average improvement over base.                        age improvement over base.
            base  boosted ∆  std  edge   ∆  std                 base  boosted ∆  std  edge   ∆   std
 australian 15.1  14.5   -0.6 0.4 14.2   -0.9 0.9    australian 13.8  16.2    2.4 1.6 14.2    0.4 0.4
 breast     14.5  14.9    0.4 0.3  4.2  -10.3 2.4    breast      2.6   5.0    2.4 1.1  2.7    0.1 0.1
 chess       7.6   8.3    0.7 0.2  7.6     0 0.1     chess      20.1   8.2   -11.9 3.1 19.1  -1.0 0.6
 cleve      15.3  14.9   -0.4 0.6 16.6   1.3 1.1     cleve      16.3  17.0    0.7 0.4 16.4    0.1 0.2
 corral      8.8   8.8     0 0.0   9.9   1.1 0.9     corral     13.6  13.6      0 5.5 14.2    0.6 0.7
 crx        16.5  16.3   -0.2 0.4 14.4   -2.1 0.8    crx        14.6  16.6    2.0 0.9 14.4   -0.2 0.2
 diabetes   31.2  31.3    0.1 0.1 24.8   -6.4 1.1    diabetes   22.6  22.6      0 0.0 22.6     0 0.2
 ﬂare       17.4  17.5    0.1 0.5 17.5   0.1 1.3     ﬂare       16.8  16.7    -0.1 0.1 17.0   0.2 0.4
 german     25.8  25.9    0.1 0.1 24.8   -1.0 1.0    german     25.5  26.3    0.8 0.7 25.1   -0.4 0.6
 glass2     29.4  27.5   -1.9 1.3 28.8   -0.6 4.7    glass2     15.6  11.9    -3.7 1.2 13.9  -1.7 1.2
 heart      16.3  15.9   -0.4 0.4 15.9   -0.4 1.9    heart      15.9  17.0    1.1 1.3 16.1    0.2 0.2
 hepatitis  17.5  17.5     0 0.0  14.1   -3.4 3.0    hepatitis  13.8  15.0    1.2 6.1  9.3   -4.5 1.2
 mofn-3-7   28.6  28.6     0 0.0  17.3  -11.3 0.8    mofn-3-7   14.2   0.0   -14.2 0.6 1.0  -13.2 0.8
 pima       30.9  30.5   -0.4 0.3 24.9   -6.0 0.8    pima       21.8  21.7    -0.1 0.1 22.2   0.4 0.4
 vote        6.7   6.7     0 0.8   5.8   -0.9 0.8    vote        9.9   5.5    -4.4 1.8 9.8   -0.1 0.2
 average    18.8  18.6   -0.2 0.4 16.1   -2.7 1.4    average    15.8  14.2    -1.6 1.6 14.5  -1.3 0.5

                     base vs boosted                                        base vs boosted
         40                                                    40

         35                                                    35

         30                                                    30

         25                                                    25

         20                                                    20

         15                                                    15

         10                                                    10
        Classification  error of base                         Classification  error of base

         5                                                     5

         0                                                     0
          0   5  10  15  20  25  30  35  40                     0   5   10  15  20  25  30  35  40
                  Classification error of boosted                       Classification error of boosted

                      base vs edge                                           base vs edge
         40                                                    40

         35                                                    35

         30                                                    30

         25                                                    25

         20                                                    20

         15                                                    15

         10                                                    10
        Classification  error of base                         Classification  error of base

         5                                                     5

         0                                                     0
          0   5  10  15  20  25  30  35  40                     0   5   10  15  20  25  30  35  40
                   Classification error of edge                          Classification error of edge

Figure 2: A comparison of average misclassiﬁcation error on Figure 3: A comparison of average misclassiﬁcation error
UCI data sets using logistic regression. Top plot: base model on UCI data sets using naive Bayes. Top plot: base model
versus boosted logistic regression. Bottom plot: base model versus boosted naive Bayes. Bottom plot: base model versus
versus “edge”-based coordination classiﬁcation.       “edge”-based coordination classiﬁcation.