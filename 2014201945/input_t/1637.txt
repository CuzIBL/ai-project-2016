 Inferring    Useful   Heuristics   from   the  Dynamics     of  Iterative  Relational    Classiﬁers

                                 Aram   Galstyan   and  Paul R. Cohen
                                  USC   Information Sciences  Institute
                                    4676 Admiralty  Way,  Suite 1001
                                    Marina del Rey, California 90292
                                       {galstyan,cohen}@isi.edu

                    Abstract                          to enhance prediction accuracy [Neville and Jensen, 2000;
                                                      Macskassy and Provost, 2003], there is an associated risk:
    In this paper we consider dynamical properties of a few false inferences sometimes lead to a “snow-ball” effect
    simple iterative relational classiﬁers. We conjec- [Neville and Jensen, 2000] cascading the number of misclas-
    ture that for a class of algorithms that use label– siﬁed entities as iteration proceeds. As a consequence, the
    propagation the iterative procedure can lead to non- ﬁnal results will depend strongly on the accuracy of initially
    trivial dynamics in the number of newly classiﬁed assigned class labels and on the classiﬁcation criteria, i.e.,
    instances. The underlaying reason for this non–   model parameters. More generally, it is known that many
    triviality is that in relational networks true class la- classiﬁcation algorithms are sensitive to parameter settings.
    bels are likely to propagate faster than false ones. For example, [Keogh et al., 2004] found that few popular
    We suggest that this phenomenon, which we call    data mining algorithms performed well on multiple problems
    two-tiered dynamics for binary classiﬁers, can be without parameter adjustments.
    used for establishing a self–consistent classiﬁca-
    tion threshold and a criterion for stopping iteration. In this paper we argue that for a class of iterative classiﬁers
    We demonstrate this effect for two unrelated binary the issue of parameter sensitivity can be addressed in a self
    classiﬁcation problems using a variation of a itera- consistent and elegant manner by examining the dynamics of
    tive relational neighbor classiﬁer. We also study an- the iterative procedure more closely. We illustrate this point
    alytically the dynamical properties of the suggested for a simple iterative classiﬁer that uses a threshold–based
    classiﬁer, and compare its results to the numerical criterion for labelling data–instances, and propose a meta–
    experiments on synthetic data.                    heuristic for setting the optimal threshold value. Our heuristic
                                                      is based on the assumption that in relational networks true
                                                      class labels are likely to propagate faster than false ones. We
1  Introduction                                       demonstrate that this phenomenon, which we call two-tiered
Recently there has been a growing interest in relational learn- dynamics, can serve as a natural criterion for both setting a
ing and classiﬁcation. While traditional learning approaches threshold value and stopping the iteration. Hence, our method
assume different data instances are independent and identi- reduces the dependency of iterative classiﬁcation on model
cally distributed, relational classiﬁcation methods allows for parameters.
the study of more complex data structures because it explic- To illustrate our approach, we introduce a simple algo-
itly takes into account their existing links and relations. Re- rithm for relational binary classiﬁcation. We consider the
cently developed algorithms for relational classiﬁcation have case when the relation between two data–instances is char-
been used for learning probabilistic relational models [Fried- acterized by the weight of the link connecting them, so that
man et al., 1999], hypertext classiﬁcation [Getoor et al., the relational structure is fully determined by an adjacency
2001], web page classiﬁcation [Slattery and Craven, 2000; matrix M. Given an initial set of known instances of a class
Macskassy and Provost, 2003], link prediction [Taskar et A, our algorithm then deﬁnes an iterative scheme with a sim-
al., 2004], discovery of authoritative information [Kleinberg, ple threshold based rule: an instance will be classiﬁed as type
1999], studying relational structures in scientiﬁc publica- A if it is connected to super–threshold number of classiﬁed
tions [McGovern et al., 2003], etc.                   or initially known instances of type A. The novelty of our
  Most of the existing methods for relational classiﬁcation approach is that we suggest a self–consistent way of setting
are iterative in nature [Neville and Jensen, 2000; Macskassy the parameter of our model, the threshold: namely, we set it
and Provost, 2003]. The intuitive assumption behind the it- automatically to the value that produces the most pronounced
erative approach is that information inferred about one entity two-tiered dynamics. We present empirical results that illus-
can be used to make inferences about other entities that are trate the use of this approach. We also develop an analytical
related to it. This allows class labels (or associated probabil- framework for describing the dynamics of iterative classiﬁca-
ities) to propagate throughout the system as newer instances tion of our algorithm, and compare its predictions with results
are classiﬁed. Although iterative classiﬁers have been shown obtained for synthetic, randomly generated networks.  The rest of the paper is organized as follows. In the next so that the state value si = 1 corresponds to type A. Ini-
section we provide a more detailed description of our algo- tially, only the entities with known class labels have si = 1.
rithm. In Section 3 we present results for two case studies that At each iteration step, for each non–classiﬁed instance we
demonstrate the two–tier dynamics. In Section 4 we present calculate the cumulative weight of the links of that instance
an analytical framework for studying the dynamical proper- with known instances of type A. If this cumulative weight
ties for a binary iterative classiﬁer. Discussion on our results is greater or equal than a preestablished threshold H, that in-
and future developments are presented in Section 5.   stance will be classiﬁed as a type A itself. This is shown
                                                      schematically in Figure 1. Note that our algorithm differs
2  Dynamics    of for Iterative Classiﬁcation         slightly from other simple relational classiﬁers (such as Re-
                                                      lational Neighbor classiﬁer [Macskassy and Provost, 2003])
To understand the main idea behind our approach, we ﬁnd in two aspects: First, it directly assigns class labels and not
it illustrative to frame the classiﬁcation problem as an epi- probabilities, and second, it is asymmetric in the sense that if
demic process. Speciﬁcally, let us consider a binary classi- an instance was classiﬁed as type A it will remain in that class
ﬁcation problem deﬁned on a network where data–instances for the remainder of the run. This later property implies that
(from classes A and B) correspond to nodes and the rela- the total number of classiﬁed A–instance is a monotonically
tions between them are represented by (weighted) links. We non–decreasing function of time. If the number of iterations
are given the correct classiﬁcation of a small subset of nodes
from class A and want to classify other members of this class. input adjacency matrix M
Assume that we are using a simple, threshold based iterative initialize si = 1, for initially known instances, si = 0 for the rest
relational classiﬁer (such as one described below in Fig. 1), initialize a threshold H
for assigning class labels and propagating them through the iterate t = 0 : Tmax
system. Now, if we treat the initially labelled data–instances for i–th node with si(t) = 0
                                                              calculate the weight w of adversary nodes connected to it:
as “infected”, then the iterative scheme deﬁnes an epidemic                   i
                                                              wi =   Mij sj (t)
model where at each time step new instances will be infected      P
                                                              if wi ≥ H ⇒ si(t + 1) = 1
if the super–threshold classiﬁcation criterion is met. Clearly, end for loop
the ﬁxed point of this epidemic process will depend both on end
the value of the threshold and both inter– and intra–class link
structure of the network. In the case where two classes are
totally decoupled (i.e., there are no cross–links between two Figure 1: Pseudo–code of the iterative procedure
sub–classes) the epidemics will be contained on the set A ,
and one can relax the classiﬁer threshold to guarantee that all Tmax is large enough, then a steady state will be achieved,
the instances of A will be correctly classiﬁed. If there are i.e., no instance will change its state upon further iterations.
links between data–instances in different sub–classes, then As we mentioned above, the ﬁnal state of the system will de-
there is a chance that the nodes from class B will be infected pend on the threshold value and the adjacency matrix. If the
too (i.e., misclassiﬁed). However, if the link patterns between threshold value is set sufﬁciently low then the system will
two subclasses are sufﬁciently different, we can hope that the evolve to a state where every instance has been classiﬁed as
process of epidemic spreading in two systems will be sepa- type A. On the other hand, if it is set too high, then no ad-
rated in time. Moreover, by tuning the classiﬁcation thresh- ditional instances will be classiﬁed at all. As we will show
old, we can control the rate of epidemic spreading in sub– below, for intermediary values of the threshold H the system
population A, hence affecting the epidemic spread in sub– will demonstrate two–tier dynamics.
population B. The main idea of our approach is to tune the
threshold parameter in order to achieve maximum temporal 3 Case Studies
separation of epidemic peaks in two classes.
  We characterize the dynamics of an iterative classiﬁer by In this section we test our hypothesis empirically on two dis-
the number of newly classiﬁed instances at each time step, tinct and unrelated data–sets: The ﬁrst is a synthetic data gen-
e.g., if N(t) is the total number of classiﬁed A–instances at erated by the Hats Simulator [Cohen and Morrison, 2004],
time t, then the relevant variable is ∆N(t) = N(t)−N(t−1). and the second is Cora [McCallum et al., 2000], a large col-
As it will be clear later, two–tiered dynamics arises whenever lection of research papers in computer science.
∆N(t) has two temporally separated peaks.
  To proceed further, we now formally deﬁne our binary clas- 3.1 Results for the Hats Simulator Data
siﬁcation algorithm. Let S be the set of data–instances to be The Hats simulator is a framework designed for developing
classiﬁed, and let assume that S is composed of two subsets and testing various intelligence analysis tools. It simulates a
SA ⊂  S and S−A  = S \ SA.  Initially, we know the cor- virtual world where a large number of agents are engaged in
rect class labels of a (small) subset of the instances of type A, individual and collective activities. Each agent has a set of el-
 0
SA, and the problem is to identify other members of class SA ementary capabilities which he can trade with other agents if
given the characterizing relations between the entities across desired. Most of the agents are benign while some are covert
both types. We deﬁne Mij as the weight of the link between adversaries that intend to inﬂict harm by destroying certain
the i-th and j–th entities.                           landmarks called beacons. There also are agents known to
  We associate a state variable with each entity, si = 0, 1 be adversaries. Agents travel for meetings that are plannedby an activities generator. Each agent belongs to one or more                 (a)
organizations that can be of two types, benign or adversary.     1200

Each adversary agent belongs to at least one adversary or-       1000
                                                                                           H=4
ganization, while each benign agent belongs to at least one                                H=6
benign organization and does not belong to any adversary or-     800
ganization. When a meeting is planned, the list of participants
                                                                 600
is drawn from the set of agents that belong to the same orga-    N(t)
nization. Hence, a meeting planned by an adversary organi-       400
zation will consist of only adversary (either known or covert)
agents, whereas a meeting planned by a benign organization       200

might contain all three types of agents.                          0
                                                                  0   2  4  6  8  10 12 14 16 18
  The type of data from the Hats simulator is a sequence of                 Iteration Number
lists containing unique hat ID-s that have met with each other.               (b)
Given this sequence, one can unequivocally construct a graph     350

(adjacency matrix) M of hats’ meeting activities, where each     300
                                                                               P  
entry M  describes the number of meetings between the i–                       b
       ij                                                        250
th and j–th agents (note that the graph is not directed so the
matrix is symmetric). In the simulations presented here we       200
                                                                 N(t)
                                                                 ∆
used Hats data for N = 1200 agents, (Nk = 50 known ad-           150
versaries, Nb = 1000 benign, and Nc = 150 covert) which
                                                                 100 P  
was collected for the ﬁrst 2500 ticks of simulations.                 a
  We tested our algorithm for small, large, and intermediate      50

                                                                  0
values of the threshold H. For small H most of the nodes in       0  2  4   6  8  10 12 14 16 18
the network are infected after a short time, as expected (see               Iteration Number
Fig. 2). Similarly, for large values of H (not shown here)
the epidemic spreads through only a very small subset of Figure 2: (a) Total number of infected nodes N(t) for H = 4
nodes. In both cases the epidemics are characterized by one– and H = 6. (b) The number of newly infected instances vs
tier dynamics. The situation is drastically different for inter- time, ∆N(t) for H = 6. Two separated peaks are a clear
mediate values of the threshold, as the behavior of epidemic indication of two–tier dynamics.
spreading demonstrates two-tiered structure. Namely, after a
sharp initial spread the epidemic seems to be saturated. How-
                                                      the amount of the available data, as well as the presence of
ever, upon further iterations, the number of infected nodes
                                                      noise, its performance is rather robust as long as the two–tier
increases sharply, and all the nodes in the network are in-
                                                      dynamics is observed.
fected shortly thereafter. Clearly, this corresponds to some
kind of threshold–phenomenon in the whole network, where 3.2 Results for Cora Data
infection of certain nodes causes an epidemic in the whole
system. This is illustrated in Fig. 2(a) where we plot the The Cora data [McCallum et al., 2000] contains a set of com-
number of infected actors vs time for H = 4 and H = 6. puter science research papers that are hierarchically catego-
As we mentioned in the introduction, this behavior suggests rized into topics and subtopics. Each paper includes a la-
a natural criterion for stopping the iteration. More precisely, bel for a topic/subtopic/sub–subtopic, and a list of cited arti-
in Fig. 2(b) we plot the number of newly infected nodes at cles. Following the previous studies [Macskassy and Provost,
each times step versus time, i.e., ∆N(t) = N(t) − N(t − 1). 2003], we focused on the papers on Machine Learning cat-
For the threshold value H = 4 (not plotted) there is only a egory, that contained seven different subtopics: Case-Based,
single peak in ∆N(t). However, for H = 6 one can distin- Theory, Genetic Algorithms, Probabilistic Methods, Neural
guish two well–separated peaks, denoted Pa and Pb which Networks, Rule Learning and Reinforcement Learning. Two
are indicative of two–tier dynamics in epidemic spreading. If papers are linked together by using common author (or au-
we assume that Pa corresponds to the epidemic spreading in thors) and citation.
the ﬁrst (covert) sub–population, and Pb corresponds to the Since our algorithm is for binary classiﬁcation, we con-
rest of the network, then the iteration should be stopped right structed separate classiﬁcation problem for each topic. We
before the infection starts to spread in the rest of the system varied the fraction of known instances from as high as 50%
(i.e., at t = 5). In this particular example, we established that to as low as 2%. For each classiﬁcation task, we did up to 10
if the above mentioned criterion is used, then the algorithm different runs using random subsets of classiﬁed hats. Note,
correctly identiﬁes 118 out of 150 covert adversaries, while that initially labelled set contained papers that belong to a
at the same time misidentifying only 8 of the 1000 benign class other than one we wanted to identify (the class label of
nodes as adversaries. This is a surprising result especially all the papers in the initially labelled sets were ﬁxed through-
taking into account the simplicity of the algorithm.  out iteration.
  More generally, our experiments with the Hats data indi- After pruning out the isolated papers from the data–set, we
cate that although the detection error rate of the algorithm were left with 4025 unique titles. Since we observed a large
varies depending on the particular structure of the network, dispersion in the node connectivity ranging from 1 to morethan 100, we revised our threshold–based rule a little so that                (a)

the threshold condition was established not only for the total   120                 P  
weight, but also on the fraction of that weight.                                      2
                                                                 100   P  
  We  observed that the structure of dynamics (i.e., two–               1
tier vs single–tier) varied from topic to topic. From the         80
seven subtopics, the data that demonstrated the best mani-
                                                                 N(t) 60
festation of two–tiered dynamics was Reinforcement Learn-        ∆
ing subtopic: it robustly demonstrated two separate peaks         40
                                                                                 F ≈0.66 
from run to run for various fraction of initially known data                     M
as shown in Fig 3(a). What is more striking, however, is          20

                                                                  0
that the accuracy of classiﬁcation was remarkable even if         0  2  4  6  8 10 12 14 16 18 20
the fraction of initially known instances were as low as 2%                 Iteration Number (t)
of the total number. Indeed, as illustrated in Fig 3(b), for                  (b)
2% of initially known class–labels, and from which only 7        0.7
in the Reinforcement Learning Topic, the F –Measure at the       0.6

iteration–stopping point t = 8 is FM ≈ 0.66. Moreover, our       0.5
                                                                           F ≈0.66 
experiments also suggest that increasing the number of ini-                 M
tially labelled data does not necessarily improve the perfor-    0.4

mance. Although this seems counterintuitive, it makes sense      0.3
from the perspective of our algorithm: Indeed, the more la-      F−Measure
belled instances we have at the start, the better the chances    0.2
that the epidemics will leave the sub–network and start to in-   0.1

fect nodes from other classes. One could think of increasing      0
                                                                  0  2  4  6 8  10 12 14 16 18 20
the threshold would help, but it did not, probably because of              Iteration Number (t)
large dispersion in node connectivity. Of course, one can al-
ways sample from available known instances and choose to Figure 3: (a) ∆N(t) for H = 4, with 2% of initially classiﬁed
include only an appropriate number of them.           instances. (b) F–Measure of predictive accuracy vs iteration
  We observed two–tier structures in most of the other topics step. At t = 8 (the iteration stopping point), FM ≈ 0.66.
too. Although some of them were not as pronounce as for
the previous case, they were robust in the sense that uprise of
the second peak almost surely corresponded with the spread local ﬁeld hi for the i–th agents as the number of its connec-
of label–propagation outside of that class. However, in some tions with known adversaries. We assume that hi-s are un-
                                                      correlated random variables drawn from a probability density
instances, notably for the Neural Networks subtopic, we did                             0
not observe any clear sign of this dynamics at all. Our ex- function P(h). Let f(h) = Ph0≥h P(h ) be the the fraction
planation is that this subcategory was vastly larger than the of agents who are connected with at least h initially known
RL–one (1269 compared to 344) so it was easier for the ini- adversary agents. Also, let ki be the number of connections
tial infection to propagate outside. This suggests that perhaps the i-th agent has with newly classiﬁed adversaries (note that
our method is best when one wants to identify a sub-class ki excludes the links to the initially known adversaries) and
that is considerably smaller compared to the total number of assume that ki–s are described by a probability density func-
instances.                                            tion P (k; t). In other words, P (k; t) is the probability that
                                                      a randomly chosen uninfected covert agent at time t is con-
                                                      nected to exactly k infected covert agents. Since the number
4  Analysis                                           of infected agents changes in time, so does the distribution
In this section we present an analysis of our classiﬁcation al- P (k; t). Initially, one has P (k; t = 0) = δk,0, where δij is
gorithm. Speciﬁcally, we study the epidemics spreading as the Kroenecker’s symbol.1.
described by our algorithm. For the sake of simplicity, we In the ﬁrst step of the iteration, the agents who have a local
consider a case of an unweighed graph when the entries in the ﬁeld larger than or equal to the threshold value, hi ≥ H, will
adjacency matrix are either 0 or 1. Generalization to the case change their states to 1. Hence, the fraction of agents classi-
of the weighed networks is straightforward. Also, for clarity ﬁed as adversaries at t = 1 is n(t = 1) = f(H). Since these
purposes we will retain the language of section 3.1 and refer new adversary agents are connected to other non-classiﬁed
to instances as agents.                               agents, this will alter the local ﬁelds for non-classiﬁed agents.
  Let us start by considering only one of the subnetworks in Let us deﬁne a variable for each agent zi = hi + ki. Then the
the system. Namely, we neglect benign agents for now and distribution of zi is described by
consider a network consisting of covert and known adver-                   ∞  ∞
saries only. We want to examine how the epidemic spreads
                                                              P (z; t) =  X  X   P (k; t)P(h)δz,k+h
through the covert population.
                                                                          k=0 h=0
  We now consider the iterative procedure more closely. Ini-
                                                         1
tially, all of the agents except known adversaries are classiﬁed Kroenecker’s symbol is deﬁned as follows: δij = 1 if i = j
as not–infected, si(t = 0) = 0, i = 1, 2, ..N. We deﬁne a and δij = 0, i =6 j.                    ∞                                                         (a)
                =      P (k; t)P(z − k)         (1)              1
                    X                                                simulations
                    k=0                                          0.9 theory

                                                                 0.8
Clearly, the criterion for infection is zi ≥ H. Hence, the
fraction of agents that will be classiﬁed as covert at time t + 1 0.7
is                                                               0.6
                                                                 0.5


                ∞           ∞                                    n(t)
     n(t + 1) = X  P (z, t) = X P (k; t)f(H − k) (2)             0.4
                                                                 0.3
               z=H         k=0
                                                                 0.2

Note that the probability P (k; t) of being connected to an      0.1

infected agent depends on the fraction of infected agents,       0
                                                                  0      5      10     15     20
P (k; t) = P (k; n(t)) . Hence, the Equation 2 is in general a              Iteration number
highly non–linear map. Once the functions P (k; t) and f(h)                   (b)
                                                                 0.35
are speciﬁed, Equation 2 can be solved (at least numerically)        simulations
                                                                     theory
                                                                            P  
to study the dynamics of epidemic spreading in a homoge-         0.3        b
nous, single–population network. In particular, the ﬁnal frac-
tion of infected agents is given by its steady state n(t → ∞).   0.25
  The above framework is easily generalized for the case         0.2
                                                                 n(t)

when there are two sub–populations in the network. We de-        ∆
                                                                 0.15
note two sub–populations by C (covert) and B (benign). Let
f (h) f (h) be the fraction of C and B agents respectively       0.1
 c    b                                                               P  
                                                                       a
that are connected to at least h known adversaries. Also, let    0.05
Pcc(k; t) and Pcb(k; t) be the probability that a randomly cho-
                                                                  0
                                                                  0      5      10     15     20
sen C agent is connected to exactly k infected C and infected               Iteration number
B agents, respectively. Similarly, we deﬁne Pbb(k; t) and
Pbc(k; t) as the probability that a randomly chosen B agent Figure 4: Analytical and simulation results for (a) n(t) and
is connected to k infected B and infected C agents, respec- (b) ∆n(t) for a random network. The results are averaged
tively. Then the fraction of infected agents in each population over 100 trials
nc(t) and nb(t) satisfy the following set of equations:
            ∞   ∞
                                                      Pbb(k; t), Pcb(k; t) and Pbc(k; t). Hence, one obtains from
 nc(t + 1) = X X  Pcc(k; t)Pcb(j; t)fc(H − k − j)     the Equation 3
           k=0 j=0
                                                                         ∞  ∞
            ∞   ∞                                                              [γ n (t)]k [γ n (t)]j
                                                          n (t + 1) =            cc c      cb b
 nb(t + 1) = X X  Pbb(k; t)Pbc(j; t)fb(H − k − j)           c           X   X      k!        j!
            k=0 j=0                                                     k=0 j=0
                                                                                      −γccnc(t)−γcbnb(t)
                                                (3)                 ×   fc(H − k − j)e                (4)
To proceed further we need to make assumptions about
                                                                         ∞  ∞          k         j
the distribution functions Pcc(k; t), Pbb(k; t), Pcb(k; t) and                 [γbbnb(t)] [γbcnc(t)]
P  k  t i.e., probability that a randomly chosen uninfected nb(t + 1) =
 bc( ; )                                                                X   X      k!        j!
agent of type C (B) is connected to k infected agents of                k=0 j=0
respective type. This is particularly easy to do when the                             −γbbnb(t)−γbcnc(t)
                                                                     ×  fb(H − k − j)e                (5)
graph is obtained by randomly establishing a link between
any two agents/nodes with a ﬁxed probability. Speciﬁcally, Equations 4 and 5 are a system of coupled maps that gov-
let us assume that each covert agent is connected to covert erns the evolution of fraction of infected individuals in both
and benign agents with corresponding probabilities pcc and sub–populations. The coupling strength depends on γcb and
pcb, while each benign agent has similarly deﬁned probabil- γbc , or in other words, average number of interconnec-
ities pbb and pbc (note that pcb = pbc). Hence, each covert tions between two sub–populations. Note that if one sets
agent in average is connected with γcc = pccNc covert and γcb = γbc = 0 the dynamics of two sub–populations are
γcb = pcbNb benign agents, and each benign agent is con- totally independent and one recovers the system Equation2
nected with γbb = pbbNb benign and γbc = pbcNb benign with corresponding parameters for each sub–population. To
agents.                                               validate the prediction of our analysis, we compared Equa-
  Consider now a randomly chosen uninfected agent of ei- tions 4 and 5 with experiments on randomly generated graphs.
ther type, say, covert, at a certain time t, and denote it as c0. The results are shown in Fig. 4 where we plot the fraction
There are Ncnc(t) infected covert agents at time t, and c0 of the infected nodes n(t) = nc(t) + nb(t) as well as the
is connected with each of them with probability pcc. Hence, difference ∆n(t) = n(t + 1) − n(t) versus iteration num-
the probability Pcc(k; t) that c0 is connected with exactly k ber for a randomly generated graph of Nc = 100 covert and
infected covert agents at time t is given by a Poisson distri- Nb = 1000 benign nodes. The parameters of the graph are
bution with a mean γccnc(t). Similar arguments hold also for pcc = 0.2, pbb = 0.04 and pcb = 0.04. Also, we chose the