  Exploiting    Informative     Priors   for Bayesian    Classiﬁcation     and   Regression    Trees

                               Nicos Angelopoulos    and  James  Cussens
                                    Department  of Computer  Science
                                           University of York
                                   Heslington, York  YO10   5DD,  UK
                                   {nicos,jc}@cs.york.ac.uk

                    Abstract                          that this paper assumes familiarity with the basic properties
                                                      of these models.
    A general method for deﬁning informative pri-       The  method is fully Bayesian using a version of the
    ors on statistical models is presented and applied Metropolis-Hastings MCMC algorithm to approximately
    speciﬁcally to the space of classiﬁcation and regres- sample from posterior distributions over the space of all pos-
    sion trees. A Bayesian approach to learning such  sible C&RT models. Even after eliminating a priori unin-
    models from data is taken, with the Metropolis-   teresting trees (for example, those containing sparsely popu-
    Hastings algorithm being used to approximately    lated leaves) this will be a very large space. The key feature
    sample from the posterior. By only using proposal of our approach is that the user can declare structural prior
    distributions closely tied to the prior, acceptance knowledge to restrict and/or bias the prior distribution over
    probabilities are easily computable via marginal  this space.
    likelihood ratios, whatever the prior used. Our ap- The rest of the paper is structured as follows. Section 2
    proach is empirically tested by varying (i) the data, describes our language for deﬁning priors. Section 3 de-
    (ii) the prior and (iii) the proposal distribution. A scribes the speciﬁc priors that have been used for Bayesian
    comparison with related work is given.            inference of C&RT models. Section 4 presents our version
                                                      of the Metropolis-Hastings (MH) algorithm and gives a con-
1  Introduction                                       vergence result for one special case. Section 5 gives a repre-
A key feature of the Bayesian approach to statistical inference sentative sample of the results of our experiments. The paper
is that prior knowledge (i.e. relevant information distinct from concludes with a comparison with related work (Section 6)
the data) can be incorporated into the learning process in a followed by pointers to future work (Section 7).
mathematically rigorous and conceptually clear manner. On
the assumption that a space of possible statistical models can 2 Deﬁning priors with stochastic logic
be deﬁned, prior knowledge is expressed via a prior distri- programs
bution over this space. This distribution is then updated with Our approach to deﬁning priors is related to a line of research
the data using Bayes theorem to produce a posterior distribu- which was independently initiated by [Chipman et al., 1998]
tion. The posterior distribution is the end result of learning and [Denison et al., 1998]. The basic idea is to specify a prior
and can then be used to make predictions about future data distribution over a space of models with a stochastic program
or, once suitably summarised, to give the data analyst insight rather than by some closed-form expression:
into the domain of interest.
  The Bayesian framework is compellingly simple, but there Instead of specifying a closed-form expression for
are many complexities in applying it to real data analysis. the tree prior, p(T ), we specify p(T ) implicitly by a
Many of these difﬁculties are computational. For example, tree-generating stochastic process. Each realization
in high-dimensional spaces the posterior will be too complex of such a process can simply be considered a ran-
to report directly so features of the distribution (e.g. mean and dom draw from this prior. [Chipman et al., 1998]
variance) must be extracted—requiring, in general, a difﬁcult A convenient language for deﬁning such stochastic pro-
integration. These problems are being progressively allevi- grams is stochastic logic programming [Muggleton, 1996]. A
ated by increased computing power and the subsequent use of stochastic logic program (SLP) can be used to deﬁne a prior
Markov chain Monte Carlo (MCMC) techniques to approxi- over a given space of statistical models by a two-step process.
mately sample from the posterior.                     Firstly, a standard logic program is written which deﬁnes the
  In this paper an existing Bayesian method for deﬁning and desired model space (the hypothesis space in machine learn-
using a very ﬂexible class of prior distributions over models ing parlance). We simply deﬁne a unary predicate cart/1
is further developed and applied speciﬁcally to classiﬁcation in a logic program such that each instantiation for T which
and regression tree (C&RT) models. C&RT models are so makes cart(T)  true is a term in ﬁrst-order logic which rep-
well known in machine learning (and increasingly statistics) resents a C&RT model. We can exploit the expressivenessof ﬁrst-order logic to represent C&RT models, in whichever 1 - 1/D : [D] : cart(leaf).
logical representation is most convenient.            1/D  :  [D]  : cart(Split-[L,R])     :-
  At this point any C&RT models we wish to exclude from   NewD  is  D+1,  splt(Split),
the hypothesis space can be so excluded by adding the ap- [NewD]   : cart(L),   [NewD]   : cart(R).
propriate constraints to the logic program. For example, sup-
pose the user is faced with a classiﬁcation task and knows (or 0.4:splt(x1). 0.3:splt(x2). 0.3:splt(x3).
wishes to assume) that the distribution over classes is con-
stant over some rectangular region (a ‘box’) of the attribute Figure 2: Prior distribution over C&RT models where the
space. It follows that the box must be contained within a leaf probability of splitting a leaf depends on its depth D.
of the ‘true’ tree so only trees with a leaf containing the box
need be considered. In general, the user may wish to declare
several such boxes. We have effected such constraints in our tree. Fig 3 displays one such proof tree which proves that
experiments by declaring facts such as those given in Fig 1, cart(x1-[x2-[leaf,leaf],leaf]) is true, i.e. that
and altering the deﬁnition of cart/1 to check that boxes this 3-leaf tree is in our model space. (Figs 2 and 3 use an
determined by our declarations are not split in any tree. abbreviated representation of C&RT models, with split val-
                                                      ues omitted.) Each proof tree simply consists of the rules
%const_class_probs(boxname,var,min,max).              and facts used in the proof ‘bolted together’ by equality con-
const_class_probs(box28,x2,-inf,127).                 straints. The initial query appears in an equality constraint
const_class_probs(box28,x8,-inf,28).                  in the root node. Conceptually, SLPs execute by probabilis-
                                                      tically growing a proof tree, backtracking if the constraints
const_class_probs(box26,x2,128,inf).                  become insoluble.
const_class_probs(box26,x6,-inf,29.8).                  To sum up, our priors are deﬁned by a sampling algorithm
                                                      within a logical framework. The sampling algorithm could,
                                                      of course, be implemented in any programming language. It
Figure 1: Declaring rectangular regions within which the dis-
                                                      involves progressively building up a data structure represent-
tribution over classes is constant.
                                                      ing the C&RT model by (i) making choices, (ii) checking
  The stochastic element of the SLP is most easily under- that constraints are not violated and (iii) backtracking if they
stood by ﬁrst considering how the logic programming lan- have. The motivation for a logic programming implementa-
guage Prolog searches for logical consequences of a logic tion is that procedures (ii) and (iii) are built-in, and that logic
program. Given a query such as :-cart(T) (“ﬁnd T such is a convenient language for declaring constraints (such as our
that cart(T) is true”), Prolog will search for suitable Ts boxes).
with a deterministic depth-ﬁrst search. When there is a choice Not all distributions can be directly sampled from (hence
of rules each of which might lead to a proof, Prolog always MCMC), so such distributions cannot be effectively repre-
chooses whichever rule occurs ﬁrst in the logic program. If sented by deﬁning a direct sampling algorithm. However,
this rule leads to a dead-end, then Prolog backtracks and tries when a statistical model can be viewed as the end result of
the second rule, and so on.                           some generative process, a generative description is well-
  The basic SLP idea is simple: probability labels are at- motivated. Bayes nets can be generated by adding arcs [An-
tached to rules in the logic program thus converting it into an gelopoulos and Cussens, 2001] and C&RT models by split-
SLP. Now when the search for proofs has to choose between ting leaves. Our addition of backtracking extends the appli-
rules, a rule is chosen probabilistically according to the prob- cability of this generative view.
ability labels. In this paper, if a chosen rule does not lead
                                                                         cart(T)
to a proof, then backtracking will try from amongst untried                 =
rules, revisiting the most recent choice-points ﬁrst and renor-      cart(Split-[L,R])      cart(R)
malising the probabilities as necessary: we call this approach,          cart(L)              =
                                                      splt(Split)           =              cart(leaf)
introduced by [Cussens, 2000], backtrackable sampling.     =       cart(Split2-[L2,R2])
  Now when the query :-cart(T) is asked, there is a dis- splt(x1)
tribution over possible instantiations for T. Since each T rep-
                                                       splt(Split2)      cart(L2)      cart(R2)
resents a C&RT model, this provides a prior distribution over =             =             =
this model space.                                        splt(x2)      cart(leaf)      cart(leaf)
  In this paper we have extended the representational power
of SLPs so that probability labels may be computed ‘on the Figure 3:   A    proof   tree   which   proves
ﬂy’. SLP rules can now be of the form ExpProb : Vars  cart(x1-[x2-[leaf,leaf],leaf])
:  Rule.  At each point at which Rule is a possible rule
to use, it is required that Vars is a ground list and that
ExpProb  is a probability computable from Vars. Fig 2 has 3 Priors for Bayesian C&RT
an example SLP where the probability of growing a tree by
splitting a leaf depends on the depth of that leaf.   In this section we describe the actual priors we have used for
  SLPs deﬁne a distribution over proofs, and to understand the experiments described in Section 5. Fixing some notation,
this distribution it is useful to represent each proof as a proof note that a given C&RT model t maps an example, describedby a set of p predictor variables x = x1, x2, . . . xp, to a distri- also probabilistic.
bution over a response variable y. In the case of classiﬁcation
trees (also known as decision trees) y is discrete and ﬁnite, 4 Using the Metropolis-Hastings algorithm
and in the case of regression trees y is continuous. Some
                                                      The Metropolis-Hastings (MH) algorithm is an MCMC algo-
C&RT  implementations throw away information given by the                               (i)
distribution of y and simply return the majority class or mean rithm which deﬁnes a Markov chain (T ) with a transition
                                                               i  i+1               (i)   (i)      (i+1)
value as appropriate, but this is just a design decision. Fun- kernel K(t , t ) as follows. If T = t , then T is
                                                                           0     0
damentally it is a distribution over that is given.   produced by generating T ∼ q(t |t(i)) for some proposal dis-
                             y                                             i               0
  It follows that each tree t deﬁnes a conditional probabil- tribution q. An acceptance probability α(t, t ) is used to de-
ity distribution P (y|t, x). This conditional distribution is the cide whether to accept the proposed t0. t(i+1) = t0 with prob-
likelihood function of the following version of Bayes theo- ability α(t, t0) (the proposed t0 is accepted) and t(i+1) = t(i)
rem: P (t|y, x) = P (t|x)P (y|t, x)/P (y|x) whose LHS gives with probability 1 − α(t, t0). By setting the acceptance prob-
the desired posterior distribution over trees. Note that the ability like this:
prior P (t|x) is only prior to y, it is conditional on the pre-                  0        0
                                                                    0         P (t |x, y) q(t|t )
dictor variables so that observed values of x in the data can  α(t, t ) = min               , 1       (1)
be used to deﬁne sensible priors.                                            P (t|x, y) q(t0|t) 

  Importantly, this allows us to rule out a priori trees with     (i)
leaves which contain few examples. There is nothing to stop a the chain (T ) will converge to sampling from the de-
user allowing trees with sparsely populated leaves, but ruling sired posterior P (T |x, y) under weak conditions (what-
out such trees is normal in this research area. It ensures that ever the starting point t(0) of the chain). It is not difﬁ-
                                                      cult to see (via Bayes theorem) that if q(t|t0)P (t0|x) =
the space of possible tree structures is a reasonable (ﬁnite) 0 0
size. In our experiments only trees whose leaves have at least Rq(t, t )q(t |t)P (t|x), for some function Rq, then:
5 examples are permitted, following [Denison et al., 1998].                              0
                                                                   0              0 P (y|t , x)
The predictors x could also be used to deﬁne a prior biassed   α(t, t ) = min Rq(t, t )      , 1      (2)
towards even splits of the data if so desired, but we have yet                     P (y|t, x) 
to investigate the desirability of such an option.    In our approach we choose proposal distributions q which
  For most of our experiments we decided to use what we permit this simpliﬁcation of the acceptance probability, and
                                                                         0
call a GROWTREE  prior, which is essentially that used by where the value Rq(t, t ) is easily computable for each pair of
[Chipman et al., 1998]. Attempting to use an SLP to model trees t, t0 . The crucial point is this: such a choice of q ensures
an externally provided prior provides a test of the represen- that α(t, t0) is easily computable even though computing the
tational ﬂexibility of SLPs: indeed we were unable to pass prior probability for any given C&RT model (as opposed to
this test before we extended SLPs to have variable probabil- merely sampling from the prior) may be prohibitively expen-
ity labels. Using the GROWTREE prior also allows better sive. This contrasts with [Chipman et al., 1998] where “spec-
comparison with others’ results.                      iﬁcations [which] allow for straightforward evaluation of p(t)
  The GROWTREE    prior grows a C&RT tree by starting for any t” are required. For us the computation of prior prob-
with a single leaf node and then repeatedly splits each leaf abilities can be expensive due to backtracking. Without back-
                             −β
node η with a probability α(1 + dη) , where dη is the depth tracking SLPs are similar to stochastic-context free grammars
of node η and α and β are prior parameters set by the user to (SCFGs)—particularly when probability labels are ﬁxed, and
control the size of trees. Unsplit nodes become leaves of the not computed ‘on the ﬂy’—and SCFG dynamic programming
tree. If a node is split, then the splitting rule for that split is algorithms could presumably be used to compute prior prob-
chosen uniformly. An abbreviated fragment of the SLP which abilities. Ruling out backtracking greatly restricts the con-
expresses this prior is given in Fig 4.               straints the user can declare so we always allow for back-
                                                      tracking.
Splt:[Splt]:splt_lf(D,..,A/B,..)         :-  ..
                                                        Since our trees do not explicitly deﬁne a distribution over
 D1  is D  + 1,
                                                      classes at the leaves of the tree, our likelihoods are marginal
 NwSplit   is  A    exp((1+D1),-B),     ...
                 *                                    likelihoods—we integrate over all possible class distribu-
 [NwSplit]:splt_lf(D1,..,A/B,..),
                                                      tions. This integration automatically prevents over-ﬁtting:
 [NwSplit]:splt_lf(      D1,..,A/B,..).
                                                      trees with 100% training set accuracy do not generally have
(1-Splt):[Splt]:splt_lf(D,..,AB,Lf)          :-
                                                      high marginal likelihood. To actually do the integration, we
          Lf =  leaf(D,..).
                                                      use exactly the same approach as [Chipman et al., 1998;
                                                      Denison et al., 1998; 2002]. For each leaf, the uniform
Figure 4: GROWTREE  prior fragment deﬁned with an SLP Dirichlet distribution (all parameters set to 1) is the distribu-
                                                      tion over all possible distributions over classes. The Dirichlet
  We have also experimented with what we call EDITTREE assumption allows a closed form for the marginal likelihood
priors. Here an ‘initial’ C&RT model is supplied. This can P (y|t, x).
be any tree, for example the tree produced by the standard Our proposals can best be understood by ﬁrst recalling that
greedy algorithm or one manually entered by the user. This sampling C&RT trees from an SLP prior is effected by sam-
tree is then probabilistically ‘edited’, by either growing, prun- pling proofs from the prior as explained in Section 2, and that
ing or changing a splitting rule. The number of such edits is each such proof has an associated proof tree, such as shownin Fig 3. Each proposal we have considered works by prun- els, this means our proposals can now snip the current C&RT
ing the proof tree corresponding to the current C&RT model tree at any node, and re-grow the tree from there, leaving the
at some point, and then re-growing the proof tree from the rest of the C&RT tree unscathed. This makes it easier for
pruning point using the sampling mechanism associated with the Markov chain to head in the direction of high likelihood
the prior. Our proposals only differ in how they choose where trees: sub-trees with high-likelihood tend to be altered rarely
to ‘snip’ the proof tree. Since only the sub-tree below the whereas proposed replacements for low-likelihood sub-trees
prune point is resampled, our proposals are not equivalent to are accepted relatively often.
proposing with the prior P (t|x) (except for one special case
to be discussed shortly). Instead each prune point k corre- 5 Experimental results
sponds to proposing a tree according to P (t|x, t ∈ Tk) where In our experiments we have used three datasets: the Wis-
Tk is the set of trees which may differ from the current tree consin breast cancer data (BCW), the Kyphosis dataset (K)
only in the sub-tree under prune point k.             and the Pima dataset (P). BCW was originally donated to
  One (overly) simple proposal corresponds to the indepen- the UCI depository by [Wolberg and Mangasarian, 1990] and
dent Metropolis-Hastings algorithm which prunes away the was used by [Chipman et al., 1998]. Dataset K comes as
current model completely so that a new model is sampled part of the rpart R package for building and manipulating
from the prior independently of the current model. For this C&RTs. Dataset P is a UCI dataset which [Denison et al.,
proposal (denoted q0) we have the following MCMC conver- 2002] used for extensive Bayesian C&RT analysis. Following
gence result. Let µi be the distribution over trees produced at [Chipman et al., 1998] we have simply deleted 16 datapoints
                                              ˆ
the ith iteration of this independent MH algorithm. Let t be a from BCW which contain missing values. In all cases the
C&RT  tree with maximal marginal likelihood: then     machine learning task is binary classiﬁcation using integer-
                                          i
       |µi − P (·|x, y)| ≤ [1 − P (tˆ|x)/P (tˆ|x, y)] (3) valued predictors—9 predictors in the case of BCW, 3 for K
                                                      and 8 for P. All splits are binary: made by splitting on some
where | · | denotes the total variation distance between two threshold. There are 683 datapoints for BCW, 81 for K and
distributions. So there is exponentially fast convergence to 768 for P.
the true posterior P (·|x, y) using this independent MH al- We have performed a large number of experiments,
gorithm. The catch is that, P (tˆ|x)/P (tˆ|x, y), the ratio be- and analysed the results in many ways. Only a small
tween tˆ’s prior and posterior probability, is tiny for any rea- representative sample of this is reported here. Data
sonably sized dataset, so in experiments (not presented here) and software for reproducing all of our experiments can
the independent M-H algorithm performs poorly. The conver- be found at http://www.cs.york.ac.uk/∼nicos/
gence result can be derived from one by [Doob, 1953] which sware/slps/mcmcms/. We used Sicstus Prolog 3.11 run-
is given by [Rosenthal, 1995]. To apply Doob’s result it is ning under Linux on two machines each with a 2.4GHz pro-
                                                0
necessary to produce an upper bound on t0 mint Kq0 (t, t ), cessor and at least 512Mb RAM. The computation of the log-
where Kq0 is the transition kernel associatedP with q0. In likelihood ratio uses a C function called from Prolog. Run-
fact, we can show (proof omitted) that this sum is exactly ning a chain for 50,000 iterations takes at most 30 minutes.
P (tˆ|x)/P (tˆ|x, y), thus establishing (3). This upper bound
for our discrete ﬁnite space is exactly half the size of the 5.1 Comparison to the standard C&RT algorithm
bound for the general independent MH algorithm established The contrasts between Bayesian C&RT and the standard
by [Mengersen and Tweedie, 1996].                     greedy algorithm for building a single C&RT model have
  A somewhat better performing proposal (denoted q0−n) been well explored in the existing Bayesian C&RT litera-
cycles through proposals qk for k = 0, 1, 2, . . . n for a user- ture [Chipman et al., 1998; Denison et al., 1998; 2002]. The
supplied n, where qk is the proposal which prunes the proof Bayesian method represents posterior uncertainty better and
                                         0
tree at the kth choice point. We have Rq0−n (t, t ) ≡ 1, so makes a more thorough exploration of the model space. This
that the acceptance probability is simply a likelihood ratio. is at the cost of more computation. How well the Bayesian
However, our best performing proposal (denoted quc) makes approach does in terms of predictive accuracy depends, of
a uniform choice of a prune point from all those available in course, on the prior. When we do have useful prior knowl-
                            0
                                    0
the current tree. For quc, Rquc (t, t ) = dt/dt , where dt is the edge it can help us if it can be incorporated into the prior
depth of tree t.                                      distribution. Facilitating this is our central motivation.
  One recent innovation has greatly increased the efﬁciency A tree with maximal marginal likelihood is a maximum a
with which the space is explored. In all previous work us- posteriori (MAP) model when a uniform prior is assumed.
ing SLPs for MCMC,  the prune points to which our pro- Call such trees MAPunif trees. Any MCMC run produces
posals jumped were not organised in a proof tree, but in a an approximation to a MAPunif tree: it is the maximum
sequence (a branch of the relevant SLD-tree, in fact). Es- marginal likelihood tree in the MCMC sample. Since the
sentially, this was because our previous proposal mechanism standard greedy algorithm is closely connected to a search for
was closely modelled on Prolog backtracking: if we back- a MAPunif tree [Buntine, 1990] it is interesting to compare
tracked to choice point k all C&RT building work done after the marginal likelihood of trees produced using the greedy al-
that choice point was thrown away. Now, if we backtrack to gorithm to that of the MAPunif tree approximations found in
point k then only the proof tree below k is (stochastically) re- the the MCMC sample.
built, even if other parts of the proof tree were built chrono- The trees found by rpart for datasets BCW and K using
logically later. Translating this speciﬁcally to C&RT mod- default settings have (rounded) marginal log-likelihoods -97                                                        -50
                                                                              ’tr_nd7_a0_95b1_bcw_data_i60K__s1.llhoods’
    15


    10                                                  -100
 Density
    5

                                                        -150
    0


           −0.4    −0.2    0.0     0.2     0.4

                   N = 256   Bandwidth = 0.009582
                                                      Figure 6: Log-likelihood trajectory. Prior=GROWTREE
Figure 5: Distribution of differences in estimated class pos- (β-200= 1), Data=BCW, MCMC=q0−7.
terior probabilities from two MCMC runs only differing in
                                                         -60                     -50
random seed.                                                       ’tr_rn1_a0_95b1_edit_data_i60K__s9.llhoods’ ’tr_rn1_a0_95b1_bcw_data_i60K__s1.llhoods’
                                                        -250
and -39, and sizes 7 and 5, respectively. Unsurprisingly, there -65
                                                                                -100
are trees produced by MCMC runs with higher marginal log- -300
                                                           0     10000   20000  30000   40000  50000  60000
likelihoods (i.e. with values closer to that of a MAPunif tree). -70
For BCW (resp. K) we can ﬁnd a tree with 5 (resp. 3) leaves
and log-likelihood of -86 (resp. -36).                   -75
                                                                                -150
5.2  Reproducibility of results
                                                      Figure-80 7: Log-likelihood trajectories. In both cases:
Since the aim of using MCMC is to approximate the poste-
                                                      Data=BCW,    MCMC=quc,    sequential.    For  LHS:
rior distribution, it is important that inferences drawn from                   -200
                                                      Prior=EDITTREE.-85 For RHS: Prior=GROWTREE (β = 1)
any reasonably long realisation of the Markov chain are ro-
bust to changing the random seeds which determine the evo-
lution of the chain. Using our original sequence-based pro- 5.4-90 Inﬂuence of priors
                                                                                -250
posals, there was strong evidence that this was not the case: Fig 7 compares log-likelihood trajectories using the EDIT-
for example, plots of log-likelihood against iteration number TREE-95 prior and the GROWTREE prior respectively with
(log-likelihood trajectories) could be quite different for ex- all other parameters being equal. The distinct horizontal
periments which were identical except for the random seeds -100                 -300
                                                      line  0in the 10000 EDITTREE 20000  30000  40000  50000trajectory 60000  0 is 10000clear 20000 evidence 30000  40000  50000that 60000the
used.                                                 EDITTREE   prior is pulling the Markov chain back to the
  To test our new proof-tree based proposals we performed initial tree. Note that Figs 6-7 all contain initial very low
the following experiment (amongst many others not reported log-likelihoods (corresponding to the chain’s initial C&RT
here). Two MCMC runs of 50,000 iterations were performed model) which have been truncated for space reasons.
using the GROWTREE  prior (α = 0.95, β = 0.8) using only [Denison et al., 2002] examined how successful their
2/3 of the Pima dataset, differing only in the random seeds chains were at ﬁnding C&RT trees with high marginal like-
used. For each of the remaining 256 Pima dataset examples lihood using the Pima (P) dataset. Their maximum marginal
each of the two MCMC samples were used to approximate log-likelihood was -343; our highest was -347. To test a hy-
the posterior probability that the example had class label 0. pothesis that many high likelihood C&RT models did not
This was done by simply getting each tree in the MCMC have high posterior probability for our priors (and hence
sample to make a class prediction for the example based on were unlikely to be visited), we started chains from the log-
the majority class at the appropriate leaf and setting the class likelihood=-343 C&RT model of Denison et al.. Fig 8 show
posterior probability equal to the relative frequency of class the results where the RHS trajectory corresponds to a prior
0 predictions. Clearly, if both MCMC samples were perfect with a stronger bias towards smaller trees. In both cases the
representations of the true posterior, then the difference in es- prior pulls away from high-likelihood C&RT models, all the
timates of the class 0 posterior would be zero for each exam- more rapidly for the stronger prior.
ple. Naturally, this is not achieved but the distribution of the Since the goal of including prior knowledge is to improve
differences in probability estimates (shown in Fig 5) is highly decision making under uncertainty (e.g. classifying test ex-
concentrated about zero which provides evidence that our ap- amples), we performed experiments where a known ‘true’
proach often produces values close to the true posterior, for tree was used to generate synthetic train and test data. We
different runs.                                       then included boxes (see Section 2) consistent with the true
                                                      tree as constraints on a GROWTREE prior, produced MCMC
5.3  Using local jumps                                samples using the synthetic training data, and measured pre-
Local jumping in tree space helps prevent getting stuck. The dictive accuracy on the synthetic test data. Each of the 500
log-likelihood trajectory using q0−7 shown in Fig 6, shows test examples was classiﬁed into its most probable class as
that the big jumps which q0−7 proposes are rarely accepted, estimated by the MCMC sample. This was all repeated for 3
so the chain remains stuck at the same model for long periods. random seeds. With no box constraints test-set accuracies
This problem is even more pronounced if q0, the independent were 74.8%, 76.2% and 74.4%. With the box constraints
MH  algorithm,is used. Compare this with other ﬁgures where given in Fig 1, the test-set accuracy was exactly 78.6% for
the quc is being used.                                each random seed. These results indicate that accurate prior