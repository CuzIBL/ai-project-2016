                              Cooperating Reasoning Processes:
                           More than just the Sum of their Parts            ∗

                                              Alan Bundy
                                         School of Informatics
                                        University of Edinburgh
                                          A.Bundy@ed.ac.uk

                    Abstract                              Other: learning of new proof methods from exam-
                                                              ple proofs, ﬁnding counter-examples, reason-
    Using the achievements of my research group over          ing under uncertainty, the presentation of and
    the last 30+ years, I provide evidence to support the     interaction with proofs, the automation of in-
    following hypothesis:                                     formal argument.
        By complementing each other, cooperat-            In particular, we have studied how these different
        ing reasoning process can achieve much            kinds of process can complement each other, and
        more than they could if they only acted           cooperate to achieve complex goals.
        individually.                                     We have applied this work to the following areas:
    Most of the work of my group has been on pro-         proof by mathematical induction and co-induction;
    cesses for mathematical reasoning and its applica-    analysis; equation solving, mechanics problems;
    tions, e.g. to formal methods. The reasoning pro-     the building of ecological models; the synthesis,
    cesses we have studied include:                       veriﬁcation, transformation and editing of both
                                                          hardware and software, including logic, functional
    Proof Search: by meta-level inference, proof          and imperative programs, security protocols and
        planning, abstraction, analogy, symmetry, and     process algebras; the conﬁguration of hardware;
        reasoning with diagrams.                          game playing and cognitive modelling.
    Representation Discovery, Formation and Evolution:
        by analysing, diagnosing and repairing failed
        proof and planning attempts, forming and      1   Introduction
        repairing new concepts and conjectures, and       “Many hands make light work” (John Heywood)
        forming logical representations of informally
        stated problems.                                Much research in Artiﬁcial Intelligence consists of invent-
                                                      ing or developing a new technique: analysing and establish-
  ∗I would like to thank the many colleagues with whom I have ing its properties, implementing and testing it, comparing
worked over the last 30+ years on the research reported in this paper: it with rival techniques for the same task, etc. Other work
MECHO/PRESS (Lawrence Byrd, George Luger, Chris Mellish, Rob consists of combining several techniques into a complex sys-
Milne, Richard O’Keefe, Martha Palmer (n´ee Stone), Leon Sterling, tem that solves problems, models natural systems, etc. It is
Bernard Silver and Bob Welham) ECO (Robert Muetzelfeldt, Mandy commonly observed that complementary techniques can as-
Haggith, Dave Robertson and Mike Uschold), Proof Planning (Dave
Barker-Plummer, David Basin, Richard Boulton, James Brotherston, sist each other, extending their range of automation and/or
Francisco Cantu, Claudio Castellini, Ewen Denney, Louise Den- effectiveness. For instance, this was the theme of a previous
nis, Lucas Dixon, Jacques Fleuriot, Jason Gallagher, Jeremy Gow, IJCAI paper of mine [Bundy, 1985]. It is not just that different
Ian Green, Jane Hesketh, Christian Horn, Andrew Ireland, Predrag techniques are needed to tackle different aspects of a complex
Janiˇci´c, Helen Lowe, Ina Kraan, Ewen Maclean, Pete Madden, R´aul task; one technique can also assist another by addressing its
Monroy, Julian Richardson, Alan Smaill, Andrew Stevens, Frank shortcomings. In the current paper we examine this observa-
van Harmelen, Lincoln Wallen and Geraint Wiggins), ISANEWT tion in more detail, giving examples of how techniques can
Hazel Duncan and Amos Storkey, TM/HR (Alison Pease, Simon complement each other: achieving more than the sum of their
Colton, Alan Smaill, Graham Steel, John Lee and Toby Walsh) and parts. The examples are drawn from the work of my research
ORS (Fiona McNeill, Marco Schorlemmer and Chris Walton). I’m group, over more than 30 years, aimed at automating mathe-
grateful for feedback on an earlier draft from David Basin, James
Brotherston, Claudio Castellini, Simon Colton, Priya Gopalan, Jane matical reasoning.
Hesketh, Andrew Ireland, Predrag Janiˇci´c, Erica Melis, Chris Mel- This same point could be illustrated by many pieces of
lish, R´aul Monroy, J¨org Siekmann and Sean Wilson. The research work. However, given the context of this paper and the space
reported in this paper was supported by numerous grants and stu- limitations of the IJCAI-07 proceedings, I have limited my-
dentships, the most recent of which is EPSRC GR/S01771. self to work in which I played some role, albeit a small one

                                                IJCAI-07
                                                    2in some cases. My apologies to those people whose work I inductive proofs, but we have found widespread applications
have not surveyed; profuse apologies to those I have not even in other types of problem. Typically, we want to rewrite the
cited.                                                goal in such a way as to separate the similarities and dif-
                                                      ferences while preserving the similarities. This enables the
2  Object-level and Meta-level Inference              given(s) to be used to prove all or part of the transformed
                                                      goal. We can visualise this process by annotating the goal
    “Not all who wander are lost.” (John Ronald Reuel and the given(s) with their similarities and differences (see
    Tolkien)                                          Figure3 1).
  Much of our work has been on automatic inference, es-
pecially proving mathematical theorems. Most work in this
area builds on mathematical logic, which is used to represent t<>(y<>z)=(t<>y)  <> z
                                                                   ↑                      ↑
the conjectures to be proved, the axioms of the theories in  h :: t <>  (y<>z)=(h     :: t <> y) <> z
which they are to be proved, and the rules of inference with
which they are to be proved. These logical formulae pro-                        ↑               ↑
                                                             h :: t<>(y<>z)     =  h :: t<>y)    <> z
vide a search space of potential proof steps. Typically, proof
search is conducted backwards, starting with the original con-                  ↑                     ↑
jecture as the main goal and applying the rules of inference  h :: t<>(y<>z)    =  h :: (t<>y) <> z
backwards to exchange each goal for a set of subgoals. Nav-
                                                                                                    ↑
igating this search space is the major problem in automated  h = h ∧ t<>(y<>z)=(t<>y)        <> z
theorem proving. It is called the combinatorial explosion,be-
cause the number of subgoals increases super-exponentially The example shows the step case of an inductive proof
with the length of the proof, rapidly swamping the computer’s of the associativity of list append, where <> is the inﬁx
memory for all but trivial problems.                      notation for append and :: is the inﬁx notation for cons.
  Human mathematicians succeed in navigating these huge    separates the induction hypothesis (the given) from the
search spaces by stepping back from the low-level details and induction conclusion (the goal). The formulae are anno-
thinking at a higher-level about the nature of the problem and tated to show the differences and similarities between the
the suitability of their tools for solving such problems. We given and the goal. The grey boxes indicate the parts of
have been trying to emulate this high-level thinking in our the goal which differ from the given. They are called
automated provers. In particular, we have implemented proof wave-fronts. Each wave-front has one or more wave-
search as simultaneous and cooperating inference at two lev- holes indicating sub-terms of the wave-fronts which cor-
                                                          respond to parts of the given. The parts of the goal out-
els: the object-level, in which the original conjecture, the- side the wave-fronts or inside the wave-holes, are called
ory and rules are expressed, and the meta-level, in which the the skeleton. The skeleton always matches the induction
proof methods are speciﬁed and the conjectures analysed. In hypothesis. The arrows indicate the direction of move-
meta-level inference, the conjecture is analysed, a suitable ment of the wave-fronts — in this case outwards through
proof method identiﬁed and applied, progress is measured  the goal until they completely surround the skeleton.
and the process recurses. In this way, inference at the meta- The rules are also annotated and annotation must also
level directs inference at the object-level, avoiding unproduc- match when rules are applied. Such annotated rules are
tive parts of the search space and making proof search com- called wave-rules. The main wave-rule used in this ex-
putationally tractable.                                   ample is:
  We have applied this two-level approach many times, but              ↑                      ↑
most notably in the domains of equation solving using the        H :: T  <> L  ⇒  H :: T<>L
PRESS1 system [Bundy and Welham, 1981; Sterling et al.,
1989] and inductive theorem proving using Clam/Oyster2    which is taken from the step case of the recursive deﬁni-
                                                                <>
[Bundy et al., 1991; Bundy, 2001]. The latest realisation of tion of .
this idea is proof planning , [Bundy, 1988; 1991],inwhich Note how the grey boxes get bigger at each wave-rule
proof methods are speciﬁed as STRIPS-like plan operators and application with more of the skeleton embedded within
plan formation is used to custom-build a proof plan for each them, until they contain a complete instance of the given.
conjecture.
  To illustrate these ideas I will describe rippling, a proof Figure 1: The Associativity of Append using Rippling
method for reducing the difference between a goal and one
or more givens [Bundy et al., 2005a]. It frequently occurs in
mathematics that the goal to be proved is syntactically simi- Rippling successfully guides proof search by ensuring that
lar to a “given”, i.e. a hypothesis, assumption or axiom. This the skeleton gets larger until it matches the givens. At this
occurs, most notably, in inductive proof, where the induction point the givens can be used to prove the goal. It has been
conclusion and induction hypothesis have strong similarities successfully applied in induction, summing series, analysis
by construction. Rippling was originally developed for such and a variety of other areas. More importantly, if and when

  1Prolog Equation Solving System.                       3Tip to reader: the mathematical details are optional and have all
  2And in later proof planners, such as λClam and ISAPLANNER been put in ﬁgures separated from the main text.

                                                IJCAI-07
                                                    3it fails, the nature of the failure can be used to suggest a way out a lot of legal, but unproductive, object-level, rule applica-
to patch the proof attempt and to recover from the failure (see tions. Middle-out reasoning can rearrange the search space,
§3).                                                  postponing difﬁcult search decisions until they are made eas-
  Meta-level inference provides least-commitment devices, ier as a side-effect of other search decisions. The object-level
such as meta-variables, which can be used to postpone search inference then provides the goals that form the ammunition
decisions. For instance, in inductive proof, choosing an for the next stage of meta-level analysis.
appropriate induction rule is an inﬁnite branching point in
the search: there is an induction rule corresponding to each 3 Inference and Fault Diagnosis
well-ordering of each recursive data-structure, such as nat-
ural numbers, lists, trees, sets, etc. The key to a success- “The best laid plans of mice and men gang aft
ful induction is often to choose an induction rule that inserts aglay.” (Rabbie Burns)
wave-fronts into the induction conclusion for which there are Like all plans, proof plans are not guaranteed to succeed.
matching wave-rules, so that rippling is successful. We can When they fail, recovery requires another kind of reasoning
turn this requirement on its head by postponing the choice process: fault diagnosis. When standard object-level proof
of induction rule, inserting higher-order meta-variables into search fails, the usual response is for the proof search to back-
the induction conclusion to stand for the unknown wave- up to some earlier choice point and retry. Proof planning
front, using higher-order uniﬁcation to instantiate these meta- enables a more productive use to be made of failure. The
variables during rippling, and retrospectively choosing an in- mismatch between the situation anticipated at the meta-level
duction rule when the wave-fronts are fully instantiated. This and the situation obtaining at the object-level provides an op-
signiﬁcantly reduces the search problem by moving it from portunity to analyse the failure and propose a patch. Human
a place (the choice of induction rule) where the branching mathematicians also make a productive use of failure. See,
is inﬁnite, to a place (rippling) where it is highly constrained. for instance, [van der Waerden, 1971] for an example of re-
Because we are effectively developing the middle of the proof peated plan failure and patching in an, eventually successful,
before the beginning or the end, we call this search moving attempt to prove a challenging conjecture.
technique middle-out reasoning, in contrast to top-down or Consider, as another example, a failure of the rippling
bottom-up reasoning.                                  method outlined in §2. This might occur, for instance, be-
  We have applied middle-out reasoning to the choice of in- cause there is no rule available to ripple the wave-front out
duction rule in two PhD projects. Initially, Ina Kraan used it one more stage. From the meta-level inference that formed
to select an appropriate induction rule from a pre-determined, the rippling-based proof plan, we can extract a partial descrip-
ﬁnite set of rules, as part of a project to synthesise logic tion of the form that the missing wave-rule should take. This
programs from their speciﬁcations [Kraan et al., 1996].In is best illustrated by an example. See Figure 2.
this project, Kraan also used middle-out reasoning to syn- We have implemented this kind of fault diagnosis and re-
thesise the logic program. More recently, Jeremy Gow ex- pair within our proof planning framework using proof critics
tended middle-out reasoning to create and verify new induc- [Ireland, 1992; Ireland and Bundy, 1996]. The original work
tion rules, customised to the current conjecture [Gow, 2004; explored ways to recover from different kinds of failure of
Bundy et al., 2005b].                                 rippling, suggesting, variously, new forms of induction, case
  Proof planning is now a thriving research area, with many splits, generalisations and intermediate lemmas. Later work
applications and extensions, for instance:            by Ireland and his co-workers has extended this to discover-
                                                      ing loop invariants in the veriﬁcation of imperative programs
  • The ΩMEGA   proof planner [Siekmann et al., 2006],
                                                      [Ireland and Stark, 2001]. They have recently applied this
    which has been applied to a wide range of areas in math-
                                                      work to industrial veriﬁcation by extending and successfully
    ematics;
                                                      evaluating Praxis’ automated prover [Ireland et al., 2006].
  • Applications to the combination and augmentation of Deepak Kapur and M. Subramaniam have also developed
    decision procedures [Janiˇci´c and Bundy, 2002];  similar methods for lemma discovery in induction [Kapur and
                                                      Subramaniam, 1996].R´aul Monroy has used critics for the
  • Multi-agent proof planning [Benzm¨uller and Sorge,
                                                      correction of false conjectures [Monroy et al., 1994],which
    2001];
                                                      requires the additional reasoning process of abduction.More
  • Reasoning about feature interaction in ﬁrst-order tempo- recently, Monroy has applied his techniques to higher-order
    ral logic [Castellini and Smaill, 2005]           faulty conjectures, leading to the automatic formation of new
                                                      theories, such as monoids [Monroy, 2001]. Andreas Meier
  • Multi-strategy proof planning [Melis et al., 2006].
                                                      and Erica Melis have adapted their multi-strategy MULTI sys-
I have also proposed it as the basis for a “Science of Reason- tem to include failure analysis and the automatic proposal
ing”, in which proof plans provide a multi-level understand- of “recommendations” to overcome them [Meier and Melis,
ing of the structure of proofs [Bundy, 1991]          2005].
  Meta-level inference, and proof planning in particular, Fault diagnosis of an earlier failure suggests the most
shows how two complementary inference processes can inter- promising alternative proof attempt. It removes the need for
act to reduce the amount of search and overcome the combi- blind backtracking, removing legal, but unproductive choices
natorial explosion. Meta-level analysis matches object-level from the search space and helping to defeat the combinatorial
goals to the proof methods best suited to solve them, cutting explosion. Moreover, the proof patches often provide inter-

                                                IJCAI-07
                                                    4                                                      4   Inference and Learning
     rev(rev(l)) = l
                                                          “To this day, we continue to ﬁnd new techniques
                        ↑           ↑
         rev(rev( h :: t )) = h :: t                     and methods. There’s always something new to
                                                          learn.” (Joseph Cocking)
                                 ↑          ↑
         rev( rev(t) <> (h :: nil) ) = h :: t          We have seen the value of proof methods when used by
                                                  meta-level inference or fault diagnosis to guide object-level
                                                      proof search, but where do such proof methods come from?
                   blocked
                                                      Mostly, they have come from detailed analysis of a fam-
    rev is a list reversing function. The example is taken ily of related proofs, and reﬂection on the thinking that in-
    from a failed proof that reversing a list twice will give forms experienced mathematical reasoners. But this is a
    you the original list. Suppose that, initially, the only rule time-consuming, highly-skilled and error-prone process. The
    available is:                                     proof methods that my group developed for inductive proof,
                  ↑                       ↑
       rev( H :: T ) ⇒  rev(T ) <> (H :: nil)         for instance, took more than a decade to develop, evaluate and
                                                      reﬁne. It is necessary to maintain constant vigilance against
                                                      quick, ad hoc ﬁxes that will not have general utility and ex-
    The ripple attempt will fail because no rule matches
    the left hand side of the goal, so the wave-front can- planatory power. It would be much better if the process of
    not be moved one stage further outwards. However, by developing new proof methods could be automated.
    analysing the blocked ripple, fault diagnosis can work out My group has explored various machine learning tech-
    that the missing wave-rule should take the form:  niques to automate the construction of proof methods. These
                                                      start with successful object-level proofs whose meta-level
                     ↑                   ↑
        rev( X<>Y     ) ⇒ F (rev(X),X,Y)              structure they try to analyse and abstract, in order to formulate
                                                      new proof methods. Our earliest attempt to do this was the
    where F stands for some unknown function, repre-  application of explanation-based generalisation (EBG)tothe
    sented by a higher-order meta-variable. If we allow the equation-solving domain [Silver, 1985]. Silver’s LEARNING
    proof to continue using this missing wave-rule schema, PRESS system was able to learn (sometimes simpliﬁed) ver-
    then the proof will succeed, instantiating F (u, v, w) to sions of all the proof methods that had been hand-coded into
    rev(w) <> u
               in the process. We now discover the miss- our PRESS equation solving system, just by applying EBG to
    ing wave-rule to be:                              examples of successfully solved equations. Later, Desimone
                    ↑                     ↑           did the same for early versions of our inductive proof methods
       rev( X<>Y     ) ⇒ rev(Y ) <> rev(X)            [Desimone, 1989].
                                                        Recently, we have explored the use of data-mining tech-
    which must be proved as a lemma to complete the proof. niques to extract new methods4 from large corpuses of proofs
    Note that this lemma is a distributive law of <> over [Duncan et al., 2004]. Duncan’s IsaNewT5 system ﬁrst iden-
    rev, and is an interesting theorem in its own right, rather tiﬁes frequently occurring sequences of proof steps using
    than just an arbitrary hack needed just to get the original variable-length Markov models (VLMM) [Ron et al., 1996].
    proof to go through.                              Then it combines these sequences using genetic algorithms
                                                      to join them with branching, repetition and macros, using a
  Figure 2: Lemma Speculation Using a Rippling Failure language developed in [Jamnik et al., 2002]. The resulting
                                                      proof methods have been evaluated successfully by compar-
                                                      ing proof success and timings on a large test corpus of proofs
                                                      with and without the newly learnt tactics. Currently, the learnt
                                                      methods consist of simple, generic combinations of object-
esting information. As the example in Figure 2 illustrates, level rules. They do not approach the sophistication nor tar-
lemma speculation often produces lemmas that are of math- geting of many hand-crafted methods, such as rippling. Nor
ematical interest in their own right and prove to be useful in do they provide dramatic search reductions. However, this
future proofs. Generalisation, which is another way of patch- use of data-mining has made a promising start and has the
ing failed inductive proofs, also often generalises the original potential for much more development.
conjecture in a mathematically interesting way.         We have introduced a new class of reasoning processes
  In the other direction, the kind of fault diagnosis illustrated from machine learning. These complement meta-level in-
in Figure 2 is only possible because of the interaction of meta- ference by constructing new proof methods from example
level and object-level inference. It is the discrepancy between proofs, thus enabling meta-level inference to guide object-
the meta-level expectation and the object-level reality that fo- level proof search. The learning methods are, in turn, in-
cuses the fault diagnosis to suggest a patch that will resolve formed by previous success of object-level inference in pro-
this discrepancy and allow the original proof plan to be re- 4Technically, it is just tactics that are learnt, rather than methods,
sumed. Thus, again, we see complementary reasoning pro- since, as discussed below, we are currently unable to learn the meta-
cesses focus their attention to solve a problem that none of language for specifying these tactics: methods being tactics together
them could manage alone — nor even acting simultaneously with their meta-level speciﬁcations.
but without interaction.                                 5Is a New Tactic.

                                                IJCAI-07
                                                    5ducing proofs. Their analysis is informed by the patterns they English GCE A-Level, applied-mathematics papers, intended
identify in these proofs. Thus we have a virtuous triangle of for 16-18 year old pre-university entrants. MECHO took me-
reasoning processes, each process in the triangle using infor- chanics problems stated in English, parsed them, constructed
mation from one of its neighbours to assist the other neigh- a semantic representation in the form of ﬁrst-order logic as-
bour.                                                 sertions, extracted equations from this logical representation
  However, there is a missing process in this story: a learn- and then solved them. This process is illustrated in Figure 3.
ing process that can construct the meta-level language used to During this process, cooperation between representation
specify the proof methods. Examples of such a language are formation and inference occurs at a number of levels and in
the concepts of wave-fronts, wave-holes and skeletons, intro- several directions.
duced and illustrated in Figure 1. Silver’s and Desimone’s • The whole process of representation enables inference,
EBG-based systems assumed the prior existence of an appro- in the form of equation solving, to solve the mechanics
priate meta-level language and used it in the analysis of the problem.
object-level proofs. Duncan’s IsaNewT does not assume the
existence of such a meta-language, so is, thereby, restricted • A form of non-monotonic inference is needed to “ﬂesh
to an impoverished language for expressing proof methods. It out” the explicit problem statement. Real-world objects
cannot use conditional branching, since the conditions would must be idealised, and this can be done in a variety of
have to be expressed in the missing meta-language. It uses ways. For instance, a ship might be idealised as a parti-
non-deterministic branching instead. Similarly, it cannot use cle on a horizontal plane in a relative velocity problem,
until-loops, since again the exit condition would have to be but in a speciﬁc gravity problem it will be idealised as
expressed in the missing meta-language. It just uses repeti- a 3D shell ﬂoating on a liquid. The string in a pulley
tion. It cannot combine the proof methods with proof plan- problem is usually idealised as inelastic and the pulley
ning or analyse failures with fault diagnosis, as the method as frictionless. MECHO uses cues to recognise the prob-
speciﬁcations necessary to do this would need to be expressed lem type and then matches a problem-type schema to the
in the missing meta-language. Instead, it is reduced to con- extracted assertions, which then provides the implicit,
ducting exhaustive search at the method level, which reduces unstated assertions.
search, but not in as directed a way as proof planning is capa- • MECHO uses a form of plan formation7 to extract a set
ble of.                                                   of equations from the assertions. A physical law is iden-
  Current AI learning mechanisms appear not to be capable tiﬁed that relates the goals to the givens, e.g., F = m.a.
of performing the learning task required here: constructing a These equations may introduce intermediate variables,
new ontology. There are plenty of mechanisms for deﬁning  which must also be solved for, causing the planning pro-
new concepts in terms of old ones, but that is not sufﬁcient cess to recurse. Preconditions of the physical laws relate
to form a new meta-language. The concept of wave-front,   the variables to the assertions, enabling the laws to be in-
for instance, cannot be deﬁned in terms of the functions and stantiated to equations describing the problem situation.
predicates in the object-language. Here’s a hard challenge for
                                                        •
the next generation of machine learning researchers. For a Equation solving is used to express the goal variable in
start on tackling this challenge, see §6.                 terms of the givens. This inferential process is imple-
                                                          mented using meta-level inference, as described in §2.
5  Inference and Representation Formation               • Inference is also required during natural language pro-
    “Once you know the formula, it’s a guiding light      cessing, e.g., to resolve ambiguities, such as pronoun
    that will give you everything you want to know.”      reference. The meta-level inference mechanisms used
    (Mark Lallemand)                                      in MECHO  were motivated by the problems of control-
                                                          ling inference both in problem-solving and semantic in-
  As discussed in §2, the automation of inference requires
                                                          terpretation, and were successful in both areas. For in-
that the axioms, rules and conjectures of a theory be repre-
                                                          stance, the inferential choices arising during semantic
sented in the computer. Where do such representations come
                                                          processing are limited by idealisation, especially by the
from? In most work in automated inference, either they are
                                                          framework imposed by problem-type schemata.
adopted/adapted from a textbook or from previous research,
or they are the outcome of careful and highly-skilled hand- The ideas from the MECHO project were subsequently
crafting. However, developing an appropriate representation adapted to the ECO program, which built an ecological simu-
is one of the most important parts of problem solving. Ap- lation program in response to a dialogue with a user [Robert-
plied mathematics, for instance, mainly consists of exploring son et al., 1991].ECO incorporated a further example of
and developing mathematical representations of physical en- collaborative reasoning: a meta-level analysis of the user’s
vironments and problems. So, in a thorough investigation of requirements was used to propose two kinds of idealisation.
automatic reasoning, the formation of formal representations ECO was able to suggest both idealisations of real world eco-
ought to be a central concern.                        logical objects, e.g., animals, plants, environments, etc., and
  In the MECHO6  Project ([Bundy et al., 1979])wead-  idealisations of the processes by which they interacted, e.g.,
dressed this issue by building a program for solving mechan-
                                                         7
ics problems stated in English, with examples drawn from the We called it the “Marples Algorithm” in honour of David
                                                      Marples, who was the ﬁrst person we were aware of to describe this
  6Mechanics Oracle.                                  process in some teaching notes.

                                                IJCAI-07
                                                    6