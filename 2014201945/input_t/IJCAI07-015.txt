                      Distance Constraints in Constraint Satisfaction

        Emmanuel Hebrard                   Barry O’Sullivan                     Toby Walsh
    4C, Computer Science Dept.        4C, Computer Science Dept.            NICTA and UNSW
            UCC, Ireland                      UCC, Ireland                   Sydney, Australia
        e.hebrard@4c.ucc.ie             b.osullivan@4c.ucc.ie               tw@cse.unsw.edu.au


                    Abstract                          C =ˆ {c1,...,cm}. Each constraint ci is deﬁned by an or-
                                                      dered set var(ci) of variables and a set sol(ci) of allowed
    Users can often naturally express their preferences combinations of values. An assignment of values to the vari-
    in terms of ideal or non-ideal solutions. We show
                                                      ables in var(ci) satisﬁes ci if it belongs to sol(ci).Afeasible
    how to reason about logical combinations of dis-  solution is an assignment to each variable of a value from its
    tance constraints on ideals and non-ideals using a domain such that every constraint in C is satisﬁed. In addi-
    novel global constraint. We evaluate our approach tion to the CSP, we assume that we have some symmetric,
    on both randomly generated and real-world conﬁg-  reﬂexive, total and polynomially bounded distance function,
    uration problem instances.                        δ, between (partial) instantiations of the variables, i.e. an as-
                                                      signment of values to some subset of X . To make reason-
1  Introduction                                       ing easier, we assume that distance is decomposable into a
                                                      sum of distances between the assignments to individual vari-
In many application domains users specify their desires in ables. For example, we might have the Hamming distance
terms of assignments to (a subset of) problem variables. For     (X[i] = Y [i])
                                                      given by  i          , or the generalised Manhattan dis-
example, when planning a vacation, a user might have an tance given by |X[i] − Y [i]|.
ideal holiday in mind. This ideal holiday might, however,            i
be infeasible. Consider as another example purchasing a car.
The user might like two models on display (say Volvo and 3 Problems of Distance
Jaguar). Moreover, she does not like at all a third model (say We suppose the user expresses her preferences in terms of
Lada). As a result, she might want to sample models similar ideal or non-ideal (partial) solutions. Partiality is important
to Volvo and Jaguar whilst different from Lada. She might so we can ignore irrelevant attributes. For example, we might
therefore specify “I would like something either like the Volvo not care whether our ideal car has run-ﬂat tires or not. The
or the Jaguar, but not the Lada”. This type of query is dif- fundamental decision problems underlying our approach en-
ﬁcult to tackle using usual constraint-based preferences since sure that a solution is at a given distance to (resp. from) an
it is not articulated in terms of variables and/or constraints but ideal (resp. non-ideal) solution.
rather (partial) solutions. Many formalisms for representing
preferences in constraint satisfaction assign preferences to in- dCLOSE (resp. dDISTANT)
dividual constraints [Bistarelli et al., 1997]. Others, such as Instance. A CSP, P , a symmetric, reﬂexive, total
CP-Nets [Boutilier et al., 2004], specify preferences at a vari- and polynomially bounded distance function δ, and
able level. However, users often like to describe their prefer- p, a partial instantiation of the variables of P .
ences at a solution level [Rossi and Sperduti, 2004].     Question. Does there exist a solution s ∈ sol(P )
  In this paper we present an algebra for complex expres- such that δ(p, s) <d(resp. δ(p, s) ≥ d).
sions of distance constraints. We describe a novel soft d          d
global constraint for propagating constraints of distance, CLOSE and DISTANT are NP-complete in general, since
                                                      they can be used to decide the CSP, P . If the distance d is not
characterise the conditions under which we can propagate it d         d
tractably, and report encouraging results on real-world and ﬁxed, CLOSE and DISTANT are not necessarily polynomial
randomly generated instances.                         even if the underlying CSP is itself polynomial [Bailleux and
                                                      Marquis, 1999]. However, one can identify tractable restric-
                                                      tions of these problems if d is ﬁxed and the underlying CSP
2  Preliminaries                                      is polynomial [Bailleux and Marquis, 1999]. We can spec-
A constraint satisfaction problem (CSP) is a triple P =ˆ ify more complex problems of distance by combining primi-
X , D, C where X is a ﬁnite set of variables X =ˆ   tive distance constraints using negation, conjunction and dis-
{x1,...,xn}, D   is a set of ﬁnite  domains D    =ˆ   junction; some examples are shown in Figure 1. The laws of
{D(x1),...,D(xn)} where the domain D(xi) is the ﬁnite our basic algebra for constructing constraint expressions are
set of values that variable xi can take, and a set of constraints as follows (we slightly abuse the notation used to deﬁne the

                                                IJCAI-07
                                                   106decision problems, without consequence) where a and b are These optimisation problems are closely related to MOST-
ideal and non-ideal (partial) assignments to the variables: CLOSE and MOSTDISTANT deﬁned in [Hebrard et al., 2005].
                                                                                                   [   ]
                                                      Like these problems, CLOSE and DISTANT are FPNP log n -
      dDISTANT(a)  ↔¬dCLOSE(a)                        complete. However, there are some differences. First, MOST-
   d        (a ∨ b) ↔ d       (a) ∨ d       (b)       CLOSE  ﬁnds the feasible solution nearest to a given subset of
    DISTANT           DISTANT        DISTANT          solutions. By comparison, CLOSE ﬁnds the feasible solution
                   ↔¬dCLOSE(a   ∧ b)                  nearest to just one solution. We will soon extend CLOSE to
   dDISTANT(a  ∧ b) ↔ dDISTANT(a) ∧ dDISTANT(b)       nearness to combinations of solutions. Second, the ideal solu-
                                                      tion that CLOSE is trying to get near to might not be feasible
                   ↔¬dCLOSE(a   ∨ b)
                                                      whereas in MOSTCLOSE  it is. Third, if the ideal solution is
  More complex expressions are also possible. For exam- feasible then CLOSE will return it whilst MOSTCLOSE will
ple, we can construct expressions using implies, iff, xor,or ﬁnd the next nearest feasible solution.
ifthen. Such connectives can, however, be constructed using We can again consider logical combinations of ideals and
the standard Boolean identities.                      non-ideals. For example, we might want to minimise the dis-
                                                      tance to one ideal or maximise the distance from a non-ideal.
                                                      Distances can be combined in a number of ways. For exam-
                                                      ple, if we want to minimise the distance to ideals a and b,we
                                                      minimise the maximum distance to either. Similarly, if we
           a                          a               want to minimise the distance to ideals a or b, we minimise
                                                      the minimum distance to either. This gives us a new global
                  sol(P)                     sol(P)   objective, F, as shown in Table 1.

      (a) dCLOSE(a)             (b) dDISTANT(a)
                                                      Table 1: Examples of some simple distance constraints and
                                                      their corresponding objective functions to be minimised.

                                                               Constraint      Objective function
       a      b                   a      b                   CLOSE(a  ∨ b)  F = min(δ(s, a),δ(s, b))
                                                             CLOSE(a  ∧ b)  F = max(δ(s, a),δ(s, b))
                  sol(P)                     sol(P)

    (c) dCLOSE(a ∨ b)         (d) dDISTANT(a ∧ b)       Other combinators like + and min are also possible. We
                                                      also permit the distance function to depend on the ideal
                                                      or non-ideal. For example, we might want distance from
                                                      ideal c to count twice as much as distance from d.In
                                                      this case, CLOSE(c ∨ d) gives the objective function F =
       a      b                   a      b            min(2δ(s, c),δ(s, d)). To make combinations uniform, we
                                                      convert maximising the distance, δ, from a non-ideal a into
                  sol(P)                     sol(P)   minimising a new distance, m − δ,toa where m is the max-
                                                      imum possible distance returned by δ. In this way, we get a
             (a ∧ b)                (a)∧        (b)
    (e) dCLOSE             (f) dCLOSE   dDISTANT      single objective F which we need to minimise. Finally, we
                                                      consider compiling out an objective function for a more com-
Figure 1: A graphical representation of the basic constraint plex logical combination of distance constraints.
expressions that can be constructed; a and b are solutions,
                                                      Example 1 (Conjunction) We consider again the example
sol(P ) is the set of solutions to the CSP P , and the radius
of the circles represents the distance, d. The shaded region of the choice of car conﬁguration within a large catalogue
represents the solutions that satisfy the constraints. used in Section 1. A customer is interested in two models
                                                      (Volvo and Jaguar), whilst disliking a third model (Lada).
                                                      The query CLOSE(Volvo), CLOSE(Jaguar), DISTANT(Lada)
                                                      implements this wish. This expression means that we seek
4  Optimisation problems                              a solution s that is simultaneously as similar as possible to
Rather than specify the precise distance from the ideals and Volvo and Jaguar and as different as possible from Lada. It
non-ideals to the solution it may be more useful to minimise can be reformulated as the following logical expression:
(maximise) the distance to an ideal (resp. a non-ideal).
                                                         (CLOSE(Volvo) ∧ CLOSE(Jaguar) ∧ DISTANT(Lada))
    CLOSE (resp. DISTANT)
    Instance. A CSP, P , a distance function δ, and a which gives the following objective function, F, substituting
    partial solution p.                               max  for logical conjunction and converting maximising dis-
    Question. Find a solution s ∈ sol(P ) such that   tance to minimising the distance complement:
    for all s ∈ sol(P ) −{s}, δ(p, s) ≤ δ(p, s) (resp.
    δ(p, s) ≥ δ(p, s)).                                 F = max(δ(s, Volvo),δ(s, Jaguar),m− δ(s, Lada)).

                                                IJCAI-07
                                                   1075  Propagation and Complexity                         domain of N. Algorithm 1 ﬁrst computes the smallest dis-
                                                                     v                           N
We consider how to propagate such distance constraints. We tance to the ideal in loop 1. Then the domain of and of
                                                      X  ,...,X
observed in [Hebrard et al., 2005] that the problems MOST- 1   n are pruned in line 2 and loop 3. For disjunctive
CLOSE  and MOSTDISTANT  can be solved using symmetri- combinations, we compute the values that are inconsistent for
cally equivalent algorithms. Similarly, the problems studied each distance constraint using Algorithm 1, and prune those
here are symmetric, therefore we focus on minimising the dis- values in the intersection. Using constructive disjunction, we
tance (similarity) rather than maximising it (diversity). Thus, achieve GAC in O(ndk) time.
we introduce a soft global constraints SIMILAR⊗. The n-ary
operator ⊗∈{min, max}  is used to aggregate distances to
individual ideals:                                    Conjunction (SIMILARmax).  Conjunctive combinations of
 SIMILAR⊗([X1,...,Xn],N,V = {v1,...,vk}, {δ1,...,δk}) distance constraints are more problematic. Consider the con-
               j=k Pi=n
           iff ⊗j=1 ( i=1 δj (Xi,vj [i])) ≤ N.        junctive Hamming distance constraint:
           min
The operator   handles disjunctions of distance constraints               i=n
whilst max handles conjunctions. The constraint ensures that      maxj=k     (X  = v [i]) ≤ N.
                                                                      j=1      i    j
                        V = {v1,...,v }         N
the distance to a set of ideals      k  is at most .                      i=1
Notice that we assume that the distance between two vectors
is equal to the sum of the distances on all coordinates. Deciding the satisﬁability of this formula is NP-hard. Hence,
  We showed that enforcing generalised arc consistency enforcing GAC on SIMILARmax with respect to an arbitrary
(GAC) on this constraint is NP-hard for ⊗ = max [He-  number of ideals is NP-hard [Hebrard et al., 2005]. However,
brard et al., 2005]. However, enforcing GAC is tractable we shall investigate ﬁltering methods stronger than a straight-
when the number of ideals is bounded. On the other hand, forward decomposition into distance constraints with respect
for ⊗ = min, GAC can be enforced in polynomial time for to a single ideal. We shall see in the next section that even
any number of ideals. Table 2 summarises the complexity of though a distance constraint to a single ideal is easy to propa-
enforcing GAC on the SIMILAR⊗ constraint. We now prove gate and the conjunction of such constraints can naturally be
the results given in this table.                      processed as individual constraints in a network, stronger ﬁl-
                                                      tering can be obtained by considering the whole conjunction.

Disjunction (SIMILARmin). Propagating the SIMILAR⊗
constraint for a single ideal can be done in polynomial time. Algorithm 2: Lower bound on N.
Indeed, it is equivalent to the problem dCLOSE on a network
                                                        Data: X1,...,Xn,N,V = {v1,...,vk}, {δ1,...,δk}
involving only domain constraints. Algorithm 1 implements Result: A lower bound on N
a linear (O(nd)) algorithm for ﬁltering SIMILAR with respect Q ← [0, 0,...,0];
to a single ideal (the value of ⊗ is undeﬁned in this case). foreach Xi do
                                                           Q ←∅;
                                                                  j ∈ D(X )
 Algorithm 1: Prune a distance constraint, single ideal.   foreach       i do
                                                               foreach M ∈ Q do
                                                                    
  Data: X1,...,Xn,N,v,δ                                           M  ← M;
                           ([X ,...,X ],N,v,δ)
  Result: GAC closure of SIMILAR 1   n                            foreach vl ∈ V do
  LB ←  0                                                                    
         ;                                                           M  [l] ← M [l]+δl(j, vl[i]);
1 foreach Xi do                                                            
                                                                  Q ←  Q ∪ M  ;
     lb[i] ← min(δ(v[i],j), ∀j ∈ D(Xi));
     LB ←  LB + lb[i]                                      Q ←  Q;
2 min(N) ←  max(min(N),LB);                             return max(M[l], ∀l ∈ [1,...,k], ∀M ∈ Q);
3 foreach Xi do
     foreach j ∈ D(Xi) do
        if min(N)+δ(v[i],j) − lb[i] >max(N) then        We show that under the assumption that the distance mea-
           D(Xi) ←  D(Xi) \{j};                       sure is discrete and bounded in size by the number of vari-
                                                      ables (as is the case for Hamming distance), enforcing GAC
                                                      on the SIMILARmax  constraint with respect to a bounded
  The notation min(N) stands for the minimal value in the number of ideals is tractable. Algorithm 2 ﬁnds a sharp lower
                                                      bound with respect to a set of ideals. Moreover its worst-case
                                                      time complexity is O(dnk+1), hence polynomial when the
                                                      number k of ideals is bounded. It is therefore easy to derive a
Table 2: The complexity of propagating the SIMILAR con-
                                                      polynomial ﬁltering procedure for this constraint by checking
straint on a disjunction (SIMILAR ) or a conjunction
                              min                     this lower bound against the upper bound of N for each of the
(SIMILAR    )ofk ideals where k is bounded by a constant,
        max                                           nd possible assignments. The complexity of such a ﬁltering
or a polynomial function (p(n)) in the size of the problem.                    2  +2
                                                      procedure would thus be O(d nk ).
                    SIMILARmin   SIMILARmax
         k ∈O(1)      O(ndk)     O(d2nk+2)            Theorem 1  Algorithm 2 ﬁnds a correct lower bound on the
       k ∈O(p(n))     O(ndk)      NP-hard             maximal Hamming distance to a set of ideals, and runs in
                                                      O(dnk+1) time.

                                                IJCAI-07
                                                   108Proof: This algorithm builds a partially ordered set of vectors solution and all the ideals will be at least 5. To minimise
of distances to ideals. A set of vectors is computed for each the maximum distance from either ideal, this total number
variable. Given two consecutive variables Xi and Xi+1,two of discrepancies should be evenly distributed across ideals,
vectors M and M  are related in the partial order (M  ≥ M) i.e., the minimum maximum distance is at least 5/2 =3.
                                           
iff there exists an assignment X +1 = j such that M − M = Hence we cannot achieve a distance of 2. The approxima-
                          i                                                                     ¯
[δ1(j, v1[i +1]),...,δk(j, vk[i +1])]. All reachable vectors tion is based on the following inequality, where X denotes
of distances are thus computed, so the bound is correct. the vector [X1,...,Xn]:
  We ﬁrst show that the cardinality of the whole poset is     j=k
at most nk. Indeed, the distance measures are discrete and          ¯              j=k  ¯
                                                                δ(X,vj)/k≤max    =1 δ(X,vj).        (1)
bounded by the number n of variables, and each vector is of                        j
                                                              j=1
dimension k, hence there are at most nk distinct vectors. The
cardinality of any layer is thus at most nk. For each layer we Now consider a second example where we add the ideal
            d                                         v3 = 0, 1, 0, 1, 0. We can compute a lower bound for the
create at most new vectors for each vector in the previous                                   X
                                  dnk                 minimum maximum distance in the same way. 1 can either
layer. This algorithm needs fewer than steps for each            0            1              1          2
layer, giving a worst-case time complexity O(dnk+1).  be assigned which entails discrepancy, or leading to
                                                      discrepancies. The same is true for X3 and X5 while the op-
Example 2 (Conjunction) We show on our example how a  posite holds for X2 and X4. Therefore we know that the total
logical expression formulating preferences in terms of ideals number of discrepancies will be at least 5. Hence we can de-
can be compiled into a constraint network. We assume that rive a lower bound of 5/3 =2, and we do not detect an
                             n         {X  ,...X }
the conﬁguration database involves variables 1  n     inconsistency. However, we cannot distribute these discrep-
subject to a set of constraints C. The objective function ancies evenly. As the ideals considered in the ﬁrst example all
   F = max(δ(s, Volvo),δ(s, Jaguar),m− δ(s, Lada))    appear in the second example, the maximum distance cannot
                                                      be smaller. This observation gives us a tighter lower bound.
is compiled into the following constraint program:    In fact, the distance from a solution to a set S1 cannot be less
                                                      than the distance to a subset S2 of S1:
               minimise(N)                             S  ⊆ S  ⇒  max     δ(X,v¯ ) ≤ max    δ(X,v¯ ).
                            subject to:                  2    1       j∈S2     j        j∈S1     j    (2)
 C(X  ,...,X )
     1      n   &                                     Therefore, we can consider any subset of ideals, and get a
            (   X  ,...,X  ,N,
 SIMILARmax       1      n                            sound lower bound. By combining (1) and (2), we get the
                {Volvo, Jaguar, Lada},                following lower bound:
                {Hamming,  Hamming,n−   Hamming})                  
                                                      max        (   δ(X,v¯ )/|S|) ≤ maxj=kδ(X,v¯ ).
                                                          S⊆{1..k}          j             j=1     j   (3)
6  Approximation Algorithm                                         j∈S
We have seen in the previous section that enforcing GAC on We introduce an algorithm (Algorithm 3) based on Equa-
                                                      tion 3. Notice that in this algorithm we do not require the
the SIMILAR    constraint for a bounded number of ide-
           max                                        distance measure to be the same on all ideals, however the
als is polynomial. However, the algorithm we introduced                N
may be impractical on large problems. We therefore propose “threshold” variable used to bound the maximum distance
                                                      to any ideal is unique. This algorithm goes through all sub-
an approximation algorithm, reducing the complexity from     V
O(d2nk+2) to O(nd2k). This algorithm does less pruning sets of and computes the minimal sum of distances that
                                                      is achievable with the current domains. Then for any assign-
than enforcing GAC but more than decomposing into indi-    X = v                                 max(N)
vidual distance constraints.                          ment       that would increase this distance above
                                                      we remove v from D(X). The complexity is in O(nd|S|) for
  As seen previously, a conjunction of distance constraints   S
can be represented as k individual constraints. First, we can each set considered. If the number of ideals is too large
decompose it into k individual constraints, one for each ideal: then only part of the power may be considered. In this case,
                                                      the computed lower bound remains valid.
                i=n                                    For each subset S of ideals, we compute LB (line 2), a
                   (X  = v [i]) ≤ N.
                     i    j                           lower bound on the maximum distance to S. For each value
                i=1                                   on each coordinate we can compute the number of ideals in
                                                      S
Each individual constraint can be made GAC in linear time. whose distance to the solution would be increased if that
                                                                                            |S|
However, by considering the ideals separately, we will not do value was chosen. This number, divided by (line 3) is a
as much pruning as is possible.                       lower bound on the contribution that this value makes to the
  To see this, consider the following example. Let X1 whole distance. The minimum of each of these individual
to X5 be 0/1 variables. Consider two ideals: v1  =    distances are aggregated to compute a lower bound on the
0, 0, 0, 0, 0,v2 = 1, 1, 1, 1, 1. We assume that δ is the distance to the complete set of ideals (line 4). Finally, the
Hamming distance, and that the distance δ from a solution lower bound and the individual distances are used to prune
to any ideal must be at most 2, i.e., D(N)=[0, 1, 2].Even values. Any value which increases the lower bound above
                                                      max(N)
though no inconsistency can be inferred when looking at v1    can be pruned (line 5).
and v2 separately, the constraint is globally inconsistent. Any Theorem 2 Algorithm 3 ﬁnds a valid lower bound on the
variable Xi will either be assigned to 0 or 1 but not both. maximal Hamming distance to a set of ideals, ﬁlters the do-
Therefore, the total sum of pairwise differences between a mains with respect to this bound and runs in O(nd2k).

                                                IJCAI-07
                                                   109                                                             n
 Algorithm 3: Prune a distance constraint, multiple ideals. We plot minus distance (the distance complement) against
                                                      cpu-time, measured in seconds, and number of backtracks av-
  Data: X1,...,Xn,N,V = {v1,...,vk},δ1,...,δk
                                                      eraged over the 100 instances, in each case. More formally,
  Result: A closure of SIMILARmax([X1,...,Xn],N,V =
        {v ,...,v }, {δ ,...,δ })                     we plot the following function, where St is the set of solu-
          1     k    1     k                                                                 t V
1 foreach S ⊆ V do                                    tions found at time (or number of backtracks) , is the set
                                                                 n
2    LB ←  0;                                         of ideals andis the number of variables:
     foreach Xi do
                                                                    (n − maxv∈V δ(s, v))/100.         (4)
        foreach j ∈ D(XPi) do
                                                                s∈St
           Dist[i][j] ←    δl(j, vl[i])
3                       vl∈S       ;
                                                        Our search strategy was to chose the next variable to branch
4       LB ←  LB + min(Dist[i])/|S|;
        if LB >max(N) then Fail;                      on with the usual domain/degree heuristic. The ﬁrst value as-
                                                      signed was chosen so as to minimise the number of discrep-
     min(N) ←  max(LB, min(N));
           X                                          ancies with the ideals for its coordinate. In other words, given
     foreach i do                                     k       {v ,...,v }                     X
        D(X  ) ←{v  ∈ D(X ) | (|S|.LB − min(Dist[i]) +  vectors 1      k , we choose for a variable i the value
5           i     j       i                           w ∈ D(X  )                  δ (w, v [i])
        Dist[i][j])/|S|≤max(N)};                               i such that j∈[1,...,k] j j  was minimal.

                                                          60                    53
                                                                                52
                                                          50                    51
                                                          40                    50
Proof: We show that Equation 3 is valid. It is a composition                    49
of two straightforward inequalities. Equation 1 relies on the  30               48
                                                                                47
fact that the maximal element of a set is larger than the aver-  20             46
                                                                                45
age, whilst Equation 2 states that the maximal element of a set distance  complement  10 decomposition decomposition
                                                                 global constraint  44  global constraint
                                                           0                    43
is larger than the maximal element of any subset. The proce-  0.1  1    10    100 10 100 1000 1e+4 1e+5 1e+6 1e+7
dure used at each iteration of the outer loop (line 1) is similar cpu-time (seconds)    backtracks
to Algorithm 1 with the same linear complexity (O(nd)). The       (a) Conﬁguration Problem: 2 ideals
number of iterations is, in the worst case, equal to the cardi-
                                     k
nality of the power set of {1,...,k}, hence 2 .          60                    51
                                                          50                    50
                                                                                49
Theorem 3 Algorithm 3 achieves a strictly stronger ﬁlter-  40
                                                                                48
ing than the decomposition into constraints on a single ideal:  30
        ([X ,...,X ],N,v ) ∀j ∈ [1,...,k]                                       47
SIMILAR    1      n     j              .                  20
                                                                                46


                                                        distance  complement  10 decomposition  45 decomposition
Proof: (sketch) We ﬁrst show that Algorithm 3 is stronger        global constraint      global constraint
                                                           0                    44
than the decomposition. Without loss of generality, consider  0.1  1    10    100 10 100 1000 1e+4 1e+5 1e+6 1e+7
an ideal vj. When the subset {vj} is explored in loop 1, the    cpu-time (seconds)      backtracks
computation, hence the ﬁltering, will be the same as in Algo-     (b) Conﬁguration Problem: 3 ideals
rithm 1. Then we give an example to show that this relation
                                                          50                    49
is strict. Let X1 to Xn be Boolean variables, and consider
                                                          45                    48
          v  =  0,...,0,v =  1,...,1                  40
two ideals: 1             2            , and assume                             47
                                                          35
that δ is the Hamming distance and N =[0,n/2 − 1]. The    30                    46
decomposition is GAC, whilst Algorithm 3 fails.          25                    45
                                                          20                    44
                                                          15
  Unfortunately, this algorithm does not achieve GAC, in                        43
                                                          10
                                                        distance  complement decomposition  42 decomposition
general. This is to be expected given its lower complexity.  5   global constraint      global constraint
                                                           0                    41
                                                           0.1    1     10    100 10 100 1000 1e+4 1e+5 1e+6 1e+7
7  Empirical Evaluation                                         cpu-time (seconds)      backtracks
                                                                  (c) Conﬁguration Problem: 4 ideals
We ran experiments using the Renault conﬁguration bench-
    1                                                               49
mark , a large real-world conﬁguration problem. The prob-           48
lem consists of 101 variables, domain size varies from 1 to 43,     47
and there are 113 table constraints, many of them non-binary.       46
                                                                    45

We randomly generated 100 sets of ideals, of cardinality 2,         44
                                                                  distance  complement
3 and 4, giving 300 instances in total. For each instance we        43              decomposition
                                                                                   global constraint
                                                                    42
used Branch & Bound to minimise the maximum Hamming                  1  2  3  4  5  6  7  8  9  10
distance to the set (conjunction) of ideals.                                 cpu-time (seconds)
  We compared the decomposition of distance constraints             (d) A “zoom” on Figure 2(c).
on each ideal separately as well as our propagation algo-
rithm approximating GAC (Algorithm 3) for the combined  Figure 2: Results for the Renault conﬁguration problem.
distance global constraint. We report the results obtained in
Figures 2(a), 2(b) and 2(c) for 2, 3 and 4 ideals, respectively. On this benchmark the gain achieved in runtime using the
                                                      global constraint instead of the decomposition is slight. In-
  1
   ftp://ftp.irit.fr/pub/IRIT/RPDMP/Configuration     deed, the curves are almost equal regardless of the number of

                                                IJCAI-07
                                                   110