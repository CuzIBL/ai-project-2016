             Hierarchical Heuristic Forward Search in Stochastic Domains

                    Nicolas Meuleau∗                             Ronen I. Brafman
               NASA Ames Research Center                  Department of Computer Science
                      Mail Stop 269-3                          Ben-Gurion University
            Moffet Field, CA 94035-1000, USA                  Beer-Sheva 84105, Israel
          nmeuleau@email.arc.nasa.gov                       brafman@cs.bgu.ac.il

                    Abstract                          ments that may be used at different locations (for instance,
                                                      warmed-up or not). The rover has only limited resource for
    Many MDPs exhibit an hierarchical structure where each plan execution phase and it must wisely allocate these
    the agent needs to perform various subtasks that are resources to different tasks. In most problem instances, the
    coupled only by a small sub-set of variables con- set of tasks is not achievable jointly, and the agent must dy-
    taining, notably, shared resources. Previous work namically select a subset of achievable goals as a function of
    has shown how this hierarchical structure can be  uncertain events outcome.
    exploited by solving several sub-MDPs represent-    These problems are often called oversubscribed planning
    ing the different subtasks in different calling con- problems. They have a natural two-level hierarchical struc-
    texts, and a root MDP responsible for sequencing  ture [Meuleau et al., 2006]. At the lower level, we have the
    and synchronizing the subtasks, instead of a huge tasks of conducting experiments at each site. At the higher
    MDP representing the whole problem. Another im-   level, we have the task of selecting, sequencing and coor-
    portant idea used by efﬁcient algorithms for solv- dinating the subtasks (in the planetary rover domain, this
    ingﬂatMDPs,suchas(L)AO*and(L)RTDP,is              includes the actions of tracking targets, navigating between
    to exploit reachability information and an admissi- locations, and warming-up instruments). This hierarchical
    ble heuristics in order to accelerate the search by structure is often obvious from the problem description, but it
    pruning states that cannot be reached from a given can also be recognized automatically using factoring methods
    starting state under an optimal policy. In this pa- such as that of [Amir and Englehardt, 2003].
    per, we combine both ideas and develop a variant of
                                                        The potential beneﬁt of hierarchical decomposition is clear.
    the AO* algorithm for performing forward heuris-
                                                      We might be able to solve a large problem by solving a num-
    tic search in hierarchical models. This algorithm
                                                      ber of smaller sub-problems, potentially gaining an exponen-
    shows great performance improvements over hier-
                                                      tial speed-up. Unfortunately, the existence of an hierarchi-
    archical approaches using standard MDP solvers
                                                      cal decomposition does not imply the existence of an opti-
    such as Value Iteration, as well as with respect to
                                                      mal decomposable policy. Thus, one must settle for certain
    AO* applied to a ﬂat representation of the prob-
                                                      restricted forms of optimality, such as hierarchical optimal-
    lem. Moreover, it presents a general new method
                                                      ity [Andre and Russell, 2002], or consider domains in which
    for accelerating AO* and other forward search al-
                                                      compact optimal policies exist, such as those that satisfy the
    gorithms. Substantial performance gains may be
                                                      reset assumption of [Meuleau et al., 2006].
    obtained in these algorithms by partitioning the set
    of search nodes, and solving a subset of nodes com- This paper formulates an hierarchical forward heuristic
    pletely before propagating the results to other sub- search algorithm for And-Or search spaces, which we refer
    sets.                                             to as Hierarchical-AO* (HiAO*). This algorithm exploits a
                                                      hierarchical partition of the domain to speed up standard AO*
  In many decision-theoretic planning problems, the agent search [Nilsson, 1980]. It may be applied anywhere that AO*
needs to perform various subtasks that are coupled only by may be applied, that is, for all problems that can represented
a small sub-set of variables. A good example of this is our as an acyclic And-Or graph, provided an hierarchical parti-
                                                      tion of the search space is deﬁned. This could be MDPs or
main application domain: planetary exploration. In this do-                 1
main, the agent, an autonomous rover, must gather scientiﬁc any other search problem. Although there is no formal guar-
data and perform experiments at different locations. The in- antee that it will result in actual performance improvements,
formation gathering and experiment running task at each site our simulations with the rover domain show that it has a great
is pretty much self-contained and independent of the other potential for oversubscribed planning problems. Further work
sites, except for two issues: the use of shared resources (such
as time, energy and memory), and the state of some instru- 1Like standard AO*, HiAO* is not designed to work on prob-
                                                      lems that contain loops. A similar extension to that in [Hansen and
  ∗QSS Group Inc.                                     Zilberstein, 2001] is required to handle these problems.

                                                IJCAI-07
                                                  2542is required to show the relevance of this approach in a more by-passing edges, and (3) local solution re-use. These three
general setting. However, this paper outlines directions that properties emerge naturally when one attempts to search hi-
could beneﬁt a wide variety of application domains, and other erarchically, and they can be used given an arbitrary parti-
forward search algorithms such as A*.                 tioning of the state space (that is, beyond the application to
  The reason why forward heuristic search can be beneﬁ- oversubscription planning). This formulation, its abstract in-
cial in hierarchical MDPs is pretty obvious. It is the well- terpretation, and its evaluation in the rover domain are the
known beneﬁt of using reachability information and admis- main contributions of this paper.
sible heuristic. The most efﬁcient algorithms for solving ﬂat In the next section, we explain how we model hierarchical
MDPs, such as (L)AO* [Hansen and Zilberstein, 2001] and MDPs. Then, we review the AO* algorithm, we explain the
(L)RTDP [Barto ıet al., 1995; Bonet and Geffner, 2003], ac- new HiAO* algorithm, and we show how it can be applied to
celerate the search by pruning states that cannot be reached oversubscribed planning problems. Finally, we describe our
from a given starting state under an optimal policy. The empirical evaluation of HiAO* and conclude.
same beneﬁt can be expected in a hierarchical representa-
tion of the problem. Hierarchical algorithms such as Abort- 1 Hierarchical MDPs
Update [Meuleau et al., 2006] must resolve similar sub-
problems, but in different calling contexts. Implementations A Markov Decision Process (MDP) [Puterman, 1994] is a
based on classical MDP solvers such as Value Iteration or Pol- four-tuple S, A, T, R,whereS is a set of states, A is a set
icy Iteration, which ignore the initial state, must consider all of actions, T : S × A × S → [0, 1] is the transition func-
                                                      tion which speciﬁes for every two states s, s ∈ S and action
possible contexts. Forward search algorithms consider only                                         
reachable contexts, and with a good heuristic function, only a a ∈ A the probability of making a transition from s to s when
subset of these.                                      a is executed, and R : S ×A×S → R is the reward function.
                                                      We augment the above description with a concrete initial state
  More interesting are the reasons why HiAO* can outper- init                               init
form standard heuristic search over ﬂat-domains as imple- s ∈ S, obtaining a quintuple S, A, T, R, s .Inthispa-
mented in standard AO*. The ﬁrst reason has to do with the per, we focus on bounded-horizon MDPs (in which the length
order and efﬁciency of the value propagation step, which is of each trajectory is bounded by a ﬁnite number) and we use
known to be the costliest part of AO*. HiAO* embodies a the undiscounted expected reward criterion.
lazy approach to value updates: the update work is concen- We shall concentrate on factored MDPs which have the
                                                      form X, A, T, R, sinit.HereX is a set of state variables,
trated within a particular sub-domain each time, and work on      init
other domains is postponed until their value is needed. and A, T, R, s are as before. The variables in X induce
  The second beneﬁt of the hierarchical partitioning of the a state space, consisting of the Cartesian product of their do-
domain is the possibility to use macro-connectors.When mains. To simplify notations, we assume all variables are
the optimal solution over a subset of states is known, it can boolean, that is, they are ﬂuents. Typically, it is assumed that
be represented as a macro-connector similar to the tempo- the transition function T is also described in a compact man-
rally abstract actions or macro-actions used in Reinforce- ner that utilizes the special form of the state space, such as
ment Learning [Sutton et al., 1999]. Macro-connectors are dynamic Bayes net [Dean and Kanazawa, 1993] or proba-
then used while solving other subsets of states, to accelerate bilistic STRIPS rules [Hanks and McDermott, 1994].Inthis
the traverse of the graph.                            paper, we do not commit to a concrete action description lan-
  The third beneﬁt of forward heuristic search in a hierarchi- guage, but we expect it to be variable-based, such as the above
cal representation is the possibility of using a known solution methods, as we assume that it is easy to identify the relevant
of a subtask to seed the algorithm in charge of solving sim- variables with respect to an action a ∈ A. Thisistheset
ilar subtasks. As will become apparent later, the dynamics of variables whose value can change when a is executed, as
within a sub-problem is not inﬂuenced by the calling context. well as those variables that affect the probability by which
The latter inﬂuences the value of nodes, and thus the optimal these variables change their value and the immediate reward
policy, but not the search space structure. Therefore, we can received for executing a.
reuse expanded solutions for different calling context, using An hierarchical decompositions of an MDP consists of a
                                                      set of smaller factored MDPs. In its deﬁnition, the notion
them as starting points. Although farther expansion will be                                          
required, we are likely to beneﬁt from much of this work. of a projection of T and R plays a central role. Let X be
  Finally, with a decomposed domain, we believe that one some subset of the variables in X. The projection of T over
                                                      X w.r.t. action a ∈ A is well deﬁned if a does not affect the
can formulate more accurate heuristic functions that are ap-                   
propriate for each of the sub-domains. A simple example value of the variables in X\X and the transition probabilities
would be the assessment of the value of a sub-domain under and reward of a do not depend on the value of these variables.
                                                      In that case, the actual projection can be obtained by ﬁxing
new calling contexts. We can simply use the value computed                                   
for similar contexts. A more sophisticated example would be some arbitrary value to the variables in X \ X .
                                                        Formally, we deﬁne a  hierarchical decomposition of
the use heuristics speciﬁcally designed for a particular sub-                            init
domains.                                              a factored MDP  M   =  X, A, T, R, s  asatreeof
  In this paper, we focus on explaining and testing the ﬁrst factored MDPs, MH = {M0,...,Mn},whereMi   =
                                                            +        init
three points above. We provide an abstract, and quite gen- Xi,Ai ,Ti,Ri,si . Each Mi is just a factored MDP. The
                                                                                        +
eral interpretation of the use of any hierarchical decomposi- only difference is that its set of actions, Ai contains a number
tion in AO* in terms of (1) propagation order, (2) extra level of special control actions which signify the passing of control

                                                IJCAI-07
                                                  2543                        M0                                                                       init
                                                       1: Initialize the explicit graph G to the start state s .
                  ˜           A                                 init
                  X0:          0:                      2: Mark s   as open.
               At(Start)    Navigate (*,*)             3: while the greedy solution graph contains some open
               At(Waypoint) Trackstart (*)
                              μ                           nodes do
                               1                            s :=
                              μ2                       4:       any open node of the greedy graph.
                                                       5:   Unmark s as open.
                                                                    s  //
    A1:        ¯                                       6:   EXPAND(  ).  Expand the greedy graph
              X1:             X¯           A
                      Resources: 2:         2:         7:    PDATE  s //
   IP(R1)     At(R1)                                        U      ( ).  Update state values and mark best ac-
                        e = 0 At(R2)      IP(R2)            tions
   Core(R1)   Tracked(R1) e = 1 Tracked(R2)
              Done(R1)  e = 2            Core(R2)      8: Return the greedy solution graph.
 TakePicture(R1)         ...  Done(R2)
             ˜                          TakePicture(R2)
   Abort    X1:                ˜                                   Algorithm 1: Standard AO*.
                               X2:        Abort
            DoneIP(R1)
                              DoneIP(R2)
            Cored(R1)
                              Cored(R2)                1: for each a ∈ A do
                                                                                       
          M                                            2:   for each s ∈ S such that T (s, a, s ) > 0 do
           1                          M                               
                                       2               3:     if s ∈/ G (s is not already present in G) then
                                                                     
                                                       4:       Add s to G.
                                                                   
Figure 1: Decomposition of a simple rover problem: a root 5:    if s is a terminal state then
                                                                     
process M0 navigates among two rocks, R1 and R2, and   6:         V (s ):=0.
schedules two corresponding subprocesses M1 and M2 (IP 7:       else
                                ˜                                 V (s):=H(s).
stands for “Instrument Placement”). Xi is the set of private 8:
                       ¯                                               s
variables of process i,andXi is the separation between sub- 9:    Mark   as open.
task i and the root process.                          10:   Add the connector (s, a, ·) to G.
                                                                    Algorithm 2: EXPAND(s).
to its parent or one of its children. These actions encode the
                                       +
hierarchy, too. More speciﬁcally, Xi ⊆ X; Ai is the union 2.1 The AO* Algorithm
of some subset Ai ⊆ A together with two types of control AO* [Nilsson, 1980] is a generalization of A* to And-Or
actions: μj corresponds to passing control to a child process graphs. As such, it can be applied to the problem of gen-
Mj,andAbort signiﬁes the passing of control back to the par- erating a policy for an MDP given an initial state, assuming
ent process; Ti is the projection of T over Xi, such that Ti is there are no loops in the transition graph [Hansen and Zilber-
           R            X      A          sinit
well-deﬁned; i depends on i and i only; and i is the stein, 2001]. In MDPs, an OR node corresponds to a choice
           sinit    X                     X   = X
projection of over  i. In addition, i=1,...,n i  ,   of an action at a state, and an AND node corresponds to the
 i=1,...,n Ai = A, Ai ∩ Aj = ∅ for every i  = j,andwhen- set of possible states resulting from each such choice. The
ever x ∈ Xi ∩Xj then x ∈ Xk for every k such that Mk is on possible AND nodes are annotated by their probability.
the path between Mi and Mj (which is known as the running AO* maintains two basic structures: the explicit graph and
intersection property). See [Meuleau et al., 2006] for a more the greedy graph. The explicit graph simply depicts the por-
detailed description of this model. A decomposition of M tion of the search space that has been expanded so far. The
into MH can be obtained automatically by a straightforward greedy graph is a subgraph of the explicit graph which repre-
extension of the methods described in [Amir and Englehardt, sents those nodes that are reachable by the greedy policy. To
2003] for deterministic planning domains.             obtain the greedy graph, one needs to perform dynamic pro-
  As an illustration, Fig. 1 describes a decomposition of a gramming in the explicit graph, propagating values bottom-
simple planetary rover domain into three sub-domains. M0 up from the leaf nodes (using their heuristic values) to the root
is the top-level domain in which we control the position of node. The value of an AND node is the expected value of its
the rover and the choice of which subtask to perform next children, and the value of an OR node is the maximum over
(these are the μi actions). M1 and M2 represent the subtasks the value of its children. If we note the choice that yielded this
associated with experimenting on of one of two rocks. M0 maximum, we can now generate the greedy graph by simply
shares some variables with its children, and the resource level following these choices starting at the root node. The pseudo-
is a variable shared by all.                          code for AO* is described in Algorithms 1 - 3.
                                                        If an admissible heuristic function is used in AO*, then
                                                      the value of each node may only decrease at each iteration.2
                                                      When we update the value of a node outside the greedy graph,
2  Hierarchical AO*                                   the greedy graph may not be affected because the update can
                                                      only reduce the value of the node. Thus, a choice that was
We start with a short review of the AO* algorithm. Next, we sub-optimal cannot become optimal. Consequently, new node
show how a hierarchical partition of the search nodes may values need only be propagated up edges marked as optimal,
be exploited to accelerate the algorithm, and we provide the
pseudo-code of a new general algorithm called Hierarchical- 2In a reward-maximization framework, an admissible heuristic is
AO* (HiAO*).                                          an heuristic that never underestimates the value of a state.

                                                IJCAI-07
                                                  2544 1: Create set Z containing only the state s.          1: while the greedy solution graph starting at s contains
 2: repeat                                                some open nodes in Si do
                                                            
 3:  Remove from Z  a state s such that no descendent of 2: s := any open node of the greedy graph starting at s
      
     s in G occurs in Z.                                    in Si.
                                                                   
 4:  Set V (s):=max a∈A                             3:   Unmark s as open.
                                                            s
               s∈G T (s ,a,s )(R(s ,a,s )+V (s ))    4:   EXPAND(  ).
     and mark the connector associated with the best action 5: Mark all nodes created at previous step and that belong
        
     in s as optimal.                                       to a child of Si as outdated.
                                                                                    
 5:  if V (s ) decreased at previous step (it cannot increase) 6: HIERARCHICALUPDATE(Si,s).
     then
                                                               Algorithm 5: Function SOLVE(Si,s).
 6:    Add all parents of s along connectors marked as
       optimal to Z.
 7: until Z is empty.                                 Delaying the propagation of new values: The main prin-
                                                      ciple implemented by HiAO* is to delay the propagation of
              Algorithm 3: UPDATE(s).
                                                      new node values in between states belonging to different
                                                      subsets. Let us ﬁrst consider why delaying updates might
                                           init
 1: Initialize the explicit graph G to the start state s . be useful. Suppose that we have expanded node u and
         init
 2: Mark s  as open.                                  then node v, and following their expansion, their value has
              init
 3: SOLVE(S0,s   ).                                   changed. In standard AO*, following the change in value in u
                                         init
 4: Return the greedy solution graph starting at s .  we would propagate this information upwards along marked
                                                      edges. Then, we would repeat the process for v.However,
           Algorithm 4: Hierarchical AO*.             it is quite possible that u and v have common ancestors, and
                                                      thus we will update these ancestors twice. Sometimes, such
                                                      an update is important because it inﬂuences our choice of
i.e., denoting the optimal choice in that state.
                                                      which node to expand. Sometimes, such an update can be
  In most cases, the most expensive parts of AO* are: (1) delayed, and we can save the repeated update of shared an-
the update stage, where we propagate value changes up the cestors. HiAO* tries to exploit the second case, assuming it
explicit graph (Alg. 3); (2) the computation of the fringe,that happens more often than the ﬁrst case.
is, the set of open nodes in the greedy graph (line 2 of Alg. 1). The general scheme we propose for delaying updates is as
We show below how a partition of the states expanded by
                                                      follows. We associate to each subset Si a set of nodes to up-
AO* may be exploited to accelerate these two operations.
                                                      date Zi similar to the set Z used in Alg. 3. At any particular
                                                      point, the algorithm has a single subset of nodes in focus and
2.2  The HiAO* Algorithm                              performs the standard AO* operations only inside of that sub-
                                                      set. Whenever a state s ∈Si is expanded and thus needs to be
We now assume that the state space S is partitioned into sub-               Z
    S ,...,S                                          evaluated, we insert it into i and enter a loop that will prop-
sets 0      k. Furthermore, we assume that these subsets agate its value up into the graph by emptying and re-ﬁlling
are organized in a hierarchy in the form of a tree,3 so that: Z
                 sinit                                the set i, as in standard AO* (Alg. 3). However, each time
(1) the starting state belongs to the root subset denoted that a new value needs to be propagated to a state s belong-
S0
  ; (2) state transitions are possible only between states in the ing to another subset Sj , j  = i (Sj is necessarily the parent
same subsets, or between two states belonging to two subsets          
                                                      or a child of Si), s is added to Zj and not to Zi (line 18 of
one being the parent of the other. These choices are motivated Alg. 6), and so, it is excluded from the loop that works only
by the hierarchical MDP framework presented above, where with Zi. So, the propagation is limited to the subset Si,and
a child subset represents a subprocess that can be called from nodes that would need to be updated but belong to another
the current subset/process (therefore, we sometime use the subset Sj are just stored in Zj, but they are not re-evaluated
term “subprocess” to designate a child subset). However, our yet and their new value is not propagated yet.
formalism is general and can be applied to any instantiation
                                                        So, when are the nodes in Sj, j  = i updated? The an-
of AO* where a hierarchy of nodes can be deﬁned.
                                                      swer depends on the hierarchical relation between Sj on Si.
  The HiAO* algorithm is presented in Alg. 4 - 6. The al- If Sj is the parent of Si, then the states that have been put in
gorithm also uses the same function EXPAND() as standard Zj during the solution of Si are updated when the algorithm
AO* (Alg. 2). The basic principle of this algorithm is the fol- moves focus from Si back to its parent subset Sj.IfSj is
lowing: each time that the optimal action in a state leads to a child of Si, then the states in Zj are updated at the latest pos-
child subset (in other words, each time it appears optimal to sible time, that is, when we want to evaluate a state outside
call a subprocess from the current state), we recursively call of Sj that may lead into Sj under the optimal action. This
the HiAO* algorithm to solve this child subset completely may never happen if calling subprocess Sj is the optimal de-
before continuing solution of the current level. We explain cision in none of the states visited by the algorithm later on,
below how this simple mechanism may beneﬁt the algorithm. in which case we save all the work of updating states in Sj.
                                                      In practice, this is implemented through the use of outdated
  3The algorithm can be generalized to handle hierarchies repre- markers, as explained below.
sented by a directed acyclic graph.                     One of the basic principle of the HiAO* algorithm is that,

                                                IJCAI-07
                                                  2545 1: Zi := Zi ∪{s}.                                    deleted (line 8 of Alg. 6), but the markers of all other entry
                                                                   4
 2: while Zi  = ∅ do                                  nodes are kept. If we later get to update another state outside
                                                                            
 3:  Remove from Zi a state s such that no descendent of of Sj and that can lead to s ∈Sj, then the outdated marker
                                                                                           
     s in G occurs in Zi.                             of s will indicate that the greedy graph below s in Sj needs
                                                                                                   Z
 4:  Set V(s ):=maxa∈A                             to be updated, even if no new node has been added to j in
                                     
            s∈G T (s ,a,s )(R(s ,a,s )+V (s )) ,    the mean time.
     call a∗(s) the optimal action in s,andmarkthe
     associated connector as optimal.                 Convergence:  As long as the problem contains no loop, Hi-
                    ∗      
 5:  while executing a (s ) in s may lead to states that are erarchical AO* is guaranteed to terminate in ﬁnite time and
     not in Si and that are marked as outdated do     to return the optimal solution:
 6:    for each child Sj of Si do
                                   ∗            Theorem 1  If the heuristic H is admissible, then HiAO* re-
 7:       for each s ∈Sj such that T (s ,a (s ),s ) > 0
                                                    turns the optimal policy in ﬁnite time.
          and s is marked as outdated do
                    
 8:         Unmark s as outdated.                     HiAO* may not always be efﬁcient, particularly if the number
 9:         HIERARCHICALUPDATE(Sj   , NULL).          of connections between subsets is large. However, we claim
                      
10:         SOLVE(Sj,s ).                             that, in the case of oversubscription planning, the state par-
              
11:    Set V(s ):=maxa∈A                           tition induced by the hierarchy is efﬁcient and allows lever-
                                       
              s∈G T (s ,a,s )(R(s ,a,s )+V (s )) ,  aging the general principle presented above. The simulation
       call a∗(s) the optimal action in s,andmarkthe results presented in this paper support this claim.
       associated connector as optimal.                 We now present two acceleration techniques that can be
           
12:  if V (s ) decreased at previous step (it cannot increase) implemented in HiAO* to get further leverage from the hier-
     then                                             archy, but are not used in the pseudo-code of Alg. 4 - 6.
                                     
13:    for each state s that is a parent of s along a con-
       nector marked as optimal do
                                                    Optimizing the algorithm:  The HiAO* algorithm pre-
14:       if s ∈Si then                               sented above exhibits the following inefﬁciency. If an ac-
                                                                           
15:         Add s to Zi.                              tion a leading to a state s ∈Sj appears optimal in state
16:       else                                        s ∈Si  (i  = j), then the algorithm will SOLVE completely
                                                                               
17:         Call Sj , j  = i, the subset containing s .             Sj          s                      s
                                                    the sub-problem  starting in before returning to state .
18:         Add s to Zj.                              In the process of solving Sj , the Q-value of action a in s
19:         if Sj is a child of Si then               may only decrease, so that it may happen that, before we are
                   s                     S
20:           Mark   , and all its predecessors in j along done solving Sj, a does not appear as optimal in s anymore.
              connectors marked as optimal,asoutdated. The algorithm presented above will not detect this and single-
                                                                             Sj
  Algorithm 6: Function HIERARCHICALUPDATE(Si,s).     mindedly continue solving until the greedy policy starting
                                                      in s is known, which can be highly inefﬁcient.
                                                        This issue can easily be addressed under an additional hy-
                                                      pothesis that is satisﬁed in the hierarchical planning context
when we are done updating a node in Si that can possibly
            s              S  j  = i                  described above and that could easily be relaxed to deal with
lead to a node in a child subset j ( ) under the optimal a more general case. We assume that each action either does
action, then we must know with accuracy the set of optimal not change the partition subset (in the case of hierarchical
decisions that leads from s either to terminal states, or back                                   a ∈  A
    S            S                                    planning, this holds true for all primitive actions ),
into i. A node of j is marked as outdated if the greedy or it leads with certainty to a single state belonging to a dif-
subgraph starting at that node has a chance of not being ac-
                                                      ferent subset (this is the case of control passing actions μi
curate or complete. Suppose that the algorithm is currently and Abort). Then, we can modify the algorithm by adding
working in subset Si and needs to propagate a new value to               τ                   (S,s)
      s                  S     S                      a threshold parameter to the function SOLVE  so that,
a state belonging to a child j of i. Then, as explained when the value of s falls below τ during the solution of S,the
above, the update of s is delayed and s is just added to Zj
                                     S         s      function exits. In the initial call to SOLVE (line 3 of Alg. 4),
(line 18 of Alg. 6). In addition, all nodes of j “above” in the threshold parameter is set to −∞, so that optimization
the greedy graph are marked as outdated (line 19 and 20 of will be pursued until its end. Later calls (line 10 of Alg. 6) are
Alg. 6). Later, if we want to evaluate a node outside of Sj that
              s ∈S             s                    performed in the following way: while computing the value
can lead to a state j ,thevalueof may not be accurate, of a state (lines 4 and 11 of Alg. 6), we record the Q-value
because we have delayed propagation of new values in Sj.If
                 s                                   of the best action that does not change the partition subset
this is the case, then must be marked as outdated and, con- (primitive action), the Q-value of the best action that induce
sequently, two operations are performed: (1) we purge the set
Z                        S                            a change of subset (control-passing action), and the Q-value
 j and update all the nodes in j that need to be re-evaluated of the second best control-passing action. If a control-passing
using a recursive call to HIERARCHICALUPDATE() (line 9 of action appears optimal and we enter the loop in lines 5 to 11,
Alg. 6). This may change the greedy policy in Sj below some
                                    
of the entry nodes of Sj , including node s ; (2) the greedy 4
                                                        A straightforward improvement to the algorithm is to delete the
graph starting at s in Sj is updated through a call to SOLVE() outdated marker in all nodes of Sj belonging to the greedy graph
                                                              
(line 10 of Alg. 6). So, the outdated marker in s may be starting in s after recomputing this graph.

                                                IJCAI-07
                                                  2546