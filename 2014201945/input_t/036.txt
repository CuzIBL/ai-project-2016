                 A Fast and Simple Algorithm for Bounds Consistency of the 
                                            AllDifferent Constraint 

             Alejandro Lopez-Ortiz1, Claude-Guy Quimper1, John Tromp2, Peter van Beek1 
                        1 School of Computer Science 2C WI 
                            University of Waterloo P.O. Box 94079, 1090 GB 
                               Waterloo, Canada Amsterdam, Netherlands 


                        Abstract                                 Several constraint propagation algorithms for the alldiffer•
                                                               ent constraint have been developed, ranging from weaker to 
     In constraint programming one models a problem 
                                                               stronger forms of local consistency (see [van Hoeve, 2001] 
     by stating constraints on acceptable solutions. The 
                                                               for an excellent survey). Regin [1994] gives an 0(n2,5) algo•
     constraint model is then usually solved by inter•
                                                               rithm for domain consistency of the alldifferent constraint, 
     leaving backtracking search and constraint propa•
                                                               where n is the number of variables, that is based on re•
     gation. Previous studies have demonstrated that de•
                                                               lating alldifferent constraints to matchings. Leconte [1996] 
     signing special purpose constraint propagators for 
                                                               gives an 0(n2) algorithm for range consistency, a weaker 
     commonly occurring constraints can significantly          form of consistency than domain consistency, that is based 
     improve the efficiency of a constraint programming        on identifying Hall intervals. Puget [1998], building upon 
     approach. In this paper we present a fast, simple         the work of Leconte [1996], gives an O(n logn) algorithm 
     algorithm for bounds consistency propagation of           for bounds consistency, which is in turn a weaker form of lo•
     the alldifferent constraint. The algorithm has the        cal consistency than range consistency. Mehlhorn and Thiel 
     same worst case behavior as the previous best algo•       [2000], building upon the work of Regin, give an algorithm 
     rithm but is much faster in practice. Using a variety     for bounds consistency that is 0(n) plus the time needed to 
     of benchmark and random problems, we show that            sort the bounds of the domains, and thus has the same worst-
     our algorithm outperforms existing bounds consis•         case behavior as Puget's algorithm in the general case. 
     tency algorithms and also outperforms—on prob•
                                                                 In this paper we present a fast and simple algorithm for 
     lems with an easily identifiable property—state-of-
                                                               bounds consistency propagation of the alldifferent constraint. 
     the-art commercial implementations of propagators         The algorithm has the same worst case behavior as the previ•
     for stronger forms of local consistency.                  ous best algorithm but is much faster in practice. Using a vari•
                                                               ety of benchmark and random problems, we show that our al•
 1 Introduction                                                gorithm outperforms existing bounds consistency algorithms 
                                                               and also outperforms—on problems with an easily identifi•
Many interesting problems can be modeled and solved us•
                                                               able property—state-of-the-art commercial implementations 
ing constraint programming. In this approach one models a 
                                                               of propagators for stronger forms of local consistency. 
problem by stating constraints on acceptable solutions, where 
                                                                 A longer version of the paper containing proofs and addi•
a constraint is simply a relation among several unknowns or 
                                                               tional experimentation is available [Lopez-Ortiz et al., 2003]. 
variables, each taking a value in a given domain. The con•
straint model is then usually solved by interleaving backtrack•
ing search and constraint propagation. In constraint propaga•  2 Background 
tion the constraints are used to reduce the domains of the vari• A constraint satisfaction problem (CSP) consists of a set of n 
ables by ensuring that the values in their domains are locally variables, a finite domain dom of possible 

consistent with the constraints.                               values for each variable xi{ and a collection of m constraints, 
   Previous studies have demonstrated that designing special                 . Each constraint C is a constraint over some 
purpose constraint propagators for commonly occurring con•     set of variables, denoted by vars{C), that specifies the al•
straints can significantly improve the efficiency of a con•    lowed combinations of values for the variables in vars(C). 
straint programming approach (e.g., [Regin, 1994; Stergiou     Given a constraint (7, we use the notation t C to denote a 
and Walsh, 1999]). In this paper we study constraint propaga•  tuple t—an assignment of a value to each of the variables in 
tors for the alldifferent constraint. An alldifferent constraint vars(C)—that satisfies the constraint C. We use the notation 
over a set of variables states that the variables must be pair- t[x] to denote the value assigned to variable x by the tuple 
wise different. The alldifferent constraint is widely used in  t. A solution to a CSP is an assignment of a value to each 
practice and because of its importance is offered as a builtin variable that satisfies all of the constraints. 
constraint in most, if not all, major commercial and research-   We assume in this paper that the domains are totally or•
based constraint systems.                                      dered. The minimum and maximum values in the domain 


CONSTRAINTS                                                                                                          245  dom(x) of a variable x are denoted by min(dom(x)) and         with a' < a causes the same update. Thus, for the purpose of 
 max(dom(x)), and the interval notation [a, b] is used as a    updating lower bounds, it suffices to restrict attention to left-
 shorthand for the set of values {a,a+ 1,...b}.                maximal Hall intervals: those [a, b] for which a is minimal. 
   CSPs are usually solved by interleaving backtracking          Puget's algorithm first sorts the variables in increasing or•
 search and constraint propagation. During the backtracking    der of max;. We assume for convenience that max,- < maxj, 
 search when a variable is assigned a value, constraint prop•  for i < j. The algorithm then processes each of the variables 
 agation ensures that the values in the domains of the unas-   in turn, maintaining a set of counters which count how many 
 signed variables arc "locally consistent" with the constraints. of the variables processed so far have a minimum bound of 
                                                               at least k. More precisely, after processing x,-, the counter 

                                                               cik denotes the cardinality of the set {j < i : minj, > k}. 
                                                               The algorithm stores the counters in a balanced binary tree, 
                                                               allowing updates in 0(log n.) time per variable. 
                                                                 Conceptually, our algorithm is similar to Puget's. The dif•
                                                               ference is in the maintenance of the counters. The key obser•
                                                               vation is that not all counters are relevant. 


   A CSP can be made locally consistent by repeatedly re•
moving unsupported values from the domains of its variables. 


                                                               Capacity is dominated by in the sense that the former 
                                                               cannot reach 0 before the latter, and if both reach 0, then the 
                                                               Hall interval starting at k:' is not left-maximal. If k is not 
                                                               equal to any min,-, then it is always dominated by the next 
                                                               greater min,, hence we need only remember capacities for 
                                                               which k equals some min,-. The critical set C is the set of 
                                                               such indices of undominated capacities. This set starts out as 
                                                                               and becomes smaller over time as variables 
                                                               are processed and capacities become dominated. We denote 

                                                               by Ci the critical set after processing x,-. The next lemma 
                                                               shows that we can effectively test when each particular ca•
                                                               pacity becomes zero or negative. 


3.1 Finding Hall intervals 
Following Leconte [1996] and Puget [1998], we analyze the 
task in terms of Hall intervals. An interval / is a Hall interval 
if its size equals the number of variables whose domain is 
contained in I. Clearly, any solution must use all the values in 
/ for those variables, making these values unavailable for any 
other variable. Puget shows that an algorithm for updating 
lower bounds can also be used to update upper bounds. The 

lower bound for variable xi- gets updated where mini > b+1, 
whenever a Hall interval [a, b] with a < mini- < b < max,-
is found. This condition implies that any Hall interval [a', b] 


246                                                                                                      CONSTRAINTS This means that differences between adjacent critical capaci•
ties remain constant, except in one place: between capacities 
Vk and vi of the ZeroTest Lemma, where the difference is re•
duced by 1. Therefore, testing for a zero or negative capacity 
need only be done at this vk. Our linked list data structure is 
designed to perform this operation efficiently. All dominated 
indices form forests pointing toward the next critical index. A 
dummy index at the end, which never becomes dominated (3 
larger than the largest max suffices), ensures that every dom•
inated index has a critical one to point to. When a difference 
in capacity, say between indices k\ < k2, is reduced from 1 
to 0, k2 becomes dominated. It must then point to the next 
critical index, say k3, which instead of pointing to k2 must 
now point to A: 1. 


                                                              while nb holds the number of unique bounds. The algorithm 
                                                              uses the following arrays: 
                                                                 • maxsorted [o . . n-1] : holds intervals sorted by max. 
                                                                 • bounds [0 . .nb+l]: sorted array of ruin's and max's. 
                                                                 • t [0 . .nb+l]: holds the critical capacity pointers; that 
                                                                   is, t [i] points to the predecessor of/ in the bounds list. 
                                                                 • d [0 . .nb+l] holds the differences between critical ca•
                                                                   pacities; i.e., the difference of capacities between inter•
                                                                   val i and its predecessor in t viz. t [i]. 
                                                                 • h[0. .nb+l] holds the Hall interval pointers; i.e., if 
                                                                   h [i] < i then the half-open interval [bounds [h [i] ], 
                                                                   bounds [i]) forms a Hall interval, and otherwise holds 
                                                                   a pointer to the Hall interval it belongs to. This Hall in•
                                                                   terval is represented by a tree, with the root containing 
3.2 Updating bounds                                                the value of its right end. 
Finding Hall intervals is only part of the solution. We also  The algorithm uses two functions for retrieving/updating 
need to efficiently update the bounds. For this we use another pointer information, namely: pathmax(a, x) which fol•
linked list structure, in which indices inside a Hall interval lows the chain x, a [x], a [a [x] ], ..., until it stops increas•
point to the location representing its upper end, while those ing, returning the maximum found and pathset (a, x, y, 
outside of any Hall interval point left toward the next such   z) which sets each of the entries a [x], a [a [x] ] a [w] 
index. We store the list of bounds in a sorted array named    to z, where w is such that a [w] equals y. The values minrank 
bounds. Intervals are hereafter numbered by their order of    and maxrank give the index in array bounds of the min and 
occurrence in this array. The linked list is implemented as   (max-hi) of an interval. 
an array t using indices to the bounds as pointers. The          The algorithm examines each interval in turn, sorted by 
differences between critical capacities appearing above the   their upper bounds. It then updates capacities accordingly, 
arrows in Example 2 are stored in an array d. The algorithm   followed by path compression operations on the underlying 
shown in Figure 1 solves one half of the problem: updating    data structures. At each step we test for failure (a negative 
all lower bounds. Variable n holds the number of intervals,   capacity) or a newly discovered Hall interval (a zero capacity, 


CONSTRAINTS                                                                                                          247  which indicates that the width of the interval is equal to the latter. Consider the right-running chains in array t. Lemma 3 
 number of variables whose domain falls within that interval). shows that all but a logarithmic number of indices see a rise 
                                                               in value as a result of a path compression operation. 
 Example 3 Table 1 shows a trace of the algorithm for updat•
 ing lower bounds (Figure 1) when applied to the CSP from 
 Examples 1 & 2. Each row represents an iteration where a 
 variable is processed. In the first graph the nodes are the el•
 ements of the vector bounds. The arrows illustrate the con•
tent of the vector t and the numbers over them are given by    This implies that a linear number of path compressions take at 
the vector d. The nodes of the second graph are also the val•  most 0(n log n) steps. The situation with array h is similar. 
ues found in vector bounds but the arrows are given by the     It follows then that the algorithm runs in time 0(n log n). 
vector h that keeps track of the Hall intervals.                 The theoretical performance of the algorithm can be im•
                                                               proved further by observing that the union operations are al•
                                                               ways performed over sets whose bounds appear consecutively 
                                                               in a left to right ordering. This is known as the interval union-
                                                              find problem. Gabow and Tarjan [1985] gave a linear time 
                                                               solution in a RAM computer provided that the keys fit in 
                                                               a single word of memory. This is a reasonable assumption 
                                                               in current architectures with 32 or 64 bit words. Using this 
                                                               technique we obtain a linear time algorithm which matches 
                                                               the theoretical performance of Mehlhorn and Thiel's solution. 
                                                               We implemented this algorithm on the Intel x386 architec•
                                                               ture using direct assembly code calls from a C++ program. 
                                                               However, in practice, the 0(n log n) solution outperformed 
                                                               both Mehlhorn and Thiel's algorithm and the algorithm using 
                                                               the interval union find data structure (see [Lopez-Ortiz et al., 
                                                               2003] for additional discussion). 

                                                               4 Experimental results 
                                                               We implemented our new bounds consistency algorithm (de•
                                                               noted hereafter as BC) and Mehlhorn and Thiel's bounds con•
                                                               sistency algorithm (denoted MT) using the 1LOG Solver C++ 
                                                               library, Version 4.2 [ILOG S. A., 1998]1. The ILOG Solver 
                                                               already provides implementations of Leconte's range consis•
                                                               tency algorithm (denoted RC), Regin's domain consistency 
                                                               algorithm (denoted DC), and an algorithm that simply re•
                                                              moves the value of an instantiated variable from the domains 
                                                              of the remaining variables (denoted as VC, for value consis•
                                                              tency). To compare against Puget's bounds consistency algo•
                                                              rithm, we use the runtime results reported by Puget [ 1998] for 
                                                               RC and our own runtime results for RC as calibration points. 
                                                              We believe this is valid as Puget also uses a similar vintage of 
                                                              ILOG Solver and when we compared, we were careful to use 
                                                              the same constraint models and variable orderings. 
                                                                 We compared the algorithms experimentally on various 
                                                              benchmark and random problems. All the experiments were 
                                                              run on a 300 MHz Pentium II with 228 MB of main memory. 
                                                              Each reported runtime is the average of 10 runs except for 
                                                              random problems where 100 runs were performed. 

              Table 1: Trace of the example. 

3.3 Time complexity 
The running time of the algorithm is dominated by the various 
calls to pathmax and pathset. Since each chain followed 
in a pathmax call is also followed in a subsequent path-
set call, we can restrict our analysis to the time spent in the 


248                                                                                                      CONSTRAINTS Figure 1: Time (sec.) to first solution for Pathological prob•
                                                              Table 3: Time (sec.) to optimal solution for instruction 
lems.                                                         scheduling problems. A blank entry means the problem was 
                                                              not solved within a 10 minute time bound. 
BC propagator offers a clear performance improvement over 
propagators for stronger forms of local consistency (see Fig•
ure 1). Comparing against the best previous bounds consis•    main size variable ordering heuristic was used in the search 
tency algorithms, our BC propagator is approx. 2 times faster (see Table 3). On these problem too, our BC propagator offers 
than MT and, using RC as our calibration point to compare     a clear performance improvement over the other propagators. 
against the experimental results reported by Puget [1998], ap•   To systematically study the scaling behavior of the algo•
prox. 5 times faster than Puget's algorithm.                  rithms, we next consider random problems. The problems 
   We next consider the Golomb ruler problem (see [Gent and   consisted of a single alldifferent constraint over n variables 
Walsh, 1999], Problem 6). Following Smith et al. [2000] we 
                                                              and each variable xi had its initial domain set to [a.b], where 
modeled the problem using auxiliary variables (their "ternary a and b, a < 6, were chosen uniformly at random from [1, n]. 
and all-different model") and we used the lexicographic vari• The problems were solved using the lexicographic variable 
able ordering. This appears to be the same model as Puget     ordering. In these "pure" problems nearly all of the run-time 
[1998] uses in his experiments as the number of fails for each is due to the alldifferent propagators, and one can clearly see 
problem and each propagator are the same. Here, our BC        the quadratic behavior of the RC and DC propagators and 
propagator is approximately 1.6 times faster than the next    the nearly linear incremental behavior of the BC propagator 
fastest propagator used in our experiments (see Table 2) and, (see Figure 2). On these problems, VC (not shown) could not 
again using RC as our calibration point, approximately 1.5    solve even the smallest problems {n = 100) within a 10 minute 
times faster than Puget's bounds consistency algorithm.       time bound and MT (also not shown) was 2.5 - 3 times slower 
                                                              than our BC propagator. 
                                                                 Having demonstrated the practicality of our algorithm, 
                                                              we next study the limits of its applicability. Schulte and 
                                                               Stuckey [2001] investigate cases where it can be proven a 
                                                              priori that maintaining bounds consistency during the search, 
                                                              rather than a stronger form of local consistency such as do•
                                                              main consistency, does not increase the size of the search 
 Table 2: Time (sec.) to optimal solution for Golomb rulers.  space. The Golomb ruler problem is one such example. In 
                                                              general, of course, this is not the case and using bounds con•
   We next consider instruction scheduling problems for       sistency can exponentially increase the search space. 
single-issue processors with arbitrary latencies. Instruction    To systematically study the range of applicability of the al•
scheduling is one of the most important steps for improv•     gorithms, we next consider random problems with holes in 
ing the performance of object code produced by a compiler.    the domains of the variables. The problems consisted of a 
Briefly, in the model for these problems there are n variables, single alldifferent constraint over n variables. The domain of 
one for each instruction to be scheduled, latency constraints each variable was set in two steps. First, the initial domain 
of the form xi, < xj + d where d is some small integer value, of the variable was set to [a, 6], where a and b, a < b, were 
a single alldifferent constraint over all n variables, and re• chosen uniformly at random from [1, n]. Second, each of the 
dundant constraints called "distance constraints" In our ex•  values a-|-1,..., b— 1 is removed from the domain with some 
periments, we used fifteen representative hard problems that  given probability p. The resulting problems were then solved 
were taken from the SPEC95 floating point, SPEC2000 float•    using both the lexicographic and the minimum domain size 
ing point and MediaBench benchmarks. The minimum do-          variable ordering heuristics. These problems are trivial for 


CONSTRAINTS                                                                                                          249 