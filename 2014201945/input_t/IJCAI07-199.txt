                           Iterated Weaker-than-Weak Dominance
                     Shih-Fen Cheng                             Michael P. Wellman
            Singapore Management University                    University of Michigan
              School of Information Systems               Computer Science & Engineering
                      80 Stamford Rd                              2260 Hayward St
                     Singapore 178902                     Ann Arbor, MI 48109-2121 USA
                  sfcheng@smu.edu.sg                           wellman@umich.edu

                    Abstract                            Elimination of a dominated strategy for one player may en-
                                                      able new dominance relations for others, as it removes cases
    We introduce a weakening of standard game-        for which the deﬁning inequality must hold. Therefore, we
    theoretic dominance  conditions, called  δ-       generally invoke dominance pruning iteratively, until no fur-
    dominance,  which  enables more   aggressive      ther reduction is possible. This requires some care in the case
    pruning of candidate strategies at the cost of solu- of weak dominance, since the set of surviving strategies is
    tion accuracy. Equilibria of a game obtained by   order dependent, that is, may differ based on the order of
    eliminating a δ-dominated strategy are guaranteed eliminations [Gilboa et al., 1990, Myerson, 1991]. Whether a
    to be approximate equilibria of the original game, strategy is eliminable through some sequence of removals of
    with degree of approximation bounded by the       weakly dominated strategies is a computationally hard prob-
    dominance parameter, δ. We can apply elimination  lem, in general [Conitzer and Sandholm, 2005]. In contrast,
    of δ-dominated strategies iteratively, but the δ for iterated strict dominance is order independent.
    which a strategy may be eliminated depends on       In this paper we investigate a further weakening of weak
    prior eliminations. We discuss implications of this dominance, which enables more aggressive pruning by allow-
    order independence, and propose greedy heuristics ing that the “dominated” strategy actually be superior to the
    for determining a sequence of eliminations to     “dominating” by up to a ﬁxed value δ in some contexts. Such
    reduce the game as far as possible while keeping  δ-dominated strategies may participate in NE of the original
    down costs. A case study analysis of an empirical game, and NE of the pruned game are not necessarily NE of
    2-player game serves to illustrate the technique, the original. However, any NE after pruning does correspond
    and demonstrate the utility of weaker-than-weak   to an approximate NE of the original game.
    dominance pruning.                                  Iterated application of δ-dominance is likewise order de-
                                                      pendent. The order of removals dictates not only eliminabil-
                                                      ity, but also the degree of approximation that can be guaran-
1  Introduction                                       teed for solutions to the reduced game. We explore alternative
                                                      elimination policies, focusing on greedy elimination based on
Analysis of games can often be simpliﬁed by pruning agents’            δ
strategy sets. For instance, a strategy is strictly dominated local assessment of .
iff there exists a mixture (randomization) over the remaining We illustrate the techniques by applying them to a two-
strategies that achieves strictly higher payoff regardless of the player 27-strategy symmetric game derived from simulation
strategies played by other agents. Elimination of strictly dom- data. Our case study demonstrates the potential utility of the
inated strategies is a venerated idea, established at the dawn weaker dominance condition, as it reduces the game substan-
of game theory as a sound way to remove unworthy strate- tially with little loss in solution accuracy.
gies from consideration [Gale et al., 1950, Luce and Raiffa,
1957]. In particular, the dominated strategy cannot be part of 2 Preliminaries
any Nash equilibrium (NE). Moreover, the elimination con- A ﬁnite normal form game is formally expressed as
serves solutions in that any NE of the pruned game is also an [I,{Si}, {ui(s)}],whereI refers to the set of players and
NE of the original.                                   m  = |I| is the number of players. Si is a ﬁnite set of pure
  Weak dominance relaxes strict dominance by allowing that strategies available to player i ∈ I.LetS = S1 ×···×Sm
the dominating strategy achieves payoffs only equally as be the space of joint strategies. Finally, ui : S → R gives the
great. Although weakly dominated strategies may appear in payoff to player i when players jointly play s =(s1,...,sm),
NE of the full game, it remains the case that NE of the pruned with each sj ∈ Sj.
game are NE of the original as well. Additional reﬁnements It is often convenient to refer to a strategy of player i sep-
and variants of dominance are possible, for example based arately from that of the remaining players. To accomodate
on rationalizability, or minimal sets of strategies closed under this, we use s−i to denote the joint strategy of all players
rational behavior [Benisch et al., 2006].             other than i.

                                                IJCAI-07
                                                  1233  Let Σ(R) be the set of all probability distributions (mix- Proposition 2 Let Γ0,...,Γn be a series of games, with Γ0
                                                                           j+1    j   j
tures) over a given set R. A mixture σi ∈ Σ(Si) is called the original game, and Γ =Γ \ t . Further, suppose the
                       i            u  σ                               tj  δ              j        σ
a mixed strategy for player . The payoff i( ) of a mixed eliminated strategy isj-dominated in Γ . Then, if is an
              σ ∈  Σ(S)                                       n              n−1             0
strategy proﬁle,       , is given by the expectation of -NE in Γ ,itisalsoa( j=0 δj + )-NE in Γ .
ui(s) with respect to σ.
  A conﬁguration where all agents play strategies that are The result follows straightforwardly by induction on Propo-
best responses to the others constitutes a Nash equilibrium. sition 1.
                          σ
Deﬁnition 1 A strategy proﬁle constitutes a Nash equilib-             δ
rium (NE) of game [I,{Si}, {ui(s)}] iff for every i ∈ I, 4 Identifying -Dominated Strategies
                         
σi ∈ Σ(Si), ui(σi,σ−i) ≥ ui(σi,σ−i).                  Deﬁnition 4 characterizes the condition for δ-dominance of
We also deﬁne an approximate version.                 a single strategy. It is often expedient to eliminate many
Deﬁnition 2 A strategy proﬁle σ constitutes an -Nash equi- strategies at once, hence we extend the deﬁnition to cover
                                                      δ-dominance of a subset of strategies.
librium (-NE) of game [I,{Si}, {ui(s)}] iff for every i ∈ I,
                             
σi ∈ Σ(Si), ui(σi,σ−i)+ ≥ ui(σi,σ−i).                Deﬁnition 5 The set of strategies T ⊂ Si is δ-dominated iff
                                                                        t ∈ T               σt ∈   S \ T
  In this study we devote particular attention to games that there exists, for each , a mixed strategy i Σ( i )
exhibit symmetry with respect to payoffs.             such that:
                    I,{S }, {u s }                                   t
Deﬁnition 3 A game  [    i    i( ) ] is symmetric iff         δ + ui(σi ,s−i) >ui(t, s−i), ∀s−i ∈ S−i. (2)
∀i, j ∈ I, (a) Si = Sj and (b) ui(si,s−i)=uj(sj,s−j)
whenever si = sj and s−i = s−j
That is, the agents in symmetric games are strategically iden- Propositions 1 and 2 can be straightforwardly generalized to
tical, since all elements of their strategic behavior are the eliminations of subsets of strategies for a particular player.
same.                                                   It is well known that standard dominance criteria can be
                                                      evaluated through linear programming [Myerson, 1991]. The
3  δ-Dominance                                        same is true for δ-dominance, and moreover we can employ
                                                                                       δ
We start by deﬁning our weaker-than-weak dominance con- such programs to identify the minimal for which the dom-
                                                      inance relation holds. The problem below characterizes the
dition.                                                        δ                          T   δ
                   d                                  minimum   such that the set of strategies is -dominated.
Deﬁnition 4 Strategy si ∈ Si is δ-dominated iff there exists
 D           d                                        The problem for dominating a single strategy is a special case.
σi ∈ Σ(Si \{si }) such that:
                                                       min   δ                                        (3)
      δ   u  σD,s    >u   sd,s  , ∀s  ∈ S  .
        +  i( i  −i)    i( i −i)   −i    −i     (1)        ∀ t ∈ T
              d                                         s.t.
In other words, si is δ-dominated if we can ﬁnd a mixed strat- 
                                       d                   δ +      xt(s)ui(s, s−i) >ui(t, s−i), ∀ s−i ∈ S−i
egy (on the set of pure strategies excluding si )that,when
                            d
              δ            s                                  s∈Si\T
compensated by , outperforms i against all pure opponent    
proﬁles. Notice that unlike the standard conditions, in con-     xt(s)=1
                      sd
sidering whether strategy i is dominated, we must exclude  s∈S \T
                                                sd            i
it from the domain of potential dominators. Otherwise, i    ≤ x  s ≤   , ∀ s ∈ S \ T
would be δ-dominated by itself.                            0    t( )  1        i
           d
  Suppose si is δ-dominated in game Γ. As noted above,
          d                                             Problem (3) is not quite linear, due to the strict inequality
if δ>0,  si may well appear with positive probability in in the ﬁrst constraint. We can approximate it with a linear
                                                 d
NE proﬁles. We may nevertheless choose to eliminate si , constraint by introducing a small predeﬁned constant, τ.The
                            d
obtaining a new game Γ =Γ\  si , which is identical to Γ result is the linear program LP-A(S, T ).
                    d
except that Si = Si \{si }, and the payoff functions apply
                                                      min   δ
only on the reduced joint-strategy space. Although Γ does
                                                        s.t. ∀ t ∈ T
not necessarily conserve solutions, we can in fact relate its   
solutions to approximate solutions of Γ.1
                                                           δ +      xt(s)ui(s, s−i) ≥ ui(t, s−i), ∀s−i ∈ S−i
                                           sd    δ
Proposition 1 Let Γ be the original game and let i be -       s∈Si\T
dominated in Γ.Ifσ is an -NE in Γ\sd,thenitisa(δ+)-NE     
                               i                                 x  s ≤   − τ
in Γ.                                                             t( )  1
                                                           s∈S \T
Note that with  =0, the proposition states that exact NE of  i
    d                                                       ≤  x s  ≤  , ∀ s ∈ S \ T
Γ \ si are δ-NE of Γ,whereδ is the compensation needed to  0    t( )  1        i
support dominance.
  We may also eliminate δ-dominated strategies in an itera- 5 Controlling Iterated δ-Dominance
tive manner.                                          By Proposition 1, every time we eliminate a δ-dominated
  1The proofs of Proposition 1 and subsequent results are omitted strategy, we add δ to the potential error in solutions to the
due to space limitations.                             pruned game. In deciding what to eliminate, we are generally

                                                IJCAI-07
                                                  1234interested in obtaining the greatest reduction in size for the Algorithm 1 Simple greedy heuristic. At each iteration, the
least cost in accuracy. We can pose the problem, for example, strategy with least δ is pruned.
as minimizing the total error to achieve a given reduction, or GREEDY(S, Δ)
                                                                  n
maximizing the reduction subject to a given error tolerance. 1: n ← 1,S ← S
  In either case, we can view iterated elimination as operat-
                                                       2: while Δ > 0 do
ing in a state space, where nodes correspond to sets of remain-     n
                                                       3:   for s ∈ Si do
ing strategies, and transitions to elimination of one or more              n
                                                       4:     δ(s) ← LP-A(S  , {s})
strategies. The cost of a transition from node S =(Si,S−i)
                                                       5:   end for
to (Si \ T,S−i) is the δ minimizing LP-A(S, T ). We can for-
                                                       6:   t ← arg mins∈Sn δ(s)
mulate the overall problem as search from the original strat-            i
                                                            d ← δ(t)
egy space. However, the exponential number of nodes and 7:
                                                       8:   if Δ ≥ d then
exponential number of transitions from any given node ren-
                                                       9:     Δ ←  Δ − d
der any straightforward exhaustive approach infeasible.        n+1     n        n+1      n+1
                                                              S    ←  S  \{t},S     ← (S    ,S−i)
  As indicated above, the problem is complicated by the or- 10: i      i                i
                                                              n ← n +1
der dependence of strategy eliminations. Eliminating a strat- 11:
                                                      12:   else
egy from player i generally expands the set of δ-dominated
                                                              Δ ←  0
strategies for the others, though it may shrink its own δ- 13:
                                                      14:   end if
dominated set. We can formalize this as follows. Let δ(t, Γ)
                                                      15: end while
denote the minimum δ such that strategy t is δ-dominated in       n
                                                      16: return S
Γ.2
                 
Proposition 3 Let ti ∈ Si.
                                                       Algorithm 2, GREEDY-K(S, Δ,k), is a simple extension
 1. δ(t, Γ \ ti) ≤ δ(t, Γ) for all t ∈ Sj, j = i, and
                                                      that prunes k strategies in one iteration. We identify the
    δ t, \ t ≥ δ t,       t ∈ S \ t
 2.  ( Γ   i)    ( Γ) for all   i  i.                 k strategies with least δ when considered individually,and
Because eliminating a strategy may decrease the cost of some group them into a set K.WethenemployLP-A(S, K) to de-
future eliminations and increase others, understanding the im- termine the cost incurred for pruning them at once. Since the
plications of a pruning operation apparently requires some set K is selected greedily, it will not necessarily be the largest
lookahead.                                            possible set that can be pruned at this cost, nor the minimum-
  Our choice at each point is what set of strategies to elim- cost set of sizek. Nevertheless, we adopt greedy selection to
                                                               |S |
inate, which includes the question of how many to elim- avoid the i optimizations it would take to consider all the
                                        1                       k
inate at one time. For example, suppose δ(ti , Γ) = δ1, candidates.
      2      1
and δ(ti , Γ \ ti )=δ2. In general, it can be shown that
        1  2
δ2 ≤ δ({ti ,ti }, Γ) ≤ δ1 + δ2. In many instances, the cost 5.2 Computing Tighter Error Bounds
of eliminating both strategies will be far less than the upper
                                                      We can reduce several players’ strategy spaces by running
bound, which is the value that would be obtained by sequen-
                                                      Algorithm 2 sequentially. Let Γ be the original game, and
tially eliminating the singletons. However, since the number                                 
                                                      let Γ be the reduced game. Let {Si} and {Si} be the set
of candidate elimination sets of size k is exponential in k,                             
                                                      of all players’ strategy spaces for Γ and Γ respectively. For
we will typically not be able to evaluate the cost of all such
                                                      each player i,letΔi be the accumulated error actually used
candidates. Instead, we investigate heuristic approaches that
                                                      in GREEDY-K. The total error generated by these reductions,
consider only sets up to a ﬁxed size for elimination in any                               
                                                      according to Proposition 2, is bounded by i Δi.Bytaking
single iteration step.                                                                   
                                                      into account the actual resulting game Γ , however, we can
5.1  Greedy Elimination Algorithms                    directly compute an error bound that is potentially tighter.
                                                        Let N be the set of all NE in Γ. The overall error bound
We propose iterative elimination algorithms that employ
                                                      is the maximum over N of the maximal gain available to any
greedy heuristics for selecting strategies to prune for a given
                                                      player to unilaterally deviating to the original strategy space.
player i. Extending these to consider player choice as well
is straightforward. The algorithms take as input a starting  =maxmax   max [ui(t, σ−i) − ui(σi,σ−i)] , (4)
set of strategies, and an error budget, Δ, placing an upper     σ∈N  i∈I t∈Ti
bound on the cumulative error we will tolerate as a result of        
                                                      where Ti = Si \ Si. To compute  with (4), we must ﬁrst ﬁnd
δ-dominance pruning.                                            
                                                      all NE for Γ . However, computing all NE will generally not
  Algorithm 1, GREEDY(S, Δ), computes δ(ti, Γ) for each
                                                      be feasible. Therefore, we seek a bound that avoids explicit
ti ∈ Si, and eliminates the strategy that is δ-dominated at
                                                      reference to the set N .
minimal δ. The algorithm repeats this process one strategy                   
                                                        Since σ is an NE in Γ ,wehavethatui(σi,σ−i)    ≥
at a time, until such a removal would exceed the cumulative                    
                                                      ui(xi,σ−i),forallxi ∈ Σ(Si). With each i ∈ I, t ∈ Ti,we
error budget.                                                                 t                t
                                                      associate a mixed strategy xi. Replacing σi by xi in (4) can
  2Equivalently, δ(t, Γ) is the solution to LP-A(S, {t}) for S the only increase the error bound. The resulting expression no
strategy space of Γ. We also overload the notation to write δ(T,Γ) longer involves i’s equilibrium strategy. We can further relax
for the analogous function on strategy sets T .       the bound by replacing maximization wrt equilibrium mix-

                                                IJCAI-07
                                                  1235Algorithm 2 Generalized greedy heuristic, with k strategies 5.3 δ-Dominance for Symmetric Games
pruned in each iteration.                             Thus far, we have emphasized the operation of pruning one
GREEDY-K(S, Δ,k)                                      or more strategies from a particular player’s strategy space.
            n
 1: n ← 1,S  ←  S                                     The method of the previous section can improve the bound
 2: while Δ > 0 do                                    by considering all players at once. For the special case of
             n
 3:  for s ∈ Si do                                    symmetric games (Deﬁnition 3), we can directly strengthen
                     n
 4:    δ(s) ← LP-A(S  , {s})                          the pruning operation. Speciﬁcally, when we prune a δ-
 5:  end for                                          dominated strategy for one player, we can at no additional
 6:  K  ←{}                                           cost, prune this strategy from the strategy sets of all players.
 7:  for j =1to k do
                                                      Proposition 4 Let Γ be a symmetric game, and suppose
 8:    tj ← arg mins∈Sn\K δ(s)                                                       
                      i                                      s  δs            Γ     Γ
          ←{   ,t }                                   strategy is -dominated in .Let  be the symmetric game
 9:    K     K   j                                    obtained by removing s from all players in Γ.Ifσ is an -NE
10:  end for                                              
                  n                                   in Γ ,thenitisa(δs + )-NE in Γ.
11:  δK ←  LP-A(S  , K)
12:  if Δ ≥ δK then                                     Based on Proposition 4, we can specialize our greedy elim-
13:    Δ  ← Δ  − δK                                   ination algorithms for the case of symmetric games. For Al-
         n+1     n      n+1      n+1                                                  {t}
14:    Si    ← Si \ K,S     ←  (Si  ,S−i)             gorithm 1, we modify line 10, so that is pruned from all
15:  else                                             players’ strategy spaces within the same iteration. For Algo-
16:    if Δ ≥ t1 then                                 rithm 2, we modify lines 14 and 18 analogously.
17:       Δ ← Δ  − δ(t1)                                When a game is symmetric, symmetric equilibria are guar-
           n+1     n        n+1      n+1
18:       Si   ← Si \{t1},S     ←  (Si  ,S−i)         anteed to exist [Nash, 1951]. As Kreps [1990] argues, such
19:    else                                           equilibria are especially plausible. In our analysis of symmet-
20:       Δ ← 0                                       ric games, therefore, we focus on the symmetric NE.
21:    end if
22:  end if                                           6   Iterative δ-Dominance Elimination: A Case
     n ←  n
23:         +1                                            Study
24: end while
           n
25: return S                                          To illustrate the use of δ-dominance pruning, we apply the
                                                      method to a particular game of interest. On this example,
                                                      we evaluate the greedy heuristics in terms of the tradeoff be-
tures σ−i with maximization wrt any pure opponent strate- tween reduction and accuracy. We also compare the theo-
gies, s−i, yielding                                   retical bounds to actual approximation errors observed in the
                                            
                                        t             reduced games.
   ¯ =maxmax      max   ui(t, s−i) − ui(x ,s−i)
                                       i       (5)
          i∈I t∈Ti s−i∈S
                      −i                                          ↓
                                     t                6.1  The TAC   2 Game
      ≥  max max  max  ui(t, σ−i) − ui(xi,σ−i)
         σ∈N  i∈I t∈Ti                                The subject of our experiment is a 2-player symmetric
      ≥  max max  max [ui(t, σ−i) − ui(σi,σ−i)] = .  game, based on the Trading Agent Competition (TAC) travel-
         σ∈N  i∈I t∈Ti                                shopping game [Wellman et al., 2003]. TAC Travel is actually
According to (5), we can bound  by ¯, which does not refer an 8-player symmetric game, where agents interact through
        N              ¯                             markets to buy and sell travel goods serving their clients.
to the set . We can ﬁnd  by solving the following opti-   ↓
mization problem:                                     TAC  2 is derivative from TAC Travel in several respects:
                                                        •
                                                         TAC travel is a dynamic game with severely incomplete
  min   ¯                                       (6)       and imperfect information, and highly-dimensional inﬁ-
   s.t.                                                                       ↓
                                                         nite strategy sets. TAC 2 restricts agents to a discrete
                           t                              set of strategies, all parametrized versions of the Uni-
     ¯ ≥ ui(t, s−i) −    x (si)ui(si,s−i),
                           i                              versity of Michigan agent, Walverine [Wellman et al.,
                    s ∈S
                     i i                                  2005b]. The restricted game is thus representable in nor-
                                              
                          ∀ i ∈ I,t ∈ Ti,s−i ∈ S          mal form.
                                             −i
            t                                           •               ↓
          xi(si)=1,       ∀ i ∈ I,t ∈ Ti                  Payoffs for TAC 2 are determined empirically through
                                                         Monte Carlo simulation.
      si∈Si
          t                                            • The game is reduced to two players by constraining
     0 ≤ xi(si) ≤ 1,      ∀ i ∈ I,t ∈ Ti,si ∈ Si.
                                                          groups of four agents each to play the same strategy.
Note that this formulation is very similar to LP-A(S, T ),de- This can be viewed as assigning a leader for each group
ﬁned in Section 4. The major difference is that LP-A(S, T ) to select a strategy for all to play. The game among
is deﬁned for a particular player i, whereas (6) considers all leaders is in this case a 2-player game. The transfor-
players at once. We employ this bound in experimental eval- mation from TAC ↓8 to TAC ↓2 is an example of the
uation of our greedy heuristics, in Section 6.            hierarchical reduction technique proposed by Wellman

                                                IJCAI-07
                                                  1236    et al. [2005a] for approximating games with many play- the algorithms may prune strategies in a different order. Sec-
    ers. Note that this form of reduction is orthogonal to ond, the algorithm GREEDY-K computes the bound for each
    the reduction achieved by eliminating strategies through iteration taking into account all k strategies pruned at once.
    dominance analysis.                                 In this instance, in fact the sequence of eliminations is quite
                                                      similar. The ﬁrst four strategies eliminated by GREEDY-1 and
  Although TAC↓2 is a highly simpliﬁed version of the ac-
tual TAC game, Wellman et al. [2005b] argue that analyzing GREEDY-2 are the same, and the next four are the same ex-
such approximations can be useful, in particular for focusing cept for a one-pair order swap. Thus, we can attribute the
on a limited set of candidate strategies to play in the actual difference in apparent cumulative error after eight removals
game. Toward that end, dominance pruning can play a com- (169 versus 78) entirely to the distinction in how they tally
plementary role to other methods of analysis.         error bounds. In general, the elimination orders can differ
                        ↓                             almost arbitrarily, though we might expect them typically to
  The actual instance of TAC 2 we investigate comprises 27                            ↓
strategies (378 distinct strategy proﬁles) for which sufﬁcient be similar. In another instance of TAC 2 (based on an earlier
                                                      snapshot of the database with 26 strategies), we also observed
samples (at least 20 per proﬁle) were collected to estimate           δ
payoffs.                                              that the ﬁrst eight -eliminations differed only in a one-pair
                                                      swap. We have not to date undertaken an empirical study of
6.2  Comparison of Greedy Heuristics                  the comparison.
Since the game is symmetric, we eliminate strategies from A more accurate assessment of the cost of iterated elimi-
all players at once rather than one at a time (see Section 5.3). nation can be obtained by computing the tighter bounds de-
                                                      scribed in Section 5.2, or directly assessing the error. Figure 2
Starting with our 27-strategy TAC↓2 game, we ﬁrst apply iter-
ative elimination of strictly dominated strategies. This prunes presents the data from Figure 1 (axes inverted), along with the
nine strategies, leaving us with an 18-strategy game that can- more precise error measurements.

not be further reduced without incurring potential approxima- 180
tion error. We then applied both GREEDY-1 and GREEDY-2,         Greedy-1
each with a budget of Δ = 200. Figure 1 plots, for each algo- 160 Greedy-2
                                                                Tighter bound
rithm, the cumulative error cost incurred to reach the associ- 140
                                                                Actual epsilon
ated number of remaining strategies. Each elimination oper- 120
ation takes a step down (by the number of strategies pruned)
and across (by the error δ added to the total). Note that the 100
ﬁrst large step down at cost zero corresponds to the initial 80
pruning by strict dominance.
                                                        60
                                                       Error  (bound or actual)

  30                                                    40
                                            Greedy-1
                                            Greedy-2    20

  25                                                     0
                                                           181716151413121110                   987654
                                                                            Strategies Remaining

  20
                                                      Figure 2:  Error bounds derived from GREEDY-1 and
                                                      GREEDY-2, compared to tighter bound estimates as well as
  15                                                  actual errors.
                                                        Tighter bounds reported in Figure 2 are those derived from
  10
 Number  of strategies                                the linear program (6), applied to the respective strategy sets.
                                                      We use the remaining strategy sets based on GREEDY-1 down

   5                                                  to 10 remaining, and the sets for GREEDY-2 thereafter. We
                                                      also determined the actual error for a given reduced strat-
                                                      egy set, by computing all symmetric NE of the reduced game
                                                                                                 3
   0                                                        GAMBIT
     0   20   40  60   80  100 120 140  160 180 200   (using        [McKelvey and McLennan, 1996]), and for
                      Accumulated δ                   each ﬁnding the best deviation to eliminated strategies. The
                                                      maximum of all these is the error for that strategy set.
Figure 1: Number of strategies versus accumulated δ,for As we can see from the ﬁgure, the cumulative error bounds
GREEDY-1 and GREEDY-2.                                reported by the algorithms (based on Proposition 2) are quite

                                                         3In some instances, GAMBIT was unable to solve our reduced
  As the graph apparently indicates, GREEDY-2 reaches any
                                                      games in reasonable time due to numerical difﬁculties. In these
particular reduction level at a cost less than or equal to cases, we tried small random (symmetry-preserving) perturbations
GREEDY-1. With the error tolerance Δ = 200,GREEDY-1   of the game until we were able to solve one for all NE. The er-
prunes the game down to ten strategies, whereas GREEDY-2 rors reported are with respect to the solutions we found, which thus
takes us all the way down to two. However, we must decouple tend to overstate the error due to elimination because they include
two factors behind the difference in measured results. First, an additional source of noise.

                                                IJCAI-07
                                                  1237