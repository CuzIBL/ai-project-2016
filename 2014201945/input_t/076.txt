             Evaluating Classifiers by Means of Test Data with Noisy Labels 

                       Chuck P. Lam                                 David G. Stork 
            Department of Electrical Engineering                Ricoh Innovations, Inc. 
                     Stanford University                    2882 Sand Hill Road, Suite 115 
                    Stanford, CA 94305                       Menlo Park, CA 94025-7022 
                  chucklam@stanford.edu                           stork@rii.ricoh.com 

                     Abstract                          labeled samples by a few orders of magnitude [Nigam et al, 
                                                       2000]. 
    Often the most expensive and time-consuming task 
    in building a pattern recognition system is col­     In order to build up and extend this success in reducing the 
    lecting and accurately labeling training and testing labeling cost, we turn to the problem of reducing the need for 
    data. In this paper, we explore the use of inexpen­ accurately labeled data in the classifier evaluation stage. In 
    sive noisy testing data for evaluating a classifier's fact, most of the experiments for learning with labeled and 
    performance. We assume 1) the (human) labeler      unlabeled data use much more labels for testing than train­
    provides category labels with a known mislabeling  ing [Nigam et al, 2000]. Thus we now need to address the 
    rate and 2) the trained classifier and the labeler are labeling cost for classifier evaluation. 
    statistically independent. We then derive the num­
    ber of "noisy" test samples that arc, on average,    As with many areas of commerce, the general economics 
    equivalent to a single perfectly labeled test sam­ of labeling is such that the higher the quality (accuracy) of la­
    ple for the task of evaluating the classifier's perfor­ beling, the greater the associated cost. This greater cost may 
    mance. For practical and realistic error and misla­ be due to greater expertise of the labeler, or the need for mul­
    beling rates, this number of equivalent test patterns tiple passes of cross-checking, or both. There is thus an addi­
    can be surprisingly low. We also derive an upper   tional cost to "clean" or "truth" those data and labels. In some 
    and lower bound for the true error rate when the   situations, such as marking a text corpus, the labeling task is 
    labeler and the classifier are not independent.    complicated enough that even experts need several passes to 
                                                       reduce labeling errors [Eskin, 2000]. Furthermore, in some 
                                                       application domains, obtaining accurate labels is simply too 
1 Introduction                                         cost prohibitive. For example, for some medical diagnostics, 
                                                       the true disease can only be known with expensive or inva­
The overall construction of a modern classification system sive techniques. Similarly, in remote sensing, one must send 
can be divided into four broad tasks: (1) specifying the clas­ measuring instruments to the ground location to obtain the 
sifier type, (2) collecting data, (3) training the classifier (i.e., "ground truth," and the transportation cost can be astronom­
learning), and (4) evaluating the classifier (i.e., testing) [Duda ical. (It is quite literal for remote sensing of other planets 
et al, 2001]. The second stage, data collection, can further [Smyth, 1997].) For both situations in practice, one must rely 
be divided into two tasks: gathering samples and labeling on the imperfect judgements of experts [Smyth, 1997]. 
them. Recently, the machine learning community has real­
ized that in many practical cases the most expensive part of We propose to lower the labeling cost in classifier evalu­
the whole design process is the labeling of such samples. ation by using cheaper, noisy labels. This paper examines 
For example, there is an enormous number of text docu­ methodologies of estimating the error rate and classifier con­
ments on the internet that can be obtained at very low cost; fusion matrix using test data with noisy labels. We shall see 
however, relatively few of these have been labeled — e.g., that even a slight labeling inaccuracy (say, 1%) can have a 
according to content topic, language, or style — in a con­ significant effect on the error rate estimate when the classi­
sistent way that would facilitate training a classifier. Like­ fier performs well. In addition, when data sets used to be 
wise, there are large databases of recorded speech, handwrit­ small and expensive to collect, it made sense to spend each 
ten digits, and printed characters but these databases, too, additional labeling effort to increase label accuracy on that 
are either not labeled accurately or not labeled at all [Stork, small data set. However, when data sets are large and cheap 
1999]. To reduce the labeling expense, many researchers have to collect, it is no longer obvious how one should spend each 
sought ways to modify training algorithms so as to utilize additional labeling effort. Should one spend it labeling the 
both labeled and unlabeled data [Blum and Mitchell, 1998; unlabeled data, or should one spend it increasing the accuracy 
Nigam et al, 2000]. This approach has shown surprisingly of already labeled data? We present a preliminary analysis to 
encouraging results, in some cases reducing the number of this question. 


LEARNING                                                                                               513  2 Preliminaries and notation 
 Our formulation assumes an object x possessing a true label 
 y € Ω, where is the set of possible states 
 of nature (e.g., category membership) for the object. The ob­
ject is presented to a labeler, who marks it with a label 
 as his guess of y. The situation that is call a labeling 
 error (or a mislabeling). The classifier system, on the other 
 hand, is presented with the feature vector x that represents 
 certain aspects of the object, and the classifier outputs a la­
 bel y(x) G as its guess of y. For notational convenience, 
 we will call the classifier output y, and its dependence on the 
 feature vector x is implicit. The situation that is call a 
 classification error (or a misclassification). 
   The probability of the labeler making mistakes, 
 is called the mislabeling rate. The probability of the classi­ The above derivation assumed that iv vt t other­
 fier's label being different from the labeler's label,        wise the noisy labels are meaningless. In practice, 
 is called the apparent error rate. Our goal is to estimate    is always much less than 1/2. More important is the inde­
Pr[y =y]. , which is called the true error rate. Note that it  pendence assumption that the labeler and the classifier make 
is possible to have a high apparent error rate even with a per­ errors independently, or stated succintly, 
fect classifier (with a true error rate of zero) simply because                     . That is, knowing that the labeler had 
of a high mislabeling rate. That is, the classifier can classify made an error on a pattern does not change the probability 
all test data perfectly, but will often disagree with the test la­ that the classifier would also make an error, and vice versa. 
bels because those labels are incorrect. On the other hand, it Section 6 will deal with some situations in which the indepen­
is also possible to have a zero apparent error rate even with a dence assumption does not hold. In the meantime, we argue 
high true error rate if the classifier and the labeler make the for this idealization and simplification based on the fact that 
same kind of mistakes.                                         human and computer generally classify samples using differ­
   The confusion matrix for the human labeler is defined as    ent methodologies, and thus they may not make similar kinds 
                                                               of mistakes. 

                                                               3.1 Example: Apparent error rate for various true 
                                                                     error rates and mislabeling rates 
                                                               Equation 2 gives us a way to account for noisy labels when 
                                                               calculating the true error rate. A natural question, then, is 
                                                               how important is it to correct for the influence of noisy la­
                                                               bels? Let's consider some classification systems with error 

                                                               rates between 2% and 10%! and testing data sets with 1% to 
                                                               5% incorrect labels. Table 1 shows the apparent error rate for 
                                                               classifiers of different accuracy and testing data of different 
                                                               mislabeling rates. The percentage increase over the true error 
   For many two-class cases where one class has a much         rate is also shown. For example, even when only 1% of the 
higher prior probability, the actual error rate is not a good  testing labels are wrong, a classifier with true error rate of 6% 
measure of classifer usefulness. For example, in detecting     will have an apparent error rate 15% higher (at 6.88%). The 
email spams or network intrusions, the undesirable events      percentage increase is even more dramatic with noisier labels 
are so rare that one can easily get an error rate less than    or more accurate classifiers. A quick rule of thumb is that, 
1% by classifying all events as "desirable." In those situa­   when the labels have relatively few errors, the denominator 
tions, then, one may want to compute the entire confusion      in Eq. 2 is approximately 1.0 and can be ignored. The mis­
matrix or metrics such as precision and recall [Frakes and     labeling rate of the testing labels is then just an 
Baeza-Yates, 1992]. We denote as the "rare" class (e.g.,       additive component to the true error rate. Continuing the pre­
spams or network intrusions). For the classifier, precision    vious example, a 1% mislabeling rate for a classifier with true 
is defined as and recall is defined as                         error rate of 6% makes the apparent error rate approximately 
                    , and analogously for the labeler. Note    7%, when the actual is 6.88%. 
that precision and recall can be derived from the confusion 
matrix and the class prior probabilities.                      4 Noisy labels for estimating true error rate 
                                                               Above we assumed knowledge of the apparent error rate, 
3 Obtaining the true error rate                                            but in practice, we must estimate this rate us­
                                                               ing test data. In this section, we analyze the effects of 
In examining the relationship between true and apparent error 

rates, we make the constraint that we have a two-class prob­      1 Wc note that many classifi ers on the UCI datasets have accuracy 
lem, that is,                                                  within this range [Kaynak and Alpaydin, 2000]. 


514                                                                                                           LEARNING  Table 1: The left sub-columns of the table show the apparent error rates for different true error rates 
 and different mislabeling rates based on Eq. 2. It is assumed that the labeler and the classifier make errors 
 independently. The right sub-columns of the table, with up-arrow signs, show the percentage increase of the apparent error 
 rate over the true error rate (i.e., 


                                                               The variance of the error estimate given perfectly labeled data 
                                                               is Thus, to get the same vari•
                                                               ance, the ratio of noisy labels to perfect labels is 

                                                                                                                      (3) 

                                                               This ratio will help us understand the economic trade-offs be•
                                                               tween using perfect and noisy labels. Collecting perfect la•
                                                               bels (or collecting noisy labels first and cleaning them) is of•
                                                               ten much more expensive than just collecting noisy labels it-
                                                               self. Therefore it may be economically justified to used noisy 
                                                               labels, as long as one does not need too many more of them. 
                                                                 Unfortunately, applying Eq. 3 requires us to know the true 
 Figure 1: The figure shows the number of noisy labels needed  error rate of the classifier, which is exactly what one is trying 
 to achieve the same variance in the true error rate estimate as to estimate. However, we often already have a good idea of a 
 a single perfect label (see Eq. 3). The four plots represent dif• reasonable range for the true error rate. In any case, we exam•
 ferent true error rates. As the mislabeling rate increases, more ine the ratio for a wide range of true error rate and mislabeling 
 noisy labels arj needed to achieve the same confidence. Note  rate, and we found the ratio to fall within a relatively narrow 
 that, in the ranges shown in the figure, when the mislabeling range, as shown in Fig. 1. Even for relatively noisy testing 
 rate is smaller than the true error rate, a single perfect label is data with 10% incorrect labels, unless the classifier is much 
 equivalent to less than four noisy labels.                    more accurate (with true error rate of less than 5%), cleaning 
                                                               the testing data to be perfectly labeled increases its value by 
 such estimates. Assume we have / objects in the test set,     less than a factor of four. In other words, one needs much less 
                                                               than four such noisy labels to achieve the same effect as one 
 each with a feature vector x,, true but unknown label yi, 
 noisy label y,, and classification in. Assume further that    perfect label. Imagine that perfect labels need to be collected 
 tuplesare independent from a domain expert, whereas noisy labels can be collected 
 and identically distributed as The apparent er•               from a non-expert, the high cost of a domain expert can often 
                                                               justify the use of noisy labels. 
ror rate estimate is in which 
     is the indicator function (i.e., I[evcnt] = 1 if event is 4.1 Example: Evaluating with many noisy labels 
true and 0 otherwise). An estimate of the true error rate is 
                                                                     or few reliable labels 
                                                               In many labeling tasks, experts must make multiple passes 
                                                               through samples to ensure accurate labeling [Eskin, 2000]. 
                                                               We now question the wisdom of that policy when the samples 
   It is straightforward to verify that                        are free but labeling cost is a constraint. 
   and , thus the estimates are                                  Consider a hypothetical labeling situation with two label-
unbiased. Intuitively we know that we have less confidence     ers, each paid to look at / samples, and both labelers have an 
when the error estimates are based on test data with noisy     error rate of E. There are two choices in how to use these two 
labels. To formalize this intuition, we examine the variance   labelers. One is to have them look at completely different 
of the true error rate estimate,                               samples, thus in the end we have a testing set of size 2/ and 
                                                               mislabeling rate E. Another choice is to have them look at the 
                                                               exact same samples. Assuming that they make independent 


LEARNING                                                                                                              515                                                               Table 2: Apparent precision recall breakeven points (i.e., 
                                                                                      for different actual classifier preci•
                                                              sion/recall and labeler precision/recall. The prior probabili•
                                                              ties for wI and w2 are 90% and 10% respectively. 

                                                              classifications (e.g., false positives and false negatives) are 
                                                              not equal, we may want to know the full confusion matrix. In 
                                                              addition, in some domains, such as classifying text or spam, 
Figure 2: The figure shows which one of the two labeling 
                                                              the distribution of classes is highly skewed, and the error rate 
policies is optimal for a range of mislabeling rate e and true 
                                                              can be misleadingly low. In those situations, we are more 
classifier error rate, based on Eq. 4. The problem is posed 
                                                              interested in precision and recall statistics, which can be esti•
such that two labelers both have mislabeling rate c and are 
                                                              mated from the confusion matrix. 
paid to label / samples. One policy is that they label different 
                                                                 We define the joint distribution matrix between labeler and 
samples, creating a test set of "21 labels on 2/ samples," with 
                                                              classifier as 
e portion mislabeled. The other policy is that they both label 
the same samples, creating a testing set of "21 labels on / sam•
ples," with portion mislabeled (after various assumptions). 

labeling errors, and optimistically assume that a sample has 
a wrong label only if both labelers err, then we have a test• which can be estimated from data. Note that unlike our anal•
ing set of size / and mislabeling rate Which is the better    ysis of the error rates, it is not necessary to assume two-class 
policy?                                                       problems. 
  Based on the previous discussion, we can have an unbi•         Our goal is to recover the classifer's confusion matrix given 
ased estimate of the true error rate from either testing set. We the labeler's confusion matrix and the joint distribution matrix 
then should prefer one that gives us a lower variance estimate. between labeler and classifier. If we make the independence 
That is, we go with the "2/ labels on 2/ samples" policy if its assumption thatthen we have 
variance is lower than the "21 labels on / samples" policy,   the decomposition We 
                                                              can rewrite the decomposition in matrix form and solve for 
                                                              the classifier's confusion matrix. 

Which, after a little algebra, becomes 

                                                    • (4)                                                            (5) 
An interesting observation is that in the realistic range of e 
                                                              in which is defined to be the column vector of prior prob•
                 the left hand side of Eq. 4 is negative for 
                                                              abilities, 
           which means that one should always choose the 
                                                                When p   is not given, it can be derived. To see this, define 
"2/ labels on / samples" policy for such inaccurate labelers,           y
                                                              the probability vector 
and such high mislabeling rate does occur in practice [Smyth, 
                                                              It is the case thatis a column vec•
1997]. For other cases, we have plotted the policy boundary 
                                                              tor of c 1 's. It is also the case that Combining 
                                                 in Fig. 2.   those two equations we have 
  For fairly accurate labelers Fig. 2 shows                                                                          (6) 
that one should prefer the "2/ labels on 21 samples" policy 
unless the classifier error rate is very low. The hint for practi•
tioners is that time spent cleaning labels is often not as effec• 5.1 Example: Precision/recall breakeven points 
tive as time spent labeling extra samples.                    As mentioned earlier, one benefit of being able to recover 
                                                              the confusion matrix is that one can then work with preci•
5 Obtaining True Confusion Matrix                             sion and recall measures. We analyze the following system to 
In evaluating classification systems, we often need to know   see some effects of noisy labels on those measures. To reduce 
more than just the error rate. When the cost of different mis- the number of variables examined, we only look at precision 


516                                                                                                          LEARNING  recall breakeven points, defined as the points where precision   Separately we derive an upper bound for the true error rate. 
 and recall are equal. They will simply be denoted as preci•

 sion/recall. For a given py, and precision/recall, the confusion 
 matrix is uniquely determined. Table 2 shows the apparent 
precision/recall (i.e., 
     for different actual classifier precision/recall and labeler Note that no assumption is used in deriving the upper bound 
precision/recall. Table 2 assumesalthough the                  (not even limiting to two-class problems). One can easily 
 values are almost exactly the same for both and verify that the bound is exact when the mislabeling rate is zero 
                                                               . The bound is also exact when the apparent error rate is zero, 
                                                               such that the true error rate is equal to the mislabeling rate. 
 6 Bounds on true error rate when the                          Thus with the looser assumption of non-negative dependency, 
     classifier and labeler are not independent                the true error rate is in the range of Pr[ynot=y] ± Pi[y not= y]. 
In deriving the true error rate (Eq. 2), we have made the as•  6.1 Example: Simulation of non-negative 
sumption that the labeler and the classifier make errors in•         dependency between classifier and labeler 
dependently. We argue for this assumption because human        In the above derivation, the lower bound is achieved ex•
and computer use different methodologies to classify sam•      actly when the mislabeling rate is small and the indepen•
ples. Even for algorithms inspired by human reasoning (e.g.,   dence assumption is true. We examine how tight the upper 
neural networks), they still do not learn human intuition but  bound is by simulation. We have taken pairs of classes from 
they do avoid psychological biases. It is even harder to imag• UCl's Opt-Digit dataset, which is a handwritten digit recog•
ine algorithms based on more abstract models (e.g., support    nition dataset, and trained both a naive Bayes classifier and a 
vector machine) to err in similar ways as humans. Further•     nearest-neighbor classifier [Duda et ai, 2001] on the training 
more, in many application domains (e.g., speech recognition),  set of each pair. The nearest-neighbor classifier is then used 
humans label the samples based on a full presentation of the   to simulate a labeler and labeled the testing set. The naive 
object, whereas the feature vector x used for classification   Bayes classifier is the classifier under evaluation. Since we 
are mathematical notions (e.g., linear vector coefficients) that have the actual labels for the testing set, both the mislabel•
have little neurological basis. In many other application do•  ing rate (of the nearest-neighbor "labeler") and the true error 
mains (e.g., statistical text classification), assumptions that rate (of the naive Bayes classifier) can be determined. The 
blatantly violate how human reasons are often made (e.g., as•  output of the naive Bayes classifier and the nearest-neighbor 
sume words in a text are independently generated, rather than  "labeler"are compared to determine the apparent error rate. 
in a grammatical way). Lastly, to make a stronger argument,      We have chosen the Opt-Digit dataset and the nearest-
we can require the training data to be labeled independently   neighbor algorithm because we know that this combination 
from the testing data (or better yet, be perfectly labeled), thus can give very low error rate [Kaynak and Alpaydin, 2000], 
avoiding the possibility that the computer would learn biases  thus closely matching the accuracy of many human labelers. 
and other "bad habits" from the training data that would cor•  In fact, for most pairs of classes, the nearest-neighbor algo•
relate with labeling errors in the testing data.               rithm has zero error. The Opt-Digit dataset is also interesting 
   However, even with the above reasoning for the indepen•     because the handwritten digit recognition task is a classical 
dence assumption, it is still conceivable for one to be more   example in which much human labeling effort has been ap•
conservative and assume some non-negative dependency,          plied. The naive Bayes classifier is chosen because it is a 
                                                               popular classifier and is sufficiently different from nearest-
That is, the probability of a classifier misclassifying a sample neighbor to give interesting results. 
is higher if the labeler has also mislabeled that sample , and   Table 3 shows the results for some pairs of classes where 
vice versa. This can happen, for example, if the training data the nearest-neighbor "labeler" has non-zero error. Note that 
have been mislabeled in the same way as the testing data, and  an insignificant positive dependence between the naive Bayes 
the classifier has learned to imitate those mislabelings. We   classifier and the nearest-neighbor "labeler" should be ex•
have deliberately ignored the case of negative dependency,     pected since they both are trained from the same dataset, use 
                                          , as we are hard-    the same features, and assume independence of those features 
pressed to find a justification for it in practice.            (explicitly in naive Bayes and implicitly in nearest-neighbor 
   The non-negative dependency assumption is easily incor•     through its distance metric), even though they are different in 
porated into Eq. 1 by changing the equal sign to a less-than-  other aspects (e.g., naive Bayes is generative while nearest-
or-equal-to sign. Propagating that change through the deriva•  neighbor classifier is discriminative). The naive Bayes classi•
tion, we have a lower bound on the true error rate,            fier's true error rate is almost exactly the upper bound for the 
                                                               pairs (1,2) and (4,5), but it is much closer to the apparent error 
                                                               rate for the pairs (7,8) and (8,9). The simulation thus shows 
                                                               the upper bound to be tight in some non-trivial situations. 

The second inequality can be tight if the mislabeling rate is  7 Discussion and Future Work 
small, as the denominator of the first inequality becomes ap•  When designing classification systems there are frequently 
proximately one.                                               parameters that are not learned automatically from the train-


LEARNING                                                                                                              517 