                                                                                             ∗
           Capturing     and  Reusing    Case-Based      Context    for Image    Retrieval
                              1                    1                     1                     2
         Dympna   O’Sullivan   , Eoin McLoughlin    , Michela Bertolotto   & David  C. Wilson
                                       1University College Dublin
                                       Belﬁeld, Dublin  4, Ireland
                               2University of North Carolina  at Charlotte
                                    Charlotte, NC  28223-0001  USA
       dymphna.osullivan@ucd.ie,   eoin.a.mcloughlin, michela.bertolotto.ucd.ie, davils@uncc.edu

                    Abstract                          by automatically constructing a knowledge base of previous
                                                      user experiences. This knowledge base can then be employed
    Like many other application areas, task-based do-
                                                      to improve future context-based query processing. Similar
    mains that employ digital imagery are faced with
                                                      tasks are no longer interpreted as simply a collection of nat-
    the problem of information overload. Modeling
                                                      ural language terms: rather image retrieval requests take into
    the relationship between images and the tasks be-
                                                      account the context of the speciﬁc user domain goals. This
    ing performed is an important step in addressing
                                                      approach allows for a dramatic reduction in both the time
    this problem. We have developed an interactive ap-
                                                      and effort required to carry out new tasks as amassed con-
    proach for the capture and reuse of image context
                                                      textual knowledge is reused in support of the similar tasks.
    information that leverages a measure of a user’s in-
                                                      Furthermore, there are beneﬁts from a knowledge manage-
    tentions with regard to tasks that they address. We
                                                      ment standpoint as contextual knowledge pertaining to par-
    analyze aspects of human-computer interaction in-
                                                      ticular tasks may now be stored and reused as an additional
    formation that enables us to infer why image con-
                                                      resource for support, training and preserving organizational
    tents are important in a particular context and how
                                                      knowledge assets.
    speciﬁc images have been used to address particu-
    lar domain goals.
                                                      2   System  Overview
1  Introduction                                       Our system enables a user to search directly for imagery cor-
Recent advances in digital image capture and storage tech- responding to their current task needs. A typical task-based
nologies have increased the problem of information overload query to our image repository may consist of any combi-
in imagery task domains. As a consequence, intelligent ap- nation of speciﬁed metadata, semantic task information and
plication support is needed to help manage imagery tasks. a sketched conﬁguration of image-objects. The user may
The majority of current retrieval techniques search for images search an image database for imagery corresponding to their
based on similarity of appearance, using low-level features current goals or a knowledge base of previous user experi-
such as color and shape or by natural language textual query- ences (called sessions) for other user’s tasks that may bear
ing where similarity is determined by comparing words in resemblance to their own. In either case the imagery/sessions
a query against words in semantic image metadata tags. The are ranked according to a percentage matching score. The
biggest problem arising from these techniques is the so-called user may then interact with the returned information as part
semantic gap [Hollink et al., 2004] — the mismatch between of their task by annotating and highlighting relevant image
the capabilities of the retrieval system and user needs. aspects.
  In order to address this problem we have developed a deci-
sion support system that can integrate information about un- 3 Capturing Case-Based Context
derlying visual data with more high-level concepts provided Our research draws on work in capturing task knowledge with
by users as they complete speciﬁed tasks. Capturing human the ultimate goal of performing more effective image retrieval
expertise and proﬁciency allows us to understand why rele- using annotations [Lieberman and Liu, 2002]. To this end we
vant information was selected and also how it was employed have developed tools for direct image manipulation to assist
                                 [               ]
in the context of a speciﬁc user task Leake et al., 1999 . the user in organizing information about relevant imagery and
From a case-based standpoint our research focuses on case their task to capture important contextual information about
knowledge acquisition and case knowledge reuse, where a speciﬁc user goals. These insights are then distilled into a
case is represented by a complete user task including all sys- form the system may use to perform similarity matching. The
tem interactions in the course of carrying out the task. The ap- tools for direct image manipulation include ﬁlters, transfor-
proach allows us to capture and reuse best practice techniques mation, highlighting, sketching, post-it type and multimedia
  ∗
   The support of the Proof of Concept Fund of Enterprise Ireland annotations. They allow the user to identify regions of inter-
is gratefully acknowledged                            est that can be linked to clariﬁcations and rationale. All con-Figure 1: Capturing User Context through Image Annotation           Figure 2: Session Retrieval

textual knowledge is gathered by the system using implicit this similarity is calculated is described in [O’Sullivan et al.,
analysis so that users are shielded from the burden of knowl- 2004]. The current user can compare their task to previous
edge engineering [Claypool et al., 2001]. We unobtrusively work both to ﬁnd relevant imagery and also to examine the
monitor, interpret and respond to user actions as they interact decisions and rationale involved in addressing the previous
with the imagery via the annotational tools and record this as task. Figure 2 shows the interface for displaying retrieved
user context.                                         sessions.
  Figure 1 shows how a user can make use of the image anno- Each row in the interface represents a similar user ses-
tation tools as part of a geo-spatial image task. The particular sion and is summarized to include the percentage matching
task that this user had in mind was the construction of an air- score, the most similar queries, the most important annota-
port on the outskirts of an urban area. The user has uploaded tions added by the similar user, media buttons to play multi-
some multimedia and textual annotations; these textual an- media annotations and thumbnails of any annotated imagery.
notations are represented by the icons on the image. The The user can reuse these similar sessions in carrying out their
notebook icon replaces the text box where the user has typed task by incorporating all or part of a relevant session into their
comments and prevents the image from becoming cluttered. own task context. Because the task-based retrieval system is
The camera icon replaces the video uploaded by the user, and tightly coupled with the activities that the user is performing,
when clicked on will play back the recording. The dark rec- the system has the capacity to make proactive recommenda-
tangles around the icons are the areas associated with these tions in an unobtrusive manner by monitoring the current task
annotations and are emphasized once the icons are moused context. Information requests, increments in the information
over. The area emphasized by the rectangle surrounding the accessed and annotations provided are no longer taking place
notebook icon represents an undeveloped area outlying a resi- in an isolated environment. Rather they can be grounded in
dential part of the urban region. The user comment states that the context of the activities that the user is performing so the
this is an area of low elevation, away from residential areas system can correspondingly anticipate and update what pre-
and drained naturally by a large river (i.e. suitable to proceed vious knowledge would be relevant, making it available to
with the new development). The user has also highlighted a the user. This knowledge is provided unobtrusively, and need
group of buildings by sketching an oval shape around them only be accessed when required. Thus the process does not
(they may have concerns that these buildings are quite close distract from the task at hand, yet makes relevant knowledge
to the area selected to build the airport). Once the user has available just-in-time.
ﬁnished interacting with the imagery their entire task process
is stored as an encapsulated session case in the knowledge 5 Experimental Evaluation
base.
                                                      The system was originally designed for the retrieval of geo-
                                                      spatial imagery and an earlier evaluation of session retrieval
4  Reusing   Similar User  Context  for Retrieval     indicated that sessions were useful as a basis for task-based
The application allows for the reuse of similar user context for retrieval [O’Sullivan et al., 2004]. In this paper we show that
retrieval. More speciﬁcally, if a user working in a similar task task-based annotation context has advantages for individual
domain to a previous user queries the system, the application image retrieval by employing the application as an aid for
reuses the previously captured context to compute similarity travel planning. We evaluated the system using images from
between the new task and the goals of previous users in or- the Corel Image Dataset [Wang and Li, 2003]. We began by
der to recommend images and user sessions that may be of analyzing a subset of 500 images (corresponding to 5 coun-
help to the current user. A more complete description of how tries - Australia, England, France, Ireland and Thailand) andmanually annotating each of them with four/ﬁve keywords
describing image objects and scenes depicted in the images. Keyword Retrieval V Annotation-Based Retrieval
In order to extract contextual information for each image, the
set of keywords for each image was entered as a query to web 100
                                                           e
                                                           r

sites offering information on holidays in the outlined coun- o 80
                                                           c

tries, for example http://www.visiteurope.com/france.html. S

                                                           g 60
                                                           n
  The resulting web pages were analyzed and the most rele- i
                                                           h

                                                           c 40
vant paragraphs from these pages were applied as annotations t
                                                           a

to the images. These annotations were between 2 and 5 sen- M 20

tences in length. An example of an annotation for a photo- %
                                                             0
graph featuring a part of the English Lake District was ”The
Lake District National Park in the north-west of England is     Tasks(Australia, England, France, Ireland, Thailand)
the largest of Englands National Parks. Its 2,292 square kilo-
                                                                       Keywords Annotations
metres cover high fells, lush green dales, still lakes, vibrant
villages and quiet hamlets”. The purpose of these annotations
was to act a baseline for comparison with task-based queries
relating to holidays in the outlined countries.        Figure 3: Keyword Retrieval V Annotation-Based Retrieval
  In order to demonstrate the task-based retrieval capabilities
of the system, several tasks were outlined relating to holidays
in the countries and user behavior was simulated by anno- ent levels of user, task and annotation contexts. We hope to
tating relevant imagery with task-speciﬁc information. An perform a comprehensive user trial in the near future. We
example of a task description for a holiday in England was plan to extend our implicit knowledge acquisition techniques
”Planning a trip to England, spend a few days in London, by extracting information from a greater variety of user ac-
visit the markets, followed by a few days in the countryside”. tions. We also intend to supplement our primarily text-based
Once the images had been annotated according to this ﬁrst set retrieval system by including multimedia annotational infor-
of tasks another set of tasks corresponding to more speciﬁc mation for retrieval.
types of holidays in the countries were outlined. An example
of such a task for planning a holiday in England was ”Inter- References
ested in an adventure holiday in the English countryside - I
                                                      [Claypool et al., 2001] Mark Claypool, Phong Le, Makoto
am particularly interested in hill-walking and water sports”.
                                                         Waseda, and David Brown. Implicit interest indicators.
The purpose of this was to see if the contextual annotations
                                                         In Proceedings of ACM Intelligent User Interfaces Con-
added to the images for the ﬁrst set of tasks could be re-used
                                                         ference, IUI-01, pages 33–40. ACM Press, 2001.
to ﬁnd imagery relevant to the second set of tasks. The 500
images were then categorized by hand as either relevant or [Hollink et al., 2004] Laura Hollink, Guus Schreiber, Bob
not relevant to each outlined task in the second category of Wielinga, and Marcel Worring. Classiﬁcation of user im-
tasks. Each task was entered as a query to the system and the age descriptions. International Journal of Human Com-
returned images were analyzed. Figure 3 demonstrates the puter Studies, 66(5):601–626, 2004.
average scores associated with the top ﬁve most relevant im- [Leake et al., 1999] David B. Leake, Larry Birnbaum,
ages (as judged by a real user) returned for the task-based Cameron Marlow, and Hao Yang. Task-based knowledge
queries. The left/right columns give the similarity respec- management. In Exploring Synergies of Knowledge Man-
tively for keyword-based retrieval and annotation-based re- agement and Case-Based Reasoning, Proceedings of The
trieval. For the most part the annotation-based retrieval vastly American Association of Artiﬁcial Intelligence (AAAI-99)
outperforms the keyword-based retrieval, demonstrating that Workshop, pages 35–39. AAAI Press, 1999.
task-based annotations can provide useful additional context [Lieberman and Liu, 2002] Henry Lieberman and Hugo Liu.
that can improve image retrieval over a dataset. We plan to
                                                         Adaptive linking between text and photos using common
expand the library both in terms of the number of images and
                                                         sense reasoning. In Proceedings of the 2nd International
in terms of the number of applied task-based queries. This Conference on Adaptive Hypermedia and Adaptive Web
experiment is a starting point for automating the construction
                                                         Based Systems, pages 2–11. Springer-Verlag, 2002.
of datasets from where information can be retrieved based on
current context rather than just on keyword or content-based [O’Sullivan et al., 2004] Dympna O’Sullivan, Eoin
search.                                                  McLoughlin, Michela Bertolotto, and David C. Wil-
                                                         son. A  case-based approach to managing geo-spatial
                                                         imagery tasks. In Proceedings of ECCBR 2004, Seventh
6  Conclusions                                           European Conference on Case-Based Retrieval, pages
We have introduced our approach to developing a context  702–716. Springer-Verlag, 2004.
aware system with a task-based focus for retrieving imagery [Wang and Li, 2003] James Wang and Jia Li. Automatic lin-
and knowledge. Our intention is to use the presented experi- guistic indexing of pictures by a statistical modeling ap-
mental results as a baseline for future evaluation frameworks proach. IEEE Transactions on Pattern Analysis and Ma-
where we will examine the relative contributions of differ- chine Intelligence, 25(9):1075–1088, 2003.