        Instance-based AMN Classiﬁcation              for Improved Object Recognition
                                in 2D and 3D Laser Range Data

        Rudolph Triebel      Richard Schmidt      Oscar´ Mart´ınez Mozos     Wolfram Burgard
                        Department of Computer Science, University of Freiburg
                          Georges-Koehler-Alle 79, 79110 Freiburg, Germany
                    {triebel, rschmidt, omartine, burgard}@informatik.uni-freiburg.de

                    Abstract                          task. They use a technique called associative Markov net-
                                                      works (AMNs), which combines the concept of relational
    In this paper, we present an algorithm to iden-   learning with collective classiﬁcation.
    tify diﬀerent types of objects from 2D and 3D       So far, AMNs have been used only based on the log-linear
    laser range data. Our method is a combination     model, which means that there is only a linear relationship
    of an instance-based feature extraction similar to between the extracted features and the weight parameters
    the Nearest-Neighbor classiﬁer (NN) and a collec- learned by the algorithm. This results in classiﬁcation algo-
    tive classiﬁcation method that utilizes associative rithms that learn hyper-planes in the feature space to separate
    Markov networks (AMNs). Compared to previ-        the object classes. However, in many real-world applications
    ous approaches, we transform the feature vectors  the assumption of the linear separability of the features is of-
    so that they are better separable by linear hyper- ten not justiﬁed. One way to overcome this problem may be
    planes, which are learned by the AMN classi-      to extend the log-linear model, but this is still subject to ongo-
    ﬁer. We present results of extensive experiments  ing research. In this paper, we propose a diﬀerent approach.
    in which we evaluate the performance of our algo- By combining the ideas of instance-based classiﬁcation with
    rithm on several recorded indoor scenes and com-  the AMN approach, we obtain a classiﬁer that is more ro-
    pare it to the standard AMN approach as well as   bust against the error introduced by the linear-separability as-
    the NN classiﬁer. The classiﬁcation rate obtained sumption. We present a way to compute new feature vec-
    with our algorithm substantially exceeds those of tors from a given set of standard features, i.e., we transform
    the AMN and the NN.                               the original features, and show that these features are better
                                                      suited for classiﬁcation using the AMN approach.
                                                        This paper is organized as follows. The next section gives
1  Introduction                                       an overview of the work that has been presented so far in
In this paper, we consider the problem of identifying objects this area. Then we summarize the concepts of collective clas-
in 2D and 3D range measurements. We believe that the seg- siﬁcation using associative Markov networks and describe
mentation of these data into known object classes can be use- shortly how learning and inference is done in AMNs. Then,
fulinmanydiﬀerent areas, such as map registration, robot lo- a detailed description of our approach is presented. Finally,
calization, object manipulation, or human-robot interaction. we present the results of experiments, which illustrate that
For example, a robot that is able to classify the 3D data ac- our method provides better classiﬁcations than previous ap-
quired by a range sensor has a better capability of ﬁnding proaches.
corresponding data points in diﬀerent measurements. In this
way, the scan registration can be carried out more reliably. 2 Related Work
Other application areas, in which object recognition is impor- The problem of recognizing objects from 3D range data has
tant, include seek-and-rescue tasks such as the one aimed by been studied intensively in the past. Most of the approaches
the RoboCup rescue initiative.                        can be distinguished according to the features used. One pop-
  What makes the object detection especially hard is the fact ular approach are spin images [Johnson, 1997; de Alarc´on
that it involves both, the segmentation and the classiﬁcation et al., 2002; Frome et al., 2004], which are rotationally and
of the segments. To simultaneously solve this segmentation translationally invariant local descriptors. Spin images are
and classiﬁcation problem, recently collective classiﬁcation also used as features in the work presented here. Other types
approaches have become a popular approach. They are based of 3D features include local tensors [Mian et al., 2004], shape
on the assumption that in many real-world domains spatial maps [Wu et al., 2004], and multi-scale features [Li and
neighbors in the data tend to have the same labels. For ex- Guskov, 2005].Osadaet al. [2001] proposed a 3D object
ample, Anguelov et al. [2005] formulate the problem of seg- recognition technique based on shape distributions. Whereas
menting 3D range data into known classes as a supervised this approach requires a complete view of the objects, our
learning task and apply collective classiﬁcation to solve the method can deal with partially seen objects. Additionally,

                                                IJCAI-07
                                                  2225Huber et al. [2004] present an approach for parts-based object presented by Anguelov et al. [2005]. The authors propose
recognition. This method provides a better classiﬁcation be- the use of associative Markov networks (AMNs), which are a
cause nearby parts that are easier to identify than others help special type of Relational Markov Random Fields, described
to guide the classiﬁcation. A similar idea of detecting object in Taskar et al.[2002]. In the following we will brieﬂy de-
components has been presented by Ruiz-Correa et al. [2003], scribe AMNs.
who introduced symbolic surface signatures. Another ap-
proach to object recognition proposed by Boykov and Hut- 3.2 Associative Markov Networks
tenlocher [1999] is based on Markov random ﬁelds (MRFs). An associative Markov network is an undirected graph in
They classify objects in camera images by incorporating sta- which the nodes are represented by N random variables
tistical relationships between nearby object parts. A rela-
                                                      y1,...,yN . In our case, these random variables are dis-
tional approach using MRFs has been proposed by Limketkai crete and correspond to the labels of each of the data points
et al. [2005]. The idea here is to exploit the spatial relation-
                                                      p1,...,pN. Each node yi and each edge (yi, y j) in the graph
ship between nearby objects, which in this case consist of 2D
                                                      has an associated non-negative value ϕ(xi, yi)andψ(xij, yi, y j)
line segments. The work that is mostly related to the approach respectively. These are also known as the potentials of the
described in this paper is presented by Anguelov et al. [2005], nodes and edges. The node potentials reﬂect the fact that for
in which an AMN approach is used in a supervised learning
                                                      a given feature vector xi some labels are more likely to be as-
setting to classify 3d range data. In this paper, we combine
                                                      signed to pi than others, whereas the edge potentials encode
this approach with techniques from instance-based classiﬁca- the interactions of the labels of neighboring nodes given the
tion to obtain improved classiﬁcation results.
                                                      edge features xij. Whenever the potential of a node or edge
                                                      is high for a given label (yi)oralabelpair(yi, y j), the con-
3  Range Scan Classiﬁcation                           ditional probability of these labels given the features is also
Suppose we are given a set of N data points p1,...,pN high. The conditional probability that is represented by the
taken from a 2D or 3D scene and a set of K object classes network can be expressed as
  ,...,
C1    CK. A data point in this context may be a 3D scan                N        
point or a 2D grid cell of an occupancy grid. The following          1
                                                            P(y | x) =    ϕ(x , y )  ψ(x , y , y ).   (1)
formulations are identical in these two cases.                       Z       i i        ij i j
                                                                       i=1       (ij)∈E
  For each data point pi, we are also given a feature vector
xi. Later we will describe in detail how the features are de- Here, Z denotes the partition function which by deﬁnition is
                                                                      N                     
ﬁned in the context of this paper. The task is to ﬁnd a label given as Z =  = ϕ(x , y ) ∈ ψ(x , y , y ).
  ∈{,...,   }                            ,...,                     y  i 1   i i   (ij) E ij i  j
yi   1     K  for each pi so that all labels yi yN are  It remains to describe the node and edge potentials ϕ and
optimal given the features. The notion of optimality in this ψ.InTaskaret al.[2004], the potentials are deﬁned using
context depends on the classiﬁcation method we choose. In the log-linear model. In this model, a weight vector wk is
the standard supervised learning approach, we deﬁne a like- introduced for each class label k = 1,...,K. The node po-
lihood function Pω(y | x) of the labels y given the features x. ϕ                   ϕ   ,  =   k ·
                                                      tential is then deﬁned so that log (xi yi) wn xi where
Then, the classiﬁcation problem can be subdivided into two =
                                      ∗               k    yi. Accordingly, the edge potentials are deﬁned as
tasks: ﬁrst we need to ﬁnd good parameters ω for the likeli-            k,l
                                              ∗       log ψ(xij, yi, y j) = we · xi where k = yi and l = y j.Note
hood function Pω(y | x). Then we seek for good labels y that                                       ,
                                                                   ﬀ                   k ∈ Rdn    k l ∈ Rde
maximize this likelihood. Assuming we are given a training that there are di erent weight vectors wn and we
data set, in which the labels yˆ have been assigned by hand, for the nodes and edges.
                                                                                                   ﬀ
we can formulate the classiﬁcation as follows:          For the purpose of convenience we use a slightly di erent
                     ∗                                notation for the potentials, namely
  • learning step: ﬁnd ω = argmaxωPω(yˆ | x)
                     ∗                                                          K
  •                    =          ∗  |
    inference step: ﬁnd y argmaxyPω (y x)                           ϕ  ,    =        k ·  k
                                                                 log (xi yi)      (wn  xi)yi          (2)
3.1  Collective Classiﬁcation                                                   k=1
In most standard classiﬁcation methods, such as Bayes clas-                     K K
                                                                 ψ   , ,    =           k,l · k l ,
siﬁcation, Nearest Neighbor, AdaBoost etc. the classiﬁcation  log (xij yi y j)       (we   xij)yi y j (3)
of a data point only depends on its local features, but not on                  k=1 l=1
the labeling of nearby data points. However, in practice one k
                                                      where yi is an indicator variable which is 1 if point pi has
often observes a statistical dependence of the labelings asso- label k and 0, otherwise.
ciated to neighboring data points. For example, if we con-
                                                        In a further reﬁnement step of our model, we introduce
sider the local planarity of a scan point as a feature, it may       k,l =               k,k ≥
happen that the likelihood P(y | x) of the class label ‘wall’ is the constraints we 0 for k l and we 0.Thisre-
                                                      sults in ψ(x , k, l) = 1fork  l and ψ(x , k, k) = λk ,where
higher than that of the class label ‘door’, although all other  ij                      ij       ij
                                                      λk ≥
scan points in the vicinity of this point belong to the class ij 1. The idea here is that edges between nodes with dif-
‘door’. Methods that use the information of neighboring data ferent labels should be penalized over edges between equally
points are denoted as collective classiﬁcation techniques (see labeled nodes. This last speciﬁcation of AMNs makes it pos-
Chakrabarti and Indyk[1998]). Recently, a collective clas- sible to run the inference step eﬃciently using graph cuts
siﬁcation approach to classify 3D range scan data has been (see [Boykov et al., 1999; Taskar, 2004]).

                                                IJCAI-07
                                                  2226                                                          1.3                      0.5
4  Learning and Inference with AMNs                               training set class 1          class 1
                                                          1.2     training set class 2          class 2
                                                          1.1      test set class 1
                                                                   test set class 2  0.4
In this section, we describe how learning and inference can be  1
carried out with AMNs. First, we reformulate Equation (1) as  0.9
                                                        2
                            |                             0.8                    2  0.3
the conditional probability Pw(y x) where the parameters  0.7
ω are expressed by the weight vectors w = (wn, we). By    0.6
                                                          0.5                      0.2
                                                                                 Feature  t
                                                |      Feature  x
plugging in Equations (2) and (3) we obtain that log Pw(y x)  0.4
                                                          0.3
                                                                                   0.1
equals                                                    0.2
N K               K                                   0.1
                                                          0                         0
        k     k           k,k    k k                       0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1  0  0.1  0.2  0.3
      (w  · xi)y +      (w  · xij)y y − log Zw(x). (4)
        n     i           e      i j                             Feature x1               Feature t1
 i=1 k=1         (ij)∈E k=1
Note that the partition function Z only depends on w and x, Figure 1: Example of the feature transform τ for a two-class
but not on the labels y.                              problem with two features. Left: Training data and test data
                                                      with ground truth labeling. Right: Test data after applying τ.
4.1  Learning
As mentioned above, in a standard supervised learning task Here, we introduced variables yk representing the labels of
                          |                                                      ij
the goal is to maximize Pw(y x). However, the problem two points connected by an edge. The last two inequality
that arises here is that the partition function Z depends on                                  k = k ∧ k
                                                      conditions are a linearization of the constraint yij yi y j.
the weights w. This means that when maximizing log Pw(yˆ |
x), the intractable calculation of Z needs to be done for each In our current implementation, we perform the learning and
w. However, if we instead maximize the margin between the inference step by solving the quadratic and linear program
optimal labeling yˆ and any other labeling y deﬁned by from Equations (6) and (7). The implementation is based on
                                                      the C++ library OOQP [Gertz and Wright, 2003].Asmen-
           log Pω(yˆ | x) − log Pω(y | x),      (5)   tioned above, the inference step can be performed more ef-
the term Zw(x) cancels out and the maximization can be done ﬁciently using graph-cuts. However, in our application, in
eﬃciently. This method is referred to as maximum margin which the data sets were comparably small, the linear pro-
optimization. The details of this formulation are omitted here gram solver turned out to be fast enough.
for the sake of brevity. We only note that the problem is re-
duced to a quadratic program (QP) of the form:        5   Instance-based Extension
       1
   min   w2 + cξ                              (6)   The main drawback of the AMN classiﬁer, which is based
       2                                              on the log-linear model, is that it separates the classes lin-
                 N                                   early. This assumes that the features are separable by hyper-
            + ξ −   α ≥        ≥
    s.t. wXyˆ        i  N;  we   0;                   planes, which is not justiﬁed in all applications. This does
                i=1                                  not hold for instance-based classiﬁers such as the nearest-
       α −      αk −  k · ≥−  k, ∀ ,                  neighbor (NN) classiﬁer. In NN classiﬁcation, a query data
        i        ij wn  xi   yˆi  i k;
           ij, ji∈E                                   point p˜ is assigned to the label that corresponds to the train-
                                                      ing data point p whose features x are closest to the features
       αk + αk −  k ·  ≥  ,αk ,αk ≥  , ∀  ∈  ,
        ij   ji we  xij  0   ij ji  0   ij  E k       x˜ of p˜. In the learning step, the NN classiﬁer simply stores
Here, the variables that are solved for in the QP are the the entire training data set and does not compute a reduced
weights w = (wn, we), a slack variable ξ and additional vari- set of training parameters, which is why it is also called lazy
ables αi, αij and α ji. We refer to Taskar et al.[2004] for de- classiﬁcation.
tails.                                                  The idea now is to combine the advantage of instance-
                                                      based NN classiﬁcation with the AMN approach to obtain a
4.2  Inference                                        collective classiﬁer that is not restricted to the linear separa-
Once the optimal weights w have been calculated, we can bility requirement. This will be presented in the next section.
perform inference on an unlabeled test data set. This is done
by ﬁnding the labels y that maximize log Pw(y | x). As men- 5.1 The Transformed Feature Vector
tioned above, Z does not depend on y so that the maximiza- Suppose we are given a general K-class classiﬁcation prob-
tion in equation (4) can be carried out without considering lem where for each training data point pˆ we are given a fea-
the last term. With the constraints imposed on the variables ture vector xˆ of length L and a labely ˆ ∈{1,...,K}.Now,
 k
yi this leads to a linear program of the form         if we assume that the correct label for a new query feature
                                                                                   ∗
           N  K             K                     vector x˜ corresponds to the labely ˆ of its closest training ex-
                   k ·   k +        k ·   k                  ∗
       max       (wn  xi)yi       (we xij)yij   (7)   ample x in feature space, then the NN algorithm yields the
            i=1 k=1         ij∈E k=1                  optimal classiﬁcation. Of course, this assumption is not valid
                                                                                                 ∗
                        K                            in general, but we can at least say that the labely ˆ will be
            k ≥ , ∀ ,        =  , ∀                   more likely than any other label. As an example, consider the
        s.t. yi 0  i k;    yi  1   i
                        k=1                           two-class problem with two features depicted in the left part
            k ≤  k, k ≤  k, ∀  ∈  ,                   of Fig. 1. The two-dimensional feature space is deﬁned by
           yij  yi yij  y j  ij E  k                  the training data shown as boxes. Now, the true labels of an

                                                IJCAI-07
                                                  2227    (a) Training data (b) Test data (ground truth) (c) NN          (d) AMN             (e) iAMN

                             Figure 2: Results on 2D data of an occupancy grid map.

arbitrary test data set, here shown as triangles, will be related 6 Experimental Results
to the labels of their closest training feature points. In our We performed a series of experiments with 2D and 3D data
example, the probability of the labely ˜ ∈{1, 2} corresponding
                                       N μ ,σ         to compare our instance–based AMN (iAMN) algorithm with
to x˜ is proportional to a Gaussian distribution ( k ) with the NN and the AMN classiﬁer. The results of these experi-
μk = d(x˜, xˆ k)andk ∈{1, 2}. Here, xˆk denotes the training ex-
                                     ·, ·             ments demonstrate that the iAMN outperforms the two other
ample with label k that is closest to x˜ and d( ) the distance algorithms, independent of the features used.
in feature space. The variance σ is set to 0.03.
  From the left side of Fig. 1, we can see that any attempt 6.1 Implementation Details
to separate the classes using hyperplanes (in this case lines)
will lead to severe classiﬁcation errors. However, if we in- To speed up the learning process, we need to represent all
                       τ  RL →  RK                    feature vectors such that the nearest neighbor search in the
troduce a feature transform :      in such a way that                              ﬃ
τ   =     ,  ,...,  ,                                 feature space can be performed e ciently. To this end, we
 (x˜) (d(x˜ xˆ1) d(x˜ xˆ K)), then the transformed features      K  ,...,K
˜ = τ                                                 use kD-trees 1      K to store the training feature vectors
t :  (x˜) are more easily separable by hyperplanes. This is         ,...,                            ﬀ
illustrated on the right side of Fig. 1. The reason for this is of each class C1 CK. This way, the computational e ort
                                                      of the nearest neighbor lookup becomes logarithmic in the
that the NN classiﬁer always chooses the label corresponding
                                                      number of the stored instances.
to the smallest component of ˜t. This means, that the set T
                                                  k     Thus, the training step consists of computing the features
of all transformed feature points t = (t1,...,tK) that will be
assigned the label k can be described by              for the training data, transforming these features according to
                                                      Eq. 8 and assigning the transformed features to the nodes of
T  = { ∈ RK | <  ∧···∧  <    ∧   <    ∧···∧   <  }.
 k   t     tk  t1     tk  tk−1 tk  tk+1     tk tK     the AMN. The edge features of the AMN consist of a constant
As can be seen from this equation, the border of the set Tk scalar value, as described by Anguelov et al. [2005].After
is described by K − 1 hyperplanes passing through the ori- solving the quadratic program we obtain the weight vectors
gin. In the case of our two-class example, the only separating wk. Then, in the inference step, we use the transformed fea-
                                                           τ
hyperplane (line) is described by the equation t1 = t2. tures M(x) of the test data as node features for the AMN.
                                                      Again, the edge features are constant.
5.2  M  Nearest Neighbors
One problem of the NN classiﬁer is that the assignment of Feature Computation Depending on the input data used,
a label to a query point p˜ only depends on the labeling of we computed diﬀerent types of features for the data points.
one instance in the training set, namely the one whose feature In the case of the 2D grid data, each point in the map is rep-
vector is closest to x˜. However, it is possible that the features resented by a set of geometrical features which are extracted
of other training instances are also very close to x˜, although from a laser range scan covering 360o ﬁeld of view. Each
they are labeled diﬀerently. For example, suppose that the
                                           1      2   laser is simulated and centered at each point in the map rep-
distances of x˜ to the two closest training features xˆ and xˆ          [               ]
                                        1     2       resenting a free space Mozos et al., 2005 . Because the num-
are very similar, and the corresponding labelsy ˆ andy ˆ are ber of geometrical features is huge (more than 300) we select
 ﬀ                                     1
di erent, the decision of assigning the labely ˆ to p˜ may be the best ones using the AdaBoost algorithm.
wrong, especially in the presence of noise. Therefore we pro- For the 3D data set we computed spin images [Johnson,
ceed as follows: For the feature vector x˜ that corresponds to p˜ 1997] with a size of 5 × 10 bins. The spherical neighborhood
we compute the M nearest training instances in each of the K for computing the spin images had a radius between 10 and
        ,...,                                  , m
classes C1   CK and the corresponding distances d(x˜ xˆk ) 15cm, depending on the resolution of the input data.
where k = 1,...,K and m = 1,...,M. These are used to
deﬁne the transformed feature vector τM(x˜)as
         τ    =  ...,  , 1 ,..., , M ,...             Data Reduction   When classifying data sets with many
          M (x˜) (  d(x˜ xˆk)  d(x˜ xˆ k ) )(8)points, e.g., 3D scans with over 10, 000 scan points, the time
Experiments show that higher values of M increase the clas- and memory requirements of the AMN classiﬁer grows very
siﬁcation rate, but for large M the improvement is very small. large. In these cases, we perform a data set reduction, again
In our experiments, M = 5 turned out to be a good choice. using kD-trees: after inserting all data points into the tree, we

                                                IJCAI-07
                                                  2228                         (a) Ground truth                             (b) NN


                            (c) AMN                                   (d) iAMN

                        Figure 3: Classiﬁcation results for one scene from the Multi data set

prune the tree at a ﬁxed level λ. All points in the subtrees from the Single set for training, because those were not oc-
below level λ are then merged into one mean point. The spin cluded by other objects. The classiﬁcation was performed on
image features, however, are still computed on the whole data the complete scans.
set to provide a high density in the feature extraction. Fig. 3 shows a typical classiﬁcation result for a scan from
                                                      the Multi test set. We can see that NN assigns wrong labels to
6.2  2D Map Annotation                                diﬀerent points while their neighbors are classiﬁed correctly.
For the 2D classiﬁcation experiment we used an occupancy The AMN results show that areas of points tend to be clas-
grid map of the interior of a building. The map was annotated siﬁed with the same label. However, due to the restriction
with three diﬀerent labels, namely ’corridor’, ’room’ and to linearly separable data, many object parts are misclassi-
’lobby’. Then the map was divided into two non-overlapping ﬁed, especially in complex objects like chairs and fans. The
submaps, one for training and one for testing. Fig. 2(a) shows results obtained with iAMN are better even in these complex
the submap used for training and Fig. 2(b) the ground truth objects, because the transformed feature vectors computed by
for the classiﬁcation. The results obtained with the NN and iAMN are better suited for a classiﬁcation based on separat-
the standard AMN approach are shown in Figs. 2(c) and 2(d), ing hyper-planes. Table 1 shows the resulting classiﬁcation
while Fig 2(e) shows the result of our iAMN algorithm. It can rates. We can see that the iAMN classiﬁer outperforms both
be seen that the iAMN approach gives the best result. The of the others in all three data sets.
classiﬁcation rate of the NN is with 92.2% higher than that of A statistical analysis using a t-student test with a signiﬁ-
the standard AMN, which was 89.8%, but the classiﬁcation cance level of 0.05 is shown in Fig. 5. As can be seen, for
is very noisy. In contrast, the iAMN result is more consistent the Multi set our algorithm performs signiﬁcantly better than
wrt. neighboring data points and has the highest classiﬁcation both the NN and the standard AMN. A detailed analysis of
rate with 95.5%.                                      the classiﬁcation results is depicted in Fig. 4 wchich demon-
                                                      strates that our iAMN yields highly accurate results for all
6.3  3D Scan Point Classiﬁcation                      threedatasets.
Furthermore, we evaluated the classiﬁcation algorithms on
three diﬀerent 3D data sets with an overall number of 38         Data set  NN    AMN    iAMN
scanned scenes. The scans were obtained with a 3D laser             uman
range scanner. The ﬁrst data set is called Human and con-         H        75%   69%     80%
sists of 11 recorded scenes with two humans in varying poses.      Single  81%   72%     89%
The scans were labeled into the four classes ’head’, ’torso’,      Multi   63%   62%     76%
’legs’, and ’arms’. The second data set named Single con-
           ﬀ
sists of 20 di erent 3D scans of the object classes ’chair’, Table 1: Classiﬁcation results for all three data sets
’table’, ’screen’, ’fan’, and ’trash can’. Each scan in the Sin-
gle data set contains just one object of each class, apart from
tables, which may have screens standing on top of them. The
last data set is named Multi and consists of seven scans with 7 Conclusions
multiple objects of the same types as in the Single data set. In this paper we proposed an algorithm that combines as-
  The Human and Single data sets were evaluated using cross sociative Markov networks with an instance-based approach
validation. For the Multi data set we used the object instances similar to the nearest neighbor classiﬁer for identifying ob-

                                                IJCAI-07
                                                  2229