                    Automated Reasoning: Past Story and New Trends* 

                                            Andrei Voronkov 
                                      The University of Manchester 


                     Abstract                          complexity of first-order reasoning and is often compromised 
                                                       in favor of a faster inference mechanism. 
    We overview the development of first-order auto•     However, despite the complexity of theorem proving in 
    mated reasoning systems starting from their early  first-order logic, an impressive progress in the area has been 
    years. Based on the analysis of current and poten• achieved in recent years. This progress is due to several fac•
    tial applications of such systems, we also try to pre• tors: development of theory, implementation techniques, and 
    dict new trends in first-order automated reasoning. experience with applications. Modern theorem provers are 
    Our presentation will be centered around two main  very powerful programs able to find in a few seconds very 
    motives: efficiency and usefulness for existing and complex combinatorial proofs which would require several 
    future potential applications.                     man-month to be solved by mathematicians. Many ideas de•
                                                       veloped in theoretical papers in this area are on their way 
  This paper expresses the views of the author on past, to implementation. There is extensive research on aspects 
present, and future of theorem proving in first-order logic of theorem proving vital for applications, such as proof-
gained during ten years of working on the development, im• checking and interfacing with proof assistants. The next gen•
plementation, and applications of the theorem prover Vam• eration of theorem provers will incorporate some of these 
pire, see [Riazanov and Voronkov, 2002a]. It reflects our re• ideas and become even more powerful tools increasingly used 
cent experience with applications of Vampire in verification, for applications which are currently beyond their reach. 
proof assistants, theorem proving, and semantic Web, as well The aim of this paper is to give a brief overview of first-
as the analysis of future potential applications.      order provers and point out new trends in theorem proving 
                                                       which are likely to be implemented in theorem provers of the 
1 Theorem Proving in First-Order Logic                 next generation. 
                                                         Currently, theorem provers are used in the following way. 
The idea of automatic theorem proving has a long history both The user specifies a problem by giving a set of axioms (a set 
in mathematics and computer science. For a long time, it was of first order formulas or clauses) and a conjecture (again, a 
believed by many that hard theorems in mathematics can be first-order formula or a set of clauses). If the input is given 
proved in a completely automatic way, using the ability of by first-order formulas, the prover should check whether the 
computers to perform fast combinatorial calculations. The conjecture logically follows from the axioms. If the input is 
very first experiments in automated theorem proving have given by a set of clauses, the prover should check whether the 
shown that the purely combinatorial methods of proving first- set of clauses is inconsistent. In either case, for many appli•
order theorems are too week even for proving theorems re• cations it is desirable that the prover output a proof, if the log•
garded as relatively easy by mathematicians.           ical consequence or inconsistency has been established. The 
  Provability in first-order logic is a very hard combinato• proofs should either be human-readable (for example, when 
rial problem. First-order logic is undecidable, which means the provers are used for proving theorems in mathematics), 
that there is no terminating procedure checking provability of or machine-checkable (for example, when provers are used 
formulas. There are decidable classes of first-order formulas as subsystems of proof assistants or verification systems). 
but formulas of these classes do not often arise in applica•
tions. Due to undecidability, very short formulas may turn out 2 Applications 
to be extremely complex, while very long ones rather easy. 
Sometimes first-order provers find proofs consisting of sev• The main application area of theorem provers has been, and 
eral thousand steps in a few seconds, but sometimes it takes continues to be, verification of software and hardware. Full 
hours to find a ten-step proof. The theory of first-order rea• applications of this kind usually cannot be directly repre•
soning is centered around the completeness theorems while in sented in the first-order form, so provers are normally used 
practice completeness is often not an issue due to the intrinsic to prove subgoals generated by other systems, for example 
                                                       VHDL-to-first-order transformation systems or proof assis•
  * Partially supported by a grant from EPSRC.         tants based on higher-order logic or type theories. There are 


INVITED SPEAKERS                                                                                      1607  too many papers on this subject to be mentioned here. Finite-   2. If the empty clause is proved, terminate with success. 
 state model checkers and interactive proof assistants are cur•     If no inference rule is applicable, terminate with failure. 
 rently prevailing in verification, but with the growing com•  The set S is the current search space. However, a simple 
 plexity of hardware first-order logic and its extensions are  implementation of this loop would hardly solve even some of 
 likely to play an increasingly important role.                the problems considered trivial by modern theorem provers 
   Theorem proving in mathematics has been the first appli•    due to the fast growth of the search space. Already in the first 
 cation area for theorem provers. Provers are not very good at paper on resolution [Robinson, 1965J it was noted that some 
 working in structured mathematical theories but they are very clauses can be removed from the search space without losing 
 efficient in fields of mathematics where combinatorial rea•   completeness. 
 soning is required, for example, in algebra. Applications of 
                                                                 More precisely, it has been observed that clauses sub•
 provers in algebra are numerous. The monograph [McCune 
                                                               sumed by other clauses can be removed from the search space 
 and Padmanabhan, 1996] gives an example of how algebra 
                                                               without losing completeness and thus regarded as redundant. 
 can be developed with the help of a theorem prover. 
                                                               Later, several other notions of redundancy were discovered. 
   Symbolic computation and computer algebra systems need      For example, [Brand, 1975] proved that the function reflexiv-
 help from theorem provers, for example, when side condi•      ity inferences and paramodulation into a variable are redun•
tions for applying a simplification rule have to be checked.   dant. Modern theorem provers use many redundancy criteria 
However, these systems are already very complex and either     to prune the search space. These criteria can be divided in 
do not use provers at all or use very primitive ones. Inter•   two categories: redundant inferences and redundant clauses. 
facing theorem provers and symbolic computation systems is     Many useful notions of redundancy are based on simplifica•
becoming an important application of theorem provers.          tion orders introduced in [Knuth and Bendix, 19701. These 
   Knowledge bases play a significant role in the semantic     orders are orders on terms which can be extended to literals 
web project. Some of these knowledge bases use first-order     and clauses. An example of an inference which is redundant 
logic or its simple extensions, see, for example, [IEEE SUO-   due to the orderings restrictions is a paramodulation inference 
KIF project, 2002]. 
   Teaching logic and mathematics is an area where first-
order provers can serve as valuable tools. The first experi•
ments in teaching mathematics using first-order provers are 
reported in [McMath et al., 2001].                             for which In the 1970s-1980s many notions of 
   Other application of first-order provers include retrieval of redundant inferences and clauses were investigated. In the 
software components [Schumann and Fischer, 1997], reason•      1990s a general theory of redundancies was described in 
ing in non-classical logics (e.g., fde Nivelle et al., 2000]), and [Bachmair and Ganzinger, 1994al. Nearly all state-of-the-art 
program synthesis [Stickel et ai, 1994]. First-order theorem   resolution theorem provers are based on this theory. Reso•
provers arc in practice used much more than it is reported in  lution with redundancy is based on the following saturation 
the literature, since many companies and organizations do not  algorithm. 
disclose proprietary use of provers.                             1. Apply all non-redundant inferences to clauses in S, 
                                                                   adding to S those conclusions of these inferences that 
3 Modern Theorem Provers                                           are non-redundant. 
The main currently supported systems are given in Figure 1.     2. If the empty clause is proved, terminate with success. 
Among these systems, Setheo is based on model elimination,         If no inference rule is applicable, terminate with failure. 
while other provers are based on resolution. In the rest of this 3. Remove all clauses that become redundant due to the 
paper we will overview resolution theorem provers only.            addition of these conclusions of inferences. 
   In the early papers, e.g., [Robinson, 1965; Robinson and 
Wos, 1969] resolution is defined as a logical system consist•  In addition to standard inference rules, these algorithms also 
ing of several inference rules operating on clauses, for exam• operate with simplifications. An inference is called a simpli•
ple, resolution and paramodulation:                           fication if it makes at least one clause in 5 redundant. Many 
                                                               modern provers implement an eager search for simplifying 
                                                               inferences, while ordinary generating inferences are applied 
                                                               lazily. 
                                                                 In modern provers inference selection is performed via 
where mgu denotes the most general unifier. Since these rules  clause selection. For this reason saturation algorithms im•
are local, i.e., their applicability is identified only by a small plemented in such provers are called the given clause algo•
number of clauses and the result of a rule application does not 
                                                               rithms. There are two main concretisations of the saturation 
change the previously generated clauses, resolution is imple•
                                                               algorithm based on the clause selection: the Otter algorithm 
mented using saturation algorithms. 
                                                               [Lusk, 1992; McCune, 1994] and the Discount algorithm 
  These algorithms operate on a set of clauses 5, initially the [Denzinger et al, 1997]. These algorithms are described and 
set of input clauses. Roughly speaking, they are based on the  analyzed in more detail in [Riazanov and Voronkov, 2002b]. 
following loop.                                               The simple description of these algorithms given above may 
  1. Apply inferences to clauses in 5, adding to 5 the con•   create an illusion of their simplicity, but in fact, some of these 
     clusions of these inferences.                             algorithms are extremely complex, and problems related to 


1608                                                                                                INVITED SPEAKERS                       prover     affiliation                        references 
                                                 General-purpose provers 
                      Otter      Argonne National Laboratory        IMcCune, 1994J 
                      Setheo     Munich University of Technology    [Moser et al, 1997] 
                      Spass      Max-Planck Institute               [Weidenbach ef al., 1996] 
                      Vampire    University of Manchester           [Riazanov and Voronkov, 2002a] 
                      Gandalf    Tallinn University of Technology   [Tammet, 1997] 
                      SCOTT      Australian National University     [Slaney et al., 1994] 
                      E          Munich University of Technology    lSchulz,2001] 
                      Snark      SRI                                [Stickel et al., 2001] 
                      Bliksem    Max-Planck Institute               [de Nivelle, 2000] 

                                           Figure 1: First-order theorem provers 

                                                               2002a] uses flatterms in constant memory for storing tempo•
                                                               rary clauses, code trees [Voronkov, 1995] for forward sub•
                                                               sumption, code trees with precompiled ordering constraints 
                                                               for forward simplification by unit equalities, perfectly shared 
                                                               terms for storing clauses, shared terms with renaming lists 
                                                               for backward simplification by unit equalities, path index with 
                                                               compiled database joins for backward subsumption and some 
                                                               other indexes. 
                                                                 Serious work with theorem provers requires extensive ex•
                                                               periments. Every simple modification to a prover should be 
                                                               tested both for bugs and for efficiency. A typical experiment 
                                                               with Vampire consists of running it for several hours on over 
                                                               5,000 TPTP problems in a number of modes on a network of 
                                                               around 50 computers. Such experiments require good infras•
                                                               tructure, both software and hardware, to facilitate debugging 
      Figure 2: A Given Clause Algorithm of Vampire            and evaluation, so Vampire is augmented by a number of pro•
                                                               grams intended for performing large-scale experiments. The 
the memory management for these algorithms have not been       necessity of having such programs and interfacing them with 
properly solved. For example, one of the given clause algo•    Vampire adds to the complexity of the system. 
rithms of Vampire is schematically shown in Figure 2 (taken 
from [Riazanov and Voronkov, 2002a]).                          4 History of Development 
   Even proof-search in inference systems with redundancy      Since the early work on automated theorem proving, the area 
creates enormously large such spaces. For example, storing     witnessed an impressive progress. This progress is due to 
10fi clauses is not unusual. Of these clauses 105 can par•     several factors described below: 
ticipate in inferences. Some operations on clauses are very 
expensive if implemented naively. For example, subsumption       1. Development of theory, both of the saturation-based 
on multi-literal clauses is NP-complete and must ideally be         theorem proving with redundancy, see [Bachmair and 
performed between each pair of clauses in the search space.         Ganzinger, 2001; Nieuwenhuis and Rubio, 2001], and 
It is difficult to imagine an implementation able to perform        of the tableau and model elimination proof-search, see 
                                                                    [Hahnle, 2001; Letz and Stenz, 2001; Degtyarev and 
1012 operations in reasonable time. 
   In the state-of-the-art theorem provers all expensive op•        Voronkov, 2001]. 
erations are implemented using term indexing [Graf, 1996;        2. Development of implementation techniques (term index•
Sekar et al, 2001]. The problem of term indexing can be             ing, new algorithms) [Graf, 1996; Sekar et al, 2001; 
formulated abstractly as follows. Given a set L of indexed          Nieuwenhuis et al, 2001]. 
terms or clauses, a binary relation R over terms or clauses 
                                                                 3. Growing experience, including experiments with appli•
(called the retrieval condition) and a term or clause t (called 
                                                                    cations, the development of TPTP [Sutcliffe and Suttner, 
the query term or clause), identify the subset M of L that con•
                                                                    1998], and the annual competitions of theorem provers 
sists of the terms or clauses I such that R(l, t) holds. A typical 
                                                                    CASC [Sutcliffe et al, 2002]. 
retrieval condition used in theorem proving is subsumption: 
retrieve all clauses in L subsumed by t. In order to support   Even a naively implemented theorem prover may be powerful 
rapid retrieval of candidate clauses, we need to process the in• enough to solve many problems collected in the TPTP library 
dexed set into a data structure called the index. Modern the•  or created automatically by proof assistants. However, there 
orem provers maintain several indexes to support expensive     have been a considerable progress in solving difficult prob•
operations. For example, Vampire [Riazanov and Voronkov,       lems. Every ten years enhancements in the theory and im-


INVITED SPEAKERS                                                                                                     1609 plementation techniques resulted in a large number problems The following built-in theories arise in many application 
which could be solved several orders of magnitude faster than and are likely to attract attention in automated reasoning. 
by the previous generations of theorem provers. Provers im•
plemented around 1970 were very inefficient, especially for • AC (the theory of associative and commutative func•
equality reasoning. In 1980 the paramodulation rule has been tions). These axioms occur in axiomatizations very of•
generally adopted and the general architecture of saturation- ten. There are many results related to building-in AC 
based provers understood. By 1990 provers started to use   in theorem provers but implementation techniques, in•
routinely simplification orderings and term indexing. The  cluding term indexing modulo AC, are still in their in•
provers used in 2000 employ the general theory of resolution fancy. Associativity and commutativity were built in the 
with redundancy, and in particular literal selection Junctions. EQP theorem prover [McCune, 1997] with a consider•
The provers of 2010 are likely to benefit from a better clause able success but essentially without term indexing. Term 
selection, built-in theories, and maybe from parallel or con- indexing modulo AC was considered in [Bachmair et al, 
current architectures.                                     1993] but only for a very special case. 
                                                         • Theories of transitive relations and orders [Bachmair 
5 Future Generation Theorem Provers                        and Ganzinger, 1994b]. 
Theorem proving is a very hard problem. The next gener•  • Various first-order theories of arithmetic. 
ation of theorem provers will incorporate new theory, data • Term algebras and other constructor-based structures. 
structures, algorithms, and implementation techniques. Their 
development will be driven by the quest for flexibility and ef• As a first step toward building-in important theories one 
ficiency. Flexibility is required to adapt provers to new appli• can consider creation of libraries of axioms/theorems about 
cations. Efficiency can be reformulated as controlling redun• commonly used data types. An example of such a project 
dancy in large search spaces [Lusk, 1992].             is the Standard Upper Ontology [IEEE SUO-KIF project, 
  It is unreasonable to expect future theorem provers to be 20021. One can also enhance theorem provers by constructs 
much faster on all possible problems. However, if we can for specifying built-in theories, for example, by constraints or 
increase performance of provers by several orders of magni• by additional inference rules. 
tude for a large number of problems coming from applica• Inductively defined types. In many applications of inter•
tions, many of these problems will be routinely solved, thus active proof assistants one has to deal with inductively de•
saving time for application developers. The development of fined types and functions on these types. The proof assis•
next generation provers will require:                  tants such as Isabelle [Paulson, 2002], HOL [Gordon and 
                                                       Melham, 1993], COQ [The Coq Development Team, 2001 ], 
  1. development of new theory, 
                                                       Twelf [Pfenning and Schuermann, 1998] have facilities to de•
  2. addition of new features;                         fine data types and functions inductively. First-order theo•
  3. development of new algorithms and data structures; rem provers have no such facilities. The work on building-in 
                                                       inductively defined types can be developed in the following 
  4. understanding how the theory developed so far can be directions: 
    efficiently implemented on top of the existing architec•
    tures of theorem provers;                            • First-order reasoning on data types given by inductive 
                                                           definitions. 
This development is impossible without considerable imple•
mentation efforts and extensive experiments.             • First-order reasoning on functions defined over such 
  There is a large number of research areas to be pursued in data types. 
automated reasoning in the near future, let me mention some • Limited forms of inductive reasoning. 
of them. 
  Built-in theories. Already in the case of equality the naive Working with large axiomatizations. Very often theo•
addition of equality axioms is too inefficient for solving even rem provers must work with large axiomatizations contain•
very simple problems. Development of superposition-based ing many irrelevant axioms. This is typical for applica•
equality reasoning resulted in an impressive improvement of tions such as reasoning with ontologies, assisting proof assis•
theorem provers. There are important theories other than tants, and verification using hierarchically defined theories. 
equality which arise in many applications. Development of Recognition of irrelevant axioms is one of the most impor•
specialized reasoning methods for these theories will be a tant problems in theorem proving. Many of these axioms 
central problem in theorem proving. This problem is dif• are definitions of relations and functions in various forms. 
ferent from the problem of designing decision procedures Recognition of the most typical definitions and efficient work 
for theories such as Presburger arithmetic because relations with them play a major role in the future provers. The first 
and functions used in these theories could be used together steps in this direction are reported in [Ganzinger et al, 2001; 
with other relations and functions and arbitrary quantifiers. Afshordel et al, 2001; Degtyarev et al, 2002]. 
Procedures for the combination of decision and unification Ontology-based knowledge representation. First-order 
algorithms can be of some help [Nelson and Oppen, 1979; formulations of many applied problems, if not created man•
Shostak, 1984; Baader and Schulz, 1996; RueB and Shankar, ually, often refer to large axiomatizations. This situation is 
2001].                                                 common for knowledge-base reasoning, proof assistants, and 


1610                                                                                    INVITED SPEAKERS theorem proving in mathematics. Using these large axiom-       the naive users who do not know (and usually do not want 
atizations and trying to extract only a small number of rele•  to know) much about theorem proving, theorem provers must 
vant axioms can be a hopeless task. The problem arises of      have a strong auto-mode which will try to select automati•
structuring these large axiomatizations in a such a way that   cally a strategy or strategies best suited for solving the given 
a relevant subset of them could be easily extracted automati•  problem. For more advanced users, there should be options to 
cally and that particular properties of the axiomatization can specify term orderings, literal selection, and clause selection. 
be exploited by provers. For example, provers could use a 
fact that a subset of axioms axiomatize properties of a rela•  References 
tion in terms of other relations. Development of knowledge    [Afshordel et al.,2001] B. Afshordel, T. Hillenbrand, and C. Wei-
representation formalisms suitable for representing large ap•  denbach. First-order atom definitions extended. In R. Nieuwenhuis 
plied theories and adaptation of provers to such formalisms    and A. Voronkov, editors, LPAR 2001. volume 2050 of LNAI, pages 
could become an important problem in automated reasoning.      309-319. Springer Verlag, 2001. 
   Proof checking. Strangely enough, modern theorem           [Appel, 2001] A.W. Appcl. Foundational proof-carrying code. In 
provers are not always good at producing proofs. Some          LICS 2001, pages 247-258, 2001. 
of them print detailed resolution and paramodulation proofs   [Baader and Schulz, 1996] F. Baader and K.U. Schulz. Unification in 
but none gives a proof of the preprocessing steps, such        the union of disjoint equational theories: Combining decision pro•
as skolemisation. Without proof-checking one cannot use        cedures. Journal of Symbolic Computations, 21:211-243, 1996. 
provers in verification and in assisting proof assistants. We [Bachmair and Ganzinger, 1994a] L. Bachmair and H. Ganzinger. 
expect that in the near future proof-checking components       Rewrite-based equational theorem proving with selection and sim•
will be added to all major first-order provers. We conjecture  plification. Journal of Logic and Computation, 4(3):217-247, 1994. 
that the main approaches to proof-checking will be similar to [Bachmair and Ganzinger, 1994b] L. Bachmair and H. Ganzinger. 
those used in proof-carrying code [Necula and Lee, 2000],      Rewrite techniques for transitive relations. In LICS'94. IEEE Com•
so that a proof is built using a number of inference rules,    puter Society Press, 1994. 
and foundational proof-carrying code [Appel, 2001], so that   [Bachmair and Ganzinger, 2001] L. Bachmair and H. Ganzinger. 
a proof will given in a system whose language is rich enough   Resolution theorem proving. In A. Robinson and A. Voronkov, edi•
                                                               tors, Handbook of Automated Reasoning, volume 1, chapter 2, pages 
to prove even the preprocessing steps, such as HOL. 
                                                               19-99. Elsevier Science, 2001. 
   Reasoning with nonstandard quantifiers, such as those 
                                                              [Bachmair et al, 1993] L. Bachmair, T. Chen, and I.V. Ramakrish-
specifying restrictions on the number of elements satisfying 
                                                               nan. Associative-commutative discrimination nets. In M.-C. Gaudel 
a relation, for example, (there exists at most 77). Such       and J.-P. Jouannaud, editors, TAPSOFT'93, volume 668 of LNCS, 
quantifiers are familiar to the description logic community.   pages 61-74. Springer Verlag, 1993. 
One can translate formulas with such quantifiers into first-  [Baumgartner, 2000] P. Baumgartner. FDPLL — a first-order Davis-
order logic with equality but the translation will create for• Putnam-Logemann-Loveland procedure. In D. McAllester, editor, 
mulas of a prohibitive size. It is interesting to develop special CADE-17, volume 1831 of LNA1, pages 200-219. Springer Verlag, 
ways of reasoning with such quantifiers, although this is not  2000. 
an obvious task.                                              [Brand, 1975] D. Brand. Proving theorems with the modification 
   Distributed and other non-standard architectures. It        method. S1AM Journal of Computing, 4:412-430, 1975. 
has been observed that cooperating heterogeneous theorem      Ide Nivelle et al., 2000] H. de Nivelle, R.A. Schmidt, and U. Hus-
provers can perform much better than the mere sum of their     tadt. Resolution-based methods for modal logics. Logic Journal of 
components [MP. Bonacina, 1994; Denzinger and Fuchs,           the IGPL, 8(3):265-292, 2000. 
 19991. However, modern theorem prover architectures are      [de Nivelle, 2000] H. de Nivelle. Bliksem 1.10 User's Manual. MPI 
not suited for cooperative or distributed theorem proving.     fur Informatik, Saarbriicken, 2000. 
   Non-resolution inference system. The recent rapid          [Degtyarev and Voronkov, 2001] A. Degtyarev and A. Voronkov. 
progress of the DPLL-based satisfiability checkers [Zhang      Equality reasoning in sequent-based calculi. In A. Robinson and 
and Malik, 2002] suggests that non-resolution systems could    A. Voronkov, editors, Handbook of Automated Reasoning, volume I, 
                                                               chapter 10, pages 611-706. Elsevier Science, 2001. 
also play a significant role in first-order theorem proving. 
The first implementation of first-order DPLL [Baumgartner,    [Degtyarev etal, 2002] A. Degtyarev, R. Nieuwenhuis, and 
                                                               A. Voronkov. Stratified resolution. Journal of Symbolic Computa•
2000] was not very encouraging, but so were the first imple•
                                                               tions, pages 1-24, 2002. to appear. 
mentations of resolution. To be more generally applicable, 
                                                              [Denzinger and Fuchs, 1999] J. Denzinger and D. Fuchs. Coopera•
non-resolution system musts find an efficient solution to the 
                                                               tion of heterogeneous provers. In T. Dean, editor, Proc. (IJCA1-99), 
problem of built-in theories [Degtyarev and Voronkov, 2001].   volume 1, pages 10-15, 1999. 
   Satisfiability-checking and model building. For many 
                                                              [Denzinger et al., 1997] J. Denzinger, M. Kroncnburg, and 
applications it is desirable to be able to establish satisfiability S. Schulz. DISCOUNT — a distributed and learning equa•
of sets of clauses and build models for satisfiable sets. Sat• tional prover. Journal of Automated Reasoning, 18(2): 189-198, 
isfiability of first-order is conceptually a much harder prob• 1997. 
lem than unsatisfiability. The set of satisfiable formulas is not [Ganzinger et al, 2001] H. Ganzinger, R. Nieuwenhuis, and 
recursively enumerable, which means that there is no semi-     P. Nivcla. The Saturate system. Max-Planck Institute fur Infor•
decision procedure for satisfiability-checking.                matik, 2001. 
  Other features. There are other features required of the   [Gordon and Mclham, 1993] M. Gordon and T. Melham. Introduc•
next generation first-order theorem provers. For example, for  tion to HOL. Cambridge University Press, 1993. 


INVITED SPEAKERS                                                                                                    1611 