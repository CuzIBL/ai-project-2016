       Maximum A Posteriori Path Estimation with Input Trace Perturbation:
         Algorithms and Application to Credible Rating of Human Routines
                     Daniel H. Wilson                            Matthai Philipose
                     Robotics Institute                             Intel Research
                Carnegie Mellon University                            6th Floor
                     5000 Forbes Ave.                            1100 NE 45th Street
                   Pittsburgh PA 15213                            Seattle WA 98115
                   dwilson@cs.cmu.edu                        matthai@cs.washington.edu
                    Abstract                          using the rating. For example, a professor grading anesthesi-
                                                      ology students performing an intubation may want to indicate
    Rating how well a routine activity is performed can what her notion of good performance is. By transparency, we
    be valuable in a variety of domains. Making the rat- mean that the system should be able to justify why it has as-
    ing inexpensive and credible is a key aspect of the signed a particular rating. Ideally, the justiﬁcation should be
    problem. We formalize the problem as MAP esti-    constructive, in that it should suggest how a low-rated perfor-
    mation in HMMs where the incoming trace needs     mance may be altered to obtain a high-rated one.
    repair. We present polynomial time algorithms       Our techniques for rating activity routines are designed to
    for computing minimal repairs with maximal like-  satisfy the above requirements. To lower incremental cost,
    lihood for HMMs, Hidden Semi-Markov Models        we choose a representation that is easily learned: all activi-
    (HSMMs) and a form of HMMs constrained with       ties to be rated in our system are modeled by variants of Hid-
    a fragment of the temporal logic LTL. We present  den Markov Models (HMMs). We intend that these models,
    some results to show the promise of our approach. especially given simple prior information, can be learned eas-
                                                      ily from training examples. More crucially, we formulate the
1  Introduction                                       justiﬁcation for a rating relative to this model generically as
Rating how well a person performs a routine activity is a the set of edits required on the trace generated by the rated ac-
broadly useful capability with many applications: professors tivities; we therefore do not require special identiﬁcation and
train medical students by rating their execution of established modeling of errors and their causes. A fundamental weak-
procedures, caregivers assess the well-being of their wards ness of these models is that they are ﬁrst order, preventing
by rating how well they are able to perform activities of daily them from capturing certain important correlations. We aug-
living, and managers and workﬂow experts identify poorly ment the Markov models with an intuitive constraint formal-
                                                                                               [ ]
performed procedures that cause bottlenecks in a system. Al- ism (a small fragment of the temporal logic LTL 1 ) that al-
though rating routine activity is certainly useful, as conven- lows raters to explicitly state relevant constraints. Given these
tionally done it is also very expensive – each activity perfor- relevant and easy-to-construct models, we formulate rating as
mance requires a dedicated human observer (often an expert). the likelihood of (possibly edited) observation sequences.
Many situations where gauging the performance of routine The core of this paper consists of efﬁcient algorithms to
activities could be helpful are therefore either not rated at all, compute maximum likelihood paths of minimally edited ver-
or rated in a cursory manner. Clearly, an opportunity exists sions of incoming observations with respect to various repre-
for automated techniques to reduce the cost of rating. In this sentations for activities, including HMMs, HSMMs and tem-
paper, we explore methods for automatically rating perfor- porally constrained HMMs. The algorithms use the dynamic
mances of routine activities.                         programming technique used to great effect by the well-
  The basic classiﬁcation task of rating, going from obser- known Viterbi algorithm. A preliminary evaluation shows the
vations to scores, is amenable to a variety of standard ap- promise of our techniques.
proaches. Rating becomes challenging, however, if we wish
to make it both incrementally inexpensive and credible. We 2 Overview
deﬁne an incrementally inexpensive rater to be a rater in In this section, we describe how we expect our system to
which the extra cost of rating a new activity is relatively low. be used, and we sketch how our system supports this usage
The main determinant of cost is whether rating a new activity model. In this paper, our goal is to develop a system that
requires a custom classiﬁer to be developed from scratch, or rates how well an elder performs day-to-day activities. Such
whether a generic classiﬁer of some kind can be easily cus- a system is of great interest to the eldercare industry. In the-
tomized to the task. A credible rater is one that is both rel- ory, caregivers will assess the elders’ well-being by consult-
evant and transparent. By relevant, we mean that the classi- ing ratings summaries and credible explanations of perfor-
ﬁcation model for a particular rating task should reﬂect con- mance deﬁcits. For example, the system may recognize that
straints on activity performance that are important to those an elder is no longer able to prepare their daily bowl of soup,and report why (e.g., can’t reach cabinet or difﬁculty holding Generating a rating and justiﬁcation Given the con-
spoon).                                                   strained model (λ, C) and threshold L, the automated
  To end-users, our system represents activities as a set of rater is ready for use. The person to be rated generates
steps. Each step has a duration and a set of observed actions a trace Y = y1, . . . , ym to be rated automatically. The
                                                                                               ˆ
performed, and is succeeded by other steps. For instance, rater ﬁnds the constrained MAP likelihood lY and path
the activity “making soup” for a particular elder may have
                                                          SˆY = (ˆs1, y1), . . . , (ˆsm, ym) for Y , and assigns it the
the following steps: “preheat water,” “open can,” “mix and
                                                          rating r = R(ˆl ). If r = fail, the rater attempts to
boil ingredients,” “serve,” and “clean up.” The step “open              Y
                                                          produce a repaired trace trace Y 0 = y0 , . . . , y0 such
can,” may have an average duration of 45 seconds and contain                                1      m
                                                          that the edit distance between Y and Y 0 is as small as
the following actions: “use utensil drawer,” “use can opener,”                               0
                                                          possible, and ˆl 0 > L. In other words, Y is the closest
“use can,” and “use pantry door.”                                     Y
                                                          trace to T that passes. The rater offers r as the rating for
  For concreteness, we will assume in what follows that we
                                                          the activity and, if appropriate, δ ˆ ˆ , the set of edits
are using RFID-based [4] sensors that will directly sense the                         SY ,SY 0
                                                                            ˆ      ˆ
action of using particular objects. Therefore, all of our actions needed to transform SY into SY 0 , as the justiﬁcation for
are of the form “use X” where X is some object. Inherently, the rating.
our system requires that actions are observable by sensors. As described above, our rating system employs two key
Given an activity trace (i.e., a trace of actions that constitutes non-standard pieces of machinery.
a particular execution of an activity), our system provides a
                                                                                                        0
rating (e.g., pass or fail). If the grade is a fail, the system pro- 1. A method to compute the repaired observation trace T ,
vides an alternate sequence of actions as close to the original that is a minimum edit distance from a given trace T
as possible that would have elicited a pass grade (essentially whose likelihood is above a pre-speciﬁed threshold L.
a constructive justiﬁcation of the grade). In more detail, use 2. A method to compute the constrained MAP likelihood
of the system proceeds as follows:                        function CMAP(M, T, C).
Learning the model A human demonstrator performs the
    routine in an exemplary fashion. The system collects 3 Trace Repair for Hidden Markov Models
    traces Y1, . . . , Yn of the routine. Each trace Yi is a A Hidden Markov Model (HMM) λ = (A, B, π) is a com-
    sequence of time-stamped observations y , . . . , y
                                        i1      imi   monly used stochastic model for dynamic systems [5]. We
    of the demonstrator’s actions. The traces are used formally pose the trace repair problem as a variation of esti-
    to learn a dynamic stochastic model (either an HMM mating the most likely state sequence given a sequence of ob-
    or an HSMM) with parameters λ. The hidden states  servations (classically solved via the Viterbi algorithm). An
    s1, . . . , sN of the model correspond to the “activity
                                                      HMM is deﬁned as follows. Let QA = {q1, . . . , qN } be the
    steps” above, and are labelled l1, . . . , lN with the names
                                                      states of the process being modeled, and OB = {o1, . . . , oM }
    of the step.                                      the observation signals possibly generated by the process.
Adding global constraints Typically, the ﬁrst-order model We use meta-variables st and yt to denote the states and
    learned in the previous step cannot capture important observations respectively at time t. Aij is the probabil-
    higher-order correlations. For instance, in a successful ity p(st+1 = qj|st = qi) of transitioning from state qi at
    soup-making routine, the stove, if it is used, should even- time t to qj at time t + 1 for any t; Bij is the probability
    tually be turned off after it is turned on. The turning on p(yt = oj|st = qi) of generating observation oj when in

    would happen in the “preheat water” step, but the turn- state qi (we write Biyt for Bij such that yt = oj). The initial
    ing off may not happen until the end of the “serve” step. state distribution πi = p(s0 = qi).
    The human rater explicitly adds a set C of constraints on
    the sequence of hidden states or observations that spec- 3.1 The Repaired MAP Path Estimation Problem
    ify these required higher-order correlations. In this case, We now formulate the problem of MAP path estimation given
    a possible constraint would be of the form use(“stove an observation sequence if we are allowed to ﬁrst make a lim-
    control knob”) E use(“stove control knob”), read as “a ited number of edits or “repairs” to the sequence. We begin
    use of a stove control knob should eventually succeeded by formalizing the notion of an edit. We then state the re-
    by a use of a stove control knob”.                paired MAP path estimation problem and present a variation
Learning rating thresholds A human rater rates each trace of the Viterbi algorithm to solve it.
                                                              N
    Yi with a rating ri ∈ {pass, fail}. Let the con-    Let Y    be the set of length-N strings of observa-
    strained MAP likelihood of trace Y given λ and C, tions over some ﬁnite alphabet Y .   Then  ek,N  =
                                                                                                       N
    ˆ                                           ˆ     ((b1, s1), ...(bN , sN )) is a length-N k-edit vector on Y ,
    lY = CMAP(M, Y,  C), be the likelihood of the path SY                                   P
    with maximum a posteriori (MAP) likelihood given λ with bi boolean, si strings over Y , and k = 1≤i≤N (bi +
                                                                                                3   4,3
    and Y that satisﬁes C. We perform a simple thresholding |si|). For instance, yˆ1 = “cat” is a string in Y ; e1 =
    computation to calculate the likelihood threshold L such ((false, “BB”), (false, “”), (true, “R”)) is an edit vector on
                                                        3
    that, given the classiﬁcation function R(l) = if l < L Y . Applying an edit vector e to string yˆn = y1 . . . yn, writ-
                       ˆ                                                          ˆ0
    then fail else pass, R(lYi ) = ri for as many of the Yi ten e(ˆy) results in a new string y obtained as follows. For
                                                                                                    0
    as possible. Intuitively, L separates the passes from the 1 ≤ i ≤ n, let if e.bi is true, then replace yi with yˆi, else
    fails.                                            replace yi with yie.si (e.si appended to yi). For example,                                                        Initialization: t = 0, k = 1 . . . K, 1 ≤ i ≤ N
            K added observations original observations
    0                                                       δt0k = 1    δtik = 0    ψtik = −1
           y1    y2    y3  y[τ]  y[t]  yT

    1                                                   Iteration: 1 ≤ t ≤ T K +T, k = at, at +1, . . . , K

    2
                                   δ ψ
                                   …ti 1 ti               (ψtik)δtik =   (arg)max    δτjκBiyit Aji
                                   δ
                                    tik                              τ,j,κ s.t. κ+at+dτt=k
    i                              …  …
                              ψτ δ


    STATE                          …
                               j…τj1 δ
                               δ    tiK
                                τjκ                     Termination: t = TM = T K + T + 1
    j                        … …
                               …
                               δ
                                τjK                     (ψtik)δtik =   (arg)max   δτiκ ; iM = argmax δtiK
    N                                                              τ,j,κ s.t. κ+at+dτt=k     1≤i≤N

                              τ              T
       0  1 2   k+2   2k + 3        t         M         Backtracking: (t, i, k) = ψ  ; while t > 0,
                       TIME STEP                                               TM iM K

                                                           1)(s ˙t, y˙t) = (qi, yit) 2)(t, i, k) ← ψtik
      Figure 1: Trellis for k-Edit Viterbi on HMMs
                                                           Table 1: The k-Edit Viterbi Algorithm for HMMs

 4,3                        0
e1 (ˆy1) = “cBBaR”. A string yˆ is a k-edit of another yˆ if
                    k,N         0    k,N              no adds, we add a column (t = TM = T K + T + 1). Rows
there exists edit vector e such that yˆ = e (ˆy).     represent possible hidden states.
  We are now ready to specify the problem of MAP estima- The end result of the algorithm is a forward path (shown
tion with repairs:                                    in light grey in ﬁgure 1) through the trellis that, unlike in the
Deﬁnition 1. (Repaired MAP Path Estimation Problem    conventional Viterbi algorithm, may jump between nodes in
(RMAP))  Given observation sequence yˆT , HMM λ  =    non-adjacent time slices. If the path jumps over the slice for
(A, B, π) and edit distance K ﬁnd observation sequence an original observation yi (where i is the position of the obser-
 0
yˆT 0 =y ˙1 . . . y˙T 0 that is a K-edit of yˆT and path sˆT 0 = vation in the input string yˆ), we conclude that yi was deleted
                          0           0         0
s˙1, . . . , s˙T 0 maximizing p(ˆsT 0 , yˆT 0 ) over all T , sˆT 0 and yˆT 0 . from yˆ, otherwise not. Further, if the path passes through
  Before discussing our solution, we deﬁne string yˆ0 as a sequence of added nodes with no intervening original node
                          0     k,n            k,n
the (k,a)-edit of string yˆn if yˆ = e (ˆy) for some e , such that yi is the ﬁrst original observation to the left of the se-
 k,n                           k,n
|e  .sn| ≤  a, and additionally, e .bn if a = 0 and   quence, and the observations at these nodes are yi1 , . . . , yin ,
 k,n
|e  .sn| > 0 if a > 0. The (k, a)-edit of a string requires we conclude that the string yi1 . . . yin was added at the i’th
its last character to be either preserved or replaced by at least spot in the incoming string. The forward path is the required
                                                                0
one character, with at most a characters added. Edits com- solution sˆT , and the string of observations along the path is
                           0                                         T 0
pose as follows (dνn = n − ν ; a = 1 if a 6= 0, 0 otherwise; the edited string yˆ .
(ν, α)<k(n, a) if ν < n and α ≤ k, or if ν = n and α < a): The algorithm uses three intermediate variables, at, dtτ
                                 kayˆ                     y            a  =  1   #t  6= 0     0
Lemma 1.  (Edit Composition) Let Yn be the set of all and  it. Variable t      if         and   otherwise;
                                             kayˆ     d   =  [t] − [τ]
(k, a)-edits of the n-preﬁx of string yˆ over Y . Then Yn = τt      , represents the number of deletes skipping
  0        0    καyˆ                        0                                    τ    t  y
{yˆ y|y ∈ Y, yˆ ∈ Yν , (ν, α)<k(n, a), κ + dνn + a = k}. original observations between and ; it is the observa-
                                                                                        i        t
  Table 1 speciﬁes an algorithm (the k-Edit Viterbi (KEV) tion considered when processing state at slice . Note
algorithm) to solve RMAP. KEV iterates over the T origi- that we only process original observations at time slices
                                                      1, K + 1, 2K + 1, ...
nal observations in the incoming observation string. For each           . In all other “added” slices, we need
original observation, it iterates over possibilities for the K to propose the observed value to be added. A simple but inef-
                                                                                                  k
added observations at that position, for a total of T K + T ﬁcient approach would be to consider for each state, -value
                                                                 t                       o ∈ O
iterations. At each iteration t corresponding to original ober- and iteration , every possible observable B as a candi-
vation [t] = t div (K + 1) + 1 and added observation #t = date. In fact, we can consider a single observation instead of
                                                      all |OB|. The key insight is that, when processing state i in
t mod (K +1), KEV computes the likelihood δtik of the most
likely path ending in state i given an observation string that an added slice, it is sufﬁcient to consider adding as observable
                                                                                          S      Y
is a (k, #t)-edit of y . . . y over all such edit vectors; KEV the most likely observable in that state. Let N and N be the
                 1    [t]                             sets of all length-N sequences of states and observables. Let
also records as ψtik the penultimate state and edit in this path.
                                                      y˙i = argmax Bij. Let sqˆ be the result of appending state q to
Following the chain of ψtik’s back to the start state iteration 1≤j≤M
gives the MAP repaired path.
                                                      sequence sˆ, and similarly for yyˆ . Then, for all qi ∈ QA:
  The trellis of ﬁgure 1 illustrates KEV. Columns of the                         0
                                                      Lemma 2.     max     p(ˆsqi, yˆ ) = max p(ˆsqi, yˆy˙i)
                                                                  0
trellis represent edits considered for inclusion into the ﬁnal  s,ˆ yˆ ∈SN ,YN+1     s,ˆ yˆ∈SN ,YN
string. Large circles represent original observations and small
                                                        This follows from  the fact that max p(ˆsqi, yyˆ i) =
ones represent adds. For technical reasons (to allow skipping                            yi
the ﬁrst original observation), we add a distinguished start max π B (Q           A  B   )(A   B   )   =
                                                            s1 s1y1  1≤i≤N,siqj ∈sˆN ij jyj sN i iyi
                                0                       yi
state q0 with new start probabilities π0 = 1, A0i = πi and
                                                      πs1 . . . AsN i max Biyi = πs1 . . . AsN iy˙i. Given this identity
Ai0 = 0 and add a column (t = 0) processed in the initializa-     yi
tion step. To allow skipping the last original observation with for the optimal observable to be added in state qi, we set yit                                                        Init., Term., Bactracking: See table 1.
to y˙i if t is an “added” timeslice, and to y[t] otherwise.
  We are now ready to establish the soundness of the KEV Iteration: 1 ≤ t ≤ T K +T, k = at, at +1, . . . , t
              i
algorithm. Let Sn be the set of length-n sequence of states
                     tik                                (ψtik)δtik =  (arg)max  δτjκp(yκkτti)AjiDi|yκkτti|
ending in state qi. Let Yn be the set of length-n strings of       1≤τ≤t,j,κ,yκkτti
observables that are (k, #t)-edits of y1 . . . y[t].

Lemma 3.  (ψtik)δtik = (arg)max p(ˆs, yˆ)                 Table 2: The k-Edit Viterbi Algorithm for HSMMs
                         i    tik
                     n,sˆ∈Sn,yˆ∈Yn

Proof sketch. Proof is by induction on t. We focus on the Table 2 speciﬁes a variant of KEV to solve the problem,
inductive case for δ. For ψ, replace “max” with “argmax”. and ﬁgure 2 shows a trellis for this algorithm. The trellis is
                                                      identical to that used by KEV (we represent k added nodes
 δtik =   max AjiBiyit δτjκ∀j,τ,κ s.t. (κ + at + dτt) = k
          τ,j,κ                                       with a single small circle), only its use is different. We fo-
      =   (by the inductive hypothesis)               cus on how δtik is calculated. At each timestep t, state i
                                                      and edit distance k, as with KEV, we iterate over previous
          max(AjiBiyit   max     p(ˆs, yˆ))
          τ,j,κ           j    τjκ
                     n,sˆ∈Sn,yˆ∈Yn                    timesteps, states and edit distances τ, j and κ. However, this
                             n−1  n                   time instead of discarding the observations in the intervening
Given sn, sn+1 is independent of sˆ , yˆ :
                                                      timesteps, we seek their sub-sequence yκkτti. We assume that
  A    =  p(s    = q |s,ˆ s = q , yˆ) ∀       τjκ     step t only ends a stay in state qi that begins immediately after
   ji        n+1    i   n    j     n,sˆ∈Sn−1,yˆ∈Yn
                                                      the stay in qj that ended in step τ. If eτt is the number of ed-
       =  p(sn+1 = qi|s,ˆ yˆ) ∀ j    τjκ
                           n,sˆ∈Sn,yˆ∈Yn              its in yκkτti (added nodes included + original nodes ignored),
Similarly, for yn+1 given sn+1:                       we require κ + at + eτt = k. The problem of maximizing
                                                      the likelihood of the path ending at (i, t) then reduces to the
                                          j    τjκ
 Biyit =   p(yn+1 = yit|s,ˆ sn+1 = qi, yˆ) ∀n,sˆ∈S ,yˆ∈Y
                                          n    n      problem of ﬁnding yκkτti maximizing p(yκkτti)Di|yκkτti|.
                                                        We ﬁnd this maximum by iterating through durations l in
Substituting for Aji and Biy above, and using p(A, B) =
                        it                            D  ; for each l, we iterate through predecessors (τ, j, κ) of
p(A|B)p(B) twice, we have, with (κ + at + dτt) = k:     i
                                                      (t, i), ﬁnding a sequence yκkτti of length l with the high-
  δtik =     max       p(sn+1 = qi, s,ˆ yn+1 = yit, yˆ)
                j    τjκ                              est probability; we keep a running tally of the maximum
       τ,j,κ,n,sˆ∈Sn,yˆ∈Yn
                                                      p(yκkτti)Dil. Finding yκkτti reduces to identifying NA
Lemma 2 ensures that maximizing over yyˆ it maximizes over added nodes (to include in yκkτti) and NO original nodes
all strings yyˆ . By lemma 1 maximizing over all yyˆ with yˆ ∈ (to ignore), such that NA + NO = k − κ − at (to satisfy
 τjκ                    tik
Y    maximizes over yˆ ∈ Y . Finally, ∀      j sˆ =   the k-edit criterion), and NA + (([t] − [τ]) − NO) = l (to
 n                     n+1          1≤j≤N,sˆ∈Snqi
∀         i  sˆ. Modifying the previous equation to reﬂect satisfy the duration constraint). The two equations ﬁx NA
 1≤i≤N,sˆ∈Sn+1
these insights:                                       and NO. Since all the added nodes have the same probability
                                                      y˙i = p(ˆoi|qi), it doesn’t matter which particular NA we pick.
   δtik =     max     p(ˆs, yˆ) = max     p(ˆs, yˆ)   On the other hand, we pick the NO original nodes with low-
         n,sˆ∈Si ,yˆ∈Y tik    n,sˆ∈Si ,yˆ∈Y tik
             n+1   n+1             n   n              est probability of observation for exclusion; this can be done
                                                      by sorting the original nodes in O(T log T ) time ofﬂine, with
                                                      O(L) access during execution. Once the sequence of nodes
  The soundness of KEV follows in a straightforward way is picked to get yκkτti, we simply multiply their observation
from the above lemma. Further, given that the trellis has and transition probabilties together to get p(yκkτti), a process
O(T KN)  nodes, that at each node we compute O(K) δ and that takes l operations, since |yκkτti| = l = O(L).
ψ values, and we consult O(NK) preceding data values to
                                          2  3          Given O(T NK)  trellis nodes, computing O(K) δ and ψ
do so, the complexity of KEV as a whole is O(T N K ). values at each node, consulting O(|D|NK) preceding values
                                                      for each value, and spending O(L) for each preceding value
4  Trace Repair for HSMMs                             considered, the entire algorithm takes O(T N 2|D|LK3)
A  Hidden  Semi-Markov  Model (HSMM)     [3] λ   =    steps. Note that in the (fairly) common case that D and L
(A, B, D, π) is identical to an HMM except for the duration are unbounded, this running time becomes O(T 3N 2K3).
distribution D. Where an HMM generates a single observa-
tion according to B on each visit to a state s, the HSMM gen-
erates l independent observations from B on each visit, where
l is drawn according to Dsl = p(l|s). The added ﬂexibility is
useful when modeling human activities, since the duration of
stay in a state is restricted to be geometric (and therefore bi-
ased to small values) in HMMs. In what follows, we assume
that D is over a ﬁnite set (of size |D|) of durations, where the
longest duration is L steps.
  The RMAP problem is: given HSMM (A, B, D, π), obser-
vations yˆT and limit K, ﬁnd  argmax       p(ˆs, yˆ).           Figure 2: Trellis for KEV on HSMMs
                            t    t        T
                        t,sˆ∈QA,yˆ∈OB ,yˆ k-edit of yˆ5  Trace Repair for Constrained HMMs                  ments compare a regular HMM and a time-sensitive HSMM,
We deﬁne a  temporally constrained HMM (TCHMM)   as   and a regular HSMM with an HSMM that has temporal logic
λ  =   (A, B, C, π), where C is a temporal constraint constraints, respectively.
                                                        First, we compare the output of HMMs versus HSMMs on
of the form  φ1Eφ2E . . . Eφ|C|. The φi are proposi-
tional boolean formulas over state labels l and observa- three activity traces from different activity models (see the
tions y: φ  ::= state(l)|obs(y)|φ ∧ φ|¬φ. Path sufﬁx  top row of Figure 3). Each activity trace was intentionally
s . . . s and observations y . . . y satisfy the constraint suf- made incorrect: for making tea, the preparation step was hur-
 i    T                i    T                         ried; for making a sandwich, not enough ingredients were
ﬁx Cj  =  φj . . . φW if for any k ≥ j, φj(sk, yk) im-
plies that (s . . . s , y . . . y ) satisfy C , written collected; and for grooming, brushing teeth and combing hair
           k+1    T  k+1    T           j+1           were performed too rapidly. In the top row of Figure 3, we
(sk+1 . . . sT , yk+1 . . . yT ) ` Cj. Intuitively if one for-
mula in the constraint sequence is true w.r.t. the head plotted the maximum likelihood values at each step of the
of the state/observation sequences, then the formulas that activity traces (where a “step” is considered to be a state tran-
follow must also eventually be true in their speciﬁed or- sition). HMMs fail to detect any problem, exhibiting high
der later in the sequences. The constraint (state(COOK) ∧ likelihood. However, HSMM likelihoods plummet, due to
obs(oil))E(state(WASH)∧obs(soap)) could, for instance cap- sensitivity to the amount of time spent in each state. The
ture the constraint that if oil is used in the cooking step of KEDIT trace correctly adds the proper number of observa-
making dinner, soap should be used in the eventual required tions to each state, resulting in a high likelihood.
washing step.                                           Second, we compare the output of HSMMs with and with-
  The RMAP problem may now be reformulated as given   out temporal logic constraints (TLCs) (see the bottom row of
TCHMM   with constraints C, observations yˆT and limit K, Figure 3). Again, we intentionally chose incorrect sequences
ﬁnd SY =        argmax       φ(ˆs, yˆ) such that SY ` C. for the three activities: for making tea, the stove is turned on
              t    t        T                         but never turned off; for preparing a sandwich, the refriger-
         t,sˆ∈QA,yˆ∈OB ,yˆ k-edit of yˆ
  Our solution for RMAP estimation is restricted to formulas ator door is opened and never closed; and for grooming, the
of the form φ ::= state(l)|φ∧φ|¬φ (we disallow dependences sink water is turned on and never turned back off. In the top
on observables). A small modiﬁcation to the KEV algorithm row of Figure 3, we plotted the maximum likelhood values at
enables polynomial time solution of this problem. We use the each step of the activity traces. Regular HSMMs fail to detect
same trellis as in KEV. For each timestep t, state i and edit any problem, reporting high likelihood. HSMMs with TLCs
distance k, we also now maintain an additional |C|-vector. An report low likelihood, because they are only allowed to con-
                                                      sider state-transitions which satisfy all constraints. In these
element δtikm with 0 ≤ m < |C| represents the likelihood of
the MAP path ending at state i in time slice t with (k, #t) traces, constraints are broken and alternate, low-likelihood,
                                                      paths must be considered. The KEDIT trace correctly adds
edits that still requires constraint sufﬁx Cm+1 to be satis-
                                                      the necessary steps (i.e., turn off stove, shut refrigerator, and
ﬁed (except δtik0, which has no outstanding constraints to be
satisﬁed). This likelihood can be computed compositionally turn off sink), resulting in high likelihood.
from δτjκµ, with τ < t and (κ, µ) pointwise ≤ (k, m) in How does the rating change as k increases? The k-edits
      2 3  2                                          Viterbi algorithm provides advice for up to K edits. Ideally,
O(T N  k |C| P ) steps, where formulas φi can be evaluated
in O(P ) steps (where P is the size of the formulas). we desire a trace that is above the likelihood threshold with
  Even MAP estimation (without trace perturbation) for the minimum number of edits. One method is to incremen-
TCHMM’s has apparently neither been formulated nor solved tally increase k until the threshold is exceeded. For this rea-
previously, although it is potentially quite powerful. For in- son, we are interested in how the likelihood changes as k in-
stance, the constrained inference work of Culotta et. al. [2] creases.
is a special case of TCHMM k-edit MAP estimation (with  In this experiment we ran k-edits Viterbi for HSMMs on
                                                      an empty trace of the “making tea” activity. In Figure 4 we
k = 0, and C = state(q0)Estate(qi)). MAP estimation is a
special case of RMAP estimation with k = 0. Our variant plotted the overall likelihood of each trace as the number of
of KEV above therefore performs MAP estimation. Interest- possible edits was increased. The dashed line is a threshold
ingly with k = 0, we can allow the more general version showing the likelihood of an acceptable “good” trace. Ob-
of formulas φ and still retain the fast running time. It is open viously, the original empty sequence had low likelihood. As
how general C can be while remaining tractable. For instance, k was increased from one to three, the algorithm was forced
our constraints can be viewed as a fragment of Linear Tem- to assemble partially complete activity traces which had even
poral Logic (LTL) [1]. It is interesting to consider larger frag- lower overall likelihood. When k = 4 the algorithm formed a
ments as candidates.                                  complete trace and met the threshold. As k increased further,
                                                      the algorithm tweaked the sequence for a slightly higher like-
                                                      lihood. The most likely possible path was reached at k = 6.
6  Evaluation                                         Afterwards, we see an “odd-even” effect as the algorithm is
How does model choice affect advice? The k-edit Viterbi al- forced to add new (less likely) observations, and then oppor-
gorithm dispenses advice based on the parameters of its activ- tunistically delete other observations. For k ≥ 9, the likeli-
ity models. The credibility of this advice will suffer from any hood drops as the algorithm performs too many modiﬁcations
differences between these models and the reality they repre- to the trace and is unable to reach the optimal solution.
sent. In order to illustrate this point, we conducted two exper- How intuitive is the advice? We now examine the advice
iments over three different activity models. The two experi- dispensed by k-edits Viterbi in several scenarios. We ran the