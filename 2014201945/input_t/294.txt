    Interactive Spoken Simulation Control and Conversational Tutoring 

                      Karl Schultz, Brady Clark, Elizabeth Owen Bratt, Stanley Peters, 
                      Heather Pon-Barry, Pucktada Treeratpituk, Zack Thomsen-Gray 

                        Center for the Study of Language and Information - Stanford University 
                                        Stanford, California 94305 
                       {schultzk,bzack,ebratt,peters,ponbany,pucktada,ztgray}@csli.stanford.edu 

                             David C Willdns, David M. Fried, Eugene Grois 

                                   Beckman Institute - University of Illinois 
                                          Urbana, Illinois 61801 
                                       {dcw,fried,e-grois}@uiuc.edu 

                                                     but also to recreate the stressful nature of the job as 
                                                     accurately as possible. 
                 Introduction                         To handle such interaction, it was possible to simulate 
We describe how spoken dialogue interfaces make a    the command-receiving agents using the simplest kind of 
simulation-based trainer and an intelligent tutoring system dialogue system, a finite-state scripted system. 
into a powerful package for Naval damage control     Furthermore, only 3 states are needed: the agent is ready to 
education. An advanced simulator gives a student real-time receive a new command, the agent has an incomplete 
experience that would otherwise be extremely costly to message and is awaiting a missing value(s), or the agent is 
provide. The dialogue interface to the simulator uses a actually issuing the command to the personnel that will 
simple finite-state script to allow the user to issue orders carry it out. 
and requests in a realistic way. Subsequently, the reflective The emphasis for the spoken interface to the simulator is 
tutor communicates to the student about their experience on providing a realistic experience. Other benefits include 
with the simulator entirely through a 'conversationally not having to learn locations and organizations of simulator 
intelligent* dialogue system, with capabilities like topic graphical menus when the spoken commands are already 
management and coordination of multi-modal input and familiar, and gaining the speed of verbal interaction. We 
output.                                              use clarification sub-dialogues to provide a way to address 
                                                     speech recognition problems, and to allow for building up 
                                                     complex commands incrementally. 
               Dialogue Systems 
Dialogue systems can range from very simple finite-state SCOT Dialogue Manager 
scripts defining the bounds of interaction, to complicated 
plan-oriented agents that can have very complex     The Spoken Conversational Tutor (SCOT) is on the 
conversational intelligence (Allen 2001). The two systems opposite end of dialogue-supporting capabilities from the 
discussed below are among the extremes, one being very simple finite-state script used in DC-Train. There is a more 
simple and the other containing more advanced forms of robust conversational intelligence (CI) at work in SCOT'S 
conversational intelligence, but both serving their purposes dialogue manager which is necessary to facilitate a 
with a good degree of success.                      prolonged conversation about damage control doctrine. 
                                                     Since the utterances here are not simply mapped into 
                                                    commands and parameters the dialogue structure becomes 
DC-Train 4.1 Dialogue Manager                       much more important. Topic management and 
The shipboard Damage Control Trainer, or DC-Train, is a coordination of multi-modal input and output (gestures) are 
simulator of damage control aboard large Navy ships. among the improvements over a simple finite-state script to 
There is a physical simulator of fire, flood, and smoke, as reach a more human-like level of conversation. 
well as simulated shipboard damage control personnel. A An annotated record of the student's performance with 
student is placed in front of the simulator and presented the DC-Train simulator is fed into SCOT, from which an 
with one or more damage control crises to solve. This initial plan is created. This plan is made by the tutoring 
involves giving orders to the various simulated agents, component of SCOT, which is completely separate from 
which should occur verbally not only for training purposes, the dialogue manager side. This extra 'planner' is one of 
                                                    the necessities with CI of topics and goals. The dialogue 


INTELLIGENT SYSTEMS DEMONSTRATIONS                                                              1643 manager will only have limited abilities to manipulate the 
plan and attach a user utterance to the relevant place. It Nuance 
understands that there are topics and sub-topics, but the 
dialogue manager obviously has no knowledge of what the The Nuance speech recognition server takes a user 
tutorial goals are or how they relate to each other. Dealing utterance and a recognition model, which we compile 
with these concerns is the job of an outside agent The directly from a Gemini grammar, and attempts to turn the 
separation of the CI from the tutoring knowledge allows the utterance into text. The grammar plays a key role in 
dialogue manager to be generic and usable for any domain, defining the bias of the recognizer towards words and 
provided an outside agent contains the semantic      phrases within the current domain, as well as assuring that 
understanding of the goals and topics.               every recognized utterance has a corresponding LF. 
  The ability to reshape the current and future dialogue Limiting what a user can say has the bonus of significantly 
threads is a major advantage over a finite-state model. It better recognition of expected utterances, but has the 
creates an interactive style which comes much closer to undesired effect of sometimes turning out-of-grammar 
humans, where topics can explored in more or less detail, phrases into in-grammar phrases, which would obviously 
or put aside for later, new topics can spring up at whim and cause problems. This is where a well engineered grammar 
old topics can never be brought back if it becomes   plays an important role. 
unnecessary. The tutor agent monitors the conversation 
and makes these changes as it sees fit to suit the overall Festival and Festvox 
tutoring strategies for teaching and specific tactics applied The Festival text-to-speech system turns any text into audio 
to get points across.                                output. How usable a speech-enabled system will be 
  This dialogue manager can also handle creating gestural depends highly on how understandable the output is. There 
output to the user and timing that with the speech, as well are a variety of voices to choose from when using Festival, 
as interpreting gestural input from the user (in the form of but they are 'computer-sounding' and lack the clarity and 
mouse clicks). Gestures are a large part of typical human- subtle inflections of a real human voice. One solution to 
to-human interaction (Clark 1996), and the more the  this is to use the Festvox add-in to Festival, which allows 
student is able to interact with a common workspace which one to create a voice which sounds exactly like the person 
SCOT shares, the more natural-feeling and effective the who creates it. This process involves recording a large 
interaction will be. Currently the student can only point at number of phrases covering the range of words in the 
designated times, but ideally all mouse movement would be desired domain. These recordings are then analyzed along 
analyzed for pointing, just as all hand movements in with the corresponding text, and a voice is compiled which 
conversation could be looked at for gestural meaning. uses the discovered human-sounding words to generate the 
                                                     audio output. 
               Voice Interaction 
Of the major technical difficulties to overcome in creating a      Acknowledgments 
robust dialogue system the input and output is obviously This work is supported by the Department of the Navy 
one of the more pertinent. The concerns of good speech under research grant N000140010660, a multidisciplinary 
recognition are one of the limiting factors to how much university research initiative on natural language 
variance in input is allowed. The audio side of speech interaction with intelligent tutoring systems. 
output is somewhat less restrictive, but that varies based on 
how realistic the voice needs to be. However, both the 
input and output are governed by an underlying grammar                 References 
which gives the system the ability to intelligently parse user Allen, J.; Byron, D.; Dzikovska, M.; Ferguson, G.; 
input and create complex output using semantic constructs, Galescu, L.; and Stent, A. 2001. "Towards Conversational 
or logical forms (LFs), rather than using canned phrases or 
                                                     Human-Computer Interaction,'1 AI Magazine. 
sentences. 
                                                    Clark, Herbert H. 1996. Using Language. Cambridge: 
Gemini                                              Cambridge University Press. 
The Gemini NLP system (Dowding et al. 1993) uses a 
single unification grammar both for parsing strings of Dowding, J.; Gawron, J.; Appelt, D.; Bear, J.; Cherny, L.; 
words into logical forms (LFs) and generating sentences Moore, R.C.; and Moran, D. 1993. Gemini: A natural 
from LF inputs. This enables us to give precise and language system for spoken-language understanding. 
reliable meaning representations which allow us to identify Proceedings of the ARPA Workshop on Human Language 
the discourse move types (e.g., a question) given a  Technology. 
linguistic input or output; e.g., the question "What 
happened next?" has the LF: (ask(wh([past,happen]))). 


1644                                                          INTELLIGENT SYSTEMS DEMONSTRATIONS 