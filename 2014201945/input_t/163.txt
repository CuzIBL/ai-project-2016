      DP-SLAM: Fast, Robust Simultaneous Localization and Mapping Without 
                                         Predetermined Landmarks 

                                          Austin Eliazar and Ronald Parr 
                                          Department of Computer Science 
                                                   Duke University 
                                            {eliazar, parr} @cs.duke.edu 


                        Abstract                               ical loop in the environment, serious misalignment errors can 
                                                               result. 
     We present a novel, laser range finder based algorithm 
     for simultaneous localization and mapping (SLAM) for        The EM algorithm provides a very principled approach to 
     mobile robots. SLAM addresses the problem of con•         the problem, but it involves an expensive off-line alignment 
     structing an accurate map in real time despite imperfect  phase [Burgard et ah, 1999]. There exist heuristic approaches 

     information about the robot's trajectory through the en•  to this problem that fall short of full EM1, but they are not a 
     vironment. Unlike other approaches that assume prede•     complete solution and they require additional passes over the 
     termined landmarks (and must deal with a resulting data-  sensor data [Thrun, 2001]. Scan matching can produce good 
     association problem) our algorithm is purely laser based. maps fLu and Milios, 1997; Gutmann and Konolige, 2000] 
     Our algorithm uses a particle filter to represent both robot 
                                                               from laser range finder data, but such approaches typically 
     poses and possible map configurations. By using a new 
                                                               must explicitly look for and require additional effort to close 
     map representation, which we call distributed particle 
     (DP) mapping, we are able to maintain and update hun•     loops. In varying degrees, these approaches can be viewed as 
     dreds of candidate maps and robot poses efficiently. The  partially separating the localization and mapping components 
     worst-case complexity of our algorithm per laser sweep    of SLAM. 
     is log-quadratic in the number of particles we maintain     The FastSLAM algorithm [Montemerlo et a/., 2002J, 
     and linear in the area swept out by the laser. However, in which does not require explicit loop-closing heuristics, is a 
     practice our run time is usually much less than that. Our recent SLAM approach which has made great progress in 
     technique contains essentially no assumptions about the 
                                                               the field. FastSLAM follows a proposal by Murphy [Mur•
     environment yet it is accurate enough to close loops of 
     60m in length with crisp, perpendicular edges on corri•   phy, 19991 using a Rao-Blackwellized particle filter to sam•
     dors and minimal or no misalignment errors.               ple robot poses and track the position of a fixed number of 
                                                               predetermined landmarks using a Kalman filter. (The land•
                                                               mark positions are conditionally independent given the robot 
1 Introduction                                                 pose.) This method mitigates some of the challenges in map•
The availability of relatively inexpensive laser range finders ping at the expense of some challenges in landmark selection 
and the development of particle filter based algorithms have   and identification. The latter can involve a fairly complicated 
led to great strides in recent years on the problem of robot   data association problem, although recent progress has been 
localization - determining a robot's position given a known    made in addressing this [Montemerlo and Thrun, 20021. 
map [Fox et al, 1999]. Initially, the maps used for these        We present a novel, laser range finder based algorithm 
methods were constructed by hand. However, the accuracy        called DP-SLAM that, like FastSLAM, exploits the condi•
of the laser suggests its use for map-making as well as lo•    tional independences noted by Murphy. However, our algo•
calization. Potential applications for accurate map-making     rithm is purely laser based and makes no landmark assump•
would include search and rescue operations, as well as space,  tions. We avoid the data association problem by storing mul•
underwater and subterranean exploration.                       tiple detailed maps instead of sparse landmarks, thereby sub•
  Even with an accurate laser range finder, map-making         suming association with localization. Our algorithm uses a 
presents a difficult challenge: A precise position estimate is particle filter to represent both robot poses and possible map 
required to make consistent updates to the the map, but a good configurations. Using a new map representation, which wc 
map is required for reliable localization. The challenge of si• call distributed particle (DP) mapping, we are able to main•
multaneous localization and mapping (SLAM) is that of pro•     tain and update hundreds or thousands of candidate maps and 
ducing accurate maps in real time, based on a single pass over robot poses in real time as the robot moves through the en•
the sensor data, without an off line correction phase. Straight• vironment. The worst-case complexity of our algorithm per 
forward approaches that localize the robot based upon a par•   laser sweep is log-quadratic in the number of particles we 
tial map and then update the map based upon the maximum 

likelihood position of the robot tend to produce maps with er•    lThis approach is heuristic because it does not maintain a joint 
rors that accumulate over time. When the robot closes a phys•  probability distribution over maps and poses. 


ROBOTICS                                                                                                            1135  maintain and linear in the area swept out by the laser. How•
 ever, in practice our run time is usually much less. Our tech•
 nique makes essentially no assumptions about the environ•
 ment yet it is accurate enough to close loops of 60m in length The a and b terms are linear correction to account for consis•
 with crisp, perpendicular edges on corridors and minimal or   tent errors in motion. The function. returns random 
 no misalignment errors. This accuracy is achieved throughout  noise from a normal distribution with mean 0 and standard 
 the mapping process, without a need for explicit algorithms   deviation a, which is derived experimentally and may depend 
 to correct the loop as temporally distant observations begin to upon the magnitudes of and 
overlap. In fact, DP-SLAM could be further complimented          After simulation, we need to weight the particles based on 
 by inclusion of existing algorithms for closing loops, though the robot's current observations of the environment. For pure 
the addition may be unnecessary if a sufficient number of par• localization, the robot stores a map in memory. The position 
ticles is used.                                                described by each particle corresponds to a distinct point and 
                                                               orientation in the map. Therefore, it is relatively simple to de•
2 Particle Filters for Localization and                        termine what values the sensors should return, given the pose 
     Mapping                                                   within the map. The standard assumption is that sensor errors 
                                                               are normally distributed. Thus, if the first obstruction in the 
A particle filter is a simulation-based method of tracking a   map along a line traced by a laser cast is at distance d and the 
system with partially observable state. We briefly review par• reported distance is the probability density of observing 
ticle filters here, but refer the reader to excellent overviews discrepancy is normally distributed with mean 0. 
of this topic iDoucet el ai, 2001] and its application to      For our experiments we assumed a standard deviation in laser 
robotics [Thrun, 2000J for a more complete discussion.         measurements of 5cm. Given the model and pose, each sen•
   A particle filter maintains a weighted (and normalized) set sor reading is correctly treated as an independent observation 
of sampled states, cahed particles. At each                    1 Murphy, 19991. The total posterior for particle i is then 
step, upon observing an observation o (or vector of observa•
tions), the particle filter: 
  1. Samples new statesfrom S with                             where is the difference between the expected and per•
     replacement.                                              ceived distances for sensor (laser cast) and particle i. 
  2. Propagates each new state through a Markovian transi•
                                                               2.2 Particle Filters for SLAM 
     tion (or simulation) model: . This entails sam•
     pling a new state from the conditional distribution over  Some approaches for SLAM using particle filters attempt 
     next states given the sampled previous state.             to maintain a single map with multiple robot poses [Thrun, 
                                                               2001], an approach that we avoid because it leads to errors 
  3. Weighs each new state according to a Markovian obser•     that accumulate over time. The basic problem is that the hid•
     vation model:                                             den state is actually both the robot pose and the map itself. An 
  4. Normalizes the weights for the new set of states          important consequence of this problem is that all observations 
   Particle filters arc easy to implement have been used       arc no longer compared to a single map, which is presumed 
to track multimodal distributions for many practical prob•     to be correct. Instead, the observations are compared against 
lems [Doucet et al, 2001].                                     an incomplete and possibly incorrect map, identified with the 
                                                               particle in question. The map itself is created by the accu•
2.1 Particle Filters for Localization                          mulation of observations of the environment and estimates of 
                                                               robot positions. 
A particle filter is a natural approach to the localization prob•
lem, where the robot pose is the hidden state to be tracked.     In principle, this "solves" the SLAM problem. In prac•
The state transition is the robot's movement and the observa•  tice, it replaces a conceptual problem with an algorithmic one. 
tions are the robot's sensor readings, all of which are noisy. Particles with errors in robot position estimates will make er•
                                                               roneous additions to their maps. An error in the map will 
  The change of the state over time is handled by a mo•
                                                               then, in turn, cause another error in localization in the next 
tion model. Usually, the motion indicated by the odometry 
                                                               step, and these inaccuracies can quickly compound. Thus, 
is taken as the basis for the motion model, as it is a reliable 
                                                               the number of particles required for SLAM is typically more 
measure of the amount that the wheels have turned. However, 
                                                               than that required for localization since the price of accumu•
odometry is a notoriously inaccurate measure of actual robot 
                                                               lated errors is much higher. Note that in pure localization, 
motion, even in the best of environments. The slip and shift 
                                                               small errors in position estimation can be absorbed as part of 
of the robot's wheels, and unevenness in the terrain can com•
                                                               the noise in the motion model. 
bine to give significant errors which will quickly accumulate. 
A motion model differs across robots and types of terrain, but   The algorithmic problem becomes one of efficiently main•
generally consists of a linear shift, to account for systematic taining a large enough set of particles to obtain robust perfor•
errors and Gaussian noise. Thus, for odometer changes of x,    mance, where each particle is not merely a robot pose, but a 
                                                               pose and map. Since maps are not light weight data struc•
  and a particle filter applies the error model and obtains, 
                                                               tures, maintaining the hundreds or thousands of such maps 
for particle 
                                                               poses a serious challenge. One reasonable approach to tam•
                                                               ing this problem is to assume that the uncertainty in the map 


1136                                                                                                          ROBOTICS can be represented in a simple parametric form. This is essen• linear in the number of iterations of the particle filter. The 
tially the approach taken by FastSLAM, for which the map is    challenge is, therefore, to provide data structures that permit 
a Kalman filter over a set of landmark positions. This is cer• efficient updates to the map and efficient localization queries 
tainly the right thing to do if one is given a set of landmarks with time complexity that is independent of the number of 
that can be quickly and unambiguously identified. We will      iterations of the particle filter. We call our solution to this 
show that this strong assumption is not required: By using     problem Distributed Particle Mapping or DP-Mapping, and 
raw laser data, combined with an occupancy grid and efficient  we explain it in terms of the two data structures that are main•
data structures, we can handle a large number of candidate     tained: the ancestry tree and the map itself. 
maps and poses efficiently, achieving robust performance. 
                                                               Maintaining the particle ancestry tree 
3 DP-SLAM                                                      The basic idea of the particle ancestry tree is fairly straight•
                                                               forward. The tree itself is rooted with an initial particle, of 
In this section we motivate and present the main technical     which all other particles are progeny. Each particle maintains 
contribution of the DP-SLAM algorithm. DP-SLAM imple•          a pointer to its parent and is assigned a unique numerical ID. 
ments what is essentially a simple particle filter over maps   Finally each particle maintains a list of grid squares that it has 
and robot poses. However, it uses a technique called dis•      updated. 
tributed particle mapping (DP-Mapping), which enables it to      The details of how we will use the ancestry tree for local•
maintain a large number of maps very efficiently.              ization are described in the subsequent section. In this section 
                                                               we focus on the maintenance of the ancestry tree, specifically 
3.1 Naive SLAM                                                 on making certain that the tree has bounded size regardless of 
When using a particle filter for SLAM, each particle corre•    the number of iterations of the particle filter. 
sponds to a specified trajectory through the environment and     We maintain a bounded size tree by pruning away unnec•
has a specific map associated with it. When a particle is re-  essary nodes. First, note that certain particles may not have 
sampled, the entire map itself is treated as part of the hidden children and can simply be removed from the tree. Of course, 
state that is being tracked and is copied over to the new parti• the removal of such a particle may leave its parent without 
cle. If the map is an occupancy grid of size M and P particles children as well, and we can recursively prune away dead 
are maintained by the particle filter, then ignoring the cost of branches of the tree. After pruning, it is obvious that the 
localization, O(MP) operations must be performed merely        only particles which are stored in our ancestry tree are exactly 
copying maps. For a number of particles sufficient to achieve  those particles which are ancestors of the current generation 
precise localization in a reasonably sized environment, the    of particles. 
naive approach would require gigabytes worth of data move•       This is still somewhat more information than we need to 
ment per update2.                                              remember. If a particle has only one child in our ancestry 
                                                               tree, we can essentially remove it, by collapsing that branch 
3.2 Distributed Particle Mapping                               of the tree. This has the effect of merging the parent's and 
By now the astute reader has most likely observed that the     child's updates to the map, a process described in the subse•
naive approach is doing too much work. To make this clearer,   quent section. By applying this process to the entire tree after 
we will introduce the notion of a particle ancestry. When a    pruning, we obtain a minimal ancestry tree, which has several 
particle is sampled at iteration i to produce a successor parti• desirable and easily provable properties: 
cle at iteration we call the generation i particle a parent 
                                                               Proposition 3.1 Independent of the number of iterations of 
and the generation particle a child. Two children with 
                                                               particle filtering, a minimal ancestry tree of P particles 
the same parent are siblings. From here, the concept of a par•
ticle ancestry extends naturally. Suppose the laser sweeps out   J. has exactly P leaves, 
an area of size and consider two siblings, s1 and s2.           2. has branching factor of at least 2, and 
Each sibling will correspond to a different robot pose and will 
make at most A updates to the map it inherits from its parent.  3. has depth no more than P. 
Thus, s1 and s2 can differ in at most A map positions.         Map representation 
   When the problem is presented in this manner, the natural   The challenge for our map representation is to devise a data 
reaction from most computer scientists is to propose record•   structure that permits efficient updates and efficient localiza•
ing the "diff" between maps, i.e, recording a list of changes  tion. The naive approach of a complete map for each parti•
that each particle makes to its parent's map. While this would cle is inefficient, while the somewhat less naive approach of 
solve the problem of making efficient map updates, it would    simply maintaining history of each particle's updates is also 
create a bad computational problem for localization: Trac•     inefficient because it introduces a dependency on the number 
ing a line though the map to look for an obstacle would re•    of iterations of the particle filter. 
quire working through the current particle's entire ancestry     Our solution to the map representation problem is to asso•
and consulting the stored list of differences for each particle ciate particles with maps, instead of associating maps with 
in the ancestry. The complexity of this operation would be     particles. DP-mapping maintains just a single occupancy 
                                                               grid. (The particles are distributed over the map.) Unlike a 
   2In addition to the theoretical analysis, anecdotal comments 
made by researchers in this area reinforce the impracticality of this traditional occupancy grid, each grid square stores a balanced 
approach.                                                      tree, such as a red-black tree. The tree is keyed on the IDs of 


ROBOTICS                                                                                                            1137  the particles that have made changes to the occupancy of the  total and the cost of deleting childless particles will be amor•
 square.                                                       tized as O(ADPlgP). 
   The grid is initialized as a matrix of empty trees. When a    It remains to be shown that the housekeeping required to 
 particle makes an observation about a grid square it inserts its maintain the ancestry tree has reasonable cost. Specifically, 
 ID and the observation into the associated tree. Notice that  we need to show that the cost of collapsing childless ancestry 
 this method of recording maps actually allows each particle   tree nodes does not exceed O(ADPlgP). This may not be 
 to behave as if it has its own map. To check the value of a   obvious at first, since successive collapsing operations can 
 grid square, the particle checks each of its ancestors to find make the set of updated squares for a node in the ancestry tree 
 the most recent one that made an observation for that square. as large as the entire map. We now argue that the amortized 
 If no ancestor made an entry, then the particle can treat this cost of these changes will be O(ADPlgP). First, consider 
position as being unknown.                                     the cost of merging the child's list of modified squares into 
   We can now describe the effects of collapsing an ancestor   the parent's list. If the child has modified n squares, we must 
with a single child in the ancestry tree more precisely: First, perform 0(nlgP) operations (n balanced tree queries on the 
the set of squares updated by the child is merged into the par• parent's key) to check the child's entries against the parent's 
ent's set. Second, for each square visited by the child, we    for duplicates. 
change the ID key stored in the balanced tree to match that of   The final step that is required consists of updating the ID 
the parent. (If both the child and parent have made an update  for all of the child's map entries. This is accomplished by 
to the same square, the parent's update is replaced with the   deleting the old ID, and inserting a new copy of it, with the 
child's.) The child is then removed from the tree and the par• parent's ID. The cost of this is again 0(nlgP). Consider that 
ent's grandchildren become its direct children. Note that this each map entry stored in the particle ancestry tree has a po•
ensures that the number of items stored in the balanced tree   tential of D steps that it can be collapsed, since D is the total 
at each grid square is 0{P).                                   number of nodes between its initial position and the root, and 
                                                               no new nodes will ever be added in between. At each itera•
3.3 Computational Complexity                                   tion, P particles each create A new map entries with potential 
                                                               D. Thus the total potential at each iteration is O(ADPlgP). 
The one nice thing about the naive approach of keeping a         The computational complexity of DP-SLAM can be sum•
complete map for each particle is the simplicity: If we ig•    marized as follows: 
nore the cost of block copying maps, lookups and changes 
to the map can all be done in constant time. In these areas,   Proposition 3.2 For a particle filter that maintains P parti•
distributed particle mapping may initially seem less efficient. cles, laser that sweeps out A grid squares, and an ancestry 
However, we can show that DP maps are in fact asymptoti•       tree of depth D, DP-SLAM requires: 
cally superior to the naive approach.                            • O(ADPlgP) operations for localization arising from: 
   Lookup on a DP-map requires a comparison between the 
                                                                      - P particles checking A grid squares 
ancestry of a particle with the balanced tree at that grid 
square. Let D be the depth of the ancestry tree, and thus is          - A lookup cost of O(DlgP) per grid square 
the maximum length of a particle's ancestry. Strictly speak•     • O(APlgP) operations to insert new data into the tree, 
ing, as the ancestry tree is not guaranteed to be balanced, D      arising from: 
can be O(P). However, in practice, this is almost never the 
case, and we have found , as the nature of parti•                     - P particles inserting information at A grid squares 
cle resampling lends to very balanced ancestry trees. (Please         - Insertion cost of O(lgP) per new piece of informa•
see the discussion in the following section for more detail on          tion 
this point.) Therefore, we can complete our lookup after just    • Ancestry tree maintenance with amortized cost 
D accesses to the balanced tree. Since the balanced tree itself    O(ADPlgP) arising from 
can hold at most P entries, and a single search takes 0(lgP) 
time. Accessing a specific grid square in the map can there•          - A cost of O(lgP) to remove an observation or move 
fore be done in O(DlgP) time.                                           it up one level in the ancestry tree 
   For localization, each particle will need to make 0(A) ac•         - A maximum potential of ADP introduced at each 
cesses to the map. As each particle needs to access the en•             iteration. 
tire observed space for its own map, we need O(AP) ac•
cesses, giving localization with DP-maps a complexity of       3.4 Complexity Comparison 
O(ADPlgP).                                                     Our analysis shows that the amortized complexity of 
  To complete the analysis we must handle two remaining        DP-SLAM is O(ADPlgP), which can be as large as 

details: The cost of inserting new information into the map,   0(AP2lgP). For the naive approach, each map is repre•
and the cost of maintaining the ancestry tree. Since we use a  sented explicitly, so lookups can be done in constant time per 
balanced tree for each grid square, insertions and deletions on grid square. The localization step thus takes only O(AP). 
our map both take 0(lgP) per entry. Each particle can make     Without the need for updates to an ancestry tree, map updates 
at most 0(A) new entries, which in turn will only need to be   can likewise be done in O(AP) time. However, the main bulk 
removed once. Thus the procedure of adding new entries can     of computation lies in the need to copy over an entire map for 
be accomplished in O(ADlgP) per particle, or O(ADPlgP)        each particle, which will require 0(MP) time, where M is 


1138                                                                                                          ROBOTICS the size of the map. Since typically this obviously            vironment are made, and no attempt is made to smooth over 
is the dominant term in the computation.                       errors in the map when loops are closed. The precision in 
   DP-SLAM will be advantageous when                           our maps results directly from the robustness of maintaining 
Even in the worst case where D approaches P, there will still  multiple maps. 
be a benefit. For a high resolution occupancy grid, M will be 
quite large since it grows quadratically with the linear mea•  4.1 Robot and Robot Model 
sure of the environment and would grow cubically if we we      The robot we used for testing DP-SLAM is an iRobot ATRV 
consider height. Moreover, A, will be a tiny fraction of M.    Jr. equipped with a SICK laser range finder attached to the 
The size of P will, of course, depend upon the environ•        front of the robot at a height of 7cm. Readings are made 
mental features and the sampling rate of the data. It is impor• across 180°, spaced one degree apart, with an effective dis•
tant to note that since the time complexity of our algorithm   tance of up to 8m. The error in distance readings is typically 
does not depend directly on the size of the map, there will    less than 5mm. 
necessarily exist environments for which DP-SLAM is vastly       Odometric readings from the ATRV Jr.'s shaft encoders are 
superior to the naive approach since the naive approach will   unreliable, particularly when turning. Our motion model as•
require block copying an amount of data will exceed physical   sumes errors are distributed in a Gaussian manner, with a 
memory.                                                        standard deviation of 25% in lateral motion and 50% in turns. 
   In our initial experiments, we have observed that P was     Turns are quasi-holonomic, performed by skid steering. We 
surprisingly small, suggesting that in practice the advantage  obtained our motion model using an automated calibration 
of DP-SLAM is much greater than the worst-case analysis        procedure that worked by positioning the robot against a 
suggests. For some problems the point at which it is advan•    smooth wall and comparing odometry data with the move•
tageous to use DP-SLAM may be closer to .                      ment inferred from the laser readings. 
This phenomenon is discussed in more detail in the subse•
quent section.                                                 4.2 Test Domain(s) and Map(s) 
                                                               We tested the algorithm on a loop of hallway approximately 
4 Empirical Results                                            16m by 14m. A new set of observations was recorded af•
We implemented and deployed the DP-SLAM algorithm on           ter each 20cm motion (approximately). The maps were con•
a real robot using data collected from the second floor of our structed with a resolution of 3cm per grid square, providing a 
computer science building. In our initial implementation our   very high resolution cross section of the world at a height of 
map representation is a binary occupancy grid. When a par•     7cm from the floor. 
ticle detects an obstruction, the corresponding point in the     Figure 1 shows the highest probability map generated after 
occupancy grid is marked as fully occupied and it remains      the completion of one such loop using 9000 particles3. In 
occupied for all successors of the particle. (A probabilistic  this test, the robot began in the middle of the bottom hallway 
approach that updates the grid is a natural avenue for future  and continued counterclockwise through the rest of the map, 
work.)                                                         returning to the starting point. 
   On a fast PC (2.4 GHz Pentium 4), the run time of DP-         This example demonstrates the accuracy of DP-SLAM 
SLAM is close to that of the data collection time, so the algo• when completing a long loop, one of the more difficult tasks 
rithm could have been run in real time for our test domains.   for SLAM algorithms. After traveling 60m, the robot is once 
In practice, however, we collected our data in a log file using again able to observe the same section of hallway in which it 
the relatively slow computer on our robot, and processed the   started. At that point, any accumulated error will readily be•
data later using a faster machine. To speed things up, we also come apparent, as it will lead to obvious misalignments in the 
implemented a novel particle culling technique to avoid fully  corridor. As the figure shows, the loop was closed perfectly, 
evaluating the posterior for bad particles that are unlikely to with no discernible misalignment. 
be resampled. This works by dividing the sensor readings for     To underscore the advantages of maintaining multiple 
each particle into disjoint, evenly distributed subsets. The   maps, we have included the results obtained when using a 
posterior for the particles is computed in passes, where pass  single map and the same number of particles. Figure 2 shows 
i evaluates the contribution from subset At the end of each    the result of processing the same sensor log file by generating 
pass, particles with significantly lower (partially evaluated) 9000 particles at each time step, keeping the single particle 
posterior in comparison to the others are assigned 0 proba•    with the highest posterior, and updating the map based upon 
bility and removed from further consideration. We also set a   the robot's pose in this particle. There is a considerable mis•
hard threshold on the number of particles we allowed the al•   alignment error where the loop is closed at the top of the map. 
gorithm to keep after culling. Typically, this was set to the top Larger, annotated versions of the maps shown here, as well 
10% of the total number of particles considered. In practice,  as maps generated from different sensor logs, will be avail•
this cutoff was almost never used since culling effectively re• able at http://www.es.duke.edu/~parr/dpslam/. 
moved at least 90% of the particles that were proposed. A 
                                                                  3In an earlier version of this paper, we presented a map produced 
value if gave us a speedup of approximately                    with 1000 particles based upon a different sensor log file. The run 
  For the results we present, it is important to emphasize that shown here covers the same area, but has less reliable odometry, 
our algorithm knows absolutely nothing about the environ•      probably due to weaker battery, and is more illustrative of the bene•
ment or the existence of loops. No assumptions about the en•   fits of DP-SLAM. 


ROBOTICS                                                                                                            1139 