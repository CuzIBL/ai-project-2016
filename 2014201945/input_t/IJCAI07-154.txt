               Prediction of Probability of Survival in Critically Ill Patients
                         Optimizing the Area Under the ROC Curve∗
                       Oscar Luaces,Jose´   R. Quevedo, Francisco Taboada†,
                           Guillermo M. Albaiceta†, Antonio Bahamonde
           Artiﬁcial Intelligence Center        †Hospital Univ. Central de Asturias (HUCA)
           University of Oviedo at Gijon´                    University of Oviedo
                  Asturias - Spain                             Asturias - Spain

                    Abstract                          ing functional limitations, major comorbidities, and treatment
                                                      location immediately prior to ICU admission.
    The paper presents a support vector method for es-  These prognostic models are mainly used to measure the
    timating probabilities in a real world problem: the efﬁciency of ICU treatments. The risk stratiﬁcation of pa-
    prediction of probability of survival in critically ill tients allows comparison of the observed outcomes versus
    patients. The standard procedure with Support Vec- accepted standards provided by score functions. ICU assess-
    tors Machines uses Platt’s method to ﬁt a sigmoid ment is very important since it is estimated that end-of-life
    that transforms continuous outputs into probabili- care consumes 10% to 12% of all healthcare costs. More-
    ties. The method proposed here exploits the differ- over, in 2001 the average daily cost per patient in ICUs was
    ence between maximizing the AUC and minimiz-      about $3000 in the USA [Provonost and Angus, 2001].On
    ing the error rate in binary classiﬁcation tasks. The the other hand, the literature also shows that prognoses have
    conclusion is that it is preferable to optimize the constituted an important dimension of critical care, as patients
    AUC ﬁrst (using a multivariate SVM) to then ﬁt a  and their families seek predictions about the duration and out-
    sigmoid. We provide experimental evidence in fa-  come of illness [Lemeshow et al., 1993].
    vor of our proposal. For this purpose, we used data In this paper we propose a new method for learning proba-
    collected in general ICUs at 10 hospitals in Spain; bilities that will be tested on the probabilities of survival in
    6 of these include coronary patients, while the other ICU patients. The method makes intensive use of the so-
    4 do not treat coronary diseases. The total number called Support Vector Machines (SVM), a powerful family
    of patients considered in our study was 2501.     of algorithms for learning classiﬁcation and regression tasks.
                                                      When used for binary classiﬁcation, SVM learn hypotheses
1  Introduction                                       that return continuous numbers: positive values for cases of
                                                      one class, and negative for the other class.
The available models for predicting outcomes in intensive On the other hand, to measure the performance of predic-
care units (ICU) are usually scoring systems that estimate tions in medicine, and in general when classes are very un-
the probability of hospital mortality of critically ill adults. balanced, the misclassiﬁcation rate (or accuracy) is usually
This is the case of APACHE (Acute Physiology And Chronic inadequate. Frequently, the Area Under a receiver operat-
Health Evaluation) [Knaus et al., 1991], SAPS (Simpliﬁed ing characteristic (ROC) Curve (AUC for short) is used. This
Acute Physiology Score) [Le Gall et al., 1984], and MPM amount can be interpreted as the degree of coherence between
(Mortality Probability Models) [Lemeshow et al., 1993]. The a continuous output (such as the probability, or the continuous
score functions of these predictors were induced from data on output of an SVM) and a binary classiﬁcation. It is important
thousands of patients using logistic regression. The data re- to emphasize that that coherence is established in terms of or-
quired by these systems come from monitoring devices, clin- derings. For this purpose, continuous outputs or scores are
ical analysis, and demographic and diagnostic features of pa- used to rank available cases, while classes in the ICU prob-
tients. So, APACHE III includes age, 16 acute physiologic lem are codiﬁed by ‘+1’ when the patient has survived, and
variables that use the worst value from the ﬁrst 24 hours ‘−1’ otherwise.
in the ICU (temperature, heart rate, blood pressure, respira- In this context, Hanley and McNeil [1982] showed that the
tory rate, oxygenation, acid-base status, serum sodium, serum AUC is the probability of a correct ranking; in other words,
blood urea nitrogen, serum creatinine, serum albumin, serum it is the probability that a randomly chosen subject of class
bilirrubin, serum glucose, white cell count, hematocrit, item- ‘+1’ is (correctly) ranked with greater output than a randomly
ized Glasgow Coma Scale score, and urine output), preexist- chosen subject of class ‘−1’. Therefore, AUC coincides with
  ∗The research reported here is supported in part under grant the value of the Wilcoxon-Mann-Whitney statistic.
TIN2005-08288 from the MEC (Ministerio de Educacion´ y Ciencia Additionally, there are other measures of the goodness of
of Spain). The authors acknowledge the work of the Grecia Group probability estimations; for instance, the Brier score is the av-
in the collection of data.                            erage of quadratic deviations of true and predicted probabili-

                                                IJCAI-07
                                                   956ties. The relation between AUC and Brier scores was studied Therefore, we shall assume that the true class probability,
in [Ikeda et al., 2002]. However, the relationship found is Prtrue(y =+1|x),is1 when the class of x, y,is+1 and
guaranteed only under very restrictive conditions that are dif- 0 otherwise.
ﬁcult to check in real world cases. Moreover, the relationship In general, when predictions are discrete probability distri-
is not always direct even in the case study reported in the ex- butions, there is basically one standard loss function: the av-
perimental section of this paper.                     erage quadratic deviation. If there are two possible outputs,
  To learn a probability distribution using SVM, it is crucial the probability loss is given by
to transform their scores or continuous outputs into proba-                     
                                                                            1                2
bilities. But this is what a method presented by Platt [2000]  ΔPr(h, S )=          (h(x ) − p )      (1)
                                                                            |S|        i    i
does. The core idea is to ﬁt a sigmoid, using a maximum                        x ∈S
likelihood procedure. The novelty of the proposal reported                      i
in this paper is that we postulate that to compute Platt’s sig- where the hypothesis h returns the estimation of the probabil-
moid it is better to look for an optimum AUC ﬁrst than to ity h(x)=Pr(y =+1|x), and pi stands for the observed
                                                                                    true
minimize the error rate with a classiﬁcation SVM. For this probability of the i-th case, pi = Pr (y =+1|xi).
reason, in Section 2.3 we shall discuss how to optimize the The measurement in Equation (1) is frequently used in
AUC with a Support Vector method [Herbrich et al., 2000; medicine and meteorology, and is known as the Brier [1950]
Joachims, 2005].                                      index or score. If the number of possible outputs is greater
  The rationale behind our proposal is that the quality of the than two, the estimated probabilities can be seen as a vector,
sigmoid ﬁt depends on the quality of the ranking of the scores. and the Mean Square of the Euclidean (MSE) distance from
If most of the cases with a higher score than a given one of predicted and observed probabilities is then used; see, for in-
class y have a class greater than y, then the task of the sigmoid stance [Melville et al., 2005]. It can be seen that, in the ICU
can be easily accomplished, and the performance of the ﬁnal problem, MSE is 2 times the Brier score.
probability is nearly optimal.
  At the end of the paper we provide experimental evidence 2.2 Optimizing accuracy plus a sigmoidal
in favor of our proposal, comparing it with other alternative transformation
approaches. For this purpose, we used data collected in gen-
                                                      The straightforward approach to the ICU problem is a binary
eral ICUs at 10 hospitals in Spain, 6 of which include coro-
                                                      classiﬁcation SVM followed by a sigmoid estimated using
nary patients, while the other 4 do not treat coronary dis-
                                                      Platt’s method [2000]. Thus, given the training set S, we can
eases. The total number of patients considered in our study
                                                      use a transformation φ deﬁned from input entries in X into a
was 2501, 19.83% of whom did not survive.
                                                      feature space H, where classes should be mostly separable by
                                                      means of a linear function. As is well known, H must have
2  Predicting probabilities                           an inner product , , and
In this section we shall start off by reviewing a standard
                                                                                         
method for learning probabilities based on Support Vector           K(xi,xj)=   φ(xi),φ(xj)           (2)
Machines to then present our proposal. But ﬁrst of all we
must realize that the performance of classiﬁcation learners is is called the kernel function of the transformation. We shall
not satisfactory in the ICU problem; otherwise, nobody would use the rbf kernel that is deﬁned by
                                                                                         2
turn to probabilities. This is a general situation in medicine,                    xi−xj 
                                                                                 −    2
as well as in other ﬁelds; accurate crisp predictions are difﬁ-      K(xi,xj)=e      2σ               (3)
cult to make, but some useful knowledge can be drawn from
data.                                                   The work of the SVM  consists in solving the following
  The section will end with the description of a straight- convex optimization problem:
forward approach for learning probabilities using regression.                     n
                                                                      1
This method will be used as a baseline for measuring the mer-   min    w, w + C    ξi,              (4)
                                                                 w,ξ  2
its of the other options.                                                         i=1
                                                                        w    x      ≥   −
2.1  The goodness of probability predictions                     s.t. yi(  ,φ( i) + b)   1  ξi,
                                                                      ξ ≥ 0,i=1,...,n
Let S = {(x1,y1),...,(xn,yn)} be a training set for a learn-           i
ing task in which a function (or hypothesis) is sought that is Then, the classiﬁcation is accomplished by the hypothesis
able to return outputs yi from entries xi of an input space
X
  . An important issue when we are learning is to ﬁx the               sign(w,φ(xi) + b)            (5)
way in which we are going to measure the quality of the re-
sult. In fact, given S formally, the aim of learning is to ﬁnd a It can be seen that the kernel and the vector α =(αi :
hypothesis h (from a given hypothesis space) that minimizes i =1,...,n) of Lagrange multipliers deﬁne the implementa-
the average loss extended over the set of independently iden- tion of Function (5) computed from input space entries x as
tically distributed (i.i.d.) test sets S, usually represented by follows:
                                                                                                 
Δ(h, S ).                                                                        n
  In the ICU problem, training and test examples have  sign(w,φ(x) + b)=sign      α y K(x  , x)+b   (6)
                                               −                                      i i   i
no probability attached, they are labeled with +1 or 1.                          i=1

                                                IJCAI-07
                                                   957  According to (4), the aim of this function is to maxi- For each x of the input space, the hypothesis so found re-
mize the margin (between classes) and to minimize the train- turns
ing loss. In fact, the sum of the so-called slack variables,            
  n                                                     f(x)=w,φ(x)  =     α  (K(x  , x)−K(x  , x)) (12)
  i=1 ξi, is an upper bound of misclassiﬁcations of (6) on                    i,j    i         j
the training set. It is acknowledged that the Function (6) so            yi>yj
achieved has good classiﬁcation accuracy on unseen cases.
  In order to compute the probabilistic outputs, we get rid of where αi,j are again the Lagrange multipliers computed by
the sign function, and we only consider the continuous out- the optimizer.
puts                                                    Unfortunately, this approach leads to dealing with one con-
                          n                          straint for each element of the dataset
   fac(x)=w,φ(x)   + b =    αiyiK(xi, x)+b    (7)
                                                              S¯ = {(xi, xj; +1) : yi =+1>yj = −1}   (13)
                          i=1
  Platt’s method then ﬁts a sigmoid to estimate probabilities: whose size is the number of positive (class +1) examples
                                                      times the number of negatives, #pos×#neg, i.e. O(n2) when
       x              |x           1
   hac( )=Pr(y   =+1    )=         ·  (x)+      (8)   the size of S is only n. This means that some applications
                            1+eAac fac   Bac
                                                      become intractable, although the approach (or a simpliﬁed
  Figure 1 depicts the ﬁt of this sigmoid to the dataset of version of it) has been successfully used on other occasions
all patients (2501) at all the available hospitals. Notice that [Joachims, 2002; Bahamonde et al., 2004].
the fac values follow a bell-shape distribution with most in- To alleviate the difﬁculties caused by the size of data sets, it
dividuals having positive values, which means that they have is not straightforward to reformulate Herbrich’s approach as
a survival prediction.                                an optimization problem with a small number of constraints.
2.3  Optimizing the AUC ﬁrst                          The main problem is that the loss function (1-AUC) (see
                                                      Equation (9)) cannot be expressed as a sum of disagreements
When classiﬁcation predictions are made comparing the val-
                                                      or errors produced by each input x .
ues returned from patients’ descriptions x by a rating function                    i
                                                                                            [    ]
with a threshold, as in classiﬁcation SVM (see Equation (5)), Following a different procedure, Joachims 2005 recently
then the performance of these predictions can be assessed us- proposed a multivariate approach to solve this problem with a
ing the AUC. According to its probabilistic interpretation, the convex optimization problem that converges using only a few
complementary of this amount (1-AUC) can be used as a loss constraints.
function. Thus, if g is a hypothesis, its loss evaluated on a test The optimization problem is:
    
set S is                                                        1
                                                     min     w, w + Cξ                        (14)
   ΔAUC  (g, S )=Pr(g(x     ) ≤ g(x )|y >y )=              w
                          i       j  i   j                 ,ξ  2   
                         :   1 (x )≤ (x )                                 
                       i,j yi>yj g i g j                   s.t. w,     (1 − y )(φ(x ) − φ(x ))≥
                 =                             (9)                          i,j    i       j
                                                                  yi>yj
                            i,j 1yi>yj
                                                                   ≥                     −
  Let us stress that the explicit objective of SVM presented in      ΔAUC  ((1,...,1)(yi,j )) ξ
the preceding section is not to minimize Equation (9). [Cortes  ∀   ∈{    −  }#pos·#neg −{        }
                                                                 yi,j   +1,  1             (1,...,1)
and Mohri, 2004] provide a detailed statistical analysis of the
difference between maximizing the AUC and minimizing the Despite the enormous potential number of constraints, the
error rate in binary classiﬁcation tasks.             algorithm proposed in [Joachims, 2005] converges in poly-
  Herbrich et al. [2000] presented a direct implementation nomial time. Moreover, it only requires a small set of con-
that solves a general ranking problem that is applicable to straints. However, the most interesting result is that the so-
maximizing the AUC. The core idea is that if a hypothesis lution w of problem (14) is also the same as that of the op-
     X   →  R                               x
f : φ( )      is linear and has to fulﬁll that f(φ( i)) > timization problem (11). Additionally, the slack variables in
    x
f(φ( j)), since yi >yj, then                          both cases are related by

   f(φ(xi)) >f(φ(xj)) ⇔ f(φ(xi) − φ(xj)) > 0.  (10)                            
                                                                         ξ =2      ξ                 (15)
  Notice that this statement converts ordering constraints into                     i,j
classiﬁcation constraints (with one class), but now the input                 yi>yj
space is X×Xand each pair (xi, xj) is represented by the
           x  −    x                                    Finally, the multivariate SVM returns a function fAUC of
difference φ( i) φ( j). According to this approach, the the form
aim is to ﬁnd a hypothesis f(x)=w,φ(x) such that w
                                                                           x    w    x 
solves the following convex optimization problem:                     fAUC ( )=    ,φ( ) .           (16)
                          
             1
       min    w, w + C        ξ              (11)     Then Platt’s method can ﬁt a sigmoid to transform the out-
       w                        i,j
        ,ξ   2                                        put of fAUC into a probability.
                        i,j:yi>yj
        s.t. w,φ(x )−w,φ(x   )≥1  − ξ  ,                                             1
                   i           j         i,j           h    (x)=Pr(y  =+1|x)=                        (17)
                                                        AUC                         AAUC ·fAUC (x)+BAUC
            ξi,j ≥ 0, ∀i, j : yi >yj                                            1+e

                                                IJCAI-07
                                                   958                      1                                                        18.0 %

                     0.9                                                       16.2 %

                     0.8                                                       14.4 %

                     0.7                                                       12.6 %

                     0.6                                                       10.8 %

                     0.5                                                        9.0 %

                     0.4                                                        7.2 %

                     0.3                                                        5.4 %

                     0.2                                                        3.6 %

                     0.1                                                        1.8 %

                      0                                                         0.0 %
                       3       2       1        0        1        2         3

Figure 1: The ﬁt of the sigmoid to the dataset of all patients (2501). The horizontal axis represents the outputs of an SVM.
Each ‘*’ mark is the average posterior probability for all examples falling into a bin of width 0.2. The sigmoidal function is
the estimation computed by Platt’s method [2000] (the output values are labeled on the left vertical side), while the bell-shaped
function is the histogram for Pr(f(x)) for all the examples (frequencies are labeled on the right).

2.4  Regression is a baseline approach                3   Experimental results
Considering that probabilities are real numbers, regression al- Using a collection of data sets of survival probabilities in crit-
gorithms must be a ﬁrst attempt to learn them. For this pur- ically ill patients, we carried out an experimental compar-
pose, all training examples of class −1 are labeled as 0. ison of four different learning approaches. SVM followed
  In order to maintain the uniformity of approach with pre- by Platt’s ﬁt of a sigmoid: the accuracy optimizer described
ceding subsections, we considered the regression based on in subsection 2.2, which will be represented by SVM(Accu);
support vectors, therefore we used the so-called Support Vec- the multivariate version, aimed at optimizing the AUC (sub-
tor Regression (SVR). Although there are least squares SVR, section 2.3), for short SVM(AUC); and ﬁnally the regression
we used the standard version; i.e. a learner of a function approach, SVR (subsection 2.4). The fourth predictor used
                 n                                   was the commercial system APACHE III; we used the cus-
                      −     +            ∗
        f  (x)=     (α  − α  )K(x , x)+b       (18)   tomization described in [Rivera-Fernandez´ et al., 1998] that
         Re           i    i      i                   was developed to improve its performance in Spain.
                 i=1
                                                        First of all, we have to point out that this is an unfair
where K is once again the rbf (3) kernel, and αi are the La- comparison, since APACHE III was trained with a cohort
grange multipliers of the solution to the convex optimization of 17440 patients from 40 different hospitals in the USA
problem:                                              [Knaus et al., 1991]; the Spanish version used records of
                          n                          10929 patients from 86 ICUs; while the available data sets in
              1w  w          +    −                 our experiments only included 2501 patients. Nevertheless,
        min       ,   + C    (ξi + ξi ),       (19)
         w,ξ  2                                       this comparison is useful to test whether or not the scores
                          i=1
               w   x       −   ≤      +             achieved by SVM methods are good enough to be considered
         s.t. (  ,φ(  i) + b)  yi   + ξi ,           for future learning tasks.
                −  w    x      ≤      −
              yi  (   ,φ( i) + b)   + ξi ,             To estimate the performance of the algorithms described in
               +  −
              ξ ,ξ  ≥ 0,i=1,...,n                     the preceding section, we used data collected from ICUs at
               i  i                                   10 different Spanish hospitals, 6 of which include coronary
  However, given that nothing forces fRe (18) outputs to be patients. It is acknowledged among the medical community
in [0, 1], we set the hypothesis output to 1 whenever fRe re- that coronary diseases generally have a lower mortality risk
turns values above 1, and 0 for fRe values below 0. In sym- than other critical illnesses. So from a learning perspective, it
bols, ﬁnally we have the hypothesis                   makes sense to differentiate between ICUs with and without
                                                      coronary patients.
              x        {     {      x }}
          hRe( )=max    0, min 1,fRe( )        (20)     The data were organized in 13 different training sets, one

                                                IJCAI-07
                                                   959                                SVM(AUC)          SVM(Accu.)            SVR            APACHE III
    # patients  Hospitals      Bs    AUC (%)     Bs     AUC (%)     Bs    AUC (%)     Bs     AUC (%)
       108          1        0.1712    75.82   0.1860    70.60    0.2019    69.86    0.1473   81.76
       189          2        0.1887    73.51   0.1998    69.23    0.2444    63.79    0.1710   77.80
       194          3        0.1735    75.32   0.1897    65.88    0.1976    70.64    0.1592   78.20
       194          4        0.1089    77.20   0.1142    74.93    0.1260    74.35    0.0961   86.17
       195          5        0.1102    84.44   0.1094    82.41    0.1078    85.33    0.1079   88.78
       239          6        0.1569    74.87   0.1637    69.12    0.1666    71.91    0.1459   77.62
       269          7        0.0993    81.09   0.1096    75.75    0.1044    80.47    0.0852   88.02
       297          8        0.1205    84.86   0.1277    81.44    0.1301    80.98    0.1127   87.37
       337          9        0.1096    81.35   0.1128    77.91    0.1099    79.87    0.1071   81.30
       479         10        0.1071    79.32   0.1120    71.74    0.1198    72.74    0.1218   78.22
           Averages          0.1346    78.78   0.1425    73.90    0.1509    74.99    0.1254   82.52
       919      {2,3,6,8}    0.1494    79.75   0.1500    78.46    0.1546    76.72    0.1432   80.86
      1582    {1,4,5,7,9,10} 0.1086    81.79   0.1108    80.37    0.1082    80.08    0.1094   82.63
      2501         all       0.1234    81.51   0.1229    81.22    0.1234    80.85    0.1218   82.27

Table 1: Brier scores (Bs) and AUC estimated by a 10-fold cross-validation for the three learners described in the text, and
for the commercial system APACHE III. All differences from SVM(AUC) are signiﬁcant according to a one tail t-test with
threshold p<0.01, considering the results on the 10 hospitals. For ease of reading, AUC scores are represented as percentages.

for each single hospital, two collecting the data from not coro- and SVR; and C =10−1 and σ =10−2 for multivariate
nary/coronary ICUs respectively, and the last one containing SVM(AUC). It is worth noting that for SVM and SVR the
all the data. Each patient in these data sets was described parameter search was aimed at minimizing the Brier score,
by the same set of variables used by APACHE III. However, while for multivariate SVM it was aimed at maximizing the
given that some of these variables have discrete values, we AUC.
had to transform them to be handled by SVM-based systems. Table 1 shows the results obtained (Brier score and AUC)
Thus, we codiﬁed each discrete variable using as many new in the experimental setting described above. Focusing on the
binary variables (with values 0 and 1) as the number of pos- results obtained by the three support vector algorithms, we
sible values of the original variable, setting only the variable can observe that, in general, the best performance (lowest Bs
corresponding to the discrete value actually taken by the orig- and highest AUC) is achieved by multivariate SVM(AUC).
inal variable to ‘1’.                                 The differences are statistically signiﬁcant according to a one
  Performance estimations were made using a 10-fold strat- tail t-test with threshold p<0.01. This should not be surpris-
iﬁed cross-validation on each of the data sets, for all the al- ing for the AUC measure, since this algorithm was specially
gorithms except for APACHE III; since it was already trained devised to optimize such a measure. But it also outperforms
with a different data set, we used the available data to test its SVM and SVR in terms of the Brier score, whose parameters
predictions. Additionally, the data was standardized accord- were set to optimize this score.
ing to the mean and deviation observed on each training fold. Let us stress that, although the optimization problem posed
  It is important to recall that the AUC achieved by the to SVR is precisely the minimization of the distance between
Spanish version of APACHE III in our experiments, 82.27% true and predicted probabilities, a large amount of data is re-
(in percentage) is similar to the amount reported by Rivera- quired to tie the scores of SVM(AUC) in the Brier score. The
Fernandez´ et al. [1998]: 81.82%. This fact supports the rep- underlying reason explaining this behavior may be that the
resentativeness of the sample of critically ill patients consid- hypothesis space used by SVR is not adequate so as to induce
ered in the experiments described here.               probability distributions from a reduced set of training data,
  As usual, when dealing with SVM, the parameter setting even with an rbf kernel.
stage is very important. To set the regularization parameter As regards the data sets used in the experiments, support
C (see optimization problems in Section 2) and the rbf kernel vector machines yielded the worst performance on the ﬁrst
parameter σ (see Eq. (3)) in the three support vector based three data sets, i.e. the smallest. SVR performance was par-
algorithms, we performed a grid search on a validation set ticularly poor on these data sets. Considering that the rows of
formed by the patients at 3 hospitals: one hospital without Table 1 are in ascending order of size of the data set, the trend
coronary patients (8), and 2 with coronary patients (1 and 9); indicates that performance could be improved if more train-
see Table 1. The ranges searched were the following: for C ing cases were available. In fact, when the data set included
we tested values from 10−4 to 102 varying the exponent in all available patients’ records, the results obtained were simi-
steps of 1; for σ we tested values from 10−2 to 101 varying lar to those yielded by APACHE III (recall that it was trained
the exponent in steps of 0.5. We found that the most promis- with data sets that were several times bigger). On the other
ing values were C =101 and σ =10−2   for SVM(Accu)    hand, we also observe that survival predictions seem to be

                                                IJCAI-07
                                                   960