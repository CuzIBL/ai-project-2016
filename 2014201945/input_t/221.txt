         Learning Consumer Photo Categories for Semantic Retrieval 

                         Joo-Hwee Lim                                          Jesse S. Jin 
               Institute for Infocomm Research                      University of New South Wales 
       21 Hcng Mui Keng Terrace, Singapore 119613                        Sydney 2052, Australia 
                    joohwee@i2r.a-star.edu.sg                             jesse@cse.unsw.edu.au 


                       Abstract 

     In this paper, wo develop a computational 
     learning framework to build a hierarchy of 
     11 consumer photo categories for semantic re•
     trieval. Two levels of visual semantics are 
     learned for image content and image category 
     statistically. We evaluate the average precisions 
     at top retrieved photos on 2400 heterogeneous 
     consumer photos with very good result. 

1 Introduction 
Research on image categorization has received more at•           Figure 1: A hierarchy of consumer photo categories 
tention lately. In particular, the efforts to classify photos 
based on contents have been devoted to: indoor ver•
                                                               image category level, we learn image category models 
sus outdoor [Bradshaw, 2000], natural versus man-made 
                                                               with small number of labeled photos to compute the rel•
[Bradshaw, 2000; Vailaya et al., 2001], and categories of 
                                                               evance measure of photos in a winner-take-all approach. 
natural scenes [Vailaya et al., 2001]. In general, the clas•
sifications were made based on low-level features such as      1.1 Learning Semantic Support Regions 
color, edge directions etc and [Vailaya et al., 2001] pre•
                                                               SSR are salient image patches that exhibit semantic 
sented the most comprehensive coverage of the problem 
                                                               meanings to us. A cropped face region, a typical grass 
with a hierarchy of 8 categories. 
                                                               patch, and a patch of swimming pool water etc can all 
   In this paper, we deal with a more comprehensive hier•
                                                               be treated as their instances. To compute the SSR from 
archy of 11 categories (Fig. 1) for 2400 consumer photos. 
                                                               training instances, we adopt support vector machines. 
These photos (Fig. 2), including photos of bad quality, 
                                                               We extract suitable features such as color and textures 
present a real spectrum of complexities when compared 
                                                               for a local image patch and denote this feature vector 
to the photos used in previous works [Bradshaw, 2000; 
                                                               as x. A support vector classifier S   devoted to a class i 
Vailaya et al., 2001], which are mainly professional pho•                                          i
                                                               of SSR is treated as a function on x, S    (x). Then the 
tos from the Corel stock photo library. Furthermore,                                                      l
                                                               posterior probability of class i can be computed as 
only 20% of our test collection is used for training and 
we evaluate our approach in terms of average precisions 
(over 10 runs) of semantic retrieval at top retrieved pho•                                                            (1) 
tos which is important for practical usage. Our approach 
is unique that we compute uniform semantic features at         For the experiments described in this paper, since we are 
both image content and image category levels using a           dealing with heterogeneous consumer photos, we adopt 
computational learning framework instead of low-level          color (means and standard deviations of each color chan•
features crafted for different categories.                     nel) and texture features (means and standard devia•
   At the image content level, salient image regions that      tions of Gabor coefficients) to characterize SSR. 
exhibit semantic meanings are adopted as training exam•          To detect SSR with translation and scale invariance in 
ples to construct semantic support regions (SSR) that          an image, the image is scanned with windows of different 
span a new indexing space. Local image regions of a            scales. To reconcile the detection maps across different 
photo is projected into this space as linear combinations      resolutions onto a common basis, we adopt the following 
of the SSR and further aggregated spatially to form im•        principle: If the probability of the most probable class 
age content signature for similarity matching. At the          of a region j at resolution k is less than that of a larger 


POSTER PAPERS                                                                                                        1413  region (at resolution k+ 1) that subsumes region j, then        We used 20% of the 2400 photos for training. We gen•
 the classification probabilities of region j should be re•    erated 10 different sets of positive training samples from 
 placed by those of the larger region at resolution k -f 1.    the ground truth list for each category based on uniforrr 
 To aggregate the classification probabilities of the recon•   random distribution. The negative training samples ofa 
 ciled detection map for a spatial area X that comprises of    given category are positive training samples from other 
 x small equal regions with feature vectors                    categories that do not overlap with the category. The 

 we compute the expected value of over x3 as                   evaluation of retrieval precision is carried out hierarchi•
                since P(XJ) are equal for all small regions    cally with respect to the category tree in Fig. 1. The 
 j. The similarity between two corresponding blocks X          test data for the category of a child node of a run is the 
                                                         3     ground truth list of its parent node minus the training 
 in image X and Yj in image Y is computed as cosine 
                                                               samples used for learning the category of the child node-
 between the probability vectors and  in the run. For example, to evaluate the retrieval perfor•
 The overall similarity between X and Y is the average         mance of nature (natr) photos, the ground truth list of 
 of the cosine values over all blocks.                         outdoor less the training sample for building the nature 
                                                               category is taken as the test data. The learning and re•
 1.2 Learning Semantic Image Categories                        trieval of each category were performed 10 times and the 
                                                               average precisions (over 10 runs) of te>p retrieved images 
 A photo category Mi is also learned using support vector 
                                                               are given in Table 1. 
 machines. The input patterns to Mi are the indexes of 
 the images The support vector learning 
 computes the support images for the categories from a 
                                                                Table 1: Average precisions at te)p numbers of photos 
 set of labeled photos. Given an unlabeled photo of index 
 Z, the output of a category Mi is S{Mj,Z). With the              [ Avg.Prec.    Size   Top 20     Top 30    Top 50 
 winner-take-all approach, we compute the winner k as 
                                                                       indr       994"    0.94      0.96      0.96 
 A: = argmaxiS(Mi, Z). Then the relevance measure of 
                                                                      outd       1218     1.00      1.00      1.00 
 Z to category M, is defined as 
                                                                       inpp       860     0.99      0.99      0.99 
                                                       (2)             inob       134     0.84      0.75      0.56 
                                                                       natr       521     0.96      0.96      0.95 
2 Empirical Evaluation                                                 city       697     0.95      0.94      0.93 
                                                                       park       304     1.00      0.99      0.98 
From the 2400 photos, we define ground truth lists for                mtrk         67     0.41      0.27      0.16 
the 11 categories. Their sizes are listed in Table 1 as               wtsd        150     0.92      0.89      0.66 
breadth-first order of Fig. 1 and examples are shown in                pool        52     0.47      0.32      0.21 
Fig. 2. We designed 2G classes of SSR: people (face, fig•              strt       645     0.99      0.99      0.99 | 
ure, crowd, skin), sky (clear, cloudy, blue), ground (floor, 
sand, grass), water (pool, pond, river), foliage (green, flo•
ral, branch), mountain (far, rocky), building (old, city, far),  From Table 1, we observe that up to first 50 images, a 
interior (wall, wooden, china, fabric, light). We cropped      user (on average) gets almost all relevant photos of the 
554 image regions from 138 images and used 375 of them        respective categories except less so for categories inte-
as training data for support vector machines to compute       rior/object (inob) and waterside (wtsd), and even less sc 
the SSR and the remaining 179 as test data to gauge gen•      for categories mountain/rocks (mtrk) and swimming poo! 
eralization performance. Among all the kernels tried, a        (pool). The reasons for poorer performance are 2-fold 
polynomial kernel with degree 2 and constant 1 gave the        First these categories have much fewer positive train•
best result on precision and recall.                           ing samples (i.e. 27,30,13,10). Next, they comprise 
                                                              images of varied contents (c.f.Fig. 2: objects plus inte•
                                                              rior, mountain and rocks, lakeside plus beach, pool wit! 
                                                              and without water as focus). We believe that with more 
                                                              training samples, their performance would be raised. 

                                                              References 
                                                               [Bradshaw, 2000] B. Bradshaw. Semantic based image 
                                                                   retrieval: a probabilistic approach. In Proc. of ACM 
                                                                   Multimedia, pp. 167-176, 2000. 
                                                               [Vailaya et al., 2001] A. Vailaya et al. Bayesian frame•
                                                                   work for hierarchical semantic classification of va•
Figure 2: Two sample photos for each category (top-                cation images. IEEE Trans, on Image Processing 
down, left-to-right): indr, outd, misc, inpp, inob, city, natr,    10(1): 117-130, 2001. 
pool, strt, wtsd, park, mtrk 


1414                                                                                                   POSTER PAPERS 