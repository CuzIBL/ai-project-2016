                          Estimating the Rate of Web Page Updates

                                        Sanasam Ranbir Singh
                                 Indian Institute of Technology Madras
                           Department of Computer Science and Engineering
                                           Chennai-36, India
                                       ranbir@lantana.tenet.res.in

                    Abstract                          estimating their changing rate can beneﬁt in improving Web
                                                      crawler’s scheduling policy, Web page popularity measure,
    Estimating the rate of Web page updates helps in  preprocessing the accessed schedules etc. This is the main
    improving the Web crawler’s scheduling policy.    motivation of this work. Another question that is attempted
    But, most of the Web sources are autonomous and   to answer in this paper is the localized rate of changes of the
    updated independently. Clients like Web crawlers  sources. For example, At what rate was a Web page updated
    are not aware of when and how often the sources   during the month of January last year? How does the rate of
    change.  Unlike other studies, the process of     updates change during the month of January for the last ﬁve
    Web page updates is modeled as non-homogeneous    years? This paper focuses mainly on estimating localized rate
    Poisson process and focus on determining local-   of updates rather than global update rates. Since the rate of
    ized rate of updates. Then various rate estimators updates of the sources may vary with time, localized estima-
    are discussed, showing experimentally how precise tion provides more detail, useful and accurate information.
    they are. This paper explores two classes of prob-
                                                        Contrast to the previous studies [Cho and Garcia-Molina,
    lems. Firstly the localized rate of updates is esti-
                                                      2003; Matloff, 2005], the process of Web page updates is
    mated by dividing the given sequence of indepen-
                                                      modeled as time-varying Poisson process. It is because of the
    dent and inconsistent update points into consistent
                                                      fact that sources are updated by its owner autonomously and
    windows. From various experimental comparisons,
                                                      independently whenever there are new developments and the
    the proposed Weibull estimator outperforms Du-
                                                      rate of updates may vary with time. Therefore, it is more ap-
    ane plot(another proposed estimator) and other es-
                                                      propriate to assume the update process as a time varying Pois-
    timators proposed by Cho et la. and Norman Mat-
                                                      son process rather than time homogeneous Poisson process.
    loff in 91.5%(90.6%) of the whole windows for
                                                      The advantage of modeling the problem as non-homogeneous
    synthetic(real Web) datasets. Secondly, the future
                                                      Poisson process is its wide range of ﬂexibilities. It can be
    update points are predicted based on most recent
                                                      noted that homogeneous Poisson process is a special case
    window and it is found that Weibull estimator has
                                                      of non-homogeneous Poisson process. A major difﬁculty in
    higher precision compared to other estimators.
                                                      modeling the problem as non-homogeneous Poisson process
                                                      is that it has inﬁnitely many parameters. In particular, it is
1  Introduction                                       parameterized by its arrival-rate λ(t), which varies with time.
Most of the information available on the Web are autonomous To simplify the problem, the attention is restricted to certain
and are updated independently of the clients. Estimating the assumptions of λ(t) i.e., constant, increasing or decreasing.
rate at which Web pages are updated, is important for Web Such assumption help in reducing the number of parameters.
clients like Web crawlers, Web caching etc. to improve their This assumption may not be correct over a long period of ob-
performance. Since the sources are updated on their own, servations (say, over years of page update records), but rea-
such a client does not know exactly when and how often the sonable over appropriate subintervals (say, over few weeks).
sources change. Web crawlers need to revisit the sources re- Therefore, the whole observation space is divided into a se-
peatedly to keep track of the changes and maintain the repos- quence of windows of consistent behavior (see Section 4).
itory upto-date. Further, if a source is revisited before it is The above assumption is reasonable as this paper is focussed
changed, then it will be a wastage of resources such as CPU more on the instanteneous page update rates.
time, ﬁle system and network bandwidth for both client and
server. Such a visit is deﬁned as a premature visit. For a client 1.1 Accessing the Web pages
like a Web crawler with a collection of thousands of millions One major problem in modeling the changing behavior of
of such sources, it is important to schedule its visits optimally Web page is that, the complete information of the sequence
such that number of unobserved changes between the subse- of updates is not available. Web pages are accessed repeat-
quent visits and the number of premature visits are minimum. edly through normal activities such as periodic crawling of
Therefore, study of the changing behavior of web pages and web pages. It is only possible to determine, whether a page

                                                IJCAI-07
                                                  2874had changed, but not possible to determine the number of modeling the process as a non-homogeneous Poisson process
changes between two subsequent accesses, which results in includes the ability to determine the instantaneous update rate
loss of information. The accuracy of the estimation of the rate i.e., λ(t). In summary, this paper makes the following contri-
of changes depends on how small the number of unobserved butions:
updates is.                                             -handles the last date of change and existence of change
  Assuming that the Web pages are accessed periodi-   cases identically.
cally with a small interval τ,letm(i) be the number of  -models the system as a non-homogeneous Poisson pro-
page updates between the (i − 1)th and ith accesses and cess.
{t(i,1),t(i,2),t(i,3), ..., t(i,m(i))} be the time sequence of cor- -proposes two λ(t) estimators namely Weibull estimator
responding updates. The changes can be observed in the fol- and Duane plot estimator and compares the estimates using
lowing two ways:                                      various datasets with the estimators proposed in existing lit-
-Last date of change: Some Web servers provide the in- eratures.
formation about when the page was last modiﬁed. It is   The rest of the paper is organized as follows. Section 2 dis-
not possible to obtain the complete update information be- cusses non-homogeneous Poisson distribution. In Section 3,
tween accesses. In such case, we only observe t(i,m(i)) and we discuss different estimators of rate of updates. In Sec-
{t(i,1),t(i,2),t(i,3), ..., t(i,m(i)−1)} are left unobserved. There tion 4, we divide the whole observation space into windows of
is no way to obtain the unobserved information. Assuming consistent behavior. Experimental veriﬁcations are discussed
that m(i) is small, we ignore the unobserved updates and in Section 5. Then we conclude the paper in Section 6.
count only one update during ((i − 1)τ,iτ] if changes occur
and consider t(i,m(i)) as the renewal point.          2   Non-homogeneous Poisson Process
-Existence of change: Some Web servers do not provide A non-homogeneous Poisson process over [0, ∞] is deter-
such information i.e., last date of change. In such case, it mined by a rate function λ(t) ≥ 0, known as intensity density
is only possible to determine whether the page has changed of the process (see Chapter 6, Trivedi [Trivedi, 1982]). Let
between accesses comparing with the old image of the page. N(T ) be the number of updates during the time period (0,T].
We can not even determine t(i,m(i)). It could have changed Then, the intensity function of the process, i.e. mean number
any number of times anywhere between (i − 1)th access and of updates during the period (0,T] is deﬁned as follows.
th                                                                                      
i  access, i>0. If changes occur, it is counted as one.                     T             ∞
                                                         μ(T )=E(N(T  )) =  0 λ(t)dt, for 0 λ(t)dt = ∞
1.2  Formulating the Process                          Now, the probability that the number of updates during the
                                                      period (0,T] equals to k,isgivenby
In the studies [Cho and Garcia-Molina, 2003; Matloff, 2005],                          k
                                                                                 [μ(T )] −μ(T )
the two classes of observing updates are handled separately.     Pr[N(T  )=k]=          e
Unlike these studies, the observed information is prepro-                          k!
cessed and a model is formulated to handle both the cases for k =0, 1, 2,... The Time homogeneous Poisson pro-
identically simplifying the problem. For the case of last date cess is a special case, where λ(t)=λ for all time instances
                                                       ≥
of change,thet(k,m(k)) is considered as the update point of t 0. Now, the probability of N(T ) becoming zero is equal
                                                                         −μ(T )
the kth interval and the process of update time is formulated to Pr[N(T )=0]=e . Thus we can write its cumula-
                                                                                           −  −μ(T )
as {t(i) | t(i)=t(k,m(k)),i= N(kτ),i,k >0},whereN(t)  tive distribution function (cdf)asF (T )=1 e and its
                                                                                                 −μ(T )
is the number of updates during the period (0,t].     probability density function (pdf)asf(T )=μ (T )e =
                                                             T
  For the case of existence of change,thet(k,m(k)) is not  −   λ(t)dt
                                                      λ(t)e  0      . Using the expression of F (t) and f(t)
available. Assuming that sources are accessed periodically above, the instantaneous λ(t) can be expressed as
with an optimal interval, we can approximate t(i),saythe
middle point or the end point of the period or a point de-                       f(t)
                                                                        λ(t)=                         (1)
termined from an appropriate distribution. Here, the t(i) is                   1 − F (t)
approximated as the middle point and the process of update
time is formulated as {t(i) | t(i)=(k − 1)τ + τ/2,i = 3   Estimating  λ(t)
N(kτ),i,k >0},whereN(t)   is the number of observed up-
dates during the period (0,t].                        As stated in Section 1, the whole observation space is divided
                                                      into a sequence of windows of consistent behavior. A win-
  Thus, the time sequence {t(i):i =0, 1, 2, ...} represents
                                                      dow is a sequence of update points satisfying the property that
the sequence of the update points for both the cases satisfy-                              th
                                                      t(i) >t(i − 1),wheret(i) is the time of the i update. Since
ing the properties t(0) = 0 and t(i) <t(i +1),wheret(i) is
             th                                       the sequence of update points are independent and identically
the time of the i update. Since the client does not know ex-
                                                      distributed and satisﬁes the memoryless property, each win-
actly when and how often the Web page updates, the sequence
                                                      dow can be processed independently to determine the λ(t).
{t(i):i =0, 1, 2, ...} is an independent and identically dis-
tributed random process, which is often modeled as a Poisson Deﬁnition 1 A window is said to be consistent, iff either one
process in several studies [Brewington and Cybenko, 2000; of the followings is true.
Cho and Garcia-Molina, 2003; Matloff, 2005]. This study 1. λ(t(i)) <λ(t(j)), ∀i<j,j>0 i.e., increased
also assumes the model as a Poisson process, but as a non- 2. λ(t(i)) >λ(t(j)), ∀i<j,j>0 i.e., decreased
homogeneous Poisson process. One of the advantages of 3. λ(t(i)) = λ(t(j)), ∀i<j,j>0 i.e., constant

                                                IJCAI-07
                                                  28753.1  Intuitive Measure: N(t)/t                        Taking partial derivative w.r.t. c and equating to zero, we get

If N(t) is the number of updates during the period (0,t],                       tn
the rate of updates at the time t is λ(t)=N(t)/t and in-                   ηˆ = 1/β .                 (4)
stantaneous mean time between updates (MTBU) at time t,                        n
MTBU(t)=t/N(t). This estimation is suitable when the  Again, taking partial derivative w.r.t. β and equating to zero,
window satisﬁes the third consistency property i.e., the rate of we get
update is constant. It is the biased estimation of λ(t) in a ho-
                                                                          n               n
mogeneous Poisson process [Cho and Garcia-Molina, 2003].      βˆ =           n      =  n     t       (5)
                                                                       n −         i           n
                                                                   n ln t    i=1 ln t    i=1 ln ti
3.2  Estimation using Weibull Distribution
                                                                ˆ                                    n
If the rate of update is either increasing or decreasing or con- Lemma 1 β is biased for small value of n and equal to n−2 β
stant, the Weibull distribution is a good mechanism to model
the process. The two parameter Weibull pdf is given by Proof As reported in [Calabria et al., 1988], 2nβ/βˆ ∼ Z,
                                                      where Z  is a chi-square random variable with 2(n − 1)
                        β−1                                                                     2nβ
                                    β                                                       ˆ
                   β   t       −(t/η)                 degree of freedom. Then we can write  β  =   Z   =
             f(t)=            e      ,          (2)       2nβ    n−2 −t/2
                    η  η                                     n−1 t  e   .   Now, the expectation of βˆ can
                                                      Γ(n−1)2                          
                                                                                 2nβ     ∞ n−3  −t/2
where β is known as shape parameter and η is known as scale be derived as E[βˆ]=    n−1    t   e   dt  =
                                         [                                   Γ(n−1)2    0
parameter and β,η > 0 (see Chapter 2, Patrick O’Connor,     2nβ         −    n−2     n
2002], [Lieblein, 1955]). Then its cdf is given by F (t)= (n−2)Γ(n−2)2n−1 Γ(n 2)2 = n−2 β.Ifn is small, then
         β
1 − e−(t/η) . Substituting equation 2 and F (t) in equation 1, βˆ is biased. 2
we get
                           β−1                        Now, Lemma 1 suggests correcting the ML by a factor of
                       β   t                             −
                 λ(t)=                          (3)   (n   2)/n and thus obtain
                        η  η
                                                                        n − 2      n − 2
From the study [Lieblein, 1955],wehave(1)ifβ =1,then               β˜ =      βˆ = n     t .
                                                                         n            ln n
λ(t)=1/η, a constant (the process reduces to the homo-                             i=1   ti
geneous Poisson process), (2) if β<1,thenλ(t) decreases                         ˜                   ˜
as t increases and (3) if β>1,thenλ(t) increases as t in- We can easily prove that E[β] is unbiased i.e., E[β]=
                                                         n−2 ˆ     n−2   ˆ                           tn
creases. A window is always in one of the above three states. E[ n β]= n E[β]=β.   Thus we get η˜ = n1/β˜ .
Therefore, Weibull’s distribution is obviously a good choice Substituting the value of β˜ and η˜ in equation 3, we deter-
of estimating  .                                                                β˜−1 β˜
           λ(t)                                       mine the value of λ˜(t)=nβt˜  /t .In[Calabria et al.,
  In [Tsokos, 1995], the author found the relationship be-                           n
                                                          ]                ˜                      ˜
tween MTBU(t)  and λ(t) as follows.                   1988 , it is proved that λ(t) is less biased i.e., E[λ(t)] =
                     ⎧                                λ(t)(n − 2)/(n − 3). Again, we correct λ˜(t) by a factor
                     ⎪      1                           −       −
                     ⎨  =  λ(ti) for β =1             (n  3)/(n  2) to get an unbiased estimation and thus obtain
                            1
        MTBU(ti)=       >  λ(ti) for β<1
                     ⎩⎪     1                                        n − 3      (n − 3)n  β˜−1 β˜
                        <       for β>1                       λˇ(t)=      λ˜(t)=        βt˜  /tn.
                           λ(ti)                                     n − 2        n − 2
Thus, 1/λ(t) deﬁnes the bounds of MTBU(t). Now our
                                                      It can easily be proved that E[λˇ(t)] is unbiased i.e., E[λˇ]=
task is to estimate the parameters β and η. We estimate these
                                                         n−3 ˜     n−3   ˜
two parameters using maximum likelihood estimator as given E[ n−2 λ(t)] = n−2 E[λ(t)] = λ(t). We use this estimator in
below. The conditional pdf of the ith event given that the our experiment. Another unbiased estimate of λ(t) is λ¯(t)=
  −   th                                  |                    βˆ−1 βˆ
(i  1)  event occurred at ti−1 is given by f(ti ti−1)= (n − 3)βtˆ /tn, which is obtained by correcting λˆ(t) by
     
β−1      β  β
β         −  1 (t −t )
   ti       ηβ i  i−1                                 a factor of (n − 3)/2 [Calabria et al., 1988].Onceweget
         e           ,ti−1 <ti. Now, the likelihood
η  η                                                  windows of consistent behavior (see Section 4), we can thus
function can be deﬁned as                             estimate λ(t).
          n                nβ          n
                                      tn β    β−1
                           1      n −( η )
 L(β,η)=     f(ti | ti−1)=       β e         ti       3.3  Estimation using Duane Plots
          i=1              η              i=1
                                                      In this Subsection, we discuss another λ(t) estimator using
Taking log on both sides we get                       Duane plot [Duane, 1964].
                                               n
                                                                                 ti
                    β            tn β                 Property 1 Let MTBU(ti)=    i ,i > 0 be the cumulative
log L(β,η)=n log(1/η )+n  log β −( ) +(β  −1)    ti                              th
                                  η           i=1     mean time between updates at i update. If the sequence of
                                                      MTBU(ti)   is either increasing or decreasing or constant as
                β
Assuming c =1/η  , we can write                       i increases and if we plot a graph between MTBU(ti) along
                                            n        y-axis and ti along x-axis on log-log graph paper, the points
                                 β
  log L(β,c)=n log(c)+n  log β − ctn +(β − 1)  ti     tend to line up following a straight line. This plot is known as
                                            i=1       Duane Plot.

                                                IJCAI-07
                                                  2876The slope of the straight line passing through points is known DataSet min max mean   Std. De.  #Pages
as Duane plot slope. From the straight line, we can write Real     4      57    27     11.46    26972
log MTBU(t)=logα    + γ log t,whereγ is the Duane plot   Synthetic 4     201    103    45.85    299324
slope and α is the intercept when t =1. Equating MTBU
to its expected value, we get MTBU(t)=αtγ . Similarly,
                                     1 −γ             Table 1: Characteristics of the datasets. (min:Minimum num-
cumulative λ(t) can be written as λ(t)= α t .Now,the  ber of updates in a page, max: maximum number of updates
slope γ can be calculated as                          in a page, mean: mean number of updates and Std. De.: Stan-
                                                      dard Deviation)
            log MTBU(ti)  − log MTBU(tj)
        γ =                              .      (6)
                     log ti − log tj
                                                      deﬁned. If W  be the set of update points, then the aver-
As we consider the λ(t) estimation only within the consis- age number of update points within the window W can be
tent windows, the Duane plot can be applied to estimate
                                                      deﬁned as μ(W )=    W λ(x)dx <  ∞,whereλ(x)   is lo-
the λ(t). This estimation works ﬁne as long as both the cally integrable. Now the localized λ(x) can be deﬁned as
points (MTBU(ti),ti) and (MTBU(tj),tj) are on the best                Pr(N(W )=1)
straight line through the points. But, it is not the case in re- λ(x) = limW →x |W | ,whereN(W ) denotes the
ality. Therefore, the straight line which is closest to all the number of updates within W and x is an update point. Thus,
observed points is considered and the γ is the slope of the ob- it is necessary for the window W to be consistent so as to be
tained straight line. The simple linear regression is applied to able to predict Pr(N(W )=1).
ﬁnd the best straight line closest to all the observed points. Now, the total observation space is divided into windows
                                                      Wi of consistent MTBU  i.e. either constant or increasing
3.4  Estimation using Linear Regression               or decreasing in nature. the length of a window | Wi(k) |
                                                      is deﬁned by (tj+k − tj),j > 0,whereWi(k)  starts just
If we consider a consistent window with either constant or  th
increasing or decreasing λ(t), linear regression is an effec- after j update and k is the number of update points within
tive mechanism to estimate λ(t). Under such conditions, the the window. The accuracy of the estimation depends on the
relationship between λ(t) and t can be deﬁned by a straight nature of the update points within the window. So, how do we
line. Linear regression deﬁnes a straight line closest to the decide the window size? The important factor in deciding the
data points. We can deﬁne the equation of the closest straight window size i.e., k is the number of consistent points within
       
line as y = a + bx,wherea and b are regression coefﬁcients the window, not | Wi(k) |.
                  −             (xi−x)(yi−y)
and deﬁned as a = y bx and b =          2  .Weap-
                                   (xi−x)             Consistent window: The initial window consists of the last
ply simple linear regression to get the best straight line closest (ﬁrst) three update points and extended backward (forward).
to all the observed points in the Duane plot. If we consider A window is always in one of the three states, either con-
x =logti and y =logMTBUc(ti),thenb    is equal to the stant or increasing or decreasing state. The window extends
slope of the Duane plots γ and a is equal to the intercept α. if the next point at tj is consistent with the state of the current
                                                      window. We often do not ﬁnd consistent windows of large
3.5  Measuring error                                  size. To increase the size of the windows, we allow few in-
An error at a point i is deﬁned as the difference between consistent update points within the window with a limit on
the observed value and predicted value at that point i i.e., the amount of discrepancies. Even if an update point tj is not
(i)=fobserved(i) − fpredicted(i). The error in measuring exactly consistent with the current state, we consider the tj
λ(t) is minimum if error in measuring MTBU(t) is min- as a consistent point if the amount discrepancy is below some
imum and vice versa. Again, overall error in MTBU(t)  threshold value, otherwise we create the next window.
                N(t)        N(t) 
is minimum when                                 −
                 i=1   (i)=    i=1 MTBU(t(i))
                                    N(t)              5   Experimental Evaluation
(t(i) − t(i − 1)) is minimum. Thus, i=1 (i) can be
used as a measure to compare different estimations of λ(t). The comparisons of different estimators are based on both
                          N(t)                        synthetic datasets (collected from the UCLA WebArchive
The λ(t) with the minimum i=1 (i) is considered as the
best estimate. But, in the case of linear regression mechanism project data available at http://webarchive.cs.ucla.edu/)and
                                                     real Web datasets. Synthetic datasets consist of 3,00,000
  i  (i)=0. To avoid this problem, we can use mean of
                     n       2                        pages’ records and each record contains 200 access units. The
square error MSE =   i=1 (i) /n as a measure to com-
pare different estimators.                            real Web datasets were collected locally. The 27034 number
                                                      of frequently access Web pages were identiﬁed from our lo-
                                                      cal proxy server log ﬁle. These pages were crawled every day
4  Generating Consistent Window                       for two months (12th April, 2006 to 12th June, 2006) to keep
In reality, most of the Web page update period sequence is track of the changes.
inconsistent. It is found to be a sequence of constant, in- Table1 shows the characteristics of the two datasets. The
creasing and decreasing over subsequent period of times in pages having less than four update points during the ob-
any order. In this Section, a procedure to generate the consis- servation period are ignored. The proposed estimators are
tent windows (as deﬁne in Deﬁnition 1) out of a sequence compared with the estimators proposed in [Cho and Garcia-
of update points is discussed. First the localized λ(t) is Molina, 2003] and [Matloff, 2005].Theλ proposed by Cho

                                                IJCAI-07
                                                  2877 DataSet   Estimator  Total  Const    Incr   Decr                      Average MSE Vs Window Size
           λcho       3.849   0.639  13.094  5.19          9
 Synthetic λnorman    3.925   0.745  13.174  5.248                                        Weibull
                                                           8                               Duane
           Weibull    2.363  0.2488   7.955  3.274                                           cho
                                                           7
           Duane      2.956   0.339  10.307  4.059                                        norman
                                                           6
           λcho       2.379   0.642    5.9   4.23
                                                           5
 Real      λnorman    2.471   0.753   5.979  4.296
           Weibull    1.363   0.245   4.069  2.513         4


           Duane      1.802   0.348   4.633  3.359       Average  MSE  3
                                                           2
Table 2: Average MSE for different estimators over different  1
window types. Windows were generated with a Threshold      0
                                                                5      10      15     20      25      30
value of 3.                                                                  Window Size
                                                                          (a) Synthetic Data
                           1    n−X+0.5
et al. can be stated as λcho = − τ log( n+0.5 ),wheren is
the number of intervals of τ and X is the number of intervals          Average MSE Vs Window Size
                                                           5
with at least one update point. Again, the λ proposed by Mat-                             Weibull
                                1        Mn
loff N. can be stated as λnorman = − τ log(1 − n ),where                                   Duane
                                                           4                                 cho
n is the number of intervals of τ and Mn is the number of                                 norman
intervals with at least one unobserved update point. To get
the best result out of the available information, τ is set to 1.  3
  The experimental evaluations consists of two parts. In the
ﬁrst part, the localized λ(t) is estimated using the estimators  2
discussed in Section 3 from the sequence of data points in Average  MSE
the observation space. The sequence of consistent windows  1
are generated using the procedure discussed in Section 4.
                                                           0
The consistent windows with a minimum size of four update       5      10      15     20      25      30
points are considered. If the size of the window is less than                Window Size
four, then one half is merged with the left window and an-                (b) Real Data
other half with the right window in the sequence introducing
some discrepancies. For each window, the λ(t) is estimated at Figure 1: Window size versus MSE between different esti-
every update point t using different estimators. For simplic- mators. Windows were generated with a Threshold value of
ity, MTBU(t) is approximated as MTBU(t) ∼ 1/λ(t) and  3.
then regenerate the whole observation space again using the
estimated MTBU(t). The difference between actual update
point and estimated update point is considered as an error. estimator outperforms other estimators for all the cases. For
The errors in every estimated update points are recorded and the case of constant state windows, all these four estima-
the average MSE for each window is determined to compare tors performs equally well with very small average MSE.
the accuracy of different estimators.                 But, Weibull estimator outperforms the rest with signiﬁcantly
                                                      smaller average MSE for both increasing and decreasing state
               Rest    cho     nor    Wei    Dua      windows. In Table 3, the percentage of the number of win-
                                                      dows out of the whole windows, in which row estimator
       cho   0.002%           100%    1.2%   2.3%
                                                      outperforms the column estimator, is shown. It shows that
 Syn   nor     0%      0%              1%    1.4%
                                                      Weibull estimator outperforms the rest in 91.5% of the whole
       Wei    91.5%   98.8%    99%           91.5%
                                                      windows for synthetic datasets and in 90.6% of the whole
       Dua    8.5%    97.6%   98.5%   8.5%
                                                      windows for real Web datasets. Whereas the previous esti-
       cho   0.002%           100%    1.2%   1.6%
                                                      mators λcho and λnorman outperforms the rest almost in 0%
 Real  nor     0%      0%              1%    0.92%
                                                      for both synthetic and real datasets. Again we compare dif-
       Wei    90.6%   98.8%    99%           90.6%
                                                      ferent estimators in terms of the average MSE for different
       Dua    9.4%    98.4%   99.1%   9.4%
                                                      window sizes as shown in Figure 1. It clearly shows that
                                                      error decreases as we increase the size of window. For the
Table 3: Estimator in the row outperforms estimator in the larger size windows, all estimators perform equally well (still
column. Windows were generated with a Threshold value Weibull outperforms by smaller extents), but for the smaller
of 3. (Syn :Synthetic, Wei:Weibull, Dua: Duane, cho:λcho, size windows, Weibull outperforms the other estimators by
nor:λnorman)                                          almost double.
                                                        The main motivation behind investigating localized λ(t),
  Table 2 compares the average MSE of different estimators rather than global λ is to use the piecewise information to im-
in terms of different window classes. The proposed Weibull prove the prediction of future update points. For example, the

                                                IJCAI-07
                                                  2878