                                  Stacked Sequential Learning
                    William W. Cohen                             Vitor R. Carvalho
       Center for Automated Learning & Discovery           Language Technologies Institute
               School of Computer Science                   School of Computer Science
                Carnegie Mellon University                   Carnegie Mellon University
                   Pittsburgh, PA 15213                         Pittsburgh, PA 15213
                   wcohen@cs.cmu.edu                              vitor@cs.cmu.edu

                    Abstract                          entropy learner generally outperforms conditional random
                                                      ﬁelds.
    We describe a new sequential learning scheme
    called “stacked sequential learning”. Stacked se-
    quential learning is a meta-learning algorithm, in 2  Motivation: A Hard Task for MEMMs
    which an arbitrary base learner is augmented so   To motivate the novel learning method that we will describe
    as to make it aware of the labels of nearby exam- below, we will ﬁrst analyze the behavior of one well-known
    ples. We evaluate the method on several “sequen-  sequential learner on a particular real-world problem. In a re-
    tial partitioning problems”, which are characterized cent paper [Carvalho and Cohen, 2004], we evaluated a num-
    by long runs of identical labels. We demonstrate  ber of sequential learning methods on the problem of recog-
    that on these problems, sequential stacking consis- nizing the “signature” section of an email message. Each
    tently improves the performance of non-sequential line of an email message was represented with a set of hand-
    base learners; that sequential stacking often im- crafted features, such as “line contains a possible phone num-
    proves performance of learners (such as CRFs)     ber”, “line is blank”, etc. Each email message was repre-
    that are designed speciﬁcally for sequential tasks; sented as a vector x of feature-vectors x1, . . . , xn, where xi
    and that a sequentially stacked maximum-entropy   is the feature-vector representation of the i-th line of the mes-
    learner generally outperforms CRFs.               sage. A line was labeled as positive if it was part of a signa-
                                                      ture section, and negative otherwise. The labels for a message
                                                      were represented as another vector y, where yi is the label for
1  Introduction                                       line i.
In this paper, we will consider the application of sequential The dataset contains 33,013 labeled lines from 617 email
probabilistic learners to sequential partitioning tasks. Se- messages. About 10% of the lines are labeled “positive”. Sig-
quential partitioning tasks are sequential classiﬁcation tasks nature sections always fall at the end of a message, usually in
characterized by long runs of identical labels: examples of the last 10 lines. In the experiments below, the data was split
these tasks include document analysis, video segmentation, into a training set (of 438 sequences/emails), and a test set
and gene ﬁnding.                                      with the remaining sequences, and we used the “basic” fea-
                                                      ture set from Carvalho & Cohen.
  Motivated by some anomalous behavior observed for one
sequential learning method on a particular partitioning task, The complete dataset is represented as a set S of exam-
we will derive a new learning scheme called stacked sequen- ples S = {(x1, y1), . . . , (xt, yt), . . . , (xm, ym)}. Sequen-
tial learning. Like boosting, stacked sequential learning is tial learning is the problem of learning, from such a dataset,
a meta-learning method, in which an arbitrary base learner a sequential classiﬁer—i.e., a function f such that f(x)
is augmented—in this case, by making the learner aware of produces a vector of class labels y. Clearly, any ordinary
                                                      non-sequential learning algorithm can be used for sequential
the labels of nearby examples. Sequential stacking is simple                                       1
to implement, can be applied to virtually any base learner, learning, by ignoring the sequential nature of the data .
                                                                           [                      ]
and imposes only a constant overhead in training time: in our In the previous paper Carvalho and Cohen, 2004 , we re-
implementation, the sequentially stacked version of the base ported results for several non-sequential and sequential learn-
learner A trains about seven times more slowly than A. ers on the signature-detection problem, including a non-
                                                      sequential maximum entropy learner [Berger et al., 1996]
  In experiments on several partitioning tasks, sequential
stacking consistently improves the performance of non-
                                                         1Speciﬁcally, one could build a dataset of non-sequential exam-
sequential base learners. More surprisingly, sequential stack-
                                                      ples (xt,i, yt,i) from S, and use it to train a classiﬁer g that maps a
ing also often improves performance of learners speciﬁcally single feature-vector x to a label y. One can then use g to classify
designed for sequential tasks, such as conditional random each instance xi in the vector x = hx1, . . . , xni separately, ignoring
ﬁelds and discriminatively trained HMMs. Finally, on our its sequential position, and append the resulting predictions yi into
set of benchmark problems, a sequentially stacked maximum- an output vector y.         Method   Noise   Error  Min Error            sages, the learned MEMM makes a false positive classiﬁca-
         ME                3.47    3.20               tion somewhere before the signature starts, and then “gets
         MEMM             31.83    4.26               stuck” and marks every subsequent line as part of a signature.
         CRF               1.17    1.17               This behavior is not consistent with previously-described lim-
         MEMM      10%     2.18    2.18               itations of MEMMs. It is known that MEMMs can represent
         CRF       10%     1.85    1.84               only a proper subset of the distributions that can be repre-
                                                      sented by CRFs [Lafferty et al., 2001]; however, this “label
                                                      bias problem” does not explain why MEMMs perform worse
Table 1: Performance of several sequential learners on the
                                                      than non-sequential ME, since MEMMs clearly can represent
signature-detection problem.
                                                      strictly more distributions that ME.
                                                        Klein and Manning [2002] also describe an “observation
(henceforth ME) and conditional random ﬁelds [Lafferty et bias problem”, in which MEMMs give too little weight to
al., 2001] (henceforth CRFs). Another plausible sequen- the history features. However, in this case, relative to the
tial learning method to apply to this task are maximum- weights assigned by a CRF, MEMM is seems to give too
entropy Markov models (MEMMs) [McCallum et al., 2000], much weight to the history features. To verify this, we en-
also called maximum-entropy taggers [Ratnaparkhi, 1999], couraged the MEMM to downweight the history features by
conditional Markov models [Klein and Manning, 2002],  adding noise to the training (not test) data: for each training
and recurrent sliding windows [Dietterich, 2002]. In this email/sequence x, we consider each feature-vector xi ∈ x
model, the conditional probability of a label sequence y in turn, and with probability 0.10, we swap line xi (together
                                                      with its label y ) with some other x , y chosen uniformly
Qgiven an instance sequence x is deﬁned to be Pr(y|x) =            i                 j  j
                                                      from the sequence. Adding this “sequence noise” almost dou-
  i Pr(yi|yi−1, xi). The local model Pr(yi|yi−1, xi) is
learned as follows. First one constructs an extended dataset, bles the error rate for CRFs, but reduces the error rate for
which is a collection of non-sequential examples of the MEMMs. (Of course, this type of noise does not affect non-
form ((xi, yi−1), yi), where (xi, yi−1) denotes an instance sequential ME.) This experiment supports the hypothesis that
in which the original feature vector for xi is augmented by MEMM is overweighting history features.
adding a feature for yi−1. We will call (xi, yi−1) an extended
instance, and call yi−1 a history feature. Note that yi is the 3 Stacked Sequential Learning
class label for the extended example ((xi, yi−1), yi).
  After constructing extended instances, one trains a 3.1  Description
maximum-entropy conditional model from the extended   The poor results for MEMM described above can be intu-
dataset. Inference is done by using a Viterbi search to ﬁnd itively explained as a mismatch between the data used to train
the best label sequence y.                            the local models Pr(yi|yi−1, x) of the MEMM, and the data
  MEMMs have a number of nice properties. Relative to used to test these models. With noise-free training data, it
the more recently-proposed CRF model, MEMMs are easy to is always the case that a signature line is followed by more
implement, and (since no inference is done at learning time) signature lines, so the MEMM’s local model tends to weight
relatively quick to train. MEMMs can also be easily general- the history feature yi−1 heavily. However, this strong regu-
ized by replacing the local model with one that uses a longer larity does not hold when the model is applied to test data in
“history” of k previous labels—i.e., a model of the form the course of executing the Viterbi algorithm, because then
Pr(yi|yi−1, . . . , yi−k, xi)—and replacing the Viterbi search the local model is applied to extended examples (xi, yˆi−1),
with a beam search. Such a learner scales well with the his- where yˆi−1 is a prediction made by the local model.
tory size and number of possible classes y.             In theory, of course, this training/test mismatch is compen-
  Unfortunately, as Table 1 shows, MEMMs perform ex-  sated for by the Viterbi search, which is in turn driven by the
tremely badly on the signature-detection problem, with an conﬁdence estimates produced by the local model. However,
error rate many times the error rate of CRFs. In fact, on if the assumptions of the theory are violated (for instance,
this problem, MEMMs perform much worse than the non-  if there are high-order interactions not accounted for by the
sequential maximum-entropy learner ME.2               maximum-entropy model), the local model’s conﬁdence esti-
  The MEMM’s performance is better if one changes the mates may be incorrect.
threshold used to classify examples. Letting pˆi be the prob- One way to correct the training/test mismatch is to mod-
ability Pr(yi = +|xi, yi−1) as computed by MEMM, we   ify the extended dataset that is used to train the local model
found, for each learner, the threshold θ such the rule [(yi = so that the true previous class yi−1 in an extended instance
+) ⇔ (ˆpi > θ)] gives the lowest test error rate. The column (xi, yi−1) is replaced by a predicted previous class yˆi−1. Be-
labeled “Min Error” in Table 1 gives this “best possible” re- low we will outline a way to do this.
sult. The “Min Error” for MEMMs is much improved, but   Assume that one is given a sample S = {(xt, yt)} of size
still higher than non-sequential ME.                  m, and a sequential learning algorithm A. Previous work
  The high error occurs because on many test email mes- on a meta-learning method called stacking [Wolpert, 1992]
                                                      suggests the following scheme for constructing a sample of
  2We used the implementations of ME, MEMMs, and CRFs pro- (x, yˆ) pairs in which yˆ is a vector of “predicted” class-labels
vided by Minorthird [Minorthird, 2004], with a limit of 50 optimiza- for x. First, partition S into K equal-sized disjoint sub-
tion iterations. This limit does not substantially change the results. sets S1, . . . , SK , and learn K functions f1, . . . , fK , whereStacked Sequential Learning.                          ME to an arbitrary sequential learner, and from a speciﬁc his-

Parameters: a history size Wh, a future size Wf , and a cross- tory feature to a parameterized set of features.
validation parameter K.                                 In our experiments, we introduced one small but important

Learning algorithm: Given a sample S = {(xt, yt)}, and a sequen- reﬁnement: each “history feature” yˆ added to an extended
tial learning algorithm A:                            example is not simply a predicted class, but a numeric value
                                                      indicating the log-odds of that class. This makes accessible
 1. Construct a sample of predictions yˆt for each xt ∈ S as fol- 0
    lows:                                             to f the conﬁdences previously used by the Viterbi search.
     (a) Split S into K equal-sized disjoint subsets S1, . . . , SK 3.2 Initial results
     (b) For j = 1, . . . , K, let fj = A(S − Sj )
                                                      We applied stacked sequential learning with ME as the base
     (c) Let Sˆ = {(xt, yˆt) : yˆt = fj (xt) and xt ∈ Sj }
                            0           0             learner (henceforth s-ME) to the signature-detection dataset.
 2. Construct an extended dataset S of instances (xt, yt) by con- We used K = 5, W = 1, and W = 0. The s-ME method
    verting each x to x0 as follows: x 0 = hx0 , . . . , x0 i where    h           f
               t   t           t     1     `t         obtains an error rate of 2.63% on the signature-detection
    x0 = (x , yˆ , . . . , yˆ ) and yˆ is the i-th component of
     i    i  i−Wh     i+Wf     i                      task—less than the baseline ME method (3.20%) but still
                                ˆ
    yˆt, the label vector paired with xt in S.        higher than CRFs (1.17%). However, certain extensions dra-
 3. Return two functions: f = A(S) and f 0 = A(S0).   matically improve performance.
                                                        For s-ME, the only impact of more “history” features is
Inference algorithm: given an instance vector x:
                                                      to add new features to the extended instances; hence like
 1. Let yˆ = f(x)                                     MEMMs, s-ME can efﬁciently handle large histories. On the
 2. Carry out Step 2 above to produce an extended instance x0 signature-detection task, increasing the history size to 11 re-
    (using yˆ in place of yˆt).                       duces error (slightly) to 2.38%.
           0 0
 3. Return f (x ).                                      For s-ME, the extended instance for xi can include pre-
                                                      dicted classes not only of previous instances, but also of “fu-
 Table 2: The sequential stacking meta-learning algorithm. ture” instances—instances that follow xi in the sequence x.
                                                      We explored different “window sizes” for s-ME, where a
                                                      “window size” of W means that Wh = Wf = W , i.e., the W
f = A(S  − S ). Then, construct the set               previous and W following predicted labels are added to each
 j          j                                         extended instance. A value of W = 20 reduces error rates to
                                                      only 0.71%, a 46% reduction from CRF’s error rate of 1.17%.
        Sˆ = {(xt, yˆt) : yˆ = fj(xt) and xt ∈ Sj}
                                                      This improvement is statistically signiﬁcant.3

In other words, Sˆ pairs each xt with the yˆt associated with Finally, stacked sequential learning can be applied to any
performing a K-fold cross-validation on S. The intent of this learner—in particular, since the extended examples are se-
method is that yˆ is similar to the prediction produced by an f quential, it can be applied any sequential learner. We evalu-
learned by A on a size-m sample that does not include x. ated stacked sequential CRFs (henceforth s-CRFs) with vary-
  This procedure is the basis of the meta-learning algorithm ing window sizes on this problem. A value of W = 20 re-
of Table 2. This method begins with a sample S and a se- duces error rates to 0.68%, a statistically signiﬁcant improve-
quential learning method A. In the discussion below we will ment over CRFs. However, for moderately large window val-
assume that A is ME, used for sequential data.        ues, there was little performance difference between s-CRF
  Using S, A, and cross-validation techniques, one ﬁrst pairs and s-ME.
with each xt ∈ S the vector yˆt associated with performing
cross-validation with ME. These predictions are then used to 3.3 Discussion
              0                    0
create a dataset S of extended instances x , which in the sim- A graphical view of a MEMMs is shown in Figure 1(a). We
plest case, are simply vectors composed of instances of the use the usual convention in which nodes for known values are
form (xi, yˆi−1), where yˆi−1 is the (i − 1)-th label in yˆ. shaded. Each node is associated with a maximum-entropy
  The extended examples S0 are then used to train a model conditional model which deﬁnes a probability distribution
f 0 = A(S0). If A is the non-sequential maximum-entropy given its input values.
learner, this step is similar to the process of building a “local Figure 1(b) presents a similar graphical view of the classi-
model” for an MEMM: the difference is that the history fea- ﬁer learned by sequential stacking with Wh = 1 and Wf = 0.
tures added to xi are derived not from the true history of xi, Inference in this model is done in two stages: ﬁrst the middle
but are (approximations of) the off-sample predictions of an layer is inferred from the bottom later, then the top layer is
ME classiﬁer.                                         inferred from the middle layer. The nodes in the middle layer
  At inference time, f 0 must be run on examples that have are partly shaded to indicate that their hybrid status—they are
been extended by adding prediction features yˆ. To keep the considered outputs by the model f, and inputs by the model
“test” distribution similar to the “training” distribution, f will f 0.
not be used as the inner loop of a Viterbi or beam-search
process; instead, the predictions yˆ are produced using a non- 3A two-tailed paired t-test rejects with > 95% conﬁdence the
sequential maximum-entropy model f that is learned from S. null hypothesis that the difference in error rate between s-ME and
The algorithm of Table 2 simply generalizes this idea from CRF on a randomly selected sequence x has a mean of zero.                                         Yi-1   Yi     Yi+1

        Yi-1     Yi     Yi+1
                                                                      Yi-2  Yi-1  Yi   Yi+1  Yi+1

                                         ^      ^      ^
                                         Yi-1   Yi     Yi+1
                                                                      ^     ^     ^    ^     ^
                                                                      Yi-2  Yi-1  Yi   Yi+1  Yi+1

        Xi-1     Xi     Xi+1

                                         Xi-1   Xi     Xi+1
                                                                      Xi-2  Xi-1  Xi   Xi+1  Xi+1

           (a) MEMM              (b) Sequential stacking, Wh = 1, Wf = 0 (c) Sequential stacking, W = 2

                      Figure 1: Graphical views of alternative sequential-stacking schemes.

  One way to interpret the hybrid layer is as a means of mak- Task MEMM ME   CRF   s-ME   s-CRF
ing the inference more robust. If the middle-layer nodes were A/aigen 53.61 8.02 20.35 6.91 5.78
treated as ordinary unobserved variables, the top-layer con- A/ainn 70.09 6.61 2.14 3.65    1.67
ditional model (f 0) would rely heavily on the conﬁdence as- A/aix 13.86 5.02 6.83  4.59   11.79
sessments of the lower-layer model (f). Forcing f 0 treat these T/aigen 0.30 2.60 2.39 1.92 0.00
variables as observed quantities allows f 0 to develop its own T/ainn 1.36 1.39 0.28 0.00   0.28
model of how the yˆ predictions made by f correlate with the T/aix 3.51 1.25  5.26  0.05    4.44
actual outputs y. This allows f 0 to accept or downweight 1/video 11.39 12.66 12.66 12.66  13.92
f’s predictions, as appropriate. As suggested by the dotted 2/video 8.86 8.86 7.59  3.80    7.59
line in the ﬁgure, stacking conceptually creates a “ﬁrewall” mailsig 31.83 3.47 1.17 1.08   0.77
between f and f 0, insulating f 0 from possible errors in conﬁ-
dence made by f.                                  Table 3: Error rate comparison of different sequential algo-
  Figure 1(c) shows a sequential stacking model with a win- rithms on a set of nine benchmark tasks.
dow of Wh = Wf = 2. To simplify the ﬁgure, only the edges
that eventually lead to the node Yi are shown.
                                                      25
  To conclude our discussion, we note that as described, vs Maxent
                                                          vs MEMM
sequential stacking increases run-time of the base learning vs CRF
                                                             x=y
method by approximately a constant factor of K + 2. (To see  20
this, note sequential stacking requires training K + 2 classi-
ﬁers: the classiﬁers f1, . . . , fK used in cross-validation, and
the ﬁnal classiﬁers f and f 0.) When data is plentiful but train-  15
ing time is limited, it is also possible to simply split the orig-
inal dataset S into two disjoint halves S1 and S2, and train  10
                  0            0
two classiﬁers f and f from S1 and S2 respectively (where


 0                                                  Error:  Stacked Maxent
S2 is S2, extended with the predictions produced by f). This
scheme leaves training time approximately unchanged for a  5
linear-time base learner, and decreases training time for any

base learner that requires superlinear time.           0
                                                          0      5       10     15      20      25
4   Further Experimental Results                                       Error: other learner
4.1  Additional segmentation tasks
                                                  Figure 2: Comparison of the error rates for s-ME with the
We also evaluated non-sequential ME, MEMMs, CRFs, s- error rates of ME, MEMM, and CRFs.
ME, and s-CRFs on several other sequential partitioning
tasks. For stacking, we used K = 5 and a window size of
Wh = Wf  = 5 on all problems. These were the only parame- [2000] and the three tasks (ai-general, ai-neural-nets, and aix)
ter values explored in this section, and no changes were made adopted by Dietterich et al [2004]. The data consists of 5-
to the sequential stacking algorithm, which was developed 7 long sequences, each sequence corresponding to a single
based on observations made from the signature-detection task FAQ document; in total, each task contains between 8,965
only.                                             and 12,757 labeled lines. Our current implementation of se-
  One set of tasks involved classifying lines from FAQ doc- quential stacking only supports binary labels, so we consid-
uments with labels like “header”, “question”, “answer”, and ered the two labels “trailer” (T) and “answer” (A) as separate
“trailer”. We used the features adopted by McCallum et al tasks for each FAQ, leading to a total of six new benchmarks.  Another set of tasks were video segmentation tasks, in Task     MEMM      ME     CRF   s-ME   s-CRF
which the goal is to take a sequence of video “shots” (a music2     28.14  21.40  21.40  18.51   13.50
sequence of adjacent frames taken from one camera) and   music5     64.97  67.00  67.00  64.46   63.45
classify them into categories such as “anchor”, “news” and
“weather”. This dataset contains 12 sequences, each corre- Table 4: Comparison of different sequential algorithms on a
sponding to a single video clip. There are a total of 418 shots, music classiﬁcation task.
and about 700 features, which are produced by applying LDA
to a 5x5, 125-bin RGB color histogram of the central frame
of the shot. (This data was provided by Yik-Cheung Tam and tral”(3), “sad”(2) and “very sad”(1). The Pearson’s corre-
Ming-yu Chen.) We constructed two separate video partition- lation [Walpole et al., 1998] was used as a measure of inter-
ing tasks, corresponding to the two most common labels. annotator agreement. The Pearson’s correlation coefﬁcient
  All eight of these additional tasks are similar to the ranges from −1 (perfect disagreement) to +1 (perfect agree-
signature-detection task in that they contain long runs of iden- ment),and the inter-annotator agreement between the two stu-
tical labels, leading to strong regularities in constructed his- dents was 0.643.
tory features. Error rates for the learning methods on these To learn a song classiﬁer, we represented each song as a
eight tasks, in addition to the previous signature-detection sequence of 1-second long “frames”, each frame being la-
task, are shown in Table 3. In each case a single train/test beled with the emotion for the song that contains it. We then
split was used to evaluate error rates. The bold-faced entries learned sequence classiﬁers from these labeled sequences. To
are the lowest error rate on a row.                   classify an unknown song, we used the sequence classiﬁer to
  We observe that MEMMs suffer extremely high error rates label the frames for the song, and ﬁnally labeled the song with
on two of the new tasks (ﬁnding “answer” lines for ai-general the most frequent predicted frame label.
and ai-neural-nets), suggesting that the “anomalous” behavior The “frames” are produced by extracting certain numerical
shown in signature-detection may not be uncommon, at least properties from a waveform representation of the song every
in sequential partitioning tasks.                     20ms, and then averaging over 1-second intervals. Each 1-
  Also, comparing s-ME to ME, we see that s-ME improves second frame has as features the mean and standard deviation
the error rate in 8 of 9 tasks, and leaves it unchanged once. of each property. The numerical properties were computed
                                                                            [                       ]
Furthermore, s-ME has a lower error rate than CRFs 7 of 9 using the Marsyas toolkit Tzanetakis and Cook, 2000 , and
times, and has the same error rate once. There is only one are based on the short-time Fourier transform, tonality, and
case in which MEMMs have a lower error rate than s-ME. Cepstral coefﬁcients.
  Overall, s-ME seems to be preferable to either of three The music dataset contains 52,188 frames from the 201
older approaches (ME, MEMMs, and CRFS). This is made  songs, with 130 features for each frame. We looked at two
somewhat more apparent by the scatter plot of Figure 2. On versions of the problem: predicting all of the ﬁve labels (mu-
this plot, each point is placed so the y-axis position is the er- sic5), and predicting only “happy” versus “sad” labels (mu-
ror of s-ME, and the x-axis position is the error of an earlier sic2). Preliminary experiments suggested that large windows
learner; thus points below the line y = x are cases where s- were effective, thus we used the following parameters in the
ME outperforms another learner. (For readability, the range experiments: K = 2 and a window size of Wh = Wf = 25
of the x axis is truncated—it does not include the highest er- on music5 problem, and K = 5 and Wh = Wf = 25 on
ror rates of MEMM.)                                   music2.
  Stacking also improves CRF on some problems, but the  The results are summarized in Table 4. Both s-CRF and
effect is not as consistent: s-CRF improves the error rate on 5 s-ME outperform their non-stacking counterparts, and s-ME
of 9 tasks, leaves it unchanged twice, and increases the error outperforms CRFs. Furthermore, s-CRF improves substan-
rate twice. In the table, one of the two stacked learners has tially over unstacked CRFs on the two-class problem, reduc-
the lowest error rate on 8 of the 9 tasks.            ing the error rate by more than 27%.
  Applying a one-tailed sign test, the improvement of s-ME
relative to ME is statistically signiﬁcant (p > 0.98), but the 5 Conclusions
improvement of s-CRF relative to CRF is statistically not Sequential partitioning tasks are sequential classiﬁcation
(p > 0.92). The sign test does not consider the amounts tasks characterized by long runs of identical labels: exam-
by which error rates are changed, however. From the ﬁg- ples of these tasks include document analysis, video segmen-
ures and tables, it is clear that error rates are often lowered tation, and gene ﬁnding. In this paper, we have evaluated the
substantially, and only once raised by more than a very small performance of certain well-studied sequential probabilistic
proportion (for the “A/aix” benchmark with CRFs).     learners to sequential partitioning tasks. It was observed that
                                                      MEMMs sometimes obtain extremely high error rates. Er-
4.2  A sequence classiﬁcation task                    ror analysis suggests that this problem is neither due to “label
As a ﬁnal test, we explored one additional non-trivial task: bias” [Lafferty et al., 2001] nor “observation bias” [Klein and
classifying popular songs by emotion. This task was consid- Manning, 2002], but to a mismatch between the data used to
ered after all code development was complete, and hence is train the MEMM’s local model, and the data on which the
a completely prospective test of sequential stacking. A col- MEMM’s local model is tested. In particular, since MEMMs
lection of 201 popular songs was annotated by two students are trained on “true” labels and tested on “predicted” labels,
on a ﬁve-point scale: “very happy”(5), “happy”(4), “neu- the strong correlations between adjacent labels associated se-