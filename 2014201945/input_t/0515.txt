                                         Solving   Checkers     

                   J. Schaeffer, Y. Bjor¨ nsson, N. Burch, A. Kishimoto,  M. Muller¨ ,
                                     R. Lake, P. Lu and  S. Sutphen
                        Department  of Computing   Science, University of Alberta
                                 Edmonton,   Alberta, Canada  T6G  2E8
                                        jonathan@cs.ualberta.ca

                    Abstract                              Strongly solved games include 6-piece chess endgames
                                                          and Awari [Romein and Bal, 2003].
    AI has had  notable success in building high-
    performance game-playing programs to compete      Note the qualiﬁcation on resources in the above deﬁnitions.
    against the best human players. However, the      In some sense, games such as chess are solved since the min-
    availability of fast and plentiful machines with  imax algorithm can in principle determine the game-theoretic
    large memories and disks creates the possibility of value, given a large enough amount of time. Resource con-
    ¡£¢¥¤§¦©¨
 a game. This has been done before for straints preclude such impractical “solutions”.
    simple or relatively small games. In this paper,    How  difﬁcult is it to solve a game? There are two dimen-
    we present new ideas and algorithms for solving   sions to the difﬁculty [Allis et al., 1991]: decision complexity,
    the game of checkers. Checkers is a popular game  the difﬁculty required to make correct decisions, and space


    of skill with a search space of © possible posi- complexity, the size of the search space. Checkers is consid-
    tions. This paper reports on our ﬁrst result. One of ered to have high decision complexity and moderate space
    the most challenging checkers openings has been   complexity. All the games solved thus far have either low


    solved – the White Doctor opening is a draw. Solv- decision complexity (Qubic; Go-Moku), low space complex-


                                                                                                 
                                                                                              £


    ing roughly 50 more openings will result in the   ity (Nine Men’s Morris, size  ; Awari, size ) or both
                                                                       £
    game-theoretic value of checkers being determined. (Connect-Four, size  ).


                                                        Checkers, or  draughts, is popular in the British Com-
                                                      monwealth (present and past) and in the United States. The
1  Introduction                                       rules are simple (pieces move one square at a time diago-
High-performance game-playing programs have been a major nally, and can capture by jumping) and the number of piece
success story for AI. In games such as chess, checkers, Oth- types is small (kings and checkers), yet the game is quite
ello, and Scrabble, mankind has been humbled by the ma- challenging. Checkers has high decision complexity (more

chine. However, although these programs are very strong, complex than  ! Go and the play of bridge hands, on par
they can still lose a game to a human. They are strong, but with backgammon, but less complex than chess) and moder-



not perfect. Perfection requires one to “solve” a game. Allis ate space complexity ( © positions versus unsolved games


                                                                                             £
                                                                                                  #
deﬁnes three levels of solving [Allis, 1994]:         such as backgammon,   " positions, and chess, posi-
                                                      tions). The best checkers programs are stronger than the best
 1. Ultra-weakly solved. The game-theoretic value for the
                                                      human players (e.g., CHINOOK won the World Man-Machine
    game has been determined. An ultra-weak solution is Championship [Schaeffer, 1997]).
    mainly of theoretical interest. For example, Hex is a ﬁrst The number of possible placings of checkers pieces on the
    player win, but no one knows the winning strategy.

                                                      board is roughly $%&£' [Chinook, 1995]. This number
 2. Weakly solved. The game is ultra-weakly solved and a is misleading since it includes positions that are not legally
    strategy is known for achieving the game-theoretic value reachable from the start of the game. For example, although


    from the opening position, assuming reasonable com- there are !(£©" possible positions with 24 pieces on the
    puting resources. Several well-known games have been board, only a small fraction can be reached in a game (e.g.,
    weakly solved, including Connect Four [Allis, 1988], 12 kings versus 12 kings is not possible).
    Qubic [Allis, 1994], Go Moku [Allis, 1994], and Nine Our effort to solve the game of checkers began in 1989! Af-
    Men’s Morris [Gasser, 1996].                      ter almost 16 years of research and development, and count-
 3. Strongly solved. For all possible positions, a strategy less thousands of computer hours, we are pleased to report the
    is known for determining the game-theoretic value for ﬁrst major milestone in our quest. The White Doctor opening
                                                                                                1
    both players, assuming reasonable computing resources. (shown in Figure 1) has been proven to be a draw. This is a

   The support of NSERC, iCORE and the University of Alberta 1Tournament checkers is played using the so-called “three-move
is acknowledged.                                      ballot”. In competitions, games begin after the ﬁrst 3 moves (3 ply)

                                


                                                         24                                         24


                              


                                                         23                                         23


                       ¡       ¡


                                                         22                                         22


                         ¡    
                ¡                                        21                                         21


                                                         20                                         20


                       ¢   ¡   ¡


                  ¡                                       19                                       19


                     ¡   ¢   ¢


                ¢                                         18                                       18


                       ¢   ¢   ¢


                  ¢                                        17                                      17


                     ¢   ¢   ¢
                ¢                                          16                                     16
                                                            15                                   15
                                                            14                                   14
                                                             13                                 13
 Figure 1: The White Doctor: White to play and only draw      12                               12
                                                               11                              11
                                                               10                             10
                                                                 9                           9
difﬁcult opening, as Black begins the game with a huge po-        8                         8
sitional disadvantage—so large that humans consider Black’s        7                       7
best play to be to sacriﬁce a checker early on to relieve the       6                     6
                                                                     5                   5
pressure. Notably, this opening was played in the decisive             4                4
game of the 1992 Tinsley–CHINOOK World Championship                     3             3
match [Schaeffer, 1997].                                                  2          2
  This paper has the following contributions:                              1       1
                                                                               0
 1. A new hybrid combination of best-ﬁrst and depth-ﬁrst
    search results to the construction of minimax proof trees. Figure 2: The checkers search space (log scale horizontally)
    Heuristic value iteration is introduced as a means of con-
    centrating search effort where it is most needed.
 2. A solution to the White Doctor opening. Achieving
    this result took years of computing, involving the pre- 4. Seeding (expert input). From the human literature, a sin-


                                                          gle line of “best play” is identiﬁed. This is fed to the


                  £
                    ¤£
    computation of   values (endgame databases), and


                                                          proof tree manager as the initial line to explore.


                                               
                                                 ¥£
    building the proof tree which took a further roughly 
    positions. This is an important ﬁrst step towards weakly Figure 2 illustrates this approach. It plots the number of
    solving the game of checkers.                     pieces on the board (vertically) versus the logarithm of the
                                                      number of positions (using data from [Chinook, 1995]; the


 3. The largest game-tree proof to date. This was made pos-


                                                                                     !©
                                                      the widest point is with 23 pieces,  positions). The
    sible not only by our new hybrid search approach, but
                                                      endgame database phase of the proof is the shaded area, all
    also by the integration of several state-of-the-art algo-
                                                      positions with 10 or fewer pieces.
    rithms and enhancements into one coherent system.
                                                        Seeding the proof process with an initial line of play is
                                                      critical to the prover’s performance; it is shown in Figure 2
2  Algorithm   Overview                               as a sequence of solid bold lines. The line leads from the
A formal proof of a game’s value can be done by depth-ﬁrst start of the opening into the endgame databases. Seeding is
                                                      not necessary to the proof—the prover is capable of doing the
alpha-beta ( ¦¨§ ) or best-ﬁrst proof number search (PNS) [Al-
lis, 1994]. For the large and complex checkers search space, proof with no expert guidance. However, this single line of
neither turned out to be effective. Instead we propose a hybrid play allows the proof process to immediately start doing work
approach of the two: heuristically guided proofs.     that is likely to be relevant to the proof. Without it, we have
  The proof procedure has four algorithm/data components: seen the prover spend considerable effort ﬂailing about while
                                                      it tries to ﬁnd the key lines of play.
 1. Endgame  databases (backward search). Computations  The inner oval area in Figure 2 illustrates that only a por-


    from the end of the game backward have resulted in a tion of the search space is relevant to the proof. Positions may


                ¥£     
  
    database of ©    positions (  pieces on the board) be irrelevant because they are unreachable in this opening, or
    for which the game-theoretic value has been computed are not required for the proof. The small circles illustrate po-
    (strongly solved).                                sitions with more than 10 pieces for which a value has been
 2. Proof tree manager (search management). This compo- proven. Each of the circles represents the root of a search tree
    nent maintains a tree of the proof in progress, traverses which has been solved. For clarity, the solved subtree below
    it, and generates positions that need to be explored to that root is not shown in the diagram.
    further the proof’s progress.
                                                      3   Endgame    Databases
 3. Proof solver (forward search). Given a position to
                                                      Endgame  databases were pioneered in chess [Thompson,
    search, this component uses two programs, ¦¨§ and PNS,
    to determine the value of the position.           1986], and were instrumental in the success of the CHINOOK
                                                      program [Schaeffer, 1997]. Using retrograde analysis, sub-
are randomly selected. Each starting position is played twice, with sets of a game with a small number of pieces on the board can
sides switched for the second game.                   be exhaustively enumerated to compute which positions arewins, losses or draws. Whenever a search reaches a database of the position, the more likely it is a win/loss. Rather than
position, instead of using an inexact heuristic evaluation func- invest the effort to prove such a position, this work is post-
tion, the exact value of the position can be retrieved. poned until it has been shown to be needed. We do this by
  We have computed all endgame databases up to 10 pieces introducing two new values to the proof tree. To win, loss,
on the board, for any combination of kings and checkers draw and unknown, we add likely win and likely loss.


[van den Herik et al., 2003]. The total database size is 39 All searches are done relative to a heuristic threshold. The


                     ©  £
                           ¥£
trillion positions, roughly  . Although this sounds im- back-end prover returns an assessment of a position. Any po-
pressive, it represents a paltry one ten-millionth of the total sition exceeding the threshold is considered a likely win; any
search space [Chinook, 1995]!                         falling below the negative threshold is a likely loss. The proof
  How  valuable are the databases? Unfortunately, because manager repeatedly traverses the proof tree, identiﬁes nodes
of the win/loss/draw construction, a good measure of the dif- to be searched, sends them off for assessment by the prover,
ﬁculty of 10-piece endgames is not available—although it is and integrates the results. Any node with a score outside the
presumed to be very high. Anecdotal evidence includes: threshold has a likely result and is not expanded further within
 1. Perfect play databases for the 7-piece endgames have this threshold; it is effectively treated as if it is proven. The
    been computed, with the longest winning line being 253 thresholds can be loosely thought of as imposing a symmetric



    ply [Trice and Dodgen, 2003].                     ¦¨§ search window on the best-ﬁrst proof manager. A value
                                                                           §
                                                      outside the window in ¦ means the result is irrelevant; a
 2. [Schaeffer et al., 2003] report that some of their database value outside the heuristic threshold means that we postpone
    computations had winning lines in excess of 180 ply— the proof until we know the result will be relevant.
    just to force a checker advance or a piece capture. Once the proof tree is complete for a given heuristic thresh-
 3. In the 5-king versus 3-king and 2-checker endgame, the old, the threshold is increased and the search restarted to con-
    longest winning line is 279 ply [Gilbert, 2005].  struct a proof for the new threshold. Any position that was
 4. Draws are much harder to prove than wins/losses.  previously resolved to a real proven value remains proven,
                                                      and positions that have a heuristic score that remain outside
This evidence strongly suggests that the databases are remov- the new heuristic threshold remain likely wins/losses. Only
ing hundreds of ply from the search depth of the proof tree. non-proven positions with heuristic values inside the new
                                                      threshold are now considered, and they must be re-searched
4  Search  Algorithm                                  with the new heuristic limit. This iterative process contin-
The proof search is split into a front-end proof tree manager ues until the heuristic threshold exceeds the largest possible
and a back-end prover. The front-end manager maintains a heuristic value. At this point all likely wins/losses have been
large persistent proof tree, and selects, stores, and organizes resolved, and the proof tree is complete.
the search results. Proofs of individual positions are done in Ideally, after the ﬁrst likely proof tree is constructed, the
parallel by a farm of back-end provers.               work would consist solely of trying to prove that the likely
                                                      wins/losses are even more likely wins/losses. In practice, the
4.1  Proof Tree Manager  (front end)                  heuristics we use are occasionally wrong (they are, after all,
The proof tree manager starts off with an empty proof tree. only heuristics), and a proof tree for a position may grow
The proof is “seeded” by being fed an initial line of play. large enough that other previously less desirable positions be-
This line is considered by humans to be best play by both come a more attractive alternative for expansion.
sides. The proof manager starts at the last position in the line For the White Doctor, we used settings of MIN = 125 (a
and solves it, then backs up one ply, solves that sub-tree, and checker is worth 100 points) and INC = 5 in Figure 3. These
so on until the root of the line is reached.          might not be the best choices; we are experimenting with dif-
  The proof is done iteratively, as shown in Figure 3. In ferent values on other checkers openings.
minimax search, we have seen iterative algorithms based on The proof manager uses PNS, trying to answer two ques-
search depth (iterative deepening) and conﬁdence in the root tions about the value of the proof tree: “is it at least a likely
value (as in conspiracy numbers [McAllester, 1988]). Our win”, and “is it at most a likely loss.” A likely win is as-
algorithm is novel in that it iterates on the range of relevant signed a proof number of 0 for the is-likely-win question, a
heuristic values for the proof.                       likely loss is assigned a proof number of 0 for the is-likely-
  Classical iterative deepening in game-playing programs is loss question, and a draw is assigned a disproof number of


used for several reasons, one of which is to improve search 0 for both questions. The prover tries to investigate the two


                                       ¨
                     §
efﬁciency by using the ¦ tree from iteration as the basis questions simultaneously by selecting nodes for considera-
for starting iteration ¨ +1. The assumption is that increasing tion that (ideally) contribute to answering both.
the depth does not cause substantial changes to the tree struc- The proof tree manager traverses the proof tree and iden-
ture; each iteration reﬁnes the previous iteration’s solution. In tiﬁes nodes that are needed or likely to be needed in the
contrast, without iterative deepening, the search can go off in proof. While a traditional PNS algorithm expands one node
the wrong direction and waste lots of effort before stumbling at a time, our manager expands many promising nodes (possi-
on the best line of play.                             bly hundreds of them), to have enough work to keep multiple
  Our iterative value solution works for similar reasons. A back-end prover processors busy.
position may require considerable effort to formally deter- When a node is selected for expansion, it is added to
mine its proven value. However, the higher/lower the score a work-to-do ﬁle that is used as input to the prover pro-ProofManager( Seeding[] ) {                           Prover() {
 // Seeding: seeding line for the proof                 repeat {
 // Seeding[ 1 ] is the opening position                  GetWork( pos, thresh );
 // MIN: starting proof heuristic threshold
 // WIN: ending proof threshold                           // HeuristicSearch returns alpha-beta heuristic value
 // INC: heuristic increment between likely proofs        heur = HeuristicSearch( pos, thresh );

 // Iterate on heuristic threshold                        // If value inside threshold range, do PNSearch
 for ( thresh = MIN; thresh <= WIN; thresh += INC )       lower = LOSS; upper = WIN;
   // Iterate over the seeded line                        if( -thresh*2 < heur && heur < 2*thresh ) {
   for ( move = Length( Seeding ); move > 0; move -= 1 ) {  // This is a simplified version of the actual code
     pos = Seeding[ move ];                                 // Check for WIN, at most DRAW, or UNKNOWN
                                                            result = DFPNSearch( pos, IS_WIN );
     // Solve current position to threshold                      if( result == PROVEN ) { lower = WIN ; }
     repeat {                                               else if( result == DISPROVEN ) { upper = DRAW; }
       worklist = PNSearch( pos, thresh );
       if( NotEmpty( worklist ) ) {                         if( lower != upper && time remaining ) {
        StartProvers( worklist, results, thresh );            // Check for LOSS, at least DRAW, or UNKNOWN
        WaitForResults( worklist, results );                  result = DFPNSearch( pos, IS_LOSS );
        UpdateProofTree( pos, results, thresh );                  if( result ==  PROVEN ) { upper = LOSS; }
       }                                                      else if( result == DISPROVEN ) { lower = DRAW; }
     } until ( IsEmpty( worklist ) );                       }
   }                                                      }
  }                                                       SaveResult( pos, thresh, heur, lower, upper );
}                                                       }

               Figure 3: Proof manager                             Figure 4: Proof solver process

cesses. The back-end is given information for the generation rent proof threshold. The (expensive) proof search attempts
of heuristic proof numbers and any proven information that to formally prove the result of the current position. The latter
is known about the position (e.g., it might already be known is only done if the former indicates it is needed.


that it is not a loss).                                 Each back-end position is ﬁrst searched by an ¦¨§ searcher
  The proof manager saves all back-end search results so that using a heuristic evaluation function and the endgame
they can be re-used for searches with a different heuristic databases. The search is limited to 25 seconds, reach-
threshold (or from a different opening). A persistent B-tree ing a depth of 17 to 23 ply plus search extensions. The
is used to store information on every position examined in heuristic value returned is compared to the search threshold.
every opening, including both the back-end results and the Values outside the threshold range are considered as likely
backed-up values computed by the front end.           wins/losses by the proof tree manager. If the heuristic value
  In the cases where the back-end proof search does not pro- is more than twice the size of the threshold, then no further
vide enough information to answer the front end’s question of processing is done; the formal proof search is postponed until
interest, the heuristic score from the back end is used to gen- later in the proof when we will have more conﬁdence that we


erate heuristic proof and disproof numbers. CHINOOK is used really need this result.
                                                                                   



to provide the heuristic scores. If the ¦¨§ search result is small The prover uses Nagai’s Df-pn algorithm [Nagai, 2002],
                                                                                                 
enough to initiate the proof search, then the result is used to a depth-ﬁrst search variant of best-ﬁrst PNS. Df-pn was pre-
help initialize the proof numbers. The proof number for a win ferred over PNS, in part, because of memory concerns. The
is a function of: 1) the difference between the heuristic score algorithm’s space requirements are limited by the size of the


and the heuristic threshold (a high score is more likely to be transposition table. In contrast, PNS needs to store the entire
                                                                                    
a win than an even score), and 2) a penalty is added for posi- tree in memory. This gives Df-pn an important advantage,
tions where both sides have a king, as these tend to be much since memory is also needed to reduce the frequency of costly


harder to prove.                                      disk I/O caused by endgame database accesses.
                                                                                 
  The disproof number for a loss is the same as the proof The time limit for the Df-pn component is 100 seconds


number for a win, with one exception. We use one additional per search. Most of the search time is spent trying to answer
                                                 §
statistic from CHINOOK. If the principal variation of the ¦ the “easy” question, the opposite result to that of the heuris-
search result depends on a draw from a database lookup, we tic search. For example, if the heuristic result indicates that
decrease the disproof number. Proof numbers for a loss and the side to move has a large advantage (a possible win), the
disproof numbers for a win are deﬁned similarly. As a ﬁnal prover ﬁrst tries to prove or disprove the position as a loss.
modiﬁcation, the numbers that depend on the minimum of This was done because this was usually the easier question to
their child values (as opposed to the sum) are divided by the answer and a disproof of a loss or win may be a sufﬁcient an-
average branching factor.                             swer for the proof manager given that we expect the value of
                                                      the proof to be a draw. If a disproof for the question is found
4.2  Proof Solver (back end)                          in less than the maximum time allotted, another proof search


Pseudo-code for the back-end prover is shown in Figure 4. It is started to answer the other proof question.
                                        §
is a novel combination of a traditional heuristic ¦ search and Proving the value of a node implies ﬁnding a path to the
a proof search. The (cheap) heuristic search value is used to endgame databases (or a draw by repetition). Clearly, the
determine whether the current position is relevant to the cur- fewer pieces on the board, the “closer” one is to a databaseposition and the easier it should be to (dis)prove. In addition, beyond 10%. Many machine architectures do not have
it should be much easier to prove a win or disprove a loss if the hardware reliability for this sustained I/O demand.
one side has more pieces than the other side. We combine 3. The massive I/O means that we can only use local I/O;
these two factors to initialize the proof and disproof numbers, network I/O is too slow. That limits the machines that
giving more attention to fewer pieces and favorable positions.
                                                          we can add to the computation to those that have 300
Furthermore, because the standard Df-pn algorithm has a   GB  of available local disk.
fundamental problem of computing (dis)proof numbers when
position repetitions are present, the techniques in [Kishimoto 4. I/O errors. Our programs are instrumented to detect and
and Muller¨ , 2003] are incorporated into the solver.     recover (if possible) from most types of I/O errors.
4.3  Graph  History Interaction                       5   Results
A forward-search-based proof cannot be correct unless the The White Doctor opening was chosen as the ﬁrst candidate
Graph History Interaction problem (GHI) is properly ad- to solve because of its importance in tournament practice to
dressed. GHI can occur when a search algorithm caches and the checkers-playing community. The opening is one of the
re-uses a search result that depends on the move history. In most difﬁcult of the three-move ballots, with Black starting
checkers, repeated positions are scored as a draw. It is pos- off with a large disadvantage. Many decades of human anal-
sible that the value of a search is inﬂuenced by a draw-by- ysis determined that Black’s desperate situation meant that a
repetition score, and this result is saved in the proof tree or in checker had to be sacriﬁced to relieve the pressure. In a typi-
a transposition table. If this cached result is later reached by a cal game, Black is down material for most of the game, barely
different move sequence, it might not be correct—we do not hanging on to salvage a draw. Is the human analysis correct?
know if the draw-by-repetition scores are correct.      The White Doctor proof began in November 2003 and a
  In the back-end prover, GHI is correctly handled by utiliz- heuristic proof for a threshold of 125 was completed one
ing the new technique described in [Kishimoto and Muller¨ , month later. For the next eight months, computer cycles were
2004]. GHI is avoided in the boundary between the front- spent increasing the heuristic threshold to a win and verify-
end tree and the back-end searches by not communicating ing that there were no bugs in the proof.2 In August 2004, we
any move history information to the back-end. Finally, in the thought the proof was complete, but an inspection showed
front-end manager, GHI is avoided by not saving any value that some trivial positions with an advantage of 7 or more
in the proof tree that is unsafely inﬂuenced by a draw-by- checkers had been eliminated from the proof (an accidental,
repetition score somewhere in its subtree. This may cause the historical error). This was corrected and in January 2005, we
manager to spend extra time searching the tree, but no ex- completed the last of the unresolved positions.
tra prover searches need be performed, as the prover results Is the proof correct? The endgame databases are being
stored in the tree are path independent.              veriﬁed by Ed Gilbert, the author of the KINGSROW check-
                                                      ers program. He has independently veriﬁed that our 9-piece
4.4  Implementation  Insights                         databases and 30% of our 10-piece databases are correct (his
The effort to turn likely wins and likely losses into proven computation is ongoing). The front-end White Doctor proof
values takes the vast majority of search effort. This holds tree is consistent and correct, assuming that all the back-end
even for a fairly high initial heuristic threshold, where likely proofs returned the right answer. Many of the back-end val-
wins/losses are positions that human checkers experts agree ues have been re-veriﬁed by a different solver developed as
are “game over”. The major reason for this is postponing part of this project, increasing our conﬁdence that the proof
moves; a non-winning side always takes the path of maximum is indeed correct. The proof is available online at http:
resistance. For example, the losing side in a position is able //www.cs.ualberta.ca/˜chinook. Several strong play-
to make terrible moves, such as sacriﬁcing a checker for no ers have looked at the proof lines and found no errors.
apparent gain, to postpone reaching the endgame databases; Some interesting statistics on the proof include:
the unknown aspect of a position with more than 10 pieces on 1. Number of positions given to the back-end to solve (ex-
the board (no matter how hopeless the position) is preferable cluding work that was used for experiments or shown to
to a known database loss. These lopsided positions must still have bugs): 841,810.
be chased down to reach a proven conclusion.
                                                        2. Number of positions in one minimal proof tree: 223,178.
  The proof process is computationally demanding. Some of
                                                          The minimal proof tree is not a minimum proof tree. We
the performance issues include:
                                                          did not try to maximize the usage of transpositions or
 1. The proof process spends most of its time accessing the choose the branches leading to the smallest subtree in
    endgame databases. The cost can be reduced by locality generating the proof tree.
    of disk accesses and caching. Smart organization of the 3. Longest line searched in the front-end proof tree: 67 ply.
    endgame databases and use of a 4GB machine (most of
    the memory going to I/O caching), means that 99% of 4. Longest line in our minimal proof tree: 46 ply. The leaf
    all endgame database positions do not require I/O.    node in the tree is the result of a 100 second proof num-
                                                          ber search (to a variable depth, possibly as much as 45
 2. Despite the above performance optimizations, the proof
    process is still I/O intensive—keeping the I/O subsystem 2Several minor problems were found, necessitating re-doing
    at maximum capacity. It is rare to see the CPU usage some of the calculations.