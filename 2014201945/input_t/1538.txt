                     Temporal     Context    Representation      and  Reasoning

                         Dan  Moldovan,   Christine  Clark, Sanda   Harabagiu
                                    Language  Computer   Corporation


                                       Richardson,  Texas, 75080
                 


                 moldovan,      christine,       sanda  ¡ @languagecomputer.com


                    Abstract                          2   Approach
                                                      Several logic or semantic standard approaches to represent
    This paper demonstrates how a model for tempo-    time (or events in time) have been deﬁned. The most com-
    ral context reasoning can be implemented. The ap- mon ones include absolute dating schemes, relative event or-
    proach is to detect temporally related events in nat- dering or duration based approaches. Decisions about the
    ural language text and convert the events into an nature of the event (instantaneous or extended) have to be
    enriched logical representation. Reasoning is pro- made. The problem with many discrete schemes for natural
    vided by a ﬁrst order logic theorem prover adapted language applications (such as Mani and Wilson, 2000) is the
    to text. Results show that temporal context reason- lack of absolute timestamps for many events. Propagation ap-
    ing boosts the performance of a Question Answer-  proaches to assign absolute time stamps to event clauses for
    ing system.                                       sequence recognition have been implemented [Filatova and
                                                      Hovy, 2001]. However, besides the recognition problems (Fi-
                                                      latova and Hovy report 52% accuracy) these approaches do
                                                      not capture temporal relations that are based on duration of
1  Introduction                                       events.
                                                        Relative event orderings and duration relations that hold
Representing and reasoning about time-dependent informa- true at all times should not be labeled with absolute times-
tion is important for applications ranging from databases, tamps as in: People are born before they die. This holds true
planning, natural language processing, and others. For exam- also for event orderings commonly found in user manuals,
ple, temporal reasoning is essential in question answering to like IT support information or cookbooks as in: What process
successfully addressing a time sensitive and dynamic world. do I need to terminate after a failed query?
Questions requiring temporal relations are not currently solv- [Allen, 1991] demonstrates a constraint propagation ap-
able in most state of the art question answering systems. Of proach based on a set of possible interval relations that could
the factoid TREC questions from 2001-2004 approximately capture this, but the recognition of these events and their re-
8.7% require temporal context reasoning. A temporal context lations is still an open research area.
scopes changing world views and serves as a tool for disam- Our approach uses a hybrid of the above mentioned meth-
biguating time dependent events or intervals. Questions such ods. Passage retrieval makes use of a descrete time scale in
as Who was the president of South Korea when Bill Clinton the form of temporal indexing so as to capture all the relevant
was President of the US? need temporal event detection and candidate passages that may not have absolute time speciﬁed
context based reasoning.                              in the document text. For the time-event model, high cover-
  While there has been much theoretical research and mod- age signal words and phrases that specify how temporal el-
eling of context reasoning in the temporal domain, few sys- ements should be related are used. The chosen signals are
tems have reported an evaluation of end to end temporal con- based on the annotations in TimeML used in the TERQAS
text enhanced question answering. This paper presents such a project [Pustejovsky et al., 2002] and are mined for and an-
system. We report on (1) temporal context indexing for pas- notated in a sampling of articles from the TREC collection.
sage retrieval, (2) a fast and robust representation of time and The signals are then classiﬁed by the type of temporal rela-
annotation of time events, (3) the implementation of a ma- tion they express, such as overlapping, inclusion, ordering,
chine learning based temporal event recognition module, (4) and more. This data is used for training the automatic tempo-
a model for a knowledge representation that maps natural lan- ral event detection module that recognizes 7 distinct temporal
guage context into ﬁrst order logic Suggested Upper Merged event interval relations on the question and its answer candi-
Ontology(SUMO)[Niles and Pease, 2001] predicates, and (5) dates. The detected temporal events enrich a logical form
a temporal context reasoning engine.                  representation of the question and answer candidates withSUMO   predicates and functions. Based on these temporal means to bootstrap a sample of the TREC collection for an-
constraints, a context resolution engine operates as an answer notation purposes. The goal of the annotation was to provide
candidate ﬁlter.                                      data for a machine learning algorithm aimed at disambiguat-
                                                      ing signal words, detecting time events, and determining the
3  Passage  Retrieval  with Temporal   Context        boundaries of the time event.
One common  class of time dependent questions targets facts Category (example) Interpretation     %
that are rooted in an absolute time, such as: Who led the NHL                                     Dist
in playoff goals in June 1998? To ensure that all passages rel- Sequence (before, after) E1 happened in full be- 12.7
evant to a temporally constrained question are retrieved it is                fore E2
necessary to index the temporal contexts in a document. The Containment (in, of) E1 is contained by E2 30.2
approach is to scan each document in a collection for its time Overlap (at,as,on) An interval exists that is 28.6
stamp as well as any underspeciﬁed or relative references to                  contained by E1 and E2
time. A date resolution module processes all underspeciﬁed Right Open Interval E1 is the left boundary 6.1
and relative dates to accurately anchor these temporal refer- (from, since)   of E2, right is undeﬁned
                                                         Left Open Interval (to, E2 is the right boundary 4.5
ences in a calendar year. The context ﬁeld consists of a (year, until)        of E1, left is undeﬁned
month, day, hour, minute, second) tuple, where any member Closed Interval (for, all) E1 lasts for the duration 6.3
in the tuple is optional. For a document with time, T(1998,                   of E2
06, 15, X, X, X), the following temporal context entries are Absolute Ordering E1 has an ordering rela- 11.6
computed and displayed in Table 1:                       (ﬁrst, last)         tive to E1

      Temporal Reference Resolved Date                Table 2: Signal Annotation Categories and their Distribution
      last year          T(1999,X,X,X,X,X)
      next week          T(1998,06,16-22,X,X,X)       The requirements of the annotation scheme used to mark up
      in a week          T(1998,06,22,X,X,X)          1000 sentences from NYT, 150 from APW, and 150 sentences
      today              T(1998,06,15,X,X,X)          from XIN were robustness, simplicity, and sufﬁcient granu-
                                                      larity of the time events.
          Table 1: Resolved Temporal Context            Time  events are deﬁned as related intervals, which are
                                                      bound by a signal expression indicating the relation of the
  The resolved references as well as the document time time events. Additionally, each signal can modify up to two
stamp is indexed and made searchable for time dependent events and can determine one of the following relations: se-
queries. For the question above the query issued to the in- quence, containment, overlap, open interval (left or right),
dex is:                                               duration and absolute ordering. An event is interpreted as an
( human) AND (lead) AND (nhl OR (national AND hockey  interval bound by signal words or phrases and can be noun

AND league)  3) AND (playoff) AND (goal) AND T(1998, 06, phrases (the bombing) or verb groups (participated).
X, X,X,X,X)                                             Since the current model operates at the sentence level, a
  For questions involving a time range, the query is trans- marker is added to signals that need more information to re-
lated into a conjunction of time operators. As an example, solve its arguments such as implicit context or missing dis-
What Chinese Dynasty was during 1412-1431? translates to: course. Table 2 lists the categories of signal words, their nat-
( organization) AND  (chinese) AND  (dynasty) AND     ural language interpretation, and their distribution across a
(T(1412,X,X,X,X,X) OR T(1413,X,X,X,X,X ) OR ... OR    sampling of the TREC collection.


T(1431,X,X,X,X,X ))                                   Example annotations based on the signal categories:


                                                                   ¡                   ¡
                                                                                                   ¢


  Internally the search engine computes the allowed range Which country E1 id=889 ¢ declared /E1 id=889 inde-


                                                               ¡                         ¡           ¡
                                                                                                   ¢


and searches for dates indexed in that range. The temporal pendence S id=889 class=contain ¢ in /S id=889 E2


                                                                   ¡
                                                                              ¢


context for the question is enforced by searching the index for id=889 ¢ 1776 /E2 id=889 ?


                                                      ¡                               ¡
                                                                                                ¢


the context detected in the question and applying document S id=358 class=sequence ¢ After /S id=358 quickly


                                                      ¡                       ¡
                                                                                          ¢


dates to all passages retrieved that do not have an explicit con- E1 id=358 ¢ decapitating /E1 id=358 the bird, Susan


                                                      ¡                   ¡
                                                                                     ¢
text within a window of 3 sentences. These resolved dates are E2 id=358 ¢ scalded /E2 id=358 the carcass.
passed along to the answer processing module which invokes
the signal based temporal event recognizer and the context 5 Detection of Temporally Ordered  Events
resolution modules to verify that the candidate answers do
meet the temporal constraints in the question         Automated discovery of temporally ordered events requires
                                                      detecting a temporal triple (S,E1,E2) which consists of a time
4  Data  Annotation                                   dependent signal word (S) and its corresponding temporal
                                                      event arguments, (E1) and (E2). Detection of a temporal triple
For an initial analysis of the signal words, the TimeML is complicated by two issues:
[Pustejovsky et al., 2000] TimeBank4 data functioned as a (1) Disambiguation of signal words: Not all signal words
source of time signal expressions to be used as seeding ma- are unambiguously classiﬁed as time indicators.
terial in the TREC 2002 corpus. The signal list served as a (a) He stood before the judge vs He proofread themanuscripts before mailing it to the publisher          Feature Description Origin
(b) He woke up at 10:00 vs He looked through the window at Signal surface form [Hindle and Rooth, 1993]
the rising sun                                          Chunk’s phrase tag  [Kudo and Matsumoto, 2001]
(2) Attaching events to signal words: Although some tem- Chunk’s hyperterms [new]
poral events are found near their signal, many signals occur +/- 1 chunk’s phrase tag [Kudo and Matsumoto, 2001]
with their temporal events underspeciﬁed (non-local).   +/- 1 chunk’s hypert- [new]
                                                        erms
(a) The problem was resolved after 4 hours of intensive main-
                                                        +/- 2 chunk’s phrase tag [Kudo and Matsumoto, 2001]
tenance but before anybody was harmed.                  +/- 2 chunk’s hypert- [new]
  In the above example the signal word after easily attaches erms
to resolved and 4 hours, while the second signal word, before
has a non-local E1 reference (also resolved).         Table 3: Signal and Local Attachment Features and their Ori-
  To address these issues machine learning is employed in gin
two stages, ﬁrst to recognize and disambiguate signals, and
second to discover and attach temporal events to their signals.
The input to the learner is the data annotated. The predictive local attachment algorithm followed by a signal chaining
classiﬁers that result from learning are used to automatically attachment algorithm.
detect temporal triples (signals with their attached temporal The Local Attachment Algorithm proceeds from left to
events) in natural language text.                     right evaluating each unattached chunk to its nearest signal
                                                      by generating features for classiﬁcation. The decision associ-
Signal Disambiguation                                 ated with the features is one of Skip (do not attach), E1 (attach
In the ﬁrst stage of the machine learning process, a signal’s as E1), or E2 (attach as E2). The features used and their origin
surface form is classiﬁed either as a temporal (signal) or are listed in Table 4.
non-temporal occurrence, with signals classiﬁed further as to The Signal Chaining Attachment Algorithm enables sig-
how they order their events, see Table 2.             nals that are missing an attachment to pick up an attach-
  A chunk parse tree is examined for text segments that ment from another signal, called link signals. The algorithm
match the surface form of a signal which are placed in their proceeds left to right evaluating a signal’s missing argument
own chunk if necessary. A set of features, listed in Table 3, against another signal’s existing argument. The decision is ei-
is then computed and used to classify each of these chunks. ther Skip, E1, or E2 wherein the latter two result in an attach-
The hyperterm feature can be described as a broadly appli- ment. The algorithm iterates until no attachments are made.
cable feature space constructed from SUMO. Each SUMO  Although this algorithm uses the features in Table 3, their
class, instance, or relation is a unique string, here called a contribution is low and so motivated the additional features
term. All terms are collected and connected to their hypert- listed in Table 4.
erm via the SUMO axioms (subclass) (subrelation) and (in-
stance). The result is a directed acyclic graph connecting all Feature Description Origin
1020 terms to their hyperterms and rooted at the SUMO class Missing signal argu- [new]
Entity. This hyperterm tree along with the WordNet to SUMO ment (E1,E2)
                                                                                      [        ]
mappings [Niles and Pease, 2003] is prepared ofﬂine. Us- Signal class       [mod. from Allen, 1991 ]
                                                        Link  signal surface [Hindle and Rooth, 1993]
ing this resource to generate the hyperterm feature consists form
of computing the union of the hyperterms for all WordNet Link signal argument [new]
concepts (senses) for each word in the chunk.           (E1,E2)
  The intuition behind using SUMO is: (1) Coarse grained Link signal class  [mod. from [Allen, 1991]]
distinctions appear to be better represented in SUMO    Parsing    direction standard
hypterterm tree than in WordNet, that is, a single term (left,right)
“Process” appears to capture the idea of eventness easily
where several WordNet hypernyms would be required to      Table 4: Signal Chaining Features and their Origin
capture the same distinction. (2) All open class words
are united in a single hyperterm tree whereas in WordNet Results
verbs have shallow hypernymy and Adjective and Adverbs Each classiﬁer was built using the LIBSVM 1 implementa-
have no hypernymy.  This allows for i) better general- tion of Support Vector Machines, with the radial basis kernel,
ization and similarity across chunks that have words not  ¢¡¤£¦¥¨§
©§¢ , and included performing a grid search to
seen during training since unseen words will still share ﬁnd the best model parameters. Measurements were taken
a signiﬁcant set of hyperterm features and for ii) uniﬁed by randomizing the annotated sentences and evaluating each
treatment of all four open lexical classes in the software. tenth of the data by training on the other 90% (10-fold cross-
The resulting decision will be one of 8 choices correspond- validation). The results measure the performance of the mod-
ing to “No signal” and the 7 types of signals listed in Table 2. ule as a whole. Measuring individual decisions of the clas-
                                                      siﬁers are not instructive due to the dominance of NoSignal
Temporal  Event Attachment                            decisions during disambiguation and Skip decisions during
Once a signal has been identiﬁed, its associated events (E1
and E2) must be attached. This task is achieved with a   1http://www.csie.ntu.edu.tw/ cjlin/libsvm/

attachment parsing.                                       Signal Class          SUMO  Logic
                                                           



                                                           S sequence, E1, E2 ¡ earlier(E1,E2)
                                                           



         Task                F-measure                     S contain, E1, E2 ¡  during(E1,E2)
                                                           

                                                           S overlap, E1, E2 ¡  overlapsTemporally(E1,E2)

         Signal detection    71.4%                         

                                                           S open right, E1, E2 ¡ meetsTemporally(E1,E2)

         Attachment          49.1%                         



                                                           S open left, E1, E2 ¡ meetsTemporally(E2,E1)
                                                           

                                                           S closed, E1, E2 ¡   duration(E1,E2)
         Table 5: Automated Detection Results
                                                              Table 6: Signal Class to SUMO Mapping
The attachment results are affected negatively by parsed
chunk boundaries not matching the temporal event text seg-
ment marked by the annotator, which results in an annotated Once the SUMO predicate is chosen, the arguments to the
attachment being scored as incorrect. An attachment will also predicate are the event argument ids from the heads of the
score as incorrect if it is not the correct argument of the signal, chunks passed as attachments to the signal expression. Since
or if the signal was not classiﬁed correctly. No partial credit all temporal SUMO predicates operate on time intervals, ab-
is given. In the current data set 41.8% of the attachment an- solute times stated in the text are translated into a pair of time
notations fail to align with a chunk boundary. This indicates point predicates to specify the begin and end of the interval.
that temporal event boundaries should not always rely on the A detailed example follows for the text: That compares with
parse chunk boundaries. An attachment will also score as in- about 531,000 arrests in 1993 before Operation Gatekeeper
correct if it is not the correct argument of the signal, or if the started.
signal was not classiﬁed correctly. The scoring program is The temporal event recognizer disambiguates in and
strict in that a temporally ordered event is correct only when before as temporal signals, and classiﬁes (1) in as a contain
the signal has been classiﬁed correctly and both event argu- interval signal, and (2) before as a sequence interval signal.
ments have been detected and assigned in the proper order. The Local Attachment and Signal Chaining algorithms then
Based on the results of our experiments reported in Table 5, determine the time event arguments for each signal. The
with 1300 sentences from the TREC corpus, it seems ap- output triples are (S1:contain=in, E1=arrests, E2=1993)
parent that more training data is needed. In order to ver- and (S2:before=before, E1=arrests, E2=started). Once
ify that, the method and algorithm used for the current im- the mapping for the temporally ordered events and the
plementation is sound and scalable, another experiment was absolute time events are complete, the SUMO predicates are
conducted using the same methodology over half the corpus generated. Predicates that were derived from signal words
(650 sentences). The results of that experiment posted an F- replace the signals in the logical form.
measure of 52.7% for signal detection and 36.1% for attach- ... 531 000 NN(x2) & arrest NN(x2) & 1993 NN(x3) & Op-
ment. Comparing that to the original results it is clear that the eration NN(x4) & Gatekeeper NN(x5) & nn NNC(x6,x4,x5)
technique outlined in this section scales well and will beneﬁt & start VB(e2,x6,x10) & earlier(WhenFn(x2),
from the ongoing effort to annotate more training data. WhenFn(e2)) & Time(BeginFn(x11), 1993, 1, 1, 0, 0,
                                                      0) &  Time(EndFn(x11), 1993, 12, 31, 23, 59, 59) &
6  A  Knowledge   Representation   with               during(WhenFn(x3), x11) & during(WhenFn(x2), x3)
   Temporal   Context
                                                      7   Temporally   Enhanced   Inference
The output of the Temporal Event Detection, described in
section 4, is transferred to the SUMO enhanced logical form The temporal context resolution module employs a ﬁrst or-
module. The function of this module is to translate the natu- der logic resolution style theorem prover adapted for natural
ral language candidate sentences, marked up with time event language text processing [Moldovan et al, 2003]. The Set of
chunks, to a temporally enhanced ﬁrst order logic assertion. Support (SOS) is the search strategy employed by the prover
The input time event chunks are labeled with the class of the to partition the axioms into those that have support and those
signal from the list in Table 2, along with the parsed chunks that are considered auxiliary [Wos, 1988]. This strategy re-
identiﬁed as the time event arguments to the signal.  stricts the search such that a new clause is inferred if and only
  The Knowledge  Representation for the temporally en- if one of its parent clauses come from the SOS. The infer-
hanced logic form is layered on top of the Logical Repre- ence rule sets are based on hypperresolution, paramdodula-
sentation proposed in [Rus and Moldovan, 2002], where the tion, and demodulation. Hyperresolution is an inference rule
ﬁrst order logic structure is derived from the syntactic parse that does multiple steps in one, paramodulation introduces
of the text and each token in the text is converted to a pred- the notion of equality substitution for the demodulators re-
icate. From this structure temporally related SUMO predi- quired on the temporal axioms. Since temporal reasoning is
cates are generated based on hand coded interpretation rules intensive and may require long proofs, hyperresolution and
for the signal classes. The purpose of the interpretation rules paramodulation inference rules are necessary as they allow
is to deﬁne an algorithm for assigning a signal word to a for a more compact and efﬁcient proof by condensing multi-
SUMO  predicate and deﬁning the manner in which the slots ple steps into one.
for the predicate are determined. Table 6 enumerates the sig- The inputs to the context resolution module include:
nal classes, and the SUMO predicate corresponding to the (1) The context relevant pieces of the natural language ques-
interpretation rule.                                  tions and candidate answers converted to a SUMO enhancedﬁrst order logical form [Rus and Moldovan, 2002]. The ques- & territory NN(x6)  &      during CTMP(x6,x9)
tion predicates are negated to invoke a proof by contradiction & Time CTMP(BeginFn(x9),1920,1,1,0,0,0) &
(2) A set of empirically derived world knowledge axioms. Ex: Time CTMP(EndFn(x9),1946,12,31,23,59,59)
EVIDENCE  IS SUPPORT FOR A CLAIM                      Answer Axiom:


evidence NN(x2) - ¢ support NN(x2) & for IN(x2,x3) &  exists e1 e2 x1 x2 x3 x4 x6 x7 x8 x9 (France NN(x1)
claim NN(x3)                                          &    country NE(x1) &   have VB(e1,x1,x2) &   differ-
(3) Linguistic transformation rules derived from the input ent JJ(x2) & relationship NN(x2) & with IN(x2,x6) &
parse of the question and its candidate answers.      Syria NN(x6) &  partly RB(e1) & because IN(e1,e3) &


Ex: THE LEADER OF X, LEADS X.                         once RB(e3) &  French NN(x5) &  mandate VB(e3,x5,x6)
                                               ¡

human  NE(x1) &   leader NN(x1) &  of IN(x1,x2) - ¢   &      territory NN(x6)   &      during CTMP(x6,x9)
lead VB(e1,x1,x2)                                     &       Time CTMP(BeginFn(x9),1920,1,1,0,0,0)    &
(4) WordNet derived axioms such as lexical chains[Moldovan Time CTMP(EndFn(x9),1946,12,31,23,59,59))
and Novischi, 2002] and glosses. Ex: TO START SOME-   Linguistic Axiom:


THING  IS SEMANTICALLY   RELATED  TO ESTABLISHING     all x1 (French NN(x1)   France NN(x1))


SOMETHING                                             Lexical Chain Axiom:
                                                                                     
start VB(e1,x1,x2) - ¢ establish VB(e1,x1,x2)         all e1 x1 x2 (mandate VB(e1,x1,x2) control VB(e1,x1,x2))
(5) A SUMO Knowledge Base of temporal reasoning axioms SUMO  Axioms:
that consists of axioms for a representation of time points and Two time intervals overlapsTemporally if and only if each
time intervals, Allen primitives, and temporal functions. one is a temporalPart of the other:


Ex: DURING IS A TRANSITIVE ALLEN PRIMITIVE            all I1 I2 (ISA(I1, TimeInterval) & ISA(I2, TimeInterval)
                                                                                      ¡
during(TIME1, TIME2) & during(TIME2, TIME3) - ¢ dur-  & overlapsTemporally CTMP(I1, I2)  (exists I3 (ISA(I3,
ing(TIME1, TIME3)                                     TimeInterval) & temporalPart CTMP(I3, I1) & temporal-
  Axioms in set (1) are loaded into the Set of Support. The Part CTMP(I3, I2))))
predicates representing the temporally relevant information Interval1 is temporalPart of Interval2 if Interval1 is
in the question are anded together, negated, and universally during Interval2:
quantiﬁed, so as to invoke a proof by contradiction. The tem- all T1 T2 (ISA(T1, TimeInterval) & ISA(T2, TimeInterval)


poral predicates for the candidate answer are also anded to- & during CTMP(T1, T2)   temporalPart CTMP(T1, T2)).
gether, existentially quantiﬁed and loaded into the SOS. The Interval1 is during Interval2 if Interval1 starts after
axioms in sets (2) - (3) are loaded into the Usable list to assist Interval2 and Interval1 ends before Interval2:
in the inference process between the question and the answer. all I1 I2 ((before CTMP(EndFn(I1), EndFn(I2)) &

  The output of the temporal context module comprises ﬁl- before CTMP(BeginFn(I2), BeginFn(I1)))     dur-
tered and re-ranked answers that are scored based on their se- ing CTMP(I1,I2)).
mantic and temporal similarity to the question. The inference A mapping of question predicates to the inferred answer
engine will continue seeking a proof until any of the TIME predicates is provided in Table 7:
predicates are unsatisﬁed. Partial satisﬁability is permitted
for other predicates in the question via a backoff algorithm Question Predicates   Answer Predicates

integrated in the inference engine [Moldovan et al, 2003]. country AT(x2)         French NN(x5)      ¢
  The following example illustrates how a temporal context                        France NN(x5)
resolution module is used to verify the temporal constraints control VB(e1,x2,x1) mandate VB(e3,x5,x6)
of a question over a candidate answer:                  Syria NN(x1)              Syria NN(x6)
Question: What country controlled Syria in 1930?        overlapsTemporally CTMP(e1, during CTMP(x6, x9) &
                                                        x3)                   &   Time CTMP(BeginFn(x9),
Question Logical Form:                                  Time CTMP(BeginFn(x3),    1920, 1, 1, 0, 0, 0) &
country AT(x2)     &      control VB(e1,x2,x1)   &      1930, 1, 1, 0,  0, 0) &   Time CTMP(EndFn(x9),
Syria NN(x1)    &     overlapsTemporally CTMP(e1,x3)    Time CTMP(EndFn(x3),      1946, 12, 31, 23, 59, 59)
&       Time CTMP(BeginFn(x3),1930,1,1,0,0,0)    &      1930, 12, 31, 23, 59, 59)
Time CTMP(EndFn(x3),1930,12,31,23,59,59)
Question Axiom:                                            Table 7: Question to Answer Predicate Resolution
-(exists e1 x1 x2 x3 ( country AT(x2) & control VB(e1,x2,x1)
&   Syria NN(x1)  &   overlapsTemporally CTMP(e1,x3)    Proofs for answers which do not have the correct context
&       Time CTMP(BeginFn(x3),1930,1,1,0,0,0)    &    will fail, resulting in the candidate answer being pruned from
Time CTMP(EndFn(x3),1930,12,31,23,59,59)))            the answer list. This in turn promotes all candidates below.
Candidate Answer 5:                                   As an example, the context resolution module will fail to ﬁnd
France has a different relationship with Syria, partly because a proof for the ﬁrst candidate answer returned by the answer
it was once a French-mandated territory, from 1920-1946 processing module (without temporal reasoning), whose doc-
Answer Logical Form:                                  ument date is 1998:
France NN(x1) &  country NE(x1) &  have VB(e1,x1,x2)  The United States did not punish Israel when it occupied ter-
& different JJ(x2) & relationship NN(x2) & with IN(x2,x6) ritories of some Arab countries such as Palestine and Syria,
& Syria NN(x6) & partly RB(e1) & because IN(e1,e3) &  and refused to comply with relevant U.N.resolutions on the
once RB(e3) &  French NN(x5) &  mandate VB(e3,x5,x6)  Middle East issues.