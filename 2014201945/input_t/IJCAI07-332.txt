          Image Modeling using Tree Structured Conditional Random Fields

          Pranjal Awasthi                Aakanksha Gagrani                Balaraman Ravindran
      IBM India Research Lab∗                Dept. of CSE                      Dept. of CSE
             New Delhi                         IIT Madras                       IIT Madras
        prawasth@in.ibm.com            aksgag@cse.iitm.ernet.in           ravi@cs.iitm.ernet.in


                    Abstract                          Bottom-up cues refer to the statistical properties of individual
                                                      pixels or a group of pixels derived from the outputs of various
    In this paper we present a discriminative framework ﬁlters. Top-down cues refer to the contextual features present
    based on conditional random ﬁelds for stochas-    in the image. This information represents the interactions that
    tic modeling of images in a hierarchical fashion. exist among the labels in the set Y.Thesetop-down cues
    The main advantage of the proposed framework is   need to be captured at different levels of scale for different
    its ability to incorporate a rich set of interactions tasks as described in [Kumar and Hebert, 2005]. Bottom-up
    among the image sites. We achieve this by inducing cues such as color and texture features of the image are in-
    a hierarchy of hidden variables over the given label sufﬁcient and ambiguous for discriminating the pixels with
    ﬁeld. The proposed tree like structure of our model similar spectral signatures. With reference to Figure 1 taken
    eliminates the need for a huge parameter space and from the Corel image database, it can be observed that {rhino,
    at the same time permits the use of exact and ef- land} and {sea, sky} pixels are closely related in terms of
    ﬁcient inference procedures based on belief prop- their spectral properties. However, an expanded context win-
    agation. We demonstrate the generality of our ap- dow can resolve the ambiguity. It also obviates the improba-
    proach by applying it to two important computer   ble conﬁgurations like the occurrence of a boundary between
    vision tasks, namely image labeling and object de- snow and water pixels. Further enlarging the context win-
    tection. The model parameters are trained using   dow captures expected global relationships such as 1) polar
    the contrastive divergence algorithm. We report the bear surrounded by snow and 2) sky at the top of the image
    performance on real world images and compare it   while water at the bottom. Any system that fails to capture
    with the existing approaches.                     them is likely to make a large number of errors on difﬁcult
                                                      test images. In this work we try to model these relationships
1  Introduction                                       by proposing a discriminative hierarchical framework.
Probabilistic modeling techniques have been used effectively
in several computer vision related tasks such as image seg-
mentation, classiﬁcation, object detection etc. These tasks
typically require processing information available at different
levels of granularity. In this work we propose a probabilistic
framework that can incorporate image information at various
scales in a meaningful and tractable model. Our framework,
like many of the existing image modeling approaches, is built
on Random ﬁeld theory. Random ﬁeld theory models the
uncertain information by encoding it in terms of a set S of
random variables and an underlying graph structure G.The
graph structure represents the dependence relationship among
these variables. We are interested in the problem of inferenc-
ing which can be stated as: Given the values taken by some
subset X ∈S, estimate the most probable values for another Figure 1: Contextual features at multiple scales play a vital
subset Y ∈S. Conventionally, we deﬁne the variables in the role in discrimination when the use of local feature fails to
set X as observations and the variables in the set Y as labels. give a conclusive answer.
  The information relevant for constructing an accurate
model of the image can be broadly classiﬁed into two cate- 1.1 Related Work
gories widely known as bottom-up cues and top-down cues.
                                                      In the past, [Geman and Geman, 1984]  have proposed
  ∗Part of this work was done while the author was at IIT Madras. Markov Random Field (MRF) based models for joint mod-

                                                IJCAI-07
                                                  2060eling of the variables X and Y. The generative nature of the advantages offered by hierarchical models and discrimi-
MRFs restricts the underlying graph structure to a simple native approaches in a single framework. The rest of the pa-
two dimensional lattice which can capture only local rela- per is organized as follows: We formally present our frame-
tionships among neighboring pixels, e.g. within a 4 × 4 or work in Section 2. In the section we also discuss the graph
a 8 × 8 window. The computational complexity of the train- structure and the form of the probability distribution. Train-
ing and inference procedures for MRFs rules out the pos- ing and inference for a TCRF are discussed in sections 3 and
sibility of using a larger window size. Multiscale Random 4 respectively. We present the results of our model on two
Fields (MSRFs) [Bouman and Shapiro, 1994] try to remove different tasks in section 5. A few possible extensions to our
this limitation by capturing the interactions among labels in a framework are discussed in section 6. We ﬁnally conclude in
hierarchical framework. Similar approach has been proposed section 7.
by [Feng et al., 2002] using Tree Structured Bayesian Net-
works (TSBNs). These approaches have the ability to capture 2 Tree Structured Conditional Random Field
long range label relationships. In-spite of the advantage of-
fered by the hierarchical nature, these methods suffer from Let X be the observations and Y the corresponding labels.
the same limitations of the generative models, namely, Before presenting our framework we ﬁrst state the deﬁnition
                                                                                            [
  • Strong independence assumptions among the observa- of Conditional Random Fields as given by Lafferty et al.,
                                                          ]
    tions X.                                          2001 .
  • Introduction of a large number of parameters by model- 2.1 CRF Deﬁnition
    ing the joint probability P (Y, X).
  •                                                   Let G  =(V,E)    be a graph such that Y is indexed by
    Need for large training data.                     the vertices of G.Then(X, Y)  is a conditional random
  Recently, with the introduction of Conditional Random ﬁeld if, when conditioned on X, the random variables yi ∈
Fields (CRFs), the use of discriminative models for classiﬁ- Y obey the Markov property with respect to the graph:
cation tasks has become popular [Lafferty et al., 2001]. CRFs p(yi | X,yj,i= j)=p(yi | X,yj,i∼ j).Herei ∼ j implies
offer a lot of advantages over the generative approaches by di- that yi and yj are neighbors in G.
rectly modeling the conditional probability P (Y | X).Since By applying the Hammersley-Clifford theorem [Li, 2001],
no assumption is made about the underlying structure of the the conditional probability p(Y | X) factors into a product of
observations X, the model is able to incorporate a rich set of potential functions. These real valued functions are deﬁned
non-independent overlapping features of the observations. In over the cliques of the graph G.
the context of images, various authors have successfully ap-
                                                                                
plied CRFs for classiﬁcation tasks and have reported signiﬁ-                 1
                                                                  p(Y | X)=        ψc(yc , X)         (1)
cant improvement over the MRF based generative models [He                    Z
et al., 2004; Kumar and Hebert, 2003].                                         c ∈ C
  Discriminative Random Fields (DRFs) which closely re- In the above equation C is the set of cliques of the graph
semble CRFs have been applied for the task of detecting man- G, yc is the set of variables in Y which belong to the clique
made structures in real world images [Kumar and Hebert, c and Z is a normalization factor.
2003]. Though the model outperforms traditional MRFs, it is
not strong enough to capture long range correlations among 2.2 TCRF Graph Structure
the labels due to the rigid lattice based structure which allows ×
for only pairwise interactions. [He et al., 2004] propose Mul- Consider a 2 2 neighborhood of pixels as shown in Figure 2.
tiscale Conditional Random Fields (mCRFs) which are capa- One way to model the association between the labels of these
ble of modeling interactions among the labels over multiple pixels is to introduce a weight vector for every edge (u, v)
scales. Their work consists of a combination of three differ- which represents the compatibility between the labels of the
ent classiﬁers operating at local, regional and global contexts nodes u and v (Figure 2a). An alternative is to introduce a
respectively. However, it suffers from two main drawbacks hidden variable H which is connected to all the 4 nodes. For
  •                                                   every value which variable H takes, it induces a probability
    Including additional classiﬁers operating at different distribution over the labels of the nodes connected to it (Fig-
    scales into the mCRF framework introduces a large ure 2b).
    number of model parameters.
  • The model assumes conditional independence of hidden
    variables given the label ﬁeld.
  Though a number of generative hierarchical models have
been proposed, similar work involving discriminative frame-
works is limited [Kumar and Hebert, 2005]. In this paper we
propose a Tree Structured Conditional Random Field (TCRF)
for modeling images. Our results demonstrate that TCRF is
able to capture long range label relationships and is robust
enough to be applied to different classiﬁcation tasks. The pri- Figure 2: Two different ways of modeling interactions among
mary contribution of our work is a method which combines neighboring pixels.

                                                IJCAI-07
                                                  2061  Dividing the whole image into regions of size m × m and L, W is a matrix of weights of size L×F estimated from
introducing a hidden variable for each of them gives a layer of the training data and f(.) is a transformation (possibly non-
hidden variables over the given label ﬁeld. In such a conﬁgu- linear) applied to the observations. Another approach is to
ration each label node is associated with a hidden variable in take Γi(yi, X)=logP (yi | X),whereP (yi | X) is the prob-
the layer above. The main advantage of following such an ap- ability estimate output by a separately trained local classi-
proach is that long range correlations among non-neighboring ﬁer [He et al., 2006].
pixels can be easily modeled as associations among the hid-
                                                      Edge Potential
den variables in the layer above. Another attractive feature is                              t,b
that the resulting graph structure induced is a tree which al- This is deﬁned over the edges of the tree. Let φ be a matrix
                                                      of weights of size L×Lwhich represents the compatibility
lows inference to be carried out in a time linear in the number                                        th
of pixels [Felzenszwalb and Huttenlocher, 2004]. Motivated between the values of a hidden variable at level t and its b
by this, we introduce multiple layers of hidden variables over neighbor at level t +1. For our quad-tree structure b =1, 2, 3
                                                      or 4.LetL denote the number of levels in the tree, with the
the given label ﬁeld. Each layer of hidden variables tries to                                         H
capture label relationships at a different level of scale by af- root node at level 1 and the image sites at level L and t
                                                      denote the set of hidden variables present at level t.Then
fecting the values of the hidden variables in the layer below.      h  y           h  ∈ H         y  ∈ Y
In our work we take the value of m to be equal to 2.The for every edge ( i, j) such that i L−1 and j
                                                                                         hT  L−1,by
quadtree structure of our model is shown in Figure 3. the edge potential can be deﬁned as exp( i φ j ).Ina
                                                      similar manner the edge potential between the node hi at level
                                                              th
                                                      t and its b neighbor hj at level t +1can be represented as
                                                           T  t,b
                                                      exp(hi φ  hj).
                                                        The overall joint probability distribution which is a product
                                                      of the potentials deﬁned above can be written as
                                                                             
                                                                                   T
                                                         P (Y, H | X) ∝  exp(    yi Wfi(X)            (3)
                                                                             y ∈
                                                                              i Y 
                                                                                          T  L−1,b
                                                                           +             hi φ    yj

                                                                             yj ∈Y hi∈HL−1
                                                                                 (  , )∈E
   Figure 3: A tree structured conditional random ﬁeld.                           yj hi
                                                                             L−2      
                                                                                              T  t,b
  Formally, let Y be the set of label nodes, X the set of                  +                 hi φ  hj)
observations and H be the set of hidden variables. We call                    t=1 hi∈Ht hj ∈Ht+1
({Y, H}, X) a TCRF if the following conditions hold:                                  (hi,hj )∈E
 1. There exists a connected acyclic graph G =(V,E)
    whose vertices are in one-to-one correspondence with 3 Parameter Estimation
    the variables in Y ∪ H, and whose number of edges                          T   {                    }
    | |  |  |−                                        Given a set of training images = (Y1, X1) ...(YN , XN )
    E  =  V    1.                                     we want to estimate the parameters Θ = {W, Φ}. A standard
 2. The node set  V  can  be partitioned into subsets way to do this is to maximize the conditional log-likelihood
    (V1 ,V2 ,...,VL) such that i Vi = V , Vi ∩ Vj = ∅ of the training data. This is equivalent to minimizing the
    and the vertices in VL correspond to the variables in Y. Kullback-Leibler (KL) divergence between the model distri-
                                                      bution   Y|X  Θ  and the empirical distribution Y|X
 3. deg(v)=1,    ∀v ∈ VL.                                   P (    ,  )                          Q(     )
                                                      deﬁned by the training set. The above approach, requires
  Similar to CRFs, the conditional probability P (Y, H | X) calculating expectations under the model distribution. These
of a TCRF factors into a product of potential functions. We expectations are approximated using Markov Chain Monte
next describe the form of these functions.            Carlo (MCMC) methods. As pointed by  [Hinton, 2002],
                                                      these methods suffer from two main drawbacks
2.3  Potential Functions
                                                        1. The Markov chain takes a long time to reach the equilib-
Since the underlying graph for a TCRF is a tree, the set of rium distribution.
cliques C corresponds to nodes and edges of this graph. We
deﬁne two kinds of potentials over these cliques:       2. The estimated gradients tend to be noisy, i.e. they have
                                                          a high variance.
Local Potential
                                                        Contrastive Divergence (CD) is an approximate learning
This is intended to represent the inﬂuence of the observations method which overcomes this problem by minimizing a dif-
X on the label nodes Y.Foreveryyi ∈ Y this function takes
              y  X      y  X                          ferent objective function [Hinton, 2002]. In this work we use
the form exp(Γi( i, )). Γi( i, ) can be deﬁned as     CD learning for estimating the parameters.
                 y  X    y T Wf  X
              Γi( i,  )=   i    i( )            (2)   3.1  Contrastive Divergence Learning
  Let L be the number of classes and F be the number of Let P be the model distribution and Q0 be the empirical dis-
image statistics for each block. Then yi is a vector of length tribution of label variables. CD learning tries to minimize the

                                                IJCAI-07
                                                  2062contrastive divergence which is deﬁned as             5.1  Feature Extraction
                     0        1                       Visual contents of an image such as color, texture, and spatial
               D =  Q  
 P − Q  
 P             (4)
                                                      layout are vital discriminatory features when considering real
                  
                                Q(y)                  world images. For extracting the color information we cal-
  where Q 
 P  =    y∈Y Q(y)log P (y) is the Kullback-
                                  1                   culate the ﬁrst three color moments of an image patch in the
Leibler divergence between Q & P . Q is the distribution CIEL∗a∗b∗ color space.
deﬁned by the one step reconstruction of the training data We incorporate the entropy of a region to account for its
vectors [Hinton, 2002]. For any weight wij ,          randomness. A uniform image patch has a signiﬁcantly lower
                                                      entropy value as compared to a non-uniform patch. Entropy
                             ∂D
                  Δwij = −η                     (5)   is calculated as shown in Equation 10
                            ∂wij                                            
                                                                      E   −      ∗                   (10)
                               Y1                                       =      (p  log(p))
  where η is the learning rate. Let be the one step re-                      p
construction of training set Y0. The weight update equations
speciﬁc to our model are                              where, p contains the histogram counts. Texture is extracted
                                                    using the discrete wavelet transform [Mallat, 1996]. Spatial
                       u  v           u v
     Δwuv   =   η[    yi fi (X) −    yi fi (X)] (6)   layout is accounted for by including the coordinates of every
                 y ∈Y0          y ∈Y1                 image site. This in all accounts for a total of 20 statistics
                  i           i
     L−1,b                              u v           corresponding to one image region.
                              E      0
  Δφuv      =   η              P (hi | Y )[hi yj ] (7)
                      0  ∈
                  yj ∈Y hi HL−1                       5.2  Object Detection
                       (yj ,hi)∈E
                                                   We apply our model to the task of detecting man-made struc-
                                         u v          tures in a set of natural images from the Corel image database.
                 −             EP ( | 1)[h y ]
                                  hi Y   i j                          ×
                      1                               Each image is 256 384 pixels. We divide each image into
                    ∈   hi∈HL−1
                   yj Y                                             ×
                        (yj ,hi)∈E                    blocks of size 8 12. Each block is labeled as either struc-
                                                   tured or unstructured. These blocks correspond to the leaf
        t,b                               u  v
                              E        0
     Δφuv   =   η              P (hi,hj | Y )[hi hj ] (8) nodes of the TCRF. In order to compare our performance with
                  hi∈Ht hj ∈Ht+1                      DRFs,weusethesamesetof108     training and 129 testing
                       (hi,hj )∈E
                                                   images as used by [Kumar and Hebert, 2003].Wealsoim-
                                           u v        plement a simple Logistic Regression (LR) based classiﬁer in
                 −             EP ( , | 1)[h h ]
                                  hi hj Y  i j        order to demonstrate the performance improvement obtained
                   hi∈Ht hj ∈Ht+1
                        (hi,hj )∈E                    by capturing label relationships. As shown in Table 1, TCRF
                                                      achieves signiﬁcant improvement over the LR based classi-
4  Inference                                          ﬁer which considers only local image statistics into account.
                                                      Figure 4 shows some the results obtained by our model.
The problem of inference is to ﬁnd the optimal label ﬁeld
 ∗
Y  = argmaxYP   (Y|X). This can be done using the max-
imum posterior marginals (MPM) criterion which minimizes Table 1: Classiﬁcation Accuracy for detecting man-made
the expected number of incorrectly labeled sites. According structures calculated for the test set containing 129 images.
                                           ∗
to the MPM criterion, the optimal label for pixel i, yi is given
as                                                                    Model  Classiﬁcation
           ∗                |     ∀  ∈
          yi = argmaxyi P (yi X),  yi  y        (9)                          Accuracy (%)
  Due to the tree structure of our model the probability value        LR     69.82
                                                                                  1
P (yi|X) can be exactly calculated using Belief Propaga-              DRF    72.54
tion [Pearl, 1988].                                                   TCRF   85.83

5  Experiments and Results
                                                      5.3  Image Labeling
In order to evaluate the performance of our model, we ap- We now demonstrate the performance of our model on label-
plied it to two different classiﬁcation tasks, namely, object ing real world images. We took a set of 100 images consisting
detection and image labeling. Our main aim was to demon- of wildlife scenes from the Corel database. The dataset con-
strate the ability of TCRF in capturing the label relationships. tains a total of 7 class labels: rhino/hippo, polar bear, vege-
We have also compared our approach with the existing tech- tation, sky, water, snow and ground. This is a data set with
niques both qualitatively and quantitatively. The predicted high variability among images. Each image is 128 × 192 pix-
label for each block is assigned to all the pixels contained els. We divide each image into blocks of size 4×6. A total of
within it. This is done in order to compare the performance 60 images were chosen at random for training. The remaining
against models like mCRF which operate directly at the pixel
level. We use a common set of local features as described 1This score as reported by [Kumar and Hebert, 2003] was ob-
next.                                                 tained by using a different region size.

                                                IJCAI-07
                                                  206340 images were used for testing. We compare our results with References
that of a logistic classiﬁer and our own implementation of the [Bouman and Shapiro, 1994] Charles A. Bouman and
mCRF  [He et al., 2004]. It can be observed from Table 2 Michael Shapiro. A multiscale random ﬁeld model for
that TCRF signiﬁcantly improves over the logistic classiﬁer bayesian image segmentation. IEEE Transactions on
by modeling the label interactions. Our model also outper- Image Processing, 3(2):162–177, 1994.
forms the mCRF on the given test set. Qualitative results on
some of the test images are shown in Figure 5.        [Felzenszwalb and Huttenlocher, 2004] Pedro F. Felzen-
                                                         szwalb and Daniel P. Huttenlocher. Efﬁcient belief
                                                         propagation for early vision. In CVPR  (1), pages
Table 2: Classiﬁcation accuracy for the task of image label- 261–268, 2004.
ing on the Corel data set. A total of 40 testing images were [       ]
                    ×                                  Feng et al., 2002 Xiaojuan Feng, Christopher K.  I.
present each of size 128 192.                            Williams, and Stephen N. Felderhof. Combining belief
                                                         networks and neural networks for scene segmentation.
               Model   Classiﬁcation                     IEEE Trans. Pattern Anal. Mach. Intell, 24(4):467–483,
                       Accuracy (%)                      2002.
               LR      65.03                          [Geman and Geman, 1984] Stuart Geman and Donald Ge-
               mCRF    74.3                              man. Stochastic relaxation, gibbs distributions, and the
               TCRF    77.76                             bayesian restoration of images. IEEE Transactions on Pat-
                                                         tern Analysis and Machine Intelligence, PAMI-6(6):721–
                                                         741, 1984.
6  Discussion                                         [He et al., 2004] Xuming He, Richard S. Zemel,  and
The framework proposed in this paper falls into the cat- Miguel A.´ Carreira-Perpi˜n´an. Multiscale conditional ran-
egory of multiscale models which have been successfully  dom ﬁelds for image labeling. In CVPR (2), pages 695–
applied by various authors [Bouman and Shapiro, 1994;    702, 2004.
Feng et al., 2002]. The novelty of our work is that we extend
                                                      [He et al., 2006] Xuming He, Richard S. Zemel, and Deba-
earlier hierarchical approaches to incorporate them into a dis-
                                                         jyoti Ray. Learning and incorporating top-down cues in
criminative framework based on conditional random ﬁelds.
                                                         image segmentation. In ICCV, 2006.
There are several immediate extensions possible to the basic
model presented in this work. One of them concerns with the [Hinton, 2002] Geoffrey E. Hinton. Training products of ex-
“blocky” nature of the labelings obtained. The reason for this perts by minimizing contrastive divergence. Neural Com-
is the ﬁxed region size which is used in our experiments. This putation, 14(8):1771–1800, 2002.
behavior is typical of tree based models like TSBNs. One so- [Kumar and Hebert, 2003] Sanjiv Kumar and Martial
lution to this problem is to directly model image pixels as Hebert. Discriminative ﬁelds for modeling spatial
the leaves of the TCRF. This would require increasing the dependencies in natural images. In NIPS. MIT Press,
number of levels of the tree. Although the number of model 2003.
parameters increase only linearly with the number of levels,
                                                      [                    ]
training and inference times can increase exponentially with Kumar and Hebert, 2005 Sanjiv Kumar and Martial
the number of levels. Recently, He et al. have reported good Hebert. A hierarchical ﬁeld framework for uniﬁed
results by applying their model over a super-pixelized repre- context-based classiﬁcation. In ICCV, pages 1284–1291.
sentation of the image [He et al., 2006]. This approach re- IEEE Computer Society, 2005.
duces the number of image sites and at the same time does [Lafferty et al., 2001] John D. Lafferty, Andrew McCallum,
not deﬁne rigid region sizes. We are currently exploring the and Fernando C. N. Pereira. Conditional random ﬁelds:
possibility of incorporating super-pixelization into the TCRF Probabilistic models for segmenting and labeling sequence
framework.                                               data. In ICML, pages 282–289. Morgan Kaufmann, 2001.
                                                      [Li, 2001] S. Z. Li. Markov Random Field Modeling in Im-
7  Conclusions                                           age Analysis. Comp. Sci. Workbench. Springer, 2001.
We have presented TCRF, a novel hierarchical model based [Mallat, 1996] S. Mallat. Wavelets for a vision. Proceedings
on CRFs for incorporating contextual features at several lev- of the IEEE, 84(4):604–614, 1996.
els of granularity. The discriminative nature of CRFs com-
bined with the tree like structure gives TCRFs several advan- [Pearl, 1988] J. Pearl. Probabilistic reasoning in intelligent
tages over other proposed multiscale models. TCRFs yield a systems: Networks of plausible inference. Morgan Kauf-
general framework which can be applied to a variety of image mann, 1988.
classiﬁcation tasks. We have empirically demonstrated that a
TCRF outperforms existing approaches on two such tasks. In
future we wish to explore other training methods which can
handle larger number of parameters. Further we need to study
how our framework can be adapted for other image classiﬁ-
cation tasks.

                                                IJCAI-07
                                                  2064