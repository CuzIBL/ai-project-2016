                              Model minimization by linear PSR

                    Masoumeh T. Izadi                              Doina Precup
                     McGill University                            McGill University
               School of Computer Science                   School of Computer Science
                   mtabae@cs.mcgill.ca                          dprecup@cs.mcgill.ca


                    Abstract                          matrix of size |S| × |S|, in which the diagonal elements corre-
                                                      spond to the probabilities of emitting o from each state, given
    Predictive state representation (PSR), proposed by that the state is reached by action a. A test is deﬁned as an or-
    [Littman et al., 2002; Singh et al., 2004], are
                                                      dered sequence of action-observation pairs t = a0o1...an−1on,
    a general representation for controlled dynamical which can happen from the current time step into the future.
    systems. We present a sufﬁcient condition under   The conditional probability of test t given a prior history h of
    which a linear PSR compresses a POMDP repre-
                                                      action-observation pairs is p(t|h) = p(o1...on|h,a0...an−1).
    sentation.                                          A set of tests Q = {q1...qm} constitutes a linear PSR if, for
1  Introduction                                       any history, the probability of any other test t can be com-
                                                      puted as a linear combination of the predictions for the tests
Efﬁcient decision making under uncertainty requires ignoring
                                                      in Q. In other words, for any test t there exists a vector m of
irrelevant details of a complex dynamical system and focus-                                           t
                                                      size |Q|, such that p(t|h) = p(Q|h)T m ,∀h.
ing on useful abstractions. A traditional representation for                          t
                                                        Littman et al. also deﬁne an outcome function u map-
stochastic dynamical systems is provided by Partially Ob-
                                                      ping tests into n-dimensional vectors deﬁned recursively by:
servable Markov Decision Processes (POMDPs). An attrac-
                                                      u(ε) = 1  and u(aot) = (T aOa,ou(t)) where ε represents a
tive alternative to POMDPs is the Predictive State Represen-  |S|
tation (PSR), introduced in [Littman et al., 2002] and further null test and en is the (1 × n) vector of all 1s. Each com-
developed in [Singh et al., 2004]. PSRs can be used to repre- ponent ui(t) indicates the probability of the test t when its
sent a larger class of dynamical systems than POMDPs. Even sequence of actions is applied from state i. A set of tests Q is
for systems that can be represented as POMDPs, PSRs hold called linearly independent if the outcome vectors of its tests
the promise of a more compact representation. In particu- u(q1),u(q2),...u(qm) are linearly independent.
lar, Littman et al (2002) show that a PSR representation is no PSRs are related to POMDPs through the state-test predic-
larger than the number of states in a POMDP. We point out tion matrix U [Littman et al., 2002]. The rows of U corre-
a special case of their linear PSR representation, in which spond to states in S and columns correspond to all possible
a strict reduction in the number of states is obtained. We tests in order of increasing length. The entry Ui j is the con-
believe this special case is interesting because it relies only ditional probability of the jth test given that the state of the
on the state dynamics, without taking into account the ob- system is i. A linear PSR can be derived from the matrix U by
servations. This can be potentially attractive, especially for searching for a maximal set of linearly independent columns
robotics applications, in which states can have similar dynam- of U. Following the deﬁnition of outcome function,
                                                                             a0 a0o1  am 1 am 1om
ics but sensor reading will often be different.              Ui j = u(t j|si) = (T O ...T − O − )i
2  Preliminaries                                      where t j = a0o1...an−1on. The maximum number of linearly
                                                      independent columns is the rank of U. Therefore the size of
A POMDP representation of a dynamical system includes
                                                      Q is upper-bounded by the number of states. Next section
the following components: a ﬁnite unobservable state space
                                                      presents a special case in which |S| is strictly greater than |Q|.
S; a ﬁnite action space A; a ﬁnite observation space O; a
                                       ′
transition function T : S × A × S → R , T (s,a,s ) = P(st+1 =
 ′    ,                                     O   R     3   Linearly dependent states
s |st = s at = a); an observation function O : S ×A× → , We say that a state i is linearly dependent on a subset of states
O o,s,a   P o     o s    s,a   a ; an initial belief state
 (     ) = ( t+1 = | t+1 =  t = )                     S′ ⊂ S if and only if its transition probabilities under any ac-
b0, which is a vector of size |S|, giving the initial probability tion a are a linear combination of the transition probabilities
of the system being in each underlying state; and a reward of states in S′ under the same action:
function R : S × A → R , where R(s,a) is the immediate ex-
                                                                        a        a
pected reward. We will not be concerned here with rewards,            Ts =  ∑ ckTk ∀a ∈ A,
we will consider just actions and observations.                            k∈S′
               a
  We denote by T an |S| × |S| matrix containing state tran- where ∑k∈S′ ck = 1 and there exists k such that ck 6= 0. Note
                                        ao
sition probabilities for action a. We denote by O a diagonal that the coefﬁcients ck will be used to weigh the transitions                                  O1

                                  S1                           S1  O1,O4


                              S2   S3  S4   S5           S2   S3  S4  S5  O1,O4

                           O4,O2  O2,O3 O4,O2 O4,O3                  O2,O3
                                                      O1,O2      O3,O4

                                  S1   O1                    S1  1
                                1
                                     1                  0.5
                                                              0.5   O1,O4
                                  S2−new
                          O2,O3,O4                        S2−new   O1,O2,O3,O4
         Figure 1: Example of a POMDP with linearly dependent states, and the model reduced by a linear PSR

corresponding to state k for all of the actions. Hence, these a is in the upper left while the model for action b is in the
coefﬁcients have to be shared across the actions.     upper right. The solid lines represent state transitions and the
  Theorem: If the underlying MDP of a given POMDP has dashed lines represent emission probabilities. For action a,
a linearly dependent states, then a linear PSR will provide a from state S1 the system transitions to one of the other states
compression of the state space.                       with equal probability. These states return deterministically
  Proof: Suppose there exists a state i ∈ S which is linearly to S1. Under action b, from all the bottom states the system
dependent on a set of states S′, so:                  transitions with probability 0.5 to state S1. The observations
                         a       a                    can be assumed to have all the same probability, although
                ∀a ∈ A : Ti = ∑ckTk                   this does not really matter for the example. In this case, states
                             k                        S3, S4 and S5 are all linearly dependent on S2 (they have the
  To prove that the ith row of U is a linear combination of same transition probabilities). However, note that they do not
the other rows for all possible tests, we proceed by induction. have the same observation models. The bottom row presents
Consider ﬁrst one-step tests. Let Oa be a matrix of size |S| × a simpliﬁed system, which has been reduced to two states
|O|, giving the probabilities of different observations being by eliminating the linearly dependent states. The models for
emitted from each state, after action a is taken. Then, by action a and b are in the left and right column. The emission
taking transposes and multiplying the above equation, we get: probabilities are all equal when more than one observation
                                                      is emitted from a state. In general, these probabilities would
         a T a         a T  a        a  T a
       (Ti ) O = (∑ckTk ) O  = ∑ck(Tk )) O            be computed by averaging the emission probabilities for the
                  k             k                     states in the original model.
  Note that this corresponds to the part of the ith row in the U Note that this theorem relates only linearly dependent state
matrix which contains the observations for all one-step tests transitions to PSR compression without considering the ob-
for action a.                                         servations. In fact, more compression can be obtained if
  Now suppose that we have established for all tests t of the observations are taken into account. A good example
length l that the outcome of t in state i can be written as a of this sort is the POMDP coffee domain used in [Poupart
linear combination of the outcomes of states k:       and Boutilier, 2003]. This problem has 32 states, 2 actions
                                                      and 3 observations. Four of these states are linearly depen-
                 ui(t) = ∑ ckuk(t)                    dent on the other ones, which means that the dimensionality
                        k∈S′                          can be reduced to 28. However, by running the linear PSR
  Consider a test aot of length l + 1. We have:       construction algorithm, a more signiﬁcant reduction is possi-
                                                      ble: the problem can be represented with just two tests. The
                  a ao             a  ao              value-directed compression method of [Poupart and Boutilier,
     ui(aot) =  Ti O  u(t) = ( ∑ ckTk )O u(t)         2003] takes advantage of the same regularities as linear PSRs,
                             k∈S′                     but also of regularities in the reward function.
                        a ao
             =   ∑  ck(Tk O u(t)) = ∑ ckuk(aot)
                k∈S′              k∈S′                References
                                                      [Littman et al., 2002] Michael Littman, Richard S. Sutton,
  Hence, the ith row of the U matrix is a linear combina-
                                          ′              and Satinder Singh. Predictive representations of state. In
tion of the rows corresponding to the states in S , with the NIPS 14, pages 1555–1561, 2002.
same mixing coefﬁcients as those from the transition matrix. [Poupart and Boutilier, 2003] Pascal Poupart and Craig
Therefore, the rank of U is strictly less than |S|. Since the Boutilier. Value-directed compression of POMDPs. In
dimension of the linear PSR is given by the rank of U, in this NIPS 15, pages 1547–1554, 2003.
case the linear PSR representation will be smaller than the [Singh et al., 2004] Satinder Singh, Michael R. James, and
size of the state space. ⋄                               Matthew R. Ruddary. Predictive state representations: A
  An example of a system with 5 states, 4 observations and new theory for modeling dynamical systems. In Proceed-
two actions, in which a simple linear dependence can be seen, ings of UAI, pages 512–519, 2004.
is provided in Figure 1. The model corresponding to action