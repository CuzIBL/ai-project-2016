                Utile Distinctions for Relational Reinforcement Learning

                                William Dabney and Amy McGovern
                                        University of Oklahoma
                                      School of Computer Science
                               amarack@ou.edu and amcgovern@ou.edu


                    Abstract                          ignore irrelevant ones. Traditionally, a state representation is
                                                      either designed by the user or learned from the policy.
    We introduce an approach to autonomously cre-
                                                        Learning in a relational representation introduces two key
    ating state space abstractions for an online rein-
                                                      challenges. The ﬁrst is the exponential growth in search space
    forcement learning agent using a relational repre-
                                                      and the second is that relational environments tend to have a
    sentation. Our approach uses a tree-based function
                                                      high degree of autocorrelation. This has been shown to cause
    approximation derived from McCallum’s [1995]
                                                      a selection bias that makes distinctions to appear useful when
    UTree algorithm. We have extended this approach
                                                      they are not [Jensen and Neville, 2002]. Relational UTree
    to use a relational representation where relational
                                                      compensates for the size of the search space by using stochas-
    observations are represented by attributed graphs
                                                      tic sampling [Srinivasan, 1999]. Autocorrelation violates the
    [McGovern et al., 2003]. We address the chal-
                                                      independent and identically distributed assumption made by
    lenges introduced by a relational representation by
                                                      many statistical techniques. We compensate for the effects of
    using stochastic sampling to manage the search
                                                      temporal autocorrelation by temporally sampling.
    space [Srinivasan, 1999] and temporal sampling to
                                                        We separately address the need to adapt to changes in the
    manage autocorrelation [Jensen and Neville, 2002].
                                                      environment by incorporating efﬁcient tree restructuring [Ut-
    Relational UTree incorporates Iterative Tree Induc-
                                                      goff et al., 1997]. This allows Relational UTree to create
    tion [Utgoff et al., 1997] to allow it to adapt to
                                                      more compact trees with the same representational power and
    changing environments. We empirically demon-
                                                      helps to prevent overﬁtting in stochastic environments.
    strate that Relational UTree performs better than
    similar relational learning methods [Finney et al., The most similar works are the G   [Finney et al.,
    2002; Driessens et al., 2001] in a blocks world do- 2002; Chapman and Kaelbling, 1991] and TG algorithms
    main. We also demonstrate that Relational UTree   [Driessens, 2004; Driessens et al., 2006]. There are several
    can learn to play a sub-task of the game of Go    major differences between TG, which is based in part on G-
    called Tsume-Go [Ramon et al., 2001].             Algorithm, and Relational UTree. The primary difference is
                                                      that Relational UTree can dynamically restructure its trees
                                                      while TG must build a new tree from scratch. This allows
1  Introduction                                       Relational UTree to adapt to changes in the environment and
This paper introduces a method that combines the expressive to correct early mistakes made in the tree. While Relational
power of a relational representation with the learning power UTree uses graphs to represent observations, TG uses ﬁrst or-
of reinforcement learning (RL). The goal is to autonomously der logic predicates. In addition, TG creates a separate policy
learn a relational state space approximation while simultane- tree (called a P-tree) while Relational UTree derives its policy
ously learning to act optimally. A relational representation from the Q-value tree. Finney et al.’s [2002] approach is also
enables an agent to reason at a higher level, which can allow based on G algorithm but uses a deictic representation, while
an agent to learn in more difﬁcult problems [Kaelbling et al., Relational UTree makes use of a full relational representation
2001]. RL is an ideal technique for real-world control be- and incorporates tree restructuring. We empirically compare
cause it can learn to achieve a goal without being told how the performance of Relational UTree to these approaches on
to accomplish it. There has been considerable recent inter- blocks world environments.
est in combining these techniques [Tadepalli et al., 2004; van 2 Algorithm Description
Otterlo, 2005].
  The primary contribution of this paper is the introduc- The Relational UTree algorithm follows the UTree algorithm
tion of an online RL method, Relational UTree, that can au- closely. We use the standard RL and partially observable
tonomously construct its own tree-based function approxi- Markov decision process (POMDP) notation where, at each
mation using a relational representation. UTree [McCallum, time step t, the agent executes an action at ∈ A, and receives
1995] develops its own tree-based state space, allowing it to an observation ot+1 ∈ O, and a reward rt+1 ∈ ℜ [Sutton and
focus on the most important aspects of observations and to Barto, 1998; Kaebling et al., 1998].

                                                IJCAI-07
                                                   738    (a)                   (b)                           Variable Memories
  Mark         Focus                                       Empty List                    Block Exists
          R                       Block
                                      Color = Green
                                     hasFocus = true
    B     G              Left Relationship              [List of all blocks] (0).Color = Green

                         Mark                                                 Yes    No
    T     T      T
                                                        [List of all blocks]
                                                        [One Green block]
    (c)
                  Block                               Figure 2: Example variable memory creation as the instance
                       Color = Red                    from Figure 1c is dropped down the tree.
                 On Top Of
                                                      istence {(x,h) | x ∈ T(V),h ∈ N}, relationship existence
  Block  Left/Right Block                             {(x,o1,o2,h) | x ∈ T(E),o1 = o2∀o1,o2 ∈ M(V),h ∈ N}, and
                                                                   {( ,      , , ) | ( ,    ) ∈  ( ),  ∈
       Color = Blue   Color = Green                   attribute value a valuea o1 h  a valuea  A o1  o1
                                                      {M(V) ∪ M(E)},h ∈ N}, where h is the history index, M is
                                                      the memory, x is a parameter limiting the number of previ-
                                                                                             N
  Block           Block           Block               ous observations that can be considered, and is the set of
                                                      natural numbers.
      Color = Table   Color = Table   Color = Table
                                                        The variables o1 and o2 are pointers to variable memories.
                                                      Variable memories reference previous distinctions in s, al-
Figure 1: a) Example blocks world conﬁguration. b) Partially lowing simple distinctions to be used to construct complex
observable blocksworld1 [Finney et al., 2002] observation. c) queries. For each type of distinction, the set of variable mem-
Fully observable blocksworld2 [Driessens et al., 2001] obser- ories created when an instance is dropped down a node with
vation.
                                                      that distinction is given by: {v ∈ Vi | T(v)=X} for object
                                                                 {( , ,  ) ∈  |  ( )=   ,  =  , ,  ∈   }
  An observation takes the form of an attributed graph G = distinctions, e v1 v2 Ei T e X v1 v2 v1 v2 Vi
 , , ( ), ( ), (  ), ( )                            for relationship distinctions, and {p ∈ Vi ∪ Ei | (a,valuea) ∈
V  E A V  A E  T V  T E  . V is the set of all objects in ( ), = ,     =  }
the environment, represented by vertices in the graph and E A v a X valuea Y for attribute value distinctions.
is the set of all relationships, represented by edges [McGov- Figure 2 shows an example of how Relational UTree uses
ern et al., 2003]. A(V) and A(E) are the set of attributes for variable memories. As the observation shown in Figure 1(c)
the vertices and edges respectively, the elements of which are falls down the root node, blocks are added to the variable
discrete or real valued attributes. A(V) and A(E) may contain memory. The second node selects blocks from this list with
zero or more elements. T(V) and T(E) are required discrete “Color = Green” and saves the matches.
valued types for vertices and edges. Example observations Relational UTree allows static objects to be referenced so
                                                      that their non-static attributes mayT be accessed. The set of
for blocks world are shown in Figure 1. Some attributes and                   =                      ∈
relationships are omitted for readability. The graphical repre- static objects is deﬁned as S H Vi. A focal object, f V,
sentation used does not place individual identiﬁers on objects, can be incorporated to allow an agent to reason deictically.
                                                      Let M(V,N) be the set of object variable memories for the
but instead objects are identiﬁed by their type, attributes, and                 ( ,  )=  ∪{  }
relationships to other objects. This property of graphical rep- node N. At the root node, Nr, M V Nr S f . The set of
                                                      object variable memories created by the distinction at a given
resentations is advantageous for generalizing concepts.                 ( ,  )
  Our Relational UTree description uses McCallum’s [1995] node, N, is denoted m V N . If we let Np be the parent node
                                                      to N, then the set of object variable memories at any node, N,
notations. We refer to the set of distinctions that lead to a tree ( ,  )=   ( ,  ) ∪ ( ,  )
node and the state represented by a leaf node as s. A transition is deﬁned as M V N M V Np m V Np . We similarly
                                                      deﬁne M(E,N),givenM(E,Nr)=0/.
instance, Tt = Tt−1,at−1,ot ,rt , represents one step of the
agent’s experience. The set of instances contained in a leaf 2.2 The Relational UTree Algorithm
node s is denoted T (s), and the set of instances contained in
a leaf node s where the next action is a is T (s,a). The time The Relational UTree algorithm works as follows:
                                   = {  , ,...,  }
ordered set of all transition instances is H T0 T1 T|H| . 1. Create a tree with no distinctions. Initialize T (s)=0/
The leaf node to which a speciﬁc transition instance belongs and H = 0/.
            (  )
is denoted by L Tt .                                    2. Take one step of experience in the environment. Choose
                                                          the action at−1 to be the policy action of L(Tt−1), with
2.1  Relational Utile Distinctions                        ε probability of choosing a random action. Record the
                                                                        =    ,    , ,       =   ∪{   }
We refer to a distinction as being utile if and only if   experience as Tt Tt−1 at−1 ot rt and H H   Tt .
the distinction statistically separates the set of transition Using standard decision tree methods, drop Tt down the
instances so that the agent is better able to predict re- tree. Save Tt to the leaf node, L(Tt )=s, setting T (s)=
ward.  The sets of possible distinctions are: Object ex-  T (s) ∪{Tt }. Mark all tree node N ∈ s as stale, where a

                                                IJCAI-07
                                                   739   stale node indicates that the distinction at that node may
   need to be changed during restructuring.                            Transposition (a)
   In some environments, observations o and o + are au-               
                                   t    t 1                            N              '
   tocorrelated. For example, in the blocksworld2 environ-
   ment shown in Figure 1 (c), the objects and relationships
                                                                  '      '             
   will remain largely the same regardless of the next action                      N       N
   performed. This is an example of temporal autocorrela-
   tion, and can cause a feature selection bias [Jensen and     A   B   C  D     A  C   B  D
   Neville, 2002]. In these situations, we remove autocor-     Deletion (b)       Replacement (c)
   relation through temporal sampling. Every c steps, T is
                                               t                
                                                                 N        '
   forgotten, where c is a user deﬁned value.                                      
                                                                                    N        '
                                                             '
3. With the leaves of the tree representing the states, per-       Leaf  A' B'
   form one step of value iteration using Equations 1 - 4.                      Leaf Leaf Leaf Leaf
   The equations for estimated immediate reward and esti-   A  B
   mated probability of arriving in state s after executing
   action a in state s are given in Equation 3 and 4 and di- Figure 3: Let N be the current node, and C(N)={N1,N2}
                                                                              φ   = φ   = φ
   rectly follow McCallum’s equations.               denote the children of N. a) N1 N2    . Perform tree
                                                     transposition by setting φ = φ = φ and φ = φ. b)
                                                                           N1    N2    N      N
           ( , ) ←  ( , )+γ     ( | , ) ( )        φ   = φ     (  )=0/      φ  =  φ     ( )=   (  )
          Q s a    R s a   ∑Pr   s s a U s     (1)    N1     and C N2     . Set  N     and C N    C N1 .
                            
                            s                        Reclassify the instances T (N2) using the N0 subtree. c)
                                                                                           
                                                     C(N1)=C(N2)=0/. Set    φN = φ , and use φ to reclassify
                  U(s)=maxQ(s,a)               (2)              T (  ) ∪ T ( )
                         a∈A                         the instances N1     N2
                                                         If there is no p ∈ Pφ below the user speciﬁed value, then
                         ∑T ∈T (s,a) ri
                 R(s,a)=    i                  (3)       N is pruned from the tree. We used p = 0.001 for this
                           |T (s,a)|                                                    
                                                         paper. Otherwise, φN is replaced by φ through a series of
                                                         tree transpositions. For distinction trees of depth greater
                                          
                |∀T ∈ T (s,a) s.t. L(T + )=s |          than one, the distinctions are ’pulled-up’ one at a time,
      Pr(s |s,a)=   i               i 1        (4)
                           |T (s,a)|                     beginning with the root distinction.
                                                         (b) Once the best distinction tree at a given node is de-
4. Update the tree every k steps by ﬁrst ensuring the quality termined, the tree is restructured following Utgoff et al.
   of current distinctions, followed by expanding the tree [1997]. If the current distinction at N is already the best,
                                                               
   by adding new distinctions at the leaves. All stale tree φN = φ , then we are done. Otherwise, a recursive depth
   nodes N are updated as follows.                       ﬁrst traversal of the tree is applied until one of the base
   (a) First, stochastically generate a set of distinction trees cases, shown in Figure 3, is reached. At this point, the
                                                                         
   Φ. Include the existing distinction tree, φN, in the set Φ, utile distinction, φ , is ”pulled-up” by recursively per-
   with Φ = Φ∪{φN}. A distinction tree is made up of one forming the tree transposition steps shown in the ﬁgure.
   or more distinctions on a set of instances, organized into After a single ”pull-up” has been performed, the next
   a tree structure. We consider distinction trees with depth base case in the tree is addressed until the best distinc-
   up to some constant k, and consider larger depths only if tion tree, φ, is at the target node, N.
   no utile distinction trees are found. Each distinction tree When the tree restructuring operation has completed for
   φ ∈ Φ deﬁnes a set of fringe leaf nodes L.            N, mark it as not stale. If the node has changed through
   For each fringe leaf node s ∈ L, the set of expected fu- tree restructuring, then mark all nodes in its subtree as
   ture discounted rewards for s makes up a distribution stale. Continue to apply step 4 to each stale child node
   δ(s) given by Equation 5 [McCallum, 1995].            of N. This process continues until no branches are stale,
                                                         and the quality of the distinctions in the tree are ensured.
           δ( )={   + γ ( (   )) | ∈ T ( )}              Finally, perform value iteration until convergence.
            s     rti U  L ti+1  ti    s       (5)
   Calculate the Kolmogorov-Smirnov distance between   5. Every k steps, expand the tree at the leaves. For each leaf
                                                         node of the tree, s, determine the best distinction tree for
   each pair of distributions, denoted KS(δ0,δ1). Let Pφ
   be the set of these p-values, given by Equation 6.    the instances at that node using the process outlined in
                                                         step 4 (a). If the new distinction tree is utile, then expand
              = {  (δ( ),δ( )) |∀ ,  ∈ L}                the tree by adding a subtree at the leaf s and dropping the
           Pφ    KS   si   s j   si s j        (6)       instances T (s) down the new distinction tree. This re-
   Choose the best distinction tree from among Φ and the moves s from the list of leaves and adds the set of leaves
                                                         L
   current distinction tree, φN, using Equation 7.         to that list. Continue expanding the tree until it is no
                                                         longer utile to do so. Perform value iteration until con-
                         ∑       ( )
                         p∈Pφ log p                     vergence after expansion is done.
                 φ = min                       (7)
                     φ∈Φ    |Pφ|                       6. Repeat at step 2 until stopped.

                                               IJCAI-07
                                                  7402.3  Stochastic Sampling                              Example observations for both domains are shown in Fig-
We use stochastic sampling [Srinivasan, 1999] to address the ure 1.
large space of possible distinctions introduced with a rela- In the blocksworld1 domain, the agent has a focus marker
tional representation. Srinivasan shows that if we can sample and a deictic marker. The agent perceives all attribute in-
tests stochastically that we can look at only a small fraction formation for the focused object but none for the marked
of the total and still be highly conﬁdent in ﬁnding one that object. The marker is only observable if it is adjacent to
is among the best possible. The number of tests that must be the focus marker. For example, if the marker is below the
                    ln(1−α)
sampled is given by n ≥ ( − ) , where α is the probability of focus block, then the agent will observe a block object, a
                    ln 1 k                            marker object, and a relationship indicating the block ob-
ﬁnding a test in the top (100 × k)% [Srinivasan, 1999]. The
                                                      ject is on the marker object. The small difference from
key to this equation is that the sample size does not depend
                                                      Finney’s domain arise from the translation from a deictic rep-
on the number of possible distinctions.
                                                      resentation to a truly relational one. The goal is to pick up
  For this paper, we have used k = 0.01 and α = 0.99 to be
                                                      the green block, which requires ﬁrst removing any blocks
99% conﬁdent in ﬁnding a distinction in the top 1%. In this
                                                      covering it. The actions available to the agent are identi-
situation we only need to sample 458 distinctions. By grad-
                                                      cal to that of Finney: move-focus(direction), focus-on(color),
ually reducing k, we can move the search for distinctions to-
                                                      pick-up(), put-down(), marker-to-focus(marker), and focus-
ward an exhaustive search. With our values, it took under
                                                      to-marker(marker). The agent is given a reward of +10 for
a second to expand a leaf node containing 5000 instances.
                                                      reaching the goal, a penalty of -0.2 for invalid moves and -0.1
When we reduce k to 0.001, it takes two minutes to do the
                                                      per time step.
same expansion. Similarly, with k = 0.0001 the expansion
time for the leaf node is almost 13 minutes. This demon- The second domain, blocksworld2, is fully observable and
strates that an exhaustive search of the distinction space is the task is to stack the green block on the red block. The
not feasible. To compensate, we use stochastic sampling. actions are move(x,y) for unique blocks x and y. As with
                                                      Driessens, the agent received a reward of 1 for reaching the
2.4  Tree Restructuring                               goal in the minimal number of steps and a 0 otherwise.
In the early stages of learning, an agent will have only seen The performance of Relational UTree with and without tree
a fraction of the environment and may create a state repre- restructuring for both domains is shown in Figure 4 (left pan-
sentation that is not well suited to the true nature of the en- els). Empirical performance is ε-optimal, with ε = 0.10, for
vironment. To prevent the tree from over-ﬁtting and to allow both domains. These results are averages across 30 runs. Be-
it to adapt to changing environments, Relational UTree im- cause this is online performance, large changes to the tree’s
plements online tree restructuring based on the Iterative Tree structure are reﬂected as temporary drops in performance.
Induction algorithm [Utgoff et al., 1997]. Iterative Tree In- This happens less frequently as the tree converges.
duction ensures that the best split for the instances is used at In the more difﬁcult blocksworld1 domain, Relational
each node of the tree, beginning with the root and working its UTree converges faster than Finney’s approach with more ac-
way to the leaves.                                    curate results. After 100,000 training instances Finney’s per-
  The original ITI algorithm kept track of a list of statistics formance was approximately 68% with ﬁnal convergence to
for each possible test at every tree node. Because Relational 80%. Our method converges to 90% of optimal, due to the
UTree is instance based, this would be redundant. While ITI use of ε-greedy exploration methods, and does so within the
looked at the list of statistics for a node to decide the current ﬁrst 100,000 steps.
best test at that node, Relational UTree regenerates tests for
the node and decides which is best directly. Keeping track Comparatively, the actions in the blocksworld2 domain are
of all possible tests is not a practical solution in this situa- higher level which allows the agent to discover the goal much
tion because of the large search space for distinctions in rela- faster than in blocksworld1. The performance of Driessens’
tional environments. This large search space is a well known TG algorithm on the same domain was comparable. TG does
                                                                                                  ε
problem for inductive logic programming [Dzeroski et al., not explore the environment, and does not use an -greedy
2001]. Although it is more computationally expensive to re- exploration method like we do. This allows their algorithm to
compute the tests, restructuring leads to signiﬁcantly smaller converge to an average reward of 1, while we converge to an
                                                                              .
trees which reduces overall computation time.         average reward per trial of 0 9.
                                                        Figure 4 (right panels) compares the tree sizes with and
3  Experimental Results                               without tree restructuring for the two domains. In both do-
                                                      mains, performance is comparable but the average tree size
3.1  Blocks World Results                             is considerably smaller when tree restructuring is used. The
We apply Relational UTree to two versions of the blocks agent is able to construct a smaller tree to capture the same
world domain. The ﬁrst, blocksworld1, is a partially observ- amount of information because it can remove irrelevant in-
able blocksworld task with low-level actions and two blocks, formation gained early in learning. The use of restructuring
as in Finney et al. [2002]. The second, blocksworld2,isa introduces an increased variance due to the temporary loss
fully observable domain with high-level relational actions and in performance directly following a large tree restructuring.
three blocks, as in Driessens et al. [2001]. Both domains con- However, smaller trees result in a signiﬁcant improvement in
tain moveable colored blocks and unmovable table blocks. running time.

                                                IJCAI-07
                                                   741                                                                         3
  1                                                                     10

  0.9

  0.8


 caled) 0.7                                                              2
                                                                       tree
 S
                                                                        10
 (
  
                                                                       in
  0.6                                                                   
                                                                       es
 Trial
                                                                       v
  
 er

  0.5                Without Restructuring                             lea
                                                                        
  P
                                                                       of

                     With Restructuring                                 

 ard 0.4
 w                                                                       1


 Re                                                                     10             BW 1 NO Restructuring
  
  0.3                                                                  umber
                                                                       N               BW 1 With Restructuring

 Total 0.2                                                                             BW 2 NO Restructuring
                                                                                       BW 2 With Restructuring
  0.1

                                                                         0
  0                                                                     10
   0     2     4     6     8     10                                      0     2     4     6     8     10
                                 4                                                Number of Training Instances 4
      Number of Training Instances in blocksworld 1 Domain x 10                                       x 10

Figure 4: Learning curves for Relational UTree in the blocksworld1 and blocksworld2 domains. Tree sizes, with and without
tree restructuring, are shown for both domains on the right.
3.2  Autocorrelation                                  The effective sample size is dramatically lower without sam-
                                                      pling and small amounts of sampling dramatically increase
To detect potential temporal autocorrelation, we used ran-
                                                      the sample size. Tests on actions have no temporal autocorre-
domization on sets of observations. We perform 10000
                                                      lation because there is no direct correlation between what ac-
randomizations on this data, each time performing a
                                                      tion will be performed and what the most recent action was.
Kolmogorov-Smirnov test. The test statistics form a distri-
                                                      Since autocorrelation causes a feature selection bias [Jensen
bution which can be analyzed to ﬁnd the effective sample
                                                      and Neville, 2002], Relational UTree used sampling to re-
size, similar to what was done with χ2 by Jensen and Neville
                                                      move the autocorrelation.
[2002]. If there is no autocorrelation, the effective sample
size should match the actual sample size used in the tests. 3.3 Tsume Go Results
  The Kolmogorov-Smirnov test compares two distributions, The Tsume Go domain is a sub-task of the game of Go
of sizes N1 and N2. The total size of the data, N1 + N2, re- where stones have already been placed in different conﬁgu-
mains constant throughout, while the proportion of data split rations. The task is to identify the best move for protecting
into either distribution can change from one distinction to the the player’s stones or capturing the opponent’s stones. Rela-
next. In our experiment, the actual number of instances var- tional UTree learns to play the best ﬁrst move of a Tsume Go
ied but the proportions that a speciﬁc distinction created was game. Relational UTree is trained on a set of 30000 randomly
                           ( , )
held constant. We use p = max N1 N2 to represent the rela- sampled problems from the GoTools database [Wolf, 1996],
                         (N1+N2)
tive sizes of the two distributions. By substituting p into the and then tested on a set of 10000 randomly sampled indepen-
original equation for KS, given by [Sachs, 1982], we obtain dent problems from the same database. The agent receives a
                                                      reward between 0 and 1 for correct answers depending on the
  = (2×(Kα)2)     =   ×    R
R     Dα    and NE  2   (4×(p−p2)) for the effective sam- quality of the move and is penalized −0.5 for incorrect at-
                                                                                 −  .
ple size NE . Kα and Dα are the critical values for the KS test. tempts. It is also penalized with 1 0 for invalid moves such
                                                      as placing a stone on top of another stone or trying to move
                                                      off the board.
               Object Block Relationship Action Move 
                 Exists   Holding Exists   Up           Similar to Ramon et al.’s [2001] approach, we test Rela-
                   %           1%                     tional UTree’s approximation by ranking moves using the Q-
  No Sampling
               1%          <1%        100%            values. Across 7 runs, Relational UTree averaged 65% ac-
                                                      curacy on the test set after one move. Ramon et al.’s [2001]
                                                      approach obtained 35% accuracy on a test set of 1000 prob-
  Drop Every 15th                                     lems generated by GoTools, after training on 2600 problems.
               65%         76%6       100%            We are encouraged by our results and are exploring this do-
                                                      main in greater detail as future work.
  Drop Every 10th
               96%         100%       100%            4   Discussion
                                                      Due to the signiﬁcant performance difference between Finney
Figure 5: Effective sample size relative to actual sample size and the large degree of similarities between our algorithm
with variable amounts of sampling.                    and Finney’s, it is useful to discuss why Relational UTree
                                                      was able to overcome some of the problems previously re-
  Figure 5 shows the results of our detection and removal ported. Relying on observation history to disambiguate states
of the temporal autocorrelation in the blocks world domain. and using state values to determine a policy before the states
The top pie chart for each group is the effective sample size are disambiguated is a difﬁcult problem that can be overcome
without sampling. The lower two pie charts are for removing through the use of tree restructuring. As the agent contin-
every 15th or every 10th instance. Effective sample sizes for ues to learn, it carries older instances whose histories reﬂect
an object existence, relationship, and action test are shown. outdated policies. As the agent’s performance increases, the

                                                IJCAI-07
                                                   742