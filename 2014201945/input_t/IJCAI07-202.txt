                               Incremental Mechanism Design∗

                     Vincent Conitzer                            Tuomas Sandholm
                      Duke University                        Carnegie Mellon University
             Department of Computer Science                Computer Science Department
                   conitzer@cs.duke.edu                        sandholm@cs.cmu.edu

                    Abstract                            The traditional approach to mechanism design has been to
                                                      try to design good mechanisms that are as general as possible.
    Mechanism design has traditionally focused almost Probably the best-known general mechanism is the Vickrey-
    exclusively on the design of truthful mechanisms. Clarke-Groves (VCG) mechanism [16; 4; 10], which chooses
    There are several drawbacks to this: 1. in certain the allocation that maximizes the sum of the agents’ utilities
    settings (e.g. voting settings), no desirable strategy- (the social welfare), and makes every agent pay the external-
    proof mechanisms exist; 2. truthful mechanisms    ity that he1 imposes on the other agents. This is sufﬁcient to
    are unable to take advantage of the fact that com- ensure that no individual agent has an incentive to manip-
    putationally bounded agents may not be able to    ulate, but it also has various drawbacks: for example, the
    ﬁnd the best manipulation, and 3. when designing  surplus payments can, in general, not be redistributed, and
    mechanisms automatically, this approach leads to  the designer may have a different objective than social wel-
    constrained optimization problems for which cur-  fare, e.g. she may wish to maximize revenue. Other general
    rent techniques do not scale to very large instances. mechanisms have their own drawbacks, and there are vari-
    In this paper, we suggest an entirely different ap- ous impossibility results such as the Gibbard-Satterthwaite
    proach: we start with a na¨ıve (manipulable) mech- theorem [8; 15] that show that certain objectives cannot be
    anism, and incrementally make it more strategy-   achieved by truthful mechanisms.
    proof over a sequence of iterations.
                                                        The lack of a general mechanism that is always satisfac-
    We give examples of mechanisms that (variants of) tory led to the creation of the ﬁeld of automated mechanism
    our approach generate, including the VCG mech-    design [5]. Rather than try to design a mechanism that works
    anism in general settings with payments, and the  for a range of settings, the idea is to have a computer au-
    plurality-with-runoff voting rule. We also provide tomatically compute the optimal mechanism for the speciﬁc
    several basic algorithms for automatically execut- setting at hand, by solving an optimization problem. A draw-
    ing our approach in general settings. Finally, we back of that approach is that current techniques do not scale
    discuss how computationally hard it is for agents to to very large instances. This is in part due to the fact that,
    ﬁnd any remaining beneﬁcial manipulation.         to ensure strategy-proofness, one must simultaneously decide
                                                      on the outcome that the mechanism chooses for every possi-
1  Introduction                                       ble input of revealed preferences, and the strategy-proofness
In many multiagent settings, we must choose an outcome constraints interrelate these decisions.
based on the preferences of multiple self-interested agents, Another observation that has been made is that in com-
who will not necessarily report their preferences truthfully plex settings, it is unreasonable to believe that every agent
if it is not in their best interest to do so. Typical settings is endowed with the computational abilities to compute an
in which this occurs include auctions, reverse auctions, ex- optimal manipulation. This invalidates the above-mentioned
changes, voting settings, public good settings, resource/task revelation principle, in that restricting attention to truthful
allocation settings, ranking pages on the web [1], etc. Re- mechanisms may in fact come at a cost in the quality of the
search in mechanism design studies how to choose outcomes outcomes that the mechanism produces. Adding to this the
in such a way that good outcomes are obtained even when observation that in some domains, all strategy-proof mecha-
agents respond to incentives to misreport their preferences nisms are unsatisfactory (by the Gibbard-Satterthwaite theo-
(or manipulate). For the most part, researchers have focused rem), it becomes important to be able to design mechanisms
simply on creating truthful (or strategy-proof) mechanisms, that are not strategy-proof. Recent research has already pro-
in which no agent ever has an incentive to misreport. This ap- posed some manipulable mechanisms. There has been work
proach is typically justiﬁed by appealing to a result known as that proposes relaxing the constraint to approximate truth-
the revelation principle, which states that for any mechanism fulness (in various senses). Approximately truthful mech-
that does well in the face of strategic misreporting by agents, anisms can be easier to execute [12; 2], or can circumvent
there is a truthful mechanism that will perform just as well. impossiblity results that apply to truthful mechanisms [14;
  ∗                                                   9]. Other work has studied manipulable mechanisms in which
   This material is based upon work supported by the National Sci-
ence Foundation under ITR grants IIS-0121678 and IIS-0427858, a
Sloan Fellowship, and an IBM Ph.D. Fellowship.           1We will use “she” for the center/designer, and “he” for an agent.

                                                IJCAI-07
                                                  1251ﬁnding a beneﬁcial manipulation is computationally difﬁcult • For each i ∈ N, a utility function ui :Θi × O → R;3
in various senses [3; 13; 6; 7].                      • An objective function g :Θ× O → R.
  In this paper, we introduce a new approach. We start  For example, in a single-item auction, N is the set of bid-
with a na¨ıvely designed mechanism that is not strategy-proof ders; O = S ×Π,whereS is the set of all possible allocations
(for example, the mechanism that would be optimal in the of the item (one for each bidder, plus potentially one alloca-
absence of strategic behavior), and we attempt to make it tion where no bidder wins), and Π is the set of all possible
more strategy-proof. Speciﬁcally, the approach systemati- vectors π1,...,πn of payments to be made by the agents
cally identiﬁes situations in which an agent has an incentive (e.g., Π=Rn); assuming no allocative externalities (that is,
to manipulate, and corrects the mechanism to take away this it does not matter to a bidder which other bidder wins the
incentive. This is done iteratively, and the mechanism may or item if the bidder does not win himself), Θi is the set of pos-
may not become (completely) strategy-proof eventually. The sible valuations that the bidder may have for the item (for
                                                                      ≥0
ﬁnal mechanism may depend on the order in which possible example, Θi = R ); the utility function ui is given by:
manipulations are considered.                         ui(θi, (s, π1,...,πn)) = θi − πi if s is the outcome in
  One can conceive of this approach as being a computa- which i wins the item, and ui(θi, (s, π1,...,πn)) = −πi
tionally more efﬁcient approach to automated mechanism de- otherwise. (In situations in which a type consists of a single
sign, insofar as the updates to the mechanism to make it value, we will typically use vi rather than θi for the type.)4
more strategy-proof can be executed automatically (by a com- A (deterministic) mechanism consists of a function
puter). Indeed, we will provide algorithms for doing so. It is M :Θ→ O, specifying an outcome for every vector
also possible to think about the results of this approach theo- of (reported) types.5 Given a mechanism M,abeneﬁ-
retically, and use them as a guide in “traditional” mechanism cial manipulation6 consists of an agent i ∈ N, a type
design. We will pursue this as well, giving various examples. vector θ1,...,θn∈Θ, and an alternative type re-
Finally, we will argue that if the mechanism that the approach port θˆi for agent i such that ui(θi,M(θ1,...,θn)) <
produces remains manipulable, then any remaining manipu- ui(θi,M(θ1,...,θi−1, θˆi,θi+1,...,θn)).Inthis
lations will be computationally hard to ﬁnd.          case we say that i manipulates from θ1,...,θn into
  This approach bears some similarity to how mechanisms
                                                      θ1,...,θi−1, θˆi,θi+1,...,θn. A mechanism is strategy-
are designed in the real world. Real-world mechanisms are proof or (dominant-strategies) incentive compatible if there
often initially na¨ıve, leading to undesirable strategic behavior; are no beneﬁcial manipulations. (We will not consider
once this is recognized, the mechanism is amended to disin- Bayes-Nash equilibrium incentive compatibility here.)
cent the undesirable behavior. For example, some na¨ıvely de-
                                                        In settings with payments, we enforce an ex-post individual
signed mechanisms give bidders incentives to postpone sub-
                                                      rationality constraint: we cannot make an agent worse off
mitting their bids until just before the event closes (i.e., snip-
                                                      than he would have been if he had not participated. That is,
ing); often this is (partially) ﬁxed by adding an activity rule,
                                                      we cannot charge an agent more than he reported the outcome
which prevents bidders that do not bid actively early from
                                                      (disregarding payments) was worth to him.
winning later. As another example, in the 2003 Trading Agent
Competition Supply Chain Management (TAC/SCM) game,   3   Our approach and techniques
the rules of the game led the agents to procure most of their
components on day 0. This was deemed undesirable, and the In this section, we explain the approach and techniques that
designers tried to modify the rules for the 2004 competition we consider in this paper. We recall that our goal is not to
to disincent this behavior [11].2                     (immediately) design a strategy-proof mechanism; rather, we
  As we will see, there are many variants of the approach, start with some manipulable mechanism, and attempt to in-
each with its own merits. We will not decide which variant is crementally make it “more” strategy-proof. Thus, the basic
the best in this paper; rather, we will show for a few different template of our approach is as follows:
variants that they can result in desirable mechanisms. 1. Start with some (manipulable) mechanism M;
                                                      2. Find some set F of manipulations (where a manipulation
2  Mechanism design background                        is given by an agent i ∈ N, a type vector θ1,...,θn,andan
                                                      alternative type report θˆi for agent i);
In a mechanism design setting, we are given:          3. If possible, change the mechanism M to prevent (many of)
•                |  |
 A set of agents N ( N = n);                          these manipulations from being beneﬁcial;
•
  A set of outcomes O (here, if payments are used in the 4. Repeat from step 2 until termination.
setting, an outcome includes information on payments to be This is merely a template; at each one of the steps, some-
made by/to the agents);                               thing remains to be ﬁlled in. Which initial mechanism do we
• For each agent i ∈ N, a set of types Θi (and we denote by
                                                         3
Θ=Θ1   × ...× Θn  the set of all type vectors, i.e. the set of The utility function is parameterized by type; while the ui are
all possible inputs to the mechanism);                common knowledge, the types encode (private) preferences.
                                                         4In general, we may have additional information, such as a prior
  2Interestingly, these ad-hoc modiﬁcations failed to prevent the over the types, but we will not use this information in this paper.
behavior, and even an extreme modiﬁcation during the 2004 com- 5In general, a mechanism may be randomized, specifying distri-
petition failed. Later research suggests that in fact all reasonable butions over outcomes, but we will not consider this in this paper.
settings for a key parameter would have failed [17].     6“Beneﬁcial” here means beneﬁcial to the manipulating agent.

                                                IJCAI-07
                                                  1252choose in step 1? Which set of manipulations do we con- the set of all outcomes o such that for any beneﬁcial
siderinstep2?Howdowe“ﬁx”themechanisminstep3to         manipulation (i, θˆi) (with (i, θ, θˆi) ∈ F ), ui(θi,o) ≥
prevent these manipulations? And how do we decide to ter- ui(θi,M(θ1,...,θi−1, θˆi,θi+1,...,θn)). It may happen
minate in step 4? In this paper, we will not resolve what is the that O(M,θ,F)=∅ (no outcome will prevent all manip-
best way to ﬁll in these blanks (it seems unlikely that there is ulations). In this case, there are various ways in which
a single, universal best way), but rather we will provide a few we can proceed. One is not to update the outcome at
instantiations of the technique, illustrate them with examples, all, i.e. set M (θ)=M(θ). Another is to minimize the
and show some interesting properties.                 number of agents that will have an incentive to manipu-
  One natural way of instantiating step 1 is to choose a late from θ after the change, that is, to choose M (θ) ∈
na¨ıvely optimal mechanism, that is, a mechanism that would arg mino∈O |{i ∈ N :(∃(i, θ, θˆi) ∈ F : ui(θi,o) <
give the highest objective value for each type vector if every
                                                       i  i    1      i−1 ˆi i+1     n   }| (and ties can
agent would always reveal his type truthfully. For instance, u (θ ,M( θ ,...,θ , θ ,θ ,...,θ )))
                                                      be broken to maximize the objective ).
if we wish to maximize social welfare, we simply always                              g
choose an outcome that maximizes social welfare for the re- Many other variants are possible. For example, instead of
                                                      choosing from the set of all possible outcomes when we
ported types; if we wish to maximize revenue, we choose an                                     O
                                                      update the outcome of the mechanism for some type vec-
outcome that maximizes social welfare for the reported types,
and make each agent pay his entire valuation.         tor θ, we can limit ourselves to the set of all outcomes that
                                                      would result from some beneﬁcial manipulation in F from
  In step 2, there are many possible options: we can choose
                                                      θ—that is, the set {o ∈ O :((∃(i, θˆi):(i, θ, θˆi) ∈ F ):
the set of all manipulations; the set of all manipulations for
                                                                          ˆ             }
a single agent; the set of all manipulations from or to a par- o = M( θ1,...,θi−1, θi,θi+1,...,θn )) —in addition to
ticular type or type vector; or just a single manipulation. The the current outcome M(θ). The motivation is that rather
structure of the speciﬁc setting under consideration may also than consider all possible outcomes every time, we may wish
make certain manipulations more “natural” than others; we to simplify our job by considering only the ones that cause
can discover which manipulations are more natural by intu- the failure of strategy-proofness in the ﬁrst place. We next
ition, by hiring agents to act in test runs of the mechanism, by present examples of some of the above-mentioned variants.
running algorithms that ﬁnd manipulations, etc. Which set of 4 Instantiating the methodology
manipulations we choose will affect the difﬁculty of step 3.
  Step 3 is the most complex step. Let us ﬁrst con-   In this section, we illustrate the potential beneﬁts of the ap-
sider the case where we are only trying to prevent a  proach by exhibiting mechanisms that it can produce in var-
                                                     ious standard mechanism design settings. We will demon-
single manipulation, from θ =  θ1,...,θn to θ  =
           ˆ                                        strate a setting in which the approach ends up producing a
 θ1,...,θi−1, θi,θi+1,...,θn . We can make this manipula- strategy-proof mechanism, as well as a setting in which the
tion undesirable in one of three ways: (a) make the outcome produced mechanism is still vulnerable to manipulation (but
that M selects for θ more desirable for agent i (when he has
                                                     in some sense “more” strategy-proof than na¨ıve mechanisms).
type θi), (b) make the outcome that M selects for θ less de- (A third setting that we studied—deciding on whether to pro-
sirable for agent i (when he has type θi), or (c) a combination duce a public good—is omitted due to space constraint.) We
of the two. We will focus on (a) in this paper. There may be emphasize that our goal in this section is not to come up with
multiple ways to make the outcome that M selects for θ suf- spectacularly novel mechanisms, but rather to show that the
ﬁciently desirable to prevent the manipulation; a natural way approach advocated in this paper produces sensible results.
to select from among these outcomes is to choose the one that Therefore, for now, we will consider the approach successful
maximizes the designer’s original objective. Note that these if it produces a well-known mechanism. In future research,
modiﬁcations may introduce other beneﬁcial manipulations. we hope to use the technique to help us design novel mecha-
  When we are trying to prevent a set of manipulations, we nismsaswell.7 We do emphasize, however, that although the
are confronted with an additional issue: after we have pre- mechanisms that the approach eventually produces were al-
vented one manipulation in the set, we may reintroduce the ready known to us,theapproach simply follows local updat-
incentive for this manipulation when we try to prevent an- ing rules without any knowledge of what the ﬁnal mechanism
other manipulation. Resolving this would require solving a should be. In other words, the algorithm is not even given a
potentially large constrained optimization problem, consti- hint of what the ﬁnal mechanism should look like.
tuting an approach similar to standard automated mechanism
design—reintroducing some of the scalability problems that 4.1 Settings with payments
we wish to avoid. Therefore, when addressing the manipula- In this subsection, we show the following result: in general
tions from one type vector, we will simply act as if we will preference aggregation settings in which the agents can make
not change the outcomes for any other type vector.    payments (e.g. combinatorial auctions), (one variant of) our
  Formally, for this particular instantiation of our approach, technique yields the VCG mechanism after a single iteration.
if M is the mechanism at the beginning of the iteration We recall that the VCG mechanism chooses an outcome that
      
and M  is the mechanism at the end of the iteration (af- 7Certainly, if we apply the approach to a previously unstud-
ter the update), and F is the set of manipulations under
                                                     ied mechanism design domain, it will produce a novel mechanism.
consideration, we have M (θ) ∈ arg maxo∈O(M,θ,F) g(θ, o) However, it would be difﬁcult to evaluate the quality of such a mech-
(here, θ =  θ1,...,θn), where O(M,θ,F)   ⊆  O  is   anism, since there would be nothing to compare the mechanism to.

                                                IJCAI-07
                                                  1253maximizes social welfare (not counting payments), and im- Without the tie-breaking assumption, the lemma does not
poses the following tax on an agent: consider the total utility hold: for example, in a single-item ﬁrst-price auction, bid-
(not counting payments) of the other agents given the chosen ding exactly the second price for the item is not an optimal
outcome, and subtract this from the total utility (not counting manipulation for the bidder with the highest valuation if the
payments) that the other agents would have obtained if the tie is broken in favor of the other bidder. However, increas-
given agent’s preferences had been ignored in choosing the ing the bid by any amount will guarantee that the item is won
outcome. Speciﬁcally, we will consider the following variant (and in general, increasing the value for s∗ by any amount
of our technique (perhaps the most basic one):        will guarantee that outcome).
•
 Our objective g is to try maximize some (say, linear) com- Proof: First, we show that this manipulation will still result
bination of allocative social welfare (i.e. social welfare not in s∗ being chosen. Suppose that allocation s = s∗ is cho-
taking payments into account) and revenue. (It does not mat-
                                                      sen instead. Given the tie-breaking assumption, it follows
ter what the combination is.)                                                  ∗             ∗
                                                      that    j  j        i ˆi         j  j    , or equiva-
•                                                            u (θ ,s) >u(θ   ,s )+    u (θ ,s )
 The set F of manipulations that we consider is that of all j=i                  j=i
                                                                                              ∗
possible misreports (by any single agent).            lently, VCGi(θi,θ−i) <  uj(θj,s)−uj(θj,s ).However,
•                                                                          j=i           
  We try to prevent manipulations according to (a) above                                            ∗∗
(for a type vector from which there is a beneﬁcial manipula- by deﬁnition, VCGi(θi,θ−i)=maxs∗∗ uj(θj,s ) −
                                                                                         j=i
tion, make its outcome desirable enough to the manipulating  ∗                        ∗
                                                      uj(θj,s ) ≥    uj(θj ,s) − uj(θj,s ), so we have the de-
agents to prevent the manipulation). Among outcomes that          j=i
achieve this, we choose one maximizing the objective g. sired contradiction. It follows that agent i’s utility under the
                                                                          ∗
  We will use the term “allocation” to refer to the part of the manipulation is ui(θi,s ) − VCGi(θi,θ−i).
outcome that does not concern payments, even though the re- Next, we show that agent i cannot obtain a higher utility
sult is not restricted to allocation settings such as auctions.
                                                      with any other manipulation. Suppose that manipulation θˆi
Also, we will refer to the utility that agent i with type θi gets
                                                      results in allocation s being chosen. Because utilities cannot
from allocation s (not including payments) as ui(θi,s).The
                                                      be negative under truthful reporting, it follows that ui(θˆi,s)+
following simple observation shows that the na¨ıvely optimal                          ∗∗
                                                                  ≥       ∗∗
mechanism is the ﬁrst-price mechanism, which chooses an  uj(θj,s)     maxs     uj(θj,s  ).  Using the fact
                                                      j=i                  j=i 
allocation that maximizes social welfare, and makes every                                 ∗∗          ∗
                                                      that VCGi(θi,θ−i)=maxs∗∗      uj(θj,s ) − uj(θj,s ),
agent pay his valuation for the allocation.                                      j=i
                                                                                                  ˆ
Observation 1 The ﬁrst-price mechanism na¨ıvely maximizes we can rewrite the previous inequality as ui(θi,s)+
                                                                 ≥                           ∗
both revenue and allocative social welfare.              uj(θj,s)   VCGi(θi,θ−i)+      uj(θj,s ), or equiva-
                                                      j=i                          j=i
                                                                                             ∗
Proof: That the mechanism (na¨ıvely) maximizes allocative lently ui(θˆi,s) ≥ VCGi(θi,θ−i)+ uj(θj ,s )−uj(θj,s).
social welfare is clear. Moreover, due to the individual ratio-                   j=i
                                                                       ∗
nality constraint, we can never extract more than the alloca- Because uj(θj ,s ) ≥ uj(θj,s), we can rewrite the pre-
tive social welfare; and the ﬁrst-price mechanism (na¨ıvely)  j             j
                                                                                                     ∗
extracts all the allocative social welfare, for an outcome that vious inequality as ui(θˆi,s) ≥ VCGi(θi,θ−i)− ui(θi,s )+
                                                                         ∗
(na¨ıvely) maximizes allocative social welfare.       ui(θi,s)+    uj(θj,s ) − uj(θj,s) ≥ VCGi(θi,θ−i) −
                                                                 j
  Before showing the main result of this subsection, we     ∗
                                                      ui(θi,s )+ui(θi,s), or equivalently, ui(θi,s) − ui(θˆi,s) ≤
ﬁrst characterize optimal manipulations under the ﬁrst-price ∗
                                                      ui(θi,s ) − VCGi(θi,θ−i), as was to be shown.
mechanism.

Lemma 1  The following is an optimal manipulation θˆi from Theorem 1 Under the variant of our approach described
θ ∈ Θ for agent i under the ﬁrst-price mechanism:     above, the mechanism resulting after a single iteration is the
• for the allocation s∗ that would be chosen under the VCG mechanism.
ﬁrst-price mechanism for θ, report a value equal to i’s Proof: By Observation 1, the na¨ıvely optimal mechanism is
                                         ˆ  ∗
VCG  payment under the true valuations (u(θi(s )) =   the ﬁrst-price mechanism. When updating the outcome for θ,
VCGi(θi,θ−i));                                        by Lemma 1, each agent i must receive a utility of at least
•                        ∗                     8           ∗                         ∗
 for any other allocation s = s , report a valuation of 0. ui(θi,s ) − VCGi(θi,θ−i),wheres is the allocation that
                                             ∗
  The  utility of this manipulation is  u(θi,s ) −    maximizes allocative social welfare for type vector θ.One
                                                                                            ∗
VCGi(θi,θ−i).   (This assumes ties will be broken in  way of achieving this is to choose allocation s , and to charge
                 ∗
favor of allocation s .)                              agent i exactly VCGi(θi,θ−i)—that is, simply run the VCG
                                                      mechanism. Clearly this maximizes allocative social welfare.
  8There may be constraints on the reported utility function that But, under the constraints on the agents’ utilities, it also max-
prevent this—for example, in a (combinatorial) auction, perhaps imizes revenue, for the following reason. For any allocation
only monotone valuations are allowed (winning more items never s, the most revenue that we can hope to extract is the al-
hurts an agent). If so, the agent should report valuations for these
                                                 ∗    locative social welfare of s,thatis, ui(θi,s), minus the
outcomes that are as small as possible, which will still lead to s                    i
being chosen.                                         sum of the utilities that we must guarantee the agents, that

                                                IJCAI-07
                                                  1254  
           ∗                                ∗
is,  ui(θi,s ) − VCGi(θi,θ−i). Because s = s  maxi-   to the number of votes that prefers b to a. Then, starting with
   i                                                 the plurality rule, after exactly s(b) − s(a) iterations of the
mizes   ui(θi,s), this means that the most revenue we can
      i                                               approach described above, the outcome for θ changes for the
                                                                                                       9
hope to extract is VCGi(θi,θ−i), and the VCG mecha-   ﬁrst time, to a (the outcome of the plurality with runoff rule).
                i
nism achieves this.                                   5   Computing the mechanism’s outcomes
                                                      In this section, we discuss how to automatically compute the
4.2  Ordinal preferences                              outcomes of the mechanisms that are generated by this ap-
In this subsection, we address voting (social choice) settings. proach in general. It will be convenient to think about set-
In such a setting, there is a set of outcomes (also known as tings in which the set of possible type vectors is ﬁnite (so that
candidates or alternatives) and a set of agents (also known the mechanism can be represented as a ﬁnite table), although
as voters), and every agent i’s type is a complete ranking i these techniques can be extended to (some) inﬁnite settings
over the candidates. (We do not need to specify numerical as well. (At the very least, types can be grouped together into
utilities here.) The mechanism (or voting rule) takes as in- a ﬁnite number; for speciﬁc settings, something better can
put the agents’ type reports (or votes), consisting of complete often be done.) One potential upside relative to standard au-
rankings of the candidates, and chooses an outcome.   tomated mechanism design techniques is that we do not need
  The most commonly used voting rule is the plurality rule, to compute the entire mechanism (the outcomes for all type
in which we only consider every voter’s highest-ranked can- vectors); rather, we only need to compute the outcome for the
didate, and the winner is simply the candidate with the highest type vector that is actually reported.
number of votes ranking it ﬁrst (its plurality score). The plu- Let M0 denote the (na¨ıve) mechanism from which we start,
rality rule is very manipulable: a voter voting for a candidate and let Mt denote the mechanism after t iterations. Let Ft de-
that is not winning may prefer to attempt to get the candi- note the set of beneﬁcial manipulations that we are consider-
date that currently has the second-highest plurality score to ing (and are trying to prevent) in the tth iteration. Thus, Mt is
win, by voting for that candidate instead. In the real world, a function of Ft and Mt−1. What this function is depends on
one common way of “ﬁxing” this is to add a runoff round, the speciﬁc variant of the approach that we are using. When
resulting in the plurality-with-runoff rule. Under this rule, we try to prevent manipulations by making the outcome for
we take the two candidates with the highest plurality scores, the type vector from which the agent is manipulating more de-
                                                      sirable for that agent, we can be more speciﬁc, and say that,
and declare as the winner the one that is ranked higher by                                         θ
more voters. By the Gibbard-Satterthwaite theorem, this is for type vector θ, Mt(θ) is a function of the subset Ft ⊆ Ft
still not a strategy-proof mechanism (it is neither dictatorial that consists of manipulations that start from θ, and of the
                                                      outcomes that Mt−1 selects on the subset of type vectors that
nor does it preclude any candidate from winning)—for exam-                             θ
ple, a voter may change his vote to change which candidates would result from a manipulation in Ft . Thus, to compute
are in the runoff. Still, the plurality with runoff rule is, in the outcome that Mt produces on θ, we only need to consider
                                                      the outcomes that Mt−1 chooses for type vectors that differ
an intuitive sense, “less” manipulable than the plurality rule                                          θ
(and certainly more desirable than a strategy-proof rule, since from θ in at most one type (and possibly even fewer, if Ft
a strategy-proof rule would either be dictatorial or preclude does not consider all possible manipulations). As such, we
                                                                                              n
some candidate from winning).                         need to consider Mt−1’s outcomes on at most |Θi| type
  In this subsection, we will show that the following variant                                 i=1
of our approach will produce the plurality-with-runoff rule vectors to compute Mt(θ) (for any given θ), which is much
when starting with the plurality rule as the initial mechanism.                         n
                                                      smaller than the set of all type vectors ( |Θi|). Of course,
• The set F consists of all manipulations in which a voter                             i=1
                                                                                            
changes which candidate he ranks ﬁrst.                to compute Mt−1(θ ) for some type vector θ , we need to
• We try to prevent manipulations as follows: for a type (vote)                     n
                                                      consider Mt−2’soutcomesonupto    |Θi| type vectors, etc.
vector from which there is a beneﬁcial manipulation, consider                       i=1
all the outcomes that may result from such a manipulation Because of this, a simple recursive approach for comput-
(in addition to the current outcome), and choose as the new                            n
                                                                                          | | t
outcome the one that minimizes the number of agents that ing Mt(θ) for some θ will require O(( Θi ) ) time. This
                                                                                       i=1
still have an incentive to manipulate from this vote vector. approach may, however, spend a signiﬁcant amount of time
•                                                                           
 We will change the outcome for each vote vector at most recomputing values Mj(θ ) many times. Another approach is
once (but we will have multiple iterations, for vote vectors to use dynamic programming, computing and storing mech-
whose outcome did not change in earlier iterations).  anism Mj−1’s outcomes on all type vectors before proceed-
  We are now ready to present the result. (The remaining ing to compute outcomes for Mj. This approach will require
proofs are omitted due to space constraint.)                n        n
                                                      O(t · (  |Θi|) · ( |Θi|)) time (for every iteration, for ev-
Theorem 2 For a given type vector θ, suppose that candi-    i=1      i=1
                                                      ery type vector, we must investigate all possible manipula-
date b is ranked ﬁrst the most often, and a is ranked ﬁrst the
second most often (s(b) >s(a) >...,wheres(o) is the num- 9This is assuming that ties in the plurality rule are broken in favor
ber of times o is ranked ﬁrst). Moreover, suppose that the of a; otherwise, one more iteration is needed. (Some assumption on
number of votes that prefers a to b is greater than or equal tie-breaking must always be made for voting rules.)

                                                IJCAI-07
                                                  1255