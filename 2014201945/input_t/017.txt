                  Increasing Dialogue Efficiency in Case-Based Reasoning 
                                Without Loss of Solution Quality 

                                            David McSherry 
                           School of Computing and Information Engineering 
                       University of Ulster, Coleraine BT52 ISA, Northern Ireland 
                                       dmg.mcsherry@ulster.ac.uk 


                     Abstract                          Schmitt et al, 2002]. Any importance weights associated 
                                                       with the case attributes are also ignored. As a result, it is 
    Increasing dialogue efficiency in case-based 
                                                       possible for a case to be recommended simply because no 
    reasoning (CBR) must be balanced against the risk 
                                                       other case has the preferred value for an attribute of low 
    of commitment to a sub-optimal solution. Focusing 
                                                       importance, even if its values for other attributes are 
    on incremental query elicitation in recommender 
                                                       unacceptable to the user. 
    systems, we examine the limitations of naive 
                                                          Kohlmaier et al [2001] propose a similarity-based 
    strategies such as terminating the dialogue when 
                                                       approach to attribute selection in which the best attribute is 
    the similarity of any case reaches a predefined 
                                                       the one that maximizes the expected variance of the 
    threshold. We also identify necessary and sufficient 
                                                       similarities of candidate cases. In domains in which cases 
    conditions for recommendation dialogues to be 
                                                       are indexed by different features, another alternative to 
    terminated without loss of solution quality. Finally, 
                                                       information gain is to rank questions in decreasing order of 
    we evaluate a number of attribute-selection 
                                                       their frequency in the most similar cases [Aha et al, 2001]. 
    strategies in terms of dialogue efficiency given the 
                                                          To address the trade-off between dialogue efficiency and 
    requirement that there must be no loss of solution 
                                                       solution quality, a CBR system must also be capable of 
    quality. 
                                                       recognizing when the dialogue can be terminated while 
1 Introduction                                         minimizing the risk of commitment to a sub-optimal 
                                                       solution. Existing approaches include terminating the 
In conversational case-based reasoning (CCBR), a query is dialogue when the similarity of any case reaches a 
incrementally elicited in an interactive dialogue with the predefined threshold, or the achievable information gain is 
user [Aha et al, 2001]. Attribute-selection strategies that less than a predefined level, or the set of candidate cases has 
aim to minimize the length of such dialogues have recently been reduced to a manageable size [Aha et al, 2001; Doyle 
attracted much research interest [Doyle and Cunningham, and Cunningham, 2000; Kohlmaier et al, 2001]. 
2000; Kohlmaier et al, 2001; McSherry, 2001; Schmitt et  However, a limitation of these approaches is that there is 
al, 2002]. Potential benefits include avoiding frustration for no guarantee that a better solution would not be found if the 
the user, reducing network traffic in e-commerce domains, dialogue were allowed to continue. Whether it is possible to 
and simplifying explanations of how conclusions were   identify more reliable criteria for termination of problem-
reached [Breslow and Aha, 1997; Doyle and Cunningham,  solving dialogues is an issue that has received little 
2000]. While our focus in this paper is on incremental query attention, if any, in CBR research. 
elicitation in recommender systems, it is worth noting that In Section 2, we examine the trade-off between dialogue 
the ability to solve problems by asking a small number of efficiency and solution quality in recommender systems. In 
questions has been a major factor in the success of help- Section 3, we present empirical techniques for identifying 
desk applications of CBR [Aha et al, 2001; Watson, 1997]. cases that can never emerge as the "best" case and can thus 
   An advantage of information gain [Quinlan, 1986] as a be eliminated. In Section 4, we identify necessary and 
basis for attribute selection is that it tends to produce small sufficient conditions for the dialogue to be terminated 
decision trees, thus helping to reduce the length of problem- without loss of solution quality. In Section 5, we evaluate a 
solving dialogues [Doyle and Cunningham, 2000;         number of attribute-selection strategies in terms of dialogue 
McSherry, 2001]. However, concerns about its suitability in efficiency given the requirement that there must be no loss 
e-commerce domains include the fact that no use is made of of solution quality. Our conclusions are presented in 
the system's similarity knowledge [Kohlmaier et al, 2001; Section 6. 


CASE-BASED REASONING                                                                                   121  2 CCBR in Product Recommendation                                 In practice, the full-length query Q* that represents the 
                                                               preferences of the user with respect to all the case attributes 
A generic algorithm for CCBR in product recommendation 
                                                               may never be known, and is only one of the many possible 
 is shown in Figure 1. In this context, the elicited query, or 
                                                               completions of Q in the sense of the following definition. 
partial query, represents the preferences of the user with 
respect to the attributes of the available products. At each 
stage of the recommendation dialogue, the system selects 
the next most useful attribute, asks the user for the preferred 
value of this attribute, and retrieves the case (or product) 
that is most similar to the query thus far elicited. The 
dialogue continues until the termination criteria are 
satisfied, or until no further attributes remain. At this point, 
the case that is most similar to the current query is presented 
to the user as the recommended case. 

                                                               2.2 Measures of Retrieval Performance 
                                                               Often in recommender systems, cases other than those that 
                                                               are maximally similar to a target query are presented as 
                                                               alternatives that the user may wish to consider [e.g. 
                                                               McGinty and Smyth, 2002]. However, in measuring 
                                                               retrieval performance, we assume that the retrieval set for a 
                                                               given query Q is the set of cases C for which Sim(C, Q) is 
                                                               maximal; that is, no case is more similar to Q. 


                                                                  Often in practice, rs(0 contains a single case; if not, we 
         Figure 1. CCBR in product recommendation.             assume that the user is shown all cases that are maximally 
                                                               similar to her final query. A simple measure of dialogue 
2.1 Similarity Measures                                        efficiency is the number of questions, on average, that the 
The similarity of a given case C to a query Q over a set of    user is asked before a recommendation is made. We 
case attributes A is typically defined as:                     measure precision and recall for an incomplete query Q 
                                                               relative to the full-length query Q* that represents the 
                                                               preferences of the user with respect to all the case attributes. 

                                                               Definition 3 Given an incomplete query Q, we define: 


                                                               2.3 Similarity Thresholds 
                                                               We now use an example recommender system in the PC 
                                                               domain to illustrate the trade-off between dialogue 
                                                               efficiency and solution quality in CCBR with termination 
                                                               based on similarity thresholds. The case library contains the 
                                                               descriptions of 120 personal computers [McGinty and 
                                                               Smyth, 2002], The attributes in the case library and weights 
                                                               assigned to them in our experiments are type (8), price (7), 
                                                               manufacturer (6), processor (5), speed (4), monitor size (3), 
                                                               memory (2), and hard disk capacity (1). In this initial 
                                                               experiment, attributes are selected in decreasing order of 
                                                               their importance weights and the dialogue is terminated 


122                                                                                           CASE-BASED REASONING when the similarity of any case reaches a predefined           be no loss of precision or recall. The dialogue would be 
threshold.                                                     terminated only if all possible completions Q* of the current 
    We use a leave-one-out approach in which each case is      query Q yielded the same retrieval set as Q. However, this 
temporarily removed from the case library and used to          approach is unfeasible in practice as the number of possible 
represent the preferences of the user in a simulated           completions of a given query is often very large. 
recommendation dialogue. We measure dialogue length as            In Section 4, we identify criteria for safely terminating 
the percentage of the 8 possible questions the user is asked   the dialogue that require minimal computational effort in 
before the dialogue is terminated. Average dialogue length,    comparison with exhaustive search. The approach is based 
precision and recall over all simulated dialogues are shown    on the concept of case dominance that we now introduce. 
in Figure 2 for similarity thresholds in the range from 0.4 to 
 1. In this case library, there is never more than a single case 
in the retrieval set for the full-length query that provides the 
baseline for our evaluation of retrieval performance. It 
follows that for each threshold, recall is the percentage of 
dialogues in which this "best" case is recommended.               The importance of case dominance can easily be seen. 
                                                               Any case that is dominated with respect to the current query 
                                                               can be eliminated as it can never emerge as the best case 
                                                               regardless of the preferences of the user with respect to the 
                                                               remaining attributes. In the following section, we present 
                                                               empirical techniques for identifying dominated cases that 
                                                               can easily be applied in practice. 

                                                               3 Identifying Dominated Cases 
                                                               We now present 3 alternative criteria for identifying cases 
                                                               that are dominated with respect to an incomplete query. We 
                                                               will refer to the dominance criteria identified in Theorems 1, 
                                                               2 and 3 as DC1, DC2 and DC3 respectively. DC1 and DC2 
                                                               are sufficient but not necessary conditions for a given case 
                                                               to be dominated by another case, while DC3 is both a 
   Figure 2. Trade-off between dialogue efficiency and solution necessary and a sufficient condition. DC1 and DC2 have the 
    quality with termination based on a predefined threshold.  advantage of not relying on the triangle inequality, but only 
                                                               DC3 is guaranteed to detect all dominance relationships. 
    The similarity threshold of 0.7 can be seen to have 
reduced average dialogue length by almost 50%. This 
equates to about 4 out of 8 questions, on average, being 
asked before a recommendation is made. However, the 
trade-off is a reduction of more than 20% in both precision 
and recall. This means that the best case is recommended in 
less than 80% of dialogues. As precision is less than recall 
for the 0.7 threshold, there arc also occasions when the          A limitation of DC1 is that it fails to recognize that the 
system recommends the best case along with one or more         similarity of the more similar case C\ is a moving target for 

other cases that are equally similar to the final query. It is the less similar case C2, and that the latter may be 
also worth noting that even a threshold of 0.9, though        dominated even if it can equal or exceed the current 

providing a reduction in dialogue length of 17%, docs not      similarity of C1. For example, if C\ and C2 have the same 
ensure that the best case is always recommended.               values for one of the remaining attributes, then any increase 

                                                               in similarity gained by C2 with respect to this attribute is 
2.4 When Can the Dialogue be Safely Terminated?               also gained by C\. Our second dominance criterion, DC2, 

The potentially damaging effects of similarity thresholds on   ignores attributes for which C1 and C2 have the same values, 
solution quality highlight the need for more reliable criteria thus making it less susceptible to this problem. 
for terminating CCBR dialogues. An incomplete query Q 
gives perfect precision and recall if and only if rs(Q) = 
rs(Q*), but the problem is that Q* is unknown. One can 
imagine an approach to CCBR that relics on exhaustive 
search to determine when the dialogue can be safely 
terminated; that is, in the certain knowledge that there can 


CASE-BASED REASONING                                                                                                 123                                                                   Figure 3 shows the numbers of dominated cases, on 
                                                              average, according to DCl, DC2 and DC3 after each 
    However, the moving target problem is only partially      question in simulated dialogues based on the PC case library 
 addressed by disregarding attributes for which C1 and C2      [McGinty and Smyth, 2002]. The experimental setup is the 
 have the same values. Any increase in similarity gained by   same here as in Section 2.3, except that the dialogue is 
 C2 with respect to an attribute for which they have different allowed to continue until no further attributes remain. 
 values may also be gained in equal or greater measure by 
 C\. Our third dominance criterion addresses this issue by 

taking account of the similarity between C\ and C2 with 
 respect to each of the remaining attributes. 


Theorem 3 If Sim is a regular similarity measure, then a 
                                                                 Figure 3. Numbers of dominated cases in the PC case library 
given case C2 is dominated by another case C\ with respect 
to an incomplete query Q if and only if                                     according to DCl, DC2, and DC3. 

                                                                 The results clearly show the inferiority of DCl as a basis 
                                                              for detecting dominance relationships. It fails to detect any 
                                                              dominance relationships until three questions have been 
                                                              asked, while it can be seen from the results for DC3 that 
                                                              more than 70% of cases, on average, are in fact dominated 
                                                              after the second question. The results also show DC2 to be 
                                                              much more effective in detecting dominance relationships 
                                                              than DCl, though unable to compete with DC3. 

                                                              4 Safely Terminating the Dialogue 
                                                              We now identify conditions in which a recommender 
                                                              system dialogue can be terminated without loss of precision 
                                                              or recall. We also show that these conditions must be 

    So C2 is dominated by C\ as required. It remains to show  satisfied in order for the dialogue to be safely terminated. 
that if:                                                      That is, termination on the basis of any other criterion runs 
                                                              the risk of some loss of solution quality. 


124                                                                                          CASE-BASED REASONING                                                                CCBR1: Select attributes in random order 
                                                               CCBR2: Select attributes in order of decreasing importance 
                                                               CCBR3: Select the attribute that maximizes the similarity variance 
                                                                       of cases not currently dominated by the target case 
                                                               CCBR4: Select the attribute that maximizes the number of cases 
                                                                       dominated by the target case 
                                                                  Attribute selection in CCBR3 is adapted from the 
                                                               approach proposed by Kohlmaier et al. [2001]. However, an 
                                                               expected similarity variance over all values of each attribute 
                                                               is not computed in our approach. Instead, the impact on 
                                                               similarity variance of each attribute is evaluated only for its 
                                                               value in the target case; this greatly reduces the 
                                                               computational effort involved in attribute selection. 
                                                                  Our experimental method is designed to compare 
                                                               average dialogue length for each attribute-selection strategy 
                                                               with the optimal dialogue length that can be achieved by 
                                                               any CCBR algorithm that always gives perfect precision and 
                                                               recall. Any such algorithm, like the algorithms in our 
                                                               evaluation, must use the termination criteria identified in 
   The cost of testing condition (a) of Theorem 4 increases    Theorem 4. As in our previous experiments, each case is 
only linearly with the size of the retrieval set. At first sight, temporarily removed from the case library and used to 
condition (b) may seem expensive to test, particularly in the  represent the preferences of the user. To determine the 
early stages of query elicitation when |rs(Q| may be large.    optimal dialogue length for a left-out case, we simulate all 
However, it can be seen from Lemma 2 that if (a) is true and   possible dialogues based on that case; that is, with the 
C1 is any case selected from rs(Q), then (b) is true if and    available attributes selected in every possible order. The 
                                                               optimal dialogue length is the minimum number of 
                                                               questions asked over all such dialogues. For each left-out 
                                                               case, we also record the dialogue length for each of our 
                                                               attribute-selection strategies. 
   It is worth noting that failure of the underlying similarity   For each strategy, Figure 4 shows the maximum, 
measure to respect the triangle inequality does not affect the minimum, and average number of questions asked over all 
ability of a CCBR algorithm that uses the termination          simulated dialogues. Similar statistics are shown for the 
criteria presented in Theorem 4 to provide perfect precision   optimal dialogues determined as described above. CCBR4 
and recall. However, the use of DC2 (which does not rely on    gave the best performance, reducing the number of 
the triangle inequality) as the dominance criterion is likely  questions asked by up to 63% and by 35% on average 
to affect retrieval performance in terms of dialogue           relative to a full-length query. Its average dialogue length of 
efficiency. In the rest of this paper, we assume that the      5.2 is only 4% higher than the lowest possible average that 
underlying similarity measure is regular, thus permitting the  can be achieved by any CCBR algorithm that guarantees 
use of DC3 in the identification of dominance relationships.   perfect precision and recall. 
                                                                  Attribute selection based on similarity variance (CCBR3) 
5 Attribute-Selection Strategies                               also performed well on this case library, with an average 
We now examine the effects on dialogue efficiency of four      dialogue length of 5.4 compared with 7.4 for the random 
approaches to attribute selection in CCBR algorithms that      strategy (CCBR1). With an average dialogue length of 5.8, 
use the termination criteria we have shown to be essential to  selecting attributes in order of decreasing importance 
ensure perfect precision and recall. Two of our algorithms     (CCBR2) was also more effective in reducing average 
are goal driven in that attribute selection is based on the    dialogue length than the random strategy. 


CASE-BASED REASONING                                                                                                 125 