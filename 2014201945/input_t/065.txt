                          Coherent Keyphrase Extraction via Web Mining 

                                                   Peter D. Turney 
                 Institute for Information Technology, National Research Council of Canada 
                            M-50 Montreal Road, Ottawa, Ontario, Canada, Kl A 0R6 
                                             peter, turney @nrc-cnrc. gc. ca 

                        Abstract                               is the motivation for developing algorithms that can 
   Keyphrases are useful for a variety of purposes,            automatically supply keyphrases for a document. Section 2.1 
   including summarizing, indexing, labeling,                  discusses past work on this task. 
   categorizing, clustering, highlighting, browsing, and         This paper focuses on one approach to supplying 
   searching. The task of automatic keyphrase extraction       keyphrases, called keyphrase extraction. In this approach, a 
   is to select keyphrases from within the text of a given     document is decomposed into a set of phrases, each of which 
   document. Automatic keyphrase extraction makes it           is considered as a possible candidate keyphrase. A 
   feasible to generate keyphrases for the huge number of      supervised learning algorithm is taught to classify candidate 
   documents that do not have manually assigned 
                                                               phrases as keyphrases and non-keyphrases. The induced 
   keyphrases. A limitation of previous keyphrase 
   extraction algorithms is that the selected keyphrases are   classification model is then used to extract keyphrases from 
   occasionally incoherent. That is, the majority of the       any given document [Turney, 1999, 2000; Frank et al., 
   output keyphrases may fit together well, but there may      1999; Witten et al, 1999, 2000]. 
   be a minority that appear to be outliers, with no clear       A limitation of prior keyphrase extraction algorithms is 
   semantic relation to the majority or to each other. This    that the output keyphrases are at times incoherent. For 
   paper presents enhancements to the Kea keyphrase            example, if ten keyphrases are selected for a given 
   extraction algorithm that are designed to increase the      document, eight of them might fit well together, but the 
   coherence of the extracted keyphrases. The approach is      remaining two might be outliers, with no apparent semantic 
   to use the degree of statistical association among 
                                                               connection to the other eight or to each other. Informal 
   candidate keyphrases as evidence that they may be 
   semantically related. The statistical association is        analysis of many machine-extracted keyphrases suggests that 
   measured using web mining. Experiments demonstrate          these outliers almost never correspond to author-assigned 
   that the enhancements improve the quality of the            keyphrases. Thus discarding the incoherent candidates might 
   extracted keyphrases. Furthermore, the enhancements         improve the quality of the machine-extracted keyphrases. 
   are not domain-specific: the algorithm generalizes well       Section 2.2 examines past work on measuring the 
   when it is trained on one domain (computer science          coherence of text. The approach used here is to measure the 
   documents) and tested on another (physics documents).       degree of statistical association among the candidate phrases 
                                                               [Church and Hanks, 1989; Church et al, 1991]. The 
 1 Introduction                                                hypothesis is that semantically related phrases will tend to 
A journal article is often accompanied by a list of            be statistically associated with each other, and that avoiding 
keyphrases, composed of about five to fifteen important        unrelated phrases will tend to improve the quality of the 
words and phrases that express the primary topics and          output keyphrases. 
themes of the paper. For an individual document, keyphrases      Section 3 describes the Kea keyphrase extraction 
can serve as a highly condensed summary, they can              algorithm [Frank et al. , 1999; Witten et al . ,, 1999, 2000]. 
supplement or replace the title as a label for the document,   Each candidate phrase is represented in Kea as a feature 
or they can be highlighted within the body of the text, to     vector for classification by a supervised learning algorithm. 
facilitate speed reading (skimming). For a collection of       Four different sets of features are evaluated in this paper. 
documents, keyphrases can be used for indexing,                Two of the sets have been used in the past [Frank et al. , 
categorizing (classifying), clustering, browsing, or           1999] and the other two are introduced here, to address the 
searching. Keyphrases are most familiar in the context of      problem of incoherence. The new features are based on the 
journal articles, but many other types of documents could      use of web mining to measure the statistical association 
benefit from the use of keyphrases, including web pages,       among the candidate phrases [Turney 2001]. 
email messages, news reports, magazine articles, and             In Section 4, experiments show that the new web mining 
business papers.                                               features significantly improve the quality of the extracted 
   The vast majority of documents currently do not have        keyphrases, using the author's keyphrases as a benchmark. 
keyphrases. Although the potential benefit is large, it would  In the first experiment (Section 4.1), the algorithm is trained 
not be practical to manually assign keyphrases to them. This   and tested on the same domain (computer science 


434                                                                                         INFORMATION EXTRACTION documents). In the second experiment (Section 4.2), the        2000]. Depending on the corpus, if the user requests five 
algorithm is trained on one domain (computer science) and      keyphrases to be output, an average of 0.9 to 1.5 of the 
tested on another (physics). In both cases, the new features   output phrases will match with the author-assigned 
result in a significant improvement in performance. In         keyphrases [Frank et al, 1999]. If the user requests fifteen 
contrast, one of the old feature sets works well in the first  keyphrases, an average of 1.8 to 2.8 will match with the 
case (intradomain) but poorly in the second case               author's keyphrases. 
(interdomain).                                                   These performance numbers are misleadingly low, 
   Section 5 considers limitations and future work. Section 6  because the author-assigned keyphrases are usually only a 
presents the conclusions.                                      small subset of the set of good quality keyphrases for a 
                                                               given document. A more accurate picture is obtained by 
2 Related Work                                                 asking human readers to rate the quality of the machine's 
                                                               output. In a sample of 205 human readers rating keyphrases 
Section 2.1 discusses related work on generating keyphrases 
                                                               for 267 web pages, 62% of the 1,869 phrases output by 
and Section 2.2 considers related work on measuring 
                                                               GenEx were rated as "good", 18% were rated as "bad", and 
coherence. 
                                                               20% were left unrated [Turney, 2000]. This suggests that 
2.1 Assignment versus Extraction                               about 80% of the phrases are acceptable (not "bad") to 
                                                               human readers, which is sufficient for many applications. 
There are two general approaches to automatically supplying      Asking human readers to rate machine-extracted 
keyphrases for a document: keyphrase assignment and            keyphrases is a costly process. It is much more economical 
key phrase extraction. Both approaches use supervised          to use author-assigned keyphrases as a benchmark for 
machine learning from examples. In both cases, the training    evaluating the machine-extracted keyphrases. Jones and 
examples are documents with manually supplied keyphrases.      Paynter [2001, 2002] argue that it is reasonable to use 
   In keyphrase assignment, there is a predefined list of      comparison with authors as a surrogate for rating by human 
keyphrases (in the terminology of library science, a           readers. They show (1) the vast majority of Kea keyphrases 
controlled vocabulary or controlled index terms). These        are rated positively by human readers, (2) the performance 
keyphrases are treated as classes, and techniques from text    of Kea is comparable to GenEx, according to human ratings, 
classification (text categorization) are used to learn models  (3) readers generally rate author-assigned keyphrases as 
for assigning a class to a given document [Leung and Kan,      good, and (4) different human readers tend to agree on the 
 1997; Dumais et al, 1998]. Usually the learned models will    rating of keyphrases. 
map an input document to several different controlled            Furthermore, Gutwin et al. [1999] show that machine-
vocabulary keyphrases.                                         extracted keyphrases are useful in an application. The 
   In keyphrase extraction, keyphrases arc selected from       Keyphind system uses keyphrases extracted by Kea in a new 
within the body of the input document, without a predefined    kind of search engine. For certain kinds of browsing tasks, 
list. When authors assign keyphrases without a controlled      Keyphind was judged to be superior to a traditional search 
vocabulary (in library science, free text keywords or jree     engine [Gutwin et al., 1999]. In summary, there is solid 
index terms), typically from 70% to 90% of their keyphrases    evidence that author-assigned keyphrases are a good 
appear somewhere in the body of their documents [Turney,       benchmark for training and testing keyphrase extraction 
1999]. This suggests the possibility of using author-assigned  algorithms, but it should be noted that the performance 
free text keyphrases to train a keyphrase extraction system.   numbers underestimate the actual quality of the output 
In this approach, a document is treated as a set of candidate  keyphrases, as judged by human readers. 
phrases and the task is to classify each candidate phrase as 
either a keyphrase or non-keyphrase [Turney, 1999, 2000;       2.2 Coherence 
Frank et al., 1999; Witten et al, 1999, 2000]. 
                                                               An early study of coherence in text was the work of Halliday 
   Keyphrase extraction systems are trained using a corpus 
                                                               and Hasan [1976]. They argued that coherence is created by 
of documents with corresponding free text keyphrases. The 
                                                               several devices: the use of semantically related terms, 
GenEx keyphrase extraction system consists of a set of 
                                                               coreference, ellipsis, and conjunctions. The first device, 
parameterized heuristic rules that are tuned to the training 
                                                               semantic relatedness, is particularly useful for isolated 
corpus by a genetic algorithm [Turney, 1999, 2000]. The 
                                                               words and phrases, outside of the context of sentences and 
Kea keyphrase extraction system uses a naive Bayes 
                                                               paragraphs. Halliday and Hasan [1976] called this device 
learning method to induce a probabilistic model from the 
                                                               lexical cohesion. Morris and Hirst [1991] computed lexical 
training corpus [Frank et al, 1999; Witten et al, 1999, 
                                                               cohesion by using a thesaurus to measure the relatedness of 
2000]. After training, both systems allow the user to specify 
                                                               words. Recent work on text summarization has used lexical 
the desired number of keyphrases to be extracted from a 
                                                               cohesion in an effort to improve the coherence of machine-
given input document. 
                                                               generated summaries. Barzilay and Elhadad [1997] used the 
   In experimental evaluations, using independent testing 
                                                               WordNet thesaurus to measure lexical cohesion in their 
corpora, GenEx and Kea achieve roughly the same level of 
                                                               approach to summarization. 
performance, measured by the average number of matches 
                                                                 Keyphrases are often specialized technical phrases of two 
between the author-assigned keyphrases and the machine-
                                                               or three words that do not appear in a thesaurus such as 
extracted keyphrases [Frank et al, 1999; Witten et ai, 1999, 


INFORMATION EXTRACTION                                                                                                435  WordNet. In this paper, instead of using a thesaurus,         IDF component). There are many ways to calculate 
 statistical word association is used to estimate lexical      TFxIDF; see Frank et al. [1999] for a description of their 
 cohesion. The idea is that phrases that often occur together  method. The distance feature is, for a given phrase in a 
 tend to be semantically related.                              given document, the number of words that precede the first 
   There are many statistical measures of word association     occurrence of the phrase, divided by the number of words in 
 [Manning and Schutze, 1999]. The measure used here is         the document. The baseline feature set consists of these two 
 Pointwise Mutual Information (PMI) [Church and Hanks,         features. 
 1989; Church et al, 1991]. PMI can be used in conjunction       The TF*IDF and distance features are real-valued. Kea 
 with a web search engine, which enables it to effectively     uses Fayyad and Irani's [1993] algorithm to discretize the 
 exploit a corpus of about one hundred billion words           features. This algorithm uses a Minimum Description 
 [Turney, 2001]. Experiments with synonym questions, taken     Length (MDL) technique to partition the features into 
 from the Test of English as a Foreign Language (TOEFL),       intervals, such that the entropy of the class is minimized 
 show that word association, measured with PMI and a web       with respect to the intervals and the information required to 
 search engine, corresponds well to human judgements of        specify the intervals. 
 synonymy relations between words [Turney, 2001].                The naive Bayes algorithm applies Bayes' formula to 
                                                               calculate the probability of membership in a class, using the 
 3 Kea: Four Feature Sets                                      ("naive") assumption that the features are statistically 
                                                               independent. Suppose that a candidate phrase has the feature 
 Kea generates candidate phrases by looking through the 
                                                               vector <T, D>, where T is an interval of the discretized 
 input document for any sequence of one, two, or three 
                                                               TFxIDF feature and D is an interval of the discretized 
 consecutive words. The consecutive words must not be 
                                                               distance feature. Using Bayes' formula and the 
 separated by punctuation and must not begin or end with 
                                                               independence assumption, we can calculate the probability 
 stop words (such as "the", "of, "to", "and", "he", etc.). 
                                                               that the candidate phrase is a keyphrase, as 
 Candidate phrases are normalized by converting them to 
                                                               follows [Frank et al, 1999]: 
 lower case and stemming them. Kea then uses the naive 
 Bayes algorithm [Domingos and Pazzani, 1997] to learn to 
 classify the candidate phrases as either keyphrase or non-                                                          (1) 
 keyphrase} 
   In the simplest version of Kea, candidate phrases are       The probabilities in this formula are readily estimated by 
 classified using only two features: TFxIDF and distance       counting frequencies in the training corpus. 
 [Frank et al, 1999; Witten et al, 1999, 2000]. In the 
 following, this is called the baseline feature set (Section   3.2 Keyphrase Frequency Feature Set 
 3.1). Another version of Kea adds a third feature, keyphrase  The keyphrase frequency feature set consists of TFxIDF 
 frequency, yielding the keyphrase frequency feature set       and distance plus a third feature, keyphrase-frequency 
(Section 3.2) [Frank et al, 1999]. This paper introduces a     [Frank et al, 1999]. For a phrase P in a document D with a 
new set of features for measuring coherence. When              training corpus C, keyphrase-frequency is the number of 
combined with the baseline features, the result is the 
                                                               times P occurs as an author-assigned keyphrase for all 
coherence feature set (Section 3.3). When combined with 
                                                               documents in C except D. Like the other features, 
the keyphrase frequency feature set, the result is the merged 
                                                               keyphrase-frequency is discretized [Fayyad and Irani, 1993]. 
feature set (Section 3.4). 
                                                               Equation (1) easily expands to include keyphrase-frequency 
   After training, given a new input document and a desired    [Frank etal, 1999]. 
number of output phrases, N, Kea converts the input              The idea here is that a candidate phrase is more likely to 
document into a set of candidate phrases with associated       be a keyphrase if other authors have used it as a keyphrase. 
feature vectors. It uses the naive Bayes model to calculate    Frank et al [1999] describe keyphrase-frequency as 
the probability that the candidates belong to the class        "domain-specific", because intuition suggests it will only 
keyphrase, and then it outputs the N candidates with the       work well when the testing corpus is in the same domain 
highest probabilities. 
                                                               (e.g., computer science) as the training corpus. This intuition 
                                                               is confirmed in the following experiments (Section 4). 
3.1 Baseline Feature Set 
 TFxIDF (Term Frequency times Inverse Document                 3.3 Coherence Feature Set 
Frequency) is commonly used in information retrieval to        The coherence feature set is calculated using a two-pass 
assign weights to terms in a document [van Rijsbergen,         method. The first pass processes the candidate phrases using 
 1979]. This numerical feature assigns a high value to a       the baseline feature set. The second pass uses the top K most 
phrase that is relatively frequent in the input document (the  probable phrases, according to the probability estimates 
 TF component), yet relatively rare in other documents (the    from the first pass, as a standard for evaluating the top L 
                                                               most probable phrases (K< L). In the second pass, for each 
 1 The following experiments use Kea version 1.1.4, which is   of the top L candidates (including the top K candidates), new 
available at http://www.nzdl.org/Kea/.                         features are calculated based on the statistical association 


436                                                                                        INFORMATION EXTRACTION  between the given candidate phrase and the top K phrases.     For the query to AltaVista, phrase, is converted to cap,, in 
 The hypothesis is that candidates that are semantically       which the first character of each word in phrase, is 
 related to one or more of the top K phrases will tend to be   capitalized, but the other characters are in lower case, and 
 more coherent, higher quality keyphrases.                     the words are not stemmed. The query "cap, AND low" is 
   The coherence feature set consists of 4+2K features. The    intended to find web pages in which phrase, appears in a 
 experiments use K = 4 and L = 100, thus there are twelve      title or heading (where it would likely be capitalized) and 
 features. The first four features are based on the first pass phrasej appears anywhere in the page (where it would likely 
 with the baseline model. The first two features are TF*IDF    be in lower case). The rank of score_capj(phrase,) is 
 and distance, copied exactly from the first pass. The third   normalized by converting it to a percentile. The plan is that 
 feature is baselinejrank, the rank of the given candidate     rank_cap, for example, will be relatively high when the 
 phrase in the list of the top L phrases from the first pass,  appearance of phrase, in a heading makes it likely that 
 where the list is sorted in order of estimated probability. The phrase1 will appear in the body. That is, phrase, would be a 
 fourth feature, baseline_probability, is the estimated        good phrase to put in the title of a document that discusses 
 probability, p(key\T, D), according to the baseline model.    phrase 1. 
   The remaining eight features are based on statistical 
 association, calculated using Pointwise Mutual Information    3.4 Merged Feature Set 
 (PMI) and a web search engine [Turney, 2001]. The             The merged feature set consists of the coherence feature set 
 following experiments use the AltaVista search engine. Let    plus keyphrase-frequency. As with the coherence feature set, 
 hits(q uery) be the number of hits (matching web pages)       there is a two-pass process, but the first pass now uses the 
 returned by AltaVista when given a query, query. Features     three features of the keyphrase frequency feature set, instead 
 five to eight are rank low rank_low2 rank_low3, and           of the baseline features. The second pass now yields thirteen 
 rank_low4. For i= 1 to 100 and j = 1 to 4, rank low is the    features, the twelve features of the coherence feature set plus 
 normalized rank of the candidate phrase, phrase,, when        keyphrase-frequency. The third and fourth features of the 
 sorted by the following score:                                coherence feature set, baselinejrank and 
                                                               baseline _probability, become key_freq_rank and 
                                                               key_freqprobability in the merged feature set. 
                                                       (2) 
                                                               4 Experiments 
 For the query to AltaVista, phrase,- is converted to lower 
                                                               The first experiment examines the behaviour of the four 
 case, lowi, but it is not stemmed. The rank of 
                                                               feature sets when trained and tested on the same domain. 
 score low (phrasse) is normalized by converting it to a 
                                                               The second experiment trains on one domain (computer 
 percentile. The ranking and normalization are performed for 
                                                               science) and tests on another (physics). 
 each document individually, rather than the corpus as a 
 whole. The query "low, NEAR low/' causes AltaVista to 
                                                               4.1 Intradomain Evaluation 
 restrict the search to web pages in which low, appears within 
                                                               This experiment compares the four feature sets using the 
 ten words of lowj in either order. Equation (2) can be 
 derived from the formula for PMI [Turney, 2001]. The          setup of Frank et al [1999]. The corpus is composed of 
                                                               computer science papers from the Computer Science 
 intent is that, with rankjowi for example, if a candidate 
 phrase, phrase,, is strongly semantically connected with      Technical Reports (CSTR) collection in New Zealand. The 
                                                               training set consists of 130 documents and the testing set 
 phrase1, then phrase, will likely receive a high score from 
                                                               consists of 500 documents. The keyphrase-frequency feature 
 Equation (2), and hence rankjow1 will tend to be relatively 
 high.                                                         is trained on a separate training set of 1,300 documents. All 
                                                               other features (including the coherence features) are trained 
   Features nine to twelve are rank_cap\, rank_cap2, 
                                                               using only the 130 training documents. The naive Bayes 
 rank cap3, and rank_cap4. For i= 1 to 100 and j = 1 to 4, 
 rank_capj is the normalized rank of the candidate phrase,     algorithm allows the features to be trained separately, since 
phrase,, when sorted by the following score:                   the features are assumed to be statistically independent. The 
                                                               experiments of Frank et al. [1999] show that the keyphrase-
                                                               frequency feature benefits from more training than the 
                                                               baseline features. Figure 1 plots the performance on the 
                                                               testing corpus. 


 INFORMATION EXTRACTION                                                                                              437                                                                 Figure 2. Performance on the LANL corpus for the four 
 Figure 1. Performance on the CSTR corpus for the four different 
                                                                different feature sets. Note that the curves for the keyphrase 
 feature sets. An output kcyphrase is considered "correct" when it 
                                                                frequency and merged features sets are intermingled, making it 
 equals an author-assigned keyphrase, after both are stemmed and 
                                                                appear that there are only three curves, instead of four. 
 converted to lower case. 

   The paired t-test was used to evaluate the statistical     4.3 Discussion 
significance of the results [Feelders and Verkooijen, 1995]. 
                                                              Both experiments show that the coherence features are a 
There are six possible ways to pair the four curves in 
                                                              significant improvement over the baseline features alone. 
Figure 1. The differences between all six pairs are 
                                                              More of the output keyphrases match with the authors' 
statistically significant with 95% confidence when five or 
                                                              keyphrases, which is evidence that their quality has 
more keyphrases arc output. The merged feature set is 
                                                              improved [Jones and Paynter, 2001, 2002]. The second 
superior to the keyphrase frequency feature set with 95% 
                                                              experiment confirms the (previously untested) hypothesis of 
confidence when any number of keyphrases are output. 
                                                              Frank et al. [1999], that the keyphrase-frequency feature is 
4.2 Interdomain Evaluation                                    domain-specific. This feature actually decreases 
                                                              performance below the baseline in the interdomain 
This experiment evaluates how well the learned models         evaluation. However, the new coherence features are not 
generalize from one domain to another. The training domain    domain-specific; they improve over the baseline even when 
is the CSTR corpus, using exactly the same training setup as  the testing domain is different from the training domain. 
in the first experiment. The testing domain consists of 580   Furthermore, the coherence features can work synergistically 
physics papers from the arXiv repository at the Los Alamos    with the keyphrase-frequency feature, when the training and 
National Laboratory (LANL). Figure 2 plots the                testing domains correspond. When they do not correspond, 
performance on the testing corpus.                            at least the merged feature set is no worse than the 
  The paired t-test shows no significant differences between  keyphrase frequency feature set. 
the keyphrase frequency feature set and the merged feature 
set. The coherence feature set is superior to the baseline    5 Limitations and Future Work 
feature set with 95% confidence when four or more 
keyphrases are output. The baseline feature set is superior to The main limitation of the new coherence feature set is the 
the keyphrase frequency and merged feature sets with 95%      time required to calculate the features. It takes ten queries 
confidence when any number of keyphrases are output.          (2+2K, K = 4) to AltaVista to calculate one coherence 
                                                              feature vector. Each query takes about one second. At 10 
                                                              queries per feature vector times 1 second per query times 
                                                              100 feature vectors per document, we have 1,000 seconds 


438                                                                                        INFORMATION EXTRACTION 