                             Corpus-based, Statistical Goal Recognition 

                                         Nate Blaylock and James Allen 
                                          Department of Computer Science 
                                               University of Rochester 
                                             Rochester, New York, USA 
                                          {blaylock.james}cs.rochester.edu 


                        Abstract                                    the system needs at least partial information to allow it 
                                                                    to act on the user's utterance. 
     Goal recognition for dialogue systems needs to be 
                                                                 3. Portability: We want to be able to rapidly port our dia•
     fast, make early predictions, and be portable. We 
                                                                    logue system to new domains. 
     present initial work which shows that using statisti•
     cal, corpus-based methods to build goal recognizers         We present initial work in which we use corpus-based 
     may be a viable way to meet those needs. Our goal         methods to build a goal recognizer. Our recognizer is fast 
     recognizer is trained on data from apian corpus and       (linear in the number of possible goals), makes early predic•
     then used to determine the agent's most likely goal       tions, and is easier to port to new domains than many systems, 
     based on that data. The algorithm is linear in the        as it does not require a hand-crafted domain plan library. 
     number of goals, and performs very well in terms            We first discuss the corpus-based approach we take in goal 
     of accuracy and early prediction. In addition, it is      recognition. We then report on initial experiments that we 
     more easily portable to new domains as does not           have performed and discuss results. Finally, we comment on 
     require a hand-crafted plan library.                      related work and then discuss future directions for our work. 
                                                               2 The Corpus-based Approach 
1 Introduction                                                 The use of statistical methods, based on corpora, has revo•
Much work has been done over the years in plan recognition,    lutionized the field of Natural Language Processing over the 
which is the task of inferring an agent's goal and plan based  past 10+ years. The method is as follows: one uses a corpus 
on observed actions. Goal recognition is a special case of     of data to train a statistical model which is then used to make 
plan recognition, in which only the goal is recognized.        predictions on future data. Seemingly simple methods have 
                                                               yielded good results in many areas of NLP.
  Goal and plan recognition have been used in a variety of                                              1 
                                                                 We apply a similar approach to the task of goal recogni•
applications including intelligent user interfaces [Lesh et al, 
                                                               tion. We use a plan corpus (a list of goals and the plans 
1999], dialogue systems [Carberry, 1990b; Allen et a/., 2000] 
                                                               an agent executed to achieve them) to train statistical mod•
and machine translation [Alexandersson, 1995]. 
                                                               els which can predict an agent's goal based on an observed 
  We are especially interested in applying goal recognition 
                                                               sequence of actions. As we show below, initially work shows 
to dialogue systems, in order to aid natural language under•
                                                               several possible advantages over previous work on goal and 
standing and intention recognition. We do not intend to use 
                                                               plan recognition: recognition is fast (linear in the number of 
a goal recognizer to directly recognize communicative inten•
                                                               goals), robust (can handle unknown actions and plans) and 
tions (the goals behind a user's utterance); rather, we intend 
                                                               does not require a hand-crafted plan library. 
to use it to identify a user's domain goals to quickly help nar•
row the search space for more costly intention recognition     2.1 Recognition using N-gram Models 
routines (e.g., [Lochbaum, 1998; Chu-Carroll and Carberry, 
                                                               We define the task of goal recognition as follows: given 
2000]). 
                                                               an observed sequence of n actions so far 
  This application places several demands on our goal recog•
                                                               (which, for compactness, we will represent as find the 
nizer: 
                                                               most likely goal G: 
  1. Speed: Dialogues happen in real-time, and the system is 
     expected to understand a user's utterance and generate a 
     response in a short amount of time. 
  2. Early/partial prediction: We need accurate goal pre•
     dictions very early on in the exchange, as the system 
     needs this information to better respond to a user's ut•
     terance. If full recognition is not immediately available, 


USER MODELING                                                                                                       1303             | Goal#    Goal Description                                                             Sessions 
            [""' 1     Find a file named 'core'                                                            11 
                   2   Find a file that contains the word 'motivating' and whose name ends in '.tex'       11 
                   3   Find a machine that has low (<1.0) load; AND determine if Oren Etzioni is 
                       logged into the machine named chum                                                   5 
                   4   Compress all large files (> 10,000 bytes) in the Testgrounds subdirectory tree       2 
                   5   Compress all files in the directory named 'backups' [Don't use *]                    3 
                   6   Find a large file (> 100,000 bytes) that hasn't been changed for over a month        8 
                   7   Find a file that contains less than 20 words                                         8 
                   8   Find a laser printer in Sieg Hall that has an active print job                      6 
                   9   Find a Sun on that has low (<1.0) load; AND determine if Dan Weld is active 
                       on the machine named chum                                                           2 
                  10   Find a file named oldpaper in neal/Testgrounds subdirectory                          1 
                  11   Find a file of length 4 in neal/Testgrounds subdirectory                             1 
                  12   See if Dan Weld is logged in to chum                                                 1 
                       Total                                                                              59 j 

                                    Table 1: Goals and their counts in the UNIX corpus 

   Since is constant in the argmax, we can drop it:                           Goal Types                 12 
                                                                              Goal Sessions             59 
                                                        (3)                   Action Types              22 
                                                                              Total Actions            412 
   Using the Chain Rule, we can rewrite this as:                              Average Actions/Goal       7 

                                                                         Table 2: Statistics for the UNIX corpus 

                                                        (4) 
   These conditional distributions are very large and difficult 3 Experiments 
 to estimate, therefore, we make an n-gram assumption, i.e., 
                                                               3.1 The Plan Corpus 
 we assume that an action Ai is only dependent on the goal 
 G and the j actions preceding it For a unigram                We performed several experiments using Lesh's UNIX plan 
 model, we assume that At is independent of all other actions. corpus [Lesh, 1998]. The corpus was gathered from human 
 In this case, our goal recognition equation becomes:          UNIX users (CS undergraduates) at the University of Wash•
                                                               ington. Users were given a task in UNIX (a goal), and were 
                                                               instructed to solve it using a subset of UNIX commands (no 
                                                        (5)    pipes, no awk, etc.) The students' commands and results 
                                                               were recorded, as well as whether or not they successfully 

   If we assume that Ai is independent of everything but G     accomplished the goal. There were 59 successful goal ses•
 and A,_I, we get a bigram model:                              sions which involved 12 different goals. Table 1 shows the 
                                                               individual goals and the number of successful goal sessions 
                                                               for each. 
                                                        (6)      We automatically removed unsuccessful commands, such 
                                                               as typos, from each execution. Remaining commands were 
                                                               stripped of arguments to a base command type form. This 
   We estimate andusing a 
                                                               means our training set consisted only of action types (such 
plan corpus. Then, for recognition, we first initialize our goal 
                                                               as Is, grep, etc.), and did not consider flags or arguments. 
probabilities with P(G). For each action we observe, we 
                                                               We hope to extend our model to incorporate that additional 
multiply each goal's score by the corresponding conditional 
                                                               information in the future (see below). 
probability. 
                                                                 Table 2 shows some relevant statistics from the resulting 
   This algorithm has the nice feature of compositionality —   plan corpus. There were 12 possible goals and 22 different 
new observations produce conditional probabilities, which      action types used in the goal sessions. On average, there were 
are simply multiplied with the previous predictions. This re•  7 actions per goal session. 
sults in computational savings, since updates are linear in the 
                                                                 We used cross-validation testing on 56 test cases.2 Because 
number of goals. It also gives us a good model for early pre•

diction (as desired for our dialogue system), since the model     2Thc total number of goal sessions was 59, but sessions involving 
is based on actions observed so far and does not require all   goals 10, 11 and 12 were not used as test data, since these were 
actions in the plan execution.                                 the only exemplars of their goals (see Table 1). These cases were 


1304                                                                                                   USER MODELING of the small size of the UNIX corpus, the training set was     partly due to the fact that some goals (such as goal 8, for ex•
formed by removing only the test case from the corpus for      ample) were highly correlated with a single command (such 
each test case.                                                as lpq in this case), which immediately boosted the proba•
                                                               bility of the correct goal. 
3.2 Evaluation Metrics 
As pointed out by Lesh [Lesh, 1998], there is a lack of agreed- 3.4 Bigram model 
upon metrics and benchmarks for reporting results for plan     In our next experiment, we used a bigram model (based on 
and goal recognizers. We use the following metrics to report   Equation 6), which encodes at least some ordering into the 
our results as they measure the attributes we are seeking for  actions by considering both the current action and the pre•
a goal recognizer (as described above). A test case is the set ceding action. 
of actions executed for a goal. The actions are fed one by one   We prepend a special start action to the front of each 
to the recognizer, which makes predictions after every action. execution, which handles the special case of Equation 6 in 
Each metric is for a single test case. For reporting multiple  which n = 1, i.e., when we've only seen one action so far. 
test cases, the metric is averaged across all cases.           This also encodes information about which actions tend to 
   • Accuracy: The number of correct predictions divided by    begin executions, which may or may not be correlated to the 
     the total number of observed actions.                     goal. 
                                                                 For the case where equals 0, i.e., the 
   • Converged: Whether or not the final prediction was cor•   bigram was never seen in conjunction with the goal, we 
     rect (i.e., whether the recognizer finish with the correct use a unigram back-off model which uses the estimation 
     answer).                                                                                 As with the unigram model 

   • Convergence point: If the recognizer converged, at        above, if P(Ai\G) equals 0, we smooth this with a small con•
     which point in the input it started giving only the correct stant. 
     answer. This is reported as an action number (i.e., after   As expected, the bigram model performed much better than 
     observing x actions); it is also reported as a percentage the unigram model, with an accuracy of 71.7% and with 
     of the input according to the following equation:         83.9% of cases converging. For the tests cases which con•
                                                               verged, they converged on average 22.3% through the input, 
                                                               or after 2.3 actions. 
                                                                 While accuracy and convergence were markedly better 
     Intuitively, this shows how far through the plan execu•   than the unigram model, the convergence point only im•
     tion the recognizer started (exclusively) predicting the  proved slightly in the bigram model. However, this was al•
     right goal, with 0% meaning after the first action, and   ready quite good, and may simply mean that we are approach•
     100% after the final action. A low percentage indicates   ing a limit on how soon the prediction can be made in this 
     that the recognizer is making accurate early predictions. particular domain. 
3.3 Unigram model                                                As for convergence, it is illustrative to look at a goal-by-
                                                               goal breakdown of results. Table 3 shows convergence results 
For our first experiment, we trained unigram models on the     for each goal type. For the 9 cases which didn't converge, 5 
data (based on Equation 5). To provide for unseen data, where  arc goal 6, which is often misclassified as either goal 1 or 
P(At\G) was 0, P(Al\G) was set to be a very small constant.    goal 11. This seems mostly to be due to the fact that these 
This smoothing technique allows goal G to still remain possi•  three goals are very similar. Goal 1 is to find a file named 
ble, in case other evidence makes it likely, despite the fact that 'core\ goal 6 is to find a large file that hasn't been changed 
action Al was not seen in relation to it in the training data. for over a month, and goal 11 is to find a file of length 4. All 
   With the unigram model, our recognizer achieved an ac•      of these have to do with finding a file with a certain set of 
curacy of 63.1%, with 73.2% of the cases converging. For       attributes, and in fact, the command Is can be used to learn 
cases which converged, the average point of convergence was    all of these attributes about a file. Goal sessions for all three 
23.1% through the input, or after observing an average of 2.4  of these goals mostly consisted of the commands cd and Is. 
actions. 
   Because a unigram model assumes independence of all ac•     3.5 Goal Abstractions 
tions, it is equivalent to treating actions as an unordered list.
                                                          3    In our final experiment, we defined an abstraction hierarchy 
This assumption is partly to blame for the relatively low ac•
                                                               for goal types. The abstract types and goals they encompass 
curacy and convergence, since action ordering is important 
                                                               are shown in Table 4. 
in the domain. We attempt to rectify this by using a bigram 
                                                                 As we discussed above, a dialogue system needs to be able 
model below. 
                                                               to reason quickly, accurately and early about a user's goals 
  It is interesting to note the low point of convergence. This 
                                                               and intentions. If the user's specific goal cannot be deter•
shows that, for the tests which did converge, they converged 
                                                               mined, a dialogue system can often use partial information 
fairly quickly, i.e., the recognizer was able to tell fairly 
                                                               in formulating a response to the user. These abstract goal 
quickly what the goal was. This quick convergence seems 
                                                               classes represent that partial information. If we are unable to 
still used in training for other test cases, however, and were still determine a specific goal, the system can perhaps determine 
candidate goals for recognition.                               what the user's abstract goal is, and this may be enough to 

   3This is a list and not a set since actions can be repeated. formulate a response. 


USER MODELING                                                                                                       1305           Goal#    Convergence       Competitors               tioned above. We then discuss several challenges that remain. 
        [ 1 10/11(90.9%)             6:1 
               2   11/11(100.0%)     none                      4.1 Desiderata 
               3   4/5 (80.0%)      9:1                        Speed Because it involves a simple probability lookup, our 
               4   2/2(100.0%)      none                       recognizer is linear in the number of goals (and training it 
               5   2/3 (66.7%)      4:1                        is linear in the amount of training data). Speed is a big ad•
               6   3/8 (37.5%)       1:2,11:3                  vantage to this approach. By comparison, logic-based rea•
               7   8/8 (100.0%)     none                       soning recognizers like [Kautz, 1991] are exponential in the 
               8   6/6 (100.0%)     none                       size of the plan library.4 Several systems [Vilain, 1990; 
                                                               Lesh, 1998] improve on this time complexity, but at the ex•
               9   1/2 (50.0%)      3:1 
                                                               pense of expressiveness. 
   Table 3: Convergence by goal in the bigram experiment 
                                                               Early/partial prediction Our recognizer was able to make 
                                                               correct predictions 22.3% (2.3 actions) through the input 
                                      Goals which              with 83.9% overall accuracy, and give correct abstract results 
      Abstract Goal                   Instantiate              11.9% (1.7 actions) through the input with 100.0% overall 
      Find a file with attributes     1,2,6,7, 10, 11          accuracy. This early prediction is crucial to our domain of 
      Find a machine with attributes  3,9,12                   dialogue systems. 
      Compress files with attributes 4,5                         Most work does not report how early the recognizer makes 
      Find a printer with attributes  8                        correct predictions. Lesh [Lesh, 1998] simulates a task-
                                                               completion agent, which, upon recognizing the user's goal, 
                Table 4: Abstract goal types                   steps in to complete the task. He reports5 a convergence point 
                                                               of 29.9% (after 8.7 actions for an average plan length of 26.8 
                                                               actions) for the task of searching for a printer with attributes 
  The probability of an abstract goal is calculated by sim•    (4 predicates) and a convergence point of 23.1% (after 4.9 
ply summing the probabilities of each of its children. For this actions for an average plan length of 17.9 actions) for a re•
experiment, we use the same bigram model as before and per•    stricted cooking domain, both with 100.0% accuracy because 
form an additional summing at each step to calculate the most  Lesh uses a 'strict consistency' approach. For most domains, 
likely abstract goal.                                          however, (like the full UNIX corpus), it is unclear if it could 
  The recognizer predicted abstract goals very well, with      make such early predictions. Because it is based on 'strict 
91.0% accuracy and 100.0% of the cases converging. The         consistency', a goal hypothesis must become logically im•
average convergence point was 11.6% through the input, or     possible before it can be ruled out. In fact, even in for the 
after 1.7 actions. Table 5 summarizes the results of all three domains he reports statistics in, the recognizer rarely recog•
experiments.                                                   nizes the user's actual goal exclusively, rather, based on the 
  It is important to note that abstract goal recognition does  set of possible goals, it tries to recognize a sufficient goal that 
not occur in competition to, but rather in conjunction with the covers all possible goals. As Lesh points out, many domains 
specific goal recognition. Of course, it is best to recognize do not lend themselves to the prediction of sufficient goals. 
the specific goal, which our bigram model seemed to do fairly 
well, but we can also recognize the abstract goal more quickly Portability The portability of our goal recognizer depends 
and more accurately. And, there may be many cases where       on the existence of a plan corpus. If a plan corpus exists or 
it will be sufficient for the dialogue system to have just the can be created for the new domain (see section below), all 
abstract goal in order to help the user. 
                                                              we have to do is use it to train models for the new domain.6 
                                                              On the other hand, most goal recognizers (e.g., [Vilain, 1990; 
4 Discussion                                                  Carberry, 1990a; Kautz, 1991; Charniak and Goldman, 1993; 
                                                              Paek and Horvitz, 2000]), require a complete, hand-crafted 
These initial results are encouraging, but there still remain 
                                                              plan library in order to perform recognition, which can re•
significant challenges for scaling up the system to sufficiently 
                                                              quire a significant amount of knowledge engineering for each 
complex domains. In this section, we discuss our goal recog•
                                                              domain. 
nizer in light of the desiderata for dialogue systems we men-
                                                                 4Granted, these systems are performing plan recognition and not 
                                                              just goal recognition, which makes the comparison unfair. However, 
                                            Abstract          very little work has been done on goal recognition in its own right, 
                      Unigram     Bigram      Goals           so plan recognizers are all we have to compare against. 
     Accuracy            63.1%     71.8%       91.0%             5 Lesh reports the average length of plan with and without the 
     Converged           73.2%     83.9%      100.0%          task-completion agent, which we used to calculate these conver•
    Conv. Point          23.1%     22.3%       11.6%          gence points. 
    Conv. Action#           2.4        2.3         1.7           6Models could also be trained for different individuals within 
                                                              a single domain by using a user- (or group-) specific corpus. With 
  Table 5: Results of the experiments on the UNIX corpus      other approaches, user-specific models have greatly improved recog•
                                                              nition (e.g., [Lesh, 1998]). 


1306                                                                                                   USER MODELING    Hong's recognizer [Hong, 2001] only requires knowledge      between consistent goals, even if one is more likely than the 
of plan operators, not the library, but it is unable to make early other. 
predictions, as it usually does not make end-goal predictions    There are several lines of research which incorporate prob•
until after it has seen the entire executed plan. Lesh [Lesh,  abilistic reasoning into plan and goal recognition. [Carberry, 
 1998] requires only knowledge of plan operators and domain    1990a] and [Bauer, 1994] use Dempster-Shafer theory and 
goal predicates.                                               [Charniak and Goldman, 1993], [Pynadath and Wellman, 
                                                               1995], and [Paek and Horvitz, 2000] use Belief Networks to 
4.2 Challenges                                                 represent the likelihood of possible plans and goals to be at•
Domain size With only 12 goals and 22 action types, the        tributed to the user. All of these methods, however, require a 
UNIX domain is quite small, and it is unclear whether our      complete plan library as well as the assignment of probability 
recognizer would scale to larger domains. One immediate        distributions over the library. 
fault of our recognizer is that it does not handle parameterized [Appelt and Pollack, 1991] and [Goldman et ai, 1999] cast 
goals. Each of the 12 goals above is treated as an atomic      plan recognition as weighted abduction. However, this also 
unit, and not as a goal schema instantiated with parameters.   requires a plan library and the acquisition of weights for ab-
One straightforward way to handle parameters would be to       ductive rules. Abduction is also computationally hard, and 
treat a goal schema as an abstract goal, with each possible set it is unclear whether such routines would be fast enough for 
of parameter instantiations as a separate, more specific goal. complex domains. 
However, this would explode the number of goals and, in the      Probably the closest work to ours is [Albrecht et ai, 1998], 
case of 2 or more parameters, lead to a multiple-inheritance   which uses a dynamic belief network (DBN) to do goal 
abstraction hierarchy, which is not supported by our current   (quest) recognition in a multi-user dungeon (MUD) domain. 
abstract goal score calculation model.                         The belief network takes into account actions, locations, and 
                                                               previous quest in recognizing the player's current quest. Sim•
Hierarchical plans Another shortcoming of the current          ilar to our own work, their model uses bigram independence 
recognizer is that, although it handles goal abstraction, it does assumptions for both actions and locations. Conditional prob•
not handle hierarchical plans. Complex plans covering longer   ability distributions for the network are estimated from a cor•
time-scales are less likely to be identifiable from a few ob•  pus of MUD sessions. 
servations alone (which tend to reflect more immediate sub-      Although our approaches are similar in terms of the use 
goals). Ideally, we would want to recognize subgoals for par•  of corpora for training, there appear to be a few significant 
tial results, even if we still cannot recognize the high-level differences. Albrecht et ai encode state into their model (in 
goal.                                                          the form of location and previous quest), whereas our current 
                                                               system considers only actions. Perhaps more significantly, 
                                                               they note that the bigram independence assumption is an in•
Data collection In some domains (like operating systems), 
                                                               herent part of DBNs, since relaxing it (say, by using trigram 
it may be possible to collect enough data from users to train a 
                                                               or 4-gram models) would cause a state-space explosion for 
recognizer. In most domains, however, it will be infeasible to 
                                                               the DBN [Albrecht et ai, 1998, 12]. Relaxing the bigram 
collect enough data on users solving goals in order to build ef•
                                                               assumption in our approach should have negligible effect 
fective statistical models. Furthermore, even it this data could 
                                                               on system speed, as probability updates are done by simple 
be collected, the inner structure of the user's hierarchical plan 
                                                               lookup, regardless of the size of the n-gram. To help alleviate 
would not be explicit from the data (i.e., we can only observe 
                                                               space issues, we can store only the higher-order n-grams that 
the primitive actions, not the subgoal structure that motivates 
                                                               we have good estimates for and use a backoff model similar to 
the actions). 
                                                               that used in our bigram model. We believe that higher-order 
   As the next step in our research, we plan to explore the use 
                                                               n-grams will have significant predictive power, and plan to 
of AI planners to generate artificial plan corpora to be used 
                                                               test their use in future research. 
for training. The approach we plan to take combines plan•
ning and Monte-Carlo simulation to generate plan corpora. 
The idea is to generate plans stochastically (allowing distri• 6 Conclusions and Future Work 
butions over different aspects of the planning process, such as 
                                                               We have presented our initial work on using statistical corpus-
the goals, situations and action decompositions). By combin•
                                                               based techniques for goal recognition. Our recognizer is fast 
ing "context-free" Monte-Carlo simulation techniques with 
                                                               (linear time), does early and partial prediction, and can be 
richly context-dependent planning algorithms, we hope to ob•
                                                               ported to new domains more easily than many recognizers. 
tain a corpus that captures likely user behavior. In addition, 
                                                               We showed several initial experiments using the goal recog•
this generated corpus has the big advantage that the subgoal 
                                                               nizer, in which we achieved high recognition rates with high 
hierarchy that generates the observed actions is also known. 
                                                               accuracy early prediction. 
                                                                 There are several areas of fiiture work that we are inter•
5 Related Work                                                 ested in. Several were alluded to above: scaling to larger 
As mentioned above, [Vilain, 1990; Lesh, 1998] improve         domains, incorporating hierarchical plans, and using AI plan•
speed over [Kautz, 1991], but do so at the expense of expres•  ners to generate artificial plan corpora. 
siveness. Also, these goal recognizers are typically not able    In addition, we plan to collect a larger human-generated 
to make early predictions, as they are unable to distinguish   corpus in the UNIX domain. With more training data, we 


USER MODELING                                                                                                        1307 