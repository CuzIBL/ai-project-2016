            MESH-based Active Monte Carlo Recognition (MESH-AMCR)

       Felix v. Hundelshausen    and  H.J. Wunsche¨    M. Block, R. Kompass     and  R. Rojas
      University of the Federal Armed Forces Munich           Free University of Berlin
           Department of Aerospace Engineering            Department of Computer Science
             Autonomous Systems Technology                     14195 Berlin, Germany
                85577 Neubiberg, Germany

                    Abstract                          the art methods and that it performs better geometric veriﬁ-
                                                      cation than current approaches for both rigid and deformable
    In this paper we extend Active Monte Carlo Recog- objects.
    nition (AMCR), a recently proposed framework        The ﬁeld of object recognition can be divided in Object
    for object recognition. The approach is based on  Class Recognition, the problem of recognizing categories of
    the analogy between mobile robot localization and objects, such as cars, bikes or faces (see [Fei-Fei et al., 2004],
    object recognition. Up to now AMCR was only       [Serre et al., 2005] , [Mutch and Lowe, 2006]) and Object
    shown to work for shape recognition on binary im- Identiﬁcation, the problem of recognizing speciﬁc, identical
    ages. In this paper, we signiﬁcantly extend the ap- objects, such a identifying a speciﬁc face or a speciﬁc build-
    proach to work on realistic images of real world  ing. Our approach MESH-AMCR  addresses this latter prob-
    objects. We accomplish recognition under sim-     lem.
    ilarity transforms and even severe non-rigid and
    non-afﬁne deformations. We show that our ap-
    proach works on databases with thousands of ob-
    jects, that it can better discriminate between ob-
    jects than state-of-the art approaches and that it has
    signiﬁcant conceptual advantages over existing ap-
    proaches: It allows iterative recognition with si-
    multaneous tracking, iteratively guiding attention
    to discriminative parts, the inclusion of feedback
    loops, the simultaneous propagation of multiple hy-
    potheses, multiple object recognition and simulta-
    neous segmentation and recognition. While recog-
    nition takes place triangular meshes are constructed
    that precisely deﬁne the correspondence between
    input and prototype object, even in the case of
    strong non-rigid deformations.

1  Introduction
Recently, Active Monte Carlo Recognition (AMCR), a new
object-recognition approach exploiting the analogy between Figure 1: Palm Sunday, an ambiguous painting by the Mexi-
robot localization and object recognition was proposed by can artist Octavio Ocampo
[von Hundelshausen and Veloso, 2006]. Although the ap-
proach is conceptually interesting, it was only shown to work
for shape recognition on binary images, so far. Further- State-of-the-art approaches in object identiﬁcation typi-
more the proposed approach is not scalable to large object cally divide the task in two stages, Feature Matching and
databases.                                            Geometric Veriﬁcation. Prominent feature detection methods
  In this paper we massively extend the approach in various are [Lowe, 2004], [Ke and Sukthankar, 2004], [Mikolajczyk
ways, such that it works on realistic images of real-world ob- and Schmid, 2004] and [Matas et al., 2002]. For ﬁnding
jects, that it is scalable to large object databases, and such that prototype images with matching features different schemes
a correspondence mesh is constructed between input and pro- have been tried, reaching from nearest neighbor search and
totype object recovering correspondence even in the case of Hough-based grouping [Lowe, 2004] to the use of vocabu-
large deformations. We show that our new approach MESH- lary trees [Nister and Stewenius, 2006]. In this ﬁrst stage,
AMCR  can better discriminate between objects than state-of- the goal is to retrieve a bunch of candidate images, with-

                                                IJCAI-07
                                                  2231out worrying about the geometric validity of feature corre- multaneously. Rather than performing a depth ﬁrst ex-
spondences. In Geometric Veriﬁcation the geometric layout amination and iterative breath-ﬁrst examination has to
of feature correspondences is veriﬁed. Typically, RANSAC  take place. While different interpretations iteratively
[Fischler and Bolles, 1981] is used to ﬁnd valid groups of compete, this competition can be examined to determine
feature correspondences, typically verifying their positions where to guide attention an which features to use in or-
subject to the class of afﬁne transformations or rigid epipo- der to discriminate between the competing hypotheses.
lar geometry [Kushal and Ponce, 2006]. An exemption is    None of the before-mentioned approaches offers an in-
[Alexander C. Berg, 2005] where low distortion correspon- terface for such a process.
dences are found through solving an integer quadratic pro- We will show that MESH-AMCR allows to integrate all these
gramming problem, similar to how correspondences where concepts. The remainder of the paper is organized as follows.
                      [                 ]
established in the work of Belongie et al., 2002 .    In section 2 we shortly review Active Monte Carlo Recog-
  Although, the referenced approaches let us reach a state nition (AMCR). In section 3 we describe our new approach
of maturity in object identiﬁcation, they still have some sig- MESH-AMCR. In section 4 we show experimental results.
niﬁcant drawbacks and conceptual problems. With the ex- Section 5 ﬁnally concludes our paper.
emption of [Belongie et al., 2002] their drawback is that
they use only the feature descriptors to distinguish between
objects. While the features are well-suited to establish hy- 2 Active Monte Carlo Recognition (AMCR)
pothetical scale invariant frames of reference, their descrip- AMCR was developed as the consequence of recognizing that
tors only describe a small amount of information that could mobile robot localization and object identiﬁcation are essen-
be used for discrimination. SIFT features, for example, are tially the same problem and transferring the best known local-
willingly not detected at edges, but edges at locations where ization method, Monte Carlo Localization (MCL) [S. Thrun
no SIFT-features are detected could help identiﬁcation. The and Dellaert, 2001] to the problem of object recognition[von
other drawbacks can best be described by three criterions that Hundelshausen and Veloso, 2006]. Similarly to how a robot
should be met by an object recognition framework that is explores its environment and localizes itself in a set of maps,
suited to be integrated in a real-time robotic system. the focus of attention explores an image and recognition is put
 1. Iterative Recognition The process of recognition  as the problem of localizing the focus of attention in one of a
    should be distributable over several frames, only per- set of prototype images. In the same way as MCL uses a set
    forming a small amount of processing in each frame, but of particles to approximate a probability distribution for the
    this amount being rapidly computable, such that other robot’s position, AMCR uses a set of M-Particles to localize
    approaches like tracking can take place simultaneously the position of the attentive V-Particle. Furthermore, not only
    in real-time. Using the information of several frames one point of attention might be used but AMCR employs a
    over time provides richer information for discrimination. set of V-Particles to explore the input image, similarly to how
    None of the above approaches fulﬁlls this criterion, be- an unknown area might be explored by a swarm of robots. To
    cause they are based on single images and perform all apply MCL only two models have to be provided, a measure-
    the processing in each image. Only by using an itera- ment model and a motion model. In AMCR, the measurement
    tive object recognition approach and combining it with model speciﬁes what kind of measurements are taken at the
    tracking the continuity constraints that underly succes- point in the image where a V-Particle is located. The mo-
    sive images of real-world video can be exploited. tion model speciﬁes the distribution of how the M-Particles
                                                      move when the corresponding V-Particle moves. Addition-
 2. Allowing Feedback Figure 1 shows, that the mind sees ally AMCR requires the speciﬁcation of a motion policy, that
    what it wants. The nose can either be a nose or an elbow is a mechanism of how the V-Particles should explore the in-
    depending on what the mind wants to see. Since recog- put image.
    nition is also a question of will” a recognition approach In the original work [von Hundelshausen and Veloso,
    should offer an interface for this will”. For example, it 2006] only binary images of various shapes where used. Each
    should offer an interface of where attention is put on and V- and M-Particle was just described by a (x, y) location to-
    on being able to specify a bias for favored interpreta- gether with an orientation. The motion policy was deﬁned
    tions. Feedback not only means the control of attention by letting the V-Particles move in the direction of their ori-
    but also on the type of features that are use for discrim- entation and letting them being reﬂected at edges. The mea-
    ination. Also, real motoric actions, like gaze control, or surement model was implemented by letting the particles per-
    even movements of a robot might be necessary to dis- forming a range scan, measuring the distance to the ﬁrst edge
    tinguish two objects. Although these ideas are not new, for each scan line, similarly to how laser range scanners are
    none of the current best object-identiﬁcation programs used in mobile robot localization.
    really implements these concepts.                   This instance of AMCR, RADIAL-AMCR  is hardly appli-
 3. Propagating Multiple Hypotheses  Meanwhile the    cable on real word images, since the measurement model is
    computer vision community has well understood, that too simplistic. But it has further drawbacks: One is, that the
    segmentation cannot be accomplished independently method does not scale well with the number of prototype ob-
    from recognition. Thus, no unique ad hoc frame of ref- jects, since for each V-Particle a whole bunch of M-Particles
    erence can be established for comparison, but rather dif- has to be instantiated in each prototype image. Another draw-
    ferent hypothetical matches have to be propagated si- back is that in RADIAL-AMCR there was no mechanism to

                                                IJCAI-07
                                                  2232prevent a V-Particle returning to a location it already had ex- and each M-Particle corresponds to exactly one cell in the M-
plored.                                               Mesh. But the cells that correspond to the particles change
  In our new approach MESH-AMCR  we will get rid of all in each iteration. In fact, the meshes expand in each iteration
these drawbacks by specifying a new measurement model, by one additional cell, respectively, and always these last cells
a new motion model and adding the idea of iteratively con- correspond to the particles. Thus both, V- and M-Particles are
structing hypothetical correspondence-meshes.         basically triangles, deﬁned by three points. This is quite dif-
                                                      ferent to [von Hundelshausen and Veloso, 2006] where the
3  Our new approach: MESH-AMCR                        particles were just points plus an orientation. In this way
                                                      each related pair of V- and M-particles naturally deﬁnes an
In RADIAL-AMCR a swarm of M-Particles starts forming a afﬁne transformation that represents the hypotheses that the
cluster in a prototype shape that corresponds to the input im- V-triangle has to be linearly mapped to the M-triangle in or-
age, at a position that corresponds to the respective V-Particle. der to make input and prototype image match to each other.
While the V-Particle is moving in the input image, the M- However, the validity of the afﬁne transformation is restricted
Particles move accordingly. Thus, a sequence of hypotheti- to the particular cells. Pixels outside the triangles have to be
cally corresponding points in the input image and the proto- mapped by the afﬁne transformations that are given by the
type images is retrieved. One basic idea of MESH-AMCR is neighboring mesh-cells, if available. Of course, the choice
to use these points to construct corresponding meshes. Here, to use triangles as mesh-cells is not arbitrarily: Two corre-
each V-Particle has a triangular mesh, and each of its M- sponding sets of three points constitute the smallest entity that
Particles has a corresponding triangular mesh with the same uniquely deﬁne an afﬁne transformation.
topology, but allowing a deformed geometric layout. Each Summarizing, a V-particle v is represented as
cell of the meshes is a triangle and each triangle in the V-       v := (p , p , p ,       ),
Particle’s mesh has one unique corresponding triangle in each       i     i0  i1 i2 V-meshi           (1)
                                                                         T
mesh of its connected M-Particles. When MESH-AMCR it- with pik =(xik,yik)k=0,1,2, being the corner points of the
eratively converges to a stable interpretation, the mesh of triangle and V-meshi being a triangular mesh that initially
the best M-Particle shows how the input image has to be only contains a copy of the V-Particle’s triangle. Similarly,
deformed in order to match the retrieved prototype-image. an M-particle is represented as a triangle, a mesh, and two
Here, each triangle in the V-particles mesh is linearly mapped additional indices:
                                                                             
to the corresponding M-Particle’s triangle. Indeed the meshes  mj := (pj0, pj1, pj2, M-meshj,ij,kj),  (2)
deﬁne an afﬁne transformation that can change from cell to
                                                      where ij is the index of the V-particle to which the M-particle
cell such that the recovering of non-afﬁne transformations is        k
possible. Before we describe these mechanisms in detail we is connected and j is the prototype image in which the M-
ﬁrst solve the problem of the bad scalability to large object particle is located.
databases.                                            3.3  Scale Invariant Features as Igniting Sparks
3.1  Candidate Object Retrieval                       The M-Particles approximate a probability distribution for the
                                                      V-Particle’s corresponding position and mesh conﬁguration
When using a large database of prototype images, we limit in the prototype maps. Since the meshes are iteratively ex-
the number of images to be considered by applying the re- panded, the dimensonality of the the space of M-Particles
cently proposed vocaulary tree method of [Nister and Stewe- varies. Initially, the meshes start with a single triangle and
nius, 2006], but using PCA-SIFT features [Ke and Suk- thus the dimensionality is 6+1=7(6 for the three points
thankar, 2004] instead of maximally stable regions [Matas and one for the prototype index kj) for the ﬁrst iteration. Even
et al., 2002]. Here, we have to extract all PCA-SIFT fea- this initial dimensionality is very large and a huge number of
tures prior to starting MESH-AMCR, and by applying the M-Particles was needed to let recognition converge to the cor-
tree bases scoring scheme we retrieve the k best candidate rect solution starting for example from a uniform distribution
images. We then apply MESH-AMCR solely on these can-  of M-Particles. To overcome this problem, the trick is to place
didate images. At this point we are violating our own itera- V- and M-Particles at initial starting position that have a high
tive recognition philosophy, but we belief that the PCA-SIFT probability of being correct. We use the PCA-SIFT matches
feature extraction approach can be changed in future, such found in the candidate retrieval phase to deﬁne good starting
that the process of extraction can itself be reorganized into points. Here, we place a V-Particle at each keypoint in the
an iterative process and distributed over several frames. This input image and connect it to M-Particles placed at possible
would be an interesting topic for future research. Currently, matches in the prototype images. More precisely, given a key-
we just extract the features in the ﬁrst frame, get the candidate point in the input image, we can efﬁciently navigate down the
prototype images and then start our iterative method with the vocabulary tree reaching a leaf-node that contains a bucket
successive frames. In our experiments we take the best 8can- with all keypoints in the protype images that deﬁne the same
didate images out of a database of 1000 objects.      visual word (see [Nister and Stewenius, 2006]). These hy-
                                                      pothetical relations between keypoints are the igniting sparks
3.2  V- and M-particles                               for MESH-AMCR.
Both V- and M-Particles will iteratively construct triangular A typical initial situtation is illustrated in ﬁgure 2. The
meshes. The trick in MESH-AMCR is that in each iteration main notion behind the V- and M-particles is that a picto-
a V-Particle corresponds to exactly one cell in the V-Mesh, rial element in the input image can be interpreted in different

                                                IJCAI-07
                                                  2233                                                                                1. iteration
ways: For instance, the nose in image 2 can either be inter-                                M-particle
preted as a nose (prototype image face) or as an ellbow (proto- V-particle
type image of an arm). We now deﬁne the motion policy, the
                                                                V-particle      2. iteration
                                                                                             M-particle
        V-particles                M-particles

                                                                V-particle
                                   m3                                           5. iteration
                                                                                               M-particle

              v1
        v2                             m1

                                                            V-particle
                                                                                21. iteration M-particle
      input image

                                        m2

                                  prototype images

                                                       V-particle
Figure 2: After keypoint matching, V- and M-particles are                        M-particle
setup according to probable keypoint matches returned as a
byproduct of the candidate object retrieval phase.


measurment model and the motion model for MESH-AMCR.                       82. iteration
3.4  Motion Policy and Mesh Expansion
Consider the case of having only one V-particle v :=
(p0, p1, p2, V-mesh). In each iteration, the V-particle per- mesh of the V-particle   mesh of the M-particle
forms a movement, i.e. the coordinates of its three points
(p , p , p )
  0  1  2  change. This movement is performed in a way, Figure 3: During expansion the meshes behold the same topo-
that the new triangle aligns with an edge of the old trian- logical structure. However, the positions of the nodes of the
gle, thereby expanding one of its edges and successively con- M-meshes can vary, thereby allowing to match deformed ob-
structing a triangular mesh. While the V-particle moves in jects.
each iteration, the data structure V − mesh holds the cor-
responding mesh that is constructed. There are many dif-
ferent possibilities regarding the order of edges that are ex- several iterations of measurement, resampling and expansion
panded. In our experiments we simply expand the boundary steps, the resulting meshes can be quite different, even when
mesh cells in a clockwise order.                      they all started to be the same.
  With the V-Particle moving and expanding its mesh by one
cell each M-particle performs a corresponding movement and 3.6 Measurement Model
mesh expansion. While the topology of the M-mesh corre- In each iteration, each M-particle gets a weight that repre-
sponds exactly to its V-mesh, the exact position of the points sents the quality of the hypothetical relation to its connected
can vary, thereby allowing deformed meshes as is illustrated V-particle. This weight is calculated by investigating the ap-
in ﬁgure 3. The distribution of variation is deﬁned in terms of propriate pixels in the input and prototype image. The trian-
the motion model. Thus while the motion policy deﬁnes how gle of the V-particle and the triangle of the M-particle deﬁne
a V-particle moves, the motion model describes the variations an afﬁne transformation and we deﬁne a dissimilarity func-
of movements the M-Particles can perform. Note, that the ex- tion that compares these triangles subject to the given afﬁne
pansion and position of the triangular cells is independent of transformation. Instead of comparing the pixels, we build his-
the initial keypoints. Only the ﬁrst cell positions during ini- tograms with 16 bins of edge orientations and compare these
tialization are placed at the location of keypoint matches. histograms. This idea is inspired by [Edelman et al., 1997],
                                                      based upon a biological model of complex cells in primary
3.5  Motion Model and Mesh Variations                 visual cortex.
Because of the resampling process, good M-particles will
produce multipe exact copies. When a V-particle performs a 3.7 Resampling of the M-particles
movement and mesh expansion step, all the M-particles will In each iteration, the M-particles obtain a weight according to
also perform a corresponding movement and mesh-expansion the measurement model and the M-particles are resampled.
step. However, each M-particle will do so in a slightly differ- In this process a complete set of new M-particles is gener-
ent way such that variations arise in the newly added trian- ated from the old one. Some of the old M-particles are dis-
gles of the M-meshes. Indeed, it is only the free point of the carded, and some are copied multiple times to the new set,
new triangle that varies among the M-meshes. However, after with the total number of M-particles remaining constant. The

                                                IJCAI-07
                                                  2234expected number of copies of an M-particle is proportional
to its weight. Resampling takes place in the set of all M-
particles that are connected to the same V-particle, no matter
in which prototype they lie. Consequently, it can happen that
a prototype looses all its M-particles after some iterations,
meaning that the respective prototype does not represent the
given input image. Vice versa, M-particles will cluster in pro-
totypes matching the input image. In this way the computa-
tional power is concentrated on similar prototypes.

4  Experimental Results
In this section we compare our method with state-of-the-art
object recognition systems and show its advantages. Since
our goal is object identiﬁcation we do not compare to object
class recognition approaches. We show that MESH-AMCR is
better for both geometric veriﬁcation and distinction between
similar objects than existing approaches. To proof this, we
show that MESH-AMCR can deal with all cases in which
traditional methods work, and that it can additionally solve
cases in which state-of-the-art methods fail.
Example
Before describing our results on large object databases we il-
lustrate MESH-AMCR with an example. In this example we
assume that an image of a deformed banknote has to be recog-
nized within 4 candidate objects retrieved by the vocabulary
tree scheme. One of the prototype images contains the same
but non-deformed banknote. While we assume that the proto-
type images are segmented, the input image is not segmented
and contains background clutter. Figure 4 shows how recog-
nition is performed and how deformations can be recovered
by deforming the meshes of the M-Particles.
Efﬁcient Implementation
Although several hypotheses are propagated, our method is
still efﬁcient. The number of V-particles in quite low (10-20).
In each iteration only one triangular cell of each M-Mesh has Figure 4: Red (dark) triangles show the position of V- and M-
to be compared to its corresponding cell of its V-Mesh. Since Particles. The yellow (light) triangles show the corresponding
several M-Particles are linked to the same V-Particle, the pix- meshes. The pixels within the M-Meshes are texture mapped
els of each V-Particle’s cell have to be sampled only once. from its corresponding V-Meshes. In (a) V- and M-Particles
Comparing the triangular cells subject to their afﬁne transfor- are initialized according to well matching PCA-SIFT fea-
mation can be efﬁciently done using standard graphics accel- tures. (b) shows the situation after 3 iterations. In (c) only
erator hardware (e.g. using DirectX).                 the maximum a posteriori (MAP) estimate of the M-Particle
                                                      and its corresponding V-Particle is shown. The meshes of the
Experiments on rigid object databases                 MAP V- and M-particles specify the correspondence between
To evaluate our method we use the wide-baseline stereo input and correctly identiﬁed prototype image.
dataset of the Amsterdam Library of Object Images (ALOI)
[Geusebroek et al., 2005] containing realistic images of 1000
objects, each captured from three different viewpoints (left, geometric validity of keypoint matches based on afﬁne trans-
center, right) rotated by 15 degrees each. We used all 1000 formations. Using this approach we get a recognition rate of
right images to learn the vocabulary tree. As test images we 72.8 percent on the 1000 objects database. For comparison
used the left images (differing by 30 degrees) but addition- we applied MESH-AMCR on the same dataset and test im-
ally we scaled them down to 40 percent of the original size, ages. Here we used only 6 iterations leading to hypothetical
plus rotating each about 45 degrees. For the geometric veriﬁ- correspondence-meshes with 6 triangular cells, respectively.
cation phase, we implemented a method of reference accord- As recognized object we take the candidate-image that has the
ing to current approaches like [Lowe, 2004] and [Ke et al., most M-Particles at the end. In doing so, we get a recognition
2004]. They use afﬁne transformations to explain the geo- rate of 85.2 percent. Thus, MESH-AMCR is performing sig-
metric layout for keypoint matches. In our reference method, niﬁcantly better. MESH-AMCR correctly recognized 46.1 of
we use RANSAC   [Fischler and Bolles, 1981] to verify the the cases that were falsely classiﬁed by the afﬁne transforma-

                                                IJCAI-07
                                                  2235