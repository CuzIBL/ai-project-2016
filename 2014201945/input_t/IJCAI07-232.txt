               Dynamic Veriﬁcation of Trust in Distributed Open Systems

                                Nardine Osman and David Robertson
                                      The University of Edinburgh
                                         School of Informatics
                               N.Osman@sms.ed.ac.uk, dr@inf.ed.ac.uk


                    Abstract                          checker [Osman et al., 2006] for verifying interesting trust
                                                      properties, which go beyond liveness and safety properties
    In open and distributed systems, agents must en-  veriﬁed by traditional veriﬁcation techniques. The result is
    gage in interactions of which they have no previous a powerful, yet simple, veriﬁcation mechanism. The veriﬁer
    experience. Deontic models are widely used to de- itself is lightweight, delegating the complexity of managing
    scribe aspects of permission, obligation, and trust
                                                      the search space to the underlying XSB tabled Prolog system
    anticipated by such agents, but no practical mech- [Sagonas et al., 1994].
    anism has been developed for testing deontic trust  We open with a motivating example in Section 2. Section 3
    speciﬁcations against models of multi-agent inter- provides an overview of our system model and the languages
    actions. This paper describes a way of doing this; used for speciﬁcation. The veriﬁcation process is introduced
    an implementation of it via model checking; and   in Section 4, before concluding with our results in Section 5.
    some preliminary results on a realistic example.
                                                      2   Motivating Example: an Auction System
1  Introduction                                       Section 3 presents our 2-layered architectural approach for
In large-scale open distributed systems, trust remains a funda- distributed open systems. Similar to web service architec-
mental challenge. Despite much research, the notion of trust tures, the basic idea is that a global interaction model is
remains vague and there is no consensus on what exactly trust used to specify the rules of the interaction, irrespective of the
is in systems such as multiagent systems (MAS). This is be- agents engaged in this interaction. Then each agent, based
cause trust may be addressed at different levels. At the low on its local constraints, tries to ﬁnd the most suitable inter-
system level, trust is associated with network security, such action protocol along with the most suitable group of agents
as authentication (determining the identity of the user entity), to interact with. We call the agents’ local constraints the de-
access permissions (deciding who has access to what), con- ontic constraints, since they specify the agents permissions,
tent integrity (determining whether the content has been mod- prohibitions, and obligations.
iﬁed), content privacy (ensuring that only authorised entities Now let us consider the case where an agent is interested in
can access the content), etc. At higher levels, the focus is engaging in an auction scenario for either selling or buying a
on trusting entities — these may be human users, software speciﬁc item. Trust issues automatically arise on two levels.
agents, services, directories, etc. — to perform actions as These may be summarised by the following two questions:
requested, provide correct information, not to misuse infor- ! Which interaction protocol should the agent engage in?
mation, execute protocols correctly, etc.
                                                        !
  Available research has mainly focused on analysing, im- In such an interaction, which agents does it engage with?
proving, and developing strategies that address trust issues For example, before selling its item, the auctioneer will
at various system levels. In this paper we focus not on the have to pick the appropriate interaction protocol, where ap-
strategies, but on the possibility of specifying and verifying propriateness is measured by the satisﬁability of certain prop-
such strategies. We therefore inherit the general deﬁnition of erties. Traditional properties to check for are usually liveness
trust; trust is deﬁned as the problem of who to interact with, and safety properties. For example, the auctioneer may de-
when to interact with them, and how to interact with them cide that the interaction protocol is trusted only if it is dead-
[Ramchurn et al., 2004]. We then show how the speciﬁca- lock free (trust issue TI 1 of Figure 1). A much more interest-
tion and veriﬁcation methods of [Osman et al., 2006] may be ing set of properties may be obtained when tackling domain
used to specify and verify trust models at various system lev- speciﬁc issues. For example, a more challenging trust issue
els. We use the Lightweight Coordination Calculus (LCC)of to verify is whether the interaction protocol enforces truth-
[Robertson, 2004] for modelling global interaction models. telling by the bidders or not (trust issue TI 2 of Figure 1).
Local trust constraints, on the agents level, are modelled via a For a given interaction protocol, each agent will then have
simple trust policy language introduced in Section 3.2. These to select the appropriate agents for such an interaction. The
models may then be fed to a lightweight dynamic model goal is to achieve a set of agents that trust each other. For

                                                IJCAI-07
                                                  1440TI 1: Is the interaction protocol deadlock free?
                                                                message(a(auctioneer,A), a(bidder,Bi), invite(I,R))
                                                            s0
TI 2: In such an interaction, can the bidders be better off if they bid either a lower or a
    higher value than their true valuation?                   message(a(auctioneer,A), a(bidder,Bi), invite(I,R))
                                                                message(a(bidder,Bi), a(auctioneer,A), bid(Vi))
TI 3: If from previous experience the agent knows that DVDs from auctioneer A are s1
    not original, then A is not trusted in delivering good quality DVDs.
                                                              message(a(bidder,Bi ), a(auctioneer,A), bid(Vi))
TI 4: If the auctioneer agent A is not trusted in delivering good quality DVDs, then it
    is not trusted in delivering good quality CDs.          s2
                                                                                      i
TI 5: Agent A is trusted to take the role of the auctioneer only if it has decent ratings message(a(auctioneer,A), a(bidder,B ), won(I,V))
    and holds a good reputation, with more importance given to the most recent
    ratings.                                                s3
                                                              message(a(bidder,Bi ), a(auctioneer,A), payment(P))

                                                            s4
     Figure 1: The auction scenario: some trust issues
                                                      where message(A,B,M) represents the transmission of message M from A to B and
                                                          a(R,I) represents an agent with id I playing the role R
example, one bidder may trust auctioneer A in selling any-
thing except DVDs — possibly, due to previous experience, Figure 2: The auction scenario: the interaction’s state-space
it now knows that these DVDs are not original. It may also
use socio-cognitive models of trust to learn that if the DVDs 3 System Modelling
are not original, then most probably the CDs will not be too
(trust issues TI 3andTI 4 of Figure 1). Another widely used We view MAS as a collection of autonomous agents. The sys-
trust mechanism is the use of ratings and reputations. The tem is open and distributed. Various agents may join or leave
agents should be capable of collecting (or having access to) the system at any time. Interactions become the backbone that
each other’s rating. It is then up to each agent to aggregate holds the system together. Agents group themselves into dif-
these ratings as they see ﬁt. For example, a bidding agent ferent, and possibly multiple, interactions. Figure 3 provides
might decide not to trust new auctioneers with no selling his- such an example, where a collection of agents are grouped
tory. An average rating is then required, possibly giving more into three different interactions (or scenarios): two auction
importance to the latest ratings (trust issue TI 5 of Figure 1). scenarios and a trip planning scenario.
  The trust issues of Figure 1 cover a wide sample of the Due to the dynamic nature of the system, we believe inter-
various trust mechanism in the literature [Ramchurn et al., action groups should be created dynamically and automati-
2004]: from socio-cognitive models (TI 4 of Figure 1), to cally by the agents. We also believe everything should be dis-
evolutionary and learning models (TI 3 of Figure 1), repu- tributed. This implies that there should be no higher layer for
tation mechanism (TI 5 of Figure 1), trustworthy interaction coordination, control, synchronisation, etc. It is the agents’
mechanisms ((TI 2 of Figure 1)), etc. In this paper, we do not responsibility to group themselves into different scenarios.
specify how trust is learned. We focus on the agent’s individ- As a result, we split the MAS model into two layers: the inter-
ual aggregation mechanisms and their speciﬁcation, which is action layer and the agents layer.
essential for verifying trust. For example, while we do not The interaction model speciﬁes the rules and constraints
focus on how the agent obtains the ratings of another (TI 5of on the interaction. This indicates how exactly the interaction
Figure 1), we do require the speciﬁcation of how these ratings may be carried out. The agents’ models specify the rules and
are aggregated.                                       constraints on the agents. These are the agents’ permissions,
                                                      prohibitions, and obligations; we therefore call this model the
  The main goal of this paper is to show how agents may
                                                      deontic model (Figure 3). Note that for one scenario there is
answer these questions by using a dynamic model checker. In
                                                      one global interaction model and several local deontic mod-
our running example, the agent’s constraints used (or the trust
                                                      els. While agents need to share the interaction model in order
constraints) are those of Figure 1. The interaction protocol
                                                      to know the rules of the interaction they’re engaged in, each
veriﬁed is presented by the state-space graph of Figure 2.
                                                      agent will have its own local constraints in its deontic model.
  The interaction of Figure 2 is that of a Vickrey auction. The In what follows, we introduce the languages used in speci-
                     s
interaction starts at state 0 when the auctioneer A sends an fying these models.
invite to a set of bidders for bidding on item I with a reserve
price R. The interaction remains at state s0 until invites are 3.1 The Interaction Model
sent to all bidders. Then the bidders send their sealed bids
                                                      We choose the Lightweight Coordination Calculus (LCC)
back to the auctioneer. This is represented by state s1 of Fig-
                                                      [Robertson, 2004] for modelling the interaction’s state-space
ure 2. When all bids are collected, the interaction moves to
                                                      graph, since it is the only executable process calculus for MAS
the new state s2. The auctioneer informs the winner of the
                                                      that we are aware of1. Having an executable process calcu-
price V to be paid, moving the interaction to state s3. Finally,
                                                      lus for modelling the interaction’s state-space graph is very
the winning bidder sends its payment P, and the interaction is
                                                      useful for dynamically verifying the executable models of in-
completed at state s4.
                                                      teraction. Figure 4 presents the syntax of LCC.
  Before we present the veriﬁcation mechanism used in Sec-
tion 4, Section 3 introduces our system model, its architec- 1Note that we are aware of other coordination systems, but none
ture, and its speciﬁcation languages.                 of these are based directly on a process calculus

                                                IJCAI-07
                                                  1441                      auction        auction     trip planning   rules of the ≡ interaction
                      scenario      scenario      scenario       interaction     model

                                   engaged in

                                                                  agent   ≡     deontic
                                                                 constraints     model


                            Figure 3: The MAS model – a 2-layered architecture model


   Interaction := {Clause,...}                         a(auctioneer(I,R, Bs),A)::
      Clause  :=  Agent :: ADef                           ( invite(I, R) ⇒ a(bidder, B) ← Bs =[B|T ]then
       Agent  :=  a(Role, Id)                              a(auctioneer(I, R, T),A))
       ADef   :=  null ← C | Agent ← C | Message ← C |    or
                  ADef then ADef | ADef or ADef |         a(auctioneer2(Bs, []),A) ← Bs =[].
                  ADef par ADef
     Message  :=  M ⇒ Agent | M ⇐ Agent                a(auctioneer2(Bs, V s),A)::
          C   :=  Term | C ∧ C | C ∨ C                    append([B, V ],Vs,Vn) ← bid(B, V ) ⇐ a(bidder, B) then
        Role  :=  Term                                    ( a(auctioneer2(Bs, V n),A) ← not(all bid(Bs, V n))
          M   :=  Term                                     or
                                                           ( win(B1,V2) ⇒ a(bidder, B1)
null denotes an event which does not involve message passing. ← all bid(Bs, V n) and
Termis a structured term in Prolog syntax.                      highest(Vn,B1, ) and second highest(Vn, ,V2) then
Id is either a variable or a unique agent identiﬁer.        deliver(I, B1) ← payment(P ) ⇐ a(bidder, B1))).

                                                       a(bidder, B)::
                                                               (  ) ⇐ (        (   ) )
                        LCC                               invite I, R a auctioneer , , ,A then
                Figure 4:   syntax                        bid(B, V ) ⇒ a(auctioneer2( , ),A ← valuation(I, V ) then
                                                          win(Bi, V i) ⇐ a(auctioneer2( , ),A) then
                                                          payment(P ) ⇒ a(auctioneer2( , ),A) ← Bi = Bandpayment(P ).
  Agents, in LCC, are deﬁned by their roles and identiﬁers.
An interaction is deﬁned by a set of clauses. A clause gives
each agent role a deﬁnition that speciﬁes its acceptable be- Figure 5: LCC speciﬁcation for the interaction of Figure 2
haviour. An agent can either do nothing (usually used for
internal computations), take a different role, or send/receive
messages (M ⇒A, M ⇐A). Agent deﬁnitions are constructed          T rustRule := TrustSpecs [← Condition]
                                                                TrustSpecs :=  trust(interaction(IP),Sign) |
using the sequential (then), choice (or), parallel composition                     (        ) |
                   ←                                                           trust Agent, Sign
(par), and conditional ( ) operators. The conditional opera-                   trust(Agent, Sign, Action)
tor is used for linking constraints to message passing actions.     Agent  :=  a(Role, Id)
                                                                     Sign  :=  + |−
Example Revisited                                                   Action :=  MPA | N-MPA | TrustSpecs
                                                                      MPA  :=  Message ⇒ Agent |
Figure 5 presents the speciﬁcation of the state-space graph of                 Message ⇐ Agent
                                                                           :=          ∧         |
Figure 2 via LCC. The auctioneer A — knowing the item I,         Condition     Condition Condition
                                                                               Condition ∨ Condition |
the reserve price R, and the set of bidders Bs — recursively                   Temporal | Term
sends an invite to all bidders in set Bs. It then takes the role Role,N-MPA, Message := Term
of auctioneer2 to collect bids, send the winner a message, where, [X] denotes zero or one occurrence of X,
collect payment, and deliver the item won. On the other side, IP is an interaction protocol speciﬁed in LCC,
each bidder agent receives an invite from the auctioneer and Id is either a variable or a unique agent identiﬁer,
                                                      Temporal is a temporal property whose syntax is speciﬁed in [Osman et al., 2006],
sends its bid based on its valuation. The winner receives a and
win message and then sends its payment P.             Termis either a variable or a structured term in Prolog syntax.
3.2  Deontic Models
                                                             Figure 6: Syntax of our trust policy language
In this paper, we focus on the trust constraints imposed by
the agents. We propose a trust policy language for the speci-
ﬁcation of trust rules. The language is similar to other logic- trust(interaction(IP),Sign),whereIP is the LCC speciﬁ-
based policy languages which are built on deontic concepts, cation of the interaction protocol in question (e.g. the in-
such as ASL [Jajodia et al., 1997], RDL [Hayton et al., 1998], teraction protocol of Figure 5). Sign could take the values
and Rei [Kagal et al., 2003]. The syntax of our language is ‘+’and‘−’ to model trust and distrust, respectively. The
presented by Figure 6.                                agent’s trustworthiness is modelled by trust(Agent, Sign),
  The syntax states that trust rules might either hold where Agent represents the agent in question. Only if the
in general or under certain conditions: TrustSpecs [← agent is trustworthy, it can engage in an interaction. Trusting
Condition]. The interaction’s trustworthiness is modelled by or distrusting agents to perform speciﬁc actions is modelled

                                                IJCAI-07
                                                  1442by trust(Agent,Sign, Action). Actions could either be mes- trust(a(auctioneer,A), +) ←
                                                ⇒            rating count(a(auctioneer,A), Total) and Total > 50 and
sage passing actions (MPA) — such as sending (Message        rating average(a(auctioneer,A), Average) and Average > 0.7 and
Agent) or receiving (Message ⇐ Agent) messages — or          rating latest(a(auctioneer,A), 20, Latest) and Latest > 0.9.
non-message passing actions (N-MPA) — such as perform-                   (a) Trust rule TI 5
ing computations. We also allow actions to take the form of trust(a(interaction(InteractionProtocol)), +) ←
another trust rule (note the TrustSpecs in the Action deﬁni- Vl’<Cl and Cl<Vl and Vl<V and V<Vh and Vh<Ch and Ch<Vh’ and
                                                         [bid(Bidder,V), bid(Competitor,Ch)] <win(Competitor, )> tt and
tion). This supports the delegation of trust, since it permits the [bid(Bidder,Vh), bid(Competitor,Ch)] <win(Competitor, )> tt and
speciﬁcation of whether an agent’s trust itself is to be trusted [bid(Bidder,Vh’), bid(Competitor,Ch)] <win(Bidder,X)> tt and
or not.                                                  [bid(Bidder,V), bid(Competitor,Cl)] <win(Bidder,Y)> tt and
                                                         [bid(Bidder,Vl), bid(Competitor,Cl)] <win(Bidder,Z)> tt and
                                                         [bid(Bidder,Vl’), bid(Competitor,Cl)] <win(Competitor, )> tt and
Example Revisited                                        X≥Y and Z≥Y.
Trust issues TI 3, TI 4, and TI 5 of Figure 1 address trust at           (b) Trust rule TI 2
the agent level. In what follows, we present the speciﬁcation
of the more complex trust rule, TI 5, in our trust policy lan-  Figure 7: Speciﬁcation of trust rules
guage. The rule is presented by Figure 7(a). It speciﬁes that
agent A is trusted as an auctioneer only if it has a selling his-
tory of at least 50 items and an average rating above 70%,
going up to 90% for the latest 20 transactions. The mecha- case 3: agent bids Vh’
                                                           where Vh’ >Ch
nism presented here distrusts new entrants and focuses on the                  Ch
agent’s latest ratings rather than the overall one.
  Trust issues TI 1andTI 2 of Figure 1 address trust at the case 2: agent bids Vh
                                                           where Ch >Vh >V

interaction level. The conditions for trusting an interaction case 1: agent bids V higher  competing bid V case 4: agent bids V
protocol are speciﬁed via a temporal language. Since the
‘deadlock free’ property of TI 1 is a straightforward property                          case 5: agent bids Vl
                                                                                                 V>V  >C
to model via a temporal language, we show how the more                                       where   l  l
                                                                               Cl
challenging property of ‘enforcing truth-telling by the bid-
ders’ (TI 2) may be speciﬁed.                                                        lower  competing bid case 6: agent bids Vl’
                                                                                                 C >V
  To prove the protocol enforces truth-telling by the bidders,                               where l l’
we prove that, for the interaction protocol of Figure 5, the
bidders cannot do any better than bidding their true valua-
tion V: the maximum value they are willing to pay. Note that Figure 8: The bidding strategies: the 6 cases
we do not verify whether the agent will actually bid V or
not, but whether the interaction protocol provides an incen-
                                                                              3
tive for bidding a different value than V. For this, we study tively complex LCC structure is passed entirely as a parame-
the two cases: (1) if the competing agent bids a higher value ter to the trust rule. The interaction protocol is then said to be
Ch, and (2) if the competing agent bids a lower value Cl.In trusted if the condition — the collection of temporal proper-
Figure 8, the grey circle represents the bidder and its valua- ties — is satisﬁed. In this example, the condition veriﬁes the
tion V. The other two circles represent the two cases of the possible occurrence of transmitting the bid( , ) and win( , )
competing agent, which may bid either a higher or a lower messages in the LCC interaction protocol of Figure 5.
value: Ch and Cl, respectively. For each of these two cases, It is worth noting that the trust rule is restricted to the auc-
the bidder may either bid its true valuation, a value between tions domain, yet independent of the speciﬁc auction proto-
its true valuation and that of its competitor, or a value be- col it is veriﬁed upon. For example, the six cases of Fig-
yond that of the competitor (Figure 8). The trust rule of Fig- ure 8 are comprehensive, even for auction systems consist-
ure 7(b) studies all 6 cases, respectively. For each bid, the ing of more than two agents. This is because verifying the
winner and the price won at are computed through the tempo- utility of one agent should take into consideration only the
                                                 2
ral property [bid(Bidder,Bid1), bid(Competitor,Bid2)] <win(Winner,Price)> tt . competing agent’s bid — all other agents’ bids are irrelevant.
The bidder should, naturally, be expected to lose to its com- Furthermore, the veriﬁcation of such a trust rule will termi-
petitor in cases 1, 2, and 6. It should win in cases 3, 4, and nate with correct results, whether positive or negative, for any
5, where case 4 would be the only case where the bidder bids auction protocol that requires agents to place their bids be-
its true valuation and wins the item for the price Y. The trust fore a message is transmitted informing who the winner is.
rule requires that the bidder is not better off when winning It will probably fail when veriﬁed against more complex auc-
in cases 3 and 5, i.e. where the item is won for prices X and tion protocols, such as those selling multiple items and having
Z, respectively. This is expressed by the conditions X≥Y and several winners. However, the veriﬁcation will be success-
Z≥Y.
                                                         3For a comparison between the LCC process calculus and tra-
  The InteractionProtocol of the trust rule presented by Fig- ditional process calculi, such as Milner’s CCS [Milner, 1989] and
ure 7(b) is in fact the LCC protocol of Figure 5. This rela- Hoar’s CSP [Hoare, 1985], the interested reader may refer to [Os-
                                                      man et al., 2006]. From this comparison, we may assert that the
  2
   The temporal property [X,Y]<Z>tt speciﬁes that if messages X complexity of LCC is similar to that of traditional process calculi,
and Y are sent, then message Z will eventually be received. such as CCS and CSP.

                                                IJCAI-07
                                                  1443ful in the most common auctions, such as the English, Dutch, agents’ local trust constraints. Trust constraints based on tem-
sealed ﬁrst-price, and sealed second-price auctions. Allowing poral properties, such as those constraining the interaction
agents to automatically verify such properties (which are rel- (e.g. TI 2 of Figure 7(b)), are modelled in the property speci-
atively independent of the speciﬁc interaction protocol), aids ﬁcation section. Other trust rules constraining the agents (e.g.
the agents in making their protocol selection when faced with TI 5 of Figure 7(b)) are kept on the deontic level of the system
new and unexplored protocols.                         model. Figure 10 provides an overview of our trust verifying
                                                      model checker. The sample input data is that of the auction
4  The Dynamic Model Checker                          system scenario. The interaction model sample in Figure 10
                                                      is a copy of that of Figure 5. The deontic model sample, or
We believe it is solely the agents’ responsibility to answer the the trust constraints on agents, is a copy of Figure 7(a). The
question of how, when, and who to interact with. Ideally, in property speciﬁcation is the trust constraint on the interaction
a highly dynamic system, this should be done at run time by protocol (Figure 7(b)).
deciding which combination of interaction and deontic (trust)
models is currently suitable. But is this feasible?                 System model:
                                                         a(auctioneer(I,R,Bs),A) :: s0
  We choose model checking from amongst other veriﬁcation ( invite(I,R) ⇒ a(bidder,B) ← Bs=[B|T] then
                                                          ...                       s1
techniques because it provides a fully automatic veriﬁcation a(auctioneer2(Bs,Vs), A) ::
process which could be carried out by the agents during in- append([B,V], Vs, Vn) ← bid(V) ⇐ a(bidder,B) then s2
                                                        model ...
teraction time. We show how interaction time veriﬁcation is interaction a(bidder,B) :: s3
                                                          invite(I,R) ⇐ a(auctioneer( , , ),A) then
made possible with the use of a remarkably efﬁcient (see Fig- ...
ure 11) and lightweight model checker. The concerned agent trust(a(auctioneer,A), +) ←
                                                          rating count(a(auctioneer,A), Total) and Total > 50 and Model Result:

                                                        model ...
can then feed the model checker with the system model: the deontic ...                     Checking  true /
                                                                                                      false
combination of the global interaction model and agents’ lo-                                 Algorithm
cal trust rules. The model checker should then verify whether    Property specification:
                                                         trust(a(interaction(InteractionProtocol)),+) ←
the trust rules are consistent amongst themselves as well as Vl’<Cl and Cl<Vl and Vl<V and
                                                          V<Vh and Vh<Ch and Ch<Vh’ and

                                                       temporal           <        >
consistent with respect to the interaction model. It should be properties [bid(Bidder,V), bid(Competitor,Ch)] win(Competitor, ) tt and
                                                          ...
capable of detecting non-suitable (distrusted) agents and/or ...
interaction protocols.
                                                       Figure 10: The auction scenario: the model checker’s input
4.1  Model Checking: an Overview
The model checking problem can be deﬁned as follows:    The model checker should then verify that the interac-
Given a ﬁnite transition system S and a temporal formula tion model is trusted and that the agents are trusted to en-
φ, does S satisfy φ? The model checking process is divided gage in the given interaction. To verify this, the concerned
into three stages: modelling, speciﬁcation, and veriﬁcation. agent feeds the model checker with the appropriate interac-
The system to be veriﬁed must ﬁrst be modelled in the lan- tion model along with the trust rules that are split between
guage of the model checker S. The properties (φ)towhich the deontic model and the property speciﬁcation. The veriﬁ-
the system model is veriﬁed upon should be speciﬁed using cation process is explained in the following section.
the model checker’s temporal logic. Both the system model
                                                      The Veriﬁcation Process
and the properties speciﬁcation are fed to the model checker
for veriﬁcation. The model checker is, essentially, an algo- In this section, we present an overview of the model check-
rithm that decides whether a model S satisﬁes a formula φ. ing algorithm — the black box of Figure 10. We refer the
                                                                       [               ]
Figure 9 illustrates the model checking process.      interested reader to Osman et al., 2006 for the details of the
                                                      model checker and its operational semantics.
                                                        The veriﬁcation process is carried out as follows. The in-
             System model:                            teraction model, the deontic model, and the temporal property
                S                                     to be veriﬁed are fed to the model checker. Veriﬁcation starts
                             Model    Result:
                            Checking  true /          at the initial state s0 of the interaction model, and the model
                                      false
                            Algorithm                 checker tries to verify that the temporal property φ is satisﬁed
           Property specification:                        4
                φ                                     at s0 . If it succeeds, the veriﬁer terminates and the prop-
                                                      erty is said to be satisﬁed. Otherwise, the veriﬁer attempts to
                                                      make a transition(s) to the next state(s) in the state-space5.If
         Figure 9: The model checking process         the transition(s) violates any of the trust (deontic) rules, then
                                                      the veriﬁcation process terminates and the property is not sat-
                                                      isﬁed. Otherwise, the satisfaction of the property φ is veriﬁed
4.2  Model Checking: the Implementation               with respect to the new state(s), and the whole process is re-
                                                      peated all over again.
In traditional model checking, the system model represents
a state-space graph. The constraints on a given state-space 4Satisfaction is veriﬁed by applying the modal μ-calculus proof
are then speciﬁed through temporal properties in the prop- rules presented in [Osman et al., 2006].
erty speciﬁcation section. In our case, the system model is 5Transitions are made based on the LCC transition rules pre-
a combination of the shared interaction’s state-space and the sented in [Osman et al., 2006].

                                                IJCAI-07
                                                  1444