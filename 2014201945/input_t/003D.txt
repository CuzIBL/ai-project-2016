                                                            The HWIM speech understanding system 
  Shortfall and Density Scoring Strategies                  developed at BBN [Woods et al., 1976; Wolf 
       for Speech Understanding Control                     and Woods, 1977] has such capabilities. A 
                                                            control strategy for such a system must 
                    W. A. woods                             answer questions such as: 
          Bolt Beranek and Newman Inc. 
               Cambridge, Ma. 02138                            a) At which points in the utterance to 
                                                                   call the Lexical Retrieval component, 
                                                                   and when, 
                       Abstract 
    This note describes two methods of                         b) What number of words to ask for, 
assigning priority scores to partially 
developed hypotheses about a speech                            c) When to give subsequences of the 
utterance for determining which hypotheses                         results to the Linguistic component, 
to extend further. These methods                                   and 
guarantee the discovery of                 the best 
matching interpretation of the utterance,                     d) When to recall the Lexical Retrieval 
when used in an appropriate control                                component to continue enumerating 
framework. Although presented in the                               words at a given point. 
speech context, the algori thms are 
applicable to a general class of                            The goal of the control strategy is to 
optimization and heuristic search                           d iscoyer the best scor inc; sequence of 
problems. The density method is words that covers the entlre utterance and 
especially interesting since it is not an                   Ts acceptable_to "the LinguTstTc component. 
instance of the general A* al gorithm of                    We will consider here a particular class 
Hart, Nilsson, and Raphael, and appears to                  of control strategies which we refer to as 
be superior to it in the domains in which                   "island-dr iven". 
it is applicable. Proofs of the 
guaranteed discovery of the best                                2* Island-Driven Strateg ies 
interpretation and some empir ical 
comparisons of the methods are g iven.                          In an island-dr iven control strategy, 
                                                            partial hypotheses about the possible 
    1. Introduction                                         identity of the utterance are formed 
                                                            around initial "seed         words somewhere in 
    This paper is concerned with control                    the utterance and are grown into larger 
strategies governing the formation and                      and larger "island            hypotheses by the 
refinement of partial hypotheses about the                  addition of words t o one or the other end 
identity of an utterance in a continuous                    of the island. Occa sionally, two islands 
speech understanding system. We assume a                    may "collide" by pro posing and discovering 
system that contains the following                          the same word in th e gap between them and 
components:                                                 may be combined i nto a single larger 
                                                            island. Each such island hypothesis is 
                                                            evaluated by the 
   o)  A Lexical ketrieva 1 component that                                                Lexical Retrieval 
       can find the k b est matching words                  component to determi ne its degree of match 
                                                            with the acoustic ev idence and checked for 
       starting or ending at any given po i n t             syntactic, semant 
       in the utterance for any number k,                                             ic, and pragmatic 
       and can be reca lied to continue                     consistency by the        Linguistic component. 
       enumerating word matches                      in     we will refer to a p artial hypothesis that 
      decreasing order of goodness at a                     has been so evalu ated and checked for 
      given Position. We assume that              this      consistency as a "th eory". The strategies 
      component is inter faced                       to     that we will c onsider operate by 
                                                            successively proces 
       appropriate signal processing,                                                 sing "events" on an 
       acoustic-phonetic         and phonological           event queue, where        events correspond to 
       analysis components as in (woods et                  suspended or dorma nt processes that may 
       al., 1976), and that it assiign             s a      result in the creati on of theories. 
       "quality" score to        each word match 
       reflecting the good ness of the match.                   The general algorithm             operates as 
                                                            follows: 
   b) A Linguistic component that, given 
       any sequence of words, can determine                     (1) An initial scan of the utterance 
       whether that sequence can be parsed                  is performed by the Lexical Retrieval 
       as a possible initial, final, or                     component to discover the n best matching 
       internal subsequence of a words anywhere in the utterance according 
       syntactically correct and to some criterion of "best" and for some 
       semantically and pragmatically value n. An initial seed event is created 
       appropriate utterance, and can                       for each such word and placed on the event 
       propose compatible classes of words                  queue. In addition, one or more 
       at each end of such a sequence.                      continuation events, which can be 
                                         Natural Lanptia pe-2: Woods 
                                                         13 processed to continue the enumeration of                       3 • I£*£ §J2°_Lt££iI £c°_li!21 Method 
successively lower scoring words, are 
created and placed on the queue. Each                             3.a) Assumptions 
seed event is assigned a priority score 
 (derived from the guality score-" that the                    The shortfall method assumes that the 
Lexical Retrieval component gave it in one                 quality scores assigned to word matches by 
of several ways to be described shortly),                  the Lexical Matching component are 
and each continuation event is assigned a                  additive, so that theories are 
priority score that can be guaranteed to                   appropriately assigned scores that are the 
bound the priority score of any word that                  sums of the scores of the word matches 
can be generated by that event (e.g.,                      contained in them. It also assumes that 
derived from the score of the last word                    word matches have associated beginning and 
enumerated prior to the continuation).                     ending positions that correspond to 
The events are ordered on the event queue                  boundary positions in the input utterance. 
by their priority scores and are processed                  In the HWIM system, the quality scores are 
in order of priority.                                      logarithms of estimates of the relative 
                                                           probabilities of the correctness of a 
     (2) The highest priority event is                     theory given the acoustic evidence. 
selected for processing, which consists of 
 (i) creating the corresponding theory (a                         3.b) The Basic Shortfall 
one-word theory in the case of a seed                                  ScojLiDJi. ProcecTure 
event), (ii) calling the Linguistic 
component to check the consistency of the                      Let t(i) be the time in milliseconds of 
theory and to make predictions for words                   the i-th boundary in the utterance; nsegs, 
and/or word classes that can occur                         the number of segments in the utterance; 
adjacent to it, (iii) calling the Lexical                  and seg(i) be the region of the input 
Retrieval component to enumerate the k                     utterance from t(i-l) to t(i) for i from 1 
best matching words satisfying the to nsegs. 
predictions at each end of the theory, and 
 (iv) generating a "word" event for each                       For a word match from position i to j 
such word found. A word event is an event                  with score q, we will allocate in some 
that will add one word to a theory to                      systematic way the total word score q to 
create a larger theory. Continuation the segments seg(i-H) ... seg(j) covered 
events are also created that will continue                 by the word match. For this discussion, 
the enumeration of successively lower let us allocate it proportional to the 
scoring words adjacent to the theory. If                   durations of the segments. 
island-collision is permitted as an 
operation, then each word event generated                      For a given utterance, we will 
is checked against an island table to see                  determine for each segment seg(i) the 
if the same word (at the same position in                  maximum score max(i) that can be allocated 
the input) has been proposed and found in                  to that segment by any word match that 
the other direction by some theory, and if                 covers the segment. The score for any 
so, an "island-collision" event is created                 word match from i to j will hence be 
that will combine the new word and the two                 bounded by the sum max(i+l)+ ...             +max(j), 
theories on either side of it. Both word                   and the maximum score for any complete 
and island-collision events are assigned                   theory will be bounded by T             the sum from 
priority scores derived from the quality                   1 to nsegs of max(i). 
score of the new word and the scores of 
the theories to which it is being added                        Every p artial theory will consist of a 
and are inserted into the event queue                      contiguous      sequence of word matches 
according to their priorities.                             spanning a region from some boundary i to 
                                                           some bounda ry j. Each such theory will 
    (3) Continue selecting the top carry with it two scores m and q, where m 
priority event from the event queue (step                   is the sum of the max(i) for the segments 
2) until a theory is discovered that spans                 covered by the sequence and q is the sum 
the entire utterance and is syntactically,                 of the word scores of the theory. We will 
semantically, and pragmatically acceptable                 assign each theory a priority score p * T 
as a complete sentence.                                    - m + q, which can be thought of as the 
                                                           maximum to tal score T for any theory 
    The main topic in this paper is the                    minus the shortfal1 from this ideal to 
assignment of priority scores to the which one i s committed by choosing this 
events in the above algorithm in order to                  particular      sequence of words (i.e., p * 
guarantee that the first complete theory                   T-(m-q)).       Alternatively, it can be 
found will be the best scoring one that                     thought of as the estimated best possible 
can be found. Using the quality scores                      future scor e consisting of the score q 
assigned by the Lexical Retrieval which has already been achieved for the 
component directly as priority scores does                  region cove red plus the best potential 
not ordinarily provide such a guarantee.                    score T-m for the region not yet covered 
                                        Natural Lanp;uap:e-2: Woods 
                                                        19 (i.e., p = qMT-m) ) . Because T-m is an                    continuation events for finding lower 
upper bound on the possible score that can                 scoring seeds or lower scoring words to 
be achieved on the region not covered, the                 add to the ends of islands) will already 
priority scores p have the characteristic                  have fallen low enough in its partial 
that they are non-increasing as theories                   score (q score) that no possible match 
grow.                                                      sequence in the remaining region of the 
                                                           utterance can bring its total score above 
                                                           that of the spanning theory. Also, the 
                                                           presence of the continuation events in the 
    In the shortfall scoring strategy, the                 queue makes the search process complete in 
priority scores of the individual seed                     the sense that any word in the vocabulary 
events are simply the shortfall scores of                  would be enumerated if the process were 
the words. A priority score for a continued long enough. Thus there is no 
continuation event that will be an upper                   possible word sequence across the 
bound on the priority score of any words                   utterance that would not be considered by 
that might result from the continuation                    this search algorithm if it were run 
can be computed as follows: Since the                      sufficiently far. Hence, any complete 
Lexical Retrieval component enumerates                     theory of the utterance will have a 
words in decreasing order of score, the                    shortfall (m-q) at least as great as that 
quality score of any word that results                     of the first complete theory discovered. 
from the continuation will be no greater                   Since all spanning theories have the same 
than that of the last word enumerated so                   maxscore m = T, it follows that the first 
far. Moreover, we can derive from the                      spanning theory also has the maximum 
lexicon 3 lower bound on the length of a                   possible quality score (q) of any spanning 
word and from this we can deduce the                       theory. 
shortest region of the utterance that such 
a word could cover, and hence the smallest                        3.e) Notes 
possible m score that such a word could 
have. From these two numbers, we can                           Note that the process can be continued 
bound the priority score (T-m+q) of any                    to obtain the second best complete theory, 
future word and use that as the priority                   and so on.              Note also that the 
score of the continuation event. (This                     admissibility        holds for this method 
bound is somewhat conservative, and in                     whether the process is left-to-right 
actual practice, it should be possible to                   (i.e., seeds only at the left end of the 
derive a much tighter bound, but this                      utterance) or middle-out (seeds anywhere 
argument is sufficient to guarantee that                   in the utterance), and that it does not 
such a bound can be computed.)                             require the island collision feature. 

    As new theories arise from processing                      The shortfall method works with almost 
events that link an existing theory with a                 any type of grammar. it makes no 
new word match, the m and q scores of an                   assumptions that the grammar is 
event and the new theory that it will                      finite-state, as do most Markovian 
create are simply the respective sums of                   strategies. In the middle-out modes, it 
the m and q scores of the old theory and                   does require the linguistic consultant to 
the word being added to it. Thus, after                    have a parser (such as the bidirectional 
assigning an m score to a word match by                    ATN parser in the current HwlM system) 
summing the max numbers for the segments                   that can take an arbitrary island fragment 
that it covers, the m score of any new                     in the middle of an utterance and judge 
theory that includes it can be computed by                 whether it is a possible subsequence of an 
a single addition.                                         acceptable sentence. In practice, it also 
                                                           helps immensely if the parser can also use 
       3.d)   Admissibi 1 i ty of _the Method              the grammar to predict the acceptable 
                                                           words and classes adjacent to the island, 
    CI aim:                                                and if the Lexical Retrieval component can 
                                                           use such predictions to constrain its 
    The first complete spanning theory                     search (as in HWIM), but this is not 
found by the shortfall scoring method will                 essential to the formal admissibility of 
be one of the best scoring complete the algorithm. 
theories (there could be more than one) 
that can be found by any strategy (i.e.,                          3 • f) Avoiding Duplicate Theories 
the algorithm is "admissible" in the 
conventional terminology). 
                                                               Note that in the middle-out, 
    Proof ;                                                island-driven strategies there are many 
                                                           different ways of eventually arriving at 
    At the time the first complete spanning                the same theory. For example, if we have 
theory has been processed, every other                     an island w with a possible word x on the 
event on the event queue (including                        left and a possible word y on the right, 
                                        Natural Lanrnnpp-2: Woods 
                                                        20 then we can first form the theory (xw) and                           with some one of the w- as a seed, and 
then (xwy) or we can form the theory (wy)                            then successively adding words either to 
and then derive (xwy) from that. Which of                            the right or the left end. (Proof 
these two routes is taken will depend on                             either w-, or w^ was chosen last, hence 
the scores of the words, but it is quite                             there are two ways to derive a string of 
possible (in fact, likely) that in the                               length k for every possible derivation of 
course of working toward a complete theory                           a string of length k-1. There is one 
a strategy will arrive at the same possible way -- i.e., as a seed -- to 
subtheory several different times by                                 derive a string of length 1.) Of all 
alternate routes.                                                    these derivation trees, the first one that 
                                                                     will be found is the one that uses the w. 
     If we do not include checks for the                             with the smallest shortfall as a seed, and 
duplication of theories, then we would                               at subsequent steps adds the better (in 
often get two copies of the same theory.                             terms of shortfall) of the two words at 
These would forever duplicate the same                               either end (assume for the moment that no 
predictions and theory formations, giving                             two of the words have exactly the same 
rise to a rapid exponential explosion of                              score). Hence, any derivation that 
the search process. If we include a test                             attempts to add a word to one end of an 
each time a theory is formed to determine                             island when that word has a smaller 
whether that theory has been formed shortfall than the word at the other end 
previously, tnen we can avoid this                                   of the island will be duplicating a theory 
exponential process. In fact, if each                                 that has already been derived (or at least 
time we are about to put an event on the                              already has an event for it on the event 
event queue we check the event to see if                             queue). In the case of two competing 
the set of word matches that it uses is                               seeds with the same shortfall or words at 
the same as that of some other event, then                           each end of an island that have the same 
we can terminate this duplication before                              shortfall, we have arbitrarily picked the 
making the entry on the queue and                                     leftmost as the preferred one, which we 
consuming the queue space (and certainly                              will permit the algorithm to follow fully, 
before calling the Linguistic component to                            and we block the derivation of duplicates 
check it out and make further                                         from the other one. Thus, if we have a 
pred i ctions) .                                                     word being added to the left end of a 
                                                                      theory that has the same shortfall as the 
     The check for duplication among all the                         word at the right end, then this event is 
events that have been created can amount-                             redundant, since the preferred order will 
to a considerable amount of testing if                               generate an equivalent event that adds the 
done in a brute force exhaustive test,                                left end word first. 
although it can be considerably reduced by 
indexing events by their beginning and end                                Thus, a very simple check between the 
points or other tricks. However, if one                               score of the word being added to a theory 
can rely on the events being Generated in                             and the score of the word at the other end 
the order determined b y the basic                                   of the theory will suffice to eliminate 
shortfall strategy, then the following                                the formation of redundant events. 
simple check based only on the word 
matches at each end of an event can be                                       3.g) Fuzzy Wor_d Matches 
used to determine whether an event is 
redundant (i.e., will produce the same                                    The above discussion does not 
theory as some event already generated):                             explicitly mention the problem of finding 
                                                                      the same word in essentially the same 
        If the new word is at the left end                           place but with slightly different end 
   and has the same or greater shortfall                             points and different scores. We have 
   as the word at the right end, then                                observed this kind of output from the 
   this event is redundant.                                           Lexical Retrieval component of HWIM and 
                                                                      indeed find it desirable to know the 
        If the new word is at. the right                             degree of variation possible in the end 
   end and has strictly greater                                      points of a word match and the appropriate 
   shortfall than the word at the left                               degradation in score for each. However, 
   end, then this event is redundant.                                 it is wasteful to give several different 
                                                                     events to the Linguistic component, all of 
The argument for the validity of this test                           which are adding word matches to a given 
is as follows:                                                        theory that differ only in their endpoints 
                                                                      and scores. For this reason, we have 
     In the search space we are considering,                          introduced a structure that groups 
it is possible, without a check for together multiple equivalent word matches 
duplication, to derive a given theory with                            into a single entity called a .fuzzy word 
                                                                     match (or "fuzzy" for short), which Ts 
words w^,w2#...rWu in 2k~i different ways 
      one corresponding to each of the given the score of its best member. A 
possible binary derivation trees starting                            theory containing fuzzy word matches 

                                               Na tural 1  Lan£ua*e     •2: Woods 
                                                                  21  actually represents a class of leading to that node (in fact all such 
 grammatically equivalent theories and                      paths have the same score in our case) . 
 carries the score of the best one.                         The simple argument given previously 
                                                            suffices to show the admissibility of the 
    When an event is created to add a word                  shortfall method, whereas the general A* 
match to a theory containing a fuzzy word                   algorithm is more complicated. 
 match at that end, the score of the event 
 must be computed using a "rectified" score                     Measuring the shortfall from any 
 that takes into account the best member of                 profile that is a per word upper bound of 
 the fuzzy that is compatible with the new                  quality score would be sufficient to 
 word (i.e., has boundaries that hook up to                 assure the theoretical admissibility of 
 the new word and satisfies appropriate                     the method. However, the tightness of the 
 phonological word boundary constraints).                   upper bound affects the number of events 
 in general, when several fuzzies are tried and partial theories created in the 
 adjacent, the best compatible sequence of                  search for a successful interpretation 
 members must be chosen, and when the new                   (i.e., the "breadth" of the search). By 
 word match is itself a fuzzy, the best                     assigning the upper bound as a 
 combination of one of its members with a                   segment-by-segment profile determined by 
 corresponding rectified score for the                      allocated shares of actual word match 
 theory must be taken. The event is thus                    scores, a fairly tight upper bound is 
 given the score of the best of the                         achieved. A further effect of scoring the 
 grammatically equivalent, non-fuzzy events                 shortfall from such a maxscore profile is 
 for which it stands.                                       that the score differences in different 
                                                            parts of the utterance are effectively 
     It word matches returned by the Lexical                leveled out, so that events in a region of 
 Retrieval component are grouped into fuzzy                 the utterance where there are not very 
 matches whenever possible, and word events                 good scoring words can hold their own 
 are given appropriately rectified scores,                  against alternative interpretations in 
 then the above admissibility result still                  regions where there are high scoring 
 holds (i.e., the first complete theory                     words. This promotes the refocusing of 
 processed will be the best). The only                      attention from a region where there may 
 difference (aside from the elimination of                  happen to be high scoring accidental word 
 separate processing for grammatically                      matches to events whose word match quality 
 equivalent theories) will be that certain                  may not be as great, but are the best 
 word events (i.e., those using a matches in their regions. Thus, an 
 less-than-best path through the existing                   apparently satisfactory and intuitively 
 theory) will be formed earlier than they                   reasonable strategy for focusing attention 
 otherwise would have. However, these emerges from the same strategy that 
 events will still be placed on the queue                   guarantees to get the best scoring theory 
 with the correct score so that they will                   first. 
 reach the top and be processed in exactly 
 the same order as they would in the                            When using the shortfa 11 method for 
 strategy without fuzzies.                                  understanding an utte ranee, the 
                                                            overwhelming tendency is for an event 
        3.h) Discussion                                     adding a new word to an isla nd to pick up 
                                                            additional shortfall and fall some 
     The shortfall scoring method is similar                distance down in the queue,           The result is 
 in some respects to the well-known branch                  that other events are proces sed before any 
 and bound, technique, except for the additional work is done on that island . 
 characteristic in the middle-out version                   (Occasionally, the new wo rd is the best 
 that the same partial interpretation may                   word in its region and buys no additional 
 be reached by many different paths, and                    shortfall, but this is a rarity.) The 
 the fact that the space of possible distance that this new even t falls down 
 solutions is determined by a grammar. It                   the queue is determined by the amount of 
 can also be modeled as an example of the                   additional shortfall that it has just 
 A* algorithm of Hart, Nilsson, and Raphael                 picked up and the shortfalls of the events 
  [1968] for finding the shortest path                      that are competing with it on the queue. 
 through a graph, where, in this case, the                  This distance directly affec ts the degree 
 nodes in the graph are partial of "depth-first" vs.                                            breadth-first" 
 interpretations of the utterance, and the                  processing done by the algor ithm. If the 
 connections in the graph correspond to the                 new word scores well, the ev ent falls only 
 seed and word events. Consequently, it                     slightly, and few, if a ny, alternate 
 shares with that algorithm a certain kind                  events are processed before it. In this 
 of optimality that Hart, Nilsson, and                      case the algorithm is re latively depth 
 Raphael prove. It is simpler than the                      first. If the new word scor es badly, the 
 general A* algorithm, however, in that we                  event falls further down t he queue, many 
 are looking for the best scoring node, and                 more alternative events have priority over 
 we are not interested in scores of paths                   it and the algorithm is more breadth 
                                                            first. 
                                         natural Langua pe-2: Woorfs 
                                                        22 