                        Relevance Estimation and Value Calibration
                            of Evolutionary Algorithm Parameters

                                    Volker Nannen and A.E. Eiben
                            Department of Computer Science, Vrije Universiteit Amsterdam
                                           {volker, gusz}@cs.vu.nl

                    Abstract                          chromosome length, or by statistical hypothesis testing, e.g.,
                                                      comparing EA performance for a number of different setups
    The main objective of this paper is to present and [Eiben et al., 1999]. This is typically a laborious, ad hoc pro-
    evaluate a method that helps to calibrate the param- cedure involving much handwork and heuristic choices. So
    eters of an evolutionary algorithm in a systematic far, no procedure has yet been established that can do this
    and semi-automated manner. The method for Rel-    systematically, exploring the full combinatorial range of pos-
    evance Estimation and Value Calibration of EA pa- sible parameter settings. Another problem is that studies on
    rameters (REVAC) is empirically evaluated in two  design aspects like conﬁdence intervals for good parameter
    different ways. First, we use abstract test cases values and a sensitivity analysis for parameter robustness are
    reﬂecting the typical properties of EA parameter  scarce. In this paper we discuss a design method that cali-
    spaces. Here we observe that REVAC is able to     brates the parameters of an EA in a robust way, regardless of
    approximate the exact (hand-coded) relevance of   the distribution of the results. For each parameter the method
    parameters and it works robustly with measure-    produces a distribution over the parameter’s range that give
    ment noise that is highly variable and not normally high probability to values leading to good EA performance.
    distributed. Second, we use REVAC for calibrat-   In this scheme, a distribution with a narrow peak indicates a
    ing GAs for a number of common objective func-    highly relevant parameter (whose values largely inﬂuence EA
    tions. Here we obtain a common sense validation,  performance), while a broad plateau belongs to a moderately
                            p
    REVAC ﬁnds mutation rate m much more sensi-       relevant parameter (whose values do not matter too much).
    tive than crossover rate pc and it recommends intu-
                      p                                 Related work includes meta-GAs as an early attempt to au-
    itively sound values: m between 0.01 and 0.1, and                     [                ]     [
     . ≤ p  ≤  .                                      tomate GA calibration Greffenstette, 1986 ,and Eiben et
    0 6   c   1 0.                                    al., 1999] that established parameter control in EAs as one
                                                      of the big challenges in EC. Czarn et al. [2004] discuss cur-
1  Introduction                                       rent problems in EA design and use polynomial models of
                                                      a response curve to estimate conﬁdence interval for parame-
Appropriate calibration of evolutionary algorithm (EA) pa- ter values. Franc¸ois and Lavergne [2001] estimate response
rameters is essential to good EA performance. Nevertheless, curves for EAs across multiple test cases to measure general-
current practice in EA calibration is based on ill-justiﬁed con- izability. The groundwork of statistical experimental design
ventions and ad hoc methods. Without exaggeration, one was laid by R.A. Fisher in the 1920s and 1930s. Response
could state that one of the canonical design problems in evo- surfaces methods that exploit sequential sampling were intro-
lutionary computing (EC)is: How to choose operators and duced in Box and Wilson [1951]. A paradigm shift that em-
parameters for an evolutionary algorithm to ensure good per- phasizes parameter robustness is due to G. Taguchi [1980].
formance? The related questions can concern relevance of A survey of optimization by building probabilistic models is
operators and parameters as well as the values of (relevant) given in [Pelikan et al., 2002].
parameters. For instance, the question whether crossover is a
relevant operator is still open, or rather, the answer depends
on the application at hand [Eiben and Smith, 2003]. Rele- 2 The REVAC Method
vance of parameters is also an issue, e.g., tournament size The REVAC method is based on information theory to mea-
can be a highly relevant parameter whose value must be cho- sure parameter relevance. Instead of estimating the perfor-
sen well for good performance, while mutation rate could be mance of an EA for different parameter values or ranges
less relevant in the sense that its values do not affect EA per- of values2, the method estimates the expected performance
formance too much.1                                   when parameter values are chosen from a probability density
  In contemporary practice, EA parameters are set by com- distribution C with maximized Shannon entropy. This maxi-
mon “wisdom”, e.g., mutation size should be 1 divided by the
                                                         2In the jargon of statistical experimental design a parameter is
  1These examples are purely hypothetical.            called factor. A range of parameter values is called level.

                                                IJCAI-07
                                                   975mized Shannon entropy is a measure of parameter relevance. Looking at the table from the horizontal perspective we can
In information theoretical terms we measure how much infor- identify two basic steps:
mation is needed to reach a certain level of performance, and 1. Evaluating parameter vectors: Given a parameter vec-
how this information is distributed over the different parame- tor x we can evaluate it: the utility of x is the perfor-
ters. In these terms the objectives of the REVAC method can mance of the EA executed with these parameter values.
be formulated as follows:
                                                        2. Generating parameter vectors: Given a set of parame-
  •                          C
    the entropy of the distribution is as high as possible for ter vectors with known utility we can generate new ones
    a given performance                                   that have higher expected utility.
  •
    the expected performance of the EA in question is as Step 1 is straightforward, let us only note that we call the
    high as possible                                  performance that an EA achieves on a problem using param-
                                                           x                   r               r   f x
  Technically, the REVAC method is an Estimation of Distri- eters the response. Response is thus a function = ( );
bution Algorithm (EDA) [Pelikan et al., 2002] that is specif- the surface of this function is called a response surface.Asfor
ically designed to measure maximized entropy in the contin- step 2, we use a method that is evolutionary itself, (but should
uous domain. Given an EA with k (strategy) parameters the not be confused with the EA we are calibrating). We work
                                              C x    with a population of m parameter vectors. A new population
REVAC method iteratively reﬁnes a joint distribution ( )                 n<m
over possible parameter vectors x = {x1,...,xk}.Begin- is created by selecting parent vectors from the current
ning with a uniform distribution C0 over the initial parameter population, recombining and mutating the selected parents to
space X , the REVAC method gives a higher and higher prob- obtain a child vector, replacing one vector of the population.
                X                                       We use a deterministic choice for parent selection as well
ability to regions of that increase the expected performance                         n
of the associated EA. This is to increase the EA performance. as for survivor selection. The best vectors of the popu-
On the other hand, the REVAC method maximizes entropy lation are selected to become the parents of the new child
by smoothing the distribution C. For a good understanding of vector, which always replaces the oldest vector in the popu-
how REVAC works it is helpful to distinguish two views on a lation. Only one vector is replaced in every generation. Re-
                                                      combination is performed by a multi-parent crossover opera-
set of parameter vectors as shown in Table 1. Taking a hori-                                    n
zontal view on the table, a row is a parameter vector and we tor, uniform scanning, that creates one child from parents,
                                                      cf. [Eiben and Smith, 2003]. The mutation operator—applied
can see the table as m of such vectors X = {x1,...,x m}.
                                         i       m    to the offspring created by recombination—is rather compli-
Taking the vertical view on the columns, column shows                                             i
values for parameter i from its domain. These values natu- cated, it works independently on each parameter in two
rally deﬁne3 a marginal density function D(x) over the do- steps. First, a mutation interval is calculated, then a random
                i                   k                 value is chosen from this interval. To deﬁne the mutation in-
main of parameter , hence we can see the columns of the                      xi              xi ,...,xi
table as k marginal density functions X = {D1,...,Dk}. terval for mutating a given j all other values 1 n for
                                                      this parameter in the selected parents are also taken into ac-
               D1    ···   Di   ···  Dk               count. After sorting them in increasing order, the begin point
                                                      of the interval can be speciﬁed as the h-th lower neighbor of
                 1          i         k                i
          x1  {x1   ···   x1   ···  x1 }             xj, while the end point of the interval is the h-th upper neigh-
           .         .                                      xi
           .          ..                              bor of j. The new value is drawn from this interval with a
          x   {x1   ···   xi   ···  xk}              uniform distribution.
           j     j          j         j                 From the vertical perspective we consider each iteration as
           .
           .                    ..                    constructing k new marginal density functions from the old
           .                     .                                1      k
                 1          i         k               set Xt = {Dt ,...,Dt }. Roughly speaking, new distribu-
         xm   {xm   ···  xm    ···  xm}
                                                      tions are built on estimates of the response surface that were
     Table 1: A table X of m vectors of k parameters  sampled with previous density functions, each iteration giv-
                                                      ing a higher probability to regions of the response surface
                                                      with higher response levels. Each density functions is con-
  Roughly speaking, REVAC works by iteratively improving structed from n uniform distributions over overlapping inter-
an initial table X0 that was drawn from the uniform distribu- vals. In this context, the rationale behind the complicated
tion over X . Creating a new table Xt+1 from a given Xt can mutation operator is that it heavily smoothes the density func-
be described from both the horizontal and the vertical per- tions. Like all evolutionary algorithms, REVAC is susceptible
spective.                                             for converging on a local maximum. By consistently smooth-
                                                      ing the distribution functions we force it to converge on a
  3                      ,
   Scaled to the unit interval [0 1] we deﬁne the density over the maximum that lies on a broad hill, yielding robust solutions
m+1 intervals between anyR two neighbors (including limits) xa,xb
         (m+1)      1                                 with broad conﬁdence intervals. But smoothing does more:
as D(x)=       with  D(x)=1and differential entropy
         |xa−xb|    0                                 it allows REVAC to operate under very noise conditions, it
                      Z
                        1                             allows REVAC to readjust and relax marginal distributions
             H(D)=−      D(x)logD(x)                  when parameters are interactive and the response surface has
                       0                              curved ridges, and it maximizes the entropy of the constructed
with H(D)=0for the uniform distribution over [0, 1]. The sharper distribution. Smoothing is achieved by taking not the nearest
                                                                                    i
the peaks, the lower the entropy.                     neighbor but the h-th neighbors of xj when deﬁning the mu-

                                                IJCAI-07
                                                   976tation interval4. Choosing a good value for h is an important is representative for EA parameter spaces. Hereby we ab-
aspect when using the REVAC method. A large h value can stract from the application and algorithm layers and reduce
slow down convergence to the point of stagnation. A small h run times enormously. Either way, there is a generalization
value can produce unreliable results. We prefer h ≈ n/10. step involved.
  Because the REVAC method is implemented as a sequence In this paper we perform both types of experiments, but
of distributions with slowly decreasing Shannon entropy, we put the emphasis on the second option. To deﬁne abstract
can use the Shannon entropy of these distributions to estimate response surfaces resembling the response surface of a typical
the minimum amount of information needed to reach a target EA we identify ﬁve essential properties:
performance level. We can also measure how this information 1. Low dimensionality: The number of parameters to cali-
is distributed over the parameters, resulting in a straightfor- brate is in the order of magnitude of 10.
ward measure for parameter relevance. This measure can be
used in several ways. First, it can be used to choose between 2. Non-linearity (epistasis, cross-coupling): Parameters in-
different operators [Nannen and Eiben, 2006]. An operator teract in non-linear ways, implying that the response
that needs little information to be tuned is more fault tolerant curves are non-separable, values for one parameter de-
in the implementation, easier to calibrate and robuster against pend on the values of other parameters.
changes to the problem deﬁnition. Second, it can be used to 3. Smoothness: Small changes in parameter values lead to
identify the critical parts of an EA. For this we calculate rele- small changes in EA performance.
vance as the normalized entropy, i.e., the fraction of total in-
                                                        4. Low multi-modality (moderate ruggedness): The re-
formation invested in the particular parameter. When an EA
                                                          sponse surface has one or few local optima, i.e., few re-
needs to be adapted from one problem to another, relevant
                                                          gions of the parameter space have high EA performance.
parameters need the most attention. With this knowledge,
the practitioner can concentrate on the critical components 5. Noise: Depending on the application, the performance
straight away. Third, it can be used to deﬁne conﬁdence inter- of a GA can be highly variable and can follow a distri-
vals for parameter choices. Given a distribution that peaks out bution that is far from the normal distribution.
in a region of high probability (except for the early stage of In section 4 we present experiments on abstract response sur-
the algorithms the marginal distributions have only one peak),
            th         th                             faces having these ﬁve properties. Thereafter, in section 5
we give the 25 and the 75 percentile of the distribution as results obtained with concrete objective functions are given.
a conﬁdence interval for the parameter. That is, every value In all cases REVAC is used with a population of m = 100 pa-
from this range leads to a high expected performance, under rameter vectors, from which the best n = 50 are selected for
the condition that the other parameters are also chosen from being a parent. We smooth by extending the mutation interval
their respective conﬁdence interval.                  over the h = 5 upper and lower neighbors. In all experiments,
  Further documentation, a Matlab implementation and  REVAC is allowed to perform 1000 evaluations. For a test
graphical demonstrations are available on the web sites with a concrete objective function f this means 1000 runs of
                                  ∼
of the authors: http://www.few.vu.nl/ volker/revac and the EA on f (evaluating 1000 different parameter vectors).
http:/www.few.vu.nl/∼gusz
                                                      4   Results on abstract EA response surfaces
3  Empirical Assessment of REVAC
                                                      We present three experiments: two on the accuracy of the
For an elaboration on how to evaluate the REVAC method
                                                      relevance estimation (without noise) and one on the resistance
method we can distinguish 3 layers in using an EA:
                                                      of the method to noise. We use k =10parameters that can
Application layer The problem(s) to solve.            take values from the range [0, 1].
Algorithm layer The EA with its parameters operating on Experiment 1: hierarchical dependency. In this exper-
    objects from the application layer (candidate solutions iment we pre-deﬁne and hard-code the dependency between
    of the problem to solve).                         parameters. The response r = f(x), showing the utility of
                                                      x, is calculated as the sum over the responses per parameter.
Design layer The REVAC method operating on objects from                         1            1
    the algorithm layer (parameters of the EA to calibrate). For the ﬁrst parameter value x the response r is equal to 1
                                                      minus the distance to a target value, randomly chosen at the
  A real in vivo assessment requires that we select a prob-
                                                      start of the experiment. The response of each consecutive pa-
lem, or a set of problems, and execute real runs of an EA on         i    i−1       i   i−1
                                                      rameter value is r = r (1 −|x  − x   |) ∈ [0, 1].The
this problem(s) for each evaluation of given parameter vec-
                                                      response of parameter i is higher if its value is closer to that
tors. This can lead to excessive running times for REVAC
                                                      of parameter i − 1. But because it is multiplied by the re-
and would deliver information on how REVAC works on the
                                                      sponse of that parameter, we have hierarchical dependencies.
given problem (s). As a second stage, we would need to make
                                                      The better the ﬁrst parameter is calibrated, the more the cali-
a generalization step to claim something about how REVAC
                                                      bration of the second parameter can contribute, and so forth.
works in general. Alternatively, we can make the general-
                                                      Knowledge of such a hierarchy of dependency and the associ-
ization step ﬁrst and create an abstract response surface that
                                                      ated hierarchy in relevance is very useful for the practitioner,
  4At the edges of the parameter ranges are no neighbors. We solve and we are interested if the REVAC method can reveal it.
this problem by mirroring neighbors and chosen values at the limits, Figures 1 and 2 show the results for one run of REVAC
similar to what is done in Fourier transformations.   (1000 evaluations). The main quality indicator for REVAC is

                                                IJCAI-07
                                                   977         relevance per parameter             response / performance            entropy of parameter 1, 4, 7
   0.3                              1                                  0                              
  0.25

   0.2
  0.15                             0.5                                 -5
   0.1                                                                          1
                                                                                4
  0.05                                                                          7
   0                                0                                 -10  
      1 2 3 4  5 6 7 8 9 10            200    400   600   800   1000       200   400   600    800  1000
Figure 1: Utility and relevance of parameters. The left graph shows the relevance (normalized entropy) per parameter at the
end, after 1000 REVAC evaluations. The middle graph shows how the measured response (parameter utility as the abstract EA
performance) increases through the calibration process. The rightmost graph shows the development of entropy for parameters
1, 4, and 7. For both, the x-axis shows evaluations 101–1000 (the ﬁrst 100 concern the initial population).

          calibrating parameter 1            calibrating parameter 4            calibrating parameter 7
 1                                  1                                  1                              
                          75%                                75%                                 75%
                          50%                                50%                                 50%
                          25%                                25%                                 25%
0.5                                0.5                                0.5


 0                                  0                                  0  
    200    400   600   800   1000      200    400   600   800   1000       200   400   600    800  1000

Figure 2: Calibration of parameters illustrated. The y-axis shows the value for the 25th,50th and 75th percentile of the
distribution. The calibration effect is achieved by taking parameter values from the range between the 25th and 75th percentile.
Note that the length of this conﬁdence interval indicates parameter relevance: narrow/broad = highly/moderately relevant. Here
parameter 1 shows highly relevant, parameter 7 does not.

the leftmost histogram in Figure 1 that shows how the rele- seen, the REVAC method can identify the more relevant ones
vance estimates for consecutive parameters approximate the and also reproduce the correct order in relevance. However, it
predeﬁned linear relationship. The rightmost graph of Figure does not reproduce the fact that the most relevant parameter
1 and the three graphs of Figure 2 show various aspects of the is twice as relevant as the follow up. This can not be repaired
calibration process for parameters 1, 4, and 7.       by averaging the results of several runs of REVAC.
                                                        Experiment 3: measurement noise. In this experiment
  Experiment 2: predeﬁned relevance distribution. In this
                                                      we study how the reliability of a relevance estimation changes
experiment we control the response contribution of each pa-
                                                      with noise of increasing variance. To measure the quality
rameter directly to see whether the REVAC method can re-
                                                      of the estimate we use the mean squared error between a
veal arbitrary relationships in relevance. To this end we cre-
                                                      relevance estimate to the target distribution, which we plot
ate a response curve by placing 1 peak randomly in the 10-
                                                      against the variance of the noise.
dimensional unit space. Again, total response is a sum over
                                                        The abstract response surface we use here is the third one
individual responses, which is 1 minus the distance to this
                                                      (non-linear increase) from experiment 2, see Figure 3, right.
peak per parameter (i.e., Hamming distance). We weight each
                                                      Addition of noise turns the abstract response curve into a
distance with a predeﬁned target relevance. In this way, an
                                                      stochastic equation r = f(x)+η,whereη is an i.i.d. ran-
irrelevant parameter has no contribution to the response, no
                                                      dom value. The noise is drawn from a Pareto distribution
matter how close its value is to the peak. On the other hand,                  −γ
the higher the target relevance of a parameter, the more its     P (X>x)=cx       ,x>logγ    c
calibration contributes to the overall response.      with exponent γ =2.3. c is a normalization value and also
  Using three sets of weights we specify three predeﬁned rel- controls the variance σ2 of the noise. Such a distribution is
evance distributions. These are given together with the exper- also called a power law distribution and can be found in many
imental results in Figure 3, cf. black vs. white columns. The physical and social systems. It has frequent outliers, a slowly
shown outcomes are from single runs of REVAC (1000 evalu- convergent variance, and is generally incompatible with sta-
ations). The accuracy of results can be improved by averaging tistical methods that require a normal distribution.
over the results of several runs. As can be seen in Figure 3, The variance of i.i.d. noise can be reduced by averaging
the REVAC method can reproduce a predeﬁned relevance dis- over multiple evaluations. The REVAC method however does
tribution quite accurately. The relationship in the right graph not average over multiple evaluations. Rather, if allowed
of Figure 3 is the most typical situation when calibrating real more evaluations, it uses them to get a better cover of the sam-
EAs, also known as the sparcity of effects principle: rele- pling space. Noise effects are only treated during the smooth-
vance is concentrated on only a few parameters. As can be ing of the distributions.

                                                IJCAI-07
                                                   978       parameter 1 and 2 are irrelevant     linear increase in relevance     non-linear increase in relevance
 0.2                                0.2                                                                
                                              target                  0.6       target
0.15                               0.15       measured                          measured
                                                                      0.4
 0.1                                0.1

0.05                   target      0.05                               0.2
                       measured
  0                                  0                                 0  
     1  2  3 4  5  6 7  8 9 10           1 2  3 4  5  6 7  8 9  10         1  2 3  4  5 6  7  8 9  10
   Figure 3: Comparing the relevance estimation of the REVAC method (white) to the hard-coded target relevance (black).

                                                            2                                      2
       mean squared error with noise     single relevance estimate for σ =5 average relevance estimate (10 runs) for σ ≈ 5

  0.1                                0.6                                0.5

                                     0.5
 0.08                                                                   0.4

                                     0.4
 0.06                                                                   0.3
                                     0.3
 0.04                                                                   0.2
                                     0.2

 0.02                                                                   0.1
                                     0.1

  0                                   0                                  0
   0     1     2    3     4     5        1 2 3  4 5  6 7  8 9 10            1 2  3 4 5  6 7  8 9 10

Figure 4: Impact of noise. The left graph shows the mean squared error of the relevance estimate as a function of the variance
of the noise. The x-axis shows the increasing variance, from 0 to 5. (5 is very high for a function with a range between 0 and 1).
The y-axis shows the results of 1000 different runs of the REVAC method over these noise levels. (The expected mean squared
error of a completely random relevance estimate is 0.29.) The middle graph shows the estimate voor σ2 =5. The right graph
is averaged over the last 10 evaluations. Note how averaging over multiple runs of REVAC recovers the main features of the
target distribution (black columns in the rightmost graph of Figure 3, right above it).

  Figure 4 shows the results of this experiment. As we               
                                                            f  x        3  x2,  −  .  ≤ x ≤   .
increase the variance of the additive noise term, the mean   1( )=      i=1 i     5 12   i   5 12     (1)
squared error of the REVAC estimate increases roughly lin-                       2 2         2
                                                                       100(x2 − x1) +(1−   x1) ,
early with the variance. This error can be reduced by aver- f2 x
                                                              ( )=      −  .   ≤ x  ≤  .              (2)
aging over multiple runs of REVAC. That means that under                  2 048   i   2 048
noisy conditions REVAC can give a quick ﬁrst approximation           5
                                                            f3(x)=     i=1xi,  −5.12 ≤ xi ≤ 5.12    (3)
that can be reﬁned by averaging over repeated calibrations.                    
This leads to an effective use of all evaluations. The fact that                 x2   x2 2 −  .
                                                                       .    (sin   1 + 2)   0 5 ,
the noise follows a non-normal distribution does not form a           0 5+             2    2  2
                                                            f6(x)=         (1 + 0.0001(x + x ))       (4)
signiﬁcant obstacle.                                                                   1    2
                                                                      − 100 ≤ xi ≤ 100

5  Results on concrete objective functions                  Table 2: REVAC results after 1000 evaluations.
                                                               optimum      conﬁdence    entropy   rele-
Here we present the outcomes of in vivo experiments, as dis-   value         interval             vance
cussedinsection3. TothisendweneedtodeﬁneanEA            f1 pm  0.012      0.011 – 0.013    -8.6    0.82
and some speciﬁc objective functions. For both purposes we pc  0.90         0.77 – 0.96    -1.9    0.18
rely on [Czarn et al., 2004] who apply rigorous statistical ex- f p
ploratory analysis to a simple GA to study the effect of cal- 2 m 0.0146 0.0143 – 0.0148   -9.4    0.82
                                                          p
ibrating the mutation and crossover operators. The EA here c   0.82         0.77 – 0.86    -2.1    0.18
is a generational GA with 22 bits per variable, Gray coding, f3 pm 0.0338 0.0334 – 0.0342  -9.0    0.72
probabilistic ranked-based selection, single point crossover pc 0.98        0.82 – 0.99    -3.5    0.28
with pc, bit ﬂip mutation with pm, and a population of 50
                                                        f6 pm  0.0604    0.0635 – 0.0641   -6.9    0.86
chromosomes. The four test functions are rather standard:
                                                          pc   0.60         0.48 – 0.68    -1.1    0.14
sphere, saddle, step, Schaffer’s f6. Our results are summa-
rized in Table 2 and Figure 5. These can be considered from
two perspectives, compared with the “usual” GA settings, and A direct comparison with [Czarn et al., 2004] is difﬁ-
with the work of Czarn et al. As Table 2 shows the values cult, because of the different types of outcomes. As for the
found by REVAC are consistent with the conventions in EC: method, they use screening experiments to narrow down the
pm between 0.01 and 0.1, and pc between 0.6 and 1.0.  space of feasible parameter settings, partition this space into

                                                IJCAI-07
                                                   979