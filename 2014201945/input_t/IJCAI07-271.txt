   A Flexible Unsupervised PP-Attachment Method Using Semantic Information

                     Srinivas Medimi                          Pushpak Bhattacharyya
             Deptt. of Computer Sc. & Engg.               Deptt. of Computer Sc. & Engg.
          Indian Institute of Technology Bombay        Indian Institute of Technology Bombay
                 Mumbai, INDIA, 400076                        Mumbai, INDIA, 400076
                     msr@cse.iitb.ac.in                           pb@cse.iitb.ac.in

                    Abstract                          PPs, but these make a difference. For example: In sen-
                                                      tence, I ate rice with salad/spoon, the attachments are rice
    In this paper we revisit the classical NLP prob-  with salad and ate with spoon. In our approach, we consider
    lem  of prepositional phrase attachment (PP-
                             V −NP   −P −NP           the contribution of noun within PP for PP-attachment. Fur-
    attachment). Given the pattern  1        2        ther, since most of the previous methods have focused only
    in the text, where V is verb, NP1 is a noun phrase,  V − N  −  P − N
    P                     NP                          on       1         2 structures, they can not consider the
      is the preposition and 2 is the other noun      attachments of far away PPs, which are mostly adjuncts. We
    phrase, the question asked is where does P − NP2
           V   NP                                     deal with such situation in our unsupervised approach.
    attach:  or    1? This question is typically an-    Even with large corpora, the biggest challenge is data spar-
    swered using both the word and the world knowl-   sity. We propose a simple, yet effective method of Data Spar-
    edge. Word Sense Disambiguation (WSD)andData      sity Reduction (DSR)-usingWordNet1. DSR helps smooth
    Sparsity Reduction (DSR) are the two requirements (generalize) the low probability counts. The correct PP-
    for PP-attachment resolution. Our approach de-    attachment is basically determined by the semantic property
    scribed in this paper makes use of training data ex- of the lexical items in the context of the preposition. We use
    tracted from raw text, which makes it an unsuper-
                                 V − P − N            an iterative graph-based unsupervised Word Sense Disam-
    vised approach. The unambiguous        and                                      [            ]
    N  − P − N                                        biguation (WSD) method (simlar to Mihalcea, 2005 ), which
      1       2 tuples of the training corpus TEACH   exploits the global semantic dependency and interaction of
    the system how to resolve the attachments in the
              V − N   − P − N                         the word senses and ranks the senses of each word. This helps
    ambiguous       1         2 tuples of the test    in correct PP-attachment.
    corpus. A graph based approach to word sense dis-   The remainder of the paper is organized as follow: Sec-
    ambiguation (WSD) is used to obtain the accurate  tion 2 describes a graph based iterative unsupervised Word
    word knowledge. Further, the data sparsity prob-  Sense Disambiguation method. Section 3 explains the data
    lem is addressed by (i) detecting synonymy using  sparsity reduction process. Section 4 details the unsupervised
    the wordnet and (ii) doing a form of inferencing
                          V     N                     PP-Attachment method. Section 5 presents the experimental
    based on the matching of sand s in the unam-      results and Section 6 concludes the paper.
    biguous patterns of V −P −NP, NP1 −P −NP2.
    For experimentation, Brown Corpus provides the
    training data and Wall Street Journal Corpus the test 2 Word Sense Disambiguation for
    data. The accuracy obtained for PP-attachment res-    PP-attachment
    olution is close to 85%. The novelty of the system In this section, we describe a Word Sense Disambiguation
    lies in the ﬂexible use of WSD and DSR phases.    (WSD) method in the context of Prepositional Phrase Attach-
                                                      ment (PP-Attachment). The approach is an iterative graph
1  Introduction                                       based algorithm which performs random walk on the sense
                                                      dependency graph of the words involved in the context. Our
Correct PP-attachment is essential for syntactic and conse- approach to word sense disambiguation for PP-attachment is
quent semantic analysis of a sentence. For example: in the based on two hypotheses: (1) Prepositions are semantic car-
sentence I lifted the girl with a crane, with crane is the riers. Most of the semantic relations are derived in associa-
                  PP
prepositional phrase ( ), and the PP-attachment could ei- tion with prepositions (2) Exploitation of the global semantic
ther be lifted with a crane (machine sense of crane)orgirl dependency among the words (preferably in the proximity of
with a crane (bird sense of crane). Word sense disambigua- a preposition) will help WSD. During the completion of this
tion and PP-attachment mutually affect each other for correct module of our work, a similar work on a generic graph-based
and unambiguous assignment of senses and PP-attachment approach for sequence data labeling and its application for
respectively, as is evident from this example. Many previous WSD was published [Mihalcea, 2005].
researches [Ratnaparkhi, 1998; Donald Hindle and Rooth,
1993] have not considered the properties of nouns inside the 1wordnet.princeton.edu

                                                IJCAI-07
                                                  16772.1  Graph Based Algorithm for WSD                    observed that the graph-based iterative algorithm performing
We perform a random walk on the graph for each context, i.e, random walk on the context sense dependency graph assigns
a sequence of words that are supposed to disambiguate each the highest weight to sense #3 for write,sense#1forbook
                                                      and sense #3 for literature. The process of assigning weights
other. For us the sequence is V − N1 − P − N2.SinceP is
                                                      to vertices are given in subsection 2.4. However, it can be
not a content word, the interaction is basically among V , N1
and N2. A typical graph for a V − N1 − P − N2 sequence is observed that the differences between the ﬁrst and the third
shown in ﬁgure 1. We formally deﬁne the graph as follow: sense of write and all the senses for the word literature are
                                                      slight. For example, all the sense in case of literature can be
Let the given sequence of words be W = w1,w2,w3, ...., wn,
                                                      interchangeably used.
and let each word wi has Nwi senses. Assume the senses for
                                     N
                       1   2   3       wi
        wi    Sw  =  {s  ,s  ,s  , ..., sw }
the word   are   i     wi  wi  wi     i  . We con-    2.3  Sense Similarity
struct a labeled graph G =(V,E) in which each vertex rep-
resents a word sense and is labeled with the sense number The similarity between the two words is computed using the
                                                      following criteria, which is motivated by the variations of
Swi . In G, there is a vertex v for every possible sense of a
     {sj ,i=1..n, j  =1..N   }                        original Lesk algorithms [Lesk, 1986]: (1) The longer the
word   wi                  wi . The dependency edges
between a pair of vertices are labeled with the sense depen- sequence of words that match, the more is the similarity, (2)
dency representing the sense similarity of the concepts, which stop words such as as, a, the, be, is, shall and will are ﬁl-
will be explained later. The word senses of the same word are tered out. Prepositions are not ﬁltered out, since our words to
not connected within themselves. Rather they are connected be sense disambiguated are associated with prepositions. If
to labeled sense vertices of other words. However, not all the same preposition appears in the deﬁnitions of the words
labeled pairs can be related by dependency.           that match, extra weight is assigned to the semantic similar-
                                                      ity. If the sequence of words match along with the preposi-
                                                      tion then the similarity gets more weight, (3) Normalization
                                                      of the weights is done based on the length of the deﬁnition to
                                                      counter the effect of long deﬁnitions, (4) Pronouns of similar
                                                      forms, such as {I, we, he, she, they, you}, are treated as a sin-
                                                      gle entity, (5) Words having different derivational morpholog-
                                                      ical forms such as published and publication are considered
                                                      similar.
                                                      2.4  Labeling Process for Graph Vertices
                                                      The basic idea is motivated by the PageRank algorithm [Brin
                                                      and Page, 1998].
                                                        1. More the number of links are connected to a vertex,
                                                          more important is the vertex.
                                                        2. If the incoming link is from a very important vertex, then
                                                          link itself carries more weight, accordingly the vertex
                                                          receiving the link is highly weighted.
                                                      For the labeled graph, given a set of weights wab associated
                                                      with the edge connecting vertices Va and Vb,the weighted
                                                      Page Rank score is determined as given in Equation 1:
                                                                             
                                                                                        wba
Figure 1: partial labeled graph with senses assigned to words WP(Va)=(1− d)+d ∗                  WP(Vb)
                                                                                                bc
                                                                                     Vc∈Out(Va) w
in the sentence He wrote a book on Literature                              Vb∈In(Va)
                                                                                                       (1)
                                                       In Equation 1, the WP(Va) value indicate the stationary
2.2  Labeling the Graph Edges                         probability of a particular sense of a word.
Consider the sentence He wrote a book on literature.The
                                                      2.5  Iterative Algorithm for Vertex Ranking
V −N1 −P  −N2  tuple is wrote book on literature and words
to be disambiguated are write, book, and literature.Thela- The algorithm consists of three main steps: (1) building of
beled graph for this VNPNtuple is constructed as described the labeled dependencies graph (2) scoring of vertices using
in Section 2.1. Figure 1 shows the labeled graph structure graph-based ranking algorithms (3) label assignment. The it-
for this sentence. All the words in the sentence have multiple erative algorithm for vertex ranking using Equation 1 is sim-
meaning. The words write, book,andliterature have nine, ilar to described in [Mihalcea, 2005], with the difference in
ten and four WordNet senses respectively. For the simplic- the way we ﬁnd the similarity between the senses of words.
ity of presentation, only a few sample labeled sense depen- The steady state weights are the relative weights of the senses.
dency edges are shown in the graph. If the sense dependency Since the graph-based algorithm ranks the weights, we have
similarity is zero, no edge is placed. In ﬁgure 1, it can be experimented with assigning multiple senses to each word.

                                                IJCAI-07
                                                  16783  Data Sparsity Reduction (DSR) Process                  each having weight of the empirical count of original
                                                          tuple. Update the appropriate frequency counts with the
Words in general are polysemous. Much of the data spar-           L  ∗ L
sity in this context can be attributed to non-exploitation of counts of 1 2 newly generated tuples.
paradigmatic relationships among words. It is rather infeasi- 3. Inferencing: The third step involves inferencing among
ble to collect all possible combinations of training examples the tuples in the V − P − N2 syntagmatic context based
even from a large corpus, if paradigmatic and contextual re- on matching partly or fully, which either may generate
lations are not exploited. Consider the following sentences as new tuples not available in the training corpus or may
a sample of the corpus.                                   increase the frequency count of the existing tuples. For
 1. He painted the wall with colour. (va- meaning verb at- example, if V1 − P − N1 and V2 − P − N1 exist as also
    achment)                                              do V1 − P − N2 and V2 − P − N2,thenifV3 − P − Ni
                                                                i =1, 2                           V  PN
 2. He paints the wall with red color. (va)               exists (     ), we can infer the existence of 3 j
                                                          where i = j, with frequency count of V3PNi added
 3. He coated the wall with colours. (va)                 appropriately.
 4. He will paint the room with medieval scenes. (va)
                                                      The above three steps are applied in the given order. We have
 5. They coated the building with cracks. (na, meaning observed signiﬁcant reduction DSR.
    noun attachment)
 6. I coloured the house with distemper. (va)
                                                      4   Unsupervised Prepositional Phrase
The corresponding PP-attachment tags are given in parenthe-
sis.                                                      Attachment Method
  In the given data set, many of the words are variants of
                                                      In this section, we propose an unsupervised PP-attachment
inﬂectional morphology, such as painted, paints, paint and a
                                                      method which does not require any annotated data. The pro-
few of them are synonyms such as colour, color and build-
                                                      posed method directly collects training examples from the
ing, house, room. We should exploit these observations.
                                                      text. Our approach is based on the hypothesis that unam-
Moreover, if we can establish a relation between the verbs
                                                      biguous attachment cases of training data TEACH how to re-
painted and coated, given the preposition with and Att=va,
                                                      solve the ambiguous attachment cases of the test data.Our
then possibly we can ﬁnd higher probability in Equation 2,
                                                      approach is motivated from the work of Ratnaparkhi [Ratna-
even though such an instance is not available in the training
                                                      parkhi, 1998] and is to some extent similar in terms of the
corpus.
                                                      statistical modelling and the extraction of training examples.
  P (N2=scene|V   = coated, P = with, Att = va) (2)   However, we have introduced the graph based word sense
                                                      disambiguation and data sparsity reduction, which is a point
The data sparsity reduction (DSR) procedure is described of difference. Another point of difference is the employing of
next.                                                 the training data reﬁnement process described in subsection
                                                      4.4.
3.1  Data Sparsity Reduction (DSR)
                                                        We resolve attachment in the ambiguous V −N1 −P −N2
Use is made of Lemmatisation, Synset replacement (paradig- test instances using the extracted unambiguous V − P − N2
matic substitution) and Inferencing based on syntagmatic and N1 − P − N2 cases from the training data. For example,
context. The updation process for Verb Attachment has been the ambiguous ate rice with spoon, can be interpreted as cor-
given below; a similar process is followed for Noun Attach- rect unambiguous ate with spoon and incorrect unambiguous
ment by substituting N1 for V. Updation process for verb rice with spoon instances. The extracted V − P − N2sare
Attachment:                                           more reliable. N1 − P − N2s are not reliable- particularly the
The following steps are applied on the original training N1PN2sinwhichP  − N2sarethePP-adjuncts which can
corpus for each preposition for modeling Pr(N2|P, V, va). appear far away from verbs but actually are attached to verbs.
When the attachment is to V , N1 is independent of N2,and
N1 statitics is not changed.
                                                      4.1  Collecting Training Data from Raw Text
 1. Lemmatisation and Morphing:  (a)Lemmatisation of
    dependent noun: after lemmatising if tuples become We ﬁrst annotate the text with part-of-speech tags using the
    similar, add to the frequency counts of the tuples and LT POS2. The the noun phrases and verb phrases are chunked
    (b)Morph verb: after morphing if tuples become simi- using our own simple chunker. After chunking we replace
    lar, add to the frequency counts of the tuples.   each chunk with their head words. Extraction heuristics are
                                                      then applied to extract the unambiguous V − P − N2sand
 2. Synset replacement: For each tuple in the corpus, N  − P − N
    create new tuples with weights proportional to em-  1        2 training instances given in subsection 4.2. The
    pirical counts, for each word in the Synsets of ﬁrst whole process of tagging, chunking, extraction of training ex-
                                                      amples are given in Table 1.
    two senses of V and N2. Suppose, if V has L1 =
    SynW Cont(V  ) number of synonymous words and N2
    has L2 =  SynW Cont(N2)   number of synonymous       2A  product of Language  Technology Group  (LTG),
    words, then L1 ∗ L2 number of tuples are generated, Edinburg.http : //www.ltg.ed.ac.uk/

                                                IJCAI-07
                                                  1679                                                      right of N2 and one word to left of V or N1. Only the nouns
Table 1: The process of extracting training data from raw text and verbs are disambiguated. Three strategies are used to re-
                                                      ﬁne the data:
       Tools.                 Output                    1. Set of heuristics for reliable unambiguous N1 − P −
      Raw Text      The professional conduct of the doctors N2s. These are based on syntactic heuristics which pick
                    is guided by Indian Medical association. almost reliable NPNs. For example, (1) N1 − P − N2
      POS Tagger   The DT professional JJ conduct NN of IN
                  the DT doctors NNS is VBZ guided VBN by IN as subject: like tube through doorway in the sentence
                  Indian NNP Medical NNP Association. NNP . . The tube through the doorway disturbs the people and
       Chunker     conduct NN of IN doctors NNS guided VBN (2) N1 − P − N2 as predicate in the B part of a sentence
                           by IN Association                          <           >
   Extraction Heuristic (N1 = conduct, P =of,N2= doctors) of the form A form of ’be’ B:asinitem in program
                    (v = guided, P =by,N2 = Association)  in the sentence It is an important item in the program.
      Morphology     (N1 = conduct, P =of,N2 = doctor)
                     (V = guide, P =by,N2= association) 2. Tuples after step 1 are further reﬁned using strong con-
     Synset Addition (N1 = conduct, P =of,N2 = doctor)    ditions. We use WordNet to ﬁnd semantic properties of
                    (N1 =behavior,P =of,N2= physician)
                  similarly we can have 4*6= 24 combinations, and words such as place, time, group etc.
                     (V = guide, P =by,N2= association) 3. Finally slightly weaker conditions are applied through
                     (V = direct, P =by,N2= association)
                   similarly we can have 9*1= 9 combinations limited statistical inferencing to give a set of highly cor-
                                                          rect V − P − N2 and N1 − P − N2 tuples.
4.2  Heuristic Extraction of Unambiguous Training     4.4  Training Method
     Data                                             Our goal is to resolve the ambiguous PP-attachment instances
The extraction heuristic exploits the idea that an attachment using the learnt knowledge of unambiguous PP-attachment.
site of a preposition is usually within a few words to the left The ambiguous tuple are of the form VN1PN2. The un-
of the preposition. The heuristic has the following parame- ambiguous training tuples are of the form V − P − N2 and
ters:                                                 N1 − P − N2. We deﬁne our classier as in Equation 3.
Window size S: This is the maximum distance in words be-
                                                        AT T (V,N1,P,N2)=arg    max   Pr(V,N1,P,N2,a)
tween a preposition P and N1, V or N2.WeuseW=4in our                           a∈{N,V }
experiments. We extract:                                                                              (3)
 1. V − P − N2, if the parsed segments satisfy:       We can factor Pr(V,N1,P,N2,a) as follows:
      • P
          is a preposition                               Pr(V,N1,P,N2,a)
      • V is not a form of the verb to be                     Pr(V )Pr(N )Pr(a|V,N  )Pr(P |a, V, N )
                                                         =               1         1             1    (4)
      • V is the ﬁrst verb that occurs within W words to      P (N2|P, a, V, N1)
        the left of P
      •                      V     P                  The factors Pr(N1) and Pr(V ) are independent of the at-
        No noun occurs between and                             a
      • N                               W             tachment   and need not be computed.  The estimation
          2 is the ﬁrst noun that occurs within words to Pr(a|V,N ) Pr(P |a, V, N )   Pr(N  |P, a, V, N )
                  P                                   of         1 ,            1 ,and     2         1 is
        the right of                                                                      N      V
      •                      P    N                   difﬁcult, because in the training data both 1 and do not
        No verb occurs between and  2                 occur together. For this reason, these factors are computed
 2. N1 − P − N2, if the parsed segments satisfy:      using the approximation in Equation 5:

      • P is a preposition                                                          Pr(a=N1|N1)
                                                                 Pr(a = N1|V,N1) ≈
                                                                                      Z(V,N1)
      • N  is the ﬁrst noun that occurs within W words to                          Pr(a=V |V )        (5)
                                                                 Pr(a = V |V,N1) ≈
        the left of P                                                               Z(V,N1)
      • No verb occurs within W words to the left of P .
                                                      where, Z(V,N1)=Pr(a         =   N1|N1)+Pr(a      =
        If it appears, it must be ensured that a preposition,
                                                      V |V ). Similarly, we approximate Pr(P |a, V, N1) and
        subordinating conjunction or a Wh-type conjunc- Pr(N |P, a, V, N )
                          N                                2         1  as given in Equations 6 and 7 respec-
        tion appears between and the new verb seen    tively. The reasons for these approximations are to avoid
      • N                               W
          2 is the ﬁrst noun that occurs within words to using counts of (V,N1) together, since they are never seen
                  P
        the right of                                  together in the extracted data.
      • No verb occurs between P and N2
                                                             Pr(P |a = N1,V,N1) ≈ Pr(P |a = N1,N1)
                             V − P −  N       N  −                                                    (6)
Since the unambiguous instances        2sand   1             Pr(P |a = V,V,N1) ≈ Pr(P |a = V,V )
P − N2s are extracted using heuristics, these- particularly
N1 − P −  N2s- are not always correct, and hence call for Pr(N2|P, a = N1,V,N1) ≈ Pr(N2|P, a = N1,N1)
reﬁnement.                                               Pr(N2|P, a = V,V,N1) ≈  Pr(N2|P, a = V,V )
                                                                                                      (7)
4.3  Reﬁnement of Training Data                       The approximated probabilities are computed from the train-
We ﬁlter out the incorrect V − P − N2 and N1 − P − N2 ing data as in [Medimi and Bhattacharyya, 2004].Weuseda
instances by applying the graph based WSD algorithm dis- variant of backed-off technique in order to smooth the proba-
cussed in 2.1. The features considered are one word to the bility computation.

                                                IJCAI-07
                                                  16805  Experiments, Results and Analysis                       86

Training Data:We used Brown corpus for collecting the un-  85
ambiguous training examples. The corpus size is 6MB, con-                                         Syn-Inf
                                                                                                  WnSyn
sisting of 51763 sentences, and nearly 1 million 27 thousand 84
words. The most frequent prepositions are in, to, for, with, on,
                                                          PP-attachment  Precision
at, from. The preposition of which is highly biased towards 83
noun attachment is not considered. The extracted unambigu-      GwsRnk1 GwsRnk2 GwsRnk3 GwsRnk3-C1 GwsRnk3-C2
ous distinct n1 − p − n2 and v − p − n2 tuples number 54030
and 22362 respectively.                               Figure 2: Performance summary of FlxUppAttch DSR-with-
Testing Data: For testing, we used Penn Treebank Wall WSD with combination of senses assigned to words
Street Journal data by Ratnaparkhi [Ratnaparkhi et al., 1994],
which is a standard benchmark data for PP attachment used that, it makes a trade-off between coverage and precision. In
by many groups  [Ratnaparkhi et al., 1994; Collins and case of (GwsRnk3-C1)), though it increases the precision, it
Brooks, 1995; Stetina and Nagao, 1997].               decreases the coverage proportionately. It may also be ob-
Baseline: We consider the unsupervised approach by Rat- served that inferencing consistently increases the precision of
naparkhi [Ratnaparkhi, 1998] as the Baseline system for our the system.
performance evaluation. We name it as Base-RP.Further,we We also compared the the performance of our system with
tested the performance of our system on the extracted unam- baseline using WSD and applying the DSR in stages. Figure
biguous samples. We name this process as Base-MS.     3 shows the performance variation.
  We name our proposed system A Flexible Unsupervised
PP-attachment or in short FlxUppAttch. We experimented
on the performance of FlxUppAttch in two stages: (i) DSR
without WSD (we call it DSR-wo-WSD) and (ii) DSR with
WSD (we call it DSR-with-WSD). The stages and their names
appear in Table 2.


Table 2: The naming of FlxUppAttch systems utilizing differ-
ent DSR stages and the graph based WSD

                    Stages of Data Sparsity Reduction
             Morphing Inferencing Synset Synset &
                                        Inferencing
 DSR-wo-WSD  Morph    Infer    WnSyn    Syn-Inf
 DSR-with-WSD MorphWS InferWS  WnSynWS  Syn-InfWS
                                                      Figure   3:      Comparison    of   Baselines  with
                                                      FlxUppAttch(GwsRnk3-C2) at different stages of DSR
  Further, since our WSD method provides ranks to all the
senses of each word, we experimented with different schemes
of sense assignment                                     The performance of our system after morphing is better
                                                      than performance of Ratnaparkhi [Ratnaparkhi, 1998], i.e
 1. GwsRnk1- assign the ﬁrst ranked sense             Base-RP. This gives an indication of the better accuracy of
 2. GwsRnk2- ﬁrst two highest ranked senses           extraction heuristics. The comparative performance of our
                                                      best performing system with the state-of-the-art systems are
 3. GwsRnk3- ﬁrst three highest ranked senses         shown in Table 3
 4. GwsRnk3-C1- ﬁrst sense always, 50% times the ran-
    dom assignment of the second sense and 30% times the
    random assignment of the third sense              6Conclusion
 5. GwsRnk3-C2- 50% times the ﬁrst sense, 30% times the We presented an unsupervised method for PP-attachment
    second sense, and 20% times the third sense       which compares favourably with the existing state of the art
With different senses being assigned, we observed the per- approaches. The method makes use of lexical semantics
formance of our system with respect to different stages of and inferencing through the use of WordNet. We employ
DSR process particulrly after synsets and after synsets and WSD in a limited way and make use of the unambiguous
inferencing. This performance comparision is given in Fig- PP-attachments to learn the resolution of PP-Attachment in
ure 2. In case of GwsRnk3, the precision is low. This is be- case of the ambiguous V − N1 − P − N2 tuples. Since the
cause, though the coverages of the tuples increases due to , starting point is raw corpora, the method is usable even when
it introduces noise through wrong lexical entries, which has annotation is not available. Clearly the efﬁcacy of the method
a net negetive effect on the precisison. The best performing depends on the richness of the presence of V − P − N and
combination is (GwsRnk3-C2)), this may be due to the fact N − P − N tuples. Obvius future work consists in reﬁning

                                                IJCAI-07
                                                  1681