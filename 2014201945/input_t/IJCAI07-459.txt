                  Combining Learning and Word Sense Disambiguation
                                  for Intelligent User Proﬁling∗

              Giovanni Semeraro, Marco Degemmis, Pasquale Lops, Pierpaolo Basile
                                       Department of Informatics
                                        University of Bari, Italy
                           {semeraro, degemmis, lops, basilepp}@di.uniba.it

                    Abstract                          search process. Traditional keyword-based approaches are
                                                      primarily driven by a string-matching operation: If a string,
    Understanding user interests from text documents  or some morphological variant, is found in both the proﬁle
    can provide support to personalized information   and the document, a match occurs and the document is con-
    recommendation services. Typically, these services sidered relevant. String matching suffers from problems of
    automatically infer the user proﬁle, a structured polysemy, the presence of multiple meanings for one word,
    model of the user interests, from documents that  and synonymy, multiple words having the same meaning. The
    were already deemed relevant by the user. Tradi-  result is that, due to synonymy, relevant information can be
    tional keyword-based approaches are unable to cap- missed if the proﬁle does not contain the exact keywords in
    ture the semantics of the user interests. This work the documents, while, due to polysemy, wrong documents
    proposes the integration of linguistic knowledge in could be deemed relevant. These problems call for alternative
    the process of learning semantic user proﬁles that methods to learn more accurate proﬁles that capture concepts
    capture concepts concerning user interests. The   expressing user interests from relevant documents. These se-
    proposed strategy consists of two steps. The ﬁrst mantic proﬁles should contain references to concepts deﬁned
    one is based on a word sense disambiguation tech- in lexicons or ontologies. This paper describes an approach
    nique that exploits the lexical database WordNet to in which user proﬁles are obtained by machine learning tech-
    select, among all the possible meanings (senses) of niques integrated with a word sense disambiguation (WSD)
    a polysemous word, the correct one. In the second strategy based on the WordNet lexical database [Miller, 1990;
    step, a na¨ıve Bayes approach learns semantic sense- Fellbaum, 1998]. The paper is organized as follows: After a
    based user proﬁles as binary text classiﬁers (user- brief discussion about the main works related to our research,
    likes and user-dislikes) from disambiguated docu- in Section 3 the WSD strategy proposed to represent docu-
    ments. Experiments have been conducted to com-    ments by using WordNet is described. Section 4 presents the
    pare the performance obtained by keyword-based    na¨ıve Bayes text categorization method we adopted to build
    proﬁles to that obtained by sense-based proﬁles.  WordNet-based user proﬁles. This method is implemented
    Both the classiﬁcation accuracy and the effective- by the content-based proﬁling system ITem Recommender
    ness of the ranking imposed by the two different  (ITR). An experimental sessions has been carried out in order
    kinds of proﬁle on the documents to be recom-     to evaluate the proposed approach in a movie recommending
    mended have been considered. The main outcome     scenario. The main results are presented in Section 5. Con-
    is that the classiﬁcation accuracy is increased with clusions and future work are discussed in Section 6.
    no improvement on the ranking. The conclusion
    is that the integration of linguistic knowledge in 2  Related Work
    the learning process improves the classiﬁcation of
    those documents whose classiﬁcation score is close Our research was mainly inspired by the following works.
    to the likes / dislikes threshold (the items for which Syskill & Webert [Pazzani and Billsus, 1997] learns user pro-
    the classiﬁcation is highly uncertain).           ﬁles as Bayesian classiﬁers able to recommend web pages,
                                                      but it represents documents using keywords. LIBRA [Mooney
                                                      and Roy, 2000] adopts a Bayesian classiﬁer to produce
1  Introduction                                       content-based book recommendations by exploiting product
                                                      descriptions obtained from the web pages of the Amazon on-
Personalized systems adapt their behavior to individual users
                                                      line digital store. Documents are represented by using key-
by learning their preferences during the interaction in order
                                                      words and are subdivided into slots, each one corresponding
to construct a user proﬁle, that can be later exploited in the
                                                      to a speciﬁc section of the document. Like Syskill & Webert,
  ∗This research was partially funded by the European Commis- the main limitation of this work is that keywords are used
sion under the 6th Framework Programme IST Integrated Project to represent documents. Conversely, SiteIF [Magnini and
VIKEF, Priority 2.3.1.7 Semantic-based Knowledge Systems. Strapparava, 2001] exploits a sense-based document repre-

                                                IJCAI-07
                                                  2856sentation to build a user proﬁle as a semantic network whose In the second step, described in Section 4, a na¨ıve Bayes
nodes represent senses of the words in documents requested approach learns sense-based user proﬁles as binary text clas-
by the user. The semantic network is built by assigning each siﬁers (user-likes and user-dislikes) from disambiguated doc-
node with a score that is inversely proportional to its fre- uments. A thorough experimental evaluation of that idea in
quency over all the corpus. Thus, the score is higher for the context of a hybrid (content-based / collaborative) rec-
less frequent senses, and this prevents very common mean- ommender system has been carried out in [Degemmis et al.,
ings from becoming too prevailing in the user model. In our 2007].
approach, a probability distribution of the senses, found in
the corpus of the documents rated by the user, is learned. 3.1 The JIGSAW Algorithm for Word Sense
OntoSeek [Guarino et al., 1999] is a system designed for   Disambiguation
content-based information retrieval from online yellow pages Textual documents cannot be directly interpreted by learning
and product catalogs, which explored the role of linguistic algorithms. An indexing procedure that maps a document
ontologies in knowledge-retrieval systems. That approach di into a compact representation of its content must be ap-
has shown that structured content representations, coupled plied. A typical choice for document indexing is the classi-
with linguistic ontologies, can increase both recall and pre- cal bag-of-words (BOW) approach, where each document is
cision of content-based retrieval systems. By taking into ac- represented as a feature vector counting the number of occur-
count the lessons learned by the aforementioned works, ITR rences of different words as features [Sebastiani, 2002].We
has been conceived as a text classiﬁer able: 1) To deal with extend the BOW model to a model in which each document
a sense-based document representation obtained by exploit- is represented by the senses corresponding to the words in its
ing a linguistic ontology; 2) To learn a Bayesian proﬁle from content and their respective occurrences. This sense-based
documents subdivided into slots. The strategy we devise in document representation is exploited by the learning algo-
order to shift from a keyword-based document representa- rithm to build semantic user proﬁles. Here, “sense” is used
tion to a sense-based one, is to integrate lexical knowledge as a synonym of “meaning”. Any implementation of sense-
in the indexing step of training documents. Several meth- based document indexing must solve the problem that, while
ods have been proposed to accomplish this task. Scott and words occur in a document, meanings do not, since they are
Matwin [1998] included WordNet information at the feature often hidden in the context. Therefore, a procedure is needed
level by expanding each word in the training set with all its for assigning senses to words. This task, known as word sense
synonyms in WordNet in order to avoid a WSD process. This disambiguation, consists in determining which of the senses
approach has shown a decrease of effectiveness in the ob- of an ambiguous word is invoked in a particular use of that
tained classiﬁer, mostly due to the word ambiguity problem. word [Manning and Sch¨utze, 1999].
Therefore, it suggests that some kind of disambiguation is The goal of a WSD algorithm is to associate a word wi oc-
required. Bloedhorn and Hotho [2004] experiment with var- curring in a document d with its appropriate meaning or sense
ious settings for mapping words to senses: No WSD, most s, by exploiting the context C in which wi is found, com-
frequent sense as provided by WordNet, WSD based on con- monly deﬁned as a set of words that precede and follow wi.
                                              1
text. They found positive results on the Reuters 25178 ,the The sense s is selected from a predeﬁned set of possibilities,
          2                3
OHSUMED     and the FAODOC  corpora. None of the pre- usually known as sense inventory. In the proposed algorithm,
vious approaches for embedding WSD in classiﬁcation has the sense inventory is obtained from WordNet (version 1.7.1).
taken into account the fact that WordNet is a hierarchical the- WordNet was designed to establish connections between four
saurus. A distinctive feature of our work is the adoption of types of Parts of Speech (POS): Noun, verb, adjective, and
a similarity measure that takes into account the hierarchical adverb. The basic building block for WordNet is the SYNSET
structure of WordNet.                                 (SYNonym  SET), which represents a speciﬁc meaning of a
                                                      word. The speciﬁc meaning of one word under one type
3  Using WordNet to Represent Documents               of POS is called a sense. Synsets are equivalent to senses,
We consider the problem of learning user proﬁles as a binary which are structures containing sets of words with synony-
text categorization task: Each document has to be classiﬁed as mous meanings. Each synset has a gloss, a short textual de-
interesting or not with respect to the user preferences. The set scription that deﬁnes the concept represented by the synset.
of categories is C = {c+, c−},wherec+ is the positive class For example, the words night, nighttime and dark constitute
(user-likes) and c− the negative one (user-dislikes). There a single synset that has the following gloss: “the time after
are several ways in which content can be represented in order sunset and before sunrise while it is dark outside”. Synsets
to be used as a basis for the learning component and there are connected through a series of relations: Antonymy (oppo-
exists a variety of machine learning methods that could be sites), hyponymy/hypernymy (IS-A), meronymy (PART-OF),
exploited for inferring user proﬁles. We propose a strategy etc. JIGSAW is a WSD algorithm based on the idea of com-
to learn sense-based proﬁles that consists of two steps. This bining three different strategies to disambiguate nouns, verbs,
section describes the ﬁrst one, that is, a WSD technique that adjectives and adverbs. The motivation behind our approach
exploits the word senses in WordNet to represent documents. is that the effectiveness of the WSD algorithms is strongly
                                                      inﬂuenced by the POS tag of the target word. An adaptation
  1http://about.reuters.com/researchandstandards/corpus/ of Lesk dictionary-based WSD algorithm has been used to
  2http://www.ltg.ed.ac.uk/disp/resources/            disambiguate adjectives and adverbs [Banerjee and Pedersen,
  3http://www4.fao.org/faobib/index.html              2002], an adaptation of the Resnik algorithm has been used to

                                                IJCAI-07
                                                  2857disambiguate nouns [Resnik, 1995], while the algorithm we the synset corresponding to the sense n.2 of the verb look
developed for disambiguating verbs exploits the nouns in the ({look,appear,seem})is“give a certain impression or have
context of the verb as well as the nouns both in the glosses a certain outward aspect”, while some examples of usage of
and in the phrases that WordNet utilizes to describe the us- the verb are: “She seems to be sleeping”; “This appears to
age of the verb. The algorithm disambiguates only words be a very difﬁcult problem”. The description of the synset
which belong to at least one synset. JIGSAW takes as in- is “give a certain impression or have a certain outward as-
put a document d = {w1, w2, ..., wh} and will output a pect She seems to be sleeping This appears to be a very dif-
list of WordNet synsets X = {s1, s2, ..., sk} (k ≤ h) in ﬁcult problem”. First, the JIGSAWverbs includes in the
which each element si is obtained by disambiguating the tar- context C for the target verb wi all the nouns in the win-
get word wi based on the information obtained from WordNet dow of 2n words surrounding wi. For each candidate synset
about a few immediately surrounding words. We deﬁne the sik of wi, the algorithm computes nouns(i, k), that is the
context C of the target word to be a window of n words to set of nouns in the description for sik. In the above exam-
the left and another n words to the right, for a total of 2n ple, nouns(look, 2)={impression, aspect, problem}. Then,
surrounding words. The algorithm is based on three different for each wj in C and each synset sik, the following value is
procedures for nouns, verbs, adverbs and adjectives, called computed:
JIGSAWnouns,   JIGSAWverbs,  JIGSAWothers, respec-
                                                                                 {SinSim(     ,  )}
tively. The POS tag of each word is computed by the HMM- maxjk  = maxwl∈nouns(i,k)         wj  wl     (1)
based tagger ACOPOST t34. JIGSAW  proceeds in several
iterations by using the disambiguation results of the previ- In other words, maxjk is the highest similarity value for wj,
ous iteration to reduce the complexity of the next one. First, with respect to the nouns related to the k-th sense for wi.
JIGSAW  performs the JIGSAWnouns   procedure. Then,   Finally, a score for each sik is computed:
                                                                            
verbs are disambiguated by JIGSAWverbs by exploiting the
                                                                              w ∈C G(posj) · maxjk
words already disambiguated by JIGSAWnouns. Finally,         ϕ(i, k)=R(k)  ·   j                     (2)
the JIGSAWothers procedure is executed. More details for                           hG(posh)
each one of the above mentioned procedures follow.
                                                      where R(k) is the ranking of sik (synsets in WordNet are
         nouns
JIGSAW                                                ranked according to their frequency of usage) and G(posj ) is
The algorithm assigns to wi the most appropriate synset sih a gaussian factor related to the position of wj with respect to
among the sense inventory Wi for wi. It computes the sim- wi in the original text that gives a higher weight to words near
ilarity between each sik in the sense inventory and the con- the target word. The synset assigned to wi is the one with the
text for wi. The method differs from the original algorithm highest ϕ value.
by Resnik [1995] in the use of the similarity measure. We
adopted the Leacock-Chodorow measure [1998],whichis   JIGSAWothers
based on the length of the path between concepts in an IS- This procedure is based on the WSD algorithm proposed
A hierarchy. The idea behind this measure is that similar- in [Banerjee and Pedersen, 2002]. The idea is to compare
ity between synsets a and b is inversely proportional to their the glosses of each candidate sense for the target word to
distance in the WordNet IS-A hierarchy. The distance is
                                                      the glosses of all the words in its context. Let Wi be the
computed by counting the number of nodes in the shortest
                                                      sense inventory for the target word wi. For each sik ∈
path joining with  (by passing through their most spe-
           a      b                                   Wi, JIGSAWothers  computes the string targetGlossik that
ciﬁc subsumer). The similarity function is: SinSim
                                            (a, b)=   contains the words in the gloss of sik. Then, the proce-
−      p     ,where   p is the number of nodes in the
  log(N /2D)        N                                 dure computes the string contextGlossi, which contains the
shortest path p from a to b,andD is the maximum depth words in the glosses of all the synsets corresponding to each
of the taxonomy (      , in WordNet 1.7.1). The proce-
               D  =16                                 word in the context for wi. Finally, the procedure computes
dure starts by deﬁning the context of i as the set of words
                            C   w                     the overlap between contextGlossi and targetGlossik,and
having the same POS tag and found in the same sentence as
                                                      assigns the synset with the highest overlap score to wi.This
wi. Next, the algorithm identiﬁes both the sense inventory score is computed by counting the words that occur both in
for i and the sense inventory j, for each word j in .
   w                      W                w    C     targetGlossik and in contextGlossi. The JIGSAW algo-
The sense inventory T for the whole context C is given by rithm was evaluated according to the parameters of the Sen-
the union of all Wj. JIGSAWnouns measures the similar- seval initiative5, that provides a forum where the WSD sys-
ity between each candidate sense sik ∈ Wi and each sense
  ∈                                                   tems are assessed against disambiguated datasets. In order to
sh  T . The sense assigned to wi is the one with the highest measure the capability of disambiguating a complete text, the
similarity score.                                     “All Words Task” for English was chosen. JIGSAW reaches
JIGSAWverbs                                           the fourth position in that task, by achieving precision and re-
Before describing the JIGSAWverbs procedure, the descrip- call equal to 50%. This result assures that our WSD algorithm
tion of a synset must be deﬁned. It is the string obtained by can be conﬁgured to have high precision, and thus would add
concatenating the gloss and the sentences that WordNet uses very little noise in the training set. Due to space limitations,
to explain the usage of a word. For example, the gloss for the details of the experiments are not reported.

  4http://acopost.sourceforge.net/                       5http://www.senseval.org.

                                                IJCAI-07
                                                  2858            3.2  Keyword-based and Synset-based Document          BOW-represented documents, tokens tk in bim are words, and
                 Representation                                   the induced categorization model relies on word frequencies.
            The WSD   procedure described in the previous section is Conversely, when training is performed on BOS-represented
            adopted to obtain a synset-based vector space representation documents, tokens are synsets, and the induced model relies
                                                                  on synset frequencies. To calculate (4), the system has to esti-
            that we called bag-of-synsets (BOS). In this model, a synset            |
            vector instead of a word vector represents a document. An- mate P (cj) and P (tk cj,sm) in the training phase. The doc-
            other key feature of the approach is that each document is uments used to train the system are rated on a discrete scale
            represented by a set of M slots, where each slot is a textual from 1 to MAX, where MAX is the maximum rating that can
            ﬁeld corresponding to a speciﬁc feature of the document, in be assigned to a document. According to an idea proposed
                                                                  in [Mooney and Roy, 2000], each training document di is la-
            an attempt to take also into account the document structure.                                i
                                                                  beled with two scores, a “user-likes” score w+ and a “user-
            According to the BOS model, the text in each slot is repre-         i
            sented by counting separately the occurrences of a synset in dislikes” score w−, obtained from the original rating r:

            the slots in which it occurs. More formally, assume that we      i     r − 1         i        i
            have a collection of N documents. Let m be the index of the    w+  =           ;    w− =1−   w+       (5)
                                                                                 MAX   − 1
            slot, for n =1, 2,...,N,then-th document dn is reduced to
            M  bags of synsets, one for each slot:                  The scores in (5) are exploited for weighting the occur-
                                                                  rences of tokens in the documents and to estimate their prob-
                   m     m  m      m    
                  dn =  tn1,tn2,...,tnDnm , m=1,2,...,M           abilities from the training set TR. The prior probabilities of
                  m                                               the classes are computed according to the following equation:
            where tnk is the k-th synset in slot sm of document dn and
            Dnm  is the total number of synsets appearing in the m-th slot                |TR|
                                              m  ∈                                              i
            of document dn.Foralln, k and m, tnk   Vm,whichis                                 wj +1
            the vocabulary for the slot sm (the set of all different synsets               i=1
                                                                                  Pˆ(cj)=                         (6)
            found in slot sm). Document dn is ﬁnally represented in the                    |TR| +2
            vector space by M synset-frequency vectors:           Witten-Bell smoothing [1991] is adopted to  compute
                         m     m   m       m                    P (tk|cj,sm), by taking into account that documents are
                        fn  = wn1,wn2,...,wnDnm
                   m                                              structured into slots and that token occurrences are weighted
            where wnk is the weight of the synset tk in the slot sm of doc- using scores in equation (5):
            ument dn, and can be computed in different ways: It can be
                                                                                ⎧
            simply the number of times synset tk appears in slot sm,as
                                                                                ⎪     NP(tk,cj ,sm)
                                                                                ⎪  V +   N(t ,c ,s ) if N(tk,cj,sm) =0
            we used in our experiments, or a more complex TF-IDF score.         ⎨   cj  i   i j m
            Our hypothesis is that the proposed document representation Pˆ(tk|cj,sm)=
                                                                                ⎪        V
            helps to obtain proﬁles able to recommend documents seman-          ⎩⎪     P  cj         1
                                                                                   V +   N(t ,c ,s ) V −V otherwise
            tically closer to the user interests. The difference with respect       cj  i   i j m     cj
            to keyword-based proﬁles is that synset unique identiﬁers re-                                         (7)
            place words.                                          where N(tk,cj,sm) is the count of the weighted occurrences
                                                                  of token tk in the slot sm in the training data for class cj,
            4ANa¨ıve Bayes Method for User Proﬁling               Vcj is the total number of unique tokens in class cj,and
                                                                  V  is the total number of unique tokens across all classes.
            ITem Recommender (ITR) uses a Na¨ıve Bayes text catego- N(tk,cj,sm) is computed as follows:
            rization algorithm to build proﬁles as binary classiﬁers (user-
            likes vs user-dislikes). The induced probabilistic model esti-                   |TR|
                                             |                                                     i
            mates the a posteriori probability, P (cj di), of document di      N(tk,cj,sm)=      wjnkim           (8)
            belonging to class cj as follows:                                                 i=1
                                                                 In (8), nkim is the number of occurrences of token tk in slot
                                               N(di,tk)
                    P (cj|di)=P (cj)    P (tk|cj)           (3)   sm of document di.ThesumofallN(tk,cj,sm)   in the de-

                                    w∈di                          nominator of equation (7) denotes the total weighted length
                                                                                                      ˆ  |
            where N(di,tk) is the number of times token tk occurs in of the slot sm in class cj.Inotherwords,P (tk cj,sm) is es-
            document di. In ITR, each document is encoded as a vec- timated as the ratio between the weighted occurrences of tk
            tor of BOS in the synset-based representation, or as a vector in slot sm of class cj and the total weighted length of the slot.
            of BOW  in the keyword-based representation, one BOS (or The ﬁnal outcome of the learning process is a probabilistic
            BOW) for each slot. Therefore, equation (3) becomes:  model used to classify a new document in the class c+ or c−.
                                                                  This model is the user proﬁle, which includes those tokens
                                  |S| |bim|                     that turn out to be most indicative of the user preferences,
                            P (cj)                  nkim
                  P (cj|di)=              P (tk|cj,sm)      (4)   according to the value of the conditional probabilities in (7).
                                i
                            P (d ) m=1 k=1

            where S= {s1, s2,...,s|S|} is the set of slots, bim is the BOS 5 Experimental Evaluation
            or the BOW in the slot sm of di, nkim is the number of oc- The goal of the experiments was to compare the performance
            currences of token tk in bim. When the system is trained on of synset-based user proﬁles to that of keyword-based pro-

                                                            IJCAI-07
                                                              2859ﬁles. Experiments were carried out on a content-based ex-    Precision   Recall       F1        NDPM
tension of the EachMovie dataset6, a collection of 1, 628 tex- Id BOW BOS BOW BOS  BOW   BOS   BOW   BOS
tual descriptions of movies rated by 72, 916 users on a 6-point 1 0.70 0.74 0.83 0.89 0.76 0.80 0.45 0.45
                                                        2   0.51  0.57 0.62  0.70  0.54  0.61 0.41  0.39
scale (1−6). The content information for each movie was col-
                                  7                     3   0.76  0.86 0.84  0.96  0.79  0.91 0.45  0.45
lected from the Internet Movie Database by using a crawler 4 0.92 0.93 0.99  0.99  0.96  0.96 0.48  0.48
that gathered the Title,theDirector,theGenre, that is the cat- 5 0.56 0.67 0.66 0.80 0.59 0.72 0.46 0.46
egory of the movie, the Keywords,theSummary and the Cast. 6 0.75  0.78 0.89  0.92  0.81  0.84 0.46  0.45
Movies are subdivided into different genres: Action, Anima- 7 0.58 0.73 0.67 0.83  0.71  0.79 0.42  0.42
tion, Classic, Art Foreign, Comedy, Drama, Family, Horror, 8 0.53 0.72 0.65  0.89  0.58  0.79 0.41  0.43
Romance, Thriller. For each genre or category, a set of 100 9 0.70 0.77 0.83 0.91  0.75  0.83 0.49  0.49
users was randomly selected among users that rated n items, 10 0.71 0.75 0.86 0.91 0.77  0.81 0.48  0.48
30 ≤ n ≤ 100 in that movie category (only for genre ‘Anima- 0.67  0.75 0.78  0.88  0.73  0.81 0.45  0.45
tion’, the number of users that rated n movies was 33, due to
the low number of movies in that genre). In this way, for each Table 2: Performance of ITR on 10 different datasets
category, a dataset of at least 3, 000 triples (user, movie, rat-
ing) was obtained (at least 990 for ‘Animation’). Table 1 sum- ing to the a-posteriori probability of the class likes.Values
marizes the data used for the experiments.            range from 0 (agreement) to 1 (disagreement). The adop-
                                                      tion of both classiﬁcation accuracy and rank accuracy metrics
   Id     Genre    Number ratings % POS  % NEG        gives us the possibility of evaluating both whether the sys-
    1    Action        4,474       72      28         tem is able to recommend relevant documents and how these
    2   Animation      1,103       57      43         documents are ranked. In all the experiments, a movie de-
    3ArtForeign        4,246       76      24
                                                      scription di is considered relevant by a user if the rating is
    4    Classic       5,026       92       8
                                                      greater or equal to 4, while ITR considers a description rele-
    5    Comedy        4,714       63      37                    |
    6    Drama         4,880       76      24         vant if P (c+ di) > 0.5, computed as in equation (4). We ex-
    7    Family        3,808       64      36         ecuted one run of the experiment for each user in the dataset.
    8    Horror        3,631       60      40         Each run consisted in: 1) Selecting the documents and the
    9   Romance        3,707       73      27         corresponding ratings given by the user; 2) Splitting the se-
   10    Thriller      3,709       72      28         lected data into a training set Tr and a test set Ts;3)Using
                      39,298       72      28         Tr for learning the corresponding user proﬁle; 4) Evaluating
                                                      the predictive accuracy of the induced proﬁle on Ts,using
  Table 1: 10 ‘Genre’ datasets obtained from EachMovie the aforementioned measures. The methodology adopted for
                                                      obtaining Tr and Ts was the 5-fold cross validation. Table 2
  Tokenization, stopword elimination and stemming have shows the results reported over all 10 genres by ITR.
been applied to index the documents according to the BOW A signiﬁcant improvement of BOS over BOW both in pre-
model. The content of slots title, director and cast was only cision (+8%) and recall (+10%) can be noticed. The BOS
tokenized because the elimination of the stopwords produced model outperforms the BOW model speciﬁcally on datasets
some unexpected results. For example, slots containing ex- 5 (+11% of precision, +14% of recall), 7 (+15% of precision,
clusively stopwords, such as “It”or“E.T.”, became empty. +16% of recall), 8 (+19% of precision, +24% of recall). Only
Moreover, it does not make sense to apply stemming and on dataset 4 no improvement can be observed, probably be-
stopword elimination on proper names. Documents have  cause precision and recall are already very high. It could be
been processed by the JIGSAW algorithm and indexed ac- noticed from the NDPM values that the relevant / not rele-
cording to the BOS model, obtaining a 38% feature reduction. vant classiﬁcation accuracy is increased without improving
This is mainly due to the fact that synonym words are repre- the ranking. This result can be explained by the example in
sented by the same synset. Keyword-based proﬁles were in- Table 3, in which each column reports the ratings or scores of
ferred by learning from BOW-represented documents, whilst the items and the corresponding positions in the ranking.
synset-based proﬁles were obtained from BOS-represented
                                                        Let Ru be the ranking imposed by the user u on a set of
documents. As ITR is conceived as a text classiﬁer, its ef-
                                                      10 items, RA the ranking computed by A,andRB the rank-
fectiveness is evaluated by the well-known classiﬁcation ac- ing computed by method B (ratings ranging between 1 and 6
                              [              ]
curacy measures precision and recall Sebastiani, 2002 .Also - classiﬁcation scores ranging between 0 and 1). An item is
used is F1 measure, a combination of precision and recall. We considered relevant if the rating r>3 (symmetrically, if the
adopted the Normalized Distance-based Performance Mea- ranking score s ≥ 0.5). Method A has a better classiﬁcation
            [        ]
sure (NDPM)  Yao, 1995 to measure the distance between accuracy compared to method B (Recall=4/5, Precision=4/5
the ranking imposed on documents by the user ratings and vs. Recall=3/5, Precision=3/4). NDPM is almost the same
the ranking predicted by ITR, that ranks documents accord-
                                                      for both methods because the two rankings RA and RB are
  6EachMovie  dataset no longer available for down-   very similar. The difference is that I4 is ranked above I6 in
load, see the GroupLens home  page  for a new  ver-   RA, whilst I6 is ranked above I4 in RB. The general conclu-
sion named MovieLens, originally based on this dataset: sion is that method A (BOS model) has improved the clas-
http://www.cs.umn.edu/Research/GroupLens/             siﬁcation of items whose score (and ratings) are close to the
  7IMDb, http://www.imdb.com                          relevant / not relevant threshold (items for which the classi-

                                                IJCAI-07
                                                  2860