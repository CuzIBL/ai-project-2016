                  Learning Minesweeper with Multirelational Learning 

                  Lourdes Pefia Castillo                            Stefan Wrobel 
               Otto-von-Guericke-University                Fraunhofer AIS, Sankt Augustin 
                   Magdeburg, Germany                       and University Bonn, Germany 


                     Abstract 

    Minesweeper is a one-person game which looks 
    deceptively easy to play, but where average hu•                    i 
    man performance is far from optimal. Playing the 
    game requires logical, arithmetic and probabilis•  Figure 1: Left: Available information on a board. Right: 
    tic reasoning based on spatial relationships on the Seven tiles can be determined safe (s) and one a mine(m) 
    board. Simply checking a board state for consis•
    tency is an NP-complete problem. Given the dif•
    ficulty of hand-crafting strategies to play this and a safe move cannot be done. Given the difficulty of hand•
    other games, AI researchers have always been in•   crafting playing strategies for this and other games, AI re•
    terested in automatically learning such strategies searchers have always been interested in the possibility of au•
    from experience. In this paper, we show that when  tomatically learning such strategies from experience. How•
    integrating certain techniques into a general pur• ever, with the exception of reinforcement learning [Tesauro, 
    pose learning system (Mio), the resulting system is 1995], most of the playing strategies and heuristics used in 
    capable of inducing a Minesweeper playing strat•   game playing programs are coded and tuned per hand in•
    egy that beats the winning rate of average human   stead of automatically learned. In this work, we use a gen•
    players. In addition, we discuss the necessary     eral purpose ILP system, Mio, to learn a playing strategy 
    background knowledge, present experimental re•     for Minesweeper. Multirelational learning or ILP consists in 
    sults demonstrating the gain obtained with our tech• learning from examples usually within the framework pro•
    niques and show the strategy learned for the game. vided by clausal logic. 
                                                         The task of learning rules to deduce Minesweeper moves 
                                                       proved itself to be an arduous test for current multirelational 
1 Introduction                                         learning systems. In this paper, we describe how recent opti•
                                                       mizations make possible for Mio to discover a Minesweeper 
Minesweeper is a popular one-player computer game written 
                                                       playing strategy. Experimental results obtained by playing 
by Robert Donner ami Curt Johnson which was included in 
                                                       Minesweeper using this strategy show a better performance 
Microsoft Windows© in 1991. At the beginning of the game, 
                                                       than that obtained on average by non-expert human players. 
the player is presented with apx q board containing pq tiles 
                                                         The remainder of this paper is organized as follows. The 
or squares which are all blank. Hidden among the tiles are M 
                                                       next section discusses the complexity of the game and de•
mines distributed uniformly at random on the board. The task 
                                                       scribes the learning task. Section 3 describes the background 
of the player is to uncover all the tiles which do not contain a 
                                                       knowledge, the learning system and the new techniques used. 
mine. At each turn the player can select one of three actions 
                                                       Section 4 shows our empirical results on the effectiveness of 
(moves): to mark a tile as a mine; to unmark a tile; and to 
                                                       the learning techniques, the strategy obtained and its perfor•
uncover a tile. In the last action, if the tile contains a mine, 
                                                       mance at game playing. Related work is surveyed in Section 5 
the player loses; otherwise, the number of mines around the 
                                                       and Section 6 concludes. 
tile is displayed. In the 4 x 4 board depicted in Fig. 1 left, the 
number 1 located on the second row from top indicates that 2 Minesweeper 
there is one and only one mine hidden among the eight blank 
neighbouring tiles.                                    2.1 Why Is Minesweeper Interesting? 
  Although the simplicity of its rules makes Minesweeper Minesweeper has been shown to be NP-complete by simulat•
look deceptively easy, playing the game well is indeed chal• ing boolean circuits as Minesweeper positions [Kaye, 2000]. 
lenging: A player requires logic and arithmetic reasoning to Kaye describes the Minesweeper consistency problem as the 
perform certain moves given the board state, and probabilis• problem of determining if there is some pattern of mines in 
tic reasoning to minimize the risk of uncovering a mine when the blank squares that give rise to the numbers seen in a given 


LEARNING                                                                                               533  board partially filled with numbers and marked mines, and 
 thus determining that the data given is consistent. 
   One realizes the complexity of the game by calculating an 
 estimate for the size of its search space. Consider an 8 x 8 
 board with M = 10 mines; in this case at the beginning of 
 the game the player has pq = 64 tiles from which to choose 
 a move (i.e., a tile to uncover) and in the last move, assuming 
 the player does not uncover a mine, there are 11 tiles from 
 which to choose one. This leads to possible move 
 sequences to win a game. Alternatively, one can calculate the 
probability of a random player winning a game. In the first 
 move the probability that the random player chooses a tile 
 which does not contain a mine is 54/04, and in the last move 
 it has 1/11 chance to choose the only tile without a mine. 
Then, the probability of a random player winning a game is 
                 and that is only for the easiest playing level! 
   Another measure of the complexity of Minesweeper is the 
number of games won on average by non-expert human play•
ers. To estimate the average human performance playing 
Minesweeper, we carried out an informal study. In the study, 
eleven persons who have played Minesweeper before were 
asked to play at least ten times in an 8 x 8 board with 10 
mines. Every participant was told to aim for accuracy rather 
than for speed. In this study, a person won on average 35% of 
the games with a standard deviation of 8%. 

2.2 The Learning Task 
In Minesweeper there are situations that can be "solved" with 
nontrivial reasoning. For example, consider Fig. 1 left where  concept such that and has 
the only available information about the board state are the   to find a clausal theory T which minimizes the classification 
numbers. After careful analysis one finds that the squares     error on future instances. Next we describe the background 
with an s (see Fig. 1 right) do not contain a mine, the square knowledge and the system used. 
with an m is a mine, and the state of the blank tiles cannot be 
determined if we do not know how many mines are hidden in 
                                                               3.1 Background Knowledge 
the board. There are other Minesweeper situations where the 
available information is not enough to identify a safe square  The background knowledge provides the system with infor•
or a mine, as in Fig. 2, and the best option available to the  mation about the domain and is given in the form of logic 
player is to make an informed guess, i.e., a guess that mini•  predicates (facts and rules, or clauses). A predicate is de•

mizes the risk of blowing up by uncovering a mine.             scribed as and, in our case, argi in•
   In this work, we consider the learning task in Minesweeper  dicates the argument's type. The background knowledge pro•
to be the induction of rules to identify all the safe squares^ vided to the learning system about Minesweeper is shown 
and squares with a mine which can be deduced given a board     in Table 1. The predicates in the background knowledge 
state. For instance, we want the system to learn rules to clas• were defined by trying to abstract the concepts used by hu•
sify all the blank tiles in Fig. 1 either as safe or mine.     mans when explaining their own Minesweeper playing strate•
                                                               gies. These concepts were obtained from the first author's 
3 The Learning Tools                                           Minesweeper playing experience and from Minesweeper 
                                                               pages on the web. 
In machine learning it is possible to choose between a propo-
sitional representation (in the form of attribute-value tuples)  In the predicates listed in Table 1, a TD is a determined or 
and a multirelational representation (in the form of logic pred• uncovered tile, i.e., a number 0... 8 is shown on the tile; a 
icates). A multirelational representation has the expressive•  TV is an undetermined or blank tile; Board is the board state 
ness required to describe the concepts involved when rea•      given as a list of characters 0... 8, m, u; Zone is a list 
soning about Minesweeper, and is thus more intuitive than      of determined tiles, and Set is a set of undetermined tiles to•
the propositional one. For this reason we use multirelational  gether with the number of mines hidden among those tiles. 
learning for the learning task described above. Usually a mul• In addition, each symbol preceding an argument denotes how 
tirelational learning system takes as input background knowl•  that argument should be instantiated when calling the predi•
                                                               cate, is an input argument and should be instanti•
edge B, positive (E+) and negative (E~) examples of a target 
                                                               ated to a non-variable term; is an output argument 
    A safe square is a blank tile which given the current board state and should be uninstantiated, and a indicates that the 
cannot contain a mine.                                         constant value of an output argument can appear in a rule. 


534                                                                                                           LEARNING      Predicate                                  Description 
     zoneOflnterest(+TU, +Board, -Zone)        . returns in Zone the tiles which are determined neighbours of TU and 
                                                the determined tiles which share an undetermined neighbour with them 
                                                (see Fig. 4 center). 
     totalMinesLeft(+Board,-Int) returns how many mines remained to be marked. 

     allMineslnFringe(+Board, -Set) gives the set of tiles in the fringe3 where all the remaining mines are. 
     setHasXMines(-TD, +Board, +Zone, -Set) gives in Set the undetermined neighbours of TD (TD is in Zone), 
                                                and the number of mines hidden among them (sec Fig. 4 right). 
     diffSetHasXMines(+Setl, +Set2, -Set) ... returns in Set all and only the tiles of Setl which are not also in Set2 
                                                and the number of mines hidden among the tiles in Set. 
     inSet(+TU, +Set) is true when TU is a member of Set. 
     lengthSet(+Set,+Int) is true when Set contains Int tiles. 
     minesInSet(+Set,-#Int) returns the number of mines hidden among the tiles in Set. 

                                      Table 1: Minesweeper background knowledge 

3.2 The System                                                 too much in effectiveness. We implement a greedy search 
Mio is an example-driven covering system (see Fig. 3) in•      with macros which consists of a lookahead step where all 
troduced by Pena Castillo and Wrobel [2002b] which uses        the macros are combined with each other and the best evalu•
a Progol-like declaration language and, the same as Pro-       ated clauses arc selected. Then if the selected clauses can be 
gol [Muggleton, 1995], lower bounds the search space with a    extended (refined) the system tries to combine these clauses 
most specific clause (also called bottom clause). This is      with all the macros available and selects the best candidates. 
a maximally specific clause which entails (covers) a positive  This last step is repeated until there is no clause which can be 
example e. Mio performs a general-to-specific (top-down)       extended and the best candidates are returned. 
IDA* [Korf, 1985] search to find a clause to add to the the•
ory. In addition, Mio selects stochastically the examples from Active Inductive Learning 
which it learns, performs parallel search to increase the stabil• In the covering algorithm a clause is learned which covers 
ity of the example-driven approach, and enforces type strict•  (explains) some positive examples and none (or few) negative 
ness. Three other techniques arc implemented in Mio to al•     ones; however, in domains such as games and puzzles, thou•
low the learning of Minesweeper rules: macro-operators (or     sands of examples are required to contain most of the possible 
macros, for short) to reduce the search space, greedy search   game situations; on the other hand, considering thousands of 
with macros to speed up the learning process, and active       examples when evaluating a rule slows down the learning pro•
learning to guide the exploration of the instance space.       cess. Thus, to improve the efficiency of the exploration of the 
                                                               instance space, active learning [Cohn et al, 1994] is included 
Macros 
                                                               in Mio. 
Macros in multirclational learning [Pena Castillo and Wro•
                                                                 Active inductive learning consists of the following steps. 
bel, 2002a] are a formal technique to reduce the hypothesis 
                                                               At the beginning, Mio learns from few randomly drawn ex•
space explored by a covering system. A macro is a sequence 
                                                               amples and when it has learned some clauses gives these 
of literals, chosen from the bottom clause, which is created 
                                                               clauses to an active learning server. The active learning server 
based on provider-consumer relationships between the liter•
                                                               returns to Mio counterexamples*. These counterexamples are 
als. A literal is a provider if it has output arguments, and it 
                                                               selected from examples given by a random example generator 
is a consumer if it receives as an input argument a variable 
                                                               (or random sampler). While Mio iterates on the new exam•
provided by another literal in the bottom clause. Pena and 
                                                               ples received, the server tests the rules obtained against ran•
Wrobel show that by adding macros instead of literals to a 
                                                               domly drawn examples, discards all the rules below a user-
clause, the number of clauses evaluated by the system is sig•
                                                               defined accuracy value and collects new counterexamples. 
nificantly reduced. 
                                                               This validation step on the server side avoids overfitting5. 
Greedy Search with Macros                                      These steps arc repeated until a user-defined maximum num•
In [Pena Castillo and Wrobel, 2002a] macros are used with      ber of iterations is reached or no counterexample is found. 
IDA*. It is well known that greedy search explores on av•        Active inductive learning is similar in spirit to integrative 
erage less nodes than IDA*; however, greedy search could       windowing [Furnkranz, 1998] with two main differences: in 
miss a solution because it underestimates the importance       our approach random sampling is done dynamically and a 
of provider literals without discriminative power which are    client-server architecture is used which allows to treat test•
nonetheless necessary to introduce new variables (this is      ing and learning as separated processes. 
known as the myopia problem). Since macros add several 
literals at once to a clause, they might reduce the myopia of     4 A counterexample is a positive example not covered by a set of 
greedy search allowing us to gain in efficiency without losing clauses T or a negative example covered by at least one clause in T. 
                                                                  5Overfitting refers to obtaining results with high classification 
   3Fringe refers to all the blank tiles with a determined neighbour. error over new data despite null or almost null training error. 


LEARNING                                                                                                              535  Figure 4: A rule learned by Mio. Left: Is the highlighted tile safe? Center: zoneOflntcrest corresponding to the highlighted 
 tile. Right: Applying difference operations to the sets determined by the tiles inside a circle is concluded that the tile 40 is safe 

 4 Empirical Results                                           the number of times the search is interrupted because of the 
                                                               search limit. Without active learning, overfitting occurs and 
 4.1 Improvements Obtained with each Technique                 erroneous rules are obtained. The performance of the rules 
 Experiments were carried out to determine the effects on the  obtained with IDA*+M is worse than that of the IDA* rules 
 rules obtained and on the system efficiency, of macros, greedy because Mio with macros explores a larger part of the hy•
 search with macros, and active inductive learning. To produce pothesis space and thus the IDA* + M setting overfits more 
 the training examples, we randomly generate board configu•    the training data. However, if no limit in the maximum num•
 rations and take all blank tiles with at least one determined ber of clauses explored per search is set, both settings (IDA* 
 neighbour as examples. If the blank tile does not contain a   and IDA*+M) obtain the same Riles. The running time of the 
 mine is labeled as safe, otherwise it is labeled as mine. Af• fastest setting (AL+GS+M) is 56hrs. 
 terwards, contradictory examples are removed. In the exper•   4.2 Rules Learned 
 iments, the learning task was to learn rules to identify safe Table 3 shows the rules with the highest winning rate which 
 tiles. The rule to discover mines was learned using the best  were obtained by using both AL+GS+M and AL+IDA*+M. 
 setting (i.e., using active learning, macros and greedy search). An extra rule was obtained with the latter setting; however, 
   For the completeness of this work, we ran Progol [Muggle-   this extra rule does not improve the playing performance. 
 ton and Firth, 2001] and Foil [Quinlan and Cameron-Jones,     One important feature of the rules learned by Mio is that they 
 1995] on the same learning task as Mio; however, we failed    can be applied independently of the size of the board and the 
 to make the systems learn correct rules about safe tiles. Pro• number of mines. The rules vary in complexity. Rule S-l and 
 gol search was interrupted due to search limits implemented   Rule M-l correspond to the trivial situations where a deter•
 in the system (although the maximum stack depth and res•      mined tile needs k mines and K: mines are already marked, 
 olutions steps were set to 50000 and 10000, respectively),    and where a determined tile needs k mines and it has A; blank 
 and Foil pruned determined literals which are needed. This    neighbours, respectively. 
 might imply that the optimizations included in Mio are in•      On the other hand, Rule S-3 can be seen as one of the most 
 deed necessary to learn a Minesweeper playing strategy. Ta•   complex rules because it involves three determined tiles to 
 ble 2 shows the empirical results with four Mio settings.     deduce a safe tile. Fig. 4 left shows a board state where Rule 
   All the experiments with active learning were performed     S-3 is the only one which allows to identify a safe tile. The 
 with the same seeds which means that the same training ex•    rule obtains the zoneOflntcrest corresponding to the unde•
amples are generated by the random sampler and that Mio        termined tile considered (Fig. 4 center). Then by applying 
selects the same examples to guide the search. For the exper•  difference operations on the sets determined by three uncov•
iments without active learning, we took five random samples    ered tiles from the zoneOflnterest (see Fig. 4 right), the set 
from the set of examples used in the active learning exper•    ([40], 0) is obtained and thus it is deduced that tile 40 is safe. 
iments. The size of the sample is equal to the number of 
examples received by Mio when performing active learning       4.3 Game Playing 
(40 positive and 34 negative examples). We carried out an      To evaluate the performance at game playing of each set 
extra experiment where Mio was given the complete set of       of rules obtained, we used each set of rules as the playing 
examples (2890 positive and 1306 negative) used by the ac•     strategy of an automatic Minesweeper player and calculated 
tive learning server to test Mio's rules and select counterex• the percentage of games won by the player in 1000 random 
amples; however, this experiment was stopped after Mio ran     games (see Table 2). The playing conditions were the same 
for 10 days. To reduce the running time of the experiments,    as the ones presented to the human players; i.e., at the begin•
we set the maximum number of clauses explored per search       ning the player is presented with an empty 8x8 board with 
to 4000 clauses.                                               M = 10 mines and can uncover a mine in the first move. 
   Table 2 shows that each optimization added to Mio reduces   Note that in most Minesweeper implementations, one never 
the average number of rules (nodes) explored per search and    hits a mine in the first move. 


536                                                                                                           LEARNING Table 2: Performance of various Mio settings used to learn rules about safe tiles (AL = Active Learning, GS = Greedy Search 
IDA* = Iterative Deepening A*, M = Macros) 


                                        Table 3: Minesweeper rules learned by Mio 


   Let us analyze the performance of the best rule set (see      PGMS plays using the Equation Strategy based on find•
Table 3). In 1000 games, the player made 15481 moves from      ing approximate solutions to derived integer linear equations, 
which 2762 where random guesses, 169 used Rule S-l, 10285      and probabilities. As mentioned by Ramsdell [2002], PGMS 
used Rule S-2, 54 used Rule S-3, and 2211 used Rule M-l.       represents the information available on the board as a set of 
   In addition, we examined the effect of adding probabilistic integer linear equations. Associated with an undetermined 
reasoning. In the experiment, we instructed the player us•     tile is a variable x that has the value 1 if the tile hides a mine, 
ing the rules shown in Table 3 to select a tile which mini•    or 0 otherwise. An equation is generated for each uncovered 
                                                               tile with an adjacent undetermined tile. Each equation has 
mizes the probability that an undetermined tile Tu is a 
                                                               the form , where 5 is a set of undetermined 
mine when none of the rules can be applied. is equal 
                                                               tiles, and c is the number of mines hidden among 5. To sim•
to where is a determined neighbour of 
                                                               plify notation, this equation is written as < Since the 
            returns the number of mines needed by T    and 
                                                     d         total number of hidden mines is known, an additional equa•
        returns the number of blank neighbours of Tj. Every 
                                                               tion simply equates this number with the sum of all of the 
time the player has to guess, it selects the tile which mini•
                                                               undetermined tiles. 
mizes . This player wins 579 of 1000 random games. 
                                                                 Every time a tile t is determined safe or a mine, the board 
                                                               changes are propagated to all the equations containing t and a 
5 Related Work                                                 new equation for the undetermined neighbours of t is added. 
5.1 Minesweeper Playing Programs                               In addition, ifare two equations such 
                                                               that So is a proper subset of , the equation 
There are several Minesweeper programs available on the        So is added. To determine whether a tile is safe or a mine, 
web. These programs are not learning programs but playing      PGMS iteratively applies the following rules until none are 

programs where the authors have embedded their own game        applicable7: 
playing strategy. Among these programs, John D. Ramsdell's 
PGMS is quite successful winning 60% of 10000 random 
games in a 8 x 8 board with 10 mines. 


LEARNING                                                                                                              537 