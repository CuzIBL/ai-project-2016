       Behavior Bounding: Toward Effective Comparisons of Agents & Humans* 

                                       Scott A. Wallace and John E. Laird 
                                          Artificial Intelligence Laboratory 
                                                University of Michigan 
                                                 Ann Arbor, MI 48109 


                         Abstract                              human and its computer counterpart were identified. In addi•
                                                               tion, automated behavior comparison can serve as the core of 
      In this paper, we examine methods for comparing          an intelligent tutoring system, where the roles are reversed. A 
     human and agent behavior. The results of such             novice human's behavior is compared to a computer agent's 
     a comparison can be used to validate a computer           behavior which serves as a gold standard and information 
     model of human behavior, score a Turning test, or         about the student's errors is used to guide the lesson. In all of 
     guide an intelligent tutoring system. We introduce        these applications, the basic process for comparing behavior 
     behavior bounding, an automated model-based ap•           is identical. The differences only stem from the source of be•
     proach for behavior comparison. We identify how           havior (e.g. human or machine, expert or novice) and how the 
     this approach can be used with both human and             results of the comparison are used (to identify programming 
     agent behavior. We demonstrate that it requires           errors, to score a test or to guide a lesson). For simplicity and 
     minimal human effort to use, and that it is efficient     cohesiveness, this paper will focus on using behavior compar•
     when working with complex agents. Finally, we             isons to aid the knowledge-base validation problem, but the 
     show empirical results indicating that this approach      discussion and results can also be applied to the other tasks 
     is effective at identifying behavioral problems in        as well. 
     certain types of agents and that it has superior per•
     formance when compared against two benchmarks. 
                                                               2   Interactive Human-Level Agents 
 1   Introduction                                              The need for behavior comparisons is particularly pro•
                                                               nounced when the agent must masquerade as its human coun•
 Over the past twenty years, AI research has successfully      terpart (the expert). These agents, which we term interac•
 demonstrated a number of techniques for constructing agents   tive human-level agents, are distinguished by two properties. 
 that exhibit intelligent behavior. Many applications have the First, the agent's performance is judged based on its ability 
 additional requirement that the agent's behavior be consistent to behave as the human expert would behave. Secondly, like 
 with that of a human expert. This is especially true for tasks humans themselves, interactive human-level agents must in•
 in which the agent must simulate a human such as in train•    teract with an external environment in order to perform many 
 ing situations or in virtual social experiences such as on-line of their tasks. 
 gaming. 
                                                                 A good example of an interactive human-level agent is 
   For these tasks, the standard approach to developing ex•    TacAir-Soar [Jones et al, 1999]. TacAir-Soar flics virtual 
 pert level agents begins with knowledge acquisition. Unfor•   military planes as part of a simulated training exercise. Team•
 tunately, knowledge acquisition is usually imperfect. As a re• mates may be other TacAir-Soar agents or human counter•
 sult, significant resources must be spent on validation, which parts. Because the agents are intended to model expert level 
 often requires both a knowledge engineer and domain expert    behavior, it is not acceptable just to achieve the final states 
 to monitor the agent's behavior in a large number of test sce• (e.g. shooting down the enemy planes). Instead, the agent 
 narios. In this paper, we present a method for automatically  must generate the same behavior as the expert. Meeting this 
 comparing two actors' behavior that could be used to over•    requirement is challenging because the expert may perform 
 come this validation bottleneck.                              the task differently on different occasions. 
   The potential uses of automated behavior comparison ex•
                                                                  In the remainder of this paper, we first begin by examin•
 tend well beyond knowledge-base validation. For example, a 
                                                               ing a simple method of comparing a computer agent's be•
 generalized approach for comparing two actors' behavior can 
                                                               havior to a human expert's behavior. Deficiencies with this 
 be used to objectively score a Turing test. A perfect result 
                                                               method lead us to examine more sophisticated model-based 
 would be indicated if no detectable differences between the 
                                                               approaches. In Section 4 we summarize desirable features of 
   *This work was supported by the Office of Naval Research, con• such an approach. Then, beginning in Section 5, we present 
tract N61339-99-C-O104                                         our method of model-based behavior comparison. 


 MULTIAGENT SYSTEMS                                                                                                   727  3   Toward Automated Behavior Comparison                      it impossible to leverage regularities that might exist in large 
 Before two actors' behavior can be compared, the behav•       classes of goal directed tasks. 
 ior must be represented in a form that can be processed 
 by the comparison algorithm. We can do this most eas•         4    Model Based Approaches 
 ily by storing individual instances of behavior, or behav•    To improve upon the simple approach for automated error de•
 ior traces. A behavior trace is a sequence of tuples B —      tection described in Section 3, we propose a model-based ap•
                                       in which each tuple     proach to comparing actors' behavior. Central to any such ap•
          indicates the environmental state (s), the goals be• proach are the properties of the behavioral model. Our choice 
 ing pursued by the actor (G), and the action being performed  is guided by the following requirements: 
 (a). The state and action portion of the behavior trace can be Low Complexity Unless the new model is significantly less 
 captured by observing the actor perform the specified task.        complex than the agent's knowledge base, understand•
 The actor's goals are necessary to disambiguate instances          ing the model and the behavior it represents is no eas•
 when different actions are performed in equivalent environ•        ier than examining the knowledge base directly. For the 
 mental states. Depending on whether the actor is human or 
                                                                    model to be an asset, it must provide an adequately ac•
 computer agent, the actor may need to record how their goals 
                                                                    curate representation of behavior while remaining easy 
 change during the task. 
                                                                    to understand. 
   A simple approach to comparing the actor's behavior can 
be performed with the following steps:                         Low Effort We have argued that one of the main uses of the 
                                                                    behavior comparison is to reduce the cost of validating 
Acquire a set of behavior traces from the human expert and          a human-level agent. In order to accomplish this goal, 
     the agent for the specified task. These sets, H and A,         the human effort required to build the behavioral models 
     represent the human expert's and agent's behavior re•          must remain low. 
     spectively over a number of different trials. 
                                                               Compatibility Behavior comparison has a number of poten•
 Extract relevant features from the behavior traces. Some in•       tial applications, but most rely on being able to examine 
     formation gathered through observation may not be use•         both human and software agent behavior. Thus the rep•
     ful to detect errors. In this step, the salient features from  resentation must be limited to data that can be collected 
     the sets H and A are used to create two new sets of se•        from either of these types of participants. 
     quences and  
                                                               Efficiency Human-level agents operate in complex environ•
Compare each sequence to the contents of                            ments and may perform their tasks in a variety of differ•
     Compute the minimal number of edit operations (insert,         ent ways. To address this problem, a model may be built 
     delete, modify) that would be required to transform a          using observations of expert behavior. In this case, it 
     into /i, where h is the sequence in that is most simi•         must be possible to generate the model efficiently, even 
     lar to a. Each edit operation indicates a potential error.     if many observations are required. 
Report all deviations (after removing any redundancies) be•    Efficacy Meeting the preceding requirements will come at 
     tween the human's and agent's behavior. This report            a cost. Most likely this will be a decreased ability to 
     summarizes all potential errors.                               distinguish between some types of behavioral deviations 
   This simple approach performs a more detailed analysis of        (potential errors). A good representation will nonethe•
behavior than simply checking that the agent and the expert         less be able to identify a wide range of behavioral devi•
reach the same final (goal) state. In this way, the agent's ex•     ations that are likely to occur within the target environ•
ternally observable behavior as well as some aspects of its         ments and overlook meaningless differences. 
internal reasoning process can be inspected to ensure that it is Prior work in model-based diagnosis (e.g. [Lucas, 1998]) 
consistent with the human expert's. In addition, this method•  has examined how to detect errors given a model of correct 
ology has the ability to identify a large number of possible   behavior. In general, however, the models in these systems 
errors because it has access to all the salient properties of the are relatively complicated and intended to identify problems 
behavior trace.                                                with mechanical or solid state devices as opposed to software 
   However, this simple approach also suffers from a num•      agents. However, one system, CLIPS-R [Murphy and Paz-
ber of potentially serious flaws. First, the representation of zani, 1994] was designed expressly for validating software 
the actors' behavior is a set of sequences extracted from the  agents. 
behavior traces. These sets grow as more observations are        In CLIPS-R, the behavior model consists of environmen•
considered. Because interactive human-level agents can typ•    tal constraints that must be met initially, as well as during 
ically solve problems in a number of different ways, and be•   and after task execution. In addition, the model can include 
cause the environments they operate within are complex, it     a finite state machine which identifies acceptable sequences 
is likely that a very large number of observations will be re• of actions pursued by the agent. Superficially, the require•
quired to adequately cover the actor's behavior. This problem  ments for the CLIPS-R approach seem relatively simple to 
is exacerbated by the fact that the sequential representation  meet. However, specifying this additional knowledge is a 
makes no assumption about how the actor's behavior might       manual process that can significantly increase human effort 
be constrained. Although this makes it possible to use this    and ironically can introduce a recursive validation problem 
simple approach with any variety of behavior, it also makes    for the constraints. 


728                                                                                             MULTIAGENT SYSTEMS 5    Behavior Bounding 
As an improvement to CLIPS-R and to the simple method 
presented in Section 3, our approach to behavior comparison, 
called behavior bounding, automatically and efficiently builds 
concise models of both the human's and agent's behavior by 
examining behavior traces. The model of the expert's behav•
ior is used to identify boundaries on acceptable behavior, and 
potential errors are reported by comparing the model of agent 
behavior to these boundaries. 

5,1   A Hierarchical Model                                     Figure 1: Hierarchical Behavior Representation & Goal Stack 
The advantages of behavior bounding all stem from its rep•
resentation of behavior. Behavior bounding is inspired by 
                                                                 In contrast to the behavior representations used for the 
the hierarchical representations used in AND/OR trees, HTN 
                                                               simple comparison described in Section 3, the HBR makes 
planning [Erol et al., 1994] and GOMS modeling [John and 
                                                               two strong assumptions about the organization of the actors' 
Kieras, 1996] to encode the variety of ways in which particu•
                                                               knowledge and the effects this will have on their behavior. 
lar tasks can be accomplished. 
                                                               These assumptions increase the efficiency and efficacy of er•
   The hierarchical behavior representation (HBR) used in      ror detection for certain types of human-level agents. 
our approach is illustrated in Figure 1A. The hierarchy is 
                                                                 The first assumption used by the behavior bounding ap•
an AND/OR tree with binary temporal constraints represent•
                                                               proach is that the actor's goals are organized hierarchically, 
ing the relationships between the actor's goals and actions. 
                                                               with more abstract goals placed toward the top of the tree. 
In this representation, internal nodes correspond to goals 
                                                               We also assume that at any point in the problem solving pro•
and leaves correspond to primitive actions. A node's chil•
                                                               cess the actor pursues a set of goals belonging to different 
dren indicates the set of sub-goals or primitive actions that 
                                                               levels in the hierarchy. This set, referred to as the goal stack, 
are relevant to accomplishing the specified goal. For ex•
                                                               corresponds to a path in the hierarchy beginning at the top 
ample, in Figure 1A, the sub-goals Destroy-Lead and 
                                                               node and descending to the most concrete sub-goal that is 
Destroy-Wingman are relevant for completing their par•
                                                               currently being pursued by the actor. Figure IB illustrates a 
ent goal, Engage - Enemy. The manner in which sub-goals 
                                                               possible goal stack maintained by the actor whose behavior is 
should be used to achieve their parent goal is encoded by the 
                                                               represented in Figure 1 A. 
parent's node-type constraint (AND vs OR) and the ordering 
constraints between sub-goals. In Figure 1A, AND and OR          The second assumption leveraged by behavior bounding 
nodes are represented with ovals and rectangles respectively.  relates to the independence of goals. Temporal constraints 
Binary temporal constraints are represented with arrows be•    can only be formed between sibling nodes, and AND/OR clas•
tween siblings. Thus, the hierarchy specifies that Engage -    sification determines which of a node's children must be per•
Enemy may be correctly accomplished by first accomplish•       formed for a particular task. This makes it is easy to con•
ing Destroy-Lead and then accomplishing Destroy-               strain the way a particular goal is achieved, but difficult to 
Wingman.                                                       represent constraints between arbitrary parts of the hierarchy. 
                                                               Although this may cause problems with some agent imple•
   This model of behavior is clearly less complex than the 
                                                               mentations, this property has significant benefits. Most im•
agent's underlying knowledge base, indeed, it is likely to 
                                                               portantly, it decreases the number of observations that are re•
be less complex than the model used by CLIPS-R. Behav•
                                                               quired. Consider a task that requires completing two goals, 
ior bounding abstracts away internal data-structures the agent 
                                                               each of which could be fulfilled in four distinct ways. A se•
may use in problem solving that cannot be represented by the 
                                                               quential representation that makes no assumptions about goal 
constraints in the hierarchy. This means, that the HBR alone 
                                                               independence (such as the one described in Section 3) would 
could not be used to perform some basic tasks such as depth 
                                                               require sixteen distinct observations to cover the acceptable 
first search. This begs the question, if the agent's behavior 
                                                               behavior space where as behavior bounding would only re•
can be represented using such a simple structure, why was 
                                                               quire four observations. This significant impact on efficiency 
it not programmed in this representation to begin with? The 
                                                               is the direct result of leveraging the assumption about how 
hypothesis here is not that this representation is sufficient to 
                                                               goals are likely to add regular structure to an actor's behav•
completely capture the agent's behavior. Most human-level 
                                                               ior. 
agents do rely on intermediate data-structures that are not 
available through the environment or through the structure 
                                                               5.2   Identifying Errors 
of the goal hierarchy. However, our hypothesis is that the 
representation provided by behavior bounding is sufficient to  In general, we can view a behavior comparison method as an 
identify a large class of possible errors in agent behavior with• algorithm which divides the space of possible behaviors into 
out sacrificing efficiency. Moreover, we believe that behavior two regions: behaviors that are likely to be consistent with 
bounding can also help identify potential problem spots in the the expert, and behaviors that are likely to be inconsistent 
agent's knowledge (e.g. a specific goal) even if an exact error with the expert. The simple comparison method described 
cannot be identified.                                          in Section 3 does this by enumerating consistent behaviors. 


MULTIAGENT SYSTEMS                                                                                                    729                                                                traces of an actor's performance on a task thus meeting the 
                                                               second requirement (low human effort). And because the be•
                                                               havior traces can be captured from either human or agent be•
                                                               havior with only minor support from the human participant, 
                                                               this model meets the third requirement. In the following sec•
                                                               tions, we will examine the remaining requirements in detail. 

                                                               6   Learnability 
                                                               In this section, we examine two aspects of behavior bound-
                                                               ing's hierarchical representation: the effort required to cre•
                                                               ate and maintain it, and its ability to represent behavior effi•
      Figure 2: Imposing Order on the Behavior Space           ciently. Both of these requirements are addressed by the over•
                                                               all learnability of the representation. That is, if the representa•
                                                               tion can be learned from observations (as we have suggested), 
 In behavior bounding, however, the constrained hierarchical   then it requires human effort only to initiate the learning pro-
representation allows us to break the space of possible behav• cess. If the learning procedure is efficient, and the data struc-
iors into more refined regions.                                ture's growth is limited, we can further say that the hierarchy 
   We begin by noting that the constrained hierarchical rep•   represents behavior efficiently. 
resentation allows us impose order on the space of possi•        The learning procedure for constructing the HBR extracts 
ble behaviors. In particular, we can define an ordering from   goal stacks and actions from a behavior trace, forming a hi•
specific to general over the behavior hierarchies, by starting erarchical structure such as the one illustrated in the previ•
with a maximally constrained hierarchy (at the top) and it-    ous section. After processing the first behavior trace, the 
eratively removing constraints until none remain. Construct•   hierarchy contains the maximum number of constraints (i.e. 
ing a representation of an expert's behavior (Section 6) per•  AND/OR constraints on the goals and binary temporal con•
forms this same generalization, but most often stops before    straints between siblings) that are consistent with the behavior 
all constraints have been removed. Figure 2, in which each     in the trace. So, if each goal in the hierarchy is pursued only 
node represents a behavior hierarchy, illustrates this ordering. once while performing the task, all internal node-types are 
Once we have created a representation for the expert's behav•  AND (maximally constrained) and all sibling internal nodes 
ior, we can identify the node it occupies in this ordered space are totally ordered (again, maximally constrained)., Upon 
(call this node A in Figure 2). This node (the upper boundary  examining subsequent behavior traces, the hierarchy is gen-
node) allows us to easily determine if the agent's behavior is eralized in such a way that it remains maximally constrained 
likely to be correct. Because correct behavior must be con•    with respect to all of the behavior traces it has processed. 
sistent with expert behavior, an agent whose behavior repre•     Due to page limitations, we cannot present the learning al•
sentation is a specialization of the expert's (i.e. lies above A gorithm in detail, however it should be clear that the hierarchy 
in the generalization lattice) exhibits behavior that is is likely can be built as described above with complexity 
to be correct.                                                 where is the size of the goal hierarchy and L is the length 
   The node that represents the completely unconstrained goal  of the behavior trace. In most cases, it is reasonable to as•
hierarchy is at the bottom of Figure 2 (labeled B) and provides sume that one property of expert quality behavior is comple•
a lower boundary. It contains the most basic specification     tion of the task within a number of steps proportional to 
for what may constitute acceptable agent behavior and as a     When this assumption holds, we can say that this algorithm 
result could be used to identify behavior representations that is bounded by \ in time and space, with respect to the 
are known to be incorrect. Such representations would have a   size of the input (i.e. the length of the behavior trace). Be•
goal decomposition structure that was inconsistent with (i.e.  cause this complexity is a low order polynomial of the 
contained different parent/child relationships than) this lower hierarchy is efficient when encoding an instance of behavior. 
boundary (nodes in the right side of Figure 2).                  We can also classify the sample complexity of our hier•
   Using the upper and lower boundaries described above we     archical representation. We can think of our representation 
can classify any representation of agent behavior as: likely-  as an ordered tuple P = where each pi 
correct (a specialization of the expert's behavior representa• is itself a tuple containing the type of the node z (either 
tion); likely-incorrect (a specialization of the expert's goal AND or OR), as well as a list L = such 
decomposition structure); and known-incorrect (inconsistent    that iff is ordered before Note that since ordering 
with the expert's goal decomposition structure).               constraints only occur between siblings, the length of the list 
  Clearly, the hierarchical representation used by our ap-     L would only need to be length in the degenerate case. 
proach describes behavior at a much higher level of abstrac•   The size of this hypothesis space is bounded by  
tion than a typical knowledge base and in so doing, it presents Using Haussler's equation [Haussler, 1988], the number of 
a much more concise illustration of potential behavior than, 
for example, a set of individual rules. As a result, it meets our 'The leaves, representing primitive actions, will only be totally 
first requirement (low complexity). In addition, this represen• ordered if each action was used only a single time to achieve its 
tation can be generated automatically by examining behavior    parent goal. 


730                                                                                             MULTIAGENT SYSTEMS training examples m required to learn the appropriate behav•   when given the task, the agent must plan a route through 
 ior representation is bounded by:                             known territory to a building thought to contain the desired 
                                                               artifact. Because the agent has no prior knowledge of the 
                                                               building's layout, it must explore the facility until the object 
                                                               is found, and then find its way back out. The task is complete 
   This indicates that the required sample size is polynomial  once the agent leaves the building with the object. A behavior 
with respect to the number of goals in the hierarchy (\N\).    comparison metric's performance is judged based its ability 
This, together with the fact that the time required to incorpo• to correctly identify errors in agent behavior, to identify all 
 rate a new behavior trace into the learned HBR is also polyno• errors that have occurred, and to produce minimal amounts 
mial in lNl, shows that our representation is PAC-Learnable.   of spurious information in the report. 
This means that the HBR efficiently represents aggregate be•
                                                               7.1   Methodology 
havior as well an individual instance of behavior, thus meet•
 ing our fourth requirement.                                   We implemented the algorithm described in Section 6, 
                                                               along with two version of the simple approach de•
7    Efficacy                                                  scribed in Section 3 to serve as benchmarks. The 
                                                               first benchmark, the action sequence, extracts the se•
The efficacy of behavior bounding is addressed by two com•     quence from the behavior trace 
ponents. First, how good is the unconstrained hierarchical     B — while the sec•
representation (the lower boundary) at identifying behavior    ond benchmark extracts the sequence of goals G = 
that is known to be incorrect. Second, how well does the       (Go, Gi,..., from B. Remember that the benchmarks 
expert's representation (the upper boundary) serve to distin•  are not particularly efficient representations; they can grow 
guish between potentially correct and incorrect behavior.      exponentially and have an exponential sample complexity. 
   At first glance, it is not obvious how much behavior can be However, they do make interesting benchmarks of efficacy. 
filtered by the lower boundary. However, its effectiveness as a  We initially constructed an agent that solves the problem 
filter is quite surprising. Consider an unconstrained behavior in a very rigid manner. That is, across different attempts, 
representation with branching factor b and depth d. Without    the agent will complete the task using identical behavior so 
loss of generality, assume that the nodes are uniquely labeled. long as it is provided identical initial states and so long as the 
For simplicity, also assume that at any level in this hierar•  environment responds identically to its behavior. Given this 
chy, the actor completes its current goal before starting the  agent, we performed modifications on its knowledge-base by 
next goal. Then, we could define an actor's behavior as a      randomly removing rules that determine preferences between 
sequence of symbols chosen from the lowest level of the un•    competing goals and actions. The results of these modifica•
constrained hierarchy. For behavior sequences of length bd,    tions are agents that complete the task successfully in the tra•
in which no symbol is repeated, there are                      ditional sense (i.e. they reach the same end state), but have 
possible sequences that are consistent with the goal decom•    increased flexibility in terms of the sequence of goals and 
position of the unconstrained hierarchy. In contrast, there are actions they use to achieve that final state. In addition, the 
bd\ sequences in which the symbols may be placed without       behavior exhibited by these modified agent's cannot be clas•
necessarily conforming to the unconstrained hierarchy. For     sified as incorrect by the lower behavior boundary node. As 
a hierarchical structure of depth 4 and branching factor 2,    a result, these tests directly examine the abilities of the upper 
only 1 in approximately 6.4 • 108 of the possible sequences    boundary node to distinguish between correct and incorrect 
of length 16 are consistent with the goal decomposition spec•  behavior. 
ified by the unconstrained hierarchy. This illustrates the po•   Each family of experiments begins by selecting two agents, 
tential power of the lower behavior boundary to discriminate   e and n, such that n is a modified (more flexible) version of 
between behavior that is potentially correct and the large col• e. We designate e as the expert, and n as the novice. Because 
lection of behavior that is inconsistent with the expert's goal n is more flexible than e, it will behave in certain ways that 
decomposition structure, and thus known to be incorrect.       are not consistent with expert behavior—these are errors. 
   To examine how well the expert's representation distin•       After the expert and novice have been selected, they are 
guishes between correct and incorrect behavior we would ide•   individually incorporated into a simulation so their behavior 
ally examine a large set of hand-programmed agents before      can be observed. We then gather between 10 and 15 behavior 
they have been validated. Unfortunately, this is not feasi•    traces of the actors performing their task, ensuring that no two 
ble. Instead, we make random modifications to an agent's       behavior traces are identical. These traces form the sets 
knowledge base. These modifications introduce unbiased be•     and for the expert and novice respectively. Finally, each 
havioral flaws in the agent program, and experiments are per•  behavior trace in is examined manually to determine 
formed to determine how well each type of error is identified. what errors it contains. 
Because the modifications are made randomly, the errors that     The captured behavior traces are then split into a number 
are examined will not be biased by our expectations about      of subsets: and A single experi•
how easily they will be to identified.                         ment consists of examining each comparison method's per•
   Our experiments are performed on a series of agents within  formance on a pair of these subsets and , A family 
a simulated object-retrieval environment. The object-retrieval of experiments contains the experiments that compare all 
task requires both planning and reactive reasoning. Initially, to all for a particular novice/expert pair. Thus comparing 


MULTIAGENT SYSTEMS                                                                                                    731 