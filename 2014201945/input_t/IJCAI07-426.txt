                                                 involved in several biological processes. In this paper we 
                                                 make the biologically plausible simplifying assumption 
    Although clustering is probably the most fre-
                                                 that the overlap of influences (biological processes) is 
    quently used tool for data mining gene expres- additive
    sion data, existing clustering approaches face at 
                                                   X  =   X (s, g | c)                  (1) 
    least one of the following problems in this do- sg   c
    main: a huge number of variables (genes) as  where Xsg is the expression level of gene g in data sample 
    compared to the number of samples, high noise s, while X(s,g ⎢c) is the expression level of g in s due to 
    levels, the inability to naturally deal with over- biological process c. We also assume that X(s,g ⎢c) is 
    lapping clusters, the instability of the resulting multiplicatively decomposable into the expression level 
    clusters w.r.t. the initialization of the algorithm Asc of the biological process (cluster) c in sample s and 
    as well as the difficulty in clustering genes and the membership degree Scg of gene g in c:
    samples simultaneously. In this paper we show         =   ⋅
                                                   X(s,g | c) Asc Scg                  (2) 
    that all of these problems can be elegantly dealt 
    with by using nonnegative matrix factorizations Fuzzy k-means [Bezdek, 1981] or Nonnegative Matrix 
    to cluster genes and samples simultaneously  Factorization (NMF) [Lee and Seung, 2001] could be 
    while allowing for bicluster overlaps and by em- used to produce potentially overlapping clusters, but 
    ploying Positive Tensor Factorization to perform these approaches are affected by the instability of the 
    a two-way meta-clustering of the biclusters pro- resulting clusters w.r.t. the initialization of the algorithm. 
    duced in several different clustering runs   This is not surprising if we adopt a unifying view of clus-
    (thereby addressing the above-mentioned insta- tering as a constrained optimization problem, since the 
    bility). The application of our approach to a fitness landscape of such a complex problem may involve 
    large lung cancer dataset proved computationally many different local minima into which the algorithm 
    tractable and was able to recover the histological may get caught when started off from different initial 
    classification of the various cancer subtypes rep- states. Although such an instability seems hard to avoid, 
    resented in the dataset.                     we may be interested in the clusters that keep reappearing 
                                                 in the majority of the runs of the algorithm. This is re-
                                                 lated to the problem of combining multiple clustering 
                                                 systems, which is the unsupervised analog of the classi-
The recent advent of high-throughput experimental data, fier combination problem but involves solving an addi-
especially in molecular biology and genomics, poses new tional so-called cluster correspondence problem, which 
challenges to existing data mining tools. Measuring the amounts to finding the best matches between clusters 
expression levels of virtually every gene of a given or- generated in different runs. 
ganism in a given state has become a routine procedure in The cluster correspondence problem can also be cast as 
many research labs worldwide and has also reached the an unsupervised optimization problem, which can be 
commercial stage in the last decade. Such gene chips, or solved by a meta-clustering algorithm. Choosing an ap-
microarrays, could in principle be used to determine the propriate meta-clustering algorithm for dealing with this 
variation in gene expression profiles responsible for com- problem crucially depends on the precise notion of clus-
plex diseases, such as cancer. However, the large num- ter correspondence.
bers of genes involved (up to a few tens of thousands) Since a very strict notion of perfect one-to-one corre-
compared to the small number of samples (tens to a few spondence between the clusters of each pair of clustering 
hundreds), as well as the large experimental noise levels runs may be too tough to be realized in most practical 
pose significant challenges to current data mining tools. cases, we could look for clusters that are most similar
  Moreover, most currently used clustering algorithms (although not necessarily identical) across all runs. This 
produce non-overlapping clusters, which represents a is closest to performing something similar to single-
 serious limitation in this domain, since a gene is typically linkage hierarchical clustering on the sets of clusters pro-


                                            IJCAI-07
                                             2651duced in the various clustering runs, with the additional the optimization problem (5), (4) is non-convex. In par-
constraint of allowing in each meta-cluster no more than ticular, the NMF algorithm produces different factoriza-
a single cluster from each individual run. Unfortunately, tions (biclusters) (A(i),S(i)) for different initializations, so 
this constraint will render the meta-clustering algorithm meta-clustering the resulting “soft” clusters might be 
highly unstable. Thus, while trying to address the insta- needed to obtain a more stable set of clusters. However, 
bility of (object-level) clustering using meta-level clus- using a “hard” meta-clustering algorithm would once 
tering, we end up with instability in the meta-clustering again entail an unwanted instability.
algorithm itself. Therefore, a “softer” notion of cluster In this paper we use Positive Tensor Factorization 
correspondence is needed.                        (PTF) as a “soft” meta-clustering approach able to deal 
  In a previous paper [Badea, 2005], we have shown that with biclusters. This not only alleviates the instability of 
a generalization of NMF called Positive Tensor Factori- a “hard” meta-clustering algorithm, but also produces a 
zation [Welling and Weber, 2001] is precisely the tool “base” set of “bicluster prototypes”, out of which all bi-
needed for meta-clustering “soft”, potentially overlap- clusters of all individual runs can be recomposed, despite 
ping biclusters produced in different clustering runs by the fact that they may not correspond to identically reoc-
fuzzy k-means or NMF. Here we demonstrate that this curring clusters in all individual runs. 
approach can be successfully used for biclustering a large 
lung cancer gene expression dataset. 

                                                 We use NMF for object-level clustering and PTF for 
                                                 meta-clustering. This unified approach solves in an ele-
                                                 gant manner both the clustering and the cluster corre-
Combining (1) and (2) leads to a reformulation of our spondence problem. More precisely, we first run NMF as 
clustering problem as a nonnegative factorization of the object-level clustering r times: 
n ×n  (samples × genes) gene expression matrix X as a 
 s  g                                              X  ≈ A ( i ) ⋅ S ( i ) i = 1,..., r             (6)
product of an n ×n (samples × clusters) matrix A and an 
             s c                                 where X is the gene expression matrix to be factorized 
n ×n  (clusters × genes) matrix S:
 c  g                                            (samples × genes), A(i) (samples × clusters) and S(i) (clus-
   X  ≈    A  ⋅ S                     (3)           ×
    sg    c sc  cg                               ters  genes). 
                                                   To allow the comparison of membership degrees Scg
with the additional nonnegativity constraints:   for different clusters c, we scale the rows of S(i) to unit 
  Asc ≥ 0, Scg ≥ 0.                   (4)        norm by taking advantage of the scaling invariance of the 
                                                                                   −1
(Expression levels and membership degrees cannot be above factorization (6): A ← A ⋅ D, S ← D ⋅ S, where D
negative.) More formally, this can be cast as a con- is a positive diagonal matrix with elements 
strained optimization problem:                   d  =     S 2 .
            1           1                         c      g cg
   min C(A, S) = || X − A⋅ S ||2 = X − A⋅ S 2       (5) 
            2         F 2          sg              Next, we perform meta-clustering of the resulting bi-
                          s,g                    clusters (A(i), S(i)). This is in contrast with as far as we 
subject to the nonnegativity constraints (4), and could be know all existing meta-clustering approaches, which take 
solved using Lee and Seung’s seminal Nonnegative Ma- only one dimension into account (either the object- or the 
trix Factorization (NMF) algorithm [Lee and Seung, sample dimension). Although such one-way approaches 
2001] (ε is a small regularization parameter):   work well in many cases, they will fail whenever two 
                                                 clusters correspond to very similar sets of genes, while 
NMF(X,  A0, S0) → (A,S)
  ←      ←                                       differing along the sample dimension.
A    A0, S S0 (typically A0,S0 are initialized randomly) In the following, we show that a slight generalization 
loop until convergence                           of NMF, namely Positive Tensor Factorization (PTF)
            (AT ⋅ X )
   S ←  S         cg                             [Welling and Weber, 2001] can be successfully used to 
    cg   cg T ⋅ ⋅  + ε
          (A  A S)cg                             perform two-way meta-clustering, taking both the gene 
                                                 and the sample dimensions into account.
             ( X ⋅ S T )
     ←             sc
   Asc  Asc      T                                 Naively, one would be tempted to try clustering the bi-
             ⋅ ⋅    + ε                                1
          ( A S S ) sc                                   (i ) ⋅ (i )                 (i )
                                                 clusters Ac Sc instead of the gene clusters Sc , but this 
  As explained above, such a factorization can be viewed is practically infeasible in most real-life datasets because 
as a “soft” clustering algorithm allowing for overlapping it involves factorizing a matrix of size r⋅ nc × ns⋅ ng. On
clusters, since we may have several significant Scg entries closer inspection, however, it turns out that it is not nec-
on a given column g of S (so a gene g may “belong” to essary to construct this full-blown matrix – actually we 
 several clusters c).
  Allowing for cluster overlap alleviates but does not 1 A(i ) is the column c of A(i), while S (i) is the row c of S(i).
 completely eliminate the instability of clustering, since c              c


                                            IJCAI-07
                                             2652are searching for a Positive Tensor Factorization of this where ‘∗’ and ‘−−’ denote element-wise multiplication 
matrix 2                                         and division of matrices, while ‘⋅’ is ordinary matrix mul-
    (i) ⋅ (i) ≈ nc α (i) ⋅ β ⋅γ             (7)  tiplication.
   Asc Scg    = ck  sk  kg
             k 1                                   After convergence of the PTF update rules, we make 
The indices in (7) have the following domains: s – sam-
                                                 the prototype gene clusters directly comparable to each 
ples, g – genes, c – clusters, k – metaclusters. To simplify                γ
the notation, we merge the indices i and c into a single other by normalizing the rows of to unit norm, as well 
                                                 as the columns of α such that α = r  (r being the 
 index (ic):                                                                i,c (ic)k
                n
   A   ⋅ S  ≈    c α  ⋅ β ⋅γ          (7’)                                                 β γ
    s(ic ) (ic ) g k =1 (ic )k sk kg             number of runs) and then run NMF initialized with ( , )
Note that β and γ are the “unified” versions of A(i) and S(i) to produce the final factorization X ≈ A⋅S.
respectively. More precisely, the columns β⋅k of β and the 
corresponding rows γk⋅ of γ  make up a base set of biclus-
ter prototypes β⋅k⋅γk⋅ out of which all biclusters of all in-
dividual runs can be recomposed, while α encodes the Before addressing real-world gene expression datasets, 
(bi)cluster-metacluster correspondence.          we evaluated our algorithm on synthetic datasets that 
  Ideally (in case of a perfect one-to-one correspondence match as closely as possible real microarray data. Clus-
of biclusters across runs), we would expect the rows of α ters were modelled using a hidden-variable graphical 
                                                 model, in which each hidden variable A  corresponds to 
to contain a single significant entry α(ic),m(i,c), so that each                 c
         (i ) ⋅ (i )                             the cluster of genes influenced by Ac (clusters can over-
bicluster Ac S c corresponds to a single bicluster proto-
                                                 lap since an observable variable Xg can be influenced by 
    β⋅   ⋅γ   ⋅
type  m(i,c) m(i,c)  (where m(i,c) is a function of i and c): several hidden variables Ac).
    (i ) ⋅ (i ) = α ⋅ β ⋅γ             (8)         Since real-world microarray data are log-normally dis-
   Ac  S c   (ic ),m (i,c) ⋅m (i,c ) m(i,c )⋅
                                                 tributed, we sampled the hidden variables from a log2-
Additionally, each metacluster m should contain no more normal distribution with parameters μ=2, σ=0.5, while 
than a single bicluster from each run, i.e. there should be the influence coefficients Scg between hidden and observ-
                  α       α         ≠            able variables were sampled from a uniform distribution 
no significant entries (ic'),m and (ic"),m  with c'  c".
                                                 over the interval [1,2]. Finally, we added log -normally
  Although it could be easily solved by a hard meta-                                  2
                                                 distributed noise ε with parameters μnoise=0, σnoise=0.5.
clustering algorithm, such an ideal cluster correspon- Thus we generated our data using the model X = A⋅S +ε.
dence is only very seldom encountered in practice, 
                                                   We used nsamples=50, ngenes=100 and a number of genes 
mainly due to the instability of most clustering algo- (respectively samples) per cluster 30 (respectively 15). 
 rithms. Thus, instead of such a perfect correspondence We compared 4 meta-clustering algorithms (fuzzy k-
 (8), we settle for a weaker one (7’) in which the rows of means, NMF, PTF and the best run3) over 10 object-level 
α
  can contain several significant entries, so that all bi- NMF clustering runs. (Other object level clustering 
clusters (i ) ⋅ (i ) are recovered as combinations of biclus-
       Ac  S c                                   methods perform very poorly and are not shown here).
ter prototypes β⋅k⋅γk⋅.                            Figures 1-3 below present a comparison of the meta-
  The nonnegativity constraints of PTF meta-clustering clustering algorithms w.r.t. the number of clusters (rang-
are essential both for allowing the interpretation of β⋅k⋅γk. ing from 2 to 16). The Figures depict average values over 
as bicluster prototypes, as well as for obtaining sparse 10 separate runs of the whole algorithm (with different 
factorizations. (In practice, the rows of α tend to contain randomly generated clusters), as well as the associated 
typically one or only very few significant entries.) SEM (Standard Error of the Mean) bars. Note that al-
  The factorization (7’) can be computed using the fol- though all algorithms produce quite low relative er-
                                                                             4
lowing multiplicative update rules:              rorsε =|| X −A⋅S ||/ || X || (under 16%) , they behave quite 
              T ⋅ β ∗ ⋅γ T                           rel
   α ← α ∗  (A   ) (S   )                        differently when it comes to recovering the original clus-
          α ⋅[(β T ⋅ β ) ∗ (γ ⋅γ T )]            ters. In a certain way, the match of the recovered clusters 
            A⋅[α ∗ (S ⋅γ T )]                    with the original ones is more important than the relative 
   β ← β ∗                            (9)        error (see [Badea, 2005] for the definition of the match
          β ⋅[(α T ⋅α) ∗ (γ ⋅γ T )]
                                                 between two sets of possibly overlapping clusters).
            α ∗  T ⋅ β T ⋅
   γ ← γ ∗ [   (A   )] S                           Figure 2 shows that PTF consistently outperforms the 
         [(α T ⋅α) ∗ (β T ⋅ β )]T ⋅γ             other meta-clustering algorithms in terms of recovering 
                                                 the original clusters. Note that since clusters were gener-
                                                 ated randomly, their overlap increases with their number, 
2 By solving the constrained optimization problem
                        n        2
            1   ⎛       c       ⎞   α β γ≥       3
 min C(α,β,γ ) = ⎜ A(i) S (i) − α (i) β γ ⎟  s.t. , , 0.  i.e. the one with the smallest relative error. 
                ⎜ sc cg   ck sk kg ⎟             4
            2 i,1c,s,g ⎝ k=     ⎠                 Except for fuzzy k-means which misbehaves for large numbers of 
                                                 clusters.


                                            IJCAI-07
                                             2653so it is increasingly difficult for the meta-clustering algo- Among all object-level clustering algorithms tried (k-
rithm to discern between them, leading to a decreasing means, fuzzy k-means and NMF), only NMF behaves 
match.                                           consistently well. The conceptual elegance of the combi-
                                                 nation of NMF as object-level clustering and PTF as 
                                                 meta-clustering thus pays off in terms of performance. 


                                                 We applied our meta-clustering approach to a large lung 
                                                 cancer microarray dataset available from the Meyerson 
                                                 lab at Harvard. Using HG-U95Av2 Affymetrix oligonu-
                                                 cleotide microarrays, Bhattacharjee et al. [2001] have 
                                                 measured mRNA expression levels of 12600 genes in 186 
                                                 lung tumor samples (139 adenocarcinomas, 21 squamous 
                                                 cell lung carcinomas, 6 small cell lung cancers, 20 pul-
                                                 monary carcinoids) and 17 normal lung samples (203 
                                                 samples in total). Whereas the non-adeno classes are 
                                                 more or less well defined histologically, adenocarcino-
     Figure 1. Relative errors versus number of clusters mas are very heterogeneous, with poorly defined histo-
                                                 logical and molecular level sub-classifications, despite 
                                                 the large variability in survival times and responsiveness 
                                                 to medication. Therefore, we applied our algorithm to the 
                                                 full dataset and used the histological classification of the 
                                                 non-adeno samples (provided in the supplementary mate-
                                                 rial to the original paper) as a gold standard for the 
                                                 evaluation of the biclustering results. 
                                                   To eliminate the bias towards genes with high expres-
                                                 sion values, the gene expression matrix was normalized 
                                                 by separate scalings of the genes to equalize their norms.5
                                                   Although nonnegative factorizations have the advan-
                                                 tage of obtaining sparse and easily interpretable decom-
                                                 positions, they cannot directly account for gene down-
                                                 regulation. To deal with gene down-regulation in the con-
                                                 text of NMF, we extended the gene expression matrix 
                                                 with new “down-regulated genes” g’ = pos(mean(gnormal)
      Figure 2. Mean match versus number of clusters − g) associated to the original genes g, where
                                                 mean(gnormal) is the average of the gene over the normal
  This can be directly seen in Figure 3, where we depict        ⋅
both the cluster overlaps (in the initial data) and the samples, while pos( ) is the Heaviside step function. 
matches of the recovered clusters with the original ones. To avoid overfitting, we estimated the number of clus-
                                                 ters nc as the number of dimensions around which the 
The inverse correlation between bicluster overlap and                ε
matches is obvious (Pearson correlation -0.92).  change in relative error d /dnc of the factorization of the 
                                                 real data “reaches from above” the change in relative 
                                                 error obtained for a randomized dataset (similar to [Kim 
                                                 and Tidor, 2003]). 
                                                   We then used our metaclustering algorithm to factorize 
                                                 the extended gene expression matrix X by running PTF 
                                                 over 20 NMF runs with the number of clusters deter-
                                                 mined above (nc=10). (The matrix X has 203 rows (sam-
                                                 ples) and 2×3529=7058 columns (extended genes).) Fig-
                                                 ure 4 shows the resulting sample cluster matrix A. Note 
                                                 that the algorithm has recovered the non-adeno sample 
                                                 clusters with high accuracy, despite the very large num-
                                                 ber of variables (genes), many of these potentially irrele-

                                                 5 Genes with nearly constant and very low expression values (aver-
                                                 age expression levels<30 and STD<50) had been discarded, leav-
   Figure 3. Overlaps and matches are inversely correlated ing 3529 genes that are expressed in the lung cancer samples. 


                                            IJCAI-07
                                             2654vant in this problem. More precisely, the clusters 6, 7, 8 The Table below shows the relative reconstruction er-
                                                                                             6
on the diagonal of A correspond to the classes   rors ε = ||X−A⋅S||F / ||X||F for k-means, fuzzy k-means,
 ‘squamous’, ‘small cell’ and ‘normal’ respectively, while NMF and PTF (we display the mean, STD and min errors 
 clusters 9 and 10 are two subtypes of carcinoids (which, for 20 clustering runs of each algorithm and clustering 
 like adenos, are heterogeneous and form two partially dimensions 5, 10, 14 and 20). PTF meta-clustering exhib-
 overlapping clusters). Note that unlike most clustering its slightly smaller relative errors than the best runs of 
 methods, our approach allows for overlapping clusters. k-means, fuzzy k-means and NMF, and the improvement 
 The accuracy of the sample cluster overlaps can be tested also increases slightly with the number of clusters. 
                                                                         fcm         NMF
 for example in the case of the samples AD341, AD275, k-means k-means fcm      NMF
                                                                         best         best PTF
                                                 nc mean(STD) best run mean(STD) mean(STD)
 AD234 and AD241, which were classified by histo-                        run          run
 pathologists as adeno-squamous and also appear in the 0.4460     0.4459      0.4408
                                                 5         0.4445       0.4451       0.44060.4406
 overlap of our ‘squamous’ cluster with other ‘adeno’ (0.0010)    (0.0007)    (0.0004)
 clusters. Similarly, the overlap between the small cell and 0.4247 0.4219    0.4062
                                                 10        0.4196       0.4184       0.40560.4052
 squamous sample clusters corresponds to mixed small (0.0030)     (0.0017)    (0.0005)
                                                     0.4151       0.4111      0.3866
 cell-squamous cases, which are mentioned in the litera- 14 0.4104      0.4068       0.38550.3849
 ture.                                              (0.0035)      (0.0025)    (0.0009)
                                                     0.4002       0.3978      0.3642
 AD259                                  63       20        0.3936       0.3895       0.3634 0.362
 AD375                                  123 6
 AD122                                  8
 AD269                                  70          (0.0045)      (0.0039)    (0.0006)
 AD370                                  121
 AD127                                  10 
 AD123                                  9
 AD234                                  49 
 AD119                                  6
 AD177                                  25 
 AD1                                    133
 AD266                                  67 
 AD311                                  87 
 AD253                                  60 
 AD323                                  94 
 AD334                                  99 
 AD18                                   131
 AD346                                  106        Fuzzy k-means clustering required a very delicate fine-
 AD305                                  84 
 AD120                                  7
 AD367                                0.35 119
 AD115                                  4
 AD252                                  59 
 AD330                                  96 
 AD3                                    136
 AD15                                   129      tuning of the fuzzy exponent for obtaining non-trivial 
 AD208                                  37 
 AD276                                  72 
 AD185                                  29 
 AD201                                  33 
 AD239                                  52 
 AD366                                  118
 AD170                                  22 
 AD178                                  26 
 AD331                                  97       clusters: we used a fuzzy exponent of 1.1, whereas a 
 AD183                                  28  5
 AD362                                  116
 AD327                                  95 
 AD224                                  43 
 AD332                                  98 
 AD318                                  92 
 AD250                                  58 
 AD213                                  40       slightly higher value of 1.15 produced only trivial, non-
 AD188                                  32 
 AD249                                  57 
 AD207                                  36 
 AD169                                0.3 21 
 AD114                                  3
 AD236                                  50 
 AD268                                  69 
 AD111                                  2
 AD277                                  73       informative clusters. However, such a small fuzzy expo-
 AD267                                  68 
 AD374                                  122
 AD287                                  76 
 AD275                                  71 
 AD164                                  19 
 AD383                                  126
 AD295                                  78 
 AD118                                  5
 AD283                                  74       nent leads to very categorical membership degrees even 
 AD296                                  79 
 AD352                                  110
 AD315                                  90 
 NL268                                  146
 AD382                                  125
 AD360                                  114
 AD335                                  100
 AD225                                  44  4    for very small differences in distance between gene pro-
 AD31                                   135
 AD157                                  14 
 AD294                                  77 
 AD313                                0.25 88 
 AD212                                  39 
 AD210                                  38 
 AD158                                  15 
 AD337                                  102
 AD187                                  31       files, so the results are similar to those of hard clustering 
 AD336                                  101
 AD136                                  13 
 AD308                                  85 
 AD255                                  61 
 AD162                                  17 
 AD355                                  112
 AD261                                  65 
 AD302                                  82 
 AD10                                   128      (plain k-means). This is probably due to the different 
 AD130                                  11 
 AD16                                   130
 AD247                                  56 
 AD361                                  115
 AD304                                  83 
 AD260                                  64 
 AD172                                  23 
 AD238                                  51       interpretations of cluster overlap in fuzzy k-means and 
 AD19                                   132
 AD258                                  62 
 AD179                                  27 
 AD167                                0.2 20 
 AD240                                  53 
 AD173                                  24 
 AD309                                  86 
 AD228                                  46  3
 AD203                                  35       NMF respectively: whereas fuzzy k-means views over-
 AD347                                  107
 AD350                                  108
 AD7                                    139
 AD218                                  41 
 AD5                                    138
 AD320                                  93 
 AD340                                  104
 AD43                                   1
 AD384                                  127      laps in terms of membership degrees, NMF and PTF in-
 AD202                                  34 
COID4518                                188
 COID14                                 194
 AD338                                  103
 AD226                                  45 
 AD221                                  42 
 AD285                                  75 
 AD314                                  89 
 AD351                                  109      terpret overlaps as mixtures (as in the case of the adeno-
 AD379                                  124
 AD353                                  111
 AD368                                  120
 AD241                                0.15 54 
 AD163                                  18 
 AD243                                  55 
 AD232                                  48 
 AD341                                  105      squamous samples – see also assumptions (1) and (2) 
 SQ1670                                 164
 SQ5                                    181
 SQ20                                   179
 SQ2557                                 165
 SQ13                                   177
 SQ2921                                 167
 SQ4389                                 172 2
 SQ4172                                 171
 SQ7324                                 175      above).
 SQ3197                                 168
 SQ3624                                 170
 SQ14                                   178
 SQ1174                                 163
 SQ8                                    183
 SQ4                                    180
 SQ3529                                 169
 SQ2572                                 166        However, much more important than a small improve-
 SQ6147                                 174
 AD230                                  47 
 SMCL8                                  161
 SQ6                                    182
 SMCL4                                0.1 160
SMCL301                                 157
 SMCL9                                  162
 SQ10                                   176
SMCL5937                                158      ment in error is the stability of the resulting clusters. All 
 AD131                                  12 
 AD186                                  30 
 AD301                                  81 
 SQ5897                                 173
 AD2                                    134
 SMCL3                                  159
 AD159                                  16 
 AD299                                  80 
 NL6943                                 155      studied methods recovered the non-adeno sample clusters 
 NL3104                                 148
 NL3681                                 149
 NL2562                                 145
 NL4353                                 151
 NL6853                                 154
 NL1179                                 140 1
 NL1884                                 143
 NL1675                                 141      satisfactorily (with differences in the adeno clusters that 
 AD363                                  117
 NL4083                                 150
 NL6084                                 153
 NL2378                                 144
 NL1698                               0.05 142
 NL279                                  147
 NL504                                  152
 NL7530                                 156
 AD356                                  113      cannot be judged based on current histological evidence). 
 AD4                                    137
 AD317                                  91 
 AD262                                  66 
 COID4                                  198
 COID9                                  203
 COID3                                  197
 COID18                                 196
COID3580                                186
COID1429                                184      To study the variability of the gene clusters S in different 
 COID11                                 191
 COID6                                  200
 COID7                                  201
 COID16                                 195
 COID12                                 192
 COID5                                  199
COID4385                                187
 COID13                                 193      runs of each algorithm, we computed the average relative 
COID2260                                185
COID9794                                189
 COID10                                 190
 COID8                                0 202
    4  5  1  2  7  6  9  8  3  10           0
                                                 differences ||Si−Sj||/||Si|| between pairs of gene cluster 
 Figure 4. The sample clusters (matrix A – normalized columns) matrices Si obtained in 20 different runs (of each algo-
  The gene clusters S recovered genes with well known rithm) for nc=10 clusters, as well as the corresponding 
involvement in the lung cancer subtypes under study. For mismatches between gene clusters matrices. We display 
example, the squamous cluster contained numerous kera- the cluster mismatches for progressively larger cutoff 
tin genes (keratins 6A, 5, 17, 14, 13, 16, 19), typical for thresholds7 to show that the differences between clusters 
squamous differentiation, the keratinocyte-specific pro- obtained in different runs involve not just the small, but 
tein stratifin, the p53 tumor suppressor analog TP73L, also the large coefficients of S.
etc. More details on the gene clusters and a larger version 
of Figure 4 can be found in the supplementary material at 6
http://www.ai.ici.ro/ijcai07/. (Note that genes with large  For both plain and fuzzy k-means, A is constructed from the clus-
                                                 ter membership function, while S is given by the cluster centers. 
Scg tend to be differentially expressed between the 7
                                                  Cluster membership degrees Scg were considered significant if 
classes, although the class information was never pro-                         θ      θ
                                                 they exceeded the thresholdsθ =1/ n , 2 0g and 3 0g respec-
vided to the algorithm.)                                              0g    g
                                                 tively. Note that the rows of S are normalized to unit norm. 


                                            IJCAI-07
                                             2655