                    Relational Learning for Email Task Management∗

                            Rinat Khoussainov    and  Nicholas Kushmerick
                                    Department of Computer Science
                                   University College Dublin, Ireland
                                          {rinat, nick}@ucd.ie


1  Introduction and Background                        vide relational clues that can be used to establish links be-
                                                      tween emails and group them into tasks. Instead of treating
Today’s email clients were designed for yesterday’s email.
                                                      these two problems separately, we propose a synergetic ap-
Originally, email was merely a communication medium. To-
                                                      proach where identifying related emails is used to assist se-
day, email has become a “habitat” [Ducheneaut and Bellotti,
                                                      mantic message analysis and vice versa.
2001]—an environment where users engage in a variety of
                                                        Our contributions are as follows:
complex activities. Our goal is to develop automated tech-
                                                        (1) We propose a new method for identifying relations be-
niques to help people manage complex activities or tasks in
                                                      tween emails, based on pair-wise message similarity. We
email. In many cases, such activities manifest the user’s par-
                                                      extend the similarity function to take into account available
ticipation in various structured processes or workﬂows. The
                                                      structured information in email.
central challenge is that most processes are distributed over
                                                        (2) We propose a relational learning approach [Neville and
multiple emails, yet email clients are designed mainly to ma-
                                                      Jensen, 2000] to email task management. We investigate how
nipulate individual messages.
                                                      (a) features of related emails in the same task can assist with
  A task-oriented email client would allow the user to man-
                                                      classiﬁcation of speech acts, and how (b) information about
age activities rather than separate messages. For instance, the
                                                      speech acts can assist with ﬁnding related messages. Combin-
user would be able to quickly inquire about the current status
                                                      ing these two methods yields an iterative relational algorithm
of unﬁnished e-commerce transactions or check the outcome
                                                      for speech act classiﬁcation and relation identiﬁcation.
of recent project meetings. Some process steps could be au-
                                                        (3) We evaluate our methods on a real-life email corpus.
tomated, such as automatically sending reminders for earlier
user’s requests. Similarly, the email client could remind the
user when her/his input is required in some activity. 2   Problem Decomposition and Email Corpora
  Previous work in this area has mainly focused on two dis- In a non-relational approach, we would use the content of a
tinct problems: ﬁnding related messages and semantic mes- message to assign speech acts, and some content similarity
sage analysis. The goal of ﬁnding related messages is to between messages to identify relations. In a relational ap-
group emails according to tasks and possibly establish con- proach to speech act classiﬁcation, we can use both the mes-
versational links between emails in a task (e.g. extract a task sage content and features of the related messages from the
from email given a seed message [Dredze, 2005]). Note that same task. For example, if a message is a response to a meet-
tasks need not correspond to folders (folders can be orthogo- ing proposal, then it is more likely to be a meeting conﬁrma-
nal to tasks); and conversations need not correspond to syn- tion or refusal. Similarly, we can use messages’ speech acts
tactic threads (users can use the “Reply” button or the same to improve relations identiﬁcation, e.g. a request followed by
subject to start a semantically new conversation).    a delivery are more likely to be related than two requests.
  Semantic message analysis involves generating metadata Therefore, we can identify four sub-problems: (P1) ﬁnd
for individual messages in a task that provides a link between relations in email using content similarity only (i.e. without
the messages and the changes in the status of the underlying using messages’ speech acts); (P2) classify messages into
process, or the actions of the user in the underlying workﬂow. speech acts (semantic message analysis) using only the mes-
For example, [Cohen et al., 2004] proposed machine learn- sage content (i.e. without using information about the related
ing methods to classify emails according to the intent of the messages); (P3) use the identiﬁed related emails to improve
sender, expressed in an ontology of “email speech acts”. the quality of speech acts classiﬁcation for a given message;
  Our key innovation compared to related work is that we (P4) use the messages’ speech acts to improve identiﬁcation
exploit the relational structure of these two tasks. The idea of relations (links) between emails. These four sub-problems
is that related messages in a task provide a valuable context can be combined into a synergetic approach to task manage-
that can be used for semantic message analysis. Similarly, ment based on an iterative relational classiﬁcation algorithm
the activity-related metadata in separate messages can pro- illustrated in Figure 1.
                                                        We used the PW CALO email corpus [Cohen et al., 2004]
  ∗This research was funded by the Science Foundation Ireland for our study. It was generated during a 4-day exercise con-
and the US Ofﬁce of Naval Research.                   ducted at SRI speciﬁcally to generate an email corpus. During   1: Identify initial relations (P1)                   Identifying Relations Using Speech Acts (P4). We treat
   2: Generate initial speech acts (P2)               the problem of ﬁnding related messages using speech acts as a
   loop                                               supervised learning task. We assume that we have access to a
     3: Use related emails in the task to clarify speech acts (P3) training set, which provides the correct labels for both speech
     4: Use speech acts to clarify relations between emails (P4)
     5: Update messages relations                     acts and message relations. The goal is to use this informa-
     6: Update messages speech acts                   tion to improve our performance on an unseen email corpus.
   end loop                                           From the given labelled email corpus, we produce a set of
                                                      training instances as follows. For each message in the cor-
Figure 1: Iterative relational algorithm for task management pus (child), we identify the most similar preceding message
                                                      (parent) using the previously deﬁned similarity function. For
 Table 1: Identifying relations Precision Recall F1   each such pair of messages, we create one training instance
     No time decay, thresh. prune 0.83  0.80  0.81    with one numeric feature for the similarity between messages,
     Time decay, thresh. prune  0.84    0.80  0.82    and two subsets of binary features for each possible speech
 P1
     No time decay, threads prune 0.83  0.81  0.82    act (10 features in total). The ﬁrst binary subset is ﬁlled with
     Time decay, threads prune  0.84    0.82  0.83    speech acts of the parent message: 1 if the message has this
 P4  Using speech acts          0.91    0.80  0.85    speech act, 0 otherwise. The second binary subset if ﬁlled
                                                      with speech acts of the child message. The class label for the
                                                      instance is positive if the corresponding messages are related
this time a group of six people assumed different work roles
                                                      and negative otherwise. The resulting classiﬁer can then be
(project leader, ﬁnance manager, researcher, etc) and per-
                                                      used to identify links in an unseen email corpus.
formed a number of activities. Each email has been manually
                                                        To evaluate the potential for improvement from using
annotated with labels linking it to other emails and also with
                                                      speech acts, we tried to train and test a classiﬁer on the same
labels showing the intent of the sender, expressed in a verb-
                                                      “User 1” corpus. We use the SMO as our classiﬁcation algo-
noun ontology of “email speech acts” [Cohen et al., 2004].
                                                      rithm [Platt, 1999]. As shown in Table 1, using speech acts
Examples of speech acts are “Propose meeting”, “Deliver in-
                                                      worked here as a more effective pruning method resulting in
formation”. For this study we only use 5 most frequent verbs
                                                      the increase in precision with only marginal loss in recall.
(“Propose”, “Request”, “Deliver”, “Commit”, “Amend”) as
speech acts. To perform experiments, we need to ensure our Classifying Speech Acts without Related Messages (P2).
training and testing sets are unrelated. So we generated 2 As in the previous case, we treat the problem of email speech
non-overlapping corpora with messages received by 2 differ- act classiﬁcation as a supervised learning task. We use the
ent users (“User 1”, 160 emails; and “User 2”, 33 emails). standard text classiﬁcation methods with bag-of-words doc-
                                                      ument representations similar to [Cohen et al., 2004], and
                                                      SMO as the classiﬁcation algorithm.
3  Solutions and Results                                Classifying Speech  Acts Using  Related Messages
Identifying Relations without Using Speech Acts (P1). For (P3). We adopt here the relational learning terminology
each email in the corpus, we ﬁnd the most similar preced- from [Neville and Jensen, 2000]. Each email message is
ing (in time) email using a pair-wise message similarity. Our represented by a set of features: intrinsic features, derived
similarity functions takes into account not only the textual from the content of the given message; and extrinsic features
similarity between messages, but also the available structured derived from the properties of related messages in the same
information in email, such as send dates, and message sub- task. To represent the intrinsic features of a message, we use
jects. The textual similarity is deﬁned as the TF/IDF cosine the raw term frequencies as in P2. To represent the extrinsic
similarity between email texts. However, the terms appear- features of a message, we use the speech acts of related mes-
ing in the subject get a higher weight, since people often sages. We want to know whether speech acts of “surround-
summarise email content in the subject making subject terms ing” messages can help in classifying speech acts of a given
more important. Similarly, related messages tend to be sent message. For each speech act, we produce a separate binary
around the same time. So, two messages with a large send classiﬁcation problem where the goal is to identify whether
time difference are less likely to be related. We use the fol- the message has this act or not.
lowing formula: Sim(m1, m2) = Cosine Sim(m1, m2) ∗      Each message can be viewed as a response to its parent
exp(−α ∗ Norm  time diﬀ (m1, m2)), where Cosine Sim   message and as a cause for its children messages. In addi-
is the cosine message similarity, Norm time diﬀ (m1, m2) tion to looking at the immediate ancestors and descendants of
is the time difference between messages divided by the max- a message, we can also include features from several “gen-
imum time difference, and α is a time decay parameter. erations” of ancestors and descendants (e.g. parents, grand-
  There may be multiple pairs of messages with non-zero parents, children, grandchildren). For each “generation” of
similarity in a corpus, however, not all are actually related. related ancestor and descendant messages, we use a separate
Hence, we would like to be able to prune the links suggested set of extrinsic features with one feature per each possible
by the similarity function. One way is to use some threshold speech act. The number of generations included into extrin-
value: if the similarity is below the threshold, the messages sic features is regulated by the depth of lookup parameters:
are not related. Another way is to use email threads: mes- one for ancestor messages and one for descendant messages
sages from different threads are not related. Table 1 compares (0 lookup depth means we use only intrinsic features).
different methods on the “User 1” corpus.               We evaluated speech act classiﬁcation using the human-  Table 2: Speech acts classiﬁcation                          0.6
  Ancest./Descend. lookup 0/0 0/1   1/0    1/1                                             Dlv
                                                              0.5                         Prop
  Amend (p=0.43)       0.40  0.36   0.45 v 0.40                                           Req
                                                              0.4                         Cmt
  Commit (p=0.05)      0.17  0.20   0.28   0.37 v                                         Amd
  Deliver (p=0.24)     0.22  0.29 v 0.21   0.29 v             0.3
  Propose (p=0.21)     0.08  0.11   0.13 v 0.15               0.2
                                                           Kappa
  Request (p=0.05)     0.09  0.17   0.14   0.31 v             0.1

                                                               0

  for all speech acts a do                                   -0.1
   Train Ca on the training set to classify speech act a using only
                                                             -0.2
   intrinsic features                                           0    1    2    3    4    5    6   7
   Train Ra on the training set to classify speech act a using in-           Sub-iterations
   trinsic+extrinsic features
  end for                                                   Figure 3: Speech acts classiﬁcation, Iteration 1
  Train L on the training set to classify email links
  /*Problem 1*/
  Set relations in the test set using similarity function tain conﬁdence scores for SMO, we used the distance from
  /*Iterative classiﬁcation*/                         the hyper-plane normalised over all test instances. We use
  for Iteration = 1 . . . I do                        the similarity function with time decay and threshold-based
   /*Problem 2*/                                      pruning to identify the initial links between messages (P1).
   Use classiﬁers Ca to set speech acts in the test set We repeated the inner speech act classiﬁcation loop 10 times
   /*Problem 3*/                                      (K = 10) and the outer iteration loop 2 times (I = 2).
   Theshold = 1                                         The initial links identiﬁcation resulted in precision = re-
   for Subiteration = 1 . . . K do                    call = F1 = 0.95. It improved after the ﬁrst iteration to
     for all messages m in the test set do
       for all speech acts a do                       precision=1.0; recall=0.95; F1=0.98, and remained the same
                                                      after the second iteration. Figure 3 shows how the speech
         Obtain conﬁdence for “m has a” using Ra
         Obtain conﬁdence for “m has no a” using Ra   acts classiﬁcation performance was changing during the ﬁrst
       end for                                        main iteration. Once the links improved after the ﬁrst itera-
     end for                                          tion, we were able to further improve the performance for the
     For all cases where conﬁdence for “m has/has no a” is “Request” speech act at the second iteration to Kappa=0.23.
     greater than Threshold update speech acts of m     Discussion. Our experiments demonstrated that: (1) struc-
     Threshold = Threshold/2                          tured features in email, such as message subject and send
     Evaluate performance for speech acts             dates, can be very useful for identiﬁcation of related mes-
   end for                                            sages and grouping them into email tasks; (2) the properties
   /*Problem 4*/
   Use L to ﬁnd links between emails in the test set  of related messages in the same task can be used to improve
   Evaluate performance for relations                 the semantic message analysis. In particular, the features of
  end for                                             related messages in a task can improve the performance of
                                                      the email speech acts classiﬁcation; (3) the semantic meta-
  Figure 2: Iterative relational algorithm (detailed version) data in messages can be used to improve the quality of task
                                                      identiﬁcation. In particular, taking into account speech acts
                                                      of messages improves identiﬁcation of links between emails.
annotated (correct) relations between messages and the cor- Finally, our combined iterative classiﬁcation algorithm was
rect speech acts for related messages on the “User 1” cor- able to simultaneously improve performance on both speech
pus. Notice that using the correct speech acts for related mes- acts and message relations. These results provide a good
sages does not mean that we use the class label of an instance empirical evidence in favour of the proposed synergetic ap-
among its features. Each message uses only the speech acts proach to email task management.
of the related messages, but not its own speech acts. Classiﬁ-
cation accuracy is not a good measure of performance on im- References
balanced data sets, so we use the Kappa statistics instead [Co- [Cohen et al., 2004] W. Cohen, V. Carvalho, and T. Mitchell.
hen et al., 2004]. The results in Table 2 are obtained in 5-fold Learning to classify email into “speech acts”. In Empirical Meth-
cross-validations repeated 10 times for statistical signiﬁcance ods in Natural Language Processing, 2004.
testing (paired T-test). “V” marks statistically signiﬁcant im- [Dredze, 2005] M. Dredze. Taxie: Automatically identifying tasks
provements over the base line (both lookup depths are 0). in email. In Manuscript avail. from the author, 2005.
  Iterative Algorithm for Task Management (P1 + P2 +  [Ducheneaut and Bellotti, 2001] N. Ducheneaut and V. Bellotti.
P3 + P4). The results for P3 and P4 have demonstrated   Email as habitat: An exploration of embedded personal infor-
promise for our synergetic approach to task management. mation management. ACM Interactions, 8(1), 2001.
Therefore, here we combine the described methods for solv- [Neville and Jensen, 2000] J. Neville and D. Jensen. Iterative clas-
ing P1–P4 into the algorithm shown in Figure 2 (which is a siﬁcation in relational data. In AAAI Workshop on Learning Sta-
detailed version of the algorithm in Figure 1).         tistical Models from Relational Data, 2000.
  In our experiments, we used the “User 1” corpus as the [Platt, 1999] John C. Platt. Fast Training of Support Vector Ma-
training set and the “User 2” corpus as the test set. To ob- chines using Sequential Minimal Optimization. MIT Press, 1999.