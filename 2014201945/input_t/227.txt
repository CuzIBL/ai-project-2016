           Learning to Compete in Heterogeneous Web Search Environments" 

                                 Rinat Khoussainov and Nicholas Kushmerick 
                          Department of Computer Science, University College Dublin 
                                              Belfield, Dublin 4, Ireland 
                                                 {rinat, nick}@ucd.ie 

 1 Introduction                                                2 Problem Formalisation 

Previous research in Web search has mainly targeted perfor•    Performance metric. We adopt an economic view on search 
mance of search engines from the user's point of view. Pa•     engine performance. Performance is a difference between the 
rameters such as precision, recall, and freshness of returned  value of the search service provided (income) and the cost of 
results were optimised. On the other hand, a provider of       the resources used to provide the service. In our simplified 
search services is rather interested in parameters like the num• version of the problem we only take into account the cost 
ber of queries processed versus the amount of resources used   of resources involved in processing search queries. Under 
to process them. We focus on performance optimisation of       these assumptions, engine performance can be expressed as 
search engines from the service provider's point of view.      follows:  
   An important factor that affects the search engine perfor•
mance is competition with other independently controlled       where Q is the number of queries received in a given time 
search engines. When there are many engines available, users   interval, D is the number of documents in the search engine 
want to send queries to those that provide the best possible   index, and are constants. 
results. Thus, the service offered by one search engine influ•       represents the service value: if the price of processing 
ences queries received by others.                              one search request for a user is then would be the total 
   Competition is even more important in heterogeneous         income from service provisioning. represents the cost 
search environments consisting of many specialised search      of processing search requests. If x amount of resources is suf•
engines (which provide access to the so-called "deep" or "in•  ficient to process Q queries, then we need 2x to process twice 
visible" Web). Each specialised engine in such environment     as many queries in the same time. Similarly, twice as many 
indexes only a subset of all documents (e.g. on a particular   resources are needed to search twice as many documents in 
topic). Each user query is only sent to a small number of      the same time. Thus, the amount of resources (and, hence, the 
the engines which can return the best results. Selection be•   cost) is proportional to both Q and D, and so can be expressed 
tween specialised search engines is done (semi)automatically   as where reflects the resource costs. The example of 
by meta-searchers, which rank engines for each user query.     the FAST search engine confirms that our cost function is not 
Thus, parameters of specialised engines automatically affect   that far from reality [Risvik and Michelsen, 2002]. 
their ranking and, hence, the queries they receive, and ulti•    Environment model. Let us assume that users issue 
mately their profit.                                           queries on just a single topic, e.g. "cars". We will see later 
   We are examining the problem of performance-maximising      how this extends to multiple topics. It is reasonable to as•
behaviour for non-cooperative specialised search engines in    sume that users would like to send queries to search engines 
heterogeneous search environments. In particular, we analyse   that contain the most relevant documents on the topic, and 
how specialised search engines can select on which topic(s)    the more of them, the better. Suppose that search engines 
to specialise and how many documents to index on that topic.   have "ideal" Web robots which for a given D can find the D 
We provide a game-theoretic analysis of a simplified ver•      most relevant documents on the topic. In this case, the user 
sion of the problem and motivate the use of the concept of     would simply have to send queries to the engine containing 
 "bounded rationality". Bounded rationality assumes that       the largest number of documents on the topic. 
decision makers are unable to act optimally in the game-         This model can be extended to multiple topics, if the state 
theoretic sense due to incomplete information about the en•    of a search engine is represented by the number of documents 
vironment and/or limited computational resources. We then         that engine i indexes for each topic t (a query on topic t 
cast our problem as a reinforcement learning task, where the   would be sent to the engine i with the largest Of course, 
goal of a specialised search engine is to exploit sub-optimal  such extension ignores possible overlaps between topics in 
behaviour of its competitors to improve own performance.       both queries and documents. On the other hand, if we asso•
                                                               ciate each topic with a search term, the whole engine selec•
   *This research was funded by Science Foundation Ireland and tion model would closely reflect how some real-life engine 
the US Office of Naval Research.                               selection algorithms work [Callan et al, 1995]. 


POSTER PAPERS                                                                                                       1429    Decision making process. For each time interval, the        learning task, where the player would have to learn a strategy 
 search engines simultaneously and independently decide on     that performs well against its sub-optimal opponents. 
 how many documents to index and allocate resources to pro•      Learning in repeated games has been studied extensively in 
 cess expected search queries (thus incurring the correspond•  game theory and machine learning. Examples include fictious 
 ing costs). As search engines cannot have unlimited crawling  play and opponent modelling [Robinson, 1951; Carmel and 
 resources, we presume that they can only do incremental ad•   Markovitch, 1996]. We apply a more recent algorithm from 
justments to their index contents that require the same time   reinforcement learning called GAPS [Peshkin et al, 2000]. 
 for all engines. The user queries are allocated to the engines In GAPS, the learner plays a parameterised strategy repre•
 based on their index parameters as described above.           sented by a finite state automaton, where the parameters are 
   Since a search engine cannot know the number of queries     the probabilities of actions and state transitions. GAPS im•
that users will submit, it may allocate less query processing  plements stochastic gradient ascent in the space of policy pa•
resources than the number of queries it will receive. We as•   rameters. After each learning trial, parameters of the policy 
sume that excess queries are discarded and the search engine   are updated by following the payoff gradient. 
does not benefit from them. Then, performance of engine /        GAPS has a number of advantages important for our do•
over a given time interval can be represented as               main. It works in partially observable games. It also scales 
                                                               well to multiple topics by modelling decision-making as a 
                                                               game with factored actions (where action components corre•
                                                               spond to topics). The action space in such games is the prod•
where is the expected number of queries 
                                                               uct of factor spaces for each action component. GAPS, how•
across all topics for which the search engine is trying to com• ever, allows us to reduce the learning complexity: rather than 
pete (i.e. index at least one document),is the                 learning in the product action space, separate GAPS learners 
total number of indexed documents, is the total                can be used for each action component. It has been shown 
number of queries actually received by engine i, and           that such distributed learning is equivalent to learning in the 
                                                               product action space. We call a search engine that uses the 
                                                               proposed approach COUGAR, which stands for Competitor 
                                                               Using GAPS Against Rivals. 

is the share of queries in topic / received by engine i, and Qt 
is the number of queries users submitted on topic t.           4 Preliminary Results 
                                                               We evaluated our approach in a number of simulation exper•
3 Analysis and Solution Approach                               iments, which demonstrated COUGAR's ability to compete 
The decision-making process can be modelled as a multi•        successfully with different opponents. For the sake of brevity, 
stage game. At each stage, a matrix game is played, where      we present here results from one such experiment with two 
                                                               competing search engines. One search engine was using a 
players are search engines, actions are values of (Dt), and 
                                                               fixed strategy, called "Bubble", the other one was COUGAR. 
player i receives payoff Pi (as above). If player ,• knew the 
actions of its opponents at a future stage k, it could calculate The search engines could increase, decrease (by one), or keep 
                                                               the number of documents indexed on each topic. They could 
the optimal response as the one maximising its payoff Pi(k) 
at that stage. For example, in case of a single topic and a con• also observe the size of own index, the relative sizes of oppo•
stant query stream it should play                              nents' indices, and the number of user queries Qt submitted 
if otherwise (sim•                                             for each topic (the last two observations can be obtained from 
ply put, outperform opponents by 1 document if profitable,     the meta-searcher). The expected number of queries on topic 
and do not incur any costs otherwise).                         t at future stage A; was calculated as  
   In reality, the players do not know the future. One possible  The experimental setup consisted of three components: the 
way around this would be to agree on (supposedly, mutually     generator of search queries, the metasearcher, and the search 
beneficial) actions in advance. To avoid deception, players    engines. The state of a search engine's document index is 
would have to agree on playing a Nash equilibrium of the       represented by a vector of the numbers of documents 
game, since only then there will be no incentive for them to   indexed by the search engine for each topic. This is the infor•
not follow the agreement. Agreeing to play a Nash equilib•     mation used by the metasearcher to select search engines. 
rium, however, becomes problematic when the game has mul•        To simulate user search queries, we used HTTP logs ob•
tiple such equilibria. Players would be willing to agree on    tained from a Web proxy of a large ISP. We developed extrac•
a Nash equilibrium yielding to them the highest (expected)     tion rules individually for 47 well-known search engines. The 
payoffs, but the task of characterising all Nash equilibria of a total number of queries extracted was 657,861 collected over 
game is NP-hard even given complete information about the      a period of 190 days. We associated topics with search terms 
game (as follows from [Conitzer and Sandholm, 2002]).          in the logs. To simulate queries for T topics, we extracted the 
  NP-hardness results and the possibility that players may     T most popular terms from the logs. The number of queries 
not have complete information about the game lead to the       generated on topic t for a given day was equal to the number 
idea of "bounded rationality", when players may not use the    of queries with term t in the logs belonging to this day. 
optimal strategies in the game-theoretic sense. Our proposal     The "Bubble" strategy tries to index as many documents 
is to cast the problem of optimal behaviour in the game as a   as possible without any regard to what competitors are do-


1430                                                                                                   POSTER PAPERS                                                                      Figure 2: "Bubble" vs COUGAR: sample trial 

                                                              5 Future Work 
ing. As follows from our performance formula (Section 2), 
such unconstrained growing leads eventually to negative per•  We do not claim to provide a complete solution for the 
formance. Once the total reward falls below a certain thresh• problem of performance management in heterogeneous Web 
old, the "Bubble" search engine goes bankrupt (it shrinks its search, but COUGAR is a promising first step. Clearly, we 
index to 0 documents and retires until the end of the trial). have made many strong assumptions in our models. One 
This process imitates the situation, in which a search provider future direction will be to relax these assumptions to make 
expands its business without paying attention to costs, and   our simulations more realistic. Another important direction 
eventually runs out of money (or an analogy with the " . com  would be to further study performance of the learning algo•
bubble"). An intuitively sensible response to the "Bubble"    rithm in self-play, as well as against other learners. 
strategy would be to wait until the bubble "bursts" and then     While we are motivated by the optimal behaviour for 
come into the game alone. That is, a competitor should not    search services over document collections, our approach is 
index anything while the "Bubble" grows and should start in•  applicable in more general scenarios involving services that 
dexing a minimal number of documents once the "Bubble"        must weigh the cost of their inventory of objects against the 
search engine goes bankrupt.                                  expected inventories of their competitors and the anticipated 
                                                              needs of their customers. For example, it would be interest•
  Our simulation had two topics, and "Bubble" was increas•    ing to apply our ideas to large retail e-commerce sites which 
ing (and decreasing) the number of documents indexed for      must decide what products to stock. 
each topic simultaneously. First, we trained COUGAR in a 
number of learning trials. Once it reached a steady perfor•   References 
mance level, the resulting strategy was evaluated in a scries 
of testing trials. Each simulation trial consists of 100 days, [Callan et al., 1995] J. P. Callan, Z. Lu, and W. B. Croft. Searching 
where each day corresponds to one stage of the multi-stage       distributed collections with inference networks. In Proc. of the 
game played. The resulting performance in the whole trial is     18th Annual Intl. ACM S1G1R Conf, pages 21-28. ACM Press, 
calculated as a sum of discounted rewards from each day.         July 1995. 
                                                              [Carmel and Markovitch, 1996] D. Carmel and S. Markovitch. 
  Figure 1 shows how COUGAR's performance improving 
                                                                 Learning models of intelligent agents. In Proc. of the 13th Na•
during learning. Figure 2 visualises a testing trial between     tional Conf. on Artifical Intelligence, pages 62-67, Menlo Park, 
the "Bubble" and the COUGAR engines by showing the num•          CA, 1996. 
ber of documents indexed by the engines on each day of the 
                                                              [Conitzer and Sandholm, 2002] V. Conitzer and T. Sandholm. 
trial (the top half of Y axis shows the number of documents 
                                                                 Complexity results about Nash equilibria. Technical Report 
for topic 1, the bottom half shows the number of documents       CMU-CS-02-135, Carnegie Mellon University, 2002. 
for topic 2). Note that COUGAR has learned to wait until 
"Bubble" goes bankrupt, and then to win all queries for both  [Peshkin etal.,2000] L. Pcshkin, N. Meuleau, K.-E. Kim, and 
topics.                                                          L.Kaelbling. Learning to cooperate via policy search. In Proc. 
                                                                 of the 16th Conf on Uncertaintly in Artifical Intelligence, pages 
  We also investigated effectiveness of our approach against     489-496. Morgan Kaufmann, 2000. 
evolving opponents. In particular, we evaluated performance   [Risvik and Michelsen, 2002] K. Risvik and R. Michelsen. Search 
of a COUGAR strategy learned in self-play against other          engines and web dynamics. Computer Networks, 39:289-302, 
learners (other COUGARs in our case). We observed that           June 2002. 
while COUGAR's performance can be quite stable against 
                                                              [Robinson, 1951] J. Robinson. An iterative method of solving a 
equally complex learners, it may still be sub-optimal, in the    game. Annals of Mathematics, 54:296-301, 1951. 
sense that a "cleverer" learner (e.g. a COUGAR with more 
policy states) can outperform it. 


POSTER PAPERS                                                                                                      1431 