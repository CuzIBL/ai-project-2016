                         State Space Search for Risk-averse Agents

           Patrice Perny                   Olivier Spanjaard               Louis-Xavier Storme
     LIP6 - University of Paris 6     LIP6 - University of Paris 6      LIP6 - University of Paris 6
           4 Place Jussieu                   4 Place Jussieu                  4 Place Jussieu
    75252 Paris Cedex 05, France     75252 Paris Cedex 05, France      75252 Paris Cedex 05, France
        patrice.perny@lip6.fr           olivier.spanjaard@lip6.fr       louis-xavier.storme@lip6.fr

                    Abstract                          transition-costs. For example, when costs are time dependent
                                                      and representable by random variables, the SDA∗ algorithm
    We investigate search problems under risk in state- has been introduced to determine the preferred paths accord-
    space graphs, with the aim of ﬁnding optimal      ing to the stochastic dominance partial order [Wellman et al.,
    paths for risk-averse agents. We consider prob-   1995]. An extension of this algorithm speciﬁcally designed
    lems where uncertainty is due to the existence of to cope with both uncertainty and multiple criteria has been
    different scenarios of known probabilities, with  proposed by Wurman and Wellman [1996].
    different impacts on costs of solution-paths. We
                                                        We consider here another variation of the search prob-
    consider various non-linear decision criteria (EU,
                                                      lem under uncertainty, that concerns the search of “robust”
    RDU, Yaari) to express risk averse preferences;
                                                      solution-paths, as introduced by Kouvelis and Yu [1997]. Un-
    then we provide a general optimization procedure
                                                      der total uncertainty, it corresponds to situations where costs
    for such criteria, based on a path-ranking algorithm
    applied on a scalarized valuation of the graph. We of paths might depend on different possible scenarios (states
                                                      of the world), or different viewpoints (discordant sources of
    also consider partial preference models like second
                                                      information). Roughly speaking, the aim is to determine
    order stochastic dominance (SSD) and propose a
    multiobjective search algorithm to determine SSD- paths with “reasonnable” cost in all scenarios. Under risk
                                                      (i.e. when probabilities are known) this problem generalizes
    optimal paths. Finally, the numerical performance
                                                      to the search of “low-cost/low-risk” paths. Let us consider a
    of our algorithms are presented and discussed.
                                                      simple example:
1  Introduction                                       Example 1  Consider the network pictured on Figure 1 where
                                                      the initial state is 1 and the goal node is 6. Assume that only
Various problems investigated in Artiﬁcial Intelligence can be
                                                      two scenarios with known probabilities p1 and p2 are relevant
formalized as shortest path problems in an implicit state space concerning the trafﬁc, yielding two different sets of costs on
graph (e.g. path-planning for mobile robots, VLSI layout, in-                        i
                                                      the network. Hence, to each path P is associated a vector
ternet searching). Starting from a given state, we want to de- i i                 1                  1
                                                      (x1,x2), one cost per scenario: P = 1, 3, 5, 6 with x =
termine an optimal sequence of admissible actions allowing     2               2            3
                                                      (5, 18), P = 1, 3, 6 with x =(8, 15), P = 1, 3, 4, 6
transitions from state to state until a goal state is reached. 3          4                  4
                                                      with x  =(16, 15), P  = 1, 2, 5, 6 with x =(13, 10),
Here, optimality refers to the minimization of one or sev- 5              5            6
                                                      P   =  1, 2, 6 with x =(16, 7), P = 1, 2, 4, 6 with
eral cost functions attached to transitions, representing dis- 6                        i     i  i
                                                      x  =(20, 2). Using cost-distributions X =(x ,x ; p1,p2),
tances, times, energy consumptions...For such problems, con-                                  1  2
                            ∗     ∗                   i =1,...,6, we want to determine solutions paths associated
structive search algorithms like A and A [Hart et al., 1968;
                                  ε                   with low-risk cost-distributions.
Pearl, 1984] for single objective problems or MOA∗ for mul-
tiobjective problems [Stewart and White III, 1991] have been
                                                                                20
proposed, performing the implicit enumeration of feasible so-    1                    p1
                                                          (2,10)     (8,1)                         p3
lutions.                                                                                  p2
                                                                                15
  An important source of complexity in path-planning prob- 3  (3,4) (3,1) 2
lems is the uncertainty attached to some elements of the prob-                                 4
                                                      (1,0)                (1,0)               p
lem. In some situations, the consequences of actions are not                    10
certain and the transitions are only known in probabilities. In                                   p5
                                                         5   (6,5)  (8,6) 4
some other, the knowledge of the current state is imperfect                     5
(partial observability). Finally, the costs of transitions might (2,8) (11,1)
                                                                                                        6
itself be uncertain. Although many studies concentrate on the    6                                     p
                                                                                0
two ﬁrst sources of uncertainty (see the important litterature                   0510            15   20
on MDPs and POMDPS, e.g. Puterman, 1994; Kaebling et
al., 1999), some others focus on the uncertainty attached to Figure 1: A 2-scenarios problem and its representation

                                                IJCAI-07
                                                  2353  This simple problem might prove very hard to solve on n. We call solution-path a path from s to a goal node γ ∈ Γ.
larger instances due to the coexistence of two difﬁculties: the Throughout the paper, we assume that there exists at least one
combinatorial nature of the solution space and the existence solution-path.
of several conﬂicting scenarios on costs. It is important to Following a classical scheme in robust optimization [Kou-
note that the vector-valued path problem introduced above velis and Yu, 1997], we consider a ﬁnite set S =
cannot be reduced to a standard shortest path problem by lin- {s1,...,sm} of possible scenarios, each having possibly
ear scalarization of cost-vectors without loosing signiﬁcant a different impact on the transition-costs, and a scenario-
information. Assume for example that the arcs of the graph dependent valuation v : A × S → N giving, for any arc
plotted on the left part of Figure 1 are valued accoding to a ∈ A and any scenario s ∈ S the cost v(a, s) of the tran-
their expected cost, so that each path P i receives a weight sition represented by a. Costs over a path are supposed to
   i         i     i                ∗
w(x ,p)=p1x1  + p2x2. Then algorithm A used with such be additive, which allows valuation v to be extended from
                          1    6
scalars weights might output P or P , depending on the rel- arcs to paths by setting, for any path P and any scenario s,
                                   4     2   5
ative value of p1 and p2, but neither path P nor P ,P .This v(P, s)= a∈P v(a, s). In the sequel, we assume that the
can easily be shown using the right part of Figure 1 where the cost of every solution path is (upper) bounded by a positive
images of solution-paths are plotted in the valuation space; constant M.
                     2   4      5                                                        m
we can indeed see that P , P and P do not belong to the A cost-vector x =(x1,...,xm) ∈  R+  is associated to
boundary of the convex hull (grey triangle) of the images of each path P in the graph in such a way that component
paths, thus being excluded from the set of potential winners, i = ( i).Leti denote the probability of scenario
                                                      x     v P, s       p              m
as long as a linear criterion is used. This is not satisfactory si, with pi ≥ 0 for i =1,...,m and i=1 pi =1,then
        4
because P presents a well-balanced proﬁle and might be pre- apathP with cost-vector x is represented by the distribu-
         1    6
ferred to P or P by a risk-averse agent. Similarly he might tion (x1,...,xm; p1,...,pm).LetL be the set of probabilis-
        2    1    5    6
prefers P to P or P to P , depending on probabilities. tic distributions having a ﬁnite support in [0,M].Thecost
  Example 1 shows the limitations of linear aggregation of each path is a random variable X characterized by law
functions in decision-making under risk on non-convex do- PX ∈L, deﬁned for any B ⊆ [0,M],byPX (B)=P ({s ∈
mains. To overcome the difﬁculty, we need to resort to more S : X(s) ∈ B}). For any random variable X, the expected
                                                                                  m
sophisticated decision criteria to compare cost distributions value of X is given by E(X)= i=1 pixi, the cumulative
in term of risk, as those introduced in decision theory. These function FX is given by FX (z)=P ({s ∈ S : X(s) ≤ z})
decision criteria escape linearity either by introducing a trans- for all z ∈ [0,M] and the associated decumulative function is
formation of costs as in the Expected Utility Model (EU denoted GX (z)=1− FX (z).
[von Neumann and Morgenstern, 1947]) or by introducing a
probability-transformation as in Yaari’s model [Yaari, 1987], 2.2 Decision Criteria for Risk-Averse Agents
or even both as in the Rank-Dependent Utility model (RDU In the ﬁeld of decision making under risk, the concept of risk-
[Quiggin, 1993]). Alternatively, partial comparison models aversion has been widely investigated, ﬁrst in the framework
including an idea of risk might be used when the agent’s util- of EU theory and then in more general frameworks. Roughly
ity function is not known (e.g. Second-order Stochastic Dom- speaking, risk-aversion amounts to preferring a solution with
inance, SSD). The aim of this paper is to incorporate such a guaranteed cost to any other risky solution with the same
models in search algorithms to determine low-risk solution expected cost. This was formalized by Pratt and Arrow [Pratt,
paths in implicit graphs.                             1964; Arrow, 1965] that deﬁne weak risk-aversion for a weak
  The paper is organized as follows: in Section 2, we intro- preference relation  on L as follows:
duce preliminary formal material as well as decision crite-
                                                      Deﬁnition 1 An agent is said to be weakly risk-averse if, for
ria modelling risk-sensitive decision behaviours. In Section             L                  (  )
3, we propose a general optimization procedure to ﬁnd the any distribution X in , he considers that E X is as least
                                                                       (  ) 
best paths with respect to such criteria. In Section 4, we pro- as good as X,i.e.E X X.
pose a multiobjective search algorithm for the determination In EU theory, risk-aversion means that the agent’s util-
of SSD-optimal paths. Finally, numerical experiments of al- ity function u on payoffs is increasing and concave,theco-
gorithms are given in Section 5.                      efﬁcient of risk-aversion of any agent being measured by
                                                      −u(x)/u(x) [Arrow, 1965]. In our context, the counterpart
2  Problem Formulation                                of EU is given by the expected weight function:
2.1  Notations and Deﬁnitions                                                  m
                                                                         (  )=        (  )
                               =(      )                             EW   X        piw xi             (1)
We consider a state space graph G  N,A  where N  is                             i=1
a ﬁnite set of nodes (possible states), and A is a set of arcs
representing feasible transitions between nodes. Formally, we where w :[0,M] → R is a strictly increasing function
                       
have A = {(n, n ),n ∈ N,n ∈ S(n)} where S(n) ⊆ N is   such that w(xi) represents the subjective weight (disutility)
the set of all successors of node n (nodes that can be reached attached to cost xi by the agent. Criterion EW(X) is to be
from n by a feasible elementary transition). Then s ∈ N minimized since it represents the disutility of any cost dis-
denotes the source of the graph (the initial state), Γ ⊆ N the tribution X. In the EW model, risk aversion means choos-
subset of goal nodes, P(s, Γ) the set of all paths from s to a ing an increasing and convex w in Equation (1), so as to get
goal node γ ∈ Γ,andP(n, n) the set of all paths linking n to EW(E(X)) ≤ EW(X) for all X ∈L.

                                                IJCAI-07
                                                  2354  Despite its intuitive appeal, EU theory does not explain Perny [2006] to enumerate the solution-paths of an implicit
all rational decision making behaviors (e.g. the violation of graph by increasing order of costs. Before expliciting step 3,
Savage’s sure thing principle [Ellsberg, 1961]). This has led we need to establish the following result:
researchers to sophisticate the deﬁnition of expected utility. Proposition 1 For all non-decreasing probability transfor-
Among the most popular generalizations of EU, let us men- mations ϕ on [0, 1] such that ϕ(q) ≥ q for all q ∈ [0, 1],for
tion the rank dependent utility introduced by Quiggin [1993], all non-decreasing and convex weight functions w on [0,M],
which can be reformulated in our context as follows:  for all X ∈Lwe have: RDW(X)   ≥ w (E(X))
        (  )=   (   )+
   RDW   X    w x(1)                               Proof. Since x(i+1) ≥ x(i) for i =1,...,m− 1 and w is
           m−1  (   (   ))  (      ) − (   )    (2)
           i=1 ϕ GX  x(i)  w x(i+1)   w x(i)          non-decreasing, we have: w(x(i+1)) − w(x(i)) ≥ 0 for all
                                                        =1        − 1                          ( ) ≥
where (.) represents a permutation on {1,...,m} such that i ,...,m   . Hence, from Equation (2), ϕ q q for
                                                          ∈ [0 1]                 ( )
x(1) ≤ ... ≤ x(m), ϕ is a non-decreasing probability trans- all q , implies that: RDW X         
                                                      ≥   (   )+    m−1    (   )  (     ) −  (   )
formation function, proper to any agent, such that ϕ(0) = 0 w x(1) i=1 GX x(i) w x(i+1)   w x(i)
     (1) = 1                                          =  1 −    (   )   (   )+     (      ) (    )
and ϕ      ,andw is a weight function assigning subjective  GXx(1)  w  x(1)  GX  x(m −1) w x(m)
disutility to real costs. This criterion can be interpreted as fol- m−1
                                                        +   i=2  GX (x(i−1)) − GX (x(i)) w(x(i))
lows: the weight of a path with cost-distribution X is at least                   m−1
                                                      = p(1)w(x(1))+ p(m)w(x(m))+       p(i)w(x(i))
w(x(1)) with probability 1. Then the weight might increase                          i=2
                                                      = EW(X)   ≥ w(E(X))  by convexity of w.          2
from w(x(1)) to w(x(2)) with probability mass ϕ(GX (x(1)));
                                                                   1      r
the same applies from w(x(2)) to w(x(3)) with probability- Now, let {P ,...,P } denotes the set of elemen-
                                                                           P(   Γ)
mass ϕ(GX (x(2))), and so on... When w(z)=z for all z, tary solution-paths in s,  , with  cost distributions
                                                        1      r                         (  1) ≤  (  2) ≤
RDW is known as Yaari’s model [Yaari, 1987].          X  ,...,X , indexed in such a way that E X E X
                                                                 r                     j             j
  Weak risk-aversion can be obtained in Yaari’s model by ... ≤ E(X ). Each distribution X yields cost xi =
                                                          j
choosing a probability transformation such that ϕ(p) ≥ p v(P ,si) with probability pi for i =1,...,m.These-
                                                                        j
for all p ∈ [0, 1]. This holds also for RDW provided  quence of paths (P )j=1,...,r can be generated by imple-
function w is convex [Quiggin, 1993]. On the other hand, menting the ranking algorithm of step 2 on the initial graph
                                                                                       
when ϕ  is the identity function, then RDW boils down G  =(N,A), using a scalar valuation v : A → R+ deﬁned
                                          =1              ( )=   m     (   )                           j
to EW. Indeed, considering probabilities q(1) and    by v a      i=1 piv a, si . Indeed, the value of any path P
                     m                                              ( j)=   (  j)
q(i+1) = GX (x(i))=  k=i+1 p(k) for all i =1, ..., m − 1, in this graph is v P E X by linearity of expectation.
RDW criterion can be rewritten as follows:              Now, assume that, during the enumeration, we reach (at
                                                                    k            ( (  k)) ≥       (  β(k))
              m−1                                  step k)apathP   such that: w E X      RDW    X
  RDW(X)=       i=1  ϕ(q(i)) − ϕ(q(i+1)) w(x(i))      where  β(k) is the index of a RDW-optimal path in
                                                (3)      1      k
              +ϕ(q(m))w(x(m))                         {P  ,...,P }, then enumeration can be stopped thanks to:
From this last equation, observing that q(i) − q(i+1) = p(i), Proposition 2 If w(E(Xk)) ≥ RDW(Xβ(k)) for some k ∈
we can see that RDW reduces to EW when ϕ(z)=z for all {1,...,r},whereβ(k) is the index of a RDW-minimal path
z. Hence, RDW generalizes both EW and Yaari’s model. For in {P 1,...,Pk},thenP β(k) is a RDW-minimal solution-
the sake of generality, we consider RDW in the sequel and path in P(s, Γ).
investigate the following problem:
                                                      Proof.  We know   that P β(k) is RDW-minimal among
RDW   Search Problem.  We want to determine a RDW-    the k-ﬁrst detected paths. We only have to show that
optimal distribution in the set of all cost distributions of paths no other solution-path can have a lower weight accord-
in P(s, Γ).                                           ing to RDW.Forallj       ∈{k   +1,...,r}   we have:
                                                              j           j
This problem is NP-hard. Indeed, choosing w(x)=x,     RDW(X    ) ≥  w(E(X  )) thanks to Proposition 1. More-
                                                             ( j)  ≥    (  k)                (  (  j)) ≥
ϕ(0) =  0 and ϕ(x)=1for all     x ∈  (0,M],weget      over E  X        E X    which implies w E  X
                                                             k               β(k)                   j
RDW(X)=x(m)      =maxi  xi. Hence RDW  minimization   w(E(X   )) ≥   RDW(X       ).  Hence RDW(X    )  ≥
in a vector valued graph reduces to the min-max shortest path RDW(Xβ(k)) which shows that P β(k) is RDW-minimal
problem, proved NP-hard by Murthy and Her [1992].     over P(s, Γ).                                    2
                                                        Propositions 1 and 2 show that the ranked enumeration of
3SearchwithRDW                                        solution-paths performed at step 2 can be interrupted with-
As many other non-linear criteria, RDW breaks the Bellman out loosing the RDW-optimal solution. This establishes the
principle and one cannot directly resort to dynamic program- admissibility of our 3-steps algorithm. Numerical tests per-
ming to compute optimal paths. To overcome this difﬁculty, formed on different instances and presented in Section 5 in-
we propose an exact algorithm which proceeds in three steps: dicate that the stopping condition is activated early in the
1) linear scalarization: the cost of every arc is deﬁned as the enumeration, which shows the practical efﬁciency of the pro-
expected value of its cost distribution; 2) ranking: enumera- posed algorithm.
tion of paths by increasing order of expected costs; 3) stop-
ping condition: stops enumeration when we can prove that a 4 Dominance-based Search
RDW-optimal distribution has been found. Step 2 can be per- Functions RDW and EW provide sharp evaluation crite-
formed by kA∗, an extension of A∗ proposed by Galand and ria but require a precise knowledge of the agent’s attitude

                                                IJCAI-07
                                                  2355towards risk (at least to assess the disutility function). In Interestingly enough, relations FSD and SSD dominance
this section we consider less demanding models yet allowing relations can equivalently be deﬁned by:
well-founded discrimination between some distributions.                          ˇ        ˇ
                                                           X FSD  Y ⇔  [∀p ∈ [0, 1], GX(p) ≤ GY (p)]  (4)
                                                                                 ˇ2       ˇ2
4.1  Dominance Relations                                   X SSD  Y ⇔  [∀p ∈ [0, 1], GX(p) ≤ GY (p)]  (5)
A primary dominance concept to compare cost distributions   ˇ      ˇ2
                                                      where GX and G   are inverse functions deﬁned by:
in L is the following:                                               X
                                                         ˇ  ( )=inf{   ∈ [0  ]:    ( ) ≤ }     ∈ [0 1]
Deﬁnition 2 For all X, Y ∈L, Functional Dominance is     GX  p      z    ,M    GX  z   p  for p   ,  ,
                                                         ˇ2 ( )=   p ˇ ( )        ∈ [0 1]
deﬁned by: X FD Y ⇔ [∀s ∈ S, X(s) ≤ Y (s)]               GX  p    0 GX  q dq, for p   ,
  For relation FD and any other dominance relation  de- Since S is ﬁnite in our context, X is a discrete distribu-
                                                                          ˇ                            2
ﬁned in the sequel, the set of -optimal distributions in L ⊆ tion; therefore GX and GX are step functions. Moreover GX
L             {  ∈   : ∀  ∈         ⇒       }           ˇ2                                     ˇ2
  is deﬁned by: X  L   Y   L, Y   X    X    Y  .      and GX  are piecewise linear functions. Function GX (z) is
  When the probabilities of scenarios are known, functional known as the Lorenz function. It is commonly used for in-
                                                      equality ordering of positive random variables [Muliere and
dominance can be reﬁned by ﬁrst order stochastic dominance
                                                      Scarsini, 1989]. As an illustration, consider Example 1 with
deﬁned as follows:                                                                    ˇ2
                                                      p1 =0.4  and p2 =0.6.Wehave:GX1     (p)=18p   for all
Deﬁnition 3 For all X, Y ∈L, the First order Stochastic          ˇ2
                                                      p ∈ [0, 0.6), GX1 (p)=7.8+5p for all p ∈ [0.6, 1], whereas
Dominance relation is deﬁned by:                       ˇ2 ( )=16          ∈ [0 0 4) ˇ2 ( )=36+7
             ⇔  [∀ ∈ [0   ]    ( ) ≤   ( )]           GX5  p      p for all p , . , GX5 p     .   p for all
    X  FSD Y      z    ,M  ,GX  z   GY  z                             ˇ2        ˇ2
                                                      p ∈ [0.4, 1]; hence GX5 (p) ≤ GX1 (p) for all p and therefore
Actually, the usual deﬁnition of FSD involves cumulative 5      1                                  5
                                                      X   SSD X  . This conﬁrms the intuition that path P with
distributions FX applied to payoffs instead of decumulative                         1
                                                      cost (16, 7) is less risky than path P with cost (5, 18)
functions GX applied to costs. In Deﬁnition 3, X FSD Y
                                                        The dominance relations introduced in this subsection be-
means that X assigns no more probability than Y to events
                                                      ing transitive, the sets of FD-optimal elements, FSD-optimal
of type: “the cost of the path will go beyond z”. Hence it
                                                      elements and SSD-optimal elements are not empty. More-
is natural to consider that X is at least as good as Y when
                                                      over, these sets are nested thanks to the following impli-
X FSD Y .
                                                      cations: X FD  Y   ⇒  X  FSD  Y  and X  FSD  Y   ⇒
  Relation FSD is clearly related to the EW model since X SSD Y , for all distributions X, Y ∈L.InExam-
                                                                           1   2  3   4   5   6
X FSD  Y if and only if EW(X) ≤ EW(Y ) for all increas- ple 1 we have L = {X ,X ,X ,X  ,X  ,X  } and p1 =
ing weight function w [Quiggin, 1993].Thisgivesanice  0.4 and p2  =0.6.    Hence the set of FD-optimal ele-
                                                                 1  2   4   5   6
interpretation to Deﬁnition 3 within EU theory, with a use- ments is {X ,X ,X ,X ,X }, the set of FSD-optimal el-
ful consequence: if the agent is a EW-minimizer (with any ements is the same and the set of SSD-optimal elements is
                                                         4   5   6
increasing weight function w), then his preferred solutions {X ,X ,X }. The next section is devoted to the following:
necessarily belong to the set of FSD-optimal solutions. Now, SSD Search Problem. We want to determine all SSD-optimal
an even richer dominance relation can be considered:  distributions in the set of cost distributions of paths in P(s, Γ)
Deﬁnition 4 For all X, Y ∈L, the Second order Stochastic and for each of them, at least one solution-path.
Dominance relation is deﬁned as follows:
                              2        2
     X  SSD Y ⇔  [∀z ∈ [0,M],GX(z) ≤ GY (z)]          4.2  Problem Complexity
              
       2 ( )=  M     ( )          ∈ [0   ]            To assess complexity of the search, we ﬁrst make explicit a
where GX z     z  GX  y dy, for all z ,M  .           link between SSD and Generalized Lorenz Dominance, as
Stochastic Dominance is acknowledged as a standard way deﬁned by Marshall and Olkin [1979]. Generalized Lorenz
of characterizing risk-averse behaviors independently of any dominance, denoted GLD in the sequel, is based on the deﬁ-
utility model. For example, Rotschild and Stiglitz [1970] nition of Lorenz vector L(x)=(L1(x),...,Lm(x)) for any
and Machina and Pratt [1997] provide axiomatic character- vector x =(x1,...,xm) where Lk(x) is the sum of the k
izations of SSD in terms of risk using “mean preserving greatest components of x. Then, relation GLD is deﬁned
spreads”. As a consequence, an agent is said to be strongly as follows: x GLD y if L(x) Pareto dominates L(y),i.e.
risk-averse if he prefers X to Y whenever X SSD Y .More- Lk(x) ≤ Lk(y) for k =1,...,m.Now,ifpi =1/m   for
over, SSD  has a natural interpretation within EU theory: i =1,...,mthen SSD deﬁned by Equation (5) on distribu-
X SSD  Y if and only if EW(X) ≤ EW(Y ) for all increas- tions reduces to Lorenz dominance on the corresponding cost
                                                                            ˇ2
ing and convex weight function w [Quiggin, 1993].Asanice vectors since Lk(x)=mGX (k/m). Hence, in the particular
consequence, we know that whenever an agent is a risk-averse case of equally probable scenarios, the SSD search problem
EW-minimizer, then his preferred solutions necessarily be- reduces to the search of Lorenz non-dominated paths, a NP-
long to the set of SSD-optimal solutions. The same applies hard problem as shown by Perny and Spanjaard [2003]. This
to RDW  provided φ(q) ≥ q for all q ∈ [0, 1] and function shows that the SSD search problem is also NP-hard.
w is convex (this directly follows from a result of Quiggin          ∗
[1993]). This shows that, even outside EU theory, SSD ap- 4.3 The SSDA Algorithm
pears as a natural preference relation for risk-averse agents. Consider Example 1 and assume that the two scenarios have
It can be used as a ﬁrst efﬁcient ﬁltering of risky paths. equal probabilities, we can see that the preferred subpath

                                                IJCAI-07
                                                  2356                                                                  
from node 1 to node 5 is P = 1, 3, 5 with cost xP =(3, 10) cost-vector in ∈ F (). Such a label can be chosen,
                                                                     OPEN
which is preferred to path P = 1, 2, 5 with cost xP  = for instance, so as to minimize EW with a convex w function.
(11, 2) since (3, 10; 0.5, 0.5) SSD (11, 2; 0.5, 0.5). Indeed, At goal nodes, this priority rule guarantees to expand only
we are in the case of Subsection 4.2 (equally probable scenar- labels attached to SSD-optimal paths.
ios) with L(xP )=(10, 13) and L(xP  )=(11, 13) and ob- Pruning: the pruning of labels cannot be done directly with
viously (10, 13) Pareto dominates (11, 13). Now, appending the SSD relation, as shown in the beginning of this subsec-
                                     
path P = 5, 6 with xP  =(2, 8) to P and P respectively tion. The following pruning rules are used:
           1                   1
yields path P = P ∪ P  with cost x =(5, 18) and path  RULE 1: at node n,alabel ∈ OPEN is pruned if there exists
 4            4                    4
P  = P ∪P   with x =(13, 10). Hence L(x ) Pareto dom- another label  at the same node n such that g() FD g().
inates L(x1), therefore (13, 10; 0.5, 0.5) SSD (5, 18; 0.5, 0.5) This rule is essentially the same as in MOA∗ and is justiﬁed
which constitutes a preference reversal and illustrates a viola- by the fact that FD-optimality does satisfy the Bellman princi-
tion of Bellman principle, thus invalidating a direct dynamic ple and FD dominance implies SSD dominance. Indeed, la-
programming approach (optimal path P 4 would be lost dur- bels pruned like this necessarily lead to a FD-dominated paths
               
ing the search if P is pruned at node 5 due to P ).   and therefore cannot lead to SSD-optimal solution paths.
  However, the problem can be overcome knowing that: i) RULE 2: a label  ∈ OPEN is pruned if for all f ∈ F () there
                                                                              
SSD-optimal paths are also FD-optimal; ii) FD-optimality exists  ∈ SOL such that g( ) SSD f. This rule allows an
satisﬁes the Bellman principle; iii) the set of scenarios be- early elimination of uninteresting labels while keeping admis-
ing ﬁnite, FD-optimality on cost distributions is nothing else sibility of the algorithm provided heuristic H is admissible,
but Pareto-optimality on cost-vectors. SSD-optimal distribu- i.e. ∀n ∈ N, ∀h∗ ∈ H∗(n), ∃h ∈ H(n) s.t. h FD h∗.
tions might indeed be obtained in two stages: 1) generate Indeed, if H is admissible, then for all f ∗ ∈ F ∗() there ex-
FD-optimal solution-paths using Multiobjective A∗ (MOA∗, ists f ∈ F () such that f = g()+h FD g()+h∗ = f ∗,
Stewart and White III, 1991; Mandow and de la Cruz, 2005); which implies that f SSD f ∗ and therefore g() SSD f ∗ by
2) eliminate SSD-dominated solutions within the output set. transitivity of SSD.
However, FD-optimal solutions being often numerous, it is Note that deciding whether X SSD Y can be performed
                                                                                         ˇ2         ˇ2
more efﬁcient to focus directly on SSD-optimal solutions dur- in constant time. Indeed, since functions GX (p) and GY (p)
ing the search. For this reason we introduce now a reﬁnement are piecewise linear as indicated in Section 2, their compar-
       ∗           ∗
of MOA  called SSDA for the direct determination of SSD- ison amounts to test for Pareto dominance on the union set
optimal solutions.                                    of break points of both functions, the cardinality of which is
  As in MOA∗, SSDA∗   expands vector-valued labels (at- upper bounded by 2m.
tached to subpaths) rather than nodes. Note that, unlike Termination: the process is kept running until the set OPEN
the scalar case, there possibly exists several Pareto non- becomes empty, i.e. there is no remaining subpath able to
dominated paths with distinct cost-vectors to reach a given reach a new SSD-optimal solution path. By construction,
node; hence several labels can be associate to a same node SSDA∗ develops a subgraph of the one developped by MOA∗
n. At each step of the search, the set of generated labels is and the termination derives from the termination of MOA∗.
divided into two disjoint sets: a set OPEN of not yet expanded
labels and a set CLOSED of already expanded labels. When- 5 Numerical Tests
ever the label selected for expansion is attached to a solution
path, it is stored in a set SOL. Initially, OPEN contains only the Various tests have been performed to evaluate the perfor-
label attached to the empty subpath on node s, while CLOSED mance of algorithms on randomly generated graphs of dif-
and SOL are empty. We describe below the essential features ferent sizes. The number of nodes in these graphs varies from
                                                                                               5
of the SSDA∗ algorithm.                               1000 to 6000 and the number of arcs from 10 (for 1000
                                                                  6
Output: it determines the set of SSD-optimal solution-paths, nodes) to 5.10 (for 6000 nodes). Cost vectors are integers
i.e. solution-paths the distribution of which is SSD-optimal. randomly drawn within interval [0, 100]. Algorithms were
If several paths have the same G2 distribution, only one implemented in C++. The computational experiments were
path among them is stored using standard bookkeeping tech- carried out with a Pentium IV CPU 3.2GHz PC.
niques.                                                 Table 1 presents the average performance of algorithms for
                      ∗
Heuristics: like in MOA ,aset H(n)  of heuristic cost- different classes of instances, characterized by #nodes (the
vectors is used at any node n since n maybeonthepath  number of nodes in the graph), and m (the number of sce-
of more than one non-dominated solution. This set estimates narios). In each class, we give the average performance com-
the set H∗(n) of non-dominated costs of paths from n to Γ. puted over 20 different instances. For every class, we give
Priority: to direct the search we use a set-valued label- #SSD the average number of SSD-optimal distributions and
                                             ( )      tSSD the average time (in seconds) to solve the SSD search
evaluation function F deﬁned in such a way that, F  ,at                ∗
any label , estimates the set F ∗() of non-dominated costs problem with SSDA . Results given in Table 1 show that
                                                      the average number of SSD-optimal distributions increases
of solution paths extending the subpath associated with .                                         ∗
This set F () is computed from all possible combinations slowly with the size of the graph; moreover SSDA com-
{g()+h  : h ∈  H(n)},whereg()  denotes the value of putation times show a good efﬁciency (less than 15 sec-
the subpath associated with  and n the node to which  is onds in worst cases). The two rightmost columns of Table 1
attached. At each step of the search, SSDA∗ expands a label concern the performance in determining RDW-optimal paths
                                                                   2             1
 in OPEN such that F () contains at least one SSD-optimal with w(z)=z and ϕ(p)=p 2 .Wegive#Gen,theaver-

                                                IJCAI-07
                                                  2357