  Using Learned Browsing Behavior Models to Recommend Relevant Web Pages

    Tingshao Zhu, Russ Greiner               Gerald Haubl¨               Kevin Jewell, Bob Price
     Dept of Computing Science             School of Business           Dept of Computing Science
        University of Alberta             University of Alberta            University of Alberta
    Edmonton, Alberta T6G 2E8         Edmonton, Alberta T6G 2R6         Edmonton, Alberta T6G 2E8
  { tszhu, greiner }@cs.ualberta.ca    Gerald.Haeubl@ualberta.ca      { kjewell, price }@cs.ualberta.ca

                    Abstract                          current information need without either explicit queries nor a
                                                      large sample of past content.
    We introduce our research on learning browsing
    behavior models for inferring a user’s information 2  Model
    need (corresponding to a set of words) based on the
    actions he has taken during his current web session. For the purposes of our present work, we focus on users using
    This information is then used to ﬁnd relevant pages, the Web to obtain some information. Our goal is to automati-
    from essentially anywhere on the web. The models, cally provide the user with additional relevant content beyond
    learned from over one hundred users during a ﬁve- what would be immediately revealed by either links on their
    week user study, are session-speciﬁc but indepen- current page, or results from a search query they might initi-
    dent of both the user and website. Our empirical  ate. We assume that this activity can be separated into distinct
    results suggest that these models can identify and sessions in which the user is pursuing a single speciﬁc infor-
    satisfy the current information needs of users, even mation need.
    if they browse previously unseen pages containing   As the user browses the Web, he visits pages and takes
    unfamiliar words.                                 actions on these pages, such as following a link, backing up to
                                                      a previous page, or bookmarking a page. We view the user’s
Keywords: machine learning, web mining                web browsing actions as implicit judgments on the content
                                                      of the pages (with respect to his current information need).
1  Introduction                                       Presently, we assume that the user is looking for text-based
                                                      resources. In this case, the content of the pages is represented
While the World Wide Web contains a vast quantity of infor- by words. We theorize that the actions the user takes while
mation, it is often difﬁcult for web users to ﬁnd the relevant browsing provide evidence about the degree to which words
information they are seeking. While modern search engines on visited pages represent the user’s current information need.
have now made search over billions of web pages an every- This intuition has appeared in previous work in special
day occurrence, this approach still requires the user to explic- cases: for instance, the idea that words appearing in the an-
itly initiate a search and to formulate a speciﬁc search query. chors of hyperlinks followed by the user are probably more
The alternative approach, which involves surﬁng the web by representative of user’s needs than words that do not. Indeed,
following appropriate links, is also challenging as users can- the Letizia [Lieberman, 1995] agent and the recommender
not always determine which links are most likely to lead to created by Watson [Budzik and Hammond, 1999] use obser-
the relevant information. Our goal is a client-side Web rec- vations of user behavior to help them locate pages, but they
ommender system that simply observes the user’s browsing are both based on a limited set of hand-coded heuristic rules.
behavior, then uses this information to suggest relevant pages Alternatively, correlation-based recommenders [Agrawal and
from anywhere on the Web, without requiring the user to pro- Srikant, 1995] tend to be tied to a speciﬁc site. Moreover,
vide any additional input.                            such systems typically suggest that the current user go to
  Historically, information ﬁltering approaches avoid the pages that other similar users have visited, without knowing
need for explicit queries, but they assume the user has sta- whether previous users actually found the page helpful. Our
ble long-term interests that can be used to pick out relevant “behavior-based inference” differs from content-based sys-
material from an ongoing, dynamically changing ﬂow of con- tems [Billsus and Pazzani, 1999], as we do not require any
tent [Lewis and Knowles, 1997]. In this case, a user’s inter- previous experience with the actual words in the hyperlink
ests can be determined by statistical inference over extensive anchor; moreover, our models are explicitly trained to iden-
historical samples of the content that the user preferred. Al- tify pages that satisfy any particular information need.
ternatively, information assistants are designed to respond ef- For example in our models, following any hyperlink pro-
fectively to transient short-term information needs that vary vides evidence for the relevance of those words appearing in
from task to task using content stored in large stable reposito- the hyperlink anchor, independent of what words are actually
ries. In contrast, we present a method to determine the user’s present in the hyperlink. Consequently the technique is notrestricted to a subset of indexed sites. Indeed, we attempt 3 LILAC Study
to predict the words that best capture the user’s information The goals of the LILAC (Learn from the Internet: Log, Anno-
need with a combination of basic text-based features (e.g., the tation, Content) study are to evaluate the browsing behavior
overall frequency of the word in the user’s current session, models presented above (Section 2), and to gather data for fu-
etc.), as well as a generalized set of behavior-based features ture research, from people working on their day-to-day tasks.
(e.g., the presence of the word in anchor text, the use of the
word on a page from which the user backed up, and the order 3.1 Overview of WebIC
in which a list of links using the word were selected, etc.). WebIC (Figure 1) is a client-side, Internet Explorer-based
  Since the precise signiﬁcance of a word appearing in a fol- web browser and recommender system. It uses information
lowed hypertext anchor, or being in some font, etc., is difﬁcult from the current browsing session to recommend a page, from
to state a priori, we use machine learning methods to learn anywhere on the Web, that it predicts the user will ﬁnd useful.
the weight of each of our features, towards identifying which
word will be relevant. This is based on data collected from
a pool of calibration subjects. Once the weights have been
calculated, we can apply our user-independent models to new
users without retraining. In fact, since the models are trained
on behaviors (e.g., the value of appearing in a followed hyper-
link, etc.) instead of the information viewed (i.e., “the user is
interested in ‘baseball’ ”), the models can also be applied to
new domains without retraining, and can respond to new user
needs as they arise during browsing.
  To apply machine learning to this domain, we need a train- Figure 1: WebIC — An Effective Complete-Web Recom-
ing set. The input to the machine learning process consists of mender System
the various text-based and behavior-based features associated
with each word in the current context [WebIC, 2005], plus a To make a prediction, WebIC ﬁrst computes the brows-
target label describing whether or not the word is representa- ing features for all stemmed non-stopwords that appear in
tive of the user’s interests. We have developed three methods any page of the current browsing session. It then determines
to produce this label using different sources of information, which of these words to submit as a query to a search engine,
each based on the subjects in a calibration pool.     using one of the models learned previously. WebIC recom-
                                                      mends the top page returned from the query, as the page it
IC-wordModel: Each subject hand-labels pages that contain de- considers most likely to satisfy the user’s current information
sired information content as IC-pages (otherwise the pages are need.
considered ¬IC-pages by default). We then assume that all non-
stopwords appearing on an “IC-page” are representative of the user’s We modiﬁed WebIC for the LILAC study. Here, whenever
current information need, whereas words that do not are unrepresen- the user requests a recommendation by clicking the “Sug-
tative.                                               gest” button, WebIC will select one of its models randomly to
IC-RelevantModel: Each subject explicitly chooses words from the generate a recommendation page. As one of the goals of the
current browsing session that they felt best represented their current LILAC study is to evaluate our various models, this special-
information need. All other words are assumed to be unrepresenta- ized version of WebIC will therefore ask the user to evaluate
tive.                                                 this proposed page.
IC-QueryModel: Each subject hand-labels pages that contain de- In addition, we also instructed the participants to click
sired information content as IC-pages (otherwise the pages are con- “MarkIC” whenever they found an IC-page. After mark-
sidered ¬IC-pages by default). But while the IC-word model viewed ing an IC-page, WebIC will recommend an alternative web
all words in the IC-page as important, this model is more selective, page as before (excluding the IC-page), as if the user had
as it includes only the subset of non-stopwords that enable a search clicked “Suggest” here. Once again, this specialized version
engine (e.g., Google) to ﬁnd that page. In a separate sub-project, we
estimate a search-engine-speciﬁc function that, given a page (here of WebIC will then ask the user to evaluate this recommended
an IC-page, p) and a list of words W , estimates whether giving W page.
as a query to the search engine will produce p. Using this func- As part of this evaluation, the user is asked to “Tell us what
tion, we label only the k highest-scoring words from the session as you feel about the suggested page”, to indicate whether the
representative.                                       information provided on the suggested page was relevant to
                                                      his/her search task. There are two categories of relevance
  Given a set of browsing sessions, we can form a matrix evaluations: related and not related at all.
where each row corresponds to a word that appears, and each In addition, the user was also asked to select informa-
column to one of the browsing features. We then label each tive “Descriptive Keywords” from a short list of words that
row using one of the models described above, and run a stan- WebIC predicted as relevant. The information collected here
dard learning algorithm (e.g., C4.5) to construct 3 different will be used to train the IC-Relevant model described above.
classiﬁers. Each classiﬁer predicts whether a word is repre-
sentative of the current information need from the text-based 3.2 Experiment Design
and behavior-based features extracted from the user’s current To participate in the LILAC study, the subjects were required
browsing session.                                     to install WebIC on their own computer, and then use it whenbrowsing their own choice of non-personal English language
web pages. They were told to use another browsing engine
when dealing with private issues, such as banking, e-mail, or
perhaps chat-rooms, etc.
  WebIC kept track of all the interactions, including a record
of the pages the user visited, as well as the evaluation data for
the pages that WebIC recommends.
  LILAC considered four models: the three described in Sec-
tion 2 — IC-word, IC-Relevant, and IC-Query— and “Fol-
lowed Hyperlink Word” (FHW), which is used as a baseline.
FHW  collects the words found in the anchor text of the fol-
                                                      Figure 3: How often the User rated a Recommended Page as
lowed hyperlinks in the page sequence. As such, there is no
                                                      “Related”, after “MarkIC”
training involved in this model. This is similar to “Inferring
User Need by Information Scent (IUNIS)” model [Chi et al.,
2001]. In all models, words are stemmed and stopwords are model increased from 66% to 74%. We also observed that
removed prior to prediction.                          FHW  increased by almost 10%. As an explanation, we spec-
  We used the data collected during the study to weekly re- ulate the following: If the subject is able to ﬁnd an IC-page,
train each of our IC-models. That is, the users initially used then the links followed in the current session appear to pro-
the IC-word0, IC-Relevant0 and IC-Query0 models, which vide a very strong hint of what constitutes the relevant in-
were based on a model obtained prior to the study. On the 2nd formation content; and FHW beneﬁts signiﬁcantly from this
week, they used the IC-word1, IC-Relevant1 and IC-Query1 hint.
models, based on the training data obtained from week 1, as
well as the prior model. We repeated this process throughout 4 Conclusion and Future Work
the study.
                                                      We have demonstrated a practical and extensible framework
3.3  Overall Results                                  for a behavior-based web recommender system. The basic
                                                      framework covered here was able to ﬁnd relevant pages 70%
A total of 104 subjects participated in the ﬁve-week LILAC of the time and consistently outperformed a common baseline
study, from both Canada (97) and the US (7); 47% are fe- method (FHW). Our method can easily be extended to include
male and 53% are male, over a range of ages (everyone was at additional features (e.g., timing, multiple search engines), and
least 18, and the majority were between 21-25). The subjects to employ personalized training models for custom feature
visited 93,443 Web pages, clicked “MarkIC” 2977 times and weights. In addition, we anticipate our results, achieved us-
asked for recommendations by clicking the “Suggest” button ing C4.5, could be improved by more sophisticated learning
2531 times. As these two conditions are signiﬁcantly dif- techniques. Extensive results from our user study suggest that
ferent, we analyzed the evaluation results for “Suggest” and behavior-based recommendation is a promising approach for
“MarkIC” separately.                                  automatically ﬁnding the pages, from anywhere on the Web
                                                      that address the user’s current information need, without re-
                                                      quiring the user to provide any explicit input.
                                                      References
                                                      [Agrawal and Srikant, 1995] R. Agrawal and R. Srikant. Mining
                                                        sequential patterns. In Int’l Conference on Data Engineering
                                                        (ICDE), 1995.
                                                      [Billsus and Pazzani, 1999] D. Billsus and M. Pazzani. A hybrid
                                                        user model for news story classiﬁcation. In User Modeling, 1999.
                                                      [Budzik and Hammond, 1999] J. Budzik and K. Hammond. Wat-
                                                        son: Anticipating and contextualizing information needs. In
                                                        American Society for Information Science, 1999.
Figure 2: How often the User rated a Recommended Page as [Chi et al., 2001] E. Chi, P. Pirolli, K. Chen, and J. Pitkow. Using
“Related”, after “Suggest”                              information scent to model user information needs and actions on
                                                        the web. In ACM CHI 2001 Conference on Human Factors in
                                                        Computing Systems, pages 490–497, Seattle WA, 2001.
  Figure 2 indicates how often the user considered the “Sug-
gest”ed page to be “Related”. We see that each of our 3 IC- [Lewis and Knowles, 1997] D. Lewis and K. Knowles. Threading
                                                        electronic mail: A preliminary study. Information Processing and
models works much better than the baseline model — each Management, 33(2), 1997.
was over 65%, versus the 38% for FHW.
                                                      [Lieberman, 1995] H. Lieberman. Letizia: An agent that assists
  Figure 3 shows the evaluation results for the recommended web browsing. In IJCAI, 1995.
pages after the user clicked “MarkIC”. We again observe that
                                                      [WebIC, 2005] 2005. http://www.web-ic.com.
our IC-models work better than FHW. The scores for IC-word
and IC-Relevant remained at around 70%, roughly the same
values they had for the “Suggest” case, while the IC-Query