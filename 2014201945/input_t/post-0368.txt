Allocation and Scheduling for MPSoCs via decomposition and no-good generation

                   Luca Benini, Davide Bertozzi, Alessio Guerri, Michela Milano
                                      DEIS, University of Bologna
                               V.le Risorgimento 2, 40136, Bologna, Italy
                          {lbenini, dbertozzi, aguerri, mmilano}@deis.unibo.it


  This paper proposes a decomposition approach to the allo- Based on our methodology, the target application running
cation and scheduling of a multi-task application on a multi- on top of the hardware platform is pre-characterized and ab-
processor system-on-chip (MPSoCs) [Wolf, 2004]. This is stracted as a task graph, with speciﬁcation of computation,
currently one of the most critical problems in electronic de- storage and communication requirements. More in detail,
sign automation for Very-Large Scale Integrated (VLSI) cir- the worst case execution time (WCET) is speciﬁed for each
cuits. With the limits of chip integration reaching beyond one task and plays a critical role whenever application real time
billion of elementary devices, current advanced integrated constraints (expressed here in terms of minimum required
hardware platforms for high-end consumer application (e.g. throughput) are to be met. In fact, tasks are scheduled on each
multimedia-enabled phones) contain multiple processors and processor based on a time-wheel. The sum of the WCETs of
memories, as well as complex on-chip interconnects. The the tasks for one iteration of the time wheel must not exceed
hardware resources in these MPSoCs need to be optimally time period RT (i.e., the minimum task scheduling period en-
allocated and scheduled under tight throughput constraints suring that throughput constraints are met), which is the same
when executing a target software workload (e.g. a video de- for each processor since the minimum throughput is an appli-
coder).                                               cation (not single processor) requirement.
  The      multi-                                       The problem we are facing is a scheduling problem with
processor system                                      alternative resources. Each task should be allocated to one
consists of a pre-                                    of the processors (Node i in Figure 1). Each task also needs
deﬁned number of                                      3 memory areas for executing, that should be allocated to a
distributed com-                                      memory device: internal task state and program data can
putation nodes, as                                    be allocated either on the local scratchpad memory or on the
depicted in Figure                                    remote on-chip memory, while communication queue (the
1.  Each node is                                      memory area used by the tasks to communicate one other)
made by a process-                                    must be allocated on the local scratchpad. Tasks duration de-
ing core and  by                                      pends on where memory slots are allocated; tasks need time
a tightly coupled Figure 1: Single chip multi-processor to access the bus and use remote memory. Clearly, tasks
local   memory.   architecture.                       should be scheduled in time subject to real time constraints,
Unfortunately, the                                    precedence constraints, and capacity constraints on all unary
scratchpad memory is of limited size, therefore data in excess and cumulative resources. However, on a different perspec-
must be stored externally in a remote on-chip memory, tive, the problem decomposes into two problems: the alloca-
accessible via the bus. The bus for state-of-the-art MPSoCs tion of tasks to processors and the memory slots required by
is a shared communication resource, and serialization of bus each task to the proper memory device; a scheduling problem
access requests of the processors (the bus masters) is carried with static resource allocation.
out by a centralized arbitration mechanism.             The objective function of the overall problem is the mini-
  Whenever predictable performance is needed for applica- mization of communication cost. This function involves only
tions, it is important to avoid high levels of congestion on variables of the ﬁrst problem. In particular, we have a com-
the bus, since this makes completion time of bus transactions munication cost each time two communicating tasks are allo-
much less predictable. Moreover, under a low congestion cated on different processors, and each time a memory slot is
regime, performance of state-of-the-art shared busses scales allocated on a remote memory device. Once the communica-
almost in the same way as that of advanced busses with topol- tion cost has been minimized, among feasible schedules we
ogy and communication protocol enhancements. Finally, bus prefer those having minimum makespan.
modelling is simpler under these working conditions (e.g., ad- The allocation problem is difﬁcult to solve with Constraint
ditive models). Communication cost is therefore critical for Programming (CP). CP has a naive method for solving op-
determining overall system performance, and will be mini- timization problems: each time a solution is found, an addi-
mized in our task allocation framework.               tional constraint is added stating that each successive solutionshould be better than the best one found so far. If the objec- solve the overall problem. Actually, since the ﬁrst experi-
tive function is strongly linked to decision variables, CP can ments showed that both CP and IP were not able to ﬁnd a
be effective, otherwise it is hopeless to use CP to ﬁnd the solution, except for the easiest instances, within 15 minutes,
optimal solution. In case the objective function is related to a we simpliﬁed these models removing some variables and con-
single variable, like for makespan in scheduling problems, CP straints. In CP, we ﬁxed the activities execution time not con-
works quite well. However, if the objective function is a sum sidering the execution time variability due to remote memory
of cost variables, CP is able to prune only few values, deep accesses; in IP, we do not consider all the variables and con-
in the search tree since the connection between the objective straints involving the bus: we do not model the bus resource
function and the problem decision variables is weak. If the and we therefore suppose that each activity can access data
objective function relates to pairs of assignments the situation whenever it is necessary.
is even worse. This is the case of our application where the We generate a large variety of problems, varying both the
objective function depends on pairs of assignments. In fact, number of tasks and processors. All the results presented are
a contribution to the objective function is added when two the mean over a set of 10 problems for each task or processor
communication tasks are allocated to different processors. number. All problems considered have a solution. Experi-
  On the contrary, Integer Programming (IP) is extremely ments were performed on a 2GHz Pentium 4 with 512 Mb
good to cope with these problems, while is weak in coping RAM. We used ILOG CPLEX 8.1 and ILOG Solver 5.3 as
with time. Scheduling problems require to assign tasks to modelling and solving tools.
time slots, and each slot should be represented by an integer 1000                              In    ﬁg-
variable, and the number of variables increases enormously.                                   ure  2  we
                                                          100
                                                         )


CP, instead, is very effective to cope with time constraints. g                               compare the
                                                         o
                                                         l

                                                         (                              Hybrid
                                                          
                                                         .                                    algorithms
  Therefore, the ﬁrst problem could be solved with IP effec- c
                                                         e


                                                         s 10                           IP
                                                          


                                                         n                                    search time

tively, while for the second CP is the technique of choice. The i
                                                          


                                                         e                              CP
                                                         m

question is now: how do these problems interact?         i                                    for   prob-
  We solve them separately, the allocation problem ﬁrst  T 1                                  lems   with
(called master problem), and the scheduling problem (called                                   a   different
                                                          0.1
subproblem) later. The master is solved to optimality and    4   5  6   7   8   9  10         number
its solution passed to the subproblem solver. If the solution       Number of Tasks           of    tasks.
                                                                                              Times   are
is feasible, then the overall problem is solved to optimality. Figure 2: Comparison between algorithms
                                                                                              expressed in
If, instead, the master solution cannot be completed by the search times for different process number.
subproblem solver, a no-good is generated and added to the                                    seconds and
model of the master problem, roughly stating that the solu- the y-axis has a logarithmic scale. For space reasons we omit
tion passed should not be recomputed again (it becomes in- the search time ﬁgure varying the number of processors, but
feasible), and a new optimal solution is found for the master it has very similar behaviours to ﬁgure 2.
problem respecting the (set of) no-good(s) generated so far. Although CP and IP deal with a simpler problem model, we
Being the allocation problem solver an IP solver, the no-good can see that these algorithms are in general not comparable
has the form of a linear constraint.                  with Hybrid and, as the number of tasks grows, IP and CP
  A similar method is known in Operations Research as Ben- performances worsen and their search times become orders of
ders Decomposition [Benders, 1962], where the overall prob- magnitude higher w.r.t. Hybrid. Furthermore, we considered
lem can be decomposed in two parts connected by some  in the ﬁgures only instances where the algorithms are able to
variables. Some related approaches are [Hooker, 2004] and ﬁnd the optimal solution within 15 minutes, and, for problems
[Grossmann and Jain, 2001].                           with 6 tasks or more, IP and CP can ﬁnd the solution only in
  We show that this method is extremely effective if com- the 50% or less of the cases.
pared to the approaches considering the problem as a whole.
  The methodology proposed in this paper has been applied References
to a video signal processing pipeline, wherein each task pro- [Benders, 1962] J. F. Benders. Partitioning procedures for solv-
cesses output data of the preceding task in the pipeline. Func- ing mixed-variables programming problems. Numerische Math-
tional pipelining is widely used in the domain of multimedia ematik, 4:238–252, 1962.
applications. Task parameters have been derived from a real [Grossmann and Jain, 2001] I. E. Grossmann and V. Jain. Algo-
video graphics pipeline processing pixels of a digital image. rithms for hybrid milp/cp models for a class of optimization prob-
The proposed allocation and scheduling techniques can be lems. INFORMS Journal on Computing, 13:258–276, 2001.
easily extended to all applications using pipelining as work-
                                                      [Hooker, 2004] J. N. Hooker. A hybrid method for planning and
load allocation policy, and aim at providing system designers scheduling. In Procs. of the 10th Intern. Conference on Principles
with an automated methodology to come up with effective and Practice of Constraint Programming - CP 2004, pages 305–
solutions and cut down on design time. To do that, we sched- 316, Toronto, Canada, Sept. 2004. Springer.
ule several repetitions of the pipeline processes in order to
                                                      [Wolf, 2004] W. Wolf. The future of multiprocessor systems-on-
achieve a working rate conﬁguration.                    chips. In In Procs. of the 41st Design and Automation Conference
  To validate the strength of our approach, we now compare - DAC 2004, pages 681–685, San Diego, CA, June 2004. ACM.
the results obtained using this model (Hybrid in the follow-
ing) with results obtained using only a CP or IP model to