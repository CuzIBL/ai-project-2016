        Training Conditional Random Fields using Virtual Evidence Boosting

            Lin Liao         Tanzeem Choudhury†             Dieter Fox         Henry Kautz
                  University of Washington                            † Intel Research
       Department of Computer Science & Engineering                  1100 NE 45th St.
                      Seattle, WA 98195                              Seattle, WA 98105

                    Abstract                          eral domains. However, no general guidance has been given
                                                      on when MPL can be safely used, and indeed MPL has been
    While conditional random ﬁelds (CRFs) have been   observed to over-estimate the dependency parameters in some
    applied successfully in a variety of domains, their experiments [Geyer and Thompson, 1992].
    training remains a challenging task. In this paper, In addition, neither ML nor MPL performs feature selec-
    we introduce a novel training method for CRFs,    tion explicitly, and neither of them is able to adequately han-
    called virtual evidence boosting, which simulta-  dle continuous observations. These limitations make them
    neously performs feature selection and parameter  unsuitable for some tasks, such as activity recognition based
    estimation. To achieve this, we extend standard   on real sensor data and identifying the set of features that
    boosting to handle virtual evidence, where an ob- are most useful for classiﬁcation. Alternatively, boosting has
    servation can be speciﬁed as a distribution rather been successfully used for feature selection in the context of
    than a single number. This extension allows us to classiﬁcation problems [Viola and Jones, 2002]. However, its
    develop a uniﬁed framework for learning both local application to relational data remains an unsolved problem
    and compatibility features in CRFs. In experiments since it assumes the independence of hidden labels.
    on synthetic data as well as real activity classiﬁ- In this paper, we show how to seamlessly integrate boost-
    cation problems, our new training algorithm out-  ing and CRF training, thereby combining the capabilities of
    performs other training approaches including max- both paradigms. The integration is achieved by cutting a
    imum likelihood, maximum pseudo-likelihood, and   CRF into individual patches, as done in MPL, and using these
    the most recent boosted random ﬁelds.             patches as training instances for boosting. The key difference
                                                      to MPL, however, is that in our framework the neighbor labels
1  Introduction                                       are not treated as observed, but as virtual evidences or beliefs.
Conditional random ﬁelds (CRFs) are undirected graphical Therefore, our approach can be seen as a “soft” version of
models that were developed for labeling relational data [Laf- MPL, and is able to avoid over-estimating the neighborhood
ferty et al., 2001]. By directly modeling the conditional dependencies, as often happens in MPL.
distribution over hidden states given the observations, CRFs This paper has three main contributions. First, we extend
make no assumptions on the dependency structure between the standard boosting algorithm to handle input features that
observations. CRFs are thus especially suitable for classiﬁca- are either virtual evidences in the form of likelihood values
tion tasks with complex and overlapped observations. How- or deterministic quantities. Second, based on the extended
ever, training CRFs with very large numbers of features, espe- boosting algorithm, we present a general approach to training
cially continuous features, is still very challenging. Standard CRFs. This approach is able to
training algorithms based on maximum likelihood (ML) re- • perform feature selection and parameter estimation in a
quire running inference at each iteration of the optimization, uniﬁed and efﬁcient manner,
which can be very expensive. Moreover, since exact inference • select compatibility features and thus learn dependency
can easily become intractable in large and dense networks, structures in the relational data, and
people often have to resort to approximate inference tech- •
niques such as loopy belief propagation and Markov Chain  handle both discrete and continuous observations.
Monte Carlo. As a consequence, the ML learning procedure Third, we perform experimental validation of our algorithm
could converge to suboptimal results or even diverge. on real world activity classiﬁcation tasks as well as synthetic
  An alternative is to maximize the pseudo-likelihood of the data using CRFs with different degrees of complexity. In
training data (MPL) [Besag, 1975]. The essential idea of the comparison, our approach consistently outperforms other
MPL is to convert a CRF into a set of independent patches; training techniques.
each patch consists of a hidden node and the true values of its The rest of this paper is organized as follows. We discuss
direct neighbors. By applying ML on this simpliﬁed model, related work in the next section. In Section 3, we extend
MPL is usually very efﬁcient and has been successful in sev- boosting with virtual evidence. Then, in Section 4, we apply

                                                IJCAI-07
                                                  2530this extension to training CRFs. Finally, we show experimen- computed as
                                                                      
tal results and conclude.                                                   eF (xi)     y
                                                                         eF (xi)+e−F (xi) if i =1;
                                                           p(yi | xi)=      −F (x )                   (2)
                                                                            e   i       y     .
2  Related Work                                                          eF (xi)+e−F (xi) if i =0

Several techniques have been presented that perform feature eF (xi)  e−F (xi)                      y
                                                      where       and       represent the potentials for i =1
selection during CRF training.                                             F       M   f   x
  For discrete features, McCallum [2003] suggested an ef- and 0, respectively, and = m=1 m( i) refers to the
ﬁcient method of feature induction by iteratively increasing sum of feature functions or ensemble of weak learners. Log-
                                                      itBoost minimizes the objective function (1) with respect to F
conditional log-likelihood. Dietterich et al. [2004] applied                                           F
gradient tree boosting to select features for CRFs; their al- in a stepwise way. Speciﬁcally, given the current ensemble ,
                                                      LogitBoost selects the next weak learner fm(x) using a New-
gorithm combines boosting with parameter estimation for 1D           f   x
linear-chain models.                                  ton step and adds m( ) to the ensemble. It has been shown
  The work closest to ours is boosted random  ﬁelds   that computing the Newton step is equivalent to solving the
(BRFs) [Torralba et al., 2004], developed speciﬁcally for vi- following weighted least-square-error (WLSE) problem:
                                                                               N
sion tasks in which graphs are often very densely connected.                                    2
                                                             fm(x)   =  argmin    wi (f(xi) − zi) ,   (3)
Both BRFs and our approach combine boosting and belief                     f
propagation, and both can select compatibility dependencies                    i=1
                                                                                                yi−0.5
as well as local features. However, there are a few key differ- wi p yi | xi − p yi | xi   zi
                                                      where    =  (     )(1    (     )) and  =  p(yi|xi) are
ences. First, for learning compatibility dependencies, BRFs the weight and working response for sample i.
use linear combinations of beliefs as weak learners instead of
combinations of CRF features. So their models are not com- 3.2 Extension with Virtual Evidence
patible with standard inference techniques. Second, BRFs as- In this section we extend LogitBoost to handle virtual ev-
sume densely-connected graphs with weak pairwise connec- idences or beliefs. That is, for each feature in the fea-
tions. As we will show in our experiments, when the depen- ture vector xi, the input to boosting could be a proba-
dencies are strong, BRFs could perform poorly. Third, since bilistic distribution over that feature’s domain, as opposed
BRFs formulate the inductions of local and compatibility fea- to a single, observed value 1. We denote a distribution
tures differently, they have to specify the number of each type over the cross-product of feature values as ve(xi) with do-
of features separately. In contrast, our approach treats both { ,...,X }
                                                      main  1      i . We again aim to minimize the negative
types of features in a consistent manner and thus the algo-        −   N     p y |  x         p y |  x
rithm can determine which type is better at a given iteration. log-likelihood, i=1 log ( i ve( i)), where ( i ve( i))
In our experiments, our algorithm automatically picks reli- represents the posterior probability of a true label conditioned
                                                      on its virtual evidence. We can compute this term as follows:
able local features at the beginning and starts selecting com-     ⎧
                                                                         PX
                                                                            i       F (xi)
patibility features after accumulating enough local evidence.      ⎪       x =1 ve(xi)e
                                                                   ⎨⎪P      i                  y
                                                                       Xi        F (x ) −F (x ) if i =1;
                                                                            (xi)(e i +e   i )
                                                                       xi=1 ve
                                                      p y |  x           PX
                                                       ( i ve( i)) =        i       −F (xi)            (4)
3  Boosting with Virtual Evidence                                  ⎪      x =1 ve(xi)e
                                                                   ⎪P      i                   y    .
                                                                   ⎩   Xi        F (x ) −F (x ) if i =0
                                                                            (xi)(e i +e   i )
Boosting is a general approach for supervised learning [Fre-           xi=1 ve
                    ]                       x1,y1          
und and Schapire, 1997 . Given the training data ( ),        Xi         ±F (x )
                                                                    xi e    i
..., (xN ,yN ), where xi is a feature vector and yi is the la- Here xi=1 ve( ) computes the expected poten-
bel, boosting works by sequentially learning a set of weak tials, which replace the potentials in (2). It is also helpful
classiﬁers and combining them for ﬁnal decisions. While to think of ve(xi) as a message in random ﬁeld models; thus
traditional boosting algorithms assume feature values be de- (4) is consistent with the belief update in belief propagation.
terministic, in this section we extend them with virtual ev- To determine the next weak learner fm(x), we modify
idence [Pearl, 1988], i.e., a feature could be a distribution the LogitBoost error criterion (3) by taking the expectation
over its domain rather than a single, observed value. Specif- w.r.t. the virtual evidence:
ically, we generalize the LogitBoost algorithm [Friedman et              N
                                                                                           2
al., 2000], which directly handles probabilities and is closely fm(x) = argmin wiE (f(xi) − zi)
related to random ﬁeld models. For simplicity, we will ex-           f   i=1
plain LogitBoost and our extension only for the binary classi-           N  Xi
              y  ∈{  , }                                                                            2
ﬁcation case, i.e., i 0 1 , but both can be easily extended    =argmin           wi ve(xi)(f(xi) − zi) , (5)
to multi-class problems [Friedman et al., 2000].                     f
                                                                         i=1 xi=1

3.1  LogitBoost Algorithm                             where wi and zi can be computed as in LogitBoost, using
LogitBoost minimizes the negative log-likelihood      p(yi|ve(xi)) obtained from (4).
                                N                      The algorithm is described in Alg. 1, which constructs F
                                                        M
−log p(y1,...,yN | x1,...,xN )=−   log p(yi | xi) , (1) in iterations. Within each iteration, the algorithm ﬁrst for-
                                i=1                   mulates the WLSE problem (line 2 to 6), and then solves it to
where the right term follows from the independence between 1In this paper virtual evidence is always a discrete distribution,
labels. Using a logistic regression model, p(yi | xi) can be which is enough for training CRFs with discrete hidden states.

                                                IJCAI-07
                                                  2531  inputs : training data (ve(xi),yi), with yi ∈{0, 1},  inputs : structure of CRF and training data (xi,yi), with
         1 ≤ i ≤ N, and F =0                                   yi ∈{0, 1}, 1 ≤ i ≤ N, and F =0
  output: F that approximately minimizes Eq. (1)        output: Learned F
1 for m =1, 2, ···,M do                               1 for m =1, 2, ···,M do
2  for i =1, 2, ···,N do                              2  Run BP using F to get virtual evidences ve(xi,n(yi));
3   Compute likelihood p(yi|ve(xi)) using Eq. (4);    3  for i =1, 2, ···,N do
4   Compute weight wi = p(yi|ve(xi))(1 − p(yi|ve(xi)); 4  Compute likelihood p(yi|ve(xi,n(yi))) using Eq. (8);
                                  yi−0.5
    Compute working response zi =        ;            5   Compute weight
5                               p(yi|ve(xi))
                                                          wi = p(yi|ve(xi,n(yi)))(1 − p(yi|ve(xi,n(yi)));
6  end                                                                                    yi−0.5
                                                          Compute working response zi =             ;
7  Obtain “best” fm(x) by solving Eq. (5);            6                               p(yi|ve(xi,n(yi)))
8  Update F (x)=F (x)+fm(x)   ;                       7  end
                                                                     f
9 end                                                 8  Obtain “best” m by solving Eq. (5);
                                                      9  Update F   F   fm ;
  Algorithm 1: Extending LogitBoost with virtual evidence         =   +
                                                      10 end
                                                               Algorithm 2: Training CRFs using VEB
obtain the next weak learner (line 7). When ve(xi) is a deter-
ministic value, Eq. (4) becomes (2) and Eq. (5) becomes (3);
thus we get exactly the original LogitBoost algorithm. So our Note that while virtual evidences are provided as inputs
extension is a generalization of the original LogitBoost and to Alg. 1, VEB must update ve(xi,n(yi)) at each iteration,
is able to handle deterministic evidence as well. It can be because the messages from n(yi) keep changing as VEB up-
shown to have the same property as standard LogitBoost, i.e., dates F . Speciﬁcally, to compute the virtual evidence of yi
it minimizes the objective function using Newton steps, from a neighbor yk, vei(yk), we distinguish messages before
                                                      and after multiplying the compatibility potentials eF (yk,yi).
4  Virtual Evidence Boosting for Training             We denote these messages as λk→i(yk) and μk→i(yi), re-
   Conditional Random Fields                          spectively. These messages are computed iteratively during
                                                      belief propagation [Pearl, 1988]:  
The boosting algorithm in previous section assumes indepen-                F (yk,xk)
                                                           λk→i(yk)=αe                      μj→k(yk)  (6)
dence between training examples. How can they be applied                          j∈n(y ),j=i
to CRFs in which the labels are dependent? Similar to the                              k
MPL algorithm, we ﬁrst convert a CRF into a set of individual and            
                                                                                  F (yk,yi)
patches; each patch consists of a hidden node, its direct neigh- μk→i(yi)=β      e      λk→i(yk),     (7)
bors, and the observations. The key difference with MPL                       yk
is that, instead of using the true labels of neighbors, we use where α and β are used for normalization. As can be seen,
the messages from the neighbors as virtual evidences. Then λ–messages contain information about the distribution of the
we apply extended boosting to these independent patches for sending node yk, and μ–messages contain information about
feature selection and parameter estimation. Based on these which values the recipient node yi should prefer. While the
ideas, we develop a new training algorithm for CRFs, called μ–messages correspond exactly to the messages sent in reg-
virtual evidence boosting (VEB). VEB is a very general tech- ular belief propagation, we use each λk→i(yk) message as
nique: It can handle both continuous and discrete observa- virtual evidence vei(yk). At the end of belief propagation,
tions, and can be used in CRFs with arbitrary structures. We we generate the combined virtual evidence ve(xi,n(yi)) for
will explain VEB in the context of binary classiﬁcation; the node yi by “stacking” the observations, xi, and the received
algorithm can be readily extended to multi-class labeling, and virtual evidence messages vei(yk). The combined virtual ev-
we have done that for our experiments.                idence can then be used to compute the posterior distribution
                                                      p y |  x ,n y
4.1  The VEB Algorithm                                 ( i ve( i ( i))) using (4). Equivalently, from belief prop-
                                                      agation we have                     
The VEB algorithm is described in Alg. 2. The crucial dif-                       F (yi,xi)
                                                         p(yi|ve(xi,n(yi))) =  γe             μk→i(yi) (8)
ference between the VEB and extended LogitBoost algorithm
                                                                                        k∈n(y )
lies in the way virtual evidences are handled. The VEB con-                                 i
siders two types of evidences for a node yi. The ﬁrst type is where γ is used for normalization.
the hard evidence given as input to the algorithm, which cor- To summarize, at each iteration, VEB updates the vir-
responds to the observations xi in the training data. The sec- tual evidences via belief propagation using only those lo-
ond type is the soft evidence, corresponding to the messages cal features and compatibility potentials already contained
from neighboring nodes n(yi); these messages are obtained in F . Initially, when F =0, all posterior distributions
by running belief propagation with the current ensemble (i.e., p(yi|ve(xi,n(yi))) are uniform. It then proceeds exactly as
linear combination of feature functions) F . Our extension to the extended LogitBoost algorithm in order to add one more
boosting allows us to treat both types as virtual evidence, de- weak learner fm. In our experiments we found it sufﬁcient
noted as ve(xi,n(yi)), so that we can learn the CRF’s local to run belief propagation for only one iteration per learning
features and compatibility features in a uniﬁed framework. cycle, which greatly increases the efﬁciency of the approach.

                                                IJCAI-07
                                                  25324.2  Feature Selection in VEB                           We can unify the three cases for computing optimal feature
A key step in Alg. 2 is step 8, which ﬁnds the “best” weak weights as follows:
      f                                                                       
learner m by solving the WLSE problem. Note that since                          N  w z c
                                                                     α          i=1 i i di
a weak learner in CRFs is a certain kind of combination of             d  =   N                      (9)
features, the algorithm is essentially performing feature se-                    i=1 wicdi
lection and parameter estimation. In this paper we only con-
                                                      Here cdi is the count of feature d in data instance i (assume
sider weak learners that are linear combinations of features                              c
                                                 2    we have cut CRFs into individual patches). di can be 0 and 1
and involve one single type of local attribute or neighbor . for local features, or a real number between 0 and 1 for com-
In a nutshell, to determine the “best” weak learner, our ap- patibility features. It can also be greater than 1 if we allow
proach enumerates all types of local attributes and neighbor parameter sharing within an instance, for example, when a
relations. For each type, it computes the optimal parameters node is connected with more than one neighbor of the same
of the weak learner and the least square error. Then it picks type. Thus in our approach parameter estimation is solved by
the one with the overall least square error as well as its opti- simply performing feature counting, which makes the whole
mal parameters. In this section, we discuss how to formulate algorithm very efﬁcient.
weak learners for CRFs with binary labels and how to esti- It is important to notice that the algorithm typically ﬁrst
mate the optimal parameters efﬁciently. Speciﬁcally, we con- picks reliable local attributes since messages from neighbors
sider three different cases: when the weak learner involves are close to uniform at the beginning. Then, after some iter-
a continuous attribute, a discrete attribute, or a neighbor re- ations, it starts picking compatibility features as those mes-
lationship. While the ﬁrst two cases can be treated just like sages provide more information.
in regular LogitBoost, we apply extended boosting for the
neighbor relationships to handle virtual evidences, with the
evidences provided by belief propagation.             5   Experiments
  First, for a continuous attribute x(k), the weak learner is We evaluate the performance of VEB and compare it with
a linear combination of decision stumps:              other alternatives: boosted random ﬁelds (BRF), maximum
        (k)            (k)           (k)
     f(x   )=α1δ(x       ≥  h)+α2δ(x    <h),          likelihood (ML), and maximum pseudo-likelihood (MPL).
       h                    α      α                  We perform experiments using both synthetic data and two
 where   is the threshold, and 1 and 2 are the feature different activity recognition datasets. In all these experi-
weights. We get their (approximately) optimal values by solv-
ing the WLSE problem in (3). Speciﬁcally, h is determined ments, we run VEB as well as BRF for 50 iterations, and
using some heuristic, e.g., to maximize the information gain. in each iteration we run one iteration of belief propagation.
Then we compute the optimal α1 and α2 analytically by set- In ML and MPL learning, we use a shrinkage prior with
ting the ﬁrst-order partial derivative of the square error equal zero mean and unit variance. ML and MPL optimization are
to zero. Thus we get                                  implemented using a quasi-Newton procedure. For ML we
     PN         (k)              PN         (k)
       i=1 wiziδ(xi ≥ h)           i=1 wiziδ(xi <h)   evaluate the likelihood using the Bethe method [Yedidia et
α1 = P                      α2 = P
       N       (k)      and        N       (k)        al., 2005] and its gradient using belief propagation. All the
          wiδ(x   ≥ h)                wiδ(x   <h)
       i=1     i                   i=1     i          learned models are tested using the MAP belief propagation,
                                (k)
Second, given a discrete attribute x ∈{1, ···,D}, the except that we have to use a speciﬁc inference algorithm for
weak learner is expressed as                          BRF, as described in [Torralba et al., 2004]. All accuracies
                       D
           f x(k)         α δ x(k)   d ,              are calculated based on the MAP labels. All experiments
            (   )=          d (   =   )               were run on a standard desktop PC with 3.4GHz CPU and
                       d=1                            1GB of memory.
                                (k)
where αd is the weight for feature δ(x = d), an indicator
function which is 1 if x(k) = d and 0 otherwise. The optimal 5.1 Synthetic Data
weights can be calculated similarly as:               VEB versus BRF
                    PN         (k)
                      i=1 wiziδ(xi = d)               VEB and BRF are similar. However, BRF assumes the graphs
            αd  =    P
                       N       (k)                    are densely connected and thereby each individual message
                          wiδ(x  = d)
                       i=1     i                      is not very informative, while VEB does not make any as-
  Third, given a certain type of neighbor and correspond- sumption about the connectivity structure. This difference is
ing virtual evidence vei(yk), the weak learner is the weighted signiﬁcant because although their assumption is often true for
sum of two indicator functions (compatibility features): the vision applications discussed in [Torralba et al., 2004],it
                       X1
                                                      may be invalid for many other applications. In this experi-
             f(yk)=       αdδ(yk = d).
                       d=0                            ment, we examine the performance of VEB and BRF as the
                                                      dependencies between nodes get stronger.
  Solving the WLSE problem with virtual evidence, as in (5), The synthetic data is generated using a ﬁrst-order Markov
we get the optimal weights:
                   N                                 chain with binary labels. To emphasize the difference on
                         wizivei(yk = d)              learning compatibility features, we intentionally use weak ob-
           α        i=1
            d   =     N                               servation models: each label is connected to 50 binary obser-
                          wivei(yk = d)
                      i=1                             vations and the conditional probabilities in the observation
  2Complex weak learners, such as decision trees involving differ- models are uniformly sampled from the range [0.45, 0.55].
ent attributes, can also be learned in similar ways.  We adjust the transition probabilities (from label 0 to 0 and

                                                IJCAI-07
                                                  2533    1                       0.7                                Training algorithm  Average accuracy
       VEB
   0.9 BRF                                                           VEB                94.1%
                            0.65
   0.8                                                               BRF                88.0%

   0.7                      0.6                               ML + all observations     87.7%
  Accuracy

                           Accuracy                              ML + boosting          88.5%
   0.6
                            0.55                             MPL + all observations     87.9%
   0.5
     0.5 0.6 0.7 0.8 0.9    0.5                                 MPL + boosting          88.5%
         Transition Prob (a)    VEB BRF MPL ML  (b)
                                                              Table 1: Average accuracy for indoor activities
Figure 1: Classiﬁcation accuracies in experiments using synthetic
data, where the error bars indicate 95% conﬁdence intervals. (a)
VEB vs. BRF when the transition probabilities (pairwise dependen- 5.2 Real Activity Recognition Data
cies) turn from weak to strong. (b) Comparison of different learning CRFs are well-suited for the tasks of activity recognition us-
algorithms for feature selection.                     ing real sensor data, because of the overlaps between mea-
from label 1 to 1) from 0.5 to 0.99. For each given transition surements and the strong relationships between activities. In
and observation model, we generate ten 2,000-labels chains this section, we compare different training approaches on
and perform leave-one-out cross-validation using a linear- such CRFs. Although VEB and BRF can handle continuous
chain CRF. We additionally run the experiments several times sensor measurements directly, doing that in ML and MPL is
by randomly generating different observation models.  not straightforward. The performance of ML and MPL is ter-
  The running durations of both algorithms are very similar, rible if we simply use the continuous measurements as fea-
so we only compare the accuracies. The average accuracies ture values. This is due to the fact that such features cor-
using VEB and BRF and their conﬁdence intervals are shown respond to a zero-mean Gaussian assumption, which could
in Fig. 1(a). It is clear that when the compatibility dependen- be far from the truth. We try two tricks to circumvent this
cies are not strong (transition probabilities range from 0.5 to difﬁculty. One is to learn decision stumps for all observa-
0.8), both methods give very similar accuracies. However, as tions, using the heuristics as in VEB and BRF. The other is to
the dependencies get stronger (from 0.9 to 0.99), VEB dra- use boosting (e.g., LogitBoost in our experiment) to select a
matically outperforms BRF, mainly because the weak inter- set of decision stump features and these decision stumps are
action assumption underlying BRF does not hold any more. then fed into ML and MPL for weight estimation (as done in
                                                      [                  ]
Feature Selection in Complex Models                    Friedman et al., 2007 ).
Many real sequential estimation problems have long-range
dependencies, which can be modeled using high-order   Indoor Activity Recognition
Markov models. However in practice it is often impossible In the ﬁrst experiment, one person collected audio, accelera-
to know the exact order, so people may have to use Markov tion, and light sensor data as he stayed indoors using a small
models that have longer dependencies than the actual data. wearable device. The total length of the data set is about
In this experiment, we simulate this scenario by generating 1,100 minutes, recorded over a period of 12 days. The goal
synthetic data using a high-order Markov model, whose tran- is to recognize the person’s major indoor activities including
sition probability p(yn | y1:n−1)=p(yn | yn−k), where k computer usage, meal, meeting, TV watching and sleeping.
is a constant (the observation model is similar as the one in We segmented the data into one-minute chunks and manually
the previous experiment). That is, a label yn only depends labeled the activity at each minute for the purpose of super-
on one past label yn−k, but the value of k is unknown to the vised learning and testing. For each chunk of data, we com-
CRF model. Speciﬁcally, we pick k from 1 to 5, and we set puted 315 feature values, which included energy in various
the transition probability p(yn | yn−k) as 0.9 if yn = yn−k frequency bands (log and linear) of the signal, autocorrela-
and 0.1 otherwise. For a given k, we generate ten 2,000-long tion, different entropy measures, etc. These features are fed
chains and perform leave-one-out cross-validation. We repeat into the CRF as observations, and one linear chain CRF is cre-
the experiment for different k’s and compute the average. ated per day. We evaluate our algorithm using leave-one-out
  Since the exact value of k is unknown to the CRF model, cross-validation. Because the person performs different ac-
we generate a densely-connected CRF that has connections tivities in different days, the accuracies can vary signiﬁcantly
between each pair of nodes whose distance is less than or from day to day. Some activities, such as meals, are hard
equal to 5; then the CRF was trained using different algo- to recognize, while other activities, such as sleeping, are rela-
rithms. In our experiments, VEB can reliably identify the tively easy to recognize. As a result, in the leave-one-day-out-
correct values of k, i.e., picking only pairwise features whose cross-validation, the accuracies for different days vary signif-
distance is k or multiples of k. Although BRF also performs icantly and the standard deviation is rather large. The overall
feature selection and structure learning, it does not perform as average accuracies using the different methods are shown in
well as VEB. The average classiﬁcation accuracies are shown Table 1, in which VEB is about 5% to 6% better than ML and
in Fig. 1(b). Because VEB can robustly extract the sparse MPL, no matter how they incorporate the continuous obser-
structures, it signiﬁcantly outperforms other approaches. As vations. Even though the error bars of the different techniques
to the running time, VEB, BRF, and MPL are all quite efﬁ- overlap, our approach is signiﬁcantly (0.05 level) better than
cient; each training takes only tens of seconds. In contrast, its competitors when we evaluate the combination of the dif-
the training using ML takes about 20 minutes.         ferent experiments reported in the paper.

                                                IJCAI-07
                                                  2534