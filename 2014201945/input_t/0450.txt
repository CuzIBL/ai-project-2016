         Automatic Text-to-Scene Conversion in the Trafﬁc Accident Domain
    Richard Johansson           Anders Berglund          Magnus Danielsson            Pierre Nugues
                      LUCAS, Department of Computer Science, Lund University
                                                Box 118
                                       SE-221 00 Lund, Sweden
                   {richard, pierre}@cs.lth.se, d98ab@efd.lth.se
                               magnus.danielsson2@comhem.se

                    Abstract                          ing the temporal dimension completely. Most of them are
                                                      limited to recreating static scenes.
    In this paper, we describe a system that automati-  In this paper, we describe a new version of the Carsim sys-
    cally converts narratives into 3D scenes. The texts, tem [Johansson et al., 2004; Dupuy et al., 2001],whichis
    written in Swedish, describe road accidents. One  a text-to-scene converter that handles real texts and that we
    of the program’s key features is that it animates the evaluated using quantitative methods. The program gener-
    generated scene using temporal relations between  ates 3D graphics from trafﬁc accident reports generally col-
    the events. We believe that this system is the ﬁrst lected from web sites of Swedish newspapers. One of its key
    text-to-scene converter that is not restricted to in- features is that it takes time and temporal relations between
    vented narratives.                                events into account to animate the synthesized scene.
    The system consists of three modules: natural lan-  The structure of this article is as follows: Section 2 de-
    guage interpretation based on information extrac- scribes the Carsim system and the application domain. Sec-
    tion (IE) methods, a planning module that produces tion 3 details the implementation of the natural language in-
    a geometric description of the accident, and ﬁnally terpretation module. Then, in Section 4, we turn to the spatial
    a visualization module that renders the geometric and temporal reasoning that is needed to construct the visual-
    description as animated graphics.                 ization. The evaluation is described in Section 5. Finally, we
    An evaluation of the system was carried out in two discuss the results and their implications in Section 6.
    steps: First, we used standard IE scoring methods
    to evaluate the language interpretation. The results
    are on the same level as for similar systems tested 2 The Carsim System
    previously. Secondly, we performed a small user   Narratives of a car accidents often make use of space descrip-
    study to evaluate the quality of the visualization. tions, movements, and directions that are sometimes difﬁcult
    The results validate our choice of methods, and   to grasp for readers. We believe that forming consistent men-
    since this is the ﬁrst evaluation of a text-to-scene tal images is necessary to understand them properly. How-
    conversion system, they also provide a baseline for ever, some people have difﬁculties in imagining situations
    further studies.                                  and may need visual aids pre-designed by professional an-
                                                      alysts.
                                                        Carsim is a computer program1 that addresses this need.
1  Introduction                                       It is intended to be a helpful tool that can enable people to
For a machine, text-to-scene conversion consists in synthe- imagine a trafﬁc situation and understand the course of events
sizing a 2D or 3D geometric description from a text and in properly. The program analyzes texts describing car accidents
displaying it. Ideally, a text-to-scene converter would recreate and visualizes them in a 3D environment.
mental images we form when we read a text. This represents a To generate a 3D scene, Carsim combines natural lan-
demanding task involving semantic and cognitive capabilities guage processing components and a visualizer. The language
and to many people seems both a far off and surreal fantasy. processing module adopts an information extraction strategy
However, there have been a small number of systems that and includes machine learning methods to solve coreference,
provided insights into the feasibility of it while at the same classify predicate/argument structures, and order events tem-
time showing signiﬁcant limitations [Adorni et al., 1984; porally. However, as real texts suffer from underspeciﬁcation
Coyne and Sproat, 2001; Arens et al., 2002]. First, all the and rarely contain a detailed geometric description of the ac-
systems are restricted to very simple narratives, typically in- tions, information extraction alone is insufﬁcient to convert
vented by the authors themselves. Furthermore, none of the narratives into images automatically. To handle this, Carsim
authors report details on the text corpus they used or any pre-
cise description of the results. Another signiﬁcant point is 1An online demonstration of the system is available at
that these systems all focus on spatial relations, while ignor- http://www.lucas.lth.se/lt.infers implicit information about the environment and the in- Text       Symbolic         Geometric
                                                                          repr.           description
volved entities from key phrases in the text, knowledge about  Interpretation     Planning         Rendering
typical trafﬁc situations, and properties of the involved enti-
ties. The program uses a visualization planner that applies
spatial and temporal reasoning to “imagine” the entities and
                                                               Linguistic World  Geometric
actions described in the text, and that tries to ﬁnd the simplest knowledge knowledge knowledge
conﬁguration that ﬁts the description.
                                                                   Figure 1: System architecture.
2.1  A Corpus of Trafﬁc Accident Descriptions
Carsim has been developed using authentic texts. As a devel-
opment set, we collected approximately 200 reports of road We use the intermediate representation as a bridge between
accidents from various Swedish newspapers. The task of an- texts and geometry. This is made necessary because the in-
alyzing the news reports is made more complex by their vari- formation expressed by most reports has usually little afﬁnity
ability in style and length. The size of the texts ranges from a with a geometric description. Exact and explicit accounts of
couple of sentences to more than a page. The amount of de- the world and its physical properties are rarely present. In ad-
tails is overwhelming in some reports, while in others, most dition, our vocabulary is ﬁnite and discrete, while the set of
of the information is implicit. The complexity of the acci- geometric descriptions is inﬁnite and continuous.
dents described ranges from simple crashes with only one car Once the NLP module has interpreted and converted a text,
to multiple collisions with several participating vehicles and the planner maps the resulting symbolic representation of the
complex movements. Although our work has concentrated on world, the entities, and behaviors, onto a complete and unam-
the press clippings, we also have access to accident reports biguous geometric description in a Euclidean space.
from the STRADA database (Swedish TRafﬁc Accident Data  Certain facts are never explicitly stated, but are assumed by
Acquisition) of Vägverket, the Swedish trafﬁc authority. the author to be known to the reader. This includes linguistic
  The next text is an excerpt from our test corpus. This report knowledge, world knowledge (such as trafﬁc regulations and
is an example of a press wire describing an accident. typical behaviors), and geometric knowledge (such as typi-
                                                      cal sizes of vehicles). The language processing and planning
       En bussolycka i södra Afghanistan krävde på torsda- modules take this knowledge into account in order to produce
    gen 20 dödsoffer. Ytterligare 39 personer skadades i oly- a credible geometric description that can be visualized by the
    ckan som inträffade tidigt på torsdagsmorgonen två mil renderer.
    norr om staden Kandahar. Bussen var på väg från Kan-
    dahar mot huvudstaden Kabul när den under en omkörn- 2.3 The Symbolic Representation
    ing körde av vägbanan och voltade, meddelade general
                                                      The symbolic representation has to manage the following
    Salim Khan, biträdande polischef i Kandahar. Läget för
                                                      trade-off. In order to be able to describe a scene, it must con-
    några av de skadade uppgavs som kritiskt.
                                                      tain enough information to make it feasible to produce a con-
            TT-AFP & Dagens Nyheter, July 8, 2004     sistent geometric description, acceptable to the user. On the
       A bus accident in southern Afghanistan last Thurs- other hand, the representation has to be close to ways human
    day claimed 20 victims. Additionally, 39 people were beings describe things to capture information in the texts.
    injured in the accident, which occurred early Thursday We used four concept categories that we ordered in an in-
    morning twenty kilometers north of the city Kandahar. heritance hierarchy. The representation is implemented using
    The bus was on its way from Kandahar towards the capi- Minsky-style (“object-oriented”) frames, which means that
    tal Kabul when it left the road while overtaking and over- the objects in the representation consist of a number of prede-
    turned, said general Salim Khan, assistant head of police ﬁned attribute/values slots. This ontology was designed with
    in Kandahar. The state of some of the injured was said to assistance of trafﬁc safety experts. It consists of:
    be critical.                                        • Objects. These are typically the physical entities that are
                    The text above, our translation.      mentioned in the text, but we might also need to present
                                                          abstract or oneiric entities as symbols in the scene. Each
2.2  Architecture of the Carsim System                    object has a type that is selected from a predeﬁned, ﬁnite
                                                              Car     Truck
We use a division into modules where each one addresses one set.  and       are examples of object types.
step of the conversion process (see Figure 1).          • Events. They correspond intuitively to an activity that
  •                                                       goes on during a period in time and here to the possible
    A natural language processing module that interprets  object behaviors. We represent events as entities with
    the text to produce an intermediate symbolic represen- a type from a predeﬁned set. Overturn and Impact
    tation.                                               are examples.
  •
    A spatio-temporal planning and inference module that • Relations and Quantities. The objects and the events
    produces a full geometric description given the symbolic need to be described and related to each other. The most
    representation.                                       obvious examples of such information are spatial infor-
  • A graphical module that renders the geometric descrip- mation about objects and temporal information about
    tion as graphics.                                     events. We should be able to express not only exact    quantities, but also qualitative information (by which using a two-step procedure. First, we identify and mark up
    we mean that only certain fundamental distinctions are text fragments that describe events, and locate and classify
    made). Behind, FromLeft,andDuring     are exam-   their arguments. Secondly, we interpret the fragments in or-
    ples of spatial and temporal relations.           der to produce event objects as well as the involved partici-
  • Environment. The environment of the accident is impor- pants, spatial and temporal relations, and information about
    tant for the visualization to be understandable. Signif- the environment. This two-step procedure is similar to other
    icant environmental parameters include light, weather, work that uses predicate-argument structures for IE, for ex-
    road conditions, and type of environment (such as rural ample [Surdeanu et al., 2003].
    or urban). Another important parameter is topography, We classify the arguments of each predicate (assign them
    but we have set it aside since we have no convenient way a semantic role) using a statistical system, which was trained
    to express this qualitatively.                    on about 900 hand-annotated examples. Following Gildea
                                                      and Jurafsky [2002], there has been a relative consensus on
3  Natural Language Interpretation                    the features that the classiﬁer should use. We use a slightly
                                                      different set; since we have no full parser, there are no fea-
We use information extraction techniques to interpret the text.
                                                      tures that refer to the parse tree. Also, since the system is
This is justiﬁed by the symbolic representation, which is re-
                                                      domain-speciﬁc, we have introduced a semantic type feature
stricted to a limited set of types and the fact that only a part
                                                      that takes the following values: dynamic object, static object,
of the meaning of the text needs to be presented visually. The
                                                      human, place, time, cause, or speed.
IE module consists of a sequence of components (Figure 2).
                                                        Similarly to the method described by Gildea and Jurafsky
The ﬁrst components carry out a shallow parse: POS tagging,
                                                      [2002], the classiﬁer chooses the role that maximizes the es-
NP chunking, complex word recognition, and clause segmen-
                                                      timated probability of a role given the values of the target,
tation. This is followed by a cascade of semantic markup
                                                      head, and semantic type attributes:
components: named entity recognition, temporal expression
detection, object markup and coreference, and predicate ar-                     C(r, t, head, sem)
                                                              Pˆ(r|t, head, sem)=               .
gument detection. Finally, the marked-up structures are in-                      C(t, head, sem)
terpreted to yield the resulting symbolic representation of the
accident. The development of the IE module has been made If a particular combination of target, head, and semantic type
more complex by the fact that few tools or annotated cor- is not found in the training set, the classiﬁer uses a back-off
pora are available for Swedish. The only signiﬁcant external strategy, taking the other attributes into account. In addition,
tool we have used is the Granska POS tagger [Carlberger and we tried other classiﬁcation methods (ID3 with gain ratio,
Kann, 1999].                                          SVMs) without any signiﬁcant improvement.
3.1  Entity Detection and Coreference                   When the system has located the references to domain
                                                      events in the text, it can interpret them; that is, we map the text
A correct detection of the involved entities is crucial for the fragments onto entities in the symbolic representation. This
graphical presentation to be understandable. We ﬁrst search stage makes signiﬁcant use of world knowledge, for example
the likely participants among the noun phrases in the text by to handle relationships such as metonymy and ownership.
checking them against a dictionary. We then apply a corefer- Since it is common that events are mentioned more than
ence solver to link the groups that refer to identical entities. once in the text, we need to remove the duplicates in order
This results in a set of equivalence classes referring to entities not to introduce unnecessary animations. Event coreference
that are likely to be participants in the accident.   is a task that can be treated using similar methods as those we
  The coreference solver uses a hand-written ﬁlter in con- used for object coreference. However, event coreference is a
junction with a statistical system based on decision trees simpler problem since the range of candidates is narrowed by
[              ]
Danielsson, 2005 . The ﬁlter ﬁrst tests each antecedent- the involved participants and the event type. To get a minimal
anaphor pair using 12 grammatical and semantic features to description of the course of events, we have found that it is
prevent unlikely coreference. The statistical system then uses sufﬁcient to unify as many events as possible, taking event
20 features to classify pairs of noun groups as coreferring or types and participants into account.
not. These features are lexical, grammatical, and semantic.
                                                        Finally, we ﬁll in the information that is lacking due to mis-
The trees were induced from a set of hand-annotated exam- takes or underspeciﬁcation using default and heuristic rules.
ples using the ID3 algorithm and a method inspired by Soon Thus, we have a complete description of the events and the
et al. [2001]. We implemented a novel feature transfer mech-
                                                      participants.
anism that propagates and continuously changes the values
of semantic features in the coreference chains during clus- 3.3 Temporal Ordering of Events
tering. This means that the coreferring markables inherit se-
mantic properties from each other. Feature transfer, as well Since we produce an animation rather than just a static image,
as domain-speciﬁc semantic features, proved to have a signif- we take time into account and we ﬁnd the temporal relations
icant impact on the performance.                      between the events. Although the planner alone can infer a
                                                      probable course of events given the positions of the partici-
3.2  Domain Events                                    pants, and some orderings are deducible by means of simple
In order to produce a symbolic representation of the accident, ad-hoc rules that place effects after causes (such as a ﬁre after
we need to recreate the course of events. We ﬁnd the events a collision), we have opted for a general approach.      Text
                                                  Clause                                       Pred / arg
               POS tagging Complex words NP Chunking       NE recognition Time detector Object detector
                                                 segmentation                                  detector

                                                                                              Intermediate
     Object     Pred/arg   Metonymy    Spatial    Event     Environment  Event
                                                                                   Defaults  representation
    coreference interpretation resolution interpretation coreference inference ordering

                           Figure 2: Architecture of the language interpretation module.

  We developed a component based on the generic TimeML initial directions and positions. Finally, it uses a search algo-
framework [Pustejovsky et al., 2002]. We ﬁrst create an or- rithm to ﬁnd the trajectory layout. Since we use no backtrack-
dering of all events in the text (where all verbs, and a small ing, this separation into steps introduces a risk of bad choices.
set of nouns, are considered to refer to events) by generating However, it reduces the computation load and proved sufﬁ-
temporal links (orderings) between the words that denote the cient for the texts we considered, enabling an interactive gen-
events. The links are generated by a hybrid system that con- eration of 3D scenes and a better user experience.
sists of a statistical system based on decision trees and a small
set of hand-written heuristics.                       4.1  Finding the Constraints
  The statistical system considers events that are close to The constraints on the animation are created using the de-
each other in the text, and that are not separated by ex- tected events and the spatial and temporal relations combined
plicit temporal expressions. It was trained on a set of hand- with the implicit knowledge about the world. The events are
annotated examples, which consists of 476 events and 1,162 expressed as conjunctions of primitive predicates about the
temporal relations. The decision trees were produced using objects and their behavior in time. For example, if we state
the C4.5 tool [Quinlan, 1993] and make use of the following that there is an Overtake event where O1 overtakes O2,this
information:                                          is translated into the following proposition:

  • Tense, aspect,andgrammatical construct of the verb         ∃t1,t2.MovesSideways(O1,Left,t1)
    groups that denote the events.                             ∧P asses(O1,O2,t2) ∧ t1 <t2
  •
    Temporal signals between the words. This is a TimeML In addition, other constraints are implied by the events and
    term for temporal connectives and prepositions such as our knowledge of the world. For example, if O1 overtakes
    “when”, “after”, and “during”.                    O2, we add the constraints that O1 is initially positioned be-
  • Distance between the words, measured in tokens, sen- hind O2,andthatO1 has the same initial direction as O2.
    tences, and in punctuation signs.                 Other constraints are added due to the non-presence of events,
                                                      such as
  The range of possible output values is the following subset
of Allen’s relations: simultaneous, after, before, is_included, NoCollide(O1,O2) ≡¬∃t.Collides(O1,O2,t)
includes,andnone.                                                                        O      O
  After the decision trees have been applied, we remove if there is no mentioned collision between 1 and 2.
conﬂicting temporal links using probability estimates derived 4.2 Finding Initial Directions and Positions
from C4.5. Finally, we extract the temporal relations between
the events that are relevant to Carsim.               We use constraint propagation techniques to infer initial di-
                                                      rections and positions for all the involved objects. We ﬁrst
3.4  Inferring the Environment                        set those directions and positions that are stated explicitly.
                                                      Each time a direction is uniquely determined, it is set and this
The environment is important for the graphical presentation
                                                      change propagates to the sets of available choices of direc-
to be credible. We use traditional IE techniques, such as
                                                      tions for other objects, whose directions have been stated in
domain-relevant patterns, to ﬁnd explicit descriptions of the
                                                      relation to the ﬁrst one. When the direction can’t be deter-
environment.
                                                      mined uniquely for any object, we pick one object and set its
  As noted by the WordsEye team [Sproat, 2001], the envi-
                                                      direction. This goes on until the initial directions have been
ronment of a scene may often be obvious to a reader even
                                                      inferred for all objects.
though it is not described in the text. In order to capture this
information, we try to infer it using prepositional phrases that 4.3 Finding the Trajectories
occur in the description of the events. We then use a Naïve
Bayesian classiﬁer to guess the environment.          After the constraints have been found, we use the IDA*
                                                      search method to ﬁnd a trajectory layout that is as simple as
                                                      possible while violating no constraints. As heuristic func-
4  Planning the Animation                             tion, we use the number of violated constraints multiplied by
We use a planning system to create the animation out of the a constant in order to keep the heuristic admissible.
extracted information. It ﬁrst determines a set of constraints The most complicated accident in our development con-
that the animation needs to fulﬁll. Then, it goes on to ﬁnd the tains 8 events, which results in 15 constraints during search,and needs 6 modiﬁcations of the trajectories to arrive at a tra- The results of the event detection is comparable to those re-
jectory layout that violates no constraints. This solution is ported in previously published work. [Surdeanu et al., 2003]
found in a few seconds. Most accidents can be described us- reports an F-measure of 0.83 in the Market Change domain
ing only a few constraints.                           for a system that uses similar IE methods.2 Although our sys-
  At times, no solution is found within reasonable time. Typ- tem has a different domain, a different language, and different
ically, this happens when the IE module has produced in- resources (their system is based on PropBank), the ﬁgures
correct results. In this case, the planner backs off. First, are roughly similar. The somewhat easier task of detecting
it relaxes some of the temporal constraints (for example: the objects results in higher ﬁgures, demonstrating that the
Simultaneous  constraints are replaced by NearTime).  method chosen works satisfactorily for the task at hand.
Next, all temporal constraints are removed.             We believe that the ﬁgures for the temporal relations will
                                                      prove competitive. We are not aware of any previous result in
5  Evaluation                                         automatic detection of temporal relations in IE. The ﬁgures
                                                      also show that the difference between the methods of eval-
We evaluated the components of the system, ﬁrst by measur-
                                                      uation is relatively small, suggesting that both methods are
ing the quality of the extracted information using standard IE
                                                      useful when evaluating temporal orderings.
evaluation methods, then by performing a user study to deter-
mine the overall perception of the complete system. For both 5.2 User Study to Evaluate the Visualization
evaluations, we used 50 previously unseen texts, which had
been collected from newspaper sources on the web. The size Four users were shown the animations of subsets of the 50 test
of the texts ranged from 36 to 541 tokens.            texts. Figure 3 shows an example corresponding to the text
                                                      from Subsection 2.1. The users graded the quality of anima-
5.1  Evaluation of the Information Extraction         tions using the following scores: 0 for wrong, 1 for “more or
     Module                                           less” correct, and 2 for perfect. The average score was 0.91.
For the IE module, three aspects were evaluated: object de- The number of texts that had an average score of 2 was 14 (28
tection, event detection, and temporal ordering of the events. percent), and the number of texts with an average score of at
Table 1 shows the precision and recall ﬁgures.        least 1 was 28 (56 percent). These ﬁgures demonstrate that
                                                      the chosen strategy is viable, especially in a restricted con-
                                                      text like the trafﬁc accident domain. However, interpretation
                                 P      R    Fβ=1
                                                      of the ﬁgures is difﬁcult since there are no previously pub-
 Objects                        0.96   0.86  0.91
                                                      lished results. In any case, they provide a baseline for further
 Events                         0.86   0.85  0.85
                                                      studies, possibly in another domain.
 Temporal relations (correct events) 0.73 0.55 0.62     To determine whether the small size of our test group in-
 Temporal relations (all events) 0.61  0.51  0.55     troduced a risk of invalid results, we calculated the standard
                                                      deviation of annotations3, and we obtained the value of 0.45.
    Table 1: Statistics for the IE module on the test set. Replacing all annotations with random values from the same
                                                      probability distribution resulted in a standard deviation of
  The evaluations of object and event detection were rather 0.83 on average. In addition, the pairwise correlation of the
straightforward. A road object was considered to be correctly annotations is 0.75. This suggests that the agreement among
detected if a corresponding object was either mentioned in or annotators is enough for the ﬁgures to be relevant.
implicit from the text, and the type of the object was correct. During discussions with users, we had a number of unex-
The same criteria applied to the detection of events, but here pected opinions about the visualizations. One important ex-
we also added the criterion that the actor (and victim, where ample of this is the quantity of implicit information they infer
it applies) must be correct.                          from reading the texts. For example, given a short descrip-
  Evaluating the quality of the temporal orderings proved to tion of a crash in an urban environment, one user imagined a
be less straightforward. First, to make it feasible to compare collision of two moving vehicles at an intersection, while an-
the graph of orderings to the correct graph, it must be con- other user interpreted it as a collision between a moving and
verted to some normal form. For this, we used the transitive a parked car.
closure (that is, we made all implicit links explicit). The tran- This user response shows that the task of imagining a situ-
sitive closure has some drawbacks – for example, one small ation is difﬁcult for humans as well as for machines. Further-
mistake may cause a large impact on the precision and recall more, while some users have suggested that we improve the
measures if many events are involved. However, we found no realism (for example, the physical behavior of the objects),
other obvious method for normalizing the temporal graphs. discussions generally made it clear that the semi-realistic
  A second problem to resolve was that of how to evaluate graphics that we use (see Figure 3) may suggest to the user
temporal orderings when the events are not all correctly de-
tected. This difﬁculty arises when the event coreference res- 2We have assumed that the Templettes that they use roughly can
olution fails and multiple instances of the same event are re- be identiﬁed with events. rP
                                                                                                  2
ported. Because of this complication, we measured the link                                  (xij −x˙ i)
                                                         3We calculated this using the formula P   ,where
precision and recall for two cases: ﬁrst, only those links that                              (ni−1)
connect properly detected events; secondly, all links. We then xij is the score assigned by annotator j on text i, x˙ i the average
compared the results.                                 score on text i,andni the number of annotators on text i.