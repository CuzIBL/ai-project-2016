                     Using core beliefs for point-based value iteration

        Masoumeh T. Izadi                   Ajit V. Rajwade                    Doina Precup
         McGill University                University of Florida              McGill University
    School of Computer Science             CISE Department              School of Computer Science
        mtabae@cs.mcgill.ca                 avr@cise.uﬂ.edu                dprecup@cs.mcgill.ca


                    Abstract                          behavior of the PBVI algorithm. We discuss how core beliefs
                                                      can be found, and we illustrate the behavior of the algorithm
    Recent research on point-based approximation al-  on several standard POMDP benchmarks.
    gorithms for POMDPs demonstrated that good so-
    lutions to POMDP problems can be obtained with-   2   POMDPs and point-based value iteration
    out considering the entire belief simplex. For in-
                                                                                               Ω    γ
    stance, the Point Based Value Iteration (PBVI) al- A POMDP is described by a tuple hS,A,O,T, ,R, ,b0i,
    gorithm [Pineau et al., 2003] computes the value  where S is a ﬁnite set of states, A is a ﬁnite set of actions
    function only for a small set of belief states and it- and O is a ﬁnite set of observations. The probability of any
    eratively adds more points to the set as needed. A state at t = 0, is described by the initial belief, b0. The tran-
                                                                          0
    key component of the algorithm is the strategy for sition function T(s,a,s ) describes the probability of going
                                                                         0
    selecting belief points, such that the space of reach- from state s to state s given that action a is chosen. The
    able beliefs is well covered. This paper presents observation function Ω(o,s,a) describes the probability of
    a new method for selecting an initial set of repre- observation o given that action a was taken and state s was
    sentative belief points, which relies on ﬁnding ﬁrst reached. The reward function, R(s,a), speciﬁes the expected
    the basis for the reachable belief simplex. Our ap- immediate reward, obtained after executing action a in state
    proach has better worst-case performance than the s. The discount factor γ ∈ (0,1) is used to weigh less delayed
    original PBVI heuristic, and performs well in sev- rewards. The goal of an agent acting in a POMDP is to ﬁnd
    eral standard POMDP tasks.                        a way of choosing actions (policy) maximizing the future re-
                                                               γt
                                                      turn: E[∑t R(st ,at )]. In order to achieve this goal, the agent
                                                      must keep either a complete history of its actions and obser-
1  Introduction                                       vations, or a sufﬁcient statistic of the history. The sufﬁcient
Partially Observable Markov Decision Processes (POMDPs) statistic in a POMDP is the belief state, b, a vector with |S|
provide a general framework for planning under uncertainty components, which represents a probability distribution over
[Kaelbling et al., 1998; Sondik, 1971]. One of the standard states:
algorithms used to provide solutions to POMDPs is value it-      bt (s) = P(st = s|b0,a0o1 ...at−1ot )
eration, which associates values to probability distributions On each time step, after taking action a and making observa-
over states. Because exact value iteration is intractable, a lot tion o, the agent updates its belief state using Bayes rule:
of recent work has focused on approximate algorithms, which
                                                                            Ω(o,s0,a)∑ b(s)T(s,a,s0)
rely on compressing the belief space or considering a ﬁnite set b(s0) ← P(s0|a,o,b) = s            ,  (1)
of reachable beliefs. A representative algorithm for this class                     P(o|a,b)
is point-based value iteration (PBVI) [Pineau et al., 2003]. In where the denominator is just a normalizing constant.
PBVI, a ﬁnite set of reachable belief points is selected heuris- In value-based POMDP methods, the agent computes a
tically, and values are computed only for these points. The value function, which is maintained over belief states. A lot
success of PBVI depends crucially on the selection of the be- of recent research has been devoted to computing such values
lief points. In particular, these points should cover the space approximately. Compression-based methods [Roy and Gor-
of reachable beliefs as evenly as possible. The main PBVI don, 2003; Poupart and Boutilier, 2004] aim to compress the
heuristic uses one-step simulated trajectories in order to ﬁnd belief space, and maintain a value function only on this com-
reachable beliefs. The belief that is “farthest away” from the pressed version. Point-based value iteration (PBVI)[Pineau
points already included is greedily added to the set. We ex- et al., 2003] maintains values and gradients (α-vectors, in
plore an alternative heuristic for choosing belief points. We POMDP terminology) for a selected set of belief points, B.
aim to ﬁnd core beliefs, i.e. beliefs which form a basis for the The idea is that much of the belief simplex will not be reach-
space of all reachable beliefs. This approach is aimed at cov- able in general. The set B is expanded over time, in order to
ering more quickly the space of beliefs that are reachable, by cover more of the reachable belief space, and these expan-
looking farther into the future. This improves the worst-case sions are interleaved with computing new value estimates.3  Belief selection                                   Algorithm 1 Finding core beliefs
In order to extend the belief set B, the standard PBVI heuristic Initialize the matrix with b0 and rows corresponding to all
considers, for each b ∈ B, all possible actions a and samples beliefs reachable by one-step tests a,o. One column is all
one observation o for each action. Among these beliefs reach- 1’s and the others correspond to one-step tests a,o.
able from b, the belief b0 that is farthest away from B is picked for all elements (b,ao) do
and added to B. This heuristic is motivated by an analytical Compute P(o|b,a), using (1) and store it in row b, col-
upper bound on the approximation error, which depends on  umn a,o
the maximum L1 distance from any reachable belief to B: end for
                                                        repeat
                                0
               εB = maxmin||b − b ||1                     Compute a set of linearly independent rows and columns
                     0 ∆¯ ∈
                    b ∈ b B                               Add the linearly independent rows to the set of core be-
where ∆¯ is the set of all reachable beliefs. PBVI does not liefs
keep an upper bound on the value function when expanding  Eliminate all linearly dependent rows and columns
its belief set. However Smith and Simmons [Smith and Sim- Add all one-step extensions to the matrix and compute
mons, 2004] have developed an alternative anytime solution the rank of the extended matrix
method, HSVI, based on maintaining an upper and a lower until The rank is unchanged
bound of the optimal value function to guide the local value
updates. They choose the belief points to update using for-
ward heuristic search. Vlassis and Spaan [Vlassis and Spaan, to get a ﬁrst approximation of the value function. We
2004] instead sample a large set of reachable beliefs B dur- extend the core belief matrix by picking one action, in
ing a random walk, but then only update a subset of of B, ε-greedy fashion. The next observation can be sampled
sufﬁcient to improve values overall.                      as well.
  We propose an approach for covering the space of reach- Note that for PBVI, the maximum error value for εB that can
able beliefs more quickly, by considering longer courses of be achieved is 2, attained for the case in which two beliefs are
action, as well as by removing the strictly greedy charac- non-zero over different states. This case cannot occur when
ter of the PBVI algorithm. We will use core beliefs, which all core beliefs are part of B. Hence, the worst-case error
form a basis for the belief simplex. The idea of core be- when using core beliefs is strictly smaller.
liefs is inspired by work on predictive state representations
(PSRs) [Littman et al., 2002], an alternative way of represent- 4 Experimental results
ing stochastic dynamical systems. In order to reason about
the space of reachable beliefs, one can consider the initial We performed experiments on several standard POMDP do-
belief vector, b0, and all possible sequences of actions and mains used in the literature. For the smaller three domains
observations following it. These sequences are called tests. (4x4 grid, 4x3 grid and Cheese) we computed the core be-
James and Singh (2004) introduced the concept of an inﬁ- liefs exactly (column “CBVI-all” of Table 1). The proposed
nite matrix, whose rows correspond to all histories and whose heuristics are run using all possible observations in the one-
columns correspond to all tests. In this paper we use the same step extensions. We also ran standard PBVI with a similar
inﬁnite matrix but the rows correspond to all reachable be- number of initial beliefs. In all cases we performed 5 itera-
liefs from a given initial belief point. For a row b and a test tions of PBVI to obtain a value function. Then, we ran 251
a0o1,...an−1on, the content of the corresponding element in trials, with each trial cut at 251 steps. We averaged the results
the matrix is the probability that o1,...on is observed given obtained over these trials, and over 5 independent runs.
that action sequence a0,...an−1 is executed starting from b. All versions of the CBVI algorithm yield improvements
This matrix has ﬁnite rank, at most equal to the number of over the PBVI heuristic. Surprisingly, in the 4x4 and Cheese
states in the POMDP. We deﬁne core beliefs as the set of lin- domains, the best result is achieved by the ε-greedy heuristic.
early independent rows of this matrix.                We conjecture that the reason is that the ε-greedy heuristic
  The computation of core beliefs can be done exactly using actually focuses the computation on good actions, that are
the POMDP model, as shown in Algorithm 1. It is similar to likely to be used in the optimal policy.
the computation of core tests in [James and Singh, 2004], ex- In the larger domains, we only used the ε-greedy heuris-
cept that here we compute the elements of the matrix having tic with sampled observations, as the other versions are too
the POMDP model while they estimate these elements from expensive. The experimental setup is as above. In this case,
data without the model. But in large environments, consid- we ﬁnd a ﬁrst set of core beliefs, then run PBVI for 5 it-
ering all one-step extensions for all tests is prohibitive. We erations. We take the resulting belief set, and add one-step
experimented with two heuristics for the extensions:  extensions using ε-greedy actions and sampled observations,
                                                      as above. This results in a new matrix, which yields a new set
 1. Random: pick a random action, but consider all obser- of core beliefs. This process is repeated at most 5 times; if no
    vations.                                          more core beliefs are detected in a new iteration, the process
 2. ε-greedy: consider actions that are likely to be picked stops. The results are presented in the columns CBVI(1) to
    by a good policy. We generate ﬁrst a subset of the core CBVI(5) in Table 2. Note that for the Coffee domain, all core
    beliefs based on all one-step tests. Then, we run PBVI beliefs are found after two such repetitions. Hence, there is
    on this subset, for a ﬁxed number of iterations, in order no data for the CBVI(3)-CBVI(5). The reward for standard                          Domain     PBVI      CBVI-all   CBVI-rand   CBVI-egr
                          4x4 grid 3.17 ± 0.22 3.80 ± 0.11 3.45 ± 0.22 3.96± 0.28
                          4x3 grid 1.58 ± 0.35 2.45 ± 0.44 2.10 ± 0.09 2.07 ± 0.11
                          Cheese   3.53 ± 0.13 3.53 ± 0.08 3.65 ± 0.22 3.81 ± 0.35

                                          Table 1: Small domains

    Domain   PBVI-orig  VS      PBVI       CBVI(1)      CBVI(2)     CBVI(3)     CBVI(4)      CBVI(5)
    Maze33     2.25     2.34    2.248     2.185 ± 0.3 2.285 ± 0.31 2.165 ± 0.38 2.234 ± 0.25 2.301 ± 0.26
   Hallway1    0.53     0.51    0.503     0.535 ± 0.03 0.617 ± 0.08 0.556 ± 0.03 0.574 ± 0.04 0.582 ± 0.08
   Hallway2    0.35     0.31    0.379     0.333 ± 0.04 0.334 ± 0.04 0.392 ± 0.05 0.403 ± 0.04 0.400 ± 0.03
     Coffee    -3.00     -   -2.759 ±0.93 0.024 ± 2.14 0.58 ±2.72      -           -            -

                                          Table 2: Large domains

PBVI using a similar number of initial beliefs is in the col- [Kaelbling et al., 1998] Leslie P. Kaelbling, Michael L.
umn PBVI in Table 2. The results reported in the original Littman, and Anthony R. Cassandra. Planning and act-
PBVI paper (PBVI-orig)[Pineau et al., 2003] and the results ing in partially observable stochastic domains. Artiﬁcial
by Vlassis and Spaan (VS)[Vlassis and Spaan, 2004] are in Intelligence, 101:99–134, 1998.
the columns PBVI-org and VS respectively. As shown in Ta- [Littman et al., 2002] Michael Littman, Richard S. Sutton,
ble 2, for Maze33 all algorithms obtain very similar results. and Satinder Singh. Predictive representations of state. In
The Coffee domain is a very favorable case for CBVI, be- NIPS 14, pages 1555–1561, 2002.
cause it has a nice structure, and the reachable space of beliefs
lies in a very low dimensional part of the entire belief sim- [Pineau et al., 2003] Joelle Pineau, Geoff Gordon, and Se-
plex. Generating core beliefs can be done in 2-3 seconds for bastian Thrun. Point-based value iteration: An anytime
this domain, because there are only two core beliefs for this algorithms for POMDPs. In Proceedings of IJCAI, pages
problem, although its POMDP representation has 32 states. 1025–1032, 2003.
Our experiments show a huge value improvemnet for this par- [Poupart and Boutilier, 2004] Pascal Poupart and Craig
ticular case over PBVI. For the larger domains, Hallway1 and Boutilier. VDCBPI: an approximate scalable algorithm
Hallway2, CBVI also has a deﬁnite advantage, especially in for large scale POMDPs. In NIPS 17, 2004.
the later iterations, when the initial subset of core beliefs is
                                                      [Roy and Gordon, 2003] Nicholas Roy and Geoffrey Gor-
larger. The time complexity of CBVI is the same as PBVI  don. Exponential family PCA for belief compression in
if generating the core beliefs can be done in a preprocessing POMDPs. In NIPS 15, pages 1635–1642, 2003.
phase. In small domains and large domains with small intrin-
sic dimensionality (e.g. Coffee) this can be done in a few sec- [Smith and Simmons, 2004] Tery Smith and Reid Simmons.
onds. However, generating all core beliefs in large domains Heuristic Search Value Iteration for POMDPs. In UAI 20,
in general is very expensive. In our experiments, we reached pages 520-527, 2004.
the maximum number of core beliefs in at most ﬁve exten- [Sondik, 1971] Edward J. Sondik. The optimal control of
sions of the matrix in algorithm 1; however, the computation Partially Observable Markov Decision Processes. PhD
time, taking into account the process of belief generation is Thesis, Stanford University, 1971.
two orders of magnitude longer than for PBVI. Although this
                                                      [                    ]
approach improves the value function and the policy that is Vlassis and Spaan, 2004 Nikos Vlassis and Matthijs
obtained, it is signiﬁcantly more expensive, at the moment, Spaan. A point-based POMDP algorithm for robot
unless the problem at hand has special structure. We are in- planning. In Proceedings of ICRA, 2004.
vestigating different ways to compute a reasonably large por-
tion of the space of core beliefs at a lower computation cost.
Acknowledgments
This research was supported in part by funding from NSERC
and CFI. We thank Joelle Pineau for very helpful discussions
and insights into point-based algorithms, as well as for con-
structive feedback. We thank Matthijs Spaan for providing
code for his point-based value iteration algorithm.

References
[James and Singh, 2004] Michael James and Satinder Singh.
  Predictive State Representations: A New Theory for Mod-
  eling Dynamical Systems. ICML 21, pages 417-424, 2004.