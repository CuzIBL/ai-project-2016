     Models of Searching and Browsing: Languages, Studies, and Applications

                      Doug Downey                          Susan Dumais & Eric Horvitz
     Department of Computer Science and Engineering              Microsoft Research
                 University of Washington                       Redmond, WA 98052
                    Seattle, WA 98195                    {sdumais,horvitz}@microsoft.com
               ddowney@cs.washington.edu

                    Abstract                            Time       User Action
                                                        5:04:10 PM Queries for drivers
    We describe the formulation, construction, and      5:04:18 PM Clicks on result http://www.windrivers.com/
    evaluation of predictive models of human informa-   5:04:42 PM Returns to results for drivers
    tion seeking from a large dataset of Web search     5:05:10 PM Requests second result page for drivers
                                                        5:06:30 PM Queries for ati 9550 drivers
    activities. We ﬁrst introduce an expressive lan-    5:06:35 PM Clicks on result http://support.ati.com/ics/...
    guage for describing searching and browsing be-                End of Session
    havior, and use this language to characterize several
    prior studies of search behavior. Then, we focus on
    the construction of predictive models from the data.     Table 1: Example of Web Search Activity
    We review several analyses, including an explo-
    ration of the properties of users, queries, and search After spending some time browsing the second page of re-
    sessions that are most predictive of future behavior. sults for “drivers,” the user reformulates the query to be more
    We also investigate the inﬂuence of temporal de-  speciﬁc (“ati 9550 drivers”). The user then navigates to a de-
    lay on user actions, and representational tradeoffs sired result page, and the search session ends. Activity logs
    with varying the number of steps of user activity such as this can be used to build predictive models of search
    considered. Finally, we discuss applications of the behavior. A search engine capable of predicting users’ future
    predictive models, and focus on the example of per- actions could streamline interaction sequences such as these,
    forming principled prefetching of content.        potentially offering dramatic improvements in search perfor-
                                                      mance.
                                                        We report on an investigation of a large dataset of Web
1  Introduction                                       searching and browsing activity, collected with permission
User interaction with Web search engines is a commonplace, from hundreds of thousands of users. We focus on the use
yet complex, information-seeking process. In the course of of machine learning to study the challenges and opportunities
a search session, users take various actions to accomplish of building predictive models from this data.
their goals. They formulate and issue queries, browse re- Our contributions are as follows:
sults, navigate to result pages or other content, reformu- 1. We introduce an expressive language for representing
late their queries, request additional results, and often mix searching and browsing behavior. This language pro-
these actions in an iterative and varying manner as they pur- vides a unifying framework for discussing and analyzing
sue information. Each step in this process is informed by models of search activity, regardless of the applications
both the user’s prior experiences and recent history with for which the models may be intended. We employ the
search and retrieval, the user’s current goal, and the informa- language to describe our study of search activity in the
tion the user gathers as the session progresses [Bates, 1989; context of other studies.
Rose and Levinson, 2004]. Behavioral data capturing such
rich interaction is becoming available via the collection of 2. We explore the construction of predictive models, and
logs of Web searching and browsing activity. This newly   measure the value of different observational variables
available data provides unprecedented opportunities for re- within these models. Our experiments demonstrate that
search on applications of machine learning and reasoning to several variables have signiﬁcant effects on predictive
better understand and support human information-seeking ac- accuracy. We include an analysis of the inﬂuence of
tivities.                                                 different temporal delays on the likelihood of future ac-
  As a concrete example, consider the log of search activity tions, and also consider the tradeoff between complexity
shown in Table 1. Here, a computer user starts with a general and predictive power when assuming different degrees
query (“drivers”), clicks on a result (“www.windrivers.com”), of locality of evidence.
and then returns to the results page (presumably unsatisﬁed). 3. We formulate and experimentally evaluate a sample ap-

                                                IJCAI-07
                                                  2740    plication of the predictive models, aimed at the princi-
    pled prefetching of content.
  Section 2 describes our language for search activity mod-
els. Section 3 gives the experimental results of our predictive                q
models, including an analysis of the inﬂuence of different ob-
servational variables. Section 4 discusses applications of the
predictive models and presents experiments on applying the          R

models to prefetch search engine results. We discuss related                          cr
work in Section 5 and conclude with a summary of the work.
                                                                    b
                                                                                      v
2  A Model of Web Search Activity
                                                                    P                 c
We found it useful for reﬂection, comparative analysis, and                            ¬r
communication with colleagues to compose an expressive
graphical language for describing search activities.                                  z
2.1  State-Machine Representation                                                          S
A model of search activity is cast in the form of a state                                      U
machine representation displayed in Figure 1. In this state
model, nodes represent events that occur during a user’s in-
teraction with a search engine, and edges indicate the pos-      Figure 1: Search Activity Model
sible transitions between events. User actions, indicated
by triangles in the diagram, are events that the user initi- 2.2 A Language for Search Activity Models
ates. Boxes within the state diagram represent states that The set of event sequences generated by the full SAM is in-
are machine generated. Lastly, the outer plates, marked by ﬁnite; a particular model will often consider only a subset of
U     S
  and   , indicate that the structures they contain are re- these possible sequences. To specify the activity sequences
                        U                    S
peated once for each user ( ) and search session ( ), re- that a particular model considers, we adopt the following def-
spectively. Deﬁne the set of search activity elements as inition:
E =  {U, S, R, P, q, cr,c¬r,b,v,z}; the individual elements
  E                                                   Deﬁnition The event sequence space (ESS) of a model M is
of  are deﬁned as follows:                                                               E ∪{   ,τ}
  • U                                                 a regular expression over the vocabulary ()  which
      – User                                          matches exactly those event sequences considered by M.
  • S – Session
                                                      The added construct () indicates events that occur, but
  • q – Query input to search engine                  that are not explicitly considered in the model. The added
  • R – Result page output by search engine           symbol τ  indicates points in the sequence at which the
                                                      model considers temporal duration. As an example, Lau and
  • P – Non-result page output by website
                                                      Horvitz [1999] investigated the inﬂuence of temporal delay
  • cr – Click on search result hyperlink             on the type of query reformulation users will next perform
  • c¬r – Click on non-result hyperlink               (e.g., specialization, generalization, etc.), given prior refor-
                                                      mulations. The event sequences that the Lau & Horvitz model
  • b – Browser-assisted navigation to previously viewed
                                                      considers are pairs of queries separated by some number of
    pages (e.g., forward/back navigation, tabbed browsing,
                                                      ignored non-query events. Additionally, the model considers
    etc.)
                                                      the duration between each pair of queries. Thus, the Lau &
  • v
     – Visit to Web page by means other than cr,c¬r,b(e.g. Horvitz model has an ESS of qτ(.∗)q. We assume that wild-
    by opening a new browser, typing into the address bar, cards in the regular expression execute a minimal match, so
    clicking a hyperlink from an external application, etc.) a .∗ term (which matches zero or more events of any type) is
  • z – End of session                                prohibited from including the event sequence following it (q
                                                      in this case).
  Doubled lines are used to indicate the session start action
                                                        The ESS language assists with comparing and contrasting
q, and a circle indicates the end state z.
                                                      the intent and results of previous work in search activity mod-
  In Figure 1, each user U executes one or more sessions
                                                      eling. Table 2 lists the event sequence spaces for several re-
S. Here a session is deﬁned as a sequence of search activity
                                                      cent studies of search activity.1 Note that the ESS language
directed toward a single user intent; all sessions begin with a
                                                      can be used to characterize a model regardless of the particu-
query q. Query actions are always followed by R (the presen-
                                                      lar application for which the model may have been designed.
tation of a search result page), and from the R state the user
                                                      For example, the models in Table 2 were developed for tasks
can execute any action. As a concrete example, the event se-
quence from the activity log in Table 1 would be expressed as 1An ESS always speciﬁes a sequence of events as executed by a
qRcrP bRqRqRcrPz. We will refer to the state machine in single user— the element U is included for cases in which users are
Figure 1 as the Search Activity Model (SAM).          explicitly modeled.

                                                IJCAI-07
                                                  2741  qτ(.∗)q                  [Lau and Horvitz, 1999]   presentation of a results page, followed by an optional result
  q(R)cr              [Beeferman and Berger, 2000]   click. In the case of a result click, we explicitly distinguish
                                  [Lee et al., 2005]  the subsequent path (<path>) of pages traversed via hyper-
  qR(crP (.∗))+                 [Cui et al., 2002]  link clicks or back actions,2 which tend to be particularly re-
  (qR(cr?(.∗))∗)+        [Rose and Levinson, 2004]   lated to the search query (a similar approach was taken in
  qR                        [Duame and Brill, 2004]   [Agichtein et al.,2006]). We consider temporal duration at
                              [Davison et al., 2003]  multiple points in the sequence, including the delay between
  q(.∗)q                    [Jones and Fain, 2003]   all search actions, the duration of the path, and the time be-
                                [Jones et al., 2006]  tween the end of the path and the next action.
  U(qRcr(.∗))+                  [Sun et al., 2005]
  S qR  c  .∗  ∗
   (   ( r?( )) )+   [Radlinski and Joachims, 2005]  3   Experiments
Table 2: Previous search models. A summary of search ac- We now turn to experiments with building predictive models
tivity models studied previously, and their respective event of search behavior. We start by describing in detail our data
sequence spaces.                                      collection process and the parameterization of the events we
                                                      consider, as well as the machine learning methodology we
                                                      employ to construct models. We then present the results of
as wide ranging as query expansion, result ranking, and pre- the experiments on predicting a search user’s next action, and
dicting different types of query reformulations, among others. analyze which aspects of the SAM described in Section 2 are
  Importantly, all of the models in Table 2 are server-side most important for the task.
models, in that the user actions they consider – q and cr –
can be detected from a search engine Web server (although 3.1 Data collection and parameterization
cr events must be redirected through the search engine to be
logged). The full SAM is a client-side model, including event Our data set consists of three weeks of Web activity col-
types (e.g. browser actions b) that require instrumentation lected via opt-in client-side instrumentation from a set of over
installed on the user’s machine. Similar client-side activity 250,000 users. The data was collected from users who con-
models have been investigated in recent work (e.g. [Agichtein sented to share their searching activities with Microsoft via
et al., 2006; Fox et al., 2005]). With the exception of the the Windows Live Toolbar download. The data consists of
scrolling events in [Fox et al., 2005], those models can be triples of the form (user ID, time, URL visted), represent-
fully expressed in our language.                      ing user activity. We extracted each user’s search actions
  A complete model of search activity is characterized by not (all search engine queries and result clicks) for three popu-
only an ESS, but also a parameterization, which maps events lar search engines as well as ten Web page requests following
                                                                      3
to a vector of features (e.g., a query action can be parameter- each search action.
ized by properties like its length or average frequency). Be- We partitioned the user actions into sessions, which, as de-
cause parameterizations can vary widely across models, we scribed in Section 2, are contiguous blocks of activity over
do not attempt to express them in our language. Section 3 which we assume the user’s search goal remains relatively
details the particular parameterizations we employ in our ex- constant. Detecting the boundaries of sessions is a challeng-
periments.                                            ing problem which could be informed by a variety of temporal
                                                      and behavioral factors. For these experiments, we employed
2.3  SAMlight                                         a simple heuristic that considers any search actions within 30
The full SAM considers all browsing activity following a minutes of each other to be part of the same session, follow-
search action. Because our focus is on search activity in par- ing previous work [Radlinski and Joachims, 2005].Wehave
ticular, we will ignore in our experiments the browsing ac- explored the sensitivity of session numbers to this segmenta-
tivity that is unlikely to be related to a search query. For ex- tion parameter. We found that the effect of using a shorter
ample, when the user types a new URL into the browser’s temporal gap of 5 minutes would have been relatively small,
address bar, it is unlikely that this URL is directly relevant further dividing about 25% of the sessions.
to a previous search action. Ignoring this browsing activity In the models, each action is parameterized by a set of fea-
allows us to dramatically reduce the size of the data sets we tures, which is detailed in Table 3. The features express prop-
analyze, while still retaining many of the events relevant to erties of different elements of the SAM, including the user,
search actions. We will focus on a subset of the SAM that we the session, query and click actions, time, and a summary
call SAMlight. SAMlight has the following form:       of information regarding non-search actions following search
  SAMlight   =   U(S(q<res>(b<res>)∗  (.∗))+) +
                                                         2Although the SAM element b refers to browser-aided naviga-
     <res>   =   Rτ(crPτ<path>τv?(.∗))?            tion in general, in our experiments, we consider only the browser’s
    <     >        c |b P  ∗                          “back” action.
     path    =((¬r     ) )
                                                         3As our instrumentation returns only which URLs the user re-
  SAMlight considers a set of users executing one or more quests, we must infer when result clicks occur. We assume all non-
sessions, where each session consists of one or more queries search URL loads originating from a link on a search page are result
followed by activity surrounding a result set (<res>) gen- clicks. Based on manual inspection, we estimate this heuristic to be
erated by a search engine. Result set activity includes the over 95% accurate.

                                                IJCAI-07
                                                  2742actions. Features describing the user (U) include statis- User Features (U)
tics such as how frequently the user searches (U(qPerDay)) U(AvgSSec)    Avg. session length (in seconds)
or the average time the user takes to click a result page U(AvgSecTocr)  Avg. search to result click interval
                                                       U q       S
(U(AvgSecTocr)). Properties of the session (S) include fea- ( PerSecIn ) Avg. queries per second within session
                                                       U(qRepeatRate)    Fraction of queries that are repeats
tures such as the number of queries issued in the current ses- U q
sion S(Numq). Features of query actions include attributes ( PerDay)     Avg. queries per day
                                                       U(AvgcrPos)       Avg. rank of clicked results
of the query text (e.g. the number of words q(WordLen)), the
                                                       U(AvgqWordLen)    Avg. query length
query words distributions in Web text (e.g. the frequency of U c
                           q                             ( rProb)        Ratio of result clicks to queries
the query’s least frequent word, (MinWordFreq)), and past U(PrefEngine)  Engine queried most frequently
search behavior for the query (e.g. the average click position U(PrefEngineFreq) Fraction of queries on preferred engine
            q    c
for the query, (Avg rPos)). Properties of click actions in- U(AvgFirstResult) Avg. ﬁrst result requested in queries
clude attributes like position in the result list (cr(Position)), Session Features (S)
and whether the click was on an advertisement (cr(IsAd)). S(Numq)        Number of queries issued
  We used the ﬁrst week of user data to estimate the “aggre- S(DurationSec) Duration of the session
gate” properties of users and queries, which are averaged over S(qFrac)  Ratio of queries to search actions
multiple search sessions (e.g. U(AvgSSec), q(AvgcrPos)). S(MaxqWords)    Maximum q(WordLen) (see below)
The following week was used as a training set, and the ﬁnal S(MinqWords) Minimum q(WordLen) (see below)
week as a test set. Features related to query word distributions Query Features (q)
on the Web (e.g. q(MinWordFreq)) were computed using a q(WordLen)        Length in words
                                                       q
400 million page sample of Web text.                    (CharLen)        Length in characters
                                                       q(FirstResult)    Rank of ﬁrst result requested
3.2  Machine-learning methodology                      q(Freq)           Number of times query is issued
                                                       q(crProb)         Prob. some result is clicked
The central challenge we address is that of predicting the q(AvgcrPos)   Avg. result position clicked
user’s next action, given a set of previous actions and in- q(AvgcrDelay) Avg. time to click after query
formation accumulated about the user and the session. For- q(AvgPathSec) Avg. PathDwellSec (see below)
mally, we model the conditional probability distribution q(AvgPathPages) Avg. PathPageLen (see below)
P (an|U, S, an−1,...,an−k), where ai represents the ith q(AvgAfterPathSec) Avg. AfterPathSec (see below)
search action in the session.4 In this distribution, actions q(DistinctU) Number of distinct users issuing query
                                                       q
an−1,...,an−k and the U and S variables are parameterized (HasDeﬁnitive) 1 iff query has “deﬁnitive” result
                                                       q
as in Table 3, and the target variable (the next action an)is (HasSuggestion) 1 iff query has a spelling suggestion
parameterized in different ways for different experiments, as q(AdImpressions) Number of times ads shown
                                                       q(AvgNumAds)      Average number of ads shown
explained below.                                       q
  To model the conditional probability distribution, we em- (AdBid)      Average bid for ads on this query.
                                                       q(IsAdvanced)     1 iff query has advanced features
ployed a learning method that performs Bayesian structure
                                                       q(MinWordFreq)    Web frequency of least frequent word
search to ﬁnd predictive models that best explain the training q(MaxWordFreq) Web frequency of most frequent word
data [Chickering, 2002]. The resulting models are Bayesian q(GeoMeanFreq) Geo. mean of word Web frequencies
dependency networks in which the conditional distributions q(AvgWordFreq) Average of word Web frequencies
at each node take the form of probabilistic decision trees. q(MaxColloqQuot) Maximum bigram collocation quotient
Parameters for restricting the density of the dependency net- q(ContainsName) 1 iff query contains a person name
works were estimated via cross validation on the training set. q(ContainsLoc) 1 iff query contains a location name
  Bayesian structure search to learn dependency networks Result Click Features (cr)
is one of several feasible learning procedures. We initially cr(Position) Result rank for cr
selected the method because it scaled nicely to training sets cr(DwellSec) Time in seconds on the target page.
containing half a million instances with up to hundreds of fea- cr(IsAd) 1 iff the click is on an advertisement
tures. Also, the dependency models and trees output by the q|cr(Engine)  Search engine for query or click
method allowed us to inspect graphical relationships among Non-search Action Features (v|c¬r|b)
observations and predictions. A comparison of alternative PathPageLen    Length in pages of path after result click
machine learning algorithms (e.g., logistic regression, Sup-             traversed by links or “back” actions.
port Vector Machines, etc.) for this task is an item of future PathDwellSec Time duration for the path
work.                                                  AfterPathSec      Time from end of path to next action.
                                                       Temporal/Transition Features
  We parameterized the target variable representing the next τ(SearchAct) Time between two search actions
action at two different levels of granularity. At a coarse level DayOfWeek Day of the week
of granularity the variable includes ﬁve output values repre- TimeOfDay  One of three 8-hour windows
senting the nature of the next action. We model whether the qq(WordDelta) Word length change between queries
next action is a query (q), result click (cr), or end of session

  4Properties of the session accumulate as the session progresses;
                                                      Table 3: Events and parameterizations considered in
for example, S(DurationSec), when used to predict an, expresses
the duration the session up until action an−1.        learning predictive models.

                                                IJCAI-07
                                                  2743      -1.1                                                             Log Likelihood  Accuracy
      -1.2                                                              Fine   Coarse   Fine  Coarse
      -1.3                                                 Marginal    -1.881  -1.497  0.323   0.345
      -1.4                                                 SAMlight    -1.108  -0.859  0.615   0.643
      -1.5
      -1.6                                  500K      Table 4: Next action prediction. At both the coarse and
      -1.7
    Performance                             100K      ﬁne granularities, SAMlight offers substantial improvements
      -1.8                                            in likelihood and accuracy over a baseline marginal model.
  Avg. Log Likelihood  Log  Likelihood Avg. -1.9
         01234
                     Previous Actions k               marginal model, which simply predicts the distribution of
                                                      next actions observed in the training data (the marginal
                                                      model’s ESS is q|cr|b). Table 4 shows the average log like-
Figure 2: Predictive performance as event history varies. lihood of each model measured on the test set. Addition-
Considering search actions beyond the previous one does not ally, we list each model’s accuracy, the fraction of test set
increase predictive performance for training sets of 100K and actions for which the model’s most likely prediction (that
500K search events.                                               P      a |U, S, a  ,...,a
                                                      is, arg maxan model( n      n−1      n−k)) is correct.
                                                      SAMlight substantially outperforms the marginal model at
(z). We distinguish three types of query actions (q-reform, both action granularities and for both measures of perfor-
q-same, q-nextpage), capturing the relationship between the mance.
next query and the most recently issued query. For the coarse
parameterization, b actions that navigate back to the previous Predictive Value of Different SAM Elements
result page are treated as occurences of q-same. At the ﬁne The SAM contains several different events, each of which can
level of granularity, we consider a total of 13 output values. be parameterized. Here, we investigate which of these ele-
These values extend the coarse granularity in that q-reform ments and parameters are most important for predictive accu-
actions are further parameterized by the type of textual mod- racy.
iﬁcation (addition, deletion,orother) as well as whether or We ﬁrst examine the relative importance of SAM events,
not the user switched search engines. Also, the ﬁne granular- and then consider individual features. The fact that the end of
ity distinguishes clicks on advertisements from other result session action z is a deterministic function of τ(SearchAct)
clicks, and distinguishes back navigation to a previous query (that is, end of session occurs iff τ(SearchAct) > 30 min-
from a refresh of the same query. For both granularities, the utes) has the potential to overstate the predictive value of tem-
remaining actions (v, c¬r, and b actions that are not q-same) poral delay. To eliminate this trivial dependency, for these
are not predicted as output values, but are summarized as in- experiments we remove from the data all cases in which the
put variables as in Table 3.                          next action is z.
                                                        Our comparison of different SAM elements is summarized
3.3  Locality of Evidence                             in Table 5. The likelihood performance at both the coarse
The SAMlight model considers arbitrarily long event se- and ﬁne granularities is shown. The coarse and ﬁne accuracy
quences; however, to model the conditional probability differences tend to be small for these models (because the
P (an|U, S, an−1,...,an−k), a machine learning algorithm event space is dominated by a few highly probable events).
requires a ﬁnite choice of k. We measured how prediction Thus, in Table 5 we include accuracy on the speciﬁc problem
performance varied with k, the number of previous search of predicting whether or not the next action is a result click
actions considered. As can be seen in Figure 2, the per- (cr), where differences between methods are more apparent.
formance improves dramatically when considering the pre- Because the test set is large, all non-zero accuracy differences
vious action, but after k =1the effect of increasing k is in Table 5 are statistically signiﬁcant (p<0.001, chi-squared
small. In fact, increasing the dimensionality of the parameter test).
space hinders performance slightly, a fact that remains true The Previous Action (PA) model uses a single input fea-
even when we increase the size of training set ﬁve-fold, from ture, whether the previous action was q (or, treated equiva-
100,000 search events to 500,000. In the remaining experi- lently, a back action to R)orcr, and ignores the other features
ments, we set k =1and use the larger training set.    and SAM elements. PA has an ESS of (q|cr|b)(q|cr|b).PA,
                                                      like SAMlight, is a client-side model. As mentioned in Sec-
3.4  Prediction Results                               tion 2, many recent search models are server-side models. To
In this subsection, we present results of our experiments on quantify the beneﬁts of client-side instrumentation, we com-
predicting users next actions. We predict actions at both lev- pare PA with a model that uses only the previous action ob-
els of granularity (coarse and ﬁne) using a number of ele- servable by the search server (ESS of (q|cr)(q|cr)). The PA
ments representing the user, query and session. We also ex- model offers substantially improved performance over both
amine the contribution of different elements and temporal de- the marginal model and (in terms of likelihood) the server-
pendencies.                                           side model.
  The results of the prediction experiments are shown in We now examine the combination of PA with additional
Table 4. We compare the accuracy of SAMlight with a   SAM elements. The action features {q, cr,b,v,c¬r} add the

                                                IJCAI-07
                                                  2744