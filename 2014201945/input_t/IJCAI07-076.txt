       Evaluating a Decision-Theoretic Approach to Tailored Example Selection 

                            Kasia Muldner 1 and Cristina Conati 1,2
         1 University of British Columbia                   2 University of Trento 
         Department of Computer Science                 Department of Information and  
            Vancouver, B.C., Canada                      Communication Technology 
          {kmuldner, conati}@cs.ubc.ca                        Povo, Trento, Italy 

                   Abstract                        overly-general knowledge, to explain how an example 
    We present the formal evaluation of a framework solution step is derived [VanLehn, 1999]. 
    that helps students learn from analogical problem Min-analogy and EBLC are beneficial for learning be-
    solving, i.e., from problem-solving activities that cause they allow students to (i) discover and fill their 
    involve worked-out examples. The framework in- knowledge gaps and (ii) strengthen their knowledge through 
    corporates an innovative example-selection   practise. Unfortunately, some students prefer more shallow 
    mechanism, which tailors the choice of example to processes which hinder learning, such as copying as much 
    a given student so as to trigger studying behaviors as possible from examples without any proactive reasoning 
    that are known to foster learning. This involves a on the underlying domain principles (e.g., [VanLehn, 1998; 
    two-phase process based on 1) a probabilistic user VanLehn, 1999]. 
    model and 2) a decision-theoretic mechanism that To find examples that best trigger the effective APS be-
    selects the example with the highest overall utility haviors for each student, the EA-Coach takes into account: 
    for learning and problem-solving success. We de- i) student characteristics, including domain knowledge and 
    scribe this example-selection process and present pre-existing tendencies for min-analogy and EBCL, and ii) 
    empirical findings from its evaluation.      the similarity between a problem and candidate example. In 
                                                 particular, the Coach relies on the assumption that certain 
 1  Introduction                                 types of differences between a problem and example may 
                                                 actually be beneficial in helping students learn from APS, 
 Although examples play a key role in cognitive skill acqui- because they promote the necessary APS meta-cognitive 
sition (e.g., [Atkinson et al., 2002]), research demonstrates skills. This is one of the novel aspects of our approach, and 
that students have varying degrees of proficiency for using in this paper we present an empirical evaluation of the EA-
examples effectively (e.g., [Chi et al., 1989; VanLehn, Coach that validates it.  
1998; VanLehn, 1999]). Thus, there has been substantial A key challenge in our approach is how to balance learn-
interest in the Intelligent Tutoring Systems (ITS) commu- ing with problem-solving success. Examples that are not 
nity in exploring how to devise adaptive support to help all highly similar to the target problem may discourage shallow 
students benefit from example-based activities (e.g., [Conati APS behaviors, such as pure copying. However, they may 
and VanLehn, 2000; Weber, 1996]). In this paper, we de- also hinder students from producing a problem solution, 
scribe the empirical evaluation of the Example Analogy because they do not provide enough scaffolding for students 
(EA)-Coach, a computational framework that provides who lack the necessary domain knowledge. Our solution to 
adaptive support for a specific type of example-based learn- this challenge includes (i) incorporating relevant factors 
ing known as analogical problem solving (APS) (i.e., using (student characteristics, problem/example similarity) into a 
examples to aid problem solving).                probabilistic user model, which the framework uses to pre-
  The EA-Coach’s general approach for supporting APS dict how a student will solve the problem and learn in the 
consists of providing students with adaptively-selected ex- presence of a candidate example; (ii) using a decision-
amples that encourage studying behaviors (i.e. meta- theoretic process to select the example that has the highest 
cognitive skills) known to trigger learning, including: overall utility in terms of both learning and problem-solving 
1) min-analogy: solving the problem on one’s own as success. The findings from our evaluation show that this 
   much as possible instead of by copying from examples selection mechanism successfully finds examples that re-
   (e.g., [VanLehn, 1998]);                      duce copying and trigger EBLC while still allowing for suc-
2) Explanation-Based Learning of Correctness (EBLC): a cessful problem solving.  
   form of self-explanation (the process of explaining and There are a number of ITS that, like the EA-Coach, select 
   clarifying instructional material to oneself [Chi et al., examples for APS, but they do not consider the impact of 
   1989]) that can be used for learning new domain prin- problem/example differences on a student’s knowledge 
   ciples by relying on, for instance, commonsense  or and/or meta-cognitive behaviors. ELM-PE [Weber, 1996] 


                                            IJCAI-07
                                              483helps students with LISP programming by choosing exam- nism aims to choose an example that meets two goals: 1) 
ples that are as similar as possible to the target problem. helps a student solve the problem (problem-solving success
AMBRE [Nogry et al., 2004] supports the solution of alge- goal) and 2) triggers learning by encouraging the effective 
bra problems by choosing structurally-appropriate exam- APS behaviors of min-analogy and EBLC (learning goal).
ples. However, it is not clear from the paper what “structur- For each example stored in the EA-Coach knowledge base, 
ally appropriate” means. Like the EA-Coach, several ITS this involves a two-phase process, supported by the EA-
rely on a decision-theoretic approach for action selection, Coach user model: simulation and utility calculation. The 
but these do not take into account a student’s meta-cognitive general principles underlying this process were described in 
skills, nor they include the use of examples [Murray et al., [Conati et al., in press]. Here, we summarize the corre-
2004; Mayo and Mitrovic, 2001]. Finally, some systems sponding computational mechanisms and provide an illus-
perform analogical reasoning in non-pedagogical contexts trative example because the selection process is the target of 
(e.g., [Veloso and Carbonell, 1993]), and so do not incorpo- the evaluation described in a later section.  
rate factors needed to support human learning. 
 In the remainder of the paper, we first describe the exam- 2.1 Phase 1: The Simulation via the User Model 
ple-selection process. We then present the results from an The simulation phase corresponds to generating a prediction
evaluation of the framework and discuss how they support of how a student will solve a problem given a candidate 
the EA-Coach’s goal of balancing learning and problem- example, and what she will learn from doing so. To generate 
solving success.                                this prediction, the framework relies on our classification of 
                                                various relations between the problem and candidate exam-
                    Example 
                                                ple, and their impact on APS behaviors. Since an under-
                    A person pulls a 9kg crate up a ramp 
                    inclined 30o CCW from the horizontal. The standing of this classification/impact is needed for subse-
A workman pulls a 50kg. block            o
                    pulling force is applied at an angle of 30 quent discussion, we begin by describing it. 
along the floor. He pulls it with a 
magnitude of 120N, applied at an CCW from the horizontal, with a magnitude Two corresponding steps in a problem/example pair are 
angle of 25 o CCW from the of 100N. Find the magnitude of the normal defined to be structurally identical if they are generated by 
horizontal. What is the magnitude force exerted on the crate.  structurally different
of the normal force on the block?               the same rule, and             otherwise. For in-
                                                stance, Fig. 2 shows corresponding fragments of the solu-
                                                tions for the problem/example pair in Fig. 1, which include 
                                                two structurally-identical pairs of steps: Pstepn/Estepn de-
                                                rived from the rule stating that a normal force exists (rule 
                                                normal, Fig. 2), and Pstepn+1/Estepn+1 derived from the rule 
                                                stating the normal force direction (rule normal-dir, Fig. 2).  
                   We answer this question using Newton’s 
                   Second Law.                    Two structurally-identical steps may be superficially dif-
                      We choose the crate as the body. ferent. We further classify these differences as trivial or 
                      A normal force acts on the crate. 
                             o                  non-trivial. 
                      It’s oriented 120 CCW  from  the   While a formal definition of these terms is given 
                      horizontal                in [Conati et al., in press], for the present discussion, it suf-
       Figure 1: Fragment of the EA-Coach Interface fices to say that what distinguishes them is the type of trans-
                                                fer from example to problem that they allow. Trivial super-
Problem Description:       Example Description: ficial differences allow example steps to be copied, because 
 A workman pulls a 50 kg block… A person pulls a 9 kg  crate… these differences can be resolved by simply substituting the 
Solution Fragment:        Solution Fragment:    example-specific constants with ones needed for the prob-

                          [Estepn]:             lem solution. This is possible because the constant corre-
 [Pstepn]:        Structurally 
      Rule:Normal            Rule:Normal        sponding to the difference appears in the example/problem 
                   identical 
 A normal force acts on the A normal force acts on the solutions and specifications, which provides a guide for its 
 block        Superficial Difference        crate  substitution [Anderson, 1993] (as is the case for 
                   (Trivial)
                                                Pstepn/Estepn, Fig. 2). In contrast, non-trivial differences 

 [Pstepn+1]:              [Estepn+1]:           require more in-depth reasoning such as EBLC to be re-
                  Structurally 
  Rule:Normal-dir            Rule:Normal-dir 
                   identical                    solved. This is because the example constant corresponding 
It’s oriented 90o CCW     It's oriented 120o CCW from  to the difference is missing from the problem/example 
              Superficial Difference     
from the horizontal               the horizontal 
                 (Non-Trivial)                  specifications, making it less obvious what it should be re-
                                                placed with (as is the case for Pstepn+1/Estepn+1, Fig. 2).  
  Figure 2: Sample Classification of Problem/Example Relations The classification of the various differences forms the ba-
                                                sis of several key assumptions embedded into the simula-
2  The EA-Coach Example-Selection Process       tion’s operation. If two corresponding problem/example 
                                                steps (Pstep and Estep respectively) are structurally differ-
The EA-Coach includes an interface that allows students to 
                                                ent, the student cannot rely on the example to derive Pstep,
solve problems in the domain of Newtonian physics and ask 
                                                i.e. the transfer of this step is blocked. This hinders problem 
for an example when needed (Fig. 1). For more details on 
                                                solving if the student lacks the knowledge to generate Pstep
the interface design see [Conati et al., in press]. As stated in 
                                                [Novick, 1995]. In contrast, superficial differences between 
the introduction, the EA-Coach example-selection mecha-


                                           IJCAI-07
                                             484 structurally-identical steps do not block transfer of the ex- - Copy, encoding the probability that the student will gener-
 ample solution, because the two steps are generated by the ate the problem step by copying the corresponding exam-
 same rule. Although cognitive science does not provide ple solution step. 
 clear answers regarding how superficial differences impact - EBLC, encoding the probability that the student will infer 
 APS behaviors, we propose that the type of superficial dif- the corresponding rule from the example via EBLC. 
 ference has the following impact. Because trivial differences During the simulation phase, the only form of direct evi-
 are easily resolved, they encourage copying for students dence for the user model corresponds to the similarity be-
 with poor domain knowledge and APS meta-cognitive tween the problem and candidate example. This similarity is 
 skills. In contrast, non-trivial differences encourage min- automatically assessed by the framework via the comparison 
 analogy and EBLC because they do not allow the problem of its internal representation of the problem and example 
 solution to be generated by simple constant replacement solutions and their specifications. The similarity node’s 
 from the example. We now illustrate how these assumptions value for each problem step is set based on the definitions 
 are integrated into the EA-Coach simulation process. presented above, to either: None (structural difference), 
                                                 Trivial or Non-trivial. Similarity nodes are instrumental in 
        normal                    normal 
                         EBLC                    allowing the framework to generate a fine-grained predic-
         0.05                n     .22
                           .19                   tion of copying and EBLC reasoning, which in turns im-
                                                 pacts its prediction of learning and problem-solving success, 
                          Copyn
            EBLCTend       .91                   as we now illustrate.  
               .5                      Pstepn
                                       .96       Prediction of Copying episodes. For a given problem solu-
                           Similarityn           tion step, the corresponding copy node encodes the model’s 
  Pstepn  minAnalogyTend    Trivial 
   0.21                                          prediction of whether the student will generate this step by 
              .1                                 copying from the example. To generate this prediction, the 
                         EBLCn+1   normal-dir  
                           .68       .69         model takes into account: 1) the student’s min-analogy ten-
                                                 dency and 2) whether the similarity between the problem 
           normal-dir  
             0.05         Copyn+1                and example allows the step to be generated by copying. 
                           0.01 
                                       Pstepn+1  The impact of these factors is shown in Fig. 3. The probabil-
   Pstepn+1                             .79                               Pstep
    0.2                                          ity that the student will generate n by copying is high 
                          Similarityn+1 
          Slice t                                (see ‘Copyn‘ node in slice t+1), because the prob-
                          Non-trivial Slice t+1  lem/example similarity allows for it (‘Similarity ’=Trivial, 
     (Pre-Simulation Slice)       (Simulation Slice)                                  n
                                                 slice t+1) and the student has a tendency to copy (indicated 
       Figure 3: Fragment of the EA-Coach User Model in slice t by the low probability of the ‘MinAnalogyTend’
 Simulation via the EA-Coach User Model          node). In contrast, the probability that the student will gen-
 To simulate how the examples in the EA-Coach knowledge erate the step Pstepn+1 by copying is very low (see node 
 base will impact students’ APS behaviors, the framework ‘Copyn+1’ in slice t+1) because the non-trivial difference 
 relies on its user model, which corresponds to a dynamic (‘Similarityn+1’=Non-trivial, slice t+1) between the problem 
 Bayesian network. This network is automatically created step and corresponding example step blocks copying. 
 when a student opens a problem and includes as its back- Prediction of EBLC episodes. For a given problem rule, 
 bone nodes and links representing how the various problem the corresponding EBLC node encodes the model’s predic-
 solution steps (Rectangular nodes in Fig. 3) can be derived tion that the student will infer the corresponding rule from 
 from domain rules (Round nodes in Fig. 3) and other steps. the example via EBLC. To generate this prediction, the 
For instance, the simplified fragment of the user model in model takes into account 1) the student’s EBLC tendency, 
Fig. 3, slice t (pre-simulation slice) shows how the solution 2) her knowledge of the rule (in that students who already 
 steps Pstepn and Pstepn+1 in Fig. 2 are derived from the cor- know a rule do not need to learn it) 3) the probability that 
responding rules normal and normal-dir. In addition, the she will copy the step, and 4) the problem/example similar-
network contains nodes to model the student’s APS ten- ity. The last factor is taken into account by including an 
dency for min-analogy and EBLC (MinAnalogyTend and EBLC node only if the example solution contains the corre-
EBLCTend in slice t, Fig. 3)1.                   sponding rule (i.e., the example is structurally identical with 
  To simulate the impact of a candidate example, a special respect to this rule). The impact of the first 3 factors is 
‘simulation’ slice is added to the model (slice t+1, Fig. 3, shown in Fig. 3. The model predicts that the student is not 
assuming that the candidate example is the one in Fig. 2). likely to reason via EBLC to derive Pstepn (see node 
This slice contains all the nodes in the pre-simulation slice, ‘EBLCn,’ in slice t+1) because of the high probability that 
as well as additional nodes that are included for each prob- she will copy the step (see node ‘Copyn’) and the moderate 
lem-solving action being simulated and account for the can- probability of her having tendency for EBLC (see node 
didate example’s impact on APS. These include:   EBLCTend in slice t). In contrast, a low probability of copy-
- Similarity, encoding the similarity between a problem so- ing (e.g., node ‘Copyn+1’, slice t+1) increases the probability 
  lution step and the corresponding example step (if any). for EBLC reasoning (see node ‘EBLCn+1’ in slice t+1), but 
                                                                 the increase is mediated by the probability that the student 
   1 Unless otherwise specified, all nodes have Boolean values has a tendency for EBLC, which in this case is moderate. 


                                            IJCAI-07
                                              485 Prediction of Learning & Problem-Solving Success. The 3 Evaluation of the EA-Coach  
 model’s prediction of EBLC and copying behaviors influ-
 ences its prediction of learning and problem-solving suc- As we pointed out earlier, one of the challenges for the EA-
 cess. Learning is predicted to occur if the probability of a Coach example-selection mechanism is to choose examples 
 rule being known is low in the pre-simulation slice and the that are different enough to trigger learning by encouraging 
 simulation predicts that the student will reason via EBLC to effective APS behaviors (learning goal), but at the same 
 learn the rule (e.g., rule normal-dir, Fig. 3). The probabili- time similar enough to help the student generate the problem 
ties corresponding to the Pstep nodes in the simulation slice solution (problem-solving success goal). To verify how well 
represent the model’s prediction of whether the student will the two-phase process described in the previous section 
generate the corresponding problem solution steps. For a meets these goals, we ran a study that compared it with the 
given step, this is predicted to occur if either 1) the student standard approach taken by ITS that support APS, i.e., se-
can generate the prerequisite steps and derive the given step lecting the most similar example. Here, we provide an over-
                                                 view of the study methodology and present the key results. 
from a domain rule (e.g. Pstepn+1, Fig. 3) or 2) generate the 
 step by copying from the example (e.g., Pstep , Fig. 3). 
                                   n             3.1 Study Design 

   Rule1   Utility Rule1                         The study involved 16 university students. We used a 
                          Learning               within-subject design, where each participant 1) completed 
                          Utility 
    Rulen  Utility Rulen                         a pencil and paper physics pre-test, 2) was introduced to the 
                                Overall Utility  EA-Coach interface (training phase), 3) solved two New-
                                                 ton’s Second Law problems (e.g., of the type in Fig. 1) us-
  Pstep1   Utility Pstep1 
                        Problem-Solving          ing the EA-Coach, (experimental phase) and 4) completed a 
                         Success Utility         pencil and paper physics post-test. We chose a within-
           Utility Pstepn 
  Pstepn                                         subject design because it increases the experiment’s power 
                                             
                                                 by accounting for the variability between subjects, arising 
        Figure 4: Fragment of the EA Utility Model from differences in, for instance, expertise, APS tendencies, 
                                                 verbosity (which impacts verbal expression of EBLC). 
 2.2 Phase 2: The Utility Calculation              Prior to the experimental phase, each subject’s pre-test 
 The outcome of the simulation is used by the framework to data was used to initialize the priors for the rule nodes in the 
 assign a utility to a candidate example, quantifying its abil- user model’s Bayesian network. Since we did not have in-
 ity to meet the learning and problem-solving success objec- formation regarding students’ min-analogy and EBLC ten-
tives. To calculate this utility, the framework relies on a dencies, the priors for these nodes were set to 0.5. During 
decision-theoretic approach that uses the probabilities of the experimental phase, for each problem, subjects had ac-
rule and Pstep nodes in the user model as inputs to the cess to one example. For one of the problems, the example 
multi-attribute linearly-additive utility model shown in Fig. was selected by the EA-Coach (adaptive-selection condi-
4. The expected utility (EU) of an example for learning an tion), while for the other (static-selection condition), an ex-
individual rule in the problem solution corresponds to the ample most similar to the target problem was provided. To 
sum of the probability P of each outcome (value) for the account for carry-over effects, the orders of the prob-
corresponding rule node multiplied by the utility U of that lems/selection conditions were counterbalanced. For both 
outcome:                                         conditions, subjects were given 60 minutes to solve the 
    EU (Rule i ) P (known (Rule i )) U (known (Rule i ))  problem, and the EA-Coach provided immediate feedback 

              P ( known (Rule i )) U ( known (Rule i )) for correctness on their problem-solving entries, realized by 
 Since in our model, U(known(Rulei))=1 and U( known coloring the entries red or green. All actions in the interface 
(Rulei ))=0, the expected utility of a rule corresponds to the were logged. To capture subjects’ reasoning, we used the 
probability that the rule is known. The overall learning util- think-aloud method, by having subjects verbalize their 
ity of an example is the weighted sum of the expected learn- thoughts [Chi et al., 1989] and videotaped all sessions.  
ing utilities for all the rules in the user model: 
                n                                3.2 Data Analysis 
                                
                  EU (Rule i ) w i               The primary analysis used was univariate ANOVA, per-
                 i                               formed separately for the dependent variables of interest 
  Given that we consider all the rules to have equal impor-
                                                 (discussed below). For the analysis, the within-subject selec-
               w                           1/n
tance, all weights  are assigned an equal value (i.e., , tion factor (adaptive vs. static) was considered in combina-
where n is the number of rules in the user model). A similar 
                                                 tion with the two between-subject factors resulting from the 
approach is used to obtain the problem-solving success util-
                                                 counterbalancing of selection and problem types. The re-
ity, which in conjunction with the learning utility quantifies sults from the ANOVA analysis are based on the data from 
a candidate example’s overall utility.  
                                                 the 14 subjects who used an example in both conditions (2 
  The simulation and utility calculation phases are repeated 
                                                 subjects used an example in only one condition: one subject 
 for each example in the EA-Coach’s knowledge base. The used the example only in the static condition, another sub-
 example with the highest overall utility is presented to the 
                                                 ject used the example only in the adaptive condition). 
 student.  


                                            IJCAI-07
                                              486 3.3 Results: Learning Goal                      opportunities in the adaptive condition, as compared to the 
 To assess how well the EA-Coach adaptively-selected ex- static one (on average, 77% vs. 52% respectively). 
 amples satisfied the learning goal as compared to the stati- Discussion. As far as the learning goal is concerned, the 
 cally-selected ones, we followed the approach advocated in evaluation showed that the EA-Coach’s adaptively-selected 
 [Chi et al., 1989]. This approach involves analyzing stu- examples encouraged students to engage in the effective 
dents’ behaviors that are known to impact learning, i.e., APS behaviors (min-analogy, EBLC) better than statically-
copying and self-explanation via EBLC in our case. Al- selected examples: students copied less and self-explained 
though this approach makes the analysis challenging be- more when given adaptively-selected examples. This sup-
cause it requires that students’ reasoning is captured and ports our assumption that certain superficial differences 
analyzed, it has the advantage of providing in-depth insight encourage effective APS behaviors. The statically-selected 
into the EA-Coach selection mechanism’s impact. For this examples were highly similar to the target problem and thus 
part of the analysis, univariate ANOVAs were performed made it possible to correctly copy much of their solutions, 
separately for the dependent variables copy and EBLC rates. which students took advantage of. Conversely, by blocking 
                                                 the option to correctly copy most of their solution, the adap-
Copy  Rate. To identify copy events, we looked for in-
stances when students: 1) accessed a step in the example tively-selected examples provided an incentive for students 
solution (as identified by the verbal protocols and/or via the to infer via EBLC the principles needed to generate the 
                                                 problem solution. 
analysis of mouse movements over the example) and 2) 
generated the corresponding step in their problem solution 3.4 Results: Problem-Solving Success Goal 
with no changes or minor changes (e.g., order of equation 
terms, constant substitutions). Students copied significantly The problem-solving success goal is fulfilled if students 
less from the adaptively-selected examples, as compared to generate the problem solution. To evaluate if the adaptive 
the statically-selected examples (F(1,14)=7.2, p=0.023; on example-selection process met this goal, we checked how 
average, 5.9 vs. 8.1 respectively).              successful students were in terms of generating a solution to 
                                                 each problem. In the static condition, all 16 students gener-
EBLC  rate
         . To identify EBLC episodes, we analyzed the ated a correct problem solution, while in the adaptive condi-
verbal protocol data. Since EBLC is a form of self- tion, 14 students did so (the other 2 students generated a 
explanation, to get an indication of how selection impacted partial solution; both used the example in both conditions). 
explanation rate in general, we relied on the definition in This difference between conditions, however, is not statisti-
     et al
[Chi     ., 1989] to first identify instances of self- cally significant (sign test, p=0.5), indicating that overall, 
explanation. Students expressed significantly more self- both statically and adaptively selected examples helped stu-
explanations while generating the problem solution in the dents generate the problem solution. 
adaptive selection condition, as compared to in the static We also performed univariate ANOVAs on the dependent 
condition (F(1, 10)=6.4, p=0.03; on average, 4.07 vs. 2.57 variables error rate and task time to analyze how the adap-
respectively). We then identified those self-explanations that tively-selected examples affected the problem solving proc-
were based on EBLC (i.e., involved learning a rule via com- ess, in addition to the problem solving result. Students took 
monsense and/or overly-general reasoning, as opposed to significantly longer to generate the problem solution in the 
explaining a solution step using existing domain knowl- adaptive than in the static selection condition (F(1, 10) 
edge). Students generated significantly more EBLC expla- =31.6, p<0.001; on average, 42min., 23sec. vs. 25min., 
nations in the adaptive than the static condition (F(1, 35sec. respectively). Similarly, students made significantly 
10)=12.8, p=0.005; on average, 2.92 vs. 1.14 respectively). more errors while generating the problem solution in the 
Pre/Post Test Differences. With the analysis presented adaptive than in the static selection condition (F(1, 
above, we evaluated how the EA-Coach selection mecha- 10)=11.5, p=0.007; on average, 22.35 vs. 7.57 respectively).  
nism impacts learning by analyzing how effectively it trig- Discussion. As stated above, the problem-solving success 
                          .
gers APS behaviors that foster it  Another way to measure goal is satisfied if the student generates the problem solu-
 learning is via pre/post test differences. In general, students tion, and is not a function of performance (time, error rates) 
 improved significantly from pre to post test (on average, while doing so. The fact that students took longer/made 
 from 21.7 to 29.4; 2-tailed t(15)=6.13, p<0.001). However, more errors in the adaptive condition is not a negative find-
 because there was overlap between the two problems in ing from a pedagogical standpoint, because these are by-
 terms of domain principles, the within-subject design makes products of learning. Specifically, learning takes time and 
 it difficult to attribute learning to a particular selection con- may require multiple attempts before the relevant pieces of 
 dition. One way this could be accomplished is to 1) isolate knowledge are inferred/correctly applied, as we saw in our 
 rules that only appeared in one selection condition and that a study and as is backed up by cognitive science findings 
 given student did not know (as assessed from pre-test); 2) (e.g., [Chi, 2000]).  
 determine how many of these rules the student showed gains However, as we pointed out above, 2 students generated a 
 on from pre to post test. Unfortunately, this left us with very correct but incomplete solution in the adaptive selection 
 sparse data making formal statistical analysis infeasible. condition. To understand why this happened, we analyzed 
 However, we found encouraging trends: there was a higher these students’ interaction with the system in detail. Both of 
 percentage of rules learned given each student’s learning them received an example with non-trivial superficial dif-


                                            IJCAI-07
                                              487