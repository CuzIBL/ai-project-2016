                A Study of Selection Noise in Collaborative Web Search∗
                                   Ois´ın Boydell  and  Barry Smyth
                                      Adaptive Information Cluster
                        Smart Media Institute, Department of Computer Science,
                         University College Dublin, Belﬁeld, Dublin 4, Ireland
                                  {oisin.boydell, barry.smyth}@ucd.ie

                                 Cathal Gurrin   and  Alan F. Smeaton
                   Adaptive Information Cluster, Centre for Digital Video Processing,
                          Dublin City University, Glasnevin, Dublin 9, Ireland
                            {cathal.gurrin, alan.smeaton}@computing.dcu.ie

                    Abstract                          of [Smyth et al., In Pressb] has suggested another source
                                                      of relevance knowledge: in the Collaborative Web Search
    Collaborative Web search uses the past search be- (CWS) approach patterns of queries and result selections
    haviour (queries and selections) of a community of from a community of users are used to re-rank the results of
    users to promote search results that are relevant to an underlying search engine. A community can be a well-
    the community. The extent to which these promo-   deﬁned group of users, such as the employees of a given
    tions are likely to be relevant depends on how re- company, or it can be an ad-hoc group of individuals, such
    liably past search behaviour can be captured. We  as the users of some topical Web site, for example a motor-
    consider this issue by analysing the results of col- ing Web site. The point is that many searches can be traced
    laborative Web search in circumstances where the  back to communities of users and our research indicates that
    behaviour of searchers is unreliable.             these communities are likely to submit similar queries and se-
                                                      lect the same types of results [Smyth et al., In Pressb]. In a
1  Introduction                                       recent analysis of search logs from a variety of sources we
                                                      have found that within communities of searchers up to 70%
Traditional approaches to Web search are term-based; they or more of queries share at least 50% of their query terms
assume that relevance is best understood from the terms with past queries from the community; see [Smyth et al., In
within documents. It has been shown that typical Web users Pressb]. For example, in [Smyth et al., In Pressa] we de-
are not experts when it comes to searching for documents scribe the results of a recent trial of CWS within a corporate
- they routinely provide ambiguous queries [Lawrence and context and a community of about 50 searchers (the employ-
Giles, 1998], making it difﬁcult for search engines to predict ees of an Irish software company). The data collected as part
their needs. In such an environment, query and document of this trial indicates that 57% of queries share half of their
terms are not always a good indication of relevance and so query terms with previous queries. The results of this trial go
content-based approaches often fail [Furnas et al., 1987]. Re- on to show that CWS can take good advantage of this type of
cent innovations have seen the introduction of new sources repetition and regularity to signiﬁcantly enhance search per-
of relevance knowledge. For example, the work of [Brin formance.
and Page, 1998] has famously demonstrated the usefulness of CWS relies on a relevance assumption—that the selection
inter-document relationships by exploiting link-connectivity of a page for some query is a reliable indicator of page rel-
information. More recently researchers have also focused on evance—which cannot be fully relied upon. Search engines
ways to exploit context in Web search as a way to disam- often return pages that turn out not to be relevant, and users
biguate vague queries, either by explicitly establishing the often mistakenly select them. The question is: how sensitive
search context up-front or by implicitly inferring the con- are the results of CWS to selection noise? We will answer this
text as part of the search process (see [Lawrence, 2000]). question in what follows by analysing the impact of selection
Yet others have focused on leveraging knowledge about the noise on result precision.
query-space to directly address the correspondence problem,
by mining query logs in order to identify useful past queries 2 Collaborative Web Search
that may help the current searcher (e.g., [Glance, 2001;
Raghavan and Sever, 1995; Wen et al., 2002]). The work CWS is a form of meta-search, relying on the search services
                                                      of a set of underlying search engines, but manipulating their
  ∗This material is based on works supported by Science Founda- results in response to the learned preferences of a given com-
tion Ireland under Grant No. 03/IN.3/I361.            munity of users. A key data structure in CWS is the hit ma-trix, H. It represents the search behaviour of a given commu- were evaluated with respect to their ability to locate pages rel-
nity of users and each time a member of a community selects evant to these topics. After the evaluation a relevance engine
a result pj in response to some query qi the entry in cell Hij was made available to help with the evaluation of new search
is incremented. In turn, the relevance of a page pj to qi can be techniques. This engine provides ground-truth relevance for
estimated as the relative number of selections pj has received the topics and allows for the detailed analysis of result-lists in
in the past for qi; see Equation 1.                   relation to the test queries.

                               Hij                    3.2  Training the Hit-Matrix
          Relevance(pj, qi) = P                 (1)
                               ∀j Hij                 Normally in CWS the hit-matrix is trained by the searches
                                                      of a given community of users, but we need a mechanism
                                                      for manipulating selection noise and so we need a more con-
           W Rel(pj, qT , q1, ..., qn) =        (2)
      P                                               trolled experimental framework. For this we require a set of
              Relevance(p , q ) • Sim(q , q )
        Pi=1...n         j  i        T  i             queries and a method for judging the relevance of the results
          i=1...n Exists(pj, qi) • Sim(qT , qi)       that are returned and that might be selected by users. We gen-
                                                      erate queries by extracting subsets of terms from the TREC
More generally, the relevance of a page p to some query q
                                  j              T    topic descriptions, after ﬁrst removing commonly occurring
can be calculated as the weighted sum of its relevance to a
                                                      stop words; for each topic we generate 50 queries with be-
set of queries that are similar to q , namely q , ..., q , with
                             T         1    n         tween 2 and 8 terms each. To simulate the action of a searcher
each individual relevance value discounted by the similarity
                                                      we use the ofﬁcial TREC relevance engine, which is capable
between q and the query in question; see Equation 2. The
        T                                             of identifying all result pages that are relevant for a given
similarity between q and the query in question, q is calcu-
                 T                        i           topic. Thus, for a training query q generated from topic t, we
lated as in Equation 3; it is worth noting that we have recently
                                                      can identify the k pages returned by a baseline search engine
evaluated a variety of alternative and more sophisticated simi-
                                                      (see [Blott et al., In Press]) that are relevant to t as the basis
larity metrics, the results of which are presented in [Balfe and
                                                      for updating our hit-matrix for topic t. During the update we
Smyth, 2005; In Press].
                                                      use two types of noise. T ypeA noise occurs when additional
                          |q ∩ q |                    non-relevant results are selected and thus during training we
             Sim(q  , q ) = T   i               (3)
                  T  i    |q ∪ q |                    assume that the user selects all k retrieved documents that
                           T    i                     are relevant and an additional n% of k non-relevant pages.
  Thus on receipt of some target query, qT , CWS dispatches T ypeB noise occurs when users fail to select all of the rele-
it to a set of underlying search engines and their results are vant results returned and thus during training we assume that
combined to form a meta-search result-list, RM . At the same the user only selects (100 − n)% of the k relevant results and
time, qT is compared to other queries in the hit-matrix to n% of k irrelevant results returned for each query.
select a set of similar queries, q1, ..., qn, that are selected if
their similarity to qT exceeds some set threshold. The re- 3.3 Precision Analysis
sults selected for these queries in the past are ranked by their To assess the precision of CWS we use the ofﬁcial TREC
weighted relevance to qT , according to Equation 2, to pro- test queries that formed the basis of the TREC 2004 evalua-
duce a new promoted result-list, Rp. RP is combined with tion; none of these queries were used in training. Two dif-
RM  to produce RT , which is then returned to the user; in our ferent versions of CWS are used for query similarity thresh-
implementation RT = RP ∪ RM . For further detail on the olds of > 0 and >= 0.5, with different types and levels of
technical details of the CWS architecture and operation see selection noise introduced. Each test query is replayed and
[Smyth et al., In Pressb].                            the percentage of relevant results for different result-list sizes
                                                      is computed. The average of these precision values is com-
3  Evaluation                                         puted to produce an overall mean average precision (MAP)
                                                      for each version of CWS. We also compute a baseline MAP
The success of CWS depends on the quality of its promoted for the TREC Benchmark search engine used in [Blott et al.,
results, RP , and their quality in turn depends on the re- In Press], which serves as the underlying engine for CWS.
liability of the user selections that underpin the core rele- The results are presented in Figures 1 and 2. Each graph
vancy calculations. In this evaluation we will assess the qual- shows the MAP for the baseline and for CWS with Type A
ity of these promotions under different degrees of selection and B noise. They show that CWS offers signiﬁcant preci-
noise with an experiment using the TREC Terabyte collec- sion increases over the baseline. For example, for the > 0
tion (see http://www-nlpir.nist.gov/projects/terabyte) and the threshold, at the 0% noise level, CWS delivers over twice
F´ısreal´ search engine [Blott et al., In Press].     the precision of the baseline (0.34 vs. 0.15). We also see
                                                      that these precision beneﬁts degrade gracefully as noise is in-
3.1  The TREC Terabyte Collection                     creased, and the beneﬁts are preserved even for high noise
This collection consists of over 25 million Web pages (ap- levels. For instance, even with 100% Type A noise we see that
prox, 426GB) crawled from the .gov domain during early CWS delivers a MAP of 0.17, which is greater than the cor-
2004. The TREC Terabyte track included 50 random topics responding baseline MAP (0.14). We see that CWS is more
as target search topics. Each topic included a short textual de- sensitive to Type B noise, especially for the >= 0.5 thresh-
scription and during the evaluation competing search engines old. Here, CWS MAP falls below the baseline for 80% noise;                                                      References
                                                      [Balfe and Smyth, 2005] Evelyn Balfe and Barry Smyth. An
                                                         analysis of query similarity in collaborative web search. In
                                                         Proceedings of the 27th European Conference on Informa-
                                                         tion Retrieval, pages 330–344, 2005.
                                                      [Balfe and Smyth, In Press] Evelyn Balfe and Barry Smyth.
                                                         A Comparative Analysis of Query Similarity Metrics for
                                                         Community-Based Web Search. In Proceedings of the 6th
                                                         International Conference on Case-Based Reasoning, (In
                                                         Press).
                                                      [                ]
          Figure 1: Similarity Threshold > 0           Blott et al., In Press Stephen Blott, Ois´ın Boydell, Fabrice
                                                         Camous, Paul Ferguson, Georgina Gaughan, Cathal Gur-
                                                         rin, Noel Murphy, Noel O’Connor, Alan F. Smeaton,
                                                         Barry Smyth, and Peter Wilkins. Experiments In Terabyte
                                                         Searching, Genomic Retrieval And Novelty Detection For
                                                         TREC-2004. In Proceedings of the Thirteenth Text RE-
                                                         trieval Conference, (In Press).
                                                      [Brin and Page, 1998] Sergey Brin and Lawrence Page. The
                                                         Anatomy of a Large-Scale Hypertextual Web Search En-
                                                         gine. Computer Networks and ISDN   Systems, 30(1–
                                                         7):107–117, 1998.
                                                      [Furnas et al., 1987] George W. Furnas, Thomas K. Lan-
                                                         dauer, Louis M. Gomez, and Susan T. Dumais. The vocab-
          Figure 2: Similarity Threshold ≥ 0.5           ulary problem in human-system communication. Commu-
                                                         nications of the ACM, 30(11):964–971, 1987.
                                                      [Glance, 2001] Natalie S. Glance. Community Search As-
this corresponds to a situation where in many search sessions
                                                         sistant. In Proceedings of the International Conference
no relevant results are selected by users.
                                                         on Intelligent User Interfaces, pages 91–96. ACM Press,
                                                         2001.
4  Conclusions
                                                      [Lawrence and Giles, 1998] Steve Lawrence and C. Lee
CWS personalizes search results for a community of like- Giles. Context and Page Analysis for Improved Web
minded searchers based on their prior search histories. It Search. IEEE Internet Computing, July-August:38–46,
is appropriate in a wide variety of search scenarios because 1998.
many Web searches are initiated within a community context;
for example, the searches initiated from a search box on some [Lawrence, 2000] Steve Lawrence. Context in Web Search.
themed Web site or the searches of some online social group. IEEE Data Engineering Bulletin, 23(3):25–32, 2000.
When responding to a new search query, CWS exploits the [Raghavan and Sever, 1995] Vijay V. Raghavan and Hayri
results of searches for similar queries that have taken place in Sever. On the reuse of past optimal queries. In Proceedings
the past (for a given community) and actively promotes those of the 18th Annual International ACM SIGIR Conference
results. Thus, results that are consistently selected for queries on Research and Development in Information Retrieval,
will tend to be promoted, although care must be taken to limit pages 344–350. ACM Press, 1995.
the inﬂuence of promotional biases as a result of selection [Smyth et al., In Pressa] Barry Smyth, Evelyn Balfe, Ois´ın
noise or malicious users.                                Boydell, Keith Bradley, Peter Briggs, Maurice Coyle, and
  In this paper we have evaluated the performance of CWS Jill Freyne. A Live-User Evaluation of Collaborative Web
when search histories contain result selections that are un- Search. In Proceedings of the 19th International Joint
reliable. Obviously, if users select results that are not rel- Conference on Artiﬁcial Intelligence, IJCAI-05, (In Press).
evant to their query then there is the risk that these results
will be promoted in the future. The question that we have at- [Smyth et al., In Pressb] Barry Smyth, Evelyn Balfe, Jill
tempted to answer is the degree to which CWS is sensitive to Freyne, Peter Briggs, Maurice Coyle, and Ois´ın Boydell.
such noisy selections. Our results indicate that CWS is rela- Exploiting Query Repetition & Regularity in an Adaptive
tively robust to noise with signiﬁcant precision beneﬁts avail- Community-based Web Search Engine. User Modeling
able even for very high levels of selection noise. This bodes and User-Adapted Interaction: The Journal of Personal-
well for CWS and is in agreement with the performance ben- ization Research, (In Press).
eﬁts witnessed in live-user trials, in which noisy selections [Wen et al., 2002] Ji-Rong Wen, Jian-Yun Nie, and Hong-
are likely to occur. In ﬁnishing, it is worth highlighting that Jiang Zhang. Query clustering using user logs. ACM
the CWS approach has been fully implemented in the I-SPY Transactions on Information Systems, 20(1):59–81, 2002.
system which can be accessed at http://ispy.ucd.ie.