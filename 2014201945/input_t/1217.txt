                            Exploiting Background Knowledge for
                          Knowledge-Intensive Subgroup Discovery
          Martin Atzmueller    and  Frank Puppe                 Hans-Peter Buscher
             Department of Computer Science               DRK-Kliniken Berlin-Kopenick,¨
                  University of Wurzburg¨                  Clinic for Internal Medicine II,
                97074 Wurzburg,¨  Germany                      12559 Berlin, Germany
    {atzmueller, puppe}@informatik.uni-wuerzburg.de           buscher.dhp@t-online.de

                    Abstract                          classes can potentially be used in other rule-based learning
                                                      methods in a straightforward manner. Similar to the applied
    In general, knowledge-intensive data mining meth- knowledge, subgroup discovery results can also be formal-
    ods exploit background knowledge to improve the   ized incrementally and can be provided as input to the search
    quality of their results. Then, in knowledge-rich method. We will introduce this approach in this paper.
    domains often the interestingness of the mined pat- Our implementation and evaluation is based on the
    terns can be increased signiﬁcantly.              knowledge-based documentation and consultation system for
    In this paper we categorize several classes of back- sonography SONOCONSULT [Huettig et al., 2004], which is
    ground knowledge for subgroup discovery, and      in routine use in the DRK-hospital in Berlin/Kopenick.¨
    present how the necessary knowledge elements can    The rest of the paper is organized as follows: First we de-
    be modelled. Furthermore, we show how subgroup    scribe the knowledge-intensive process for subgroup discov-
    discovery methods beneﬁt from the utilization of  ery. We introduce the subgroup discovery method, present
    background knowledge, and discuss its application the different types of suitable background knowledge and dis-
    in an incremental process-model. The context of   cuss their characteristics in detail. After that, an experimental
    our work is to identify interesting diagnostic pat- evaluation of the impact of the proposed method is demon-
    terns to supplement a medical documentation and   strated by a case study in the medical domain. Finally, we
    consultation system. We provide a case study in   conclude the paper with a discussion of the presented work,
    the medical domain, using a case base from a real- and we show promising directions for future work.
    world application.
                                                      2   Knowledge-Intensive Subgroup Discovery
1  Introduction                                       In this section, we ﬁrst give an overview of the subgroup dis-
                                                      covery method and deﬁne the basic concepts of our knowl-
Knowledge-intensive learning methods usually exploit back- edge representation schema. Furthermore, we present the
ground knowledge, because this can improve the quality of knowledge-intensive subgroup discovery process, and de-
their results signiﬁcantly (c.f. [Richardson and Domingos, scribe the background knowledge in detail.
2003]). In this paper we exploit background knowledge for
subgroup discovery [Wrobel, 1997; Klosgen,¨ 2002], applied 2.1 Subgroup Discovery
for exploration or descriptive induction, to discover ”inter- Subgroup discovery [Wrobel, 1997; Klosgen,¨ 2002] is a
esting” subgroups concerning a certain property of interest. method to discover ”interesting” subgroups of individuals,
Background knowledge can help to focus the algorithm for e.g., ”the subgroup of patients who are treated in a small, un-
subgroup search on the relevant patterns according to the derstaffed hospital are signiﬁcantly more likely to suffer from
goals of the user, thus reducing uninteresting patterns and re- complications in the future than the patients in the reference
stricting the search space. This can increase the quality of the population”. Subgroups are described by relations between
discovered set of subgroups signiﬁcantly, as well as the efﬁ- independent (explaining) variables and a dependent (target)
ciency of the search method. It is obvious, that the amount variable, rated by a certain interestingness measure. For ex-
of available background knowledge depends on the particu- ample, two possible criteria are the difference in the distrib-
lar application domain. For example, in the medical domain ution of the target variable concerning the subgroup and the
usually a lot of background knowledge is available.   general population, and the subgroup size. The main appli-
  Besides (simple) constraints the background knowledge for cation areas of subgroup discovery are exploration and de-
the presented knowledge-intensive process consists of two scriptive induction, to obtain an overview of the relations
categories: a task-speciﬁc subset of derived attributes and between a target variable and usually many explaining vari-
general ontological background knowledge, that can be re- ables. Subgroup discovery does not necessarily focus on ﬁnd-
ﬁned incrementally. Certain knowledge classes can also be ing complete relations; instead partial relations, i.e., (small)
used to derive new (lower-level) knowledge. The knowledge subgroups with ”interesting” characteristics can be sufﬁcient.  Before deﬁning the subgroup discovery task, we ﬁrst intro- the quality function qBT , the quality function qRG only com-
duce the necessary notions concerning our knowledge repre- pares the target shares of the subgroup and the total popula-
sentation schema. Let ΩA the set of all attributes. For each tion measuring the relative gain. Therefore, a suitable support
attribute a ∈ ΩA a range dom(a) of values is deﬁned. Fur- threshold is necessary to discover signiﬁcant subgroups.
thermore, we assume VA to be the (universal) set of attribute Considering the subgroup search strategy an efﬁcient
values of the form (a : v), where a ∈ ΩA is an attribute and search is necessary, since the search space is exponential con-
v ∈ dom(a) is an assignable value.                    cerning all the possible selectors of a subgroup description.
  A subgroup discovery task mainly relies on the following Commonly, a beam search strategy is used because of its ef-
four main properties: the target variable, the subgroup de- ﬁciency [Klosgen,¨ 2002]. For our search strategy, we use
scription language, the quality function, and the search strat- a modiﬁed beam search strategy, where an initial subgroup
egy. The target variable may be binary, nominal or numeric. description can be selected as the initial value for the beam.
Depending on its type, there are different analytic questions, Beam search adds a selector to the k best subgroup descrip-
e.g., for a numeric target variable we can search for signiﬁ- tions in each iteration. Iteration stops if the quality as evalu-
cant deviations of the mean of the target variable.   ated by the quality function q does not improve any further.
  A subgroup discovery problem encapsulates the target vari-
able, the search space of independent variables, the general 2.2 The Knowledge-Intensive Process Model
population, and additional constraints.               Often suitable background knowledge can help both to focus
                                                      the subgroup discovery task on the relevant patterns concern-
Deﬁnition 1 (Subgroup Discovery Problem). A subgroup dis- ing the given analysis goals, and to restrict the search space.
covery problem SP is deﬁned as the tuple              We propose an incremental approach in which background
                SP = (T, A, C, CB) ,                  knowledge can be applied initially at the start, but also dur-
                                                      ing the discovery process. The proposed knowledge-intensive
where T ∈ ΩA ∪VA is a target variable. A ⊆ ΩA is the set of process for subgroup discovery is depicted in Figure 1.
attributes to be included in the subgroup discovery process. We start with a deﬁned population given as a case base
CB is the case base representing the general population used CB and existing background knowledge, if available. For the
for subgroup discovery. C speciﬁes (optional) constraints for analysis task deﬁned by a subgroup discovery problem the
the discovery method. We deﬁne ΩSP as the set of all possible subgroup discovery method generates a set of subgroups. If
subgroup discovery problems.                          these are considered as interesting by the user, the results are
  The deﬁnition above allows for arbitrary target variables. presented, and the process is ﬁnished. Otherwise the sub-
However, for our analytic questions we will focus on binary groups are analyzed, and background knowledge including
                                                      constraints can be added to the subgroup discovery problem.
target variables, i.e., T ∈ VA.
The description language speciﬁes the individuals from the Additionally, selected subgroups can be used as the basis for
reference population belonging to the subgroup.       further reﬁnement. Then the process continues with a new
                                                      iteration: all constraints of the current subgroup discovery
Deﬁnition 2 (Subgroup Description). A subgroup description problem are applied for the search process. In summary, the
sd = {ei} consists of a set of selection expressions (selectors) knowledge-intensive process consists of three main steps:
ei = (ai, Vi) which are selections on domains of attributes, 1. DISCOVER: Discover subgroups – result set SG
i.e., ai ∈ ΩA, Vi ⊆ dom(ai). A subgroup description is de- 2. INSPECT: If SG is interesting – STOP and present the
ﬁned as the conjunction of its contained selection expressions. subgroup discovery results; otherwise
We deﬁne Ωsd as the set of all possible subgroup descriptions. 3. REFINE: Analyze the discovered subgroups; adapt the
  A quality function measures the interestingness of the sub- subgroup discovery problem, i.e., extend or modify
group (c.f., [Klosgen,¨ 2002] for examples).              background knowledge and/or use interesting subgroups
                                                          as a starting point for step 1. GOTO step 1
Deﬁnition 3 (Quality Function). A quality function

                q : Ωsd × ΩSP → R

evaluates a subgroup description sd ∈ Ωsd given a sub-
group discovery problem SP ∈ ΩSP . It is used by the search
method to rank the discovered subgroups during search.
  For binary target variables, examples for quality functions
are given by
                √   r
       (p − p0) · n      N               p − p0
qBT = p             ·        ,  qRG =             ,
        p0 · (1 − p0)  N − n           p0 · (1 − p0)
                                                          Figure 1: The Knowledge-Intensive Process Model
where p is the relative frequency of the target variable in the
subgroup, p0 is the relative frequency of the target variable in Step 3 is performed by the domain specialist according to the
the total population, N = |CB| is the size of the total popu- analysis goals. Examples for the adaptation of the subgroup
lation, and n denotes the size of the subgroup. In contrast to discovery problem are given in the case study in Section 3.2.3  Background Knowledge for Subgroup                Constraints can signiﬁcantly restrict the search space and fo-
     Discovery                                        cus the search process. The knowledge acquisition cost for
We want to make the acquisition of helpful background constraints is moderate, depending on the number of relations
knowledge as easy as possible. Therefore, we try utilize that need to be modeled; the costs can also be decreased uti-
knowledge known from other knowledge systems, that the lizing ontological knowledge as described below.
domain specialist is already familiar with. There are different
classes of background knowledge which can be used in the Pattern Knowledge In general, pattern knowledge speciﬁes
knowledge-intensive process for subgroup discovery: con- the kinds of patterns that the user is especially interested in.
straints, ontological knowledge, abstraction knowledge, and For example, pattern knowledge can be used to deﬁne already
pattern knowledge. Knowledge acquisition is always expen- known subgroups, that can be directly applied in the discov-
sive, so its costs should be minimized. Sometimes knowledge ery process for subgroup reﬁnement. As another kind of pat-
can be derived from already formalized knowledge, e.g., we tern knowledge, the user can specify priority groups which
can derive constraints from ontological knowledge, and thus are partial disjunctive sets of attributes, that have an assigned
reduce its acquisition costs.                         priority, e.g., depending on the association strength between
  In the following table, we summarize the different classes an attribute and the target variable. Then, we can start with
and types of background knowledge (CK = constraint knowl- the set of attributes with the highest priority. If the discovered
edge, OK = ontological knowledge, PK = pattern knowledge, subgroups cannot be improved any further by the attributes in
AK = abstraction knowledge). We show their characteris- the current set, then we take the attributes in the next priori-
tics in terms of the ’derivable knowledge’ if applicable, their tized attribute set into account, in the next iteration. The costs
costs, and their potential contribution to restricting the search for pattern knowledge are not too high, if the patterns are dis-
space and/or focusing the search process. Considering the covered automatically. For priority knowledge, the cost is
costs and the impact of the knowledge types on the search encoded in the partially disjunctive separation of attributes.
space, the label - indicates no cost/impact; the labels +, ++, Pattern knowledge does not really restrict the search space,
and +++ indicate increasing costs and impact. A +(+) signi- but can help to focus the search.
ﬁes, that the respective element has low costs if it can be de-
rived/learned, and moderate costs otherwise. Similarly ++(+) Ontological Knowledge We can utilize ontological knowl-
indicates this for moderate and high costs, respectively. edge which is commonly used in the development of knowl-
                                                      edge systems, e.g., in case-based reasoning systems. The fol-
 Knowledge           Derivable    Cost   Search Space
 Class Type          Knowledge          Restr. Focus  lowing elements need to be deﬁned by the domain specialist if
 CK    Syntactical Constr. –      +     +     +       they cannot be learned (semi-)automatically, e.g., [Baumeis-
 CK    Quality Constr. –          +     ++    ++      ter et al., 2002].
 CK    Attr. Values Constr. –     +(+)  +     +
 CK    Meta Values Constr. –      +(+)  –     ++        •
 CK    Attributes Constr. –       +(+)  ++    ++          weights of attributes denoting their importance
 OK    Normality Info Attr. Val. Constr. + +  ++        • similarity information about the relative similarity be-
 OK    Abnormality Info Attr. Val. Constr. ++ + ++        tween attribute values
                     Meta Val. Constr.  –     ++
 OK    Similarity Info Meta Val. Constr. ++(+) – ++     • abnormality information about attribute values
 OK    Ordinality Info Meta Val. Constr. + ++ +++       • ordinality information about attributes
 OK    Attr. Weights Attr. Constraints +(+) + ++
 AK    Derived Attributes Derived Attributes +++ +++ +++ Abnormality/Normality Information If abnormality or
 PK    Subgroup Pattern Derived Attributes +(+) – +
 PK    Priority Groups –          ++    –     +       normality information about attribute values is available, then
                                                      each value v ∈ dom(a) of an attribute a is attached with
  The most important types of background knowledge with
                                                      a label that explains, if v is describing a normal or an ab-
an especially good cost/beneﬁt ratio are indicated in bold
                                                      normal state of the attribute. Normality information only
type. Derived attributes are a special case with potentially
                                                      requires a binary label while abnormality information de-
high beneﬁt as discussed below. Then, the need for derived
                                                      ﬁnes several categories. For example, consider the attribute
attributes depends on the speciﬁc application domain.
                                                      temperature with the value range dom(temperature) =
Constraint Knowledge  Constraints are a class of back- {normal, marginal, high, very high}. The values normal and
ground knowledge, which is especially simple to apply. The marginal denote normal states of the attribute, while the val-
different constraint types can be described as follows: ues high and very high describe abnormal states. Several cate-
  • Attribute values constraints: the attribute values can be gories can be deﬁned according to the degree of abnormality.
    restricted to the set of relevant values.         We use ﬁve degrees of abnormality given by the symbolic
  • Meta values constraints: speciﬁc value groups deﬁning values A1, A2, A3, A4, A5. Category A1 denotes a normal
    an abstracted ’meta value’ can be speciﬁed, e.g., inter- value; the categories {A2, A3, A4, A5} denote abnormal val-
    vals for ordinal values. Meta values are not restricted to ues in ascending order. Using abnormality/normality knowl-
    intervals, but can cover any combination of values. edge we can constrain the value range of an attribute: e.g., ei-
  • Constraints for attributes: speciﬁc attributes and/or com- ther all values corresponding to selected abnormal categories
    binations of attributes can be excluded.          or the values marked with the normal category can be ex-
  • General constraints restricting the syntactical form of the cluded from the domain of an attribute used in the subgroup
    discovered subgroups, or quality constraints for the dis- discovery method, by a global exclusion condition. Then, at-
    covered subgroups can be applied.                 tribute values constraints are derived accordingly.Meta Values Abnormality information and similarity infor- Improving the Handling of Missing Values Considering
mation concerning attribute values can be used to deﬁne ad- the quality functions abstraction knowledge contributes to
ditional meta values: e.g., if the similarity between two at- one major point – handling missing values. Missing values
tribute values is very high, then they can potentially be ana- in cases are a signiﬁcant problem for subgroup discovery and
lyzed as one value, thus forming a disjunctive selection ex- machine learning in general. For example, in medical case
pression on the value range of an attribute. Likewise, global bases for a speciﬁc patient usually only a subset of the possi-
abnormality groups can be deﬁned by providing groups of ab- ble examinations is performed, given a structured data gath-
normality degrees that specify which values should be com- ering strategy in real-world applications. Then, only the rel-
bined. This is especially relevant in the medical domain with evant questions for the diagnostic tasks are presented to the
attribute values such as probable, possible, and unveriﬁable. user. This results in reduced costs for the examiner, however
In diagnostics the value probable contributes more evidence then a speciﬁc instance of the data set concerning the basic
to the represented concept than the value possible. However, attributes may be quite sparse.
for analysis often the values probable and possible have an al- There exist several strategies for dealing with missing val-
most equivalent meaning and can be considered as one value. ues: a common strategy [Tsumoto, 2002] removes objects
  Ordinality information that speciﬁes if an attribute is or- (cases) with missing values from the set of analyzed objects.
dinal can be used to deﬁne meta values relating to ordinal Other strategies try to ﬁll in the missing values according to
groups: we can generate meta values covering all adjacent statistical evaluations, or try to model the distribution [Ragel
combinations of attribute values, or all ascending/descending and Crewmilleux,´ 1999]. The subgroup quality functions ba-
combinations of values, starting with the minimum or max- sically perform a kind of statistical hypothesis testing given a
imum, respectively. If abnormality information is available, subgroup description, the target variable and the general pop-
then we partition the value range by the given normal value ulation. For such a test only the cases of the population can
and only start with the most extreme value. For example, be considered in which all variables have deﬁned values. The
for the ordinal attribute liver size with the values 1:smaller power of the test is decreased signiﬁcantly, if many analysis
than normal, 2:normal, 3:marginally increased, 4:slightly in- objects are removed due to missing values.
creased, 5:moderately increased and 6:highly increased, we In general, we cannot simply apply the ”closed-world as-
partition by the normal value (2) and obtain the following sumption”, i.e., that missing values of a concept indicate the
meta values: (1), (3, 4, 5, 6), (4, 5, 6), (5, 6) and (6). non-existence or negation of the concept. For example, in the
  We summarize how constraints can be derived from on- medical domain, a diagnosis may be missing, because either
tological knowledge: The set of relevant attributes can be all its relevant observations are missing or they are known
constrained using attribute weights, with a suitable thresh- but denote the normal, i.e., the non-pathological state. Conse-
old. Given similarity and abnormality/normality information quently the diagnosis is not inferred. If we construct a derived
about attribute values we can model/restrict the value ranges attribute to indicate the cases when the relevant observations
of attributes. Ordinality information about attribute values are missing, then we can use this derived ”helper” attribute to
can be easily used to construct ordinal grouped meta values, indicate when the diagnosis really has a missing value. Ad-
which are often more meaningful for the domain specialist. ditionally, derived attributes besides the described ”helper”
Then, the original values can be replaced, optionally. attributes can also be constructed accordingly to minimize
                                                      missing values themselves, such that a certain default value
Abstraction Knowledge This class of background knowl- is provided which denotes the normal category. So, the de-
edge is given by derived attributes that are inferred from ba- rived attributes serve three purposes:
sic attributes or other derived attributes. Derived attributes • They focus the subgroup discovery method on the rele-
often correspond to certain known dependencies between at- vant analysis objects,
tributes, or known intermediate concepts, that are not stored • They decrease multi-correlations between attributes that
as basic attributes. For example, in the medical domain, we are not interesting,
can infer the derived attribute body mass index, given the at- • Derived attributes can reduce missing values for a given
tributes height and weight. Additionally, if there are a lot of concept, since they can be constructed such that a de-
basic attributes in the case base, (known) multi-correlations ﬁned value is more often computed if the respective con-
between basic attributes can cause unstructured subgroup dis- cept would have a missing value otherwise.
covery results. Then, data abstraction can increase the in- The derived attributes can either be constructed based on ex-
terpretability of the subgroup discovery results signiﬁcantly. pert knowledge, or on speciﬁc discovered subgroups. A sub-
Simple concepts can be aggregated to intermediate concepts group description is a set of selectors for a speciﬁc target con-
to form more potentially meaningful and interesting selec- cept that are highly correlated with the concept. If the selec-
tors. A nominal derived attribute a ∈ ΩA is deﬁned us- tors can be abstracted into a derived attribute, then it can be
ing abstraction rules, which are utilized to derive the val- used as potential background knowledge as well. Further-

ues via ∈ VA concerning attribute a. A rule of the form more, derived attributes can potentially be reﬁned according

rva = cond(rva ) → va is used for a value va of attribute to the subgroup discovery results, by specialization or gener-

a, where the rule condition cond(rva ) contains conjunctions alization. Abstraction knowledge is probably the most costly
and/or disjunctions of (negated) attribute values vi ∈ VA. class of background knowledge in the knowledge-intensive
Furthermore, derived attributes with a numerical value range process. If the abstractions are not based on discovery results,
can be deﬁned by algebraic formula expressions.       then they have to be formalized manually by the expert.2.4  Related Work                                       In the next stage, the expert decided to deﬁne new at-
Using background knowledge to constrain the search space tributes, i.e., abstracted attributes which described interest-
and pruning hypotheses during the search process has been ing concepts for analysis. The expert provided 45 derived at-
proposed in ILP approaches. [Weber, 2000] proposes require- tributes, that consist of symptom interpretations directly indi-
and exclude-constraints for attribute – value pairs, in order to cating a diagnosis and intermediate concepts which are used
prune the search space. [Zelezny et al., 2003] integrate con- in clinical practice, for example pleura-effusion, portal hy-
straints into an ILP approach as well; the used constraints are pertension, or pathological gallbladder status. Furthermore,
mainly concerned with syntactical restrictions and constraints constraints were formalized, that prevented the combination
relating to the quality of the discovered subgroups.  of certain attributes, to restrict the search space. Some ex-
  The main difference between the presented approach and amples are depicted in the Table 1, where the dependent and
the existing approaches is the fact, that we are able to inte- independent variables are directly related to each other. The
grate several new types of additional background knowledge. Target Variable Independent Variable
                                                       Chronic Pancreatitis Pancreas Disease
This additional background knowledge can be reﬁned incre- Pancreas Disease Carcinoma of the Pancreas
mentally according to the requirements of the discovery task, Body Mass Index Relative Body Weight
and can additionally be used to infer new background knowl-
edge on the ﬂy, e.g., constraints. As a major point we apply Table 1: Examples of known/uninteresting relations
special abstraction knowledge, which can be deﬁned by the newly deﬁned abstraction knowledge was applied extending
expert, or can be constructed semi-automatically using the the search space to the expert-deﬁned attributes. For each
subgroup discovery results. This type of knowledge can be attribute a in the set of derived attributes and each value
applied dynamically in the process and does not rely on a sta- vi ∈ dom(a), a subgroup discovery problem SP ai ∈ ΩSP
tic data-preprocessing and cleaning task, for example. was generated using the binary target variable (a = vi).
                                                        The impact of the added background knowledge was
3  Case Study                                         proven by a greater acceptance of the subgroup discovery re-
                                                      sults by the expert. However still too many subgroups were
In this section we describe a case study for the application of not interesting for the expert, because too many normal val-
the knowledge-intensive process. We use cases taken from ues were included in the results, e.g., liver-size = normal, or
                        [                ]
the SONOCONSULT  system  Huettig et al., 2004 – a med- fatty liver = unlikely. This motivated the application of ab-
ical documentation and consultation system for sonography normality information to constrain the value space to the set
– which has been developed with the knowledge system D3 of abnormal values of the attributes. Additionally, the ex-
[          ]
Puppe, 1998 . The system is in routine use in the DRK- pert suggested to group sets of values into disjunctive value
                 ¨
hospital in Berlin/Kopenick and documents an average of sets deﬁned by abnormality groups, e.g., grouping the values
about 300 cases per month. These are detailed descriptions possible and probable for some attributes. Furthermore, or-
of ﬁndings of the examination(s), together with the inferred dinality information was applied to construct meta values of
diagnoses (binary attributes). The derived diagnoses are usu- ordinal attributes like age or liver size.
ally correct as shown in a medical evaluation (c.f. [Huettig
         ]                                             Target Variable   Def. Pop. Subgroup Description
et al., 2004 ), resulting in a high-quality case base with de- Aorta-sclerosis = calciﬁed 1418 Pancreas Disease={probable;possible}
tailed case descriptions. The applied SONOCONSULT case Aorta-sclerosis = calciﬁed 75 Pancreas Disease={probable;possible}
base contains 4358 cases. The domain ontology contains 427                       AND Ascites = present
basic attributes with about 5 symbolic values on average, 133
symptom interpretations, which are rule-based abstractions    Table 2: Example: Missing Value Problem
of the basic attributes, and 221 diagnoses. This indicates the Further investigation showed that missing values play a
potentially huge search space for subgroup discovery. central role in the discovery process. Sometimes the deﬁned
  Subgroup   discovery was   performed   using  the   population signiﬁcantly decreased, when adding a selection
[VIKAMINE, 2005]  (Visual, Interactive and Knowledge- expression to a subgroup description, compared to the parent
Intensive Analysis and Mining  Environment) system,   subgroup. An example is given in Table 2; the deﬁned popu-
developed at the Department of Computer Science VI of the lation is indicated in the second column. In this example, the
University of Wurzburg.¨ We used beam search with a beam attribute ascites has many missing values. This problem was
size of 10 as the search strategy, and the quality function solved by adapting the derived attributes to indicate when a
qRG as deﬁned in Section 2.1. The discovered subgroups missing value corresponds to the value ”disease not present”.
were evaluated by domain specialists according to (clinical) Then, the ﬁnal set of interesting subgroups was obtained.
novelty, interestingness, and actionability aspects.    Figure 2 shows exemplary discovered subgroups concern-
  First, we performed subgroup discovery only using basic ing the target variable gallstones, that were considered as in-
attributes and general background knowledge. We used at- teresting for clinical practice (lines 1-6). All these subgroups
tribute weights for feature subset selection. The subgroup dis- were at least signiﬁcant at the 10−6 level. The individual sub-
covery algorithm presented many signiﬁcant subgroups, that groups are shown in the rows of the table. Subgroup parame-
supported the validity of the subgroup discovery techniques. ters given in the columns are: (Subgroup) Size, TP (true pos-
However the results at this stage were not really novel, since itives), FP (false positives), Pop. (deﬁned population size),
they indicated mostly already known dependencies, e.g., the RG (relative gain) and the value of the binomial quality func-
relation between relative body weight and body-mass index. tion qBT (Bin. QF), c.f., Section 2.1. The domain specialists