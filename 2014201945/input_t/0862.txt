                          Sensitivity Analysis in Markov Networks

                                    Hei Chan and Adnan Darwiche
                                     Computer Science Department
                                 University of California, Los Angeles
                                        Los Angeles, CA 90095
                                      {hei,darwiche}@cs.ucla.edu

                    Abstract                          in a Markov network to represent symmetrical probabilistic
                                                      dependencies between variables.
    This paper explores the topic of sensitivity analy- For the quantitative part, the parameters in a Bayesian net-
    sis in Markov networks, by tackling questions sim- work are speciﬁed in conditional probability tables (CPTs)
    ilar to those arising in the context of Bayesian net- of the variables, where each CPT consists of the conditional
    works: the tuning of parameters to satisfy query  probability distributions of a variable given instantiations of
    constraints, and the bounding of query changes    its parents, which are the variables that directly inﬂuence this
    when perturbing network parameters. Even though   variable. Because these parameters are conditional probabili-
    the distribution induced by a Markov network      ties, they are more intuitive, but have to obey certain proper-
    corresponds to ratios of multi-linear functions,  ties. For example, the probabilities in each conditional distri-
    whereas the distribution induced by a Bayesian net- bution must be normalized and sum to 1. On the other hand,
    work corresponds to multi-linear functions, the re- the parameters in a Markov network are given in potentials,
    sults we obtain for Markov networks are as effec- deﬁned over instantiations of cliques, which are maximal sets
    tive computationally as those obtained for Bayesian of variables such that every pair of variables in a clique are
    networks. This similarity is due to the fact that con- connected by an edge. These parameters do not need to be
    ditional probabilities have the same functional form normalized and can be changed more freely.
    in both Bayesian and Markov networks, which         The topic of sensitivity analysis is concerned with under-
    turns out to be the more inﬂuential factor. The ma- standing and characterizing the relationship between the lo-
    jor difference we found, however, is in how changes cal parameters quantifying a network and the global queries
    in parameter values should be quantiﬁed, as such  computed based on the network. Sensitivity analysis has
    parameters are interpreted differently in Bayesian been investigated quite comprehensively in Bayesian net-
    networks and Markov networks.                     works [Laskey, 1995; Castillo et al., 1997; Jensen, 1999;
                                                      Kjærulff and van der Gaag, 2000; Chan and Darwiche, 2002;
                                                      2004; 2005]. Earlier work on the subject has observed that
1  Introduction                                       the distribution induced by a Bayesian network corresponds
In the domain of uncertainty reasoning, graphical models are to multi-linear functions, providing effective computational
used to embed and represent probabilistic dependencies be- methods for computing ∂P r(e)/∂θx|u: the partial derivative
tween random variables. There are two major types of graph- of a joint probability with respect to a network parameter.
ical models: Bayesian networks [Pearl, 1988; Jensen, 2001] These earlier results were recently pursued further, providing
and Markov networks [Pearl, 1988]. In both models, there effective methods for solving the following problems:
are two components, a qualitative part and a quantitative part.
                                                        • What is the necessary parameter change we need to ap-
In the qualitative part, a graph is used to represent the interac-
                                                          ply such that a given query constraint is satisﬁed? For
tions between variables, such that variables with direct inter-
                                                          example, we may want some query value P r(z | e)
actions are connected by edges, and information of indepen-
                                                          to be at least p by changing network parameters. Efﬁ-
dence relationships between variables can be inferred from
                                                          cient solutions were given to this problem for computing
the network structure. In the quantitative part, a set of pa-
                                                          minimum changes for single parameters [Chan and Dar-
rameters are speciﬁed to quantify the strengths of inﬂuences
                                                          wiche, 2002], and multiple parameters in a single CPT
between related variables. The joint probability distribution
                                                          [Chan and Darwiche, 2004].
can then be induced from the two components.
  Bayesian networks and Markov networks differ in both the • What is the bound on the change in some query value
qualitative and quantitative parts of the models. For the qual- if we apply an arbitrary parameter change? Here, we
itative part, directed edges are used in a Bayesian network to are interested in ﬁnding a general bound for any query
represent inﬂuences from one variable to another, and no cy- and any parameter of any network. It has been shown
cles are allowed in the graph, while undirected edges are used that the log-odds change in any conditional query in a                                                                  
    Bayesian network is bounded by the log-odds change in                      A1 
    any single parameter [Chan and Darwiche, 2002].
  • What is the bound on the difference between some query
    value induced by two networks that have the same struc-           B1               B2 
    ture but different parameter values? The solution to this
    problem is based on a newly proposed distance measure
    [Chan and Darwiche, 2005], which allows one to bound                       A2 
    the difference between the query values under two dis-                                     
    tributions. Based on this distance measure, and given Figure 1: A sample Markov network structure in terms of an
    two Bayesian networks that differ by only a single CPT, undirected graph G.
    the global distance measure between the distributions in-
    duced by the networks can be computed from the local
    distance measure between the CPTs, thereby allowing to the deﬁnition and parameterization of Markov networks.
    one to provide a bound on the difference between the Section 3 presents a procedure which tunes parameters in a
    query values. Moreover, if we are given multiple CPTs Markov network in order to satisfy a query constraint. Sec-
    that do not intersect with each other, the global distance tion 4 introduces a distance measure that can be used to bound
    measure can still be computed as the sum of the local query change between distributions induced by two Markov
    distance measures between the individual CPTs.    networks. Section 5 concludes the paper.
  In this paper, we address these key questions of sensitiv-
ity analysis but with respect to Markov networks. The main 2 Markov networks
question of interest is the extent to which these promising A Markov network M = (G, Θ) consists of two parts: the
results hold in Markov networks as well. There is indeed a network structure in terms of an undirected graph G, and the
key difference between Bayesian networks and Markov net- parameterization Θ. Each node in the undirected graph G
works which appears to suggest a lack of parallels in this represents a random variable, and two variables are connected
case: whereas the joint distribution induced by a Bayesian by an edge if there exists a direct interaction between them.
network corresponds to multi-linear functions, the joint dis- The absence of an edge between two variables means any po-
tribution induced by a Markov network corresponds to ratios tential interaction between them is indirect and conditional
of multi-linear functions. As it turns out, however, the con- upon other variables.
ditional probability function has the same functional form in
                                                        As an example, consider four individuals, A1, A2, B1, B2,
both Bayesian and Markov networks, as ratios of multi-linear and we wish to represent the possible transmission of a con-
functions. This similarity turns out to be the key factor here, tagious disease among them. A network structure which con-
allowing us to derive similarly effective results for Markov sists of these variables is shown in Figure 1. Each pair of vari-
networks. This is greatly beneﬁcial because we can answer
                                                      ables {Ai, Bj} is connected by an edge, meaning these pairs
the previous three questions in the context of Markov net-
                                                      of individuals are in direct contact of each other. However, A1
works as well, with the same computational complexity. For
                                                      and A2 are not connected with an edge, meaning they do not
example, we can go through each parameter in a Markov net- interact directly with each other, although diseases can still
work, compute the minimum single parameter changes nec-
                                                      be transmitted between them indirectly through B1 or B2.
essary to enforce a query constraint, and ﬁnd the one that per- To quantify the edges in a Markov network, we ﬁrst deﬁne
turbs the network the least. Alternatively, we can change all cliques in the network structure. A clique C is a maximal set
parameters in a single clique table, and ﬁnd the change that of variables where each pair of variables in the set C is con-
minimizes network perturbation. Afterwards, we can com- nected by an edge. In the network structure in Figure 1, there
pute a bound on any query change using the distance measure are four cliques: {A , B }, {A , B }, {A , B }, {A , B }.
incurred by the parameter change.                                      1  1     1  2     2  1     2  2
                                                        For each clique C, we deﬁne a table ΘC that assigns a
  Our results, however, point to a main semantical difference
                                                      nonnegative number θc to each instantiation c of variables C,
between Bayesian networks and Markov networks, relating which measures the relative degree of compatibility associ-
to how one should quantify and measure parameter changes. ated with each instantiation c. The numbers given indicate the
That is, how should one quantify a parameter change from .3 level of compatibility between the values of the variables in
to .4? In a Bayesian network, parameters are interpreted as the clique, where direct interactions exist between every pair
conditional probabilities, and the measure which quantiﬁes of variables. For example, in our example network, we deﬁne
the change is the relative odds change in the parameter value.
                                                      the same clique table ΘA ,B shown in Table 1 for each clique
This means query values are much more sensitive to changes                 i j
                                                      {Ai, Bj}. For example, it can be viewed that both Ai and Bj
in extreme probability values, whether close to 0 or 1. On the not having the disease is four times more compatible than
other hand, in a Markov network, parameters are interpreted                                           1
                                                      both Ai and Bj having the disease, since θ ¯ = 4θa ,b .
as compatibility ratios, and the measure which quantiﬁes the                              a¯i,bj   i j
change is the relative change in the parameter value. This 1Parameters may be estimated on an ad hoc basis [Geman and
difference stems from how the parameters in the two models Geman, 1984] or by statistical models. It can be difﬁcult to assign
are interpreted and will be explained in more depth later. meanings and numbers to Markov network parameters intuitively
  This paper is structured as follows. Section 2 is dedicated [Pearl, 1988, pages 107–108].                  Ai  Bj  ΘAi,Bj                      CPTs, one for each variable X, which are conditional proba-
                   ai bj    1                         bilities in the form of θ = P r(x | u), where U are the par-
                       ¯                                                 x|u
                   ai bj    2                         ents of X. The joint distribution P rB induced by Bayesian
                   a¯i bj   3                         network B = (N, Θ) is:
                       ¯
                   a¯i bj   4                                                     Y
                                                                        B    def
                                                                     P r (x) =        θx|u.
                                                                                 x,u∼x
Table 1: The clique table of {Ai, Bj} of the Markov network
whose structure is shown in Figure 1.                 The joint probability P rB(e) can be expressed as:
                                                                              X   Y
                                                                       B
                                                                    P r (e) =         θx|u,
2.1  Joint and conditional probabilities induced by                           x∼e x,u∼x
     Markov networks                                  and any conditional probability P rB(z | e) as:
                                                                                 P      Q
We now proceed to ﬁnd the distribution induced by a Markov              B
                                                                     P r (z, e)                θx|u
network. If X is the set of all variables in the Markov network B                 Px∼z,eQ x,u∼x
                                                         P r (z | e) =   B     =                   .  (4)
M  = (G, Θ), the joint potential ψ over X induced by M is             P r (e)       x∼e   x,u∼x θx|u
deﬁned as:                 Y                          We can easily see the similarities between the expressions of
                       def                               M              B
                  ψ(x) =      θc.               (1)   P r  (z | e) and P r (z | e) in Equations 3 and 4 lie in
                           c∼x                        the fact that both can be expressed as ratios of two multi-

That is, ψ(x) is the product of parameters θc in each clique linear functions of the network parameters. This is different
C, such that instantiation c is consistent with x. The joint dis- for joint probabilties, where in a Bayesian network they are
tribution P rM induced by Markov network M is then deﬁned multi-linear functions of the network parameters, while in a
as its normalized joint potential:                    Markov network they are ratios of multi-linear functions of
                                                      the network parameters,P since the normalizing constant can
                  def   ψ(x)
          P rM (x) =  P        = Kψ(x),               be expressed as K = 1/ x ψ(x) = 1/φ(true). This simi-
                        x ψ(x)                        larity in terms of conditional probabilities will be the basis of
             P                                        our results in the following section.
where K = 1/   x ψ(x) is the normalizing constant. From
this equation, we can easily verify that the speciﬁc parameter 3 Tuning of parameters in Markov networks
values in a clique are not important, but their ratios are. This
is a major departure from Bayesian networks, where speciﬁc We now answer the following question in the context of
parameter values in CPTs are important.               Markov networks: what is the necessary change we can ap-
  Given the network structure in Figure 1 with the parame- ply to certain parameter(s) such that a query constraint is sat-
terization in Table 1, we can compute the joint probability isﬁed? For example, if P r is the probability distribution in-
of any full instantiation of variables induced by our example duced by a Markov network, we may want to satisfy the query
                                               ¯      constraint P r(z | e) ≥ k, for some k ∈ [0, 1].2
network. For example, the joint probability of a1, a¯2, b1, b2 is
                                                        Notice that given all the parameters θc in the clique C,
equal to Kθa1,b1 θa1,b¯2 θa¯2,b1 θa¯2,b¯2 = K · 1 · 2 · 3 · 4, where K
is the normalizing constant.                          φ(e) can be expressed as a multi-linear function of these pa-
  For an instantiation e of variables E ⊆ X, we can express rameters, as shown in Equation 2. Since φ(e) is linear in each
the joint probability P rM (e) as:                    parameter θc, and no two parameters in the same clique are
              X            X                          multiplied together, if we apply a change of ∆θc to each pa-
      M             M
    P r (e) =    P r  (x) =    Kψ(x) =  Kφ(e),        rameter θc in the clique C, the change in φ(e) is:
              x∼e          x∼e                                               X   ∂φ(e)
                                                                     ∆φ(e) =          ∆θ  .
where the function φ(e) is deﬁned as the sum of the potentials                    ∂θ     c
                                                                              c     c
of x which are consistent with e:
                                                      To ensure the query constraint P r(z | e) ≥ k, from Equa-
                def X         X   Y
           φ(e) =      ψ(x) =        θc,        (2)   tion 3, this is equivalent to ensuring the inequality φ(z, e) ≥
                   x∼e        x∼e c∼x                 k · φ(e). If the current φ values of z, e and e are ϕ(z, e) and
                                                      ϕ(e) respectively, this inequality becomes:
and any conditional probability P rM (z | e) as:
                                                              ϕ(z, e) + ∆φ(z, e) ≥ k(ϕ(e) + ∆φ(e)),
                  M
     M         P r  (z, e)  Kφ(z, e)   φ(z, e)        or:
  P r  (z | e) =   M     =          =        .  (3)                              Ã                    !
                P r  (e)     Kφ(e)      φ(e)                  X   ∂φ(z, e)                X  ∂φ(e)
                                                      ϕ(z, e) +          ∆θ   ≥ k  ϕ(e) +          ∆θ   .
From Equation 2, we can see that both φ(z, e) and φ(e) are          ∂θ      c                 ∂θ     c
                                                               c      c                    c    c
sums of products of the network parameters. Therefore, the
conditional probability P rM (z | e) induced by a Markov net- Rearranging the terms, we get the following theorem and
work can be expressed as the ratio of two multi-linear func- corollary.
tions of the network parameters.                         2We can easily expand our results in this section into other forms
  As a comparison, the parameterization Θ of a directed of constraints, such as P r(z | e) ≤ k, P r(z1 | e)−P r(z2 | e) ≥ k,
acyclic graph N for a Bayesian network consists of a set of or P r(z1 | e)/P r(z2 | e) ≥ k.Theorem 1 To ensure the probability distribution P r in- 4 Bounding belief change between Markov
duced by a Markov network satisﬁes the query constraint   networks using a distance measure
P r(z | e) ≥ k, we must change each parameter θ in the
                                            c         We now  answer the following question in the context of
clique C by ∆θc such that:
        X                                             Markov networks: what is the bound on the difference be-
            α(θc)∆θc ≥ −(ϕ(z, e) − k · ϕ(e)),   (5)   tween some query value induced by two networks that have
         c                                            the same structure but different parameter values? We will
                                                      answer it by using a previously proposed distance measure.
where ϕ(z, e) and ϕ(e) are the current φ values of z, e and Let P r and P r0 be two probability distributions over
e respectively, and:                                  the same set of variables X. We use a distance measure
                                                               0
                    ∂φ(z, e)    ∂φ(e)                 D(P r, P r ) deﬁned as follows [Chan and Darwiche, 2005]:
            α(θ  ) =        − k      .          (6)
                c                                                                 0              0
                      ∂θc        ∂θc                                 def       P r (x)        P r (x)
                                                          D(P r, P r0) = ln max       − ln min       ,
Corollary 1 If instead of changing all parameters in the                    x   P r(x)      x  P r(x)
clique C, we are only allowed to change a single parameter
                                                                            def            def  3
θc by ∆θc, the solution of Theorem 1 becomes:         where we will deﬁne 0/0 = 1 and ∞/∞  =  1.
                                                        The signiﬁcance of this distance measure is that if the dis-
          α(θc)∆θc ≥ −(ϕ(z, e) − k · ϕ(e)),     (7)   tance measure is D(P r, P r0) = d, the change in the proba-
                                                      bility of any conditional query z | e is bounded by:
which returns a solution interval of possible ∆θc.
  Therefore, to solve for ∆θ in Inequality 7 for all parame-                O0(z | e)
                        c                                             e−d ≤         ≤  ed,
ters in the Markov network, we need to compute the origi-                   O(z | e)
nal values ϕ(z, e) and ϕ(e), which should already be known
                                                              0
when computing the original probability of z | e, and the par- where O (z | e) and O(z | e) are the odds of z | e under
                                                      distributions P r0 and P r respectively.4 Given p = P r0(z |
tial derivatives ∂φ(z, e)/∂θc and ∂φ(e)/∂θc, to ﬁnd α(θc) in
                                                      e), this result can also be expressed in terms of probabilities:
Equation 6 for all parameters θc. To do this, we can use a pro-
cedure in time complexity O(n exp(w)) where n is the num-      p · e−d                     p · ed
ber of variables and w is the treewidth of the Markov network,                0
                                                              −d         ≤ P r (z | e) ≤  d        .  (8)
similar to the one proposed to compute partial derivatives in p(e − 1) + 1             p(e − 1) + 1
a Bayesian network [Darwiche, 2003]. This can greatly help The advantage of this distance measure is that it can be
users debug their network when they are faced with query re- computed using local information for Bayesian networks.
                                                                                   0
sults that do not match their expectations.           Given distributions P rB and P rB induced by two Bayesian
  We now use our example network to illustrate this proce- networks B and B0 that differ by only the CPT of a single
dure. The probability distribution P r induced by the cur- variable X, if P r(u) > 0 for every u of parents U, the dis-
rent parameterization gives us the conditional query value                            0
                                                      tance measure between P rB and P rB can be computed as:
P r(a ¯2 | a1) = .789. Assume that we would like to change
a single parameter in the clique {A , B } to ensure the con-    B    B0                0
                             2   1                        D(P r  , P r ) =   D(ΘX|U,  Θ    )
straint P r(a ¯ | a ) ≥ .9. We need to compute the α values                            X|U
          2   1                                                                      0           0
for each parameter in the clique using Equation 6, and then                         θx|u        θx|u
                                                                         =   ln max     − ln min    . (9)
use Inequality 7 to solve for the minimal ∆θc. The solutions                    x,u θx|u     x,u θx|u
are:
                                                      This is useful because we can compute the bound on any
               ∆θa2,b1  ≤   −2.93;                    query change using Inequality 8 by computing the local dis-
                                                      tance between the CPTs Θ   and Θ0   in B and B0. For
               ∆θa2,b¯1 ≤   −1.467;                                          X|U      X|U
                                                      example, if X is binary, and we only change a single parame-
               ∆θa¯2,b1 ≥   12;
                                                      ter θx|u while applying a complementary change on θx¯|u, the
               ∆θ    ¯  ≥   8.8.
                  a¯2,b1                              bound on the change in query z | e is given by:
However, notice that since the parameter values have to
                                                                            B0            0
be non-negative, the solution for ∆θ is impossible to            O(θx|u)   O  (z | e)  O(θx|u)
                                a2,b1                                   ≤            ≤        ,      (10)
achieve. Therefore, no possible single parameter change on          0        B
                                                                 O(θx|u)   O  (z | e)  O(θx|u)
θa2,b1 is possible to ensure our query constraint. However,
                                                      where O(θ0  ) and O(θ  ) are the odds of parameters θ0
we can decrease the parameter θa2,b¯1 from 2 to .533 to ensure x|u        x|u                         x|u
our query constraint.                                 and θx|u respectively. Intuitively this means the relative
  If we are interested in changing all the parameters in the change in the query odds is bounded by the relative change
clique {A2, B1} to satisfy our query constraint, we need to in the parameter odds.
ﬁnd a solution that satisﬁes Inequality 5. As a consequence,
we are now faced with multiple solutions of changing the pa- 3This measure is a distance measure because it satisﬁes positive-
rameters, and we want to commit to one which disturbs the ness, symmetry and the triangle inequality.
                                                         4
network the least. We will discuss this in the next section us- The odds of z | e under distribution P r is deﬁned as: O(z |
                                                         def
ing a distance measure which measures network perturbation. e) = P r(z | e)/(1 − P r(z | e)).                                                                      δ
  We can get a similar result for Markov networks, where            0.2
the distance measure between distributions induced by two
Markov networks that differ by only a single clique table can       0.15
be computed by the distance measure between the tables.             0.1
                                                                    0.05
                              M       M 0
Theorem 2 Given distributions P r and P r induced by                                       p
two Markov networks M and M 0 which differ by only the                   0.2 0.4 0.6 0.8  1
                                                                   -0.05
parameters in a single clique C, such that the clique tables
            0                                                       -0.1
are ΘC and ΘC respectively, the distance measure between
             0
P rM and P rM is given by:                                         -0.15
                                                                    -0.2
          M     M 0              0
     D(P r  , P r )  =   D(ΘC, ΘC)
                               θ0         θ0          Figure 2: The amount of parameter change δ that would guar-
                     =   ln max c − ln min c , (11)
                            c  θ       c  θ           antee the query P r(z | e) = .75 to stay within the interval
                                c          c          [.667, .818], as a function of the current Bayesian network
                           5
if ∂ψ(x)/∂θc 6= 0 for all c ∼ x.                      parameter value p.

Proof  Given instantiation c such that c ∼ x, the joint po- and the change in query z | e is bounded by:
tential ψ of x is linear in the parameter θc, and the ratio of
 0                       0                                                  M 0         0
ψ (x) and ψ(x) induced by M and M respectively is:                   θc   O   (z | e)  θc
                                                                      0 ≤   M        ≤   .           (12)
                    ψ0(x)   θ0                                       θc    O  (z | e)  θc
                         =   c ,
                    ψ(x)    θc                        This means for Markov networks, the relative change in
                                                      query odds is bounded by the relative change in the parame-
if ∂ψ(x)/∂θc 6= 0. We have:                           ter itself, not the relative change in the parameter odds as for
                                                      Bayesian networks. This is an important distinction between
              M 0        0 0       0 0
            P r  (x)   K ψ (x)   K  θc                Markov networks and Bayesian networks.
               M    =          =      .
            P r (x)    Kψ(x)      Kθc                   As an example, suppose we have a network and we want
                                                      to ensure the robustness of the query P r(z | e) after we ap-
Note that since the parameters have changed, the normalizing
                0                   0                 ply a parameter change. Assume that we deﬁne robustness
constants K and K for networks M and M respectively are as the relative change in any query odds to be less than 1.5.
different. Therefore, the distance measure between P rM and
  M 0                                                 For example, if currently P r(z | e) = .75, the new query
P r  is given by:                                     value must stay in the interval [.667, .818] after the parameter
                            M 0              M 0      change. We may ask, how much change can we apply to a
            0             P r  (x)         P r  (x)
     M    M                                           parameter if we want to ensure robustness? The answers for
D(P r  , P r )  =  ln max    M    −  ln min   M
                       x  P r  (x)      x  P r (x)    Bayesian networks and Markov networks are different due to
                          K0θ0         K0θ0           our previous results, as we will show next.
                =  ln max    c − ln min    c
                       c  Kθc       c  Kθc              For a Bayesian network, the amount of permissible change
                          θ0         θ0               is determined by Inequality 10, and is plotted in Figure 2. We
                =  ln max  c − ln min c               can see that the amount of permissible change is small when
                       c  θc      c  θc               the parameters have extreme values close to 0 or 1, because
                           0
                =  D(ΘC,  ΘC),                        the relative odds change is large when even a very small ab-
                                                      solute change is applied.
if ∂ψ(x)/∂θ 6= 0 for all c ∼ x.
          c                                             On the other hand, for a Markov network, the amount of
  Therefore, the global distance measure between the distrib- permissible change is determined by Inequality 12, and is
utions induced is equal to the local distance measure between plotted in Figure 3. We can see that the amount of permis-
the individual clique tables. This is useful for computing the sible change is proportional to the parameter values, because
bound on query change after changing the parameters in a relative change is used instead of relative odds change.
clique table. For example, what is the bound on the change Therefore, for a Bayesian network, the sensitivity of the
in some query value if we apply an arbitrary change on the network with respect to a parameter is largest for extreme
single parameter θc? The distance measure in this case is: values close to 0 or 1, and becomes smaller as the parame-
                              ¯    ¯
                              ¯   0 ¯                 ter approaches .5, while for a Markov network, the sensitivity
                          0      θc
             D(P rM , P rM ) = ¯ln ¯ ,                of the network with respect to a parameter is proportional to
                              ¯  θ ¯
                                  c                   its value, and increases as it grows larger.
  5This condition is satisﬁed when the network parameters are all The distance measure is useful in many aspects of sensi-
strictly positive. However, this is a sufﬁcient condition, not a nec- tivity analysis. For example, given the possible single para-
essary condition. The necessary condition is there exists some x meter changes in our example in the previous section, we can
such that ∂ψ(x)/∂θc 6= 0 for all c. This means that changing any choose the one which perturbs the network the least accord-
parameter θc will have some impact on the joint potential ψ. ing to the distance measure. In this case, the most preferred