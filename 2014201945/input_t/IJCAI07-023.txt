               A Theoretical Framework for Learning Bayesian Networks
                           with Parameter Inequality Constraints

      Radu Stefan Niculescu                Tom M. Mitchell                    R. Bharat Rao
     Siemens Medical Solutions        Carnegie Mellon University        Siemens Medical Solutions
         Malvern PA, USA                  Pittsburgh PA, USA                 Malvern PA, USA
   stefan.niculescu@siemens.com        tom.mitchell@cs.cmu.edu           bharat.rao@siemens.com

                    Abstract                            When learning Bayesian Networks, the correctness of the
                                                      learned network of course depends on the amount of train-
    The task of learning models for many real-world   ing data available. When training data is scarce, it is useful to
    problems requires incorporating domain knowl-     employ various forms of prior knowledge about the domain to
    edge into learning algorithms, to enable accurate improve the accuracy of learned models. For example, a do-
    learning from a realistic volume of training data. main expert might provide prior knowledge specifying condi-
    Domain knowledge can come in many forms. For      tional independencies among variables, constraining or even
    example, expert knowledge about the relevance of  fully specifying the network structure of the Bayesian Net-
    variables relative to a certain problem can help per- work. In addition to helping specify the network structure,
    form better feature selection. Domain knowledge   the domain expert might also provide prior knowledge about
    about the conditional independence relationships  the values of certain parameters in the conditional probabil-
    among variables can help learning of the Bayesian ity tables (CPTs) of the network, or knowledge in the form
    Network structure.                                of prior distributions over these parameters. While previous
    This paper considers a different type of domain   research has examined a number of approaches to represent-
    knowledge for constraining parameter estimates    ing and utilizing prior knowledge about Bayesian Network
    when learning Bayesian Networks. In particular,   parameters, the type of prior knowledge that can be utilized
    we consider domain knowledge that comes in the    by current learning methods remains limited, and is insufﬁ-
    form of inequality constraints among subsets of pa- cient to capture many types of knowledge that may be readily
    rameters in a Bayesian Network with known struc-  available from experts.
    ture. These parameter constraints are incorporated  The main contribution of our paper consists of deriving
    into learning procedures for Bayesian Networks, by closed form Maximum Likelihood estimators for the param-
    formulating this task as a constrained optimization eters in a Bayesian Network, in the setting that expert do-
    problem. The main contribution of this paper is the main knowledge is available in the form of parameter inequal-
    derivation of closed form Maximum Likelihood pa-  ity constraints, which current methods can not accommodate.
    rameter estimators in the above setting.          With our estimators comes a theorem that describes the per-
                                                      formance in the case when the domain knowledge represented
                                                      by the inequality constraints might not be entirely accurate.
1  Introduction                                         The next section of the paper describes related research
Probabilistic models have become increasingly popular in on constraining parameter estimates for Bayesian Networks.
the last decade because of their ability to capture non- Section 3 presents the task of parameter estimation in the
deterministic relationships among variables describing many presence of general parameter constraints and formulates it
real world domains. Among these models, Bayesian Net- as a constrained optimization problem. Section 4 details the
works [Heckerman, 1999] have received signiﬁcant attention main contribution of this paper: closed form solutions for pa-
because of their ability to compactly encode conditional in- rameter estimates for several classes of parameter inequality
dependence assumptions over random variables and because constraints. Some formal guarantees about our estimators are
of the development of effective algorithms for inference and discussed in section 5. We conclude with a brief summary of
learning based on these representations. A Bayesian Network this research along with several directions for future work.
consists of two components: a structure, which encodes the
assumption that a variable is conditionally independent of its 2 Related Work
non-descendants in the network, given the value of its parents,
and a set of parameters, which describe how each variable The main methods to represent relationships among param-
relates probabilistically to its parents. A Bayesian Network eters of a Bayesian Network fall into two main categories:
encodes a unique joint probability distribution, which can be Dirichlet Priors and their variants (including smoothing tech-
easily computed using the chain rule.                 niques) and Parameter Sharing of several kinds.

                                                IJCAI-07
                                                   155  In [Geiger and Heckerman, 1997], it is shown that Dirich- act estimators. Further, [Altendorf et al., 2005] assumes the
let Priors are the only possible priors for discrete Bayesian values of the variables can be totally ordered and [Feelders
Networks, provided certain assumptions hold. One can think and van der Gaag, 2006] assumes all variables are binary.
of a Dirichlet Prior as an expert’s guess for the parameters Our framework makes none of these assumptions. In the next
in a discrete Bayesian Network, allowing room for some section we will place parameter learning with inequality con-
variance around the guess. One of the main problems with straints in a general constrained optimization framework and
Dirichlet Priors and related models is that it is impossible we will show how closed form learning of the parameters of
to represent even simple equality constraints between pa- Bayesian Networks can be performed when expert knowledge
rameters (for example the constraint: θ111 = θ121 where is available in the form of either of two types of parameter in-
θijk = P (Xi =  xij |Parents(Xi)=paik)) without us-   equality constraints.
ing priors on the hyperparameters of the Dirichelet Prior, in
which case the marginal likelihood can no longer be com- 3 Problem Deﬁnition and Approach
puted in closed form, and expensive approximate methods are
required to perform parameter estimation. A second problem Here we deﬁne the problem and suggest a general optimiza-
is that it is often beyond the expert’s ability to specify a full tion based approach to solve it. This approach has serious
Dirichlet Prior over the parameters of a Bayesian Network. limitations when the constraints are arbitrary. However, it
  A widely used form of parameter constraints employed constitutes the basis for computing the Maximum Likelihood
by Bayesian Networks is Parameter Sharing. Models us- estimators for the classes of inequality constraints described
ing different types of Parameter Sharing include: Dy- in section 4. We begin by describing the problem along with
namic Bayesian Networks [Murphy, 2002] and their spe- several assumptions.
cial case Hidden Markov Models [Rabiner, 1989], Module
Networks [Segal et al., 2003], Context Speciﬁc Indepen- 3.1 The Problem
dence models [Boutilier et al., 1996] such as Bayesian Multi- Our task here is to perform parameter estimation in a
networks, Recursive Multinetworks and Dynamic Multinet- Bayesian Network where the structure is known in advance.
works [Geiger and Heckerman, 1996; Pena et al., 2002; To accomplish this task, we assume a dataset of examples
Bilmes, 2000], Probabilistic Relational Models [Friedman et is available. In addition, a set of parameter equality and/or
al., 1999], Object Oriented Bayes Nets [Koller and Pfeffer, inequality constraints is provided by a domain expert. The
1997], Kalman Filters [Welch and Bishop, 1995] and Bilinear equality constraints are of the form gi(θ)=0for 1 ≤ i ≤ m
Models [Tenenbaum and Freeman, 2000]. Parameter Sharing and the inequality constraints are of the form hj(θ) ≤ 0 for
methods constrain parameters to share the same value, but 1 ≤ j ≤ k,whereθ represents the set of parameters of the
do not capture more complicated constraints among parame- Bayesian Network.
ters such as inequality constraints or constraints on sums of Initially we will assume the domain knowledge provided
parameter values. The above methods are restricted to shar- by the expert is correct. Later, we investigate what happens if
ing parameters at either the level of sharing a conditional this knowledge is not completely accurate. Next we enumer-
probability table (CPT) (Module Networks, HMMs), at the ate several assumptions that must be satisﬁed for our meth-
level of sharing a conditional probability distribution within ods to work. These are similar to common assumptions made
a single CPT (Context Speciﬁc Independence), at the level when learning parameters in standard Bayesian Networks.
of sharing a state-to-state transition matrix (Kalman Filters) First, we assume that the examples in the training dataset
or at the level of sharing a style matrix (Bilinear Models). are drawn independently from the underlying distribution. In
None of the above models allow sharing at the level of gran- other words, examples are conditionally independent given
ularity of individual parameters. [Niculescu et al., 2005] in- the parameters of the Bayesian Network. Second, we assume
troduces a parameter equality constraint framework that de- that all the variables in the Bayesian Network can take on at
scribes many models that use parameter sharing: Module least two different values. This is a safe assumption since
Networks, Context Speciﬁc Independence models, HMMs   there is no uncertainty in a random variable with only one
and Dynamic Bayesian Networks. Within this framework, possible value. Any such variables in our Bayesian Network
it is showed how efﬁcient parameter learning is performed can be deleted, along with all arcs into and out of the nodes
from both a frequentist and bayesian point of view, from both corresponding to those variables. Third, when computing pa-
observable and partially observable data.             rameter estimators, we additionally assume that all observed
  All the models described so far can only take advantage of counts corresponding to parameters in the Bayesian Network
certain types of parameter equality constraints. Only recently, are strictly positive. We enforce this condition in order to
[Altendorf et al., 2005; Feelders and van der Gaag, 2006] avoid potential divisions by zero, which may impact infer-
study the feasibility of incorporating simple inequality con- ence negatively. In the real world it is expected there will be
straints in the learning of parameters of Bayesian Networks. observed counts which are zero. This problem can be solved
The constraints analyzed in these papers are somehow restric- by using priors on parameters, that essentially have the ef-
tive, in the sense that each constraint must involve all parame- fect of adding a positive quantity to the observed counts and
ters in a conditional probability table, whereas our framework essentially create strictly positive virtual counts.
allows for constraints at individual distribution level of gran- Finally, the functions g1,...,gm and h1,...,hk must be
ularity. Additionally, in [Altendorf et al., 2005], the authors twice differentiable, with continuous second derivatives. This
employ an approximation algorithm, whereas we derive ex- assumption justiﬁes the formulation of our problem as a con-

                                                IJCAI-07
                                                   156            strained maximization problem that can be solved using stan- of adverbs is no greater than the aggregate probability mass
            dard optimization methods.                            of the verbs in a given language. Formally, in this type of
                                                                  domain knowledge, the parameters of a conditional probabil-
            3.2  A General Approach                               ity distribution, denoted by θ1,...,θn, can be partitioned into
                                                                       s       s
                                                                  θ = ∪    Ak ∪   Bk ∪C such that      θi ≤        θi
            In order to solve the problem described above, here we brieﬂy k=1  k=1                θi∈Ak       θi∈Bk
                                                                          ≤   ≤
            suggest an approach based on already existing optimization for all 1 k s. Let us denote by NAk the sum of the ob-
            techniques. The idea is to formulate our problem as a con- served counts corresponding to parameters in Ak. Similar

            strained maximization problem where the objective function deﬁnitions hold for NBk and NC .LetN be the sum of all
            is the data log-likelihood log P (D|θ) and the constraints are observed counts Ni corresponding to parameters θ.
            given by gi(θ)=0for  1  ≤ i ≤  m  and hj(θ) ≤ 0 for     An expert can potentially specify different such con-
            1 ≤  j ≤  k. It is easy to see that, applying the Karush- straints for several conditional probability distributions in the
            Kuhn-Tucker conditions theorem [Kuhn and Tucker, 1951], Bayesian Network. Because of the decomposability of log-
            the maximum must satisfy a system with the same number of likelihood, the problem of computing the Maximum Like-
            equations as variables. To solve this system, one can use any lihood parameter estimators can be decomposed in a set of
            of several already existing methods (for example the Newton- independent optimization subproblems, one for each condi-
            Raphson method [Press et al., 1993]).                 tional probability distribution in the network. We have the
              It is well known that ﬁnding a solution for the system given following theorem:
            by the KKT conditions is not enough to determine the opti- Theorem 4.1. If all Ni are strictly positive, the Maximum
            mum point, but fortunately the objective function is concave Likelihood Estimators of parameters θ are given by:
            and most of the constraints we have encountered in real life
                                                                               N  +N
            are linear equalities or inequalities. Therefore several well ˆ Ni · Ak  Bk      ∈            ≥
                                                                    a) θi = N    2·N    if θi  Ak and NAk   NBk
                                                                                   Ak
            known sufﬁciency criteria can guarantee optimality.                N  +N
                                                                       ˆ   Ni · Ak   Bk      ∈            ≥
                                                                    b) θi = N    2·N    if θi  Bk and NAk   NBk
              Unfortunately, the above methods have serious shortcom-              Bk
            ings in the general case. With a large number of parameters in Ni
                                                                    c) θˆ =   if θ ∈ Ak ∪ Bk and NA  <NB
            the Bayesian Network, they can be extremely expensive be-  i   N     i                 k      k
                                                                       ˆ   Ni      ∈
            cause they involve potentially multiple runs of the Newton- d) θi = N if θi C
            Raphson method and each such run requires several expen- Proof. Finding Maximum Likelihood estimators is equiva-
            sive matrix inversions. Other methods for ﬁnding the solu-
                                                                  lent to maximizing l(θ)=    i Ni · log θi subject to the
            tions of a system of equations can be employed, but, as noted domain knowledge constraints, including the constraint that
            in [Press et al., 1993], all these methods have limitations in
                                                                  g(θ)=     i θi − 1=0. Since this problem contains in-
            the case when the constraints are arbitrary, non-linear func- equality constraints, we can attempt to solve it using Karush-
            tions. The worst case happens when there exists a constraint Kuhn-Tucker theorem. We introduce the Lagrange Multiplier
            that explicitly uses all parameters in the Bayesian Network.
                                                                  λ for g and μk for inequality constraint hk(θ)= θ ∈A θi−
              The above method should be regarded as a mere suggestion                                      i  k
                                                                          θi ≤ 0. The optimum θˆ can then be found among the
            and, because of its shortcomings, we believe it is not compu- θi∈Bk
            tationally feasible with arbitrary constraints. We mentioned it solutions of the system:
            here only to show how learning in the presence of parameter
                                                                    ⎧                      
            constraints can be formulated as a general constrained max- ⎪ ∇ ˆ −  ·∇    ˆ −       ·∇     ˆ
                                                                    ⎪   θ l(θ) λ    θ g(θ)   k μk   θ hk(θ)=0
            imization problem. This general approach also provides the ⎨⎪               ˆ
            starting point for ﬁnding closed form Maximum Likelihood                  g(θ)=0
                                                                                       ·   ˆ
            estimators given the particular classes of parameter inequal- ⎪         μk  hk(θ)=0
                                                                    ⎪
            ity constraints presented in the next section.          ⎩⎪                hk(θˆ) ≤ 0
                                                                                       μk ≥ 0
            4  Learning with Inequality Constraints                 From the ﬁrst equation we obtain:
            In this section we derive closed form Maximum Likelihood              ⎧
                                                                                       Ni
            estimators for the parameters in a discrete Bayesian Network          ⎨            ∈  k
                                                                                     λ+μk if θi  A
            with known structure when domain knowledge is provided as                  Ni
                                                                              θˆi =       if θi ∈ Bk
                                                                                  ⎩  λ−μk
            either of the two types of inequality constraints.                         Ni
                                                                                       λ  if θi ∈ C
                                                                                          N                   N
            4.1  Inequalities between Sums of Parameters                                    Ak                   Bk
                                                                    Therefore,       θˆi =     and        θˆi =     .
                                                                                θi∈Ak     λ+μk       θi∈Bk      λ−μk
            Brieﬂy, this type of Parameter Domain Knowledge states that Based on whether constraint k is tight or not we have:
            the sum of several parameters within one conditional prob-
                                                                                       NA     NB               NA
                                                                    •    k ˆ             k      k                k
            ability distribution is bounded by the sum of other parame- If h (θ)=0,then λ+μk = λ−μk . This implies λ+μk =
                                                                       N        N  +N                
            ters in the same distribution of the Bayesian Network. Intu- Bk      Ak   Bk
                                                                            =            and therefore          θˆi =
                                                                       λ−μk        2λ                   θi∈Ak∪Bk
            itively, one can think of this constraint in terms of the parts N +N
                                                                        Ak   Bk                       ·     −
            of speech of a language. Usually, an adverb comes along       λ    . In this case, we also have λ (NAk NBk )=
                                                                         ·                      ≥
            with a verb and therefore it is reasonable to assume that a lan- μk (NAk + NBk ).Sinceμk 0,wealsomusthave
                                                                           ≥
            guage expert can specify that the aggregate probability mass NAk NBk in order for constraint k to be tight.

                                                            IJCAI-07
                                                               157              • If hk(θˆ) < 0,thenμk =0and therefore we again have the optimum point. This algorithm starts with an empty set
                               N  +N
                                 Ak   Bk
                           θˆi =        . Inthiscasewealsohave    and at each step adds one of the ﬁnal tight constraints.
                  θi∈Ak∪Bk         λ
                        N  −N                                       Again, an expert can specify different sets of such con-
                   ˆ     Ak   Bk             ˆ
                hk(θ)=      λ    and since hk(θ) < 0,wemustalso   straints for different conditional probability distributions in
                have NAk <NBk  .                                  the network and, because of the decomposability of log-
              The above observations allow us to conclude that a con- likelihood, we can decompose the task of ﬁnding the Max-
                                        ≥
            straint is tight if and only if NAk NBk . Now, summing up imum Likelihood estimators into a set of independent opti-
            over all parameters in the conditional probability distribution mization subproblems:
            we get:                                               Theorem  4.2. Assume all observed counts Ni are strictly
                                   
                                                                 positive and also assume we know the set K = {k1,...,kl}
                              NC +    k(NAk + NBk )   N
                  1=     θˆi =                      =             of constraints that are tight at the point given by the Maxi-
                                        λ             λ
                       i                                          mum Likelihood estimators θˆ. Then, we have:

              This gives us: λ = N and therefore:                      ˆ        Ni
                                                                    a) θi = αk · N if θi ∈ Ak and k ∈ K
                                                                                Ak
                            ⎧                                          ˆ       −          · P   Ni          ∈
                                Ni                                  b) θi =(1      j∈K αj)        N   if θi   Ak  and
                            ⎨            ∈  k                                                 m∈K Am
                               N+μk if θi  A
                                Ni                                k ∈ K
                       θˆi =        if θi ∈ Bk
                            ⎩  N−μk
                                Ni
                                 N  if θi ∈ C                     Proof. We can approach the problem of ﬁnding the Maxi-
                                                                  mum Likelihood estimators in a similar fashion as in Theo-
              Assume now that NA  ≥  NB  . According to the obser-
                                k       k                         rem 4.1. The data log-likelihood is given by l(θ)= i Ni ·
            vations above, it means constraint k is tight and we have:
             N       N        N  +N                               log θi which we have to maximize with respect to the do-
              Ak       Bk      Ak   Bk
            N+μk  =  N−μk  =    2·N   . From this we immediately  main knowledge constraints, including the constraint that
                            N  +N                                             −
                  ˆ    Ni ·  Ak   Bk      ∈             ≥         g(θ)=    i θi 1=0. Again, we use Karush-Kuhn-Tucker
            derive: θi = N   2·N     if θi  Ak  and NAk   NBk
                                Ak                                theorem. We introduce the Lagrange Multiplier λ for g and
                    N   NA +NB
               ˆ     i ·  k    k      ∈            ≥               k                       k                −  k ≤
            and θi = N    2·N    if θi  Bk and NAk   NBk .        μ  for inequality constraint h (θ)= θ ∈Ak θi α   0.
                            Bk                                                                       i
              If NAk <NBk  , then, as discussed above, μk must be 0 The optimum θˆ can then be found among the solutions of the
                        ˆ    Ni      ∈    ∪
            and therefore θi = N if θi Ak   Bk and NAk  <NBk  .   system:
            Because the log-likelihood objective function is concave and
                                                                    ⎧                      
            because the constraints are linear inequalities, it follows that θˆ ⎪ ∇ ˆ − ·∇ ˆ −   ·∇     ˆ
                                                                    ⎪   θ l(θ) λ    θ g(θ)   k μk   θ hk(θ)=0
            is the set of Maximum Likelihood estimators. This concludes ⎨⎪              ˆ
            the proof of our theorem.                                                 g(θ)=0
                                                                    ⎪               μk · hk(θˆ)=0
                                                                    ⎪
            4.2  Upper Bounds on Sums of Parameters                 ⎩⎪                hk(θˆ) ≤ 0
                                                                                          ≥
            Here the domain expert provides upper bounds on the sum of                 μk   0
            several parameters within one conditional probability distri- From the ﬁrst equation we obtain:
            bution in the Bayesian Network. Consider the same language
            example described in the introduction of the previous subsec-
                                                                                 ˆ      Ni       ∈
            tion. Here the expert may state that the aggregate probability       θi =        if θi Ak
                                                                                      λ + μk
            of nouns is no greater than 0.4, the aggregate probability of                 N
                                                                                            Ak
            verbs is no greater than 0.4 and the aggregate probability of Therefore, θˆi =     . Based on whether con-
                                                                                θi∈Ak      λ+μk
            adjectives is no greater than 0.3. Even though the combined straint k is tight or not we have:

            probability mass of all words equals one, the sum of the upper                      NA
                                                                    •    k ˆ          ∈           k     k
            bounds provided by the expert can be greater than one. For- If h (θ)=0i.e. k K,then λ+μk = α . This implies
            mally, in this type of domain knowledge, the parameters of ˆ    Ni         Ni
                                                                      θi = λ+μ  = αk · N  .
                                                                              k         Ak
            a conditional probability distribution, denoted by θ1,...,θn,
                                  s
                                 ∪     k                  ≤  k      •      ˆ           ∈
            can be partitioned in θ = k=1A such that θ ∈Ak θi α       If hk(θ) < 0 i.e. k K,thenμk =0and therefore we
                                                   i                                  N
                    ≤    ≤           k                                                  Ak
            for all 1 k    s,whereα    is a given positive constant.  have        θˆi =   .
                                                                             θi∈Ak      λ
            Again, denote by NAk the sum of the observed counts cor-
            responding to parameters in Ak and by N be the sum of all Summing up over all parameters not involved in the tight
            observed counts Ni corresponding to parameters θ.Ifthere constraints, we get:
                                                                                                    
            are parameters not involved in any of these constraints, then               
                                                                                                      j∈K NAj
            we can consider they belong to their own set Ak with αk =1.  (1 −    αj)=           θi =
              In the previous subsection we found an easy way to de-                                     λ
                                                                             j∈K      θi∈Ak,k∈K
            cide whether a constraint is tight at the optimum point. For            P
                                                                                          N
            the type of constraints we deal with here, we are not able to             mP∈K Am             ˆ
                                                                    We obtain λ  =  1−     α   and further: θi =(1−
            derive such a simple criterion. However, we show a simple,                 j∈K j
                                                                             P   Ni
                                                                    j∈K αj) ·           if θi ∈ Ak and k ∈ K. Because
            linear algorithm that computes the set of tight constraints at     m∈K NAm

                                                            IJCAI-07
                                                               158                                                          
                                                        −           j
the log-likelihood objective function is concave and because (1 j∈K∪kl α ) > 0 and the ﬁrst part of the induction step
the constraints are linear inequalities, it follows that θˆ is the is proved.
set of Maximum Likelihood estimators. This concludes our If in both sides of inequality 1 we add the quantity (1 −
                                                       k −         j ·             A
derivation of the Maximum Likelihood estimators when we α l   j∈K α )   m∈K∪{kl} N m , we obtain:
know in advance which constraints are satisﬁed by our esti-                                
mators.                                                 −   −        ·         ≥   −       ·
                                                      (1  αkl     αj)     NAm    (1     αj)          NAm
                                                              j∈K    m∈K           j∈K     m∈K∪{k }
  Next we describe the algorithm that ﬁnds the set K of tight                                     l
constraints:                                                           −    −
                                                      which, given that 1 αkl    j∈K αj > 0, is equivalent to
Algorithm 4.1. (Finding the set of tight constraints if λl ≥ λl+1. This concludes the proof of our lemma.
  j αj =1 )
                                                      Applying Lemma 4.2, it follows that, in the case when
                                                             
STEP 1. Start with K = ∅ and at each step add a constraint j αj =1, the Algorithm 4.1 ends at a step l such that
                                                      N
                                                        Ak                               N
to K.                                                     j                                Ak
                                                       α    ≥  λj ≥ λl for all kj ∈ K and α   <λl  for all
                                 P                      kj                                 k
                                       N
                                   mP∈K Am           k ∈ K. From Lemma 4.1 it follows that K is the set of tight
STEP 2. If K = {k1,...,kl},letλl = 1−   α  as in the
                                     j∈K  j           constraints in the case when j αj =1 and therefore Algo-
above theorem.                                        rithm 4.1 is correct. Another case is when all constraints are

                                     NA               processed and we are not left with a λl to compare with. This
                                       kl+1
                    l+1 ∈                 ≥   l
STEP 3. If there exists k K such that αk     λ ,let   situation can not happen, because, at the last step, we would
                                       l+1            have:
K =  K ∪{kl+1}  and GO TO Step 2. Otherwise STOP and
declare K the set of tight constraints.                                  NA          NA
                                                                           ks    ≤     ks
                                                                       −
Proof. (Correctness of Algorithm) We start by making the             1     j=k αj    αks
                                                                             s    
following observation, based on the proof of Theorem 4.2:
                                                      and therefore either j αj =1or j αj < 1. In the second
                  N
                    Ak
  •    k                  k          k ≥              case, the constraints are contradictory, which can not happen
    If h tight, then λ+μk = α . Because μ 0,wemust
         N                                            because we assume the domain expert provides accurate do-
          Ak ≥
    have αk    λ.                                     main knowledge. If  j αj =1(case which is not covered
  • If hk not tight, then μk =0and therefore we have 0 > by Algorithm 4.1), it is obvious that the all constraints must
            N                                N
             Ak                               Ak      be tight not only for the Maximum Likelihood estimators, but
    hk(θˆ)=     − αk and therefore we must have  <
             λ                               αk       for every feasible value of θ.
    λ. It is obvious that λ ≥ 0 must hold, otherwise we
    would have negative parameters.                   5   Formal Guarantees
  We have just developed a criterion to test if a set K of Sometimes it may happen that the constraints provided by
constraints is the set of tight constraints:          an expert are not completely accurate. In all our methods
Lemma 4.1. Given λ (which depends on K) computed as in so far, we assumed that the constraints are correct and there-
Theorem 4.2, K is the set of tight constraints if and only if fore errors in domain knowledge can prove detrimental to the
N                       N
 Ak                      Ak                           performance of our learned models. In this section we investi-
    ≥ λ for all k ∈ K and   <λfor all k ∈ K.
 αk                     αk                            gate the relationship between the true, underlying distribution
  Before proving that our algorithm produces the set of tight of the observed data and the distribution estimated using our
constraints, let us prove another useful result:      methods based on inequality constraints. Because of space
                                                     reasons, we omit the proofs for the theorem and the corollary
                                   ≥    ≥
Lemma 4.2. If j αj =1then  N  = λ0   λ1    ..., and  presented in this section.
the quantity 1 − j∈K αj is always strictly positive.    Suppose P is the true distribution from which data is sam-
                                                      pled. Let P ∗ be the the closest distribution to P (in terms of
Proof. (of lemma) Since initially K = ∅, it is obvious that KL(P, ·)) that factorizes according to the given structure and
 −          ≥
1     j∈K αj  0. It is also obvious λ0 = N. Let us verify obeys the expert’s inequality constraints. We have:
the induction step.                                   Theorem 5.1. With an inﬁnite amount of data, the distribu-
       NA                      
         kl
  From  α   ≥ λl and because 1 − j∈K αj > 0 we get:   tion Pˆ given by the Maximum Likelihood estimators in Theo-
         kl
                                                      rem 4.1 converges to P ∗ with probability 1.
                                 
                                                      Corollary 5.1. If the true distribution P factorizes according
  NA  · (1 − αk −    αj ) ≥ αk ·        NAm     (1)
    kl        l              l                        to the given structure and if the parameter inequality con-
                 j∈K           m∈K∪{kl}
                                                     straints provided by the expert are completely accurate, then
             −            j  ≥                                      ˆ
  It follows (1   j∈K∪kl α )   0 with equality if and the distribution P given by the estimators computed in Theo-
only if we processed all constraints, in which case we have rem 4.1 converges to P with probability 1.
1=     j αj and it is obvious that all constraints must be Similar results hold for the inequality constraints described
tight. However, since we assumed j αj =1 ,wemusthave in subsection 4.2.

                                                IJCAI-07
                                                   159