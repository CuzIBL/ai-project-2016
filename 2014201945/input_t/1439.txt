           Aﬃne      Algebraic      Decision     Diagrams        (AADDs)        and   their
                Application       to  Structured       Probabilistic       Inference
                      Scott   Sanner                            David   McAllester
            Department    of Computer   Science                   TTI   at Chicago
                  University  of Toronto                       1427  East 60th  Street
           Toronto,  ON   M5S  3H5,  CANADA                   Chicago,  IL 60637,  USA
                ssanner@cs.toronto.edu                        mcallester@tti-c.org

                    Abstract                            a) Conjunctive ADD b) Disjunctive ADD c) Additive and Multiplicative
                                                              Structure       Structure       ADD Structure
    We  propose  an  aﬃne  extension to  ADDs                  A        A                     A
    (AADD)   capable of compactly  representing

    context-speciﬁc, additive, and multiplicative           B              B             B        B
    structure. We show that the AADD has worst-
    case time and space performance within a mul-
    tiplicative constant of that of ADDs, but that it   C                      C       C    C   C    C
    can be linear in the number of variables in cases

    where ADDs  are exponential in the number of                                      7  6 5 4 3 2  1 0
                                                         1      0       1      0
    variables. We provide an empirical comparison                                      7 6 5 4  3 2 1 0
    of tabular, ADD, and AADD    representations
    used in standard Bayes net and MDP inference
    algorithms and conclude that the AADD  per-       Figure 1:  Some example ADDs   showing a) conjunctive
    forms at least as well as the other two represen- structure (f = if(a b   c, 1, 0), b) disjunctive structure
                                                      (f = if(a  b  c, 1, 0)),∧ and∧ c) additive (f = 4a + 2b + c)
    tations, and often yields an exponential perfor-           ∨  ∨        4a+2b+c
    mance  improvement over both when  additive       and multiplicative (f = γ  ) structure (top and bottom
    or multiplicative structure can be exploited.     sets of terminal values, respectively). The high (true) edge is
                                                      solid, the low (false) edge is dotted.
    These results suggest that the AADD is likely
    to yield exponential time and space improve-
    ments for a variety of probabilistic inference al- ADDs  can oﬀer exponential space savings over a fully
    gorithms that currently use tables or ADDs.       enumerated tabular representation. However, the com-
                                                      pactness of ADDs does not extend to the case of additive
                                                      or multiplicative independence, as demonstrated by the
1   Introduction                                      exponentially large representations when this structure
Algebraic decision diagrams (ADDs) [1] provide an eﬃ- is present (1c). Unfortunately such structure often oc-
cient means for representing and performing arithmetic curs in probabilistic and decision-theoretic reasoning do-
operations on functions from a factored boolean domain mains, potentially leading to exponential running times
                          n                           and space requirements for inference in these domains.
to a real-valued range (i.e., B R). They rely on two
main principles to do this: →
                                                      2   Aﬃne     Algebraic   Decision   Diagrams
 1. ADDs  represent a function Bn   R as a directed
    acyclic graph – essentially a decision→ tree with re- To address the limitations of ADDs, we introduce an
    convergent branches and real-valued terminal nodes. aﬃne extension to the ADD (AADD) that is capable of
                                                      canonically and compactly representing context-speciﬁc,
 2. ADDs  enforce a strict variable ordering on the de- additive, and multiplicative structure in functions from
    cisions from the root to the terminal node, enabling Bn R. We deﬁne AADDs   with the following BNF:
    a minimal, canonical diagram to be produced for a    →
    given function. Thus, two identical functions will al-  G   ::=  c + bF
                                                                             var
    ways have identical ADD representations under the       F   ::=  0   if(F   , ch + bhFh, cl + blFl)
    same variable ordering.                                            |
                                                      Here, ch and cl are real (or ﬂoating-point) constants in
  As shown  in Figure 1, ADDs  often provide an eﬃ-   the closed interval [0, 1], bh and bl are real constants in
cient representation of functions with context-speciﬁc the half-open interval (0, 1], F var is a boolean variable
independence [2], such as functions whose structure is associated with F , and Fl and Fh are non-terminals of
conjunctive (1a) or disjunctive (1b) in nature. Thus, type F . We also impose the following constraints: a) Additive AADD Structure b) Multiplicative AADD Structure         < c   , b   >         < c   , b   >
                                                                      1 1                   2 2
              f = 2a + b              f = 2a b ; < 1
                                                                    var        op         var
                                                                   F1                    F             
           < 0 , 3 >               < 3 , 1 − 3 >                                          2
                                                            < c , b >  < c , b >  < c , b >  < c , b >
                                                             1,h 1,h    1,l 1,l    2,h 2,h     2,l 2,l
          A                      A
                                                               var      var
                          2  3            3                                           var     var
                           −            −   1 −                F1,h    F1,l          F       F
 < 2/3, 1/3 > < 0 , 1/3 > < 0 , >    <     ,    >                                    2,h      2,l
                          1 − 3       1 − 3 1 − 3
          B                      B                    Figure 3: Two AADD  nodes F1 and F2 and a binary oper-
                                                      ation op with the corresponding notation used in this paper.
   < 1, 0 >  < 0 , 0 >     < 0 , 0 > < 1, 0 >

          0                      0                    the exponentially sized ADDs from Figure 1c represented
                                                      by generalized AADDs  of linear size.
Figure 2: Portions of the ADDs from ﬁgure 1c expressed as We let op denote a binary operator on AADDs with
generalized AADDs. The edge weights are given as c, b .
                                           h   i      possible operations being addition, substraction, multi-
                                                      plication, division, min, and max denoted respectively
                  var
 1. The variable F   does not appear in Fh or Fl.     as  ,  ,  ,  , min( , ), and max( , ).
                                                         ⊕  ª ⊗  ®      · ·          · ·
 2. min(ch, cl) = 0
                                                      3   Related    Work
 3. max(ch + bh, cl + bl) = 1
                                                      There has been much  related work in the formal veriﬁ-
 4. If Fh = 0 then bh = 0 and ch > 0. Similarly for Fl.
                                                      cation literature that has attempted to tackle additive
 5. In the grammar for G, we require that if F = 0 then and multiplicative structure in representation of func-
    b = 0, otherwise b > 0.                                       n    m
                                                      tions from B    B  . These include *BMDs, K*BMDs,
Expressions in the grammar for F will be called normal- EVBDDs, FEVBDDs,→  HDDs,  and *PHDDs   [3]. While
ized AADDs  and expressions in the grammar for G will space limitations prevent us from discussing all of the
be called generalized AADDs.1                         diﬀerences between AADDs   and these data structures,
  Let V al(F, ρ) be the value of AADD F under variable we note two major diﬀerences: 1) These data structures
value assignment ρ. This can be deﬁned recursively by have diﬀerent canonical forms relying on GCD factoriza-
the following equation:                               tion and do not satisfy the invariant property of AADDs
                                                      that internal nodes have range [0, 1]. 2) The fact that
             F = 0 :                0                                                              m
                       var                            these data structures have integer terminals ( ) re-
V al(F, ρ) = F = 0  ρ(F   ) = true : ch + bh V al(Fh, ρ)                                         B
              6  ∧    var                ·           quires a rational or direct ﬂoating-point representation
            F = 0  ρ(F   ) = false : cl + bl V al(Fl, ρ)
               6  ∧                      ·            of values in R. In our experience, this renders them
Lemma   2.1. For any normalized AADD F we have that  unusable for probabilistic inference due to considerable
V al(F, ρ) is in the interval [0, 1], minρ V al(F, ρ) = 0, numerical precision error and computational diﬃculties.
and if F = 0 then max V al(F, ρ) = 1.
        6           ρ
  We  say that F satisﬁes a given variable ordering if 4  Algorithms
                            var
F = 0 or F is of the form if(F , ch + bhFh, cl + blFl)
       var                                var         We  now  deﬁne AADD   algorithms that are analogs of
where F    does not occur in Fh or Fl and F  is the   those given by Bryant [4]2 except that they are extended
earliest variable under the given ordering occuring in F . to propagate the aﬃne transform of the edge weights
We say that a generalized AADD of form c+bF satisﬁes  on recursion and to compute the normalization of the
the order if F satisﬁes the order.                    resulting node on return.
Lemma    2.2. Fix a variable ordering. For any non-     All algorithms rely on the helper function GetGNode
constant function g mapping Bn     R, there exists a  given in Algorithm 1 that takes an unnormalized AADD
                               −→
unique generalized AADD  G satisfying the given vari- node of the form if(v, ch+bhFh, cl+blFl) and returns the
                                  n                                                                     3
able ordering such that for all ρ B we have g(ρ) =    cached, generalized AADD node of the form cr +brFr .
V al(G, ρ).                   ∈                                                               h       i
  Both lemmas can be proved by straightforward induc- 4.1   Reduce
tion on n. The second lemma shows that under a given  The  Reduce algorithm given in Algorithm 2 takes an
variable ordering, generalized AADDs are canonical, i.e., arbitrary ordered AADD, normalizes and caches the in-
two identical functions will always have identical AADD ternal nodes, and returns the corresponding generalized
representations.                                      AADD.   One nice property of the Reduce algorithm is
  As an example of two AADDs  with compact additive   that one does not need to prespecify the structure that
and multiplicative structure, Figure 2 shows portions of
                                                         2Bryant gives algorithms for binary decision diagrams
  1Since normalized AADDs in grammar F are restricted (BDDs), but they are essentially identical to those for ADDs.
to the range [0, 1], we need the top-level positive aﬃne trans- 3In the algorithms we use the representation c, b, F ,
form of generalized AADDs in grammar G to allow for the while in the text we often use the equivalent notationh c+bFi
representation of functions with arbitrary range.     to make the node semantics more clear.      h     iAlgorithm  1: GetGNode(v,  ch, bh, Fh , cl, bl, Fl )  Algorithm   2: Reduce( c, b, F ) cr, br, Fr
                          h       i h      i −→                            h     i −→  h       i
cr, br, Fr
h       i                                               input   : c, b, F : Oﬀset, multiplier, and node id
                                                                 h     i
  input   : v, ch, bh, Fh , cl, bl, Fl : Var, oﬀset, mult,
             h       i h      i                         output  : cr, br, Fr : Return values for oﬀset,
           and node id for high/low branches                     hmultiplier,i and node id
  output  : cr, br, Fr : Return values for oﬀset,       begin
           h       i
           multiplier, and canonical node id               // Check for terminal node
  begin                                                    if (F = 0) then
     // If branches redundant, return child                    return c, 0, 0 ;
                                                                    h     i
     if (cl = ch bl = bh Fl = Fh) then
              ∧       ∧
        return cl, bl, Fl ;                                // Check reduce cache
              h      i                                     if ( F   cr, br, Fr is not in reduce cache) then
     // Non-redundant so compute canonical form                // →Noth in cache,i so recurse
     rmin := min(cl, ch); rmax := max(cl + bl, ch + bh);
                                                               ch, bh, Fh := Reduce(ch, bh, Fh);
     rrange := rmax rmin;                                      h       i
                  −                                            cl, bl, Fl := Reduce(cl, bl, Fl);
     cl := (cl rmin)/rrange; ch := (ch rmin)/rrange;           h      i
            −                      −
     bl := bl/rrange; bh := bh/rrange;                         // Retrieve canonical form
                                                                                      var
     if ( v, ch, bh, Fh , cl, bl, Fl id is not in node         cr, br, Fr := GetGNode(F , ch, bh, Fh , cl, bl, Fl );
     cache)h hthen i h      ii →                               h       i                 h       i h      i
        id := currently unallocated id;                        // Put in cache
        insert v, ch, bh, Fh , cl, bl, Fl id in cache;         insert F  cr, br, Fr in reduce cache;
              h h        i h     ii →                                 → h       i
     // Return the cached, canonical node                  // Return canonical reduced node
     return rmin, rrange, id ;                             return c + b cr, b br, Fr ;
           h            i                                        h    ·    ·     i
  end                                                   end

the AADD   should exploit. If the represented function cases (the third case where both operands are 0 terminal
contains context-speciﬁc, additive, or multiplicative in- nodes having been taken care of in the previous section):
dependence, the Reduce algorithm will compactly repre-                                    var    var
                                                      F1 or F2 is a 0 terminal node,  or F1   = F2  : We
sent this structure uniquely and automatically w.r.t. the assume the operation is commutative and6 reorder the
variable ordering as guaranteed by previous lemmas.   operands so that F1 is the 0 node or the operand whose
                                                      variable comes later in the variable ordering.4 Then we
4.2   Apply
                                                      propagate the aﬃne transform to each of F2’s branches
The Apply routine given in Algorithm 3 takes two gen- and compute the operation applied separately to F1 and
eralized AADD  operands and an operation as given in  each of F2’s high and low branches. We then build an if
                                                                              var
Figure 3 and produces the resulting generalized AADD. statement conditional on F2 and normalize it to obtain
The control ﬂow of the algorithm is straightforward: We the generalized AADD node cr, br, Fr for the result:
ﬁrst check whether we can compute the result immedi-                            h        i
                                                       ch, bh, Fh = Apply( c1, b1, F1 , c2 + b2c2,h, b2b2,h, F2,h , op)
ately, otherwise we normalize the operands to a canonical h   i         h      i h                   i
                                                        cl, bl, Fl = Apply( c1, b1, F1 , c2 + b2c2,l, b2b2,l, F2,l , op)
form and check if we can reuse the result of a previously h   i        h     vari h                i
                                                       cr, br, Fr = GetGNode(F2 , ch, bh, Fh , cl, bl, Fl )
cached computation. If we can do neither of these, we  h      i                  h       i h      i
then choose a variable to branch on and recursively call                                      var    var
                                                      F1 and F2 are non-terminal  nodes and  F    = F   :
   Apply                                                                                      1      2
the      routine for each instantiation of the variable. Since the variables for each operand match, we know the
We cover these steps in-depth in the following sections.
                                                      result cr, br, Fr is simply a generalized if statement
                                                            h        ivar    var
Terminal  computation                                 branching on F1   (=  F2  ) with the true case being
The function ComputeResult  given in the top half of  the operator applied to the high branches of F1 and F2
Table 1, determines if the result of a computation can and likewise for the false case and the low branches:
be immediately computed without recursion. The ﬁrst       ch, bh, Fh = Apply( c1 + b1c1,h, b1b1,h, F1,h ,
                                                         h       i        h                   i
entry in this table is required for proper termination of                  c2 + b2c2,h, b2b2,h, F2,h , op)
the algorithm as it computes the result of an operation                   h                   i
                                                           cl, bl, Fl = Apply( c1 + b1c1,l, b1b1,l, F1,l
applied to two terminal 0 nodes. However, the other       h      i        h                  i
                                                                           c2 + b2c2,l, b2b2,l, F2,l , op)
entries denote a number of pruning optimizations that                     h     var          i
                                                          cr, br, Fr = GetGNode(F1 , ch, bh, Fh , cl, bl, Fl )
immediately return a node without recursion. For ex-     h       i                 h        i h     i
ample, given the operation 3 + 4F1  5 + 6F1 , we can     4
                        h       i ⊕ h     i               We note that the ﬁrst case prohibits the use of the non-
immediately return the result 8 + 10F1 .              commutative  and   operations. However, a simple solution
                           h        i                            ª     ®
                                                      would be to recursively descend on either F1 or F2 rather than
Recursive  computation                                assuming commutativity and swapping operands to ensure
If a call to Apply is unable to immediately compute a descent on F2. To accommodate general non-commutative
result or reuse a previously cached computation, we must operations, we have used this alternate approach in our spec-
recursively compute the result. For this we have two  iﬁcation of the Apply routine given in Algorithm 3.Canonical  caching                                    Algorithm    3:  Apply( c1, b1, F1 , c2, b2, F2 , op)
                                                                             h      i h       i     −→
If the AADD   Apply algorithm were to compute  and     cr, br, Fr
                                                      h       i
cache the results of applying an operation directly to the
operands, the algorithm would provably have the same    input   : c1, b1, F1 , c2, b2, F2 , op : Nodes and op
                                                                 h       i h       i
time complexity as the ADD Apply algorithm. Yet, if we  output  : cr, br, Fr : Generalized node to return
                                                                 h       i
were to compute 0+1F1    0+2F2   and cache the result   begin
               h      i⊕h      i
 cr + brFr , we could compute 5 + 2F1   4 + 4F2  =         // Check if result can be immediately computed
h        i                  h       i ⊕ h      i
 (2cr + 9) + 2brFr without recursion.                      if (ComputeResult( c1, b1, F1 , c2, b2, F2 , op)
h               i                                                            h       i h       i     →
  This suggests a canonical caching scheme that normal-     cr, br, Fr is not null ) then
                                                           h       i
                                                               return cr, br, Fr ;
izes all cache entries to increase the chance of a cache hit.       h       i
The actual result can then be easily computed from the     // Get normalized key and check apply cache
                                                              0 0   0  0
cached result by reversing the normalization. This en-       c1, b1 , c2, b2 :=
                                                           hh    i h    ii
sures optimal reuse of the Apply operations cache and          GetNormCacheKey(   c1, b1, F1 , c2, b2, F2 , op);
                                                                 0  0      0 0   h       i h       i
                                                           if (  c1, b1, F1 , c2, b2, F2 , op cr, br, Fr is not
can lead to an exponential reduction in running time           hh       i h      i   i → h      i
over the non-canonical caching version.                    in apply cache) then
  We introduce two additional functions to perform this        // Not terminal, so recurse
                                                               if                        then
caching: GetNormCacheKey   to compute the canonical              (F1 is a non-terminal node)
                                                                  if (F2 is a non-terminal node) then
cache key, and ModifyResult to reverse the normaliza-                    var             var
                                                                     if (F1  comes before F2 ) then
                                                                                var
tion in order to compute the actual result. These algo-                 var := F1 ;
rithms are summarized in the bottom half of Table 1.                 else
                                                                                var
4.3   Other  Operations                                                 var := F2 ;
While space limitations prevent us from covering all of           else
                                                                             var
the operations that can be performed (eﬃciently) on                  var := F1 ;
AADDs,  we brieﬂy summarize some of them here:                 else
                                                                         var
min  and max   computation:  The  min and max  of a               var := F2 ;
generalized AADD node  c + bF  are respectively c and
                      h      i                                 // Propagate aﬃne transform to branches
c + b due to [0, 1] normalization of F .                                                   var
                                                               if (F1 is non-terminal var = F1 ) then
Restriction: The restriction of a variable xi in a func-           v1          v1 ∧
                                                                  Fl  := F1,l; Fh := F1,h;
tion to either true or false (i.e. F x =T/F ) can be com-          v1   0   0       v1    0   0
                                i                                 cl := c1 + b1 c1,l; ch := c1 + b1 c1,h;
puted by returning the proper branc| h of nodes contain-           v1   0     · v1    0        ·
                                                                  bl := b1 b1,l; bh := b1 b1,h;
ing that test variable during the Reduce operation.                       ·            ·
                                                               else
                                         x                         v1         v1    0   v1    0
Sum   out/marginalization:   A  variable  i can be                F   := F1; c  := c1; b   := b1;
                                          F                        l/h        l/h       l/h
summed  (or marginalized) out of a function simply                                         var
                                                               if (F2 is non-terminal var = F2 ) then
by computing the sum  of the restricted functions (i.e.            v2          v2 ∧
                                                                  Fl  := F2,l; Fh := F2,h;
F xi=T   F xi=F ).                                                 v2   0   0       v2    0   0
 |     ⊕  |                                                       cl := c2 + b2 c2,l; ch := c2 + b2 c2,h;
Negation/reciprocation:    While it may  seem  that                v2   0     · v2    0        ·
                                                                  b  := b2 b2,l; b := b1 b2,h;
negation of a generalized AADD node  c + bF  would                 l      ·     h      ·
                                    h      i                   else
be as simple as   c +   bF , we note  that this vio-               v2         v2    0   v2    0
                                                                  F   := F2; c  := c ; b   := b ;
lates our normalizationh− −schemei which requires b > 0.           l/h        l/h   2   l/h   2
Consequently, negation must be performed explicitly as         // Recurse and get cached result
                                         1                                       v1 v1  v1   v2 v2  v2
0   c + bF . Likewise, reciprocation (i.e., hc+bF i ) must     cl, bl, Fl := Apply( cl , bl , Fl , cl , bl , Fl , op);
 ª h      i                                                    h      i        h  v1 v1  vi1 h v2 v2  vi2
                                                               ch, bh, Fh := Apply( c , b , F , c , b , F , op);
be performed explicitly as 1 c + bF .                          h       i        h h  h   h i h h  h  h i
                          ® h     i                            cr, br, Fr := GetGNode(var, ch, bh, Fh , cl, bl, Fl );
Variable  reordering:  A  generalization of Rudell’s           h       i                h       i h      i
                                                               // Put result in apply cache and return
ADD  variable reordering algorithm [5] that recomputes                0  0    0  0
                                                               insert c1, b1, F1, c2, b2, F2, op cr, br, Fr
edge weights of reordered nodes  can be  applied to                  h                 i  →   h       i
AADDs   without loss of eﬃciency.                              into apply cache;
                                                           return ModifyResult( cr, br, Fr );
                                                                              h       i
4.4   Cache  Implementation                             end
If one were to use a naive cache implementation that re-
lied on exact ﬂoating-point values for hashing and equal-
ity testing, one would ﬁnd that many nodes which should it is diﬃcult to guarantee such an exact property for
be the same under exact computation often turn out to an eﬃcient hashing scheme, we next outline an approx-
have oﬀsets or multipliers diﬀering by 1e-15 due to nu- imate approach that we have found to work both eﬃ-
merical precision error. This can result§in an exponential ciently and nearly optimally in practice.
explosion of nodes if not controlled. Consequently, it is The node cache used in GetGNode and the operation
better to use a hashing scheme that considers equality result cache used in Apply both use cache keys containing
within some range of numerical precision error ². While four ﬂoating-point values (i.e., the oﬀsets and multipliers                            ComputeResult( c1, b1, F1 , c2, b2, F2 , op) cr, br, Fr
                                          h       i h       i   −→  h       i
            Operation  and Conditions                          Return Value

             c1 + b1F1 op  c2 + b2F2 ; F1 = F2 = 0             (c1 op c2) + 0 0
            h        i h i h       i                           h  h  i      · i
            max( c1 + b1F1 , c2 + b2F2 ); c1 + b1 c2           c2 + b2F2
                 h       i h       i         ≤                 h       i
            max( c1 + b1F1 , c2 + b2F2 ); c2 + b2 c1           c1 + b1F1
                 h       i h       i         ≤                 h       i
             c1 + b1F1   c2 + b2F2 ; F1 = F2                   (c1 + c2) + (b1 + b2)F1
            h        i ⊕ h       i                             h                  i
            max( c1 + b1F1 , c2 + b2F1 ); F1 = F2,             c1  c2  b1  b2 : c1 + b1F1
                 h       i h       i                             ≥   ∧   ≥    h        i
            (c1  c2  b1   b2) (c2  c1  b2  b1)                 c2  c1  b2  b1 : c2 + b2F1
               ≥    ∧  ≥    ∨    ≥   ∧   ≥                       ≥   ∧   ≥    h        i
                           Note: for all max operations above, return opposite for min
             c1 + b1F1 op  c2 + b2F2 ; F2 = 0, op  ,           (c1 op c2) + b1F1
            h        i h i h       i          ∈ {⊕ ª}          h  h  i         i
             c1 + b1F1 op  c2 + b2F2 ; F2 = 0, c2 0, op  ,     (c1 op c2) + (b1 op c2)F1
            h        i h i h       i          ≥     ∈ {⊗  ®}   h  h  i        h  i    i
                  Note: above two operations can be modiﬁed to handle F1 = 0 when op ,
                                                                              ∈ {⊕  ⊗}
            other                                              null

                                                  0  0  0 0                                   0  0  0
    GetNormCacheKey(   c1, b1, F1 , c2, b2, F2 , op) c1, b1 c2, b2 and ModifyResult( cr, br, Fr ) c , b , F
                      h       i h      i    −→  hh   ih    ii                  h       i −→ h r  r ri
 Operation  and Conditions      Normalized Cache  Key  and Computation           Result Modiﬁcation

  c1 + b1F1  c2 + b2F2 ; F1 = 0 cr + brFr = 0 + 1F1   0 + (b2/b1)F2               (c1 + c2 + b1cr) + b1brFr
 h        i ⊕ h      i    6     h       i  h       i ⊕ h          i              h                     i
  c1 + b1F1  c2 + b2F2 ; F1 = 0 cr + brFr = 0 + 1F1   0 + (b2/b1)F2               (c1  c2 + b1cr) + b1brFr
 h        i ª h      i    6     h       i  h       i ª h          i              h   −                 i
  c1 + b1F1  c2 + b2F2 ; F1 = 0 cr + brFr = (c1/b1) + F1  (c2/b2) + F2            b1b2cr + b1b2brFr
 h        i ⊗ h      i    6     h       i  h           i ⊗ h         i           h               i
  c1 + b1F1  c2 + b2F2 ; F1 = 0 cr + brFr = (c1/b1) + F1  (c2/b2) + F2            (b1/b2)cr + (b1/b2)brFr
 h        i ® h      i    6     h       i  h           i ® h         i           h                    i
 max( c1 + b1F1 , c2 + b2F2 );  cr + brFr = max( 0 + 1F1 , (c2 c1)/b1 + (b2/b1)F2 ) (c1 + b1cr) + b1brFr
     h        i h       i       h       i       h      i h  −                i   h                 i
 F1 = 0, Note: same for min
    6
 any op  not matching above:    cr + brFr = c1 + b1F1 op  c2 + b2F2               cr + brFr
     h i                        h       i  h        i h i h       i              h        i
  c1 + b1F1 op  c2 + b2F2
 h        i h i h      i
    Table 1: Input and output summaries of the ComputeResult, GetNormCacheKey, and ModifyResult routines.

for two AADD   nodes). If we consider this 4-tuple of
                                                               <v ,v >
ﬂoating-point values to be a point in Euclidean space,           1 2
then we can  measure the error between two 4-tuples                                    <u1 ,u2 >
                                                                                          ε
 u1, u2, u3, u4 and v1, v2, v3, v4 as the L2 (Euclidean)                                               
distanceh betwieen theseh points. Asi a consequence of the
triangle inequality for four dimensions, we know that                                          ε
                                                                         d          d       ε
          2           2          2           2                            1          2
  (u1  v1) + (u2   v2) + (u3   v3) + (u4  v4)    ²
     −2     2    −2    2    2−    2    2 −   2 ≤
  √u1   + u2 + u3  + u4 -√v1  + v2 + v3  + v4    ².                              <0,0>
p
⇒This| is shown graphically for two dimensions in Figure| ≤ 4.
  Based on this inequality, we can use the following ap- Figure 4: A 2D visualization of the hashing scheme we use.
                                                      All points within ² of u1, u2 (the dark circle) lie within the
proximate hashing scheme for v1, v2, v3, v4 : Compute
                                                                        h     i      √   2    2
    L                   v , vh, v , v  i              ring having outer and inner radius u1 + u2 ². Thus,
the  2 distance between  1  2  3  4  and the origin;  a hashing scheme which hashes all points within§the ring to
For hashing, extract only theh bits from thei ﬂoating-point
                                                      the same bucket guarantees that all points within ² of u1, u2
base representing a fractional portion greater than ² and also hash to the same bucket. We can use squared distancesh i
use this as the integer representation of the hash key to avoid a √ , thus the hash key for v1, v2 can be eﬃciently
                                                                                    h    i
(we are eﬀectively discretizing the distances into buckets computed as the squared distance from v1, v2 to the origin.
of width ²); For equality, test that the true L2 metric                                h     i
between  u1, u2, u3, u4 and v1, v2, v3, v4 is less than ². 5 Theoretical Results
        h           i    h           i
  While this hashing scheme does not guarantee that all Here we present two fundamental results for AADDs:
4-tuples having distance from the origin 0, 0, 0, 0 within
² hash to the same bucket (some 4-tuplesh withini² could Theorem 5.1. The  time and  space performance of
fall over bucket boundaries), we found that with bucket Reduce and Apply for AADDs is within a multiplicative
width ² = 1e-9 and numerical precision error generally constant of that of ADDs in the worst case.
less than 1e-13, there was only a small probability of Proof Sketch. Under the same  variable ordering, an
two nodes equal within numerical precision straddling a ADD is equivalent to a non-canonical AADD with ﬁxed
bucket boundary. For the empirical results described in edge weights c = 0, b = 1. Thus the ADD   Reduce
Section 6, this hashing scheme was suﬃcient to prevent and Apply algorithms can be seen as analogs of the
any uncontrollable cases of numerical precision error. AADD  algorithms without the additional constant-time