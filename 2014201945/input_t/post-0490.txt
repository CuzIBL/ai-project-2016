Naturalness of an Utterance Based on the Automatically Retrieved Commonsense

                               Rafal Rzepka, Yali Ge and Kenji Araki
             Graduate School of Information Science and Technology, Hokkaido University
                                      Language Media Laboratory
                           Kita-ku Kita 14 Nishi 9, 060-0814 Sapporo, Japan
                             kabura,geyali,araki@media.eng.hokudai.ac.jp

                    Abstract                          nored here) phrases text-mined from homepages improve the
                                                      user’s acceptation for talking systems.
    In this research we investigated user’s behavior
    while facing a system coping with common knowl-   2   Commonsense Knowledge Retrieval
    edge about keywords and compared it with not only
    classic word-spotting method but also with ran-   2.1  Collected Data Structure
    dom  text-mining. We show how even a simple       For the set of experiments we performed, we used only nouns
    implementation of our idea can enrich the conver- as for decades they were usually the main part of open-
    sation and increase the naturalness of computer’s domain chat programs, although we claim that te common-
    utterances. Our results show that even very com-  sensical context is the future of dialogue processing. Using
    monsensical utterances are more natural than clas- a nouns list and Larbin robot we created 1,907,086 sentences
    sic approaches and also methods we developed to   WWW    corpus which was a base for a verb, a noun and VO
    make a conversation more interesting. For arous-  n-gram dictionaries. The noun and verb dictionaries consist
    ing opinion exchange during the session, we will  of 79,460 verbs and 134,189 nouns extracted with help of
    also brieﬂy introduce our idea of combining latest ChaSen Analyzer. For creating VO phrases automatically,
    NLP achievements into one holistic system where   our system had to search for the relationships between verbs
    the main engine we want to base on commonsense    and nouns and also between verbs. In this step, we used
    processing and affective computing.               the verbs and nouns which had the highest occurrence and
                                                      are common, as they are used in everyday live, for exam-
1  Introduction                                       ple [pour/drink/melt]-water, [listen/switch on/enjoy]-music
                                                      or [go to/buy at/enter]convenient store. We used Japanese
During one of the NLP community meetings in Japan we at- language, which has useful grammar features like rentaikei
tended a discussion about evaluating the freely (meaning ”in where the verb sufﬁx te usually joins verbs in a time sequence
the open domain”) talking computer systems. The partici- e.g. gohan wo tabe-te neru (to sleep after having a dinner) or
pants agreed that such systems are almost ignored by com- tara, eba and to “if” forms which are able to distinguish dif-
puter scientists while so called ”chatter-bots” as Parry [Colby, ferent causal connotations. By these useful grammar features
1975] or ELIZA [Weizenbaum, 1976] seem to be very of- we are able to web-mine commonsensical knowledge as “it is
ten the only known yield of AI for other scientists and non- usual that some people buy sweets at convenient store even
scholars. But today, even if passing the Turing test is still if they didn’t wanted”. Until now such data had to be col-
questionable, we have faster and faster access to massive cor- lected manually[Singh, 2002] but full automatizing of such
pora, which we believe may incline researchers to rethink the knowledge collecting brings new opportunities not only for
need of naturally talking systems and we claim they might dialogue but also for storytelling, question answering, ma-
be done without much labor and cost. Such renaissance chine translation and many other ﬁelds.
would not only be important for the public recognition of the
ﬁeld but also could bring more young scholars fascinated by 2.2 Architecture Overview
the fact that Internet has a chance to replace programmer’s Basically, our system’s architecture for creating commonsen-
will and change the program’s behavior depending on the sical data can be summarized into the following processing
facts discovered in millions of web-pages. Already Rzepka steps:
    [ ]
et al. ? has noticed such possibility proposing an automat- a) A noun of is assigned for a keyword;
ically developing average personality of “Mr. Internet” and
has conﬁrmed that commonsense knowledge can be retrieved b) The system uses our web corpus for frequency check
from the WWW. We want to go a step further and show that  to retrieve 3 most frequent verbs following the keyword
using even simple usage of commonsensical (S)VO-then-V    noun;
(Verb-Object and following Verb) and (S)VO-if-(S)VO (Sub- c) The most frequent particle between noun keyword and 3
jects vary depending on the conversation processing so ig- most frequent verbs is discovered; d) For creating bi-gram the system retrieves a list of most
    frequent verbs occurring after the previously chosen
    verb;
 e) By using Yahoo search engine, the system checks if the
    noun-particle unit occurs with new verb-verb unit for
    time-sequence actions and verb-if unit for casual depen-
    dencies;
 f) If yes - the VO-then-V and VO-if-VO units are stored:

      VOthenV   = N + Pmax  + Vmax1 + Vmax2
N :Triggering noun (keyword);
Pmax:most frequent particle joining noun and verb;
Vmax1:most frequent verb occurring after the N;
Vmax2:most frequent verb occurring after Vmax1;

VOif V = N1+P1max+V1max+if     +N2+P2max+V2max        Figure 1:  Naturalness Level Evaluation: CS1:29.5%,

N1 :Triggering noun (keyword);                        CS2:21%, WRR:24.5%, ELI: 25%
P1 max:most freq. particle joining ﬁrst noun with a verb;
V1 max:most freq. verb after the N1P1;
N2 max:most freq. noun after N1P1maxV1max and “if”;   4   Results and Conclusions
P2 max:most freq. particle joining N2 and V2;         In “continuation will degree” ELIZA unsurprisingly achieved
V2 max:most freq. verb after N2P2;                    452 points out of 2919 for four systems (only 15.48%). But
                                                      the performance of commonsenseical utterances was surpris-
                                                      ingly high (CS1:25.38%), CS2:27.14%) which suggest that
3  Experiments                                        interlocutor prefers a machine saying “smoking is bad” than
                                                      one naturally asking questions. The highest result of WRR
In order to see user’s perception of the basic commonsense (32%) tells us how simple tricks can help on keeping up the
knowledge included in a utterance, we performed a set of ex- conversation. On the contrary, the naturalness degree results
periments basically using four kinds of utterances following (see Fig.1) show that the “tricks” of ELIZA and WRR and in-
input with one noun keyword:                          formation overload of CS2 are less natural than the ordinary
  • ELIZA’s output [ELI] (input sentence structure changing truth statements. Due to the lack of space, more speciﬁc re-
    to achieve different outputs)                     sults analysis and graphs we are going to provide during the
  • WWW random retrieval output [WRR] (a shortest of 10 poster session.
    sentences retrieved by using keyword and query pattern
    “did you know that?”)                             References
  • WWW    commonsense retrieval output “high” [CS1]  [Weizenbaum, 1976] Joseph Weizenbaum. Computer Power
    (sentences using common knowledge of highest usual-  and Human Reason. W.H. Freeman and Co., New York,
    ness (most frequent mining results)                  1976.
  • WWW commonsense retrieval output “low” [CS2] (sen- [Colby, 1975] Kenneth Colby. Artiﬁcial Paranoia: A Com-
    tences using common knowledge of the lowest usualness puter Simulation of Paranoid Process Pergamon Press.,
    (least frequent mining results).                     New York, 1975.
Typical ELIZA answer is “why do you want to talk about [Rzepka et. al, 2003] Rafal Rzepka, Kenji Araki and Koji
smoking” if the keyword is “smoking”. For the same       Tochinai. Ideas for the Web-Based Affective Process-
keyword WRR retrieved a sentence “did you know that peo- ing. Proceedings of the Seventh Multi-Conference on Sys-
ple wearing contact lenses have well protected eyes when temics, Cybernetics and Informatics; vol. XIV Computer
somebody is smoking?”. An example of CS1 is “you will    Science, Engineering Applications, vol XIV:376–381, Au-
get fat when you quit smoking” and CS2 is “smoking may   gust 2003.
cause mouth, throat, esophagus, bladder, kidney, and pan- [Singh, 2002] Push Singh. The public acquisition of com-
creas cancers”. We selected 10 most common noun keywords monsense knowledge. Proceedings of AAAI Spring Sym-
of different kinds (water, cigarettes, subway, voice, snow, posium on Acquiring (and Using) Linguistic (and World)
room, clock, child, eye, meal) not avoiding ones often used Knowledge for Information Access, Palo Alto, CA: AAAI,
in Japanese idioms (voice, eye) to see if it inﬂuences the text- 2002.
mining results. 13 referees were evaluating every set of four
utterances in two categories – “naturalness degree” and “will
of continuing a conversation degree” giving marks from 1 to
10 in both cases.