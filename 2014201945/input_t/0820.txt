        Reducing     Checks    and   Revisions   in  Coarse-grained      MAC     Algorithms∗

                                  D. Mehta†  and  M.R.C.  van  Dongen
                              Cork Constraint Computation   Centre, Ireland


                    Abstract                          1977] and AC-3d [van Dongen, 2004]. These algorithms have
                                                      a low O(e + n d) space complexity but they repeat their sup-
    Arc consistency algorithms are widely used to     port checks and have a non optimal bound of O(e d3) for
    prune the search space of Constraint Satisfaction their worst-case time complexity. Here e is the number of
    Problems (CSPs). Coarse-grained arc consistency   constraints, n the number of variables and d the maximum
    algorithms like AC-3, AC-3d and AC-2001 are ef-   domain size of the variables. On the other hand there are al-
    ﬁcient when it comes to transforming a CSP to its gorithms such as AC-4 [Mohr and Henderson, 1986], AC-6
    arc-consistent equivalent. These algorithms repeat- [Bessiere` and Cordier, 1993], and AC-2001 [Bessiere` and
    edly carry out revisions. Revisions require support Regin,´ 2001] that use auxiliary data structures to avoid re-
    checks for identifying and deleting all unsupported peating their support checks and have an optimal worst-case
    values from the domain of a variable. In revisions time complexity of O(e d2).
    for difﬁcult problems most values have some sup-
    port. Indeed, most revisions are ineffective, i.e.  Since the introduction of AC-4 [Mohr and Henderson,
    they cannot delete any value and consume a lot    1986] much  work has been done to avoid repeating sup-
    of checks and time. We propose two solutions to   port checks by using auxiliary data structures. Depending
    overcome these problems. First we introduce the   upon the algorithm, these auxiliary data structures store one
    notion of a Support Condition (SC) which guaran-  or more supports for each value involved in each constraint.
    tees that a value has some support. SCs reduce sup- The belief is that reducing checks helps in solving problems
    port checks while maintaining arc consistency dur- more quickly. However, allowing algorithms to repeat (not
    ing search. Second we introduce the notion of a   too many) checks, relieves them from the burden of a large
    Revision Condition (RC) which guarantees that all additional bookkeeping and this may save time, especially
    values have support. A RC avoids a candidate re-  if checks are cheap. In this paper, we introduce the notion
    vision and queue maintenance overhead. For ran-   of a Support Condition (SC) which guarantees that a value
    dom problems, SCs reduce the checks required by   has some support. SCs help avoiding many (but not all) se-
    MAC-3 (MAC-2001) up to 90% (72%). RCs avoid       quences of support checks eventually leading to a support
    at least 50% of the total revisions. Combining the without storing and maintaining support values.
    two results in reducing 50% of the solution time.   Coarse-grained arc consistency algorithms repeatedly
                                                      carry out revisions to remove all unsupported values from the
1  Introduction                                       domain of a variable. Many revisions are ineffective, i.e. they
                                                      cannot remove any value. For example, when RLFAP #11 is
Arc consistency (AC) algorithms are widely used to prune solved using MAC-3 or MAC-2001, 83% of the total revisions
the search space of binary Constraint Satisfaction Problems are ineffective. We introduce the notion of a Revision Condi-
(CSPs). MAC [Sabin and Freuder, 1994] is a backtrack al- tion (RC) which guarantees that all values have some support.
gorithm that Maintains Arc Consistency during search. It RCs help avoiding many (but not all) ineffective revisions and
reduces the thrashing behaviour of a backtrack algorithm, much queue maintenance, which is also a great source of time
which usually fails many times as a result of the same local consumption [van Dongen and Mehta, 2004]. Furthermore,
inconsistencies. MAC-x uses AC-x for maintaining arc con- we show that reverse variable based heuristics [Mehta and
sistency during search.                               van Dongen, 2004] result in fewer revisions.
  Many arc consistency algorithms have been proposed. On
                                                        The remainder of this paper is as follows. Section 2 is a
the one hand there are algorithms such as AC-3 [Mackworth,
                                                      brief introduction to constraints. Section 3 discusses revision
  ∗This work has received some support from Science Foundation ordering heuristics and the coarse-grained algorithm AC-3.
Ireland under Grant No. 00/PI.1/C075.                 Sections 4 and 5 introduce the notions of a support condition
  †The ﬁrst author is supported by Boole Centre for Research in and a revision condition. Section 6 presents experimental re-
Informatics.                                          sults. Conclusions are presented in Section 7.                                                           Function AC-3: Boolean;
2  Constraint   Satisfaction                               begin
                                                             Q := G
A Constraint Satisfaction Problem is deﬁned as a set V of n  while Q not empty do begin
variables, a non-empty domain D(x) for each variable x ∈ V     select any x from {x : (x, y) ∈ Q }
and a set of e constraints among subsets of variables of V. A  eﬀective revisions := 0
                                                               for each y such that (x, y) ∈ Q do
binary constraint Cxy between variables x and y is a subset      remove (x, y) from Q
of the Cartesian product of D(x) and D(y) that speciﬁes the      revise(x, y, changex)
allowed pairs of values for x and y. We only consider CSPs       if D(x) = ∅ then
                                                                  return False
whose constraints are binary.
                                                                 else if changex then
  A value b ∈ D(y) is called a support for a ∈ D(x) if            eﬀective revisions := eﬀective revisions + 1
                                                                  y00 := y;
(a, b) ∈ Cxy. Similarly a ∈ D(x) is called a support for b ∈   if eﬀective revisions = 1 then
D(y) if (a, b) ∈ Cxy. A support check (consistency check)        Q := Q ∪ { (y0, x) | y0 is a neighbour of x ∧ y0 6= y00}
is a test to ﬁnd if two values support each other. A value     else if eﬀective revisions > 1 then
                                                                 Q := Q ∪ { (y0, x) | y0 is a neighbour of x}
a ∈ D(x) is called viable if for every variable y constraining return True;
x the value a is supported by some value in D(y). A CSP is end;
called arc-consistent if for every variable x ∈ V, each value
a ∈ D(x) is viable.                                                      Figure 1: AC-3.
                                        2
  The density p1 of a CSP is deﬁned as 2 e/(n − n). The
tightness p of the constraint C between the variables x and
         2               xy                           tion based heuristics because the consequences of removing
y is deﬁned as 1 − | C |/| D(x) × D(y) |. The degree of a
                  xy                                  one or more values from     are propagated in all of its
variable is the number of constraints involving that variable.              D(x)
                                                      neighbours. If a variable x is selected then the domain of all
Before starting search MAC transforms the input CSP to its
                                                      its neighbours in the constraint graph will be revised against
arc-consistent equivalent. We call the domain of a variable in
                                                           . In this setting there are usually fewer selections from
this arc-consistent equivalent as the arc-consistent domain of D(x)
                                                      the queue at the cost of performing more checks. If checks
that variable. For the remainder of this paper for any variable
                                                      are cheap then time can be saved because the queue needs
x, we use D  (x) for the arc-consistent domain of x, and
           ac                                         fewer selections. Here too every effective revision results in
D(x) for the current domain of x. The directed constraint
                                                      updating the queue.
graph of a given CSP is a directed graph having an arc (x, y)
                                                                                    [
for each combination of two mutually constraining variables Reverse variable based heuristics Mehta and van Dongen,
                                                          ]
x and y. We will use G to denote the directed constraint graph 2004 ﬁrst select a variable x and then repeatedly select arcs
                                                      of the form    for the next revision until there are no more
of the input CSP.                                               (x, y)
                                                      such arcs or D(x) becomes empty. They may be regarded
                                                      as support based heuristics because for one variable x at a
3  Revision  Ordering   Heuristics                    time, each value in D(x) seeks support with respect to all
Coarse-grained arc consistency algorithms use revision or- of its neighbours for which it is currently unknown whether
dering heuristics to select an arc from a data structure called such support exists. When a variable x is selected a number
a queue (set really). When an arc, (x, y), is selected from of revisions is performed which is between 1 and the num-
the queue, D(x) is revised against D(y). Here to revise ber of arcs of the form (x, y) currently present in the queue.
D(x) against D(y) means removing all values from D(x) Therefore, the number of selections (of x), and the overhead
that are not supported by any value of D(y). Revision order- of queue management, is usually less.
ing heuristics can inﬂuence the efﬁciency of arc consistency Selecting a variable x and revising it against all its neigh-
algorithms [Wallace and Freuder, 1992]. They can be clas- bours y such that (x, y) is currently present in the queue we
siﬁed into three categories: arc based, variable based [Mc- call a complete relaxation of x. Another advantage of using
Gregor, 1979], and reverse variable based [Mehta and van reverse variable based heuristics is that the queue only needs
Dongen, 2004] heuristics. The differences between them are to be updated after every effective complete relaxation and
as follows.                                           not after every effective revision, which reduces the number
  Arc based revision ordering heuristics are the most com- of times the arcs are added to the queue. Overall fewer revi-
monly presented. Given some criterion they select an arc sions are performed which results in saving support checks.
(x, y) for the next revision. Selecting the best arc can be Pseudo-code for AC-3 equipped with reverse variable based
expensive [van Dongen and Mehta, 2004]. Each selected arc revision ordering heuristic is depicted in Figure 1. The revise
corresponds to exactly one revision. Since there may be many function upon which AC-3 depends is depicted in Figure 4.
revisions there may be many selections and this may result in In Figure 1, if D(x) was changed after a complete relax-
a signiﬁcant overhead. When arc based heuristics are used, ation and if this was the result of only one effective revi-
the queue needs to be updated after every effective revision sion (effective revisions = 1), which happened to be against
unless the domain of a variable becomes empty. Many up- D(y00), then all arcs of the form (y0, x) where y0 is a neigh-
dates can be an overhead too.                         bour of x and y0 6= y00 are added to the queue. However,
  Variable based heuristics [McGregor, 1979] ﬁrst select a if D(x) was changed as the result of more than one effec-
variable x and then repeatedly select arcs of the form (y, x) tive revision (effective revisions > 1) then all arcs of the
for the next revision until no more such arcs exist or some form (y0, x) where y0 is a neighbour of x are added to the
D(y) becomes empty. They may be regarded as propaga-  queue.  Modulo constraint propagation effects this avoidsqueue maintenance overhead.                                              w[y,x,b]              w[y,x,b]

                                                            a1          b1 1      a1          b1 1

4   A  Support  Condition                                   a2          b2 1      a2          b2 3
                                                            a           b  1      a           b  3
Arc consistency algorithms are based on the notion of sup-   3          3          3           3
port. Most arc consistency algorithms proposed so far put a a4          b4 1      a4          b4 1
lot of effort in identifying a support to conﬁrm the existence x       y            x        y
of a support. Identifying the support is more than is needed to Case 1                 Case 2
guarantee that a value is supportable: knowing that a support
exists is enough. Optimal algorithms like AC-2001 and AC-6 Figure 3: Support inference using different weights
always keep track of the last known support for each value.
When this support is lost they try to identify the next support.
                                                      then (x, a) is supported by y:
AC-4 is the only algorithm that conﬁrms the existence of a

support by not identifying it during the course of search but                                   0
its inefﬁciency lies in its space complexity O(e d2) and the          w[ y, x, b ] >     w[ y, x, b ] . (2)
                                                               X                  0 X
necessity of maintaining huge data structures during search. (a,b) ∈ Cxy         b ∈ R(y)
  We propose the notion of a support condition (SC), which We call the left hand side of Equation (2) the cumulative
guarantees that a value has some support. The key point is weight of (x, a) with respect to y: it is equal to the sum of the
that it guarantees the existence of a support without identi- weights of the supports of (x, a) in D (y). We call the right
fying it and without storing and maintaining support values.                         ac
                                                      hand side of Equation (2) the removed weight from Dac(y)
Let Cxy be the constraint between x and y, let a ∈ D(x) with respect to x: it is equal to the sum of the weights of the
(also denoted as (x, a)) and let scount[ x, y, a ] be the num-
                                                      values removed from Dac(y) with respect to x. Note that if
ber of supports of (x, a) in Dac(y). A value a ∈ D(x) is the weight associated with each arc-value pair is 1 then Equa-
supported by y if it has at least one support in D(y). Further- tion (1) is a special case of the condition in Equation (2). In
more if R(y) = Dac(y) \ D(y) are the removed values from that case the cumulative weight of (x, a) with respect to y is
the arc-consistent domain of y then | R(y) | is an upper bound
                                                      equal to the number of supports of (x, a) in Dac(y) and the
on the number of lost supports of (x, a) in y. Therefore, if the removed weight from D (y) is equal to the number of val-
following condition is true then (x, a) is supported by y:                 ac
                                                      ues removed from Dac(y). We call the condition in Equation
              scount[ x, y, a ] > | R(y) |      (1)   (2) a Support Condition (SC). A SC guarantees the existence
                                                      of a support and may allow to save many checks.
In order to use the Equation (1) in any coarse-grained MAC We illustrate the use of SC to infer the existence of a sup-
algorithm, for each arc-value pair involving the arc (x, y) and port by using the example as shown in Figure 3. In Figure 3
the value a on x, scount[ x, y, a ] must be assigned the num- (Case 1), the weight associated with each value is 1. The cu-
ber of supports of (x, a) in Dac(y). Once these support coun- mulative weight of a1 with respect to y is 2: it is equal to the
ters are initialised they remain static during search. Hence, number of the supports of a1 in Dac(y). Now assume that b1
there is no overhead of maintaining them. The pseudo-code is deleted from Dac(y) then the removed weight from Dac(y)
for computing the support count for each arc-value pair is with respect to x is 1: it equals | R(y) |. It can be inferred that
depicted in Figure 2. In the algorithm, last[ x, y, a ] stores a1 still has a support in D(y) since the cumulative weight of
AC-2001’s last known support for (x, a) in y. Note that the a1 is greater than the removed weight from Dac(y). Simi-
algorithm does not repeat checks and uses the bidirectional larly, a support for any value in D(x) can be inferred if any
property of constraints. For easy problems initialising sup- single value is removed from Dac(y). If any two values are
port counters can be an overhead in terms of support checks. removed from Dac(y) then the removed weight from Dac(y)
However, it can save time and checks for hard problems. is 2. Here a support cannot be inferred for any value of D(x)
  Next we generalise the idea presented in the Equation (1). because the cumulative weight of each value in D(x) is 2,
Here we associate a weight (non-negative integer) w[ x, y, a ] which is not greater than the removed weight.
with each arc-value pair. If the following condition is true If other weights are used and if SC holds for any value a ∈
                                                      D(x) then a support is still guaranteed to exist in D(y). Let
     Function InitialiseSupportCounters ( )           us examine Case 2 of Figure 3 where the weight assigned to
       call AC-2001                                   each value in Dac(y) is its own support count with respect to
       if the problem is arc-consistent then          x. Now  the cumulative weight of a is 4 since the weights
        for each (x, y) ∈ G do                                                       1
          for each a ∈ Dac(x) do                      of the supports of b1 and b2 are 1 and 3 respectively. Like
            scount[ x, y, a ] := 1                    Case 1, if any single value is removed from Dac(y), a support
        for each (x, y) ∈ G such that x < y do        can be inferred for all values in D(x). If the two values b
          for each a ∈ Dac(x) do                                                                        1
            for each b ∈ Dac(y) such that b > last[ x, y, a ] do and b4 are removed then the removed weight from Dac(y) is
               if b supports a then begin             2. Unlike Case 1 a support can be inferred for all the values
                scount[ x, y, a ] := scount[ x, y, a ] + 1
                scount[ y, x, b ] := scount[ y, x, b ] + 1 of x. In another situation if b1 and b2 are removed then also
               end                                    the existence of support can be inferred for at least a2 and a3
                                                      since their cumulative weights are 6 and the removed weight
       Figure 2: Initialisation of support counters.  from Dac(y) is 4. We will see further on that using support   Function revise(x, y, var changex)
   begin                                              ifeﬀective revisions = 1 then
                                                                  0   0              0   00
     changex := False                                  Q := Q ∪ { (y , x) | y is a neighbour of x ∧ y 6= y ∧
                                                                         0         0                 0 0
     for each a ∈ D(x) do                              min{ P a,b ∈ C w[x, y , b] : a ∈ D(y )} ≤ P 0 ∈ 0 w[x, y , b ]}
                                          0                  ( )  y0 x                    b  R(y )
       if P        w[ y, x, b ] > P 0 w[ y, x, b ] then
          ( a,b ) ∈ Cxy       b ∈ R(y)                else if eﬀective revisions > 1 then
         skip /* a is supported */                     Q := Q ∪ { (y0, x) | y0 is a neighbour of x ∧
       else if @b ∈ D(y) such that b supports a then begin               0         0                 0 0
                                                       min{ P a,b ∈ C w[x, y , b] : a ∈ D(y )} ≤ P 0 ∈ 0 w[x, y , b ]}
         D(x) := D(x) \ { a }                                ( )  y0 x                    b  R(y )
         changex := True
       end
   end;                                                Figure 5: Enforcing RC while adding the arcs to the queue.

          Figure 4: Algorithm revise of AC-3.
                                                        Note that both SC and RC are presented in such a way that
                                                      the idea is made as clear as possible. This should not be
counts as weights lets SCs save more checks.
                                                      taken as the real implementation. We compute the cumula-
  The revise function for AC-3 is depicted in Figure 4. This
function is slightly different from its original version because tive weight for each arc-value pair before the search starts.
                                                      Whenever a value is deleted from the domain of a variable
it uses SC to avoid a series of checks for which it can be
known in advance that it will eventually lead to a support. x, we update the removed weight for all the arcs of the form
                                                          . If there is a change in the domain size of a variable
The use of SC is not restricted to AC-3. It can be integrated in (·, x)
any coarse-grained algorithm.                         x after a complete relaxation, we update the LCW for all the
                                                      arcs of the form (x, ·). The space complexity of storing the
5  A  Revision  Condition                             cumulative weights is O(e d). The space complexity of stor-
                                                      ing the removed weights and the LCWs for all the arcs is
The support check is the core operation carried out by arc O(e) but it may increases to O(e n) during search. The over-
consistency algorithms. To reduce the number of checks, al- all space complexity of using SC in conjunction with RC is
gorithms proposed so far (1) perform viability checks like in O(e d + e n) = O(e max(d, n)).
AC-2001, (2) check the status of counters like in AC-4, (3) Updating the least cumulative weight for all the arcs of the
make some inference based on the supports stored in auxil- form (x, ·), if there is a change in the domain of x after every
iary data structures like in AC-7, or (4) carry out SCs as men- complete relaxation can be an overhead. The other option is
tioned in Section 4. We call all these tests auxiliary support to update the LCW of only one arc (x, y) while revising D(x)
checks (ASCs). When support checks are not too expensive against D(y) instead of all the arcs of the form (x, ·) after
then ASCs can be an overhead and reducing the checks alone a complete relaxation. This can be done cheaply and may
does not always help in reducing the solution time.   avoid the addition of the arc (x, y) to the queue in future. This
  All the improvements proposed so far to reduce support can be considered as a weak version of a revision condition
checks are done at ﬁne level of granularity. We propose a (WRC) because the LCW is not maintained for all the arcs. The
coarser check at arc level. The idea is that we will use this disadvantage here is that not all possible ineffective revisions
coarser check to avoid a complete revision. This will not will be saved then can be saved by RC.
only save support checks but will also avoid auxiliary support Independent work by [Boussemart et al., 2004] uses
checks. For a given arc  , if the least cumulative weight
                    (x, y)                                                                 0      , which
                                                      min{   ( a,b )∈Cxy 1 : a ∈ Dac(x) } > b ∈ R(y) 1
(LCW) of the values of D(x) with respect to y is greater than is a specialP case of Equation (3). Note Pthat in their setting
the removed weight from     then all the values of
                     Dac(y)                   D(x)    w[x, y, a] is 1 for each arc-value pair and the above condition
are supported by y. This can be expressed as follows: is exploited after determining the arc for the revision. For a
                                                      given arc (x, y), this condition examines the least cumulative
                                              0     weight (the least support count) of the values of and
min        w[ y, x, b ] : a ∈ D(x) >  w[ y, x, b ] .                                         Dac(x)
        X                          0 X
     ( a,b )∈Cxy                  b ∈ R(y)            not of D(x) with respect to y as is done in Equation (3). We
                                              (3)   call this condition a static version of a revision condition be-
We call this condition a Revision Condition (RC). The RC can cause the least cumulative weight is not updated for any arc
be used by all coarse-grained arc consistency algorithms to during the course of search. It remains static for all the arcs.
reduce unnecessary revisions while maintaining full arc con- This may not allow to avoid as many ineffective revisions as
sistency during search.                               can be avoided by RC.
  If a RC holds then it can be exploited after selecting the arc
(x, y) or when arcs are added to the queue. In the former case 6 Experimental Results
the corresponding revision is not carried out and in the latter
case the arc (x, y) is not added to the queue. We will use the 6.1 Introduction
revision condition by tightening the condition for adding the In this section, we shall present some results to prove the
arcs to the queue: arcs should only be added if RC does not practical efﬁciency of SC, RC and WRC. We implemented
hold. This is depicted in Figure 5. With this implementation them in MAC-3 and MAC-2001 equipped with comp [van
the advantages of using the RC are threefold: (a) it will reduce Dongen, 2004] as a revision ordering heuristic. We denote
the number of arcs that have to be added to the queue, (b) it the arc based, reverse variable based, and the variable based
will reduce the number of arcs that have to be selected from heuristic comp as arc:comp, rev:comp, and var:comp respec-
the queue, and (c) it will reduce the total number of revisions. tively. The details about these heuristics can be found in                                                  MAC-3                MAC-2001
                          Heuristic Condition Weight Checks Time Revisions Checks Time
                                 -      -     79,644,545 25.39 16,627,343 20,876,139 27.20
                          arc:comp SC   1     10,226,932 23.22 16,627,343 7,122,238 25.52
                                 WRC    1     28,632,454 15.51 6,944,423 17,188,921 18.56
                                 SC + WRC 1   10,226,932 14.49 6,944,423 7,122,238 16.46
                                 -      -     74,985,422 21.76 15,297,543 20,587,469 22.88
                                 SC     1     10,056,858 19.34 15,297,543 7,064,437 21.23
                                 SC     scount 7,149,704 26.59 15,297,543 5,569,970 29.14
                                 WRC    1     28,136,221 13.44 6,708,679 17,063,043 15.80
                                 WRC    scount 18,548,689 16.21 4,641,513 12,614,384 19.04
                          rev:comp SC + WRC 1 10,056,858 12.21 6,708,679 7,064,437 13.80
                                 SC + WRC scount 7,149,704 15.48 4,641,513 5,569,970 17.44
                                 RC     1     22,256,549 12.74 5,153,349 13,971,627 21.73
                                 RC     scount 13,902,999 18.03 3,276,247 9,724,569 20.20
                                 SC + RC 1    10,056,858 12.82 5,153,349 7,064,437 21.45
                                 SC + RC scount 7,149,704 18.22 3,276,247 5,569,970 20.27

                                  Table 1: Results for the random problems.

                                               MAC-3               MAC-2001
                             Heuristic Conditions Checks Time Revisions Checks Time
                                    -       56,431,728 2.656 2,154,081 10,412,277 2.661
                             arc:comp SC    36,832,553 2.370 2,154,081 15,217,649 2.626
                                    WRC     37,250,230 1.771 809,623 14,886,826 1.763
                                    SC + WRC 36,832,553 1.755 809,623 15,217,649 1.824
                                    -       42,519,506 1.931 1,602,603 10,332,998 2.082
                                    SC      28,429,473 1.750 1,602,603 15,147,054 2.114
                             rev:comp WRC   28,829,358 1.380 752,277 14,835,844 1.243
                                    SC + WRC 28,429,473 1.382 752,277 15,147,054 1.270
                                    RC      28,818,246 1.448 750,789 14,825,485 1.450
                                    SC + RC 28,429,473 1.467 750,789 15,147,054 1.475

                                      Table 2: Results for RLFAP#11.

[Mehta and van Dongen, 2004]. During search all MACs vis- and RC are especially effective for difﬁcult problems that take
ited the same nodes in the search tree. They were equipped a lot of time. The original version of MAC-3 requires 3.81
with a dom/deg variable ordering heuristic with a lexico- times more checks than the original version of MAC-2001
graphical tie breaker, where dom is the domain size and deg is but it reduces to 1.28 after using SC. It is interesting to
the original degree of a variable. All algorithms were written note that for the random problem and the quasigroup prob-
in C. The experiments were carried out on linux on a PC Pen- lem MAC-3 with SC requires fewer checks than the original
tium III (2.266 GHz processor and 256 MB RAM). Perfor- version of MAC-2001. Remember that MAC-3 uses a non-
mance is measured in terms of the number of support checks, optimal algorithm AC-3 while MAC-2001 uses an optimal al-
the CPU time in seconds, and the number of revisions. gorithm AC-2001 but that they usually repeat checks in differ-
  We  experimented with random problems which were    ent branches of the search. In case of RLFAP #11 when SC
generated by Frost et al.’s model B generator [Gent   is used in MAC-2001 there is an improvement in the number
et al., 2001] (http://www.lirmm.fr/˜bessiere/         of checks required during the course of search but not in the
generator.html).   In this model a random CSP instance total number of checks. This is caused by the initialisation of
is characterised by h n, d, p1, p2 i where n is the number of the cummulative weights.
variables, d the uniform domain size, p1 the average den- MAC-2001 always spends fewer checks than MAC-3 but
sity, and p2 the uniform tightness. For each combination of requires more time. This corresponds to the results presented
hn, d, p1, p2i, 50 random problems were generated. Table 1 in [van Dongen, 2004]. Using SC in MAC-3 and MAC-2001
shows the mean results for h50, 10, 1.0, 0.13i which is located reduces the number of checks but this is not reﬂected in the
at the phase transition. In Table 1, under the column labelled solution time. In fact there is only a marginal saving and in
as Weight, 1 denotes that the weight associated with each arc- some cases it may consume more time. This shows that when
value pair is 1 (also the default value) while scount denotes checks are cheap carrying out ASCs to reduce the checks is
that the weight associated with each arc-value pair is its own not really a great help in reducing the overall solution time.
support count. Table 2 corresponds to the real world instance Both RC and WRC avoid at least 50% of the total revisions.
RLFAP  #11 which came from the CELAR suite. Table 3 cor- RCs are able to save more ineffective revisions than WRCs.
responds to a quasigroup with holes problem [Achlioptas et Satisfying a RC or a WRC avoids a complete revision that not
al., 2000] of order 10 and 74 holes.                  only reduces checks but also ACSs and the overhead of queue
                                                      management.  When  rev:comp and WRC are used together
6.2  Discussion                                       in MAC-3 or in MAC-2001 there is on average 50% reduc-
One can immediately notice that SC reduces the number of tion in the solution time compared to the original algorithms
checks required by MAC-3 and MAC-2001.  For instance  equipped with arc:comp, which is signiﬁcant. Results for
for the random problem, checks required by MAC-3 and  arc:comp with RC are not presented due to the space restric-
MAC-2001 are reduced by 90% and 72% respectively, when tion. The overhead to maintain LCWs is less with rev:comp
the weight associated with each arc-value pair is its own sup- because they need to be updated after every effective com-
port count. We observed that for the random problems SC plete relaxation but in case of arc:comp and var:comp after