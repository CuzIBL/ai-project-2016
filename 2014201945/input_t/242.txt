                     Imitation Learning of Team-play in Multiagent System 
                                   based on Hidden Markov Modeling 

                                                      Itsuki Noda 
                         Cyber Assist Research Center, AIST and PRESTO, JST, Japan 
                                               i.noda@aist.go.jp 


                        Abstract                               of overall behavior of agents. For example, in soccer, a 'drib•
                                                               ble' is a play to achieve the intention 'guide a ball in a cer•
     This paper addresses agents' intentions as building       tain direction', which consists of atomic actions like 'turn', 
     blocks of imitation learning that abstract local sit•     'dash', 'kick', and so on. A play for the intention is also an in•
     uations of the agent, and proposes a hierarchical         dividual behavior without collaboration with other agents be•
     hidden Markov model (HMM) to represent coop•              cause an intention is an individual idea. As shown below, an 
     erative behaviors of teamworks. The key of the            intention and the corresponding play are used as a main trig•
     proposed model is introduction of gate probabilities      ger to synchronize team-plays among multiple agents. This 
     that restrict transition among agents' intentions ac•     means that the intention is treated as a kind of partial condi•
     cording to others' intentions. Using these probabil•      tion of the world. 
     ities, the framework can control transitions flexibly 
     among basic behaviors in a cooperative behavior.          2.2 Team-play 
                                                               We suppose that team-play is a collection of plays performed 
1 Introduction                                                 by multiple agents to achieve a certain purpose. As men•
Imitation learning is considered to be a method to acquire     tioned in the previous section, an intention is an individual 
complex human and agent behaviors and as a way to pro•         idea. This means that multiple agents who do not change their 
vide seeds for further learning [KI93; Sch99; MK98]. While     intentions can not perform a team-play because they have no 
those studies have focused on imitating behaviors of single    way to synchronize their plays. Instead, we assume that they 
agents, few works address imitation for teamwork among         can synchronize their plays by changing their intentions ac•
multiple agents because the complexity of the world state      cording to situations of environments and intentions of other 
increases drastically in multi-agent systems. On the other     agents. For example, in soccer, when two players (passer and 
hand, stochastic models like hidden Markov models (HMM)        receiver) guide a ball by dribble and pass, players will change 
have been studied as tools to model and to represent multi-    their intentions as follows: 
agent/human interactions [ORP00; IB99]. It is, however, hard 
to apply these stochastic models to imitate teamworks by ob•
servation because of the complexity of the model of multiple 
agents. This study focuses upon intentions of agents as build•
ing blocks of an abstract state of the local world for the agent 
in order to overcome the problem. Using intention, I for•
malize teamwork and propose a hierarchical hidden Markov 
model for imitation learning of teamwork.                      In this example, the passer and the receiver initially have 
                                                               intentions 'dribbling' and 'supporting', respectively. Then, 
2 Teamwork and Imitation                                       the passer changes the intention to 'seek-receiver', followed 
                                                               by the receiver's change to 'free-run', the passer's change to 
2.1 Intention and Play                                         'pass', and so on. Play synchronization is represented as con•
We suppose that an intention is a short-term idea to achieve   ditions when agents can change the intention. In the example, 
a certain condition from another condition. For example, in    the passer changes its intention from 'seek-receiver' to 'pass' 
soccer, the intention 'to guide a ball in a certain direction' when the teammate's intention is 'free-run'. 
is an idea to move to a certain direction with the ball. We 
assume that an intention is an individual idea; therefore, an  2.3 Imitation Learning of Team-play 
agent does not pay attention to others' efforts to achieve their The imitation learning of a teamplay is formalized as follows: 
intention.                                                     (1) Observation: to observe behaviors of mentor agents and 
  A play is postulated as a sequence of atomic actions to      estimate what intention each agent has at each time step. (2) 
achieve a single intention. The play is a basic building block Extraction: to extract conditions prevailing when each agent 


1470                                                                                                   POSTER PAPERS changes intentions. A condition is represented as a conjunc•   the agent calculate a likelihood of the state snj at a certain 
tion of others' intentions. (3) Generation: to generate a se•  time t + 1 according to the following equation: 
quence of intentions according to changes of environment and 
others' intentions. In the second step of this process, the in-
                                                                                                                       (1) 
tention plays an important role: that is, conditions of changes 
of intentions. As described in Section 2.1, we consider that 
intention can represent world conditions. In addition to it,   , where is a partially observed output value in v at time 
we use only intentions to construct rules for agents to change t + L 
their intentions. 
                                                               4 Experiments 
3 Hierarchical Hidden Markov Model for                         I applied the framework to collaborative play of soccer. The 
     Agents                                                    demonstration by mentors is dribble and pass play as shown 
                                                               in Fig. 1: A player starts to dribble from the center of the 
3.1 Single Behavior Model                                      left half field and brings the ball to the right half. At the 
We formalize behaviors of a basic play m performed by a        same time, another player runs parallel along the upper (or 
single agent as a Moore-type HMM as follows:                   lower) side of the field supporting the dribbling player. Then, 
                                                               the first player slows to look-up the second player; it then 
                                                              passes the ball to that player. Simultaneously, the second 
                                                              player starts to dash to the ball and dribbles after receiving 
                                                               the ball. After the pass, the first player exchanges roles with 
                                                               the teammate so that it becomes a supporting player for the 
                                                               second player. 

                                                                 To imitate this demonstration, 1 trained six HMMss to 
                                                               model'dribble', 'slow-down and look-up', 'pass', 'free-run', 

                                                               'chase-ball', and 'support'. Each of HJMMss has 5 states. The 
3.2 Cooperative Behavior Model                                 output of these HMM's consists of local situations (the rela•
As discussed in the previous section, we consider that team-  tive position and the velocity to the ball) and agent's actions 
play consists of a sequence of intentions of multiple agents.  ('turn', 'dash', 'small-kick', 'long-kick\ 'trap', and 'look'). 
This means that cooperative behavior of a single agent in a   Note that there is no information about others' situations for 
team of agents is considered as transitions among several ba•  output of HMMss. As described in Section 2.2, others' situ•
                                                               ations are taken into account during the Extraction phase in 
sic plays (HMMS). Therefore, we formalize cooperative be•
havior as the following modified Mealy-type HMM,               learning. 
                                                                 Two HMMcs for agent X (the first player) and Y (the sec•
           HMMC = {M,U,E,F,G,H),                               ond player) are constructed after the training of the HMJVTs. 
                                                              Then, the learner observes behaviors of the mentor and ad•

                                                              justs probabilities of the HMMcs. 
                                                                 Figure 2 shows result of observation and estimation. This 
                                                              figure shows the relative likelihood of each play state for each 
                                                              agent at each timestep estimated by Observation phase. In 
                                                              this figure, there are 12 rows of small squares: upper 6 rows 
                                                              correspond 6 plays of the first player (agent X), and the rest 
                                                              6 are plays for the second player (agent Y). Each row corre•
                                                              sponds to a play D, K, P, F, C, and S, each of which means 
                                                               'dribble (D)', 'slow-down and look-up (K)\ 'pass (P)', 'free-
                                                              run (F)', 'chase-ball (C)', and 'support (S)\ respectively. In 
                                                              each row, a column consists of 5 small squares each of which 

                                                              corresponds a state of HMMsfor one of the 6 plays at a certain 
                                                              timestep. The ratio of black area in the square indicates the 

                                                              relative likelihood with which the state of the HMMsis active 
                                                              at the timestep. Columns are aligned along with time. So, a 
                                                              horizontal line of squares means changes of likelihood of a 

3.3 Joint-Behavior Model                                      state of HMMS. From this figure, we can see that the learner 

Finally, we coupled multiple HMMcs, each of which repre•      estimates that the agent X starts the play with the intention 
sents the behavior of an agent. Coupling is represented by    of'dribble', followed by 'slow-down', 'pass' and 'support', 
gate probabilities H. For example, when agent X and agent Y   while the player Y starts 'support' play, followd by 'chase-
are collaborating with each other, the gate probability       ball' and 'dribble' plays. 

in HMMC for agent X indicates the probability that agent Y       After the training by the Observation, the learner can gen•
is performing play u at time t when agent X changes the play  erate behaviors similar to the demonstration by using the ac•
from m to n during time Using the gate probability,           quired probabilities of the HMlVTas shown in Fig. 3. This 


POSTER PAPERS                                                                                                       1471  Figure 1: Exp. 3: Dribble and 
 Pass Play by Mentor 
                                Figure 2: Exp. 3: Result of Recognition of Men-  Figure 3: Exp.3: State Transitions Gener•
                                tor's Behaviors                                  ated by Learned HMM 

 figure is constructed in the same way as Fig. 2, but only one   One important issue is the design of the intention. In the 
 square is filled in a timestep because the learner decides one proposed model, intentions play various important roles like 
 of the possible states according to the likelihood shown in   chanking of the actions and conditions of world state. There•
 Eq. 1. In this example, although the learner sometimes gener• fore, we must design intentions carefully so that team-plays 
 ates wrong state transitions, for example a transition to states can be represented flexibly. 
 to the 'free-run' play in agent Y during agent X is doing 
 'slow-down', it recovers to the suitable transitions and con• References 
 tinues to imitate the demonstrator. This shows robustness 
                                                               [GJ97]    Zoubin Ghahramani and Michael I. Jordan. Fac•
 of the model against accidents. Because the model is cou•
                                                                         torial hidden markov models. Machine Learning, 
 pled loosely with world and other's states by output probabil•
 ities of HMM, it can permit variation and misunderstanding              29:245 275, 1997. 
 of world and others' states.                                  [IB99]    Y. A. Ivanov and A. F. Bobick. Recognition of 
                                                                         multi-agent interaction in video surveillance. In In•
 5 Discussion                                                            ternational Conference on Computer Vision (Vol•
                                                                         ume I), pages 169-176. IEEE, Sep. 1999. 
 There are several works on coupling HMMs that can repre•
 sent combinational probabilistic phenomena like multi-agent   LJGJS99] Michael 1. Jordan, Zoubin Ghahramani, Tommi 
 collaboration [JGS97; GJ97; JGJS99]. In these works, prob•              Jaakkola, and Lawrence K. Saul. An introduction 
 abilistic relation among several HMMs (agents) are repre•               to variational methods for graphical models. Ma•
 sented as state-transition probabilities, such that the amount          chine Learning, 37(2): 183-233, 1999. 
 of memory complexity increases exponentially. This is a se•   [JGS97] Michael I. Jordan, Zoubin Ghahramani, and 
 rious problem for imitation learning because we assume that             Lawrence K. Saul. Hidden markov decision trees. 
 the number of examples for imitation is small. In our model,            In Michael C. Mozer, Michael I. Jordan, and 
 the relation among agents is represented by gate probabilities          Thomas Petsche, editors, Advances in Neural In•
 H, in which others' states are treated as outputs instead of           formation Processing Systems, volume 9, page 
 as conditions of state transition. Using them, the likelihoods          501. The MIT Press, 1997. 
 of state-transitions are simplified as products of several prob• [KJ93] Y. Kuniyoshi and H. Inoue. Qualitative recogni•
 abilities (Eq. 1). In addition, detailed states of other agents         tion of ongoing human action sequences. In Proc. 
 are abstracted by play (intention). As a result, the number            IJCAI93, pages 1600-1609, 1993. 
 of parameters is reduced drastically, so that learning requires 
 very small number of examples as shown in above examples.     [MK98] Hiroyuki Miyamoto and Mitsuo Kawato. A ten•
Although such simplification may decrease flexibility of rep•           nis serve and upswing learning robot based on 
 resentation as a probabilistic model, experiments show that            bi-directional theory. Neural Networks, 11:1331-
 the proposed model has enough power to represent team-play              1344, 1998. 
 among agents.                                                 [ORP00] Nuria M. Oliver, Barbara Rosario, and Alex Pent-
   Intention in the model brings another aspect to communi•              land. A bayesian computer vision system for 
cation among agents. We assume that there are no mutual                 modeling human interactions. IEEE Transactions 
communication in the proposed model. However, we can in•                on Pattern Analysis and Machine Intelligence, 
troduce communication as a bypass of observation and esti•              22(8):831-843, 2000. 
mation of other's intention (play). The proposed model will 
                                                               [Sch99] Stefan Schaal. Is imitation learning the route to 
be able to provide criteria for when an agent should inform 
                                                                        humanoid robots? Trends in Cognitive Sciences, 
their intention to others by comparing agents' actual inten•
                                                                        3(6):233-242, Jun. 1999. 
tions and estimated intention of the agent itself by simulating 
 its own HMM1. 


 1472                                                                                                 POSTER PAPERS 