                   Where is . •. ? Learning and Utilizing Motion Patterns 
                                  of Persons with Mobile Robots 

                 Grzegorz Cielniak Maren Bennewitz Wolfram Burgard 
          department of Computer Science, University of Freiburg, 79110 Freiburg, Germany* 
                  Department of Technology, Orebro University, 70182 Orebro, Sweden 


                     Abstract                          recorded with laser-range finders. Furthermore, we demon•
                                                       strate how the learned models can be used to predict positions 
     Whenever people move through their environments   of persons. 
     they do not move randomly. Instead, they usually    Recently, a variety of service robots has been developed 
     follow specific trajectories or motion patterns cor• that have been designed to operate in populated environ•
     responding to their intentions. Knowledge about   ments. These robots for example, have been deployed in hos•
     such patterns may enable a mobile robot to robustly pitals [6], museums [4], office buildings [1], and department 
     keep track of persons in its environment or to im• stores [51 where they perform various services e.g., deliver, 
    prove its obstacle avoidance behavior. This paper  educate, entertain [141 or assist people [13, 8, 12]. A variety 
     proposes a technique for learning collections of tra• of techniques has been developed that allows a robot to track 
    jectories that characterize typical motion patterns people in its vicinity [15, 7]. Additionally, several authors 
    of persons. Data recorded with laser-range finders have used models of peopic's motions to adapt the behavior 
     is clustered using the expectation maximization al• of a mobile platform according to predicted movements [18, 
    gorithm. Based on the result of the clustering pro• 17, 9]. These approaches, however, assume that a motion 
    cess we derive a Hidden Markov Model (HMM).        model is given. They provide no means to learn the parame•
    This HMM is able to estimate the current and fu•   ters of the motion behavior of persons. Bui et al. proposed an 
    ture positions of multiple persons given knowledge Abstract Hidden Markov Model (AHMM) to predict people's 
     about their intentions. Experimental results ob•  motion [3J. They assume that the goals and subgoals a per•
    tained with a mobile robot using laser and vision  son might have (i.e. locations the person aims to approach) 
    data collected in a typical office building with sev• are given. Our approach, in contrast, is able to learn the in•
    eral persons illustrate the reliability and robustness tentions and to automatically derive the parameters of the un•
    of the approach. We also demonstrate that our      derlying HMM. The technique described in this paper is an 
    model provides better estimates than an HMM di•    extension of the approach recently proposed by Bennewitz et 
    rectly learned from the data.                      al. [2]. We describe how to learn the intentions of persons and 
                                                       how to derive an HMM from the corresponding motion pat•
                                                       terns. This Hidden Markov Model allows the robot to main•
1 Introduction                                         tain a belief about the current location of a person. 
                                                         The paper is organized as follows. The next section intro•
Whenever mobile robots are designed to operate in populated 
                                                       duces our approach to learn motion patterns from observed 
environments, they need to be able to perceive the people in 
                                                       trajectories and describes how we generate Hidden Markov 
their neighborhood and to adapt their behavior according to 
                                                       Models to predict motions of persons. In Section 3 we 
the activities of the people. Knowledge about typical motion 
                                                       present several experiments illustrating the robustness of our 
behaviors of persons can be used in several ways to improve 
                                                       approach for estimating the positions of single and multiple 
the behavior of a robot since it may provide better estimates 
                                                       persons using laser and vision data with a mobile robot. We 
about current positions of persons as well as allow better pre•
                                                       also give results indicating that our models provide better es•
diction of future locations. 
                                                       timates than Hidden Markov Models directly learned from 
  In this paper we present an approach for learning prob• the observations. 
abilistic motion patterns of persons. We use the EM-
algorithm 110] to simultaneously cluster trajectories belong• 2 Learning Motion Patterns 
ing to the same motion behavior and to learn the characteris•
tic motions of this behavior. We apply our technique to data When people perform their everyday activities in their envi•
                                                       ronment they do not move permanently. They usually stop at 
   *This work has partly been supported by the German Science several locations and stay there for a certain period of time, 
Foundation (DFG) under contract number SFB/TR8-03 and by the depending on what activity they are currently carrying out. 
EC under contract numbers 1ST-2000-29456 and HPMT-CT-00251. Accordingly, we assume that the input to our algorithm is a 


PERCEPTION                                                                                             909 collection of trajectories between resting            patterns which has the highest data likelihood. EM is an al•
places. The output is a number of different types of motion gorithm that iteratively maximizes expected data likelihood 
patterns a person might exhibit in its nat•           by optimizing a sequence of lower bounds. In particular it 
ural environment. Each trajectory consists of a sequence generates a sequence of models denoted as ... of 
                        of positions Accordingly, increasing data likelihood. The standard method is to use a 
    is the first position of the person when it starts leaving a so-called function which depends on two models, and 
resting area and is the destination. The task of the algo• In accordance with [2] this function is factored as follows: 
rithm described in this section is to cluster these trajectories 
into different motion behaviors and finally to derive an HMM 
from the resulting clusters. 
  Throughout this paper we assume that all trajectories have 
the same length where is chosen as the maximum length 
of all trajectories. A trajectory of length is ex•
tended by linear interpolation. The learning algorithm de•
scribed below operates solely on this information and there•
fore does not take into account the velocities of the persons 
during the learning phase. In our experiments, we never 
found evidence that the walking speed of a person depends 
on its intention. However, one way to incorporate veloci•
ties is to introduce further dimensions to the state variables. 
The necessary changes to our clustering algorithm are then starting with some initial model Whenever the 
straightforward.                                      function is continuous as in our case, the EM algorithm con•
                                                      verges at least to a local maximum. 
2.1 Motion Patterns 
                                                        In particular, the optimization involves two steps: calculat•
We begin with the description of our model of motion pat• ing the expectations given the current model 
terns, which is subsequently estimated from data using EM. , and finding the new model that has the maximum 
Within this paper we assume that a person engages in M dif• expected data log likelihood under these expectations. The 
ferent types of motion patterns. A motion pattern denoted as first of these two steps is typically referred to as the E-step 
   where M is represented by K probability dis•
                                                      (short for: expectation step), and the latter as the M-step 
tributions For each the probability distri•
                                                      (short for: maximization step). 
bution is computed based on subse•
quent positions on the trajectories. Accordingly,       To calculate the expectations we apply 
specifies the probability that the person is at location alter Bayes' rule, obeying independence assumptions between dif•
                  steps given that it is engaged in motion ferent data trajectories: 
pattern Thus, we calculate the likelihood of a trajectory 
under the motion patternas 

                                                (1) 
                                                      where the normalization constants and ensure that the 
2.2 Expectation Maximization                          expectations sum up to 1 over all If we combine (1) and 
In essence, our approach seeks to identify a model that max• (4) utilizing the fact that the distributions are represented by 
imizes the likelihood of the data. To define the likelihood of Gaussians we obtain: 
the data under the model it will be useful to introduce a 
set of correspondence variables denoted as Here i is the 
index of the trajectory and is the index of the motion                                                (5) 
pattern Each correspondence is a binary variable. It 
is 1 if and only if the th trajectory corresponds to the th 
motion pattern. If we think of a motion pattern as a specific Finally, the M-step calculates a new model by max•
motion activity a person might be engaged in, then is 1 if imizing the expected likelihood. Technically, this is done by 
person was engaged in motion activity in trajectory   computing for every motion pattern m and for each probabil•
  In the sequel, we will denote the set of all correspon• ity distribution a new mean We thereby 
dence variables for the data item by that is,         consider the expectations computed in the E-
              For any data item the fact that exactly one step: 
of its correspondence variable is 1 leads to 
  Throughout this paper we assume that each motion pat•
                                                                                                       (6) 
tern is represented by K Gaussian distributions with a fixed 
standard deviation The goal is to find the set of motion 


                                                                                             PERCEPTION  2.3 Estimating the Number of Model Components         sequence of positions covered by the person during that mo•
 Since in general the correct number of motion patterns is not tion. When computing these trajectories, we ignore positions 
 known in advance, we need to determine this quantity during which lie closer than 15cm to each other. 
the learning phase. If the number of motion patterns is wrong, 
 we can distinguish two different situations. First, if there are 2.5 Deriving Hidden Markov Models from 
 too few motion patterns there must be trajectories, that are Learned Intentions 
 not explained well by any of the current motion patterns. On Once the intentions of the persons have been learned, we can 
 the other hand, if there are too many motion patterns then easily derive Hidden Markov Models to estimate their posi•
there must be trajectories that are explained well by different tions. To achieve this, we distinguish two types of nodes. The 
 model components. Thus, whenever the EM algorithm has first class are the initial and final nodes that correspond to the 
converged, we check whether the overall data likelihood can resting places. To connect these nodes we introduce so-called 
be improved by increasing or decreasing the number of model intermediate nodes which lie on the learned motion patterns. 
components. To limit the model complexity, during the eval• In our current system we use a sequence of intermediate 
uation we use a penalty term that depends on the number of nodes for each intention . The intermediate 
model components (see[ L2]). This avoids that our algorithm nodes are distributed over such that the distance between 
 learns a model that overfits the data, which in the worst case is two consecutive nodes is 50cm . Given this equidis•
a model with one motion pattern for every single trajectory. If tant distribution of the sub-nodes and assuming a constant 
the maximum number of iterations is reached or if the overall speed with standard deviation of the person, the transi•
evaluation cannot be improved after increasing and decreas• tion probabilities of this HMM depend on the length of 
 ing the model complexity our algorithms stops and returns the time interval between consecutive updates of the HMM 
the model with the best value found so far. In most of the as well as on and In our current system, this value is set 
experiments carried out with different data sets our approach to 5secs. Accordingly, we compute the probability 
correctly clustered the trajectories into the corresponding cat• that the person will be in node given it is currently in 
egories.                                               and given that the time has elapsed as: 

2.4 Laser-based Data Acquisition 
The EM-based learning procedure has been implemented for 
data acquired with laser-range finders. To acquire the data 
we used several laser-range scanners which were installed in Here is the value of the Gaussian 
the environment so that the relevant parts of the environment with mean and standard deviation at posi•
were covered. First, to identify persons in the laser data our tion The transition probabilities for the resting places are 
system extracts features which are local minima in the range computed based on a statistics about the average time period 
scans that come from the legs of persons. Additionally, it which elapses before the person starts this particular motion 
considers changes in consecutive scans to more reliably iden• behavior after staying in the corresponding resting area. 
tify the moving people. To keep track of a person, we use a Please note that the resulting model can be regarded as a 
Kalman filter. The state of a person at time step is repre• two-level Abstract Hidden Markov Model [3]. Whereas the 
sented by a vector . Whereas x and represent          higher-level goals of this AHMM correspond to the resting 
the position of the person, the terms and represent the places of the person, the lower-level goals are the nodes along 
velocity of the person in and -direction. Accordingly, the the paths to the high-level goals. 
prediction is carried out by the equation: 
                                                      2.6 An Application Example 
                                                      To see how our EM-based learning procedure works in prac•
                                                      tice please consider Figure 1. In this example, a model 
                                                      for nine trajectories with three different intentions has to be 
                                                      learned. The leftmost image shows the initial model (the 
where is the time elapsed between the measurement     means of the three model components are indicated by cir•
and Usually, sensors only give the position of an object. cles). In the next two images one can see the evolution of 
Since the laser range sensor does not provide the velocities the model components. The fourth image shows the model 
   and which are also part of our state space, the mea• components after convergence of the EM algorithm. As can 
surement matrix projects onto the first two components of the be seen, the trajectories are approximated quite well by the 
state space. Accordingly, the predicted measurement at step corresponding motion patterns. Finally, the rightmost picture 
     is:                                              shows the HMM derived from these motion patterns. The dif•
                                                      ferent resting places are indicated by rectangles and numbers. 
                                                      3 Experimental Results 
In a second step we identify the resting places and perform The technique described above has been implemented and 
a segmentation of the data into different slices in which the evaluated using data acquired in an unmodified office envi•
person moves. Finally, we compute the trajectories, i.e. the ronment. The experiments described in this section are de-


PERCEPTION                                                                                            911 Figure 2: Hidden Markov Model derived from learned inten• Figure 3: Evolution of the probability for a person of being in 
tions.                                                 different resting areas over the time. 

signed to illustrate that the approach can learn complex mo• recursive Bayesian update scheme: 
tion behaviors in a typical office environment. We further•
more demonstrate that the resulting models can be used to 
robustly estimate the positions of persons. Additionally, we Thereby the likelihood of an observation given 
compare the performance of the models learned by our al• the state is computed using a Gaussian distribution which 
gorithm to that of a standard HMM. Finally, we present an depends on both, the variance in the current estimate of the 
extension which allows the system to deal with multiple per• tracking system and the variance used during the learning 
sons.                                                  of the intentions. 
                                                         Figure 3 plots for different resting areas the probability that 
3.1 Learning Intentions in an Office Environment       the person stays in this particular place. Whereas the x-axis 
To evaluate our approach, we applied it to data recorded over represents the individual time steps, the y-axis indicates the 
two hours in our office environment. During the acquisition probability. The graph also includes the ground truth, which 
phase the average speed of the person was cm/sec with  is indicated by the corresponding horizontal line-pattern at 
a standard deviation cm/sec. From the resulting data   the .9 level. As can be seen from the figure, the system can 
our system extracted 129 trajectories which were successfully reliably determine the current position of the person. During 
clustered into 49 different intentions. The resulting Hidden this experiment it predicted the correct place of the person in 
Markov Model is shown in Figure 2.                     93% of the time. 
                                                      3.3 A Comparison to Standard HMMs 
3.2 Tracking a Single Person 
                                                      The second experiment is designed to demonstrate that an 
To analyze the applicability of the learned HMM for the pre• HMM that takes into account the people's intentions allows 
diction of the locations of a person, we used our mobile robot a better prediction than a standard HMM that is directly gen•
Albert, which is a B21r platform equipped with a laser range erated from the observed trajectories of the persons and that 
scanner. While the robot was moving along the corridor of does not take into a account the clustered trajectories. To 
our department with speed up to 40cm/sec, its task was to evaluate the performance of the two different approaches we 
maintain a belief about the position of the person.   chose two motion patterns from those depicted in Figure 2. 
  To incorporate observations into the HMM we apply the The first pattern is the one leading from resting place 7 via 


912                                                                                          PERCEPTION  the office containing resting place 6 to the staying area 2. 
The second one is the motion pattern between the places 6 
 and 5. We defined a standard HMM over the possible states 
of the person in the space where and were 
discretized in 15cm patches; and encode 9 possible in•
cremental moves per cell. The transition probabilities were 
 learned from the trajectories corresponding to both motion 
 patterns by counting. We randomly chose a position along 
 the trajectories of both patterns as the observed position of the 
 person. The states of the HMM were initialized according to Figure 4: Typical scene with two persons walking along the 
 the observation model (see Section 3.2). After convergence corridor (left image) and corresponding estimate of the laser-
of the HMM we measured the likelihood of the final destina• based people tracking system (right image). 
tion. We compared this value to those obtained by the HMM 
generated by our algorithm for the trajectories correspond•
 ing to these two intentions. We repeated this experiment for rate calibration between the camera and the laser and we use 
different locations along the trajectories of both patterns and a perspective projection to map the 3D position of the per•
determined the average probability of the true goal location. son in world coordinates to 2D image coordinates. Whereas 
Whereas we obtained an average of .74 with our model, the color histograms arc robust with respect to translation, ro•
corresponding value of the standard HMM is .56. This il• tation, scale and to any kind of geometric distortions they 
 lustrates that our model leads to better results and that the are sensitive to varying lighting conditions. To handle this 
 standard independence assumption of HMMs is generally not problem we consider the HSV (Hue-Saturation-Value) color 
justified in this application domain. Please note that similar space. In this color model the intensity factor can be sepa•
observations have been reported by Murphy 111]. In contrast rated so that its influence is reduced. In our current system 
to a standard HMM our model automatically chooses the tran• we simply ignore this factor. Throughout all our experiments 
sitions that correspond to the actual intention of the person. we could not find any evidence that this factor negatively af•
                                                       fected the performance of the system. The image database 
3.4 Estimating the Locations of Multiple Persons       is created beforehand. For each person it contains one his•
The final experiment described in this section is designed to togram which is built from 20 images. 
 illustrate that our models can also be used to maintain beliefs To compare a given query histogram 7 with a prototype 
about multiple persons. The major difference to the situation M in the database we use normalized intersection norm 
with a single person is that we have to be able to represent H(I, M) [161. This quantity can be computed as: 
the beliefs for the individual persons and to detect multiple 
persons in the observations. In our current system we learn                                           (11) 
an individual HMM for every person. 
  To track multiple persons in the range scans, we apply in•
dependent Kalman filters, one for each feature. To solve the where / and M are color histograms both having n. bins. One 
data association problem, we apply a nearest neighbor ap• advantage of this norm is that it also allows to compare partial 
 proach, i.e. we update a filter using the observation that views, i.e. when the person is close to the camera and only a 
 is closest to New filters are introduced for observations part of it is visible. 
from which all predictions arc too far away. Furthermore, fil•
ters are removed if no corresponding feature can be found for 
one second. 
  We also need to be able to identify a person in order to ap•
propriately update the belief about the location of that person. 
To achieve this we additionally employ the vision system of 
our robot. To identify a person, we proceed as follows: Ev•
ery time the laser-based people tracker detects a person in the 
field of view of the camera, an image is collected and follow•
ing three steps are applied: 
                                                       Figure 5: Segmentation of the two persons from the image 
  1. Segmentation: The size of a rectangular area of the im• grabbed with the camera of the robot (left image) and sim•
     age containing the person is determined.          ilarity of these segments to the data base prototypes (right 
  2. Feature extraction: We compute a color histogram for image). 
     the area selected in the previous step. 
  3. Database matching: To determine the likelihood of a To incorporate the similarity measure provided by the vi•
     particular person, we compare the histogram computed sion system into the HMM of the person we simply multi•
     in step 2 to all prototypes existing in the database. ply the likelihoods provided by the laser tracking system with 
To determine the area in the image corresponding to a feature the similarity measure H of the query histogram Is 
detected by the laser tracking system, we rely on an accu- for the segment s and the data base prototype for person 


PERCEPTION 