  Detect and Track Latent Factors with Online Nonnegative Matrix Factorization
       Bin Cao1, Dou Shen2, Jian-Tao Sun3, Xuanhui Wang4, Qiang Yang2          and Zheng Chen3
                                   1Peking university, Beijing, China
                    2Hong Kong University of Science and Technology, Hong Kong
                      3Microsoft Research Asia, 49 Zhichun Road, Beijing, China
                       4University of Illinois at Urbana, Champaign Urbana, USA
                            caobin@pku.edu.cn,   {dshen, qyang}@cse.ust.hk
                         {jtsun, zhengc}@microsoft.com, xwang20@uiuc.edu

                    Abstract                          a whole. In this paper, we will focus on the detection and
                                                      tracking of latent topics that characterize the temporal data.
    Detecting and tracking latent factors from tempo-   A key challenge of detecting and tracking the latent top-
    ral data is an important task. Most existing algo- ics is that the data may contain various topics and the topics
    rithms for latent topic detection such as Nonneg- may evolve with time. Take the reports about Asia tsunami
    ative Matrix Factorization (NMF) have been de-    disaster as an example. At the beginning, one major topic in
    signed for static data. These algorithms are unable the reports is about the “ﬁnancial aids”, but ﬁnally this topic
    to capture the dynamic nature of temporally chang- evolves to “debt” and “reconstruct” when the tsunami disas-
    ing data streams. In this paper, we put forward   ter is ending. Thus this task requires that the algorithm adapts
    an online NMF (ONMF) algorithm  to detect la-     itself to the topic evolvement quickly and accurately. How-
    tent factors and track their evolution while the data ever, most existing approaches mentioned before cannot be
    evolve. By leveraging the already detected latent directly used on this task because they are aimed at handling
    factors and the newly arriving data, the latent fac- static data. Techniques for data-stream classiﬁcation, such as
    tors are automatically and incrementally updated  [Domingos and Hulten, 2000], are not designed for handling
    to reﬂect the change of factors. Furthermore, by  text data, while techniques for topic detection in data streams
    imposing orthogonality on the detected latent fac- such as [Mei and Zhai, 2005] are not incremental in nature.
    tors, we can not only guarantee the unique solution
    of NMF but also alleviate the partial-data problem, In this paper, we tackle these challenges by improving the
    which may cause NMF to fail when the data are     basic NMF method along two directions. In previous works,
    scarce or the distribution is incomplete. Experi- the basic NMF method has been proven to be an effective
    ments on both synthesized data and real data val- method for discovering latent factors from co-occurrence data
                                                                                     [                  ]
    idate the efﬁciency and effectiveness of our ONMF by seeking the nonnegative factors Lee and Seung, 1999 .
    algorithm.                                        However, the basic NMF and its existing variations assume
                                                      the latent factors and data are static, which prohibits them
                                                      from reﬂecting the dynamic nature of data streams. In order
1  Introduction                                       to apply these NMF-based methods on data streams, where
                                                      the data continuously arrive in a sequential manner, we have
Discovering latent factors (or topics) from an evolving data to re-calculate the latent factors from scratch every time new
collection is an important topic in many applications rang- data come. This procedure is clearly time-consuming. Fur-
ing from text mining [Xu and Gong, 2004] to image pro- thermore, the factors discovered at different times are inde-
cessing [Guillamet et al., 2003]. Many existing methods, in- pendent of each other, which cannot be made to reﬂect the
cluding Nonnegative Matrix Factorization (NMF) [Lee and evolution of the factors. Thus, our ﬁrst direction is aimed at
Seung, 1999], Latent Semantic Indexing (LSI) [Deerwester improving the basic NMF method by developing an online
et al., 1990] and Probabilistic Latent Semantic Indexing version, known as ONMF, which can automatically update
(PLSI) [Hofmann, 1999] are widely used to ﬁnd latent fac- the latent factors by combining the old factors with the newly
tors from a static data collection. However, in reality, we arrived data. At the same time, ONMF can discover the con-
need to consider the dynamic nature of data when they arrive nections between the old and new factors, so that we can track
over time in the form of a stream bearing the meaningful time the evolutionary patterns of latent factors naturally. A second
stamps. For example, in the news mining problem domain, direction in our research is that when data are incomplete, the
news articles on a certain event appear one after another, re- latent factors found by NMF may be incorrect. To prevent this
ﬂecting the development of an event. By considering the time so-called partial-data problem to occur in ONMF, we impose
information of the event, we may discover the evolution pat- asetoforthogonal constraints on all the latent factors and
tern of the latent factors, which reﬂect the event’s appearance, design an orthogonal NMF algorithm. The orthogonal NMF
development, fading away, and termination. Such evolution guarantees the uniqueness of NMF decomposition, a good
patterns are beneﬁcial for the understanding of the event as property in tracking the latent factors. Experiments on both

                                                IJCAI-07
                                                  2689synthesized data and real data help validate the efﬁciency and 4 Online Nonnegative Matrix Factorization
effectiveness of our proposed approach in ONMF.       The conventional NMF assumes that the input data and the
                                                      latent factors are static. Clearly, this assumption does not
2  Related Work                                       hold for temporally changing data. A straightforward way
Our work is related to temporal data analysis and NMF. A to apply NMF on temporal data is to feed NMF with the
major direction in temporal data analysis is Topic Detection global up-to-date data matrix whenever new data come. How-
and Tracking (TDT) [Allan et al., 1998]. TDT aims at dis- ever, the approach is not efﬁcient since we need to work on
covering and threading together topically related material in a larger and larger data matrix without leveraging the previ-
streams of data. In this problem, a “topic” is actually a ous factorization results. Another method is to split the data
speciﬁc event or activity, described by a series of news sto- to sub-collections according to different time spans and ap-
ries. In our work, we assume that a news story/document ply NMF on each sub-collection independently. But this ap-
may contain multiple topics and these topics may evolve over proach cannot detect the relations between the factors from
time. [Wang et al., 2003] discussed the classiﬁcation prob- different time. To cater for temporal data, we put forward our
lem on the time series data and [Edmond H.C. Wu, 2005; proposed online NMF, or ONMF, approach.
Aggarwal et al., 2003] discussed the clustering problem.
These works are all on the “document” level rather than 4.1 ONMF Problem Formulation
“topic” level. In [Mei and Zhai, 2005], the authors conducted In order to formulate the online NMF problem, we consider
research with an aim similar to ours and proposed a Tempo- matrix factorization at two neighboring time spans t and t+1.
ral Text Mining framework. They split a document collection Assume that at time t,wehaveam × n data matrix V where
into sub-collections according to time stamps and then ex- each row represents a data sample; V is factorized by
tracted topics from each sub-collection independently using              V =  WH
a simple probabilistic mixture model. They then judged the   t +1                    p
connections among the discovered topics from different sub- At time , assume that there are new data samples that
                                                      are represented by a p × n nonnegative matrix U. Hence the
collections by KL-divergence. Different from their work, we                           V
                                                                              V =
propose an online NMF approach to extract the topics and whole data matrix becomes    U   . Now the online
exploit the relations among topics in a uniﬁed framework.
  NMF has attracted much attention in the past years [Berry NMF problem is how to integrate W and H into W and H so
et al., 2006]. Most of the previous works focused on design- that V = WH .
ing factorization algorithms for NMF [Lee and Seung, 2000]
and imposing certain constraints to improve NMF’s perfor- 4.2 Our Solution to ONMF Problem
mance [Hoyer, 2004; J. Piper and Gifﬁn, 2004; Li et al., ]. The following theorem makes it possible to design an online
There is also some work on accelerating the algorithms’ con- version of NMF.
           [              ]
vergence rate Wild et al., 2004 . To our best knowledge, this Theorem 1. (Full-Rank Decomposition Theorem)
paper is the ﬁrst attempt to extend NMF to an online setting If V = WH and V = W H are both full rank decompo-
for exploiting temporal data.                         sitions, then there exists one invertible matrix P satisfying
                                                      W  = W P and H = P −1H.
3  Nonnegative Matrix Factorization (NMF)
                                                      Proof. With the condition WH = W  H, by multiplying
NMF seeks a lower rank decomposition of a nonnegative ma- HT                  WHHT     =  W HHT
trix [Berry et al., 2006]. It is formalized in Equation (1): in both sides we have                .From
                                                      full rank condition we get W = W H(HHT )−1 = W P ,
                     V ≈ WH                     (1)   where P  = H(HHT   )−1. As the same we can get H =
                                                      (W T W )−1W T W H = QH                    PQ  =
     V  W      H                       V     m × n                              . It is easy to validate
where  ,   and   are nonnegative matrices. is a       QP  =  I where I is the identity matrix. Therefore, Q =
matrix, in which each row represents a data sample and each P −1.
column corresponds to an attribute. H is a k × n matrix with
each row representing a latent factor. W is an m × k matrix, Consider the factorization problem.
reﬂecting the association weights between the data samples                            
                                                                     V               W
and the factors. To simplify our following derivations, we    V =       =  WH =     1   H
                                                                     U                               (3)
use equality sign “=” and the approximately equal sign ( “≈”                         W2
) interchangeably.                                                          
  The NMF problem is solved by minimizing the distance where W1, W2 are blocks of W corresponding to V and U re-
                                                                                       
between the original matrix and the reconstructed one, as spectively. Therefore, we have V = W1H. Since we already
shown in Equation (2):                                have another form of decomposition of V with V = WH,
                  min ||V − WH||                      according to Theorem (1), we can build the relationship be-
                                                (2)                                       
                                                      tween the two decomposition forms by W1 =  WP   and
     || · ||                                                 −1
where     is a norm operator.                         H = P   H where P is an invertible matrix. Thus, the orig-
                                              V  =
  Often, the solution to this problem is not unique. If inal factorization problem is converted to
WH, we can ﬁnd another solution (WP)(P −1H) so long as
         −1                                                                       
WP  and P  H  are nonnegative matrices.                             U = W2Hs.t.H      = PH            (4)

                                                IJCAI-07
                                                  2690P reﬂects the relations between the new factor matrix H and
the old factor matrix H. All the decompositions satisfy the
nonnegative constraint. We return to this discussion in Sec-
tion 4.3.
  In order to ﬁnd a solution to Equation (4) , we consider the
factorization of the new data matrix by replacing V by H
                              
                               ∗
          H         ∗  ∗     W1      ∗
                = W  H  =      ∗   H            (5)
           U                 W2
                                         ∗  ∗
By solving this problem we obtain H =  W1 H  ,U  =
  ∗  ∗         ∗ ∗             ∗      ∗−1      ∗
W2 H  . H = W1  H  implies that H = W1   H if W1 is         Figure 1: An Example of Partial-Data Problem
invertible. Now we get the solution to Equation (4) by setting
      ∗        ∗−1         ∗
H  = H  , P = W1   , W2 =  W2 . Based on the previous
                                ∗  ∗                  5   Orthogonality Constraint on ONMF
factorization result V = WH = WW1 H ,wehave
                                                    As discussed in [Donoho and Stodden, 2004] and veriﬁed in
                      ∗
                 WW1                              our experiments, when the data are scarce or incomplete in
           V =       ∗    H  = W H
                   W2                                 distribution, NMF may ﬁnd the latent factors correctly. We
Here we summarize the factor updating rules:          refer to this problem as the partial-data problem. Figure 1
                                                    shows an illustration of this problem. In this ﬁgure, assume
                             ∗
                        WW1                          that we have three hidden factors, each being represented by
                 W  =       ∗                  (6a)
                          W2                          a corner of a triangle in Figure 1. In Figure 1(1), we have
                  H = W ∗−1H                         enough observed data which are distributed in regions rep-
                        1                      (6b)   resented by A, B, C, respectively. In Figure 1(2), the ob-
  Since the solution to Equation (5) is solved by minimizing served data are only distributed within region D. As a result,
a target function which is not convex, our current solution to the factors discovered from Figure 1(1) are correct. However,
Equation (3) is an approximation rather than an exact solu- since the possible factors that generate the data in Figure 1(2)
tion. However, the following analysis shows the approximate are not unique, the discovered factors are also wrong. This
solution is reasonable. Furthermore, the empirical results on partial-data problem can be a serious problem in temporal
two datasets validate the reasonability of this approach. data as the data may arrive in an irregular fashion.
                                                        The partial-data problem is inherently related to the unique
4.3  Discussions of ONMF                              solution problem of NMF decomposition. In [Plumbley,
From the algebra point of view, the task of NMF is to ﬁnd a 2002], the authors studied the unique solution of NMF under
set of nonnegative bases to represent the input data by a lin- permutation. In [Donoho and Stodden, 2004], the authors
ear combination. When new data arrive, the bases need to be proposed the complete factorial sampling requirement for
updated to represent the new data. Since the old bases can correct factorization from a geometric point of view. How-
be used to represent the old data, we can update the bases ever, none of the above work answers how to solve the partial-
using the previous bases and the new data instead of using data problem. To solve the partial-data problem, below we
all the data. This is the philosophy behind our ONMF ap- ﬁrst give Theorem 2 to clarify the condition for unique NMF
proach. In order to adjust the contributions of the old factors, decomposition from an algebra point of view. Then we in-
we can modify our current ONMF by introducing a weighting troduce the orthogonal constraints on ONMF to tackle the
schema. That is, we can use ΛH to replace H in Equation (5). partial-data problem. The proofs of theorems in this section
Λ is a nonnegative diagonal matrix with Λii representing the are not provided for space reasons.
             h
weight of factor i. Then the relation between the old factors Theorem 2. Suppose that we are given a nonnegative fac-
                   H∗  = W −1ΛH
and the new factors is     1     and the update rules torization  V = WH,whereW    and  H  satisfy W =
become:
                                                        Δ1
                   −1   ∗                             P1       , H =(Δ2,H1) P2, and where P1 and P2 are per-
              W  Λ  W1            ∗−1                   W1
        W  =         ∗      , H = W1   ΛH       (7)
                  W2                                  mutation matrices, while Δ1 and Δ2 are diagonal matrices.
  Now we show how our method deals with the temporal na- The factorization is unique under permutation (apart from a
                                                      scaling factor).
ture of data streams. As shown in Section 4.2, H = PH
represents the relation between the old latent factors and the Intuitively, Theorem (2) requires the latent factors to have
new factors through a linear transformation. In some real ap- distinct features from each other and the data distribution
plications, it is possible that the relations between H and H should be complete. In order to make the solution unique
are not linear. Just as a nonlinear smooth function can be ap- when the data are incomplete, more strict requirements are
proximated by a linear function within a small region, the lin- needed for the factors.
ear relation can be a good approximation in a short time span Theorem 3. If we restrict H to satisfy hi · hj =0for i = j
                                                                   th     th
while the latent factors are changing smoothly. This claim (hi,hj are the i and j rows of H), then the nonnegative
is veriﬁed by our experiment on a simulated image dataset, factorization V = WH is unique under permutation (apart
whichisdiscussedinSection6.1.                         from a scaling factor).

                                                IJCAI-07
                                                  2691  Theorem 3 requires the factors are orthogonal, thus the de- 6.1 Experiments on Temporal Image Data
composition problem is converted to a minimization problem: The ﬁrst dataset consists of a series of simulated image data.
                      1                               Figure 2 shows the factors used for data generation. Each
              minJ  =   ||V − WH||2                   factor corresponds to a picture of 10 × 10 pixels with a hori-
                      2           F
                                                (8)   zontal or vertical bar. The intensity of any pixel is between 0
               s.t.W ≥ 0,H ≥  0,                      and 1. Each simulated picture is generated by a linear combi-
                  hi · hj =0,i= j                    nation of these factors. In order to introduce evolving latent
                                                     factors during the data generation process, the two factors on
          2          2
where ||X||F =   ij Xij . (·) is the inner product. By in- the left-most side in Figure 3 are made to change over time,
troducing a regularizer for the orthogonality constraint, the while the other factors are kept static. The short horizontal
minimization problem is further converted to the following bar moves from left to right and the short vertical bar moves
problem:                                              from bottom to top step by step. In each step, we generated
                                                      1000 data. A subset of the simulated data are shown in Fig-
             1                                        ure 4. Our task is to detect the latent factors and track their
         J =   ||V − WH||2 + αΓHHT
             2           F                      (9)   evolution from the simulated data.

where Γ is a symmetry nonnegative matrix with diagonal el-
ements equal to zero and other elements greater than zero.
α is a positive number. According to the Karush-Kuhn-
Tucker(KKT) conditions [Xu and Gong, 2004], we can ob-
tain the solution to Equation (8) by the following the iterative Figure 2: Factors Used for Data Generation
formulas:

                      (VHT  )
           w   ←  w          ij
             ij    ij       T
                     (WHH    )ij
                                               (10)
                         (W T V )                      Figure 3: Two Evolving Factors Used for Data Generation
            h  ←  h             ij
             ij    ij   T
                     (W  WH   + αΓH)ij

The proof of this algorithm’ convergence is omitted here, but
we note that during the iterations, we need to let α increase
from a small value to inﬁnity in order to solve Equation (8).
Detailed study of the change of α is left to our future work.
                                                         Figure 4: Simulated Data Generated from Real Factors
  Now we can summarize the procedure of applying ONMF
on data streams in Algorithm 1:

Algorithm 1 : ONMF
  Timestep 0: Initialization, using current data V to calcu-
     W      H
  late  and   by orthogonal NMF(10);                          Figure 5: Factors Reconstructed by NMF
  Timestep t:
  Substep 1: Use new data U and H to calculate W and H
            by orthogonal NMF(10);
  Substep 2: Update W and H by W and H by online NMF
            (7);
  Timestep T: Output ﬁnal W and H.                       Figure 6: Factors Reconstructed by Orthogonal NMF

                                                        We ﬁst investigate whether the orthogonal NMF can help
  Because the algorithm of orthogonal NMF (10) is iterative,
                                                      handle the partial-data problem. Figure 5 shows the factors
initial parameter values must chosen appropriately. We can
                                                      learned by NMF and ﬁgure 6 shows the factors learned by or-
set these values randomly, but in the context of online classi-
                                                      thogonal NMF on 100 randomly sampled simulated data. We
ﬁcation tasks, a natural choice at time step t is the result get
                                                      can see that the orthogonal NMF correctly detects the real
from time step t − 1.
                                                      factors while NMF only learns the mixtures of them. In this
                                                      experiment, we let α =0.1 × 1.01n during the iterations,
6  Experiments                                        where n is the iteration number. Figure 7 shows the KL dis-
                                                      tance between the reconstructed factors and the real factors
We conduct experiments using three different datasets to ver- during the iterations. Clearly, compared with NMF, the or-
ify the effectiveness of our ONMF approach.           thogonal NMF can ﬁnd better latent factors, which validates

                                                IJCAI-07
                                                  2692    600
                                  Orthogonal NMF
                                  NMF
    500

    400

    300


   KL  Distance 200

    100

     0
      0          500         1000        1500
                      Iteration                           Figure 9: Three Threads of Topics of 20NG Dataset
         Figure 7: Reconstructed Factors’ Error

                                                          1

                                                         0.9

                                                         0.8

                                                         0.7

                                                         0.6

                                                         0.5

  Figure 8: Two Moving Factors Reconstructed by ONMF   Similarity(cosine) 0.4
                                                              thread rec
                                                         0.3  thread comp
                                                              thread talk
the effectiveness of orthogonal constraint on alleviating the 0.2
                                                          2    3    4     5    6    7    8     9    10
partial-data problem.                                                         Time
  Figure 8 shows the evolution of the latent factors discov-
ered by our ONMF. Although all the factors, including the     Figure 10: Changes of Similarity of Topics
static ones, have been detected, we only show the two dy-
namic factors for brevity. From this ﬁgure, we can see that news articles about the Asian Tsunami event dated from Dec.
ONMF successfully detects and tracks the two evolving fac- 19, 2004 to Feb. 8, 2005, sorted by their reporting times.
tors. As shown in Figure 3, the relations between the old fac- These articles are collected from 10 sources, with the key-
tors and the new factors does not follow a linear transforma- word query ”tsunami”.
tion. But our ONMF can approximate the nonlinear relations To track the latent topics, we feed the news articles sequen-
and track the latent factors, as the two evolving factors change tially to our ONMF algorithm. To illustrate the topics tracked
smoothly. This fact validates our conclusions in Section 4.3. in the whole process, we select a special topic “ﬁnance”
6.2  Experiments on 20NG Dataset                      and use three representative terms “aids”,“reconstruct” and
                                                      “debt” to show the evolution of the topic. To avoid the “re-
                                                 1
The second experiment is carried out on the 20NG dataset , port delay” problem mentioned in [Mei and Zhai, 2005], only
consisting of approximately 20,000 newsgroup documents news from CNN are used in this experiment. As shown in
which are evenly distributed across 20 categories. Since the Figure (11), the “aids” topic has a large probability at the be-
original 20NG did not contain time information, we manually ginning and then decreases in the following days. ”debt” and
construct 3 threads for experiments, illustrated in Figure 9. ”reconstruct” have small probabilities at the very beginning
In each thread, 1000 documents are ordered according to their but increase in the following days.
category sequence. The ﬁrst thread contains documents about
autos (denoted by “rec.*”) . In the second thread (“comp.*”), 6.4 Time Complexity
the ﬁrst 500 documents are about ‘comp.ibm.hardware’ and
                                                      Our ONMF is more efﬁcient for ﬁnding new factors when
the remaining documents are about ‘comp.mac.hardware’. In new data arrive. The basic NMF algorithm [Lee and Seung,
the third thread (“talk.*”), the ﬁrst 300 documents are about
                                                      2000] has a complexity of O(mn). Our online NMF has a
‘talk.politics.mideast’, while the middle 400 documents are
                                                      complexity of O(pn) to update the latent factors while the
about ‘talk.politics.misc’, and the last 300 documents are basic NMF computation needs O((m + p)n)) to get the new
about ‘talk.religon.misc’.
                                                      factors. Figure 12 shows the comparison of the computational
  Documents in different threads are then mixed together.
Our ONMF updates its latent factors when 300 new docu-
ments arrive. Figure 10 shows the change in the similarity 0.16
                                                         0.14   reconstruct
between the topics at time t and those at time t − 1.Fromthis   aids
                                                         0.12
ﬁgure, we can ﬁnd both the topic evolvement trend and the       debt
time spans with severe topic change detected by our ONMF  0.1
algorithm are consistent with the real data.             0.08
                                                         0.06
                                                        Probability
6.3  Experiments on Tsunami News Data                    0.04
                                                         0.02

We also tested our approach on the real tsunami news data set 0
                                                           0    2    4   6    8    10   12  14   16
used by [Mei and Zhai, 2005]. This dataset consists of 7,468 Dec.19 2004     Time             Feb.8 2005 

  1http://people.csail.mit.edu/jrennie/20Newsgroups/  Figure 11: Evolution of Probability for Terms “reconstruct”,
                                                      “aids” and “debt”

                                                IJCAI-07
                                                  2693