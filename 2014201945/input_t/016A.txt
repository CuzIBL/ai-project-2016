             Integrating Explanatory and Descriptive Learning in ILP 

         Yannis Dimopoulos Saso Dzeroski Antonis Kakas 
         Institut fur Informatik Dep. of Intelligent Systems Dep. of Computer Science 
          Universitat Freiburg Jozef Stefan Institute University of Cyprus 
            Am Flughafen 17 Jamova 39, SI-1000 Ljublijana, P.O. Box 537, CY-1678 
       79110 Freiburg, Germany Slovenia Cyprus 
 yannis@informatik.uni-freiburg.de Saso.Dzeroski@isj.si antonis@turing.cs.ucy.ac.cy 

                         Abstract                                  very few (if any) attempts have been made to combine 
                                                                   the two frameworks. On the other hand, the combina­
     A learning framework that combines the two 
                                                                   tion of rules and integrity constraints is a very power­
     frameworks of explanatory and descriptive In­
                                                                   ful modeling or representation framework found in sev­
     ductive Logic Programming (ILP) is presented. 
                                                                   eral areas of Computer Science. It forms for exam­
     The induced hypotheses in this framework are 
                                                                   ple the basic conceptual model of databases where the 
     pairs of the form (T, IC) where T is a defi­
                                                                   data must always conform to the properties that the in­
     nite clausal theory and IC is a set of integrity 
                                                                   tegrity constraints of the database specify. In Artifi­
     constraints. The two components allow us to 
                                                                   cial Intelligence the combination of a theory with con­
     combine complementary information from the 
                                                                   straints has been extensively studied (e.g. [Poole, 1988; 
     same data by applying both explanatory and 
                                                                   Kakas et a/., 1993]) and applied to problems of planning, 
     descriptive learning methods. This non-trivial 
                                                                   diagnosis, legal reasoning and many others. 
     integration is achieved using a nonmonotonic 
     entailment relation for the basic notion of cov­                 In this paper we bring together work from the areas of 
     erage in the combined language of rules and                   Machine Learning (ILP) and Knowledge Representation 
     constraints where the constraints can restrict                to propose an integrated learning framework that synthe­
     the conclusions derivable by the rules.                       sizes in a non-trivial way the two separate approaches of 
     We present a semantics for the new framework                  explanatory and descriptive learning. In this framework 
     and then discuss different cases where combin­                the induced hypothesis is a pair of a definite clausal the­
     ing information from explanatory and descrip­                 ory (set of rules), T, and a set of integrity constraints, 
     tive ILP could be useful. We present some basic               IC. This induced theory is used to reason in a non­
     algorithmic frameworks for learning in the new                monotonic way, where the integrity constraints in IC 
     framework, and report on some preliminary ex­                 specialize the rules in T by restricting their conclusions. 
     periments with encouraging results.                           The integration of the two forms of learned output in T 
                                                                   and IC becomes non-trivial by this reasoning. In turn, 
1 Introduction                                                     when this is used as the basic notion of coverage for the 
                                                                   learning problem the two processes of explanatory and 
Inductive logic programming (ILP, [Muggleton and 
                                                                   descriptive learning interact in a strong way. 
De Raedt, 1994]) is concerned with learning clausal the­
ories in first-order logic. Two main approaches exist to              The integrated learning framework allows us to com­
learning in first-order logic, known under the names of            bine together (during the learning process) complemen­
explanatory and descriptive learning. The first [Mug­              tary information that can be learned from the same data 
gleton, 1995] is also called learning from entailment or           using the two different approaches of explanatory and 
normal ILP, the second [De Raedt and Dzeroski, 1994]               descriptive learning. In a typical situation, the rules 
is also called learning from interpretations or nonmono­           generated by the explanatory learning process can be 
tonic ILP. The first setting is concerned with the induc­          (informally) understood as sufficient information on the 
tion of rules that explain (correctly classify) the given          concepts to be learned whereas the output of descriptive 
observations, whereas the latter is concerned with the             learning as necessary information. This combination of 
induction of constraints that describe the (dependencies           information is particularly useful when the learning data 
in the) given observations.                                        or the learning method is incomplete. The integrated 
   While attempts have been made to relate the two                 learning framework can thus enhance our learning capa­
settings (see e.g. [Muggleton and De Raedt, 1994]),                bilities by allowing us to learn inherently non-monotonic 


900 LEARNING theories (which by definition can not be completely spec­          the reasoning made with each part and then using this 
ified). More importantly though it can also be particu­            as the basic notion of coverage for the learning prob­
larly useful (enhancing) for many other learning prob­             lem. This combined notion of entailment is inherited 
lems not necessarily non-monotonic in nature as learn­             here from work in the area of Knowledge Representa­
ing by its very nature is often an incompletely specified          tion [Poole, 1988], [Kakas et a/., 1993]. Reasoning with 
problem. At the more practical level, the integration of           the theory is done in the usual way using the minimal 
a set of integrity constraints in the learned theory : (i)         Herbrand model semantics. For the integrity constraints 
provides additional complementary information, (ii) of­            there are several alternative semantics. In this paper we 
fers a new type of specialization operator on the rules of         will use the epistemic or meta-level view [Reiter, 1988] 
the theory, (iii) offers a complementary notion of clas­           where the constraints are understood as statements at a 
sification via the satisfaction of the constraints and (iv)        different level from those in the theory and they specify 
allows us to learn from incomplete data, e.g., from pos­           what must be true of the theory. They are formalized 
itive data only where the constraints provide implicitly           as first order formulae that must be true in any given 
negative data.                                                     model of the theory for this model to be accepted. 
   Although there exist several learning systems 
[De Raedt and Bruynooghe, 1993; De Raedt and 
Van Laer, 1995; Muggleton, 1995] that learn (or can 
learn) integrity constraints none of these does so in a 
strongly integrated fashion as we are proposing here. In 
fact, most of the constraints learned in practical domains 
(see e.g. [De Raedt and Dehaspe, 1996]) have the form of 
definite clauses (the same form as for explanatory ILP), 
and are even used in the same fashion i.e. for explanation 
rather than description as is their natural role. 

2 An Integrated Learning Framework 
In this section we present the basic learning framework 
that integrates the two different problems of explanatory 
and descriptive learning. We will assume that the reader 
is familiar with basic notions of first order logic and logic 
programming (see e.g. [Lloyd, 1987]). 
   In the integrated framework the hypothesis space is 
extended to accommodate the learned output for either 
setting of explanatory or descriptive learning. 

Definition 1 (Hypothesis Language): A hypothesis H is 
a triple < T, C, IC >, where C is a set of predicate sym­
bols (the concepts to be learned), T is a Definite Horn 
theory (of rules defining concepts in C) and IC is a set of 
first order formulae (integrity constraints on the theory 
T). 

   The integrity constraints in IC can in general be any 
first order formula but in practice (see e.g. [De Raedt 
and Bruynooghe, 1993]) it is useful to restrict these to be 
clauses which are also range-restricted. We have also re­
stricted here the theory T to contain only definite Horn 
clauses with no negation as failure (NAF). The frame-
work can easily be extended to allow NAF. Moreover, 
the language of definite rules with integrity constraints 
subsumes NAF [Eshghi and Kowalski, 1989]. 
  The integration of the two forms of learned output 
(explanatory rules in T and general regularities of the 
data in IC) becomes non-trivial by combining together 


                                                                            DIMOPOULOS, DZEROSKI, & KAKAS 901 learned theory H. There are also several ways in which             framework of definite rules and integrity constraints [Es-
 this problem could be generalized or modified. For ex­            hghi and Kowalski, 1989]. Hence the integrated frame-
ample, the background knowledge may already contain                work subsumes the use of NAF in learning systems. Con­
some integrity constraints. Another alternative relates            versely, it is indeed possible to simulate the effect of most 
to how strong we want the exclusion of negative exam­              forms of integrity constraints using NAF. This, however, 
ples to be. We may for example want to replace the third           would typically require the use of auxiliary new predi­
condition by the stronger condition "there is no general­          cates, as in the above example, thus making the learning 
ized model M of H such that                                        process unnecessarily more complicated with the need of 
The proper study of these extensions and alternatives is           predicate invention [Bain and Muggleton, 1990]. A more 
beyond the scope of this paper.                                    important difference is the fact that the use of NAF alone 
   The above definition combines elements from the ex­             still relies only on the explanatory (normal) ILP learning 
planatory and descriptive learning problems via the cov­           criteria. In the integrated framework in addition we can 
erage relation of definition 2. The rules in the theory T          use the second independent learning criterion of describ­
give sufficient conditions for the concept(s) that we are          ing the data available. This can be significant particu­
learning whereas the integrity constraints in IC provide           larly in problems where the training data is incomplete. 
complementary necessary conditions on the concept.                 In the above example, if we are not given the negative ex­
                                                                   amples the integrated framework can still find the same 
   Let us illustrate the potential and possible use of the 
                                                                   solution as before since the integrity constraint can be 
integrated framework with a few simple examples. As a 
                                                                   learned independently from the rest of the problem. 
first example we take a well known domain from knowl­
edge representation which is not possible to express using            In the previous example due to the inherent non-
only the language bias of definite Horn logic.                     monotonicity of the problem it is not possible to learn 
                                                                   the correct theory using each of the two ILP settings 
Example: Consider the background theory B                          separately. We will now consider some examples where 
bird(x) <- penguin(x)                                              although there are solutions in these separate settings 
penguin(x) <--- superpenguin(x)                                    these may be difficult to find. Lack of complete infor­
bird{a), bird(b), penguin(c), penguin(d),                          mation in learning can effectively result in a situation 
superpenguin(e), superpenguin(f)                                   similar to that of a non-monotonic problem. 
with the set of concepts to be learned C = {flies(-)}. 
                                                                      Let us first consider an example where we are try­
Consider also the training data consisting 
                                                                   ing to learn the concept daughter given complete back­
simply of a set of positive and negative examples as fol-
                                                                   ground information on parent, father, mother, male 
                                                                   and female but possibly incomplete information on 
                                                                   daughter. Suppose that we have learned the rule 
                                                                   daughter(x,y) <- parent(y, x). 
   A solution to this problem is given by the hypothesis           We first note that the usual specialization of this rule 
                                                                   by adding the extra condition of female(x) can also be 
                                                                   equivalently achieved by learning the integrity constraint 
The integrity constraint expresses a general regularity            female(x) <-- daughter{x,y). 
that characterizes the available data is also used to com­         In fact, any condition in a rule can be simulated by a new 
pensate for the overgenerality of the learned rule in T.           constraint of the general form condition <-- concept, sub-
The conclusion flies(c) is not possible as the constraint          body-of-rule. Note though that this alternative way of 
is violated: in we would have penguin(c) and                       specializing the rule is also possible even when there 
not superpenguin(c). On the other hand, the conclu­                is insufficient negative information in the training data 
sion flies(e) is allowed by the learned theory since this          to drive the first alternative of explicit specialization 
does not violate the constraint. Note that if the integrity        of the rule. Suppose now that the background knowl­
constraint is considered simply as another clause in the           edge does not contain the predicate female. An ex­
theory T then the resulting hypothesis would be incon­             plicit specialization of the rule can now only be done 
sistent covering negative examples.                                using the NAF condition not(male(x)). This can again 
   This learning problem can also be captured using the            be equivalently achieved via the integrity constraint 
non-monotonic construct of NAF by extending the lan­               -(daughter(x,y),male(x)) but as before this constraint 
guage bias of the theory T from definite Horn clauses              can exist independently of any negative examples. 
to normal logic program clauses. A possible solution is               The information provided by the integrity constraints 
given by the rules: flies(x)<-- bird(x),not abnormal(x)            may not be captured by the rules of the theory and is 
and abnormal(x) <---penguin(x),not superpenguin(x).                thus complementary to that of the rules. Suppose for 
   Negation as failure can easily be captured within the           example that we do not have any direct information on 


902 LEARNING  the predicates male and female and we have learned                straints are not simply some extra clauses of the theory 
 the rule daughter(x,y) <- parent(y, x). It is still possi­        learned on some additional concepts that (possibly) ap­
 ble to specialize this rule with the use of integrity con­        pear in the heads of the integrity constraints. Although 
 straints. This can happen using other information avail­          the integrity constraints could be used to provide a par­
 able in the background knowledge and/or the training              tial definition for these predicates their main purpose is 
 data that we learn (using the descriptive criteria) is nec­       to specialize the concept rules in the theory T. To be 
 essarily related to the concept of daughter. Consider             more specific, if the above integrity constraint is consid­
 for example that the background knowledge also con­               ered simply as another clause in the theory for a new 
 tains information about the predicates child(-,-) and             concept sister, this will not have any effect on the rule 
 sister(—,—). Then we could learn the integrity con­               of the theory which will remain overgeneral. Similarly, 
 straint: sister(x,z) <- daughter{x,y),child{z,y),z ≠ x.           if we add the "corresponding clause" 
 This will provide (some) specialization to the general rule       daughter(x,y) <-- sister(x, z),child{z,y) 
 excluding all persons which are not sisters to their sib­         to the theory, this will not have any specialization effect 
 ling from being classified as daughters. Similarly other          on the other rule for daughter. The choice of the in­
 integrity constraints such as mother(x,z);aunt(x,z) <-            tegrity constraints is not independent from the rules of 
 daughter(x,y),grandparent(y,z) etc could provide ad­              the theory and part of the difficulty is to find the "rel­
 ditional specialization of the rule.                              evant" constraints that would compensate correctly for 
   This type of specialization comes from learned depen­           the rules of the theory. 
 dencies in the data relating the concept we are trying               Summarizing, the integrity constraints can sometimes 
 to learn with other known relations in the background             provide implicitly the required specialization of the 
 knowledge. This information encoded by the integrity              defining rules without the need of explicit negative train­
 constraint should not necessarily be seen as part of the          ing data. They effectively form additional implicit train­
 rule definition of the concept. It is instructive to com­         ing data for the explanatory part of the problem allowing 
 pare the behavior of the integrated framework with that           us to learn from positive data only. In addition, the in­
 of normal ILP in these situations. Firstly, for the lat­          tegrity constraints offer new possibilities of specialization 
 ter framework to capture this type of information it will         of the rules when these express regularities of the con­
 need explicit negative information to drive this special­         cept with other predicates not directly involved in the 
 ization, e.g., a negative example of a sibling that is not        definition of the concept. 
 a daughter. If this is given then normal ILP will try 
to specialize the general rule by adding extra conditions          3 Learning algorithms and Experiments 
 in its body. In the example above it will specialize the          Several approaches to developing learning algorithms in 
rule to daughter(x,y) <-- parent(y,x),cMld(z,y),z ≠                the integrated framework are possible. One is to sepa­
 x,sister(x,z) resulting in an arguably artificial defini­         rate the generation of the two components (rules or con­
 tion.                                                             straints). A top-level description of an algorithm that 
   Apart from the non-naturality of the rules another              generates the rules first, which then drive the rest of the 
important difference of encoding this type of informa­             learning process, is: 
 tion in rules instead of integrity constraints is the fact 
that the extra conditions added to the rules (e.g., here           Algorithm 1 
child(z, y),z ≠ x) now become necessary for the conclu­            Find a set of rules R that cover all + ve examples; 
sion to hold whereas this is not the case with the integrity       Decide-bias-of-ics(R, E; Bias); 
constraints. But these conditions may not be relevant in           Generate-ics (Bias, E; IC); 
all cases. They may not be known by the theory (e.g., in           Choose-ics( IC, R,E;C); 
the case where we have multiple predicate learning and             Return (R,C); 
child is another predicate that we are learning) or they 
simply do not hold (e.g., cases where the daughter does               After the first step that generates the rules of the the­
not have a sibling). This then means that in addition,             ory, the algorithm goes into a constraint generation and 
the normal ILP system must now generate another rule               selection phase. We first select the general IC schema(ta) 
 (or rules) to re-cover all the positive examples that are         (or bias) that will be given as input to the descriptive 
lost by these extra conditions. This is the phenomenon             inductive procedure. We have identified two types of 
of rule splitting in normal ILP systems that can result            analysis that help decide on the bias (a) analysis of the 
in many overspecific rules containing conditions not di­           form of the rules (b) analysis on the examples misclas-
rectly relevant to the proper definition of the concept.           sified. Other information that helps in finding an ap­
   Learning integrity constraints differs significantly from       propriate schema for the constraints is their complex­
learning more clauses in the theory. The integrity con­            ity (roughly the number of literals they involve) and 


                                                                            D1MOPOULOS, DZEROSKI, & KAKAS 903 more importantly their independence from the exist­                ate for problems where there is no or limited explicitly 
ing rules (i.e. they should not be subsumed by the                 given negative training data. A top level shell for such 
rules). In the experiments we report below we have re­             an algorithm is the following: 
stricted this kind of analysis to constraints of the form 
literati <- concept,literal2 or literall <- concept, sub-          Algorithm 3 
body-of-rule, literal2 where literall is a literal which           Generate a set of ICs C; 
can be the "false" literal and literal2 is a conjunction of        (use descriptive criteria e.g. degree of applicability) 
up to 2 literals.                                                  repeat 
Then we call a descriptive system that generates con­              Generate rule R; 
straints with the decided bias. In our experiments we              While and not satis f(R, C) 
have used the CLAUDIEN system which offers a strong                Specialize-rule(R); 
declarative language for expressing the bias. 
The last step in the constraint computation phase is to            until all positive examples are covered; 
choose among the constraints produced by the descrip­              C' := set of ICs violated by the generated rules; 
tive system, those that will be actually added to the              Return (R',C')■ 
theory. Here we use a combination of the usefulness of 
the constraints in specializing the theory (the number                Note that here specialization of the rules does not 
of negative example misclassifications they correct) to­           come form the negative examples only, but also from the 
gether with descriptive criteria, e.g., the degree of appli­       ICs that are violated. These constraints force the spe­
cability in the data.                                              cialization of a rule until either some minimum thresh­
  In algorithm 1 above, the generation of rules is done            old on the number of positive examples that it covers is 
outside the process of generating the ICs of the theory.           reached or the integrity constraints are indeed satisfied 
In an "interleaved" approach the generation of rules and           by all the consequences of the generated rule. If the con­
ICs are combined together and one dynamically influ­               straints can not be fully satisfied within the threshold, 
ences the other. Constraints again offer an extra possi­           they are returned in the output. The Generate-rule and 
bility of specialization.                                          Specialize-rule are the usual procedures from top-down 
                                                                   normal ILP algorithms. 

                                                                   3.1 Initial Experiments 
                                                                   We report here on some initial experiments with inte­
                                                                   grated learning, the main purpose of which was to pro­
                                                                   vide an initial confirmation of the theoretical ideas and 
                                                                   a basis for the future development of a system for inte­
                                                                   grated learning. 
                                                                     Several experiments were carried out on the real-life 
                                                                   problem of characterizing river water quality. The task 
                                                                   is to interpret a biological sample taken from a river in 
                                                                   terms of five quality classes (see [Dzeroski et al, 1994]). 
  The procedure Extended-Specialization (R; R', NIC)               A fact of the form family(X) (resp. family(X, A)) in­
can use either the normal specialization step of adding a          dicates that the bioindicator family is present in sam­
new literal in the body of R or call on a descriptive ILP          ple X (resp. at abundance level A). The five classes are 
algorithm to generate more constraints NIC. As above               denoted class0(X) to class4(X). Several machine learn­
this will involve deciding on the bias of constraints to           ing systems have been applied on this problem, including 
look for and choosing amongst the generated ones. The              CN2 [Clark and Boswell, 1991], CLAUDIEN [De Raedt 
form of the integrity constraints can now be more specific         and Bruynooghe, 1993] and GOLEM [Muggleton and 
relating strongly to the rules they are trying to special­         Feng, 1990]. Making use of abundance level data CN2 
ize. The general bias of the constraints again follows the         achieves accuracy of 0.62 on unseen cases, while without 
schema literall <- concept, literal2 where literall can            abundance levels it achieves 0.64 accuracy. CLAUDIEN 
be the "false" literal.                                            and GOLEM were only used to generate rules from the 
  Another possibility is to generate (and select) in a             entire dataset. In the following, a theory correctly classi­
first phase the integrity constraints and then use these           fies a sample if it predicts the correct class, and no other 
in a second phase of rule generation. The integrity con­           class is predicted by it. This is different from the clas­
straints are used primarily as additional (negative) train­        sification procedure in CN2, which adds the numbers of 
ing data and thus this strategy is particularly appropri­          examples of each class covered by each rule applicable to 


904 LEARNING 