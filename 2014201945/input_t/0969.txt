                   Viewing Referring Expression Generation as Search

                                   Bernd Bohnet∗   and Robert Dale†
                   ∗Institute for Intelligent Systems, University of Stuttgart, Germany
               †Centre for Language Technology, Macquarie University, Sydney, Australia
                        Bohnet@iis.uni-stuttgart.de, Robert.Dale@mq.edu.au


                    Abstract                            3. The goal of referring expression generation is therefore
                                                          to ﬁnd some collection of attributes and their values
    Almost all natural language generation (NLG) sys-     which distinguish the intended referent from all the po-
    tems are faced with the problem of the genera-        tential distractors in the context.
    tion of referring expressions (GRE): given a sym-
    bol corresponding to an intended referent, how do Over the last 15 years, a wide variety of algorithms have been
    we work out the semantic content of a referring ex- proposed to deal with speciﬁc aspects of this problem. For
    pression that uniquely identiﬁes the entity in ques- example, while earlier algorithms focussed on the use of at-
    tion? This is now one of the most widely explored tributes that correspond to simple one-place predicates (as
    problems in NLG: over the last 15 years, a number might be realised, for example, by means of adjectives such
    of algorithms have been proposed for addressing   as red or large), later work attempts to address the use of re-
    different aspects of this problem, but the different lational predicates (as might be realised by prepositions such
    approaches taken make it very difﬁcult to compare as in and next to), and other work looks at the incorporation
    and contrast the algorithms provided in any mean- of boolean operators such as not and and. Consequently, we
    ingful way. In this paper, we show how viewing    now have a considerable body of research in this area; how-
    the problem of referring expression generation as ever, it is difﬁcult to establish just how these different algo-
    a search problem allows us to recast existing algo- rithms relate to each other.
    rithms in a way that makes their similarities and          This paper represents a ﬁrst step towards consol-
    differences clear.                                idating the results in this area, with the aim of developing
                                                      a framework within which different algorithms can be com-
                                                      pared and assessed. The structure of the paper is as follows.
1  Introduction                                       In Section 2, we provide a brief overview of work on the gen-
                                                      eration of referring expressions to date. In Section 3, we bor-
A major component task in natural language generation row a standard approach used in Artiﬁcial Intelligence (AI) to
(NLG) is the generation of referring expressions: given an en- represent problems in an elegant and uniform way (see, for
tity that we want to refer to, how do we determine the content example, [Simon and Newell, 1963]; [Russell and Norvig,
of a referring expression that uniquely identiﬁes that intended 2003]), sketching how GRE algorithms can be expressed in
referent? This is now a widely explored problem in the NLG terms of problem-solving by search. In Section 4, we explore
literature; since at least [Dale, 1989], the standard conception how the most well-known algorithms can be expressed in this
of this task has been as follows:                     framework. In Section 5, we discuss how this approach en-
                                                      ables a more fruitful comparison of existing algorithms, and
 1. We assume we have a knowledge base that characterises we point to ways of taking this work further.
    the entities in the domain in terms of a set of attributes
    and the values that the entities have for these attributes;
    so, for example, our knowledge base might represent the 2 A Brief Review of Work To Date
    fact that entity e1 has the value cup for the attribute type,
                                                      Although the task of referring expression generation is dis-
    and the value red for the attribute colour.
                                                      cussed informally in earlier work on NLG (in particular, see
 2. In a typical context where we want to refer to some ei, [Winograd, 1972; McDonald, 1980; Appelt, 1981], the ﬁrst
    which we call the intended referent, there will be other formally explicit algorithm was introduced in [Dale, 1989].
    entities from which the intended referent must be dis- This algorithm, which we will refer to as the Full Brevity (FB)
    tinguished; these are generally referred to as distractors. algorithm, is still frequently used as a basis for other GRE al-
    So, for example, we may want to distinguish a particular gorithms. The FB algorithm searches for the best solution
    cup from all the other items present in the context of a amongst all possible referring expressions for an entity; the
    dining table.                                     algorithm derives the smallest set of attributes for the referentin question, producing a referring expression that is both ad- problem.
equate (in the sense that it provides enough information to do Within the wider context of AI, [Russell and
what it needs to do) and efﬁcient (in the sense that it does not Norvig, 2003] present an elegant deﬁnition of a general al-
provide any more information than it needs to).       gorithm for problem solving by search. The search graph
         This initial algorithm limited its application to consists of nodes with the components state and path-cost; a
one-place predicates. [Dale and Haddock, 1991] introduced problem is represented by an initial-state, an expand-method
a constraint-based procedure that could generate referring ex- which identiﬁes new states in the search space, a queuing-
pressions involving relations (henceforth IR), using a greedy method which determines the order in which the states should
heuristic to guide the search.                        be considered, and a path-cost-function which determines the
         As a response to the computational complexity of cost of reaching a given state. In this framework, the search
greedy algorithms, [Reiter and Dale, 1992; Dale and Re- strategy is determined by the combination of queuing-method
iter, 1995] introduced the psycholinguistically motivated In- and path-cost-function used.
cremental Algorithm (IA). The most used and adapted al-        In the following, we use this framework to pro-
gorithm, this is based on the observation that people often vide a characterisation of existing GRE algorithms in terms
produce referring expressions which are informationally re- of problem solving by search. Given an intended referent,
dundant; the algorithm uses a preference ordering over the a set of properties true of the intended referent,1 and the set
attributes to be used in a referring expression, incorporating of distractor entities from which we wish to distinguish the
those attributes which rule out at least one potential distractor. intended referent, we can conceptualise the search space as
         In recent years there have been a number of im- consisting of states that correspond to possible descriptions
portant extensions to the IA. The Context-Sensitive extension of the intended referent. Each state has three components:
(CS; [Krahmer and Theune, 2002]) is able to generate refer- a description that is true of the intended referent, the set of
ring expressions for the most salient entity in a context; the distractor entities that the description also applies to besides
Boolean Expressions algorithm (BE; [van Deemter, 2002]) is the intended referent, and the set of properties of the intended
able to derive expressions containing boolean operators, as referent that have not yet been considered in describing the
in the cup that does not have a handle; and the Sets algo- referent.
rithm (SET; [van Deemter, 2002]) extends the basic approach
to references to sets, as in the red cups. Some approaches 1. The initial-state is of the form h{}, C, P i, where C is
reuse parts of other algorithms: the Branch and Bound (BaB; the set of distractors in the initial context, and P is the
[Krahmer et al., 2003]) algorithm uses the Full Brevity al- set of all properties true of the intended referent.
gorithm, but is able to generate referring expressions with
                                                        2. The    goal    state   is    of    the    form
both attributes and relational descriptions using a graph-based                 0
technique.                                                h{λxP1, λxP2, . . .}, {}, P i, where the ﬁrst term
                                                          contains a set of properties of the intended referent that,
         We have identiﬁed here what we believe to be the by virtue of the second term (the set of distractors)
most cited strands of research in this area, but of course being an empty set, distinguish the intended referent;
there are many other algorithms described in the litera-  P 0 contains any properties of the intended referent not
ture: see, for example, [Horacek, 1997; Bateman, 1999;    yet used in the description.
Stone, 2000]. Space limitations prevent a complete summary
of this other work here, but our intention is to extend the anal- 3. All other states in the search space are then intermediate
ysis presented in this paper to as many of these other algo- states through which an algorithm will move as it adds
rithms as possible.                                       new properties to the description.
         All these algorithms focus on the generation of
deﬁnite references. In principle, they would be embedded 4. The search strategy is carried out by the expand-method
in a higher-level algorithm that includes cases for when the and the queuing-method, which together characterise the
entity has not been previously mentioned (thus leading to speciﬁc GRE algorithm (for example, FB, GH or IA) that
an initial indeﬁnite reference) or when the referent is in is used.
focus (thus leading to a pronominal reference). However,
in practice, most work tends to focus exclusively on deﬁ- 5. The path-cost-function allows us to route the search as
nite reference; see [Dale, 1989; Krahmer and Theune, 2002; required; this can be used to take account of salience
Dale, 2003] for further discussion of the more general case. weights, or to embody some kind of heuristic search.

                                                      For any given algorithm, not all of the methods and functions
3   GRE from the Perspective of Problem               need to be implemented; in particular, we will see that some
   Solving                                            algorithms do not require a path-cost-function.
With so many algorithms to choose from, it would be useful
to have a uniform framework in which to discuss and com- 1We will use the notion of a property to correspond to an at-
pare algorithms; unfortunately, this is rather difﬁcult given tribute and its value; this will considerably simplify the notation we
the variety of different approaches that have been taken to the provide.4   GRE Algorithms in Terms of Problem                 Deﬁnition 2: The Basic Algorithm Structure
   Solving                                              makeRefExp() {
We adopt here an object oriented formalism,2 since this al- // create a initial queue with a single node
                                                          nodeQueue  ← [new Node(initialState())]
lows the representation of dependencies between the algo- while nodeQueue 6= ∅ do
rithms by means of inheritance and overwriting.             node ← removeFront(nodeQueue)
         To enable more fruitful comparison of the different if goal(node.getState()) then
GRE algorithms, we want to distinguish those aspects of the   return node // success
algorithms which are true of all algorithms, and those which end
are unique to each particular algorithm. In Section 4.1, we nodeQueue ← queue(nodeQueue,expand(node))
                                                          end
ﬁrst describe the elements that are shared by all the algo- return nil // failure
rithms; we then go on to describe the distinct aspects of each }
algorithm in turn.

4.1  Common Elements
                                                      algorithms. One such ‘utility function’ is the method rule-
Following from the previous section, the deﬁnitions of the sOut, which takes a property or relation p and a set of distrac-
node and state classes are as shown in Deﬁnition 1. This ﬁg- tors, and returns the set of distractors which are ruled out by
ure also shows the deﬁnitions for initial-state and goal, which p.
remain constant across the algorithms.
                                                               With this machinery in place, we can now rede-
                                                      ﬁne the existing algorithms in terms of their core differences,
 Deﬁnition 1: The Node and State Classes              which correspond essentially to different ways of expanding
  class Node {                                        the search space.
   s // State
   path-cost // Cost of the path to this node
   getState()                                         4.2  The Full Brevity Algorithm
    {return s} // returns the state of the node
                                                      The distinctive property of the Full Brevity (FB) algorithm is
  }
  class State {                                       that it computes all combinations of the available properties
   L // Set of chosen properties and/or relations     P with increasing length, so that it may ﬁnd the shortest com-
   C // Set of distractors                            bination that succeeds in identifying the intended referent.
   P // Set of available properties and/or relations           This behaviour is captured by the expand method
  }                                                   shown in Deﬁnition 3. The method creates a set of successors
  initialState() {return new State(∅,C,P )}           by creating a node for each property p which has not so far
  // the goal is the empty set of distractors                                         i
                                                      been checked, provided that p rules out at least one distractor.
  goal(s) {                                                                   i
    if s.C = ∅ then return true                                The FB algorithm uses a breadth-ﬁrst search im-
    else return false                                 plementation of the queue, as shown in Deﬁnition 4. Conse-
  }                                                   quently, any solution for which goal returns true will have a
                                                      minimal number of properties, since the breadth-ﬁrst search
                                                      considers smaller combinations of properties ﬁrst.
         Given these components, the main method mak-
eRefExp is then as represented in Deﬁnition 2. This takes two  The FB algorithm uses the expand method, and
arguments, which serve as the parameters that distinguish one createNode method which are shown in Deﬁnition 3 and it
algorithm from another: an expand method to create the suc- is invoked by a call of makeRefExp method which is shown
cessors of a given state, and a queue method, which deﬁnes in Deﬁnition 2.
how to insert nodes into the node queue. Depending on the or-
der in which the nodes are inserted, different search strategies 4.3 The Incremental Algorithm
can be realized: for example, when the nodes are inserted at The distinctive property of the Incremental Algorithm is that
the front of the queue, the search strategy is depth-ﬁrst; when it reduces the computational complexity of constructing a
the nodes are inserted at the end of the queue, the search strat- referring expression by considering properties to use in se-
egy is breadth-ﬁrst; when the nodes of the queue are sorted quence from a predeﬁned ordering of the available properties.
by the estimated distance to the goal, then the search type is The implementation of the expand method shown in Deﬁni-
best-ﬁrst; and so on.                                 tion 5 provides this behaviour.
         In addition, we may require a number of general-      If the set of properties of the current state s.P is
purpose methods which can be used by a number of different not empty, then the ﬁrst property p according to the given or-
  2We follow the code conventions typically used in OO- der O is chosen from the set of properties of the current state
languages, where the names of classes start with upper case char- s.P , and a node is created with a new state by the method
acters, and the names of methods and variables start with lower case createNode. Note that the createNode method is the same as
characters.                                           that used in the FB algorithm and shown in Deﬁnition 3. Deﬁnition 3: The Full Brevity Algorithm               Deﬁnition 6: The Set Algorithm
  expand(node) {                                        R // Set of referents
    N ←  ∅                                              createNode(node, p) {
    s ←  node.getState()                                  out ← rulesOut(p, s.C)
    foreach p ∈ s.P do                                    if (¬∃x ∈ R&x ∈ out)&(∃x ∈ C&x ∈ out) then
      N ← N ∪ { createNode (node, p)}                       return new Node(s.C − out, s.L∪{p},s.P − {p})
    end                                                   else return new Node(s.C, s.L, s.P − {p})
    return N                                            }
  }
  createNode(node, p) {
    s ← node.getState()
    out ← rulesOut(p, s.C)                            from the set of intended referents R and when it rules out at
    if out 6= ∅ then                                  least one entity from the set of distractors C. If a property
      return new Node(s.C − out, s.L ∪ {p},           does not fulﬁl that condition, then a node with the current
                    s.P − {p})                        state is returned and the process is continued, as in the IA,
    else return new Node(s.C, s.L, s.P − {p})         with the next property.
  }
                                                      4.5  GRE  Involving Relations
                                                      The algorithm for GRE Involving Relations (IR) introduced
 Deﬁnition 4: Breadth-ﬁrst Queueing                   by [Dale and Haddock, 1991] is constraint-based. The search
  queue(actNodes, newNodes) {                         strategy used to fulﬁl the constraints is a combination of a
    // append the nodes at the end                    greedy search, which chooses the relation that leads to the
    return actNodes ∪ newNodes                        smallest set of distractors, and depth-ﬁrst search to describe
  }                                                   the entities, that is, the intended referent as well as entities
                                                      which are referenced in the relations.
                                                               The strategy can be explained best by means of an
         Unlike the expand method used in the FB algo- AND/OR-tree, as shown in Figure 1. Here, the top node rep-
rithm, however, the set of nodes returned here contains only resents a state in which relational properties are to be consid-
one node. The main method applies the goal predicate to this ered as additions to the set of chosen properties. Each search
node; if this returns true, then the node containing the state step consists of two stages: in the ﬁrst stage, we choose the
with the list of properties for the referring expression is re- relation pi which rules out the largest number of distractors;
turned.                                               in the second stage, each entity which is referenced by the
                                                      chosen relation has to be described by repeating the process
 Deﬁnition 5: The Incremental Algorithm               recursively. This is done in a depth-ﬁrst manner, but if the
                                                      related entity is not uniquely distinguished then the next pj
  O // Predeﬁned constant order of properties         that the intended referent participates in is chosen, and so
  expand(node)
             {                                        on. This process continues until all entities are uniquely de-
    N ←  ∅
    s ←  node.getState()                              scribed (success) or no further relations can be chosen (fail-
    if s.P 6= ∅ then                                  ure).
      p ← choose the ﬁrst p in O, where p ∈ s.P
      N ←  N ∪  { createNode(node, p) }                                  N=({bowl(x)},[Cx={b1, b2}]}
    end
    return N
                                                                     choose relation
  }

                                                                   between(x,w,v)   on(x,y)

                                                                describe entity    ...
4.4  Extension of the IA to Sets
The algorithms considered so far have been concerned                  w        v
with constructing descriptions for individual referents; [van
Deemter, 2002] introduced an algorithm which extends the     Figure 1: Expansion tree for the IR algorithm
IA to sets. The extension is shown in terms of our framework
in Deﬁnition 6.                                                The algorithm is represented in the problem solv-
         Note that, precisely because this algorithm is an ing paradigm as in Deﬁnition 7. Here, the expand method
extension of the IA algorithm, we reuse the expand method chooses a relation which rules out the largest number of dis-
from that algorithm. Consequently, the extension requires tractors; it then calls the method createNode, which recur-
only the rewriting of the createNode method, whereby an at- sively calls makeRefExp for each new referent contained in
tribute pi is only chosen when it does not rule out entities the relation. Deﬁnition 7: Involving Relations                      Deﬁnition 8: Context-Sensitive Algorithm
  r // Referent                                         r // Referent
  expand(node) {                                        createNode(node, p) {
    s ←  node.getState()                                  s ←  node.getState()
    pc ← nil                                              out ← rulesOut(p, s.C)
    // Chosen relation is pc, where p rules out           C ←  s.C − out
    // the largest number of distractors                  L ←  s.L
    foreach p ∈ s.P do                                    if (out 6= ∅ or contrastive(r, p)) then
      if pc = nil or                                        L ←  L ∪ {p }
                                                                                          0
       |rulesOut(p, s.C)| > |rulesOut(pc, s.C)|             if v expresses a relation between r and r then
                                                                                  0
      then pc ← p                                             noder0 ← makeRefExp(r )
      end                                                     L ←  L ∪ noder0 .getState().L
    end                                                     end
    nodec ← createNode(node, pc)                          end
    if (nodec = nil) then return ∅                        if mostSalient(r, L, C) then
    else return {nodec}                                     L ←  L ∪  { defArt }
  }                                                         // The most salient rules out all distractors:
  createNode(node, p) {                                     C ←  ∅
    s ← node.getState()                                   end
    C ←  s.C− rulesOut(p, s.C)                            return new Node(C, L, s.P − {p})
    L ← s.L ∪ {p}                                       }
    // Extend Description
           0
    foreach r ∈ {rp|rp ∈ referents(p) & rp 6= r} do
                         0
      noder0 ← makeRefExp(r )
      if noder0 = nil then return nil // failure      is viewed as a search problem, where we effectively build a
      L ← L ∪ node.getState().L
    end                                               search space consisting of possible descriptions.
    return new Node(C, L, s.P − {p})                           There are three signiﬁcant advantages to this ap-
  }                                                   proach.
                                                               First, it allows us to determine what the algorithms
                                                      have in common. This is particularly interesting in that it al-
4.6  Context-Sensitive GRE                            lows us to begin to assemble a collection of core function-
                                                      alities that are usable in a variety of different approaches to
[Krahmer and Theune, 2002] also introduced a number of ex- GRE. This is apparent not only in terms of the general frame-
tensions to the IA: the use of salience weights in order to add work (where, for example, the notions of states and their ini-
a deﬁnite article to the description for the most salient entity; tialisation, the deﬁnition of what it is to be a goal state, and
contrastive properties in order to add properties which impose the overall algorithmic pattern) are shared, but in terms of
a contrast between two entities; and a relational extension, ‘helper’ routines (such as rulesOut and mostSalient) which
similar in spirit but not in form to that in the IR algorithm can be modularised out of the essence of different algorithms
described above.                                      and reused elsewhere.
         Again, as for the SETS algorithm, the commonality     Second, it makes it possible to see more clearly
with the IA algorithm surfaces as the reuse of the latter algo- what the essential differences between the algorithms really
rithm’s expand method; only the createNode method needs to are. In their original forms, these differences are obscured,
be rewritten, as in Deﬁnition 8. To model this variant in our due to the absence of a common vocabulary for expressing the
framework, we introduce the following additional methods algorithms; by representing the algorithms within a common
(cf. [Krahmer and Theune, 2002]):                     framework, it becomes easier to see where the algorithms dif-
                                                      fer, and where the differences are simply due to differences in
  • contrastive takes a referent r and a property pi; it checks
    whether the property under consideration is contrastive. notation or presentation. By using the framework of problem
                                                      solving as search, we have effectively decomposed the algo-
  • mostSalient takes a referent r, a set of properties, and a rithms into a number of key elements: a search srategy, repre-
    set of distractors; it checks whether every entity in the sented by the queuing-method, and an expand-method, which
    set of distractors has a lower salience weight than r. encompasses two aspects of each algorithm: the basic strat-
                                                      egy adopted and the particular kinds of referring expressions
                                                      covered. Furthermore, the expand-method decomposes into a
5  Conclusions and Future Work                        general strategy for expansion (as found in, for example, the
In the foregoing, we have shown how a number of the most Full Brevity algorithm and the Incremental Algorithm), and
frequently discussed algorithms for the generation of refer- a createNode method, which varies depending upon the kind
ring expressions can be represented within a common frame- of referring expression targetted.
work. The framework is, we believe, an intuitively appeal-     Third, it allows us to see more clearly the logical
ing one: the process of constructing a referring expression space within which the algorithms reside, and to see ways of