                                            Goal   Change
           Steven Shapiro                  Yves  Lesperance´                Hector  J. Levesque
       Computer  Science  Inst.        Dept. of Computer  Science       Dept.  of Computer  Science
        University of Leipzig               York  University               University of Toronto
           Leipzig  04109                     Toronto, ON                       Toronto, ON
              Germany                      M3J  1P3   Canada                M5S   3G4   Canada
 shapiro@informatik.uni-leipzig.de       lesperan@cs.yorku.ca              hector@cs.toronto.edu

                    Abstract                          place. We ﬁrst deﬁne goals using an accessibility relation,
                                                      W , which picks out the situations that the agent wants to be
    Although there has been much discussion of belief the case. We then give a successor state axiom for W that
    change (e.g., [Gardenfors,¨ 1988; Spohn, 1988]),  is affected by two communicative actions: REQUEST actions,
    goal change has not received much attention. In   which cause agents to adopt goals, and CANCELREQUEST ac-
    this paper, we propose a method for goal change in tions, which cause agents to drop goals that had been adopted
    the framework of Reiter’s [2001] theory of action in following prior requests. We then consider some properties of
    the situation calculus [McCarthy and Hayes, 1969; our axiomatization: expansion, contraction, and persistence.
    Levesque et al., 1998], and investigate its prop- Finally, we identify the restrictions on the accessibility rela-
    erties. We extend the framework developed by      tions that give us positive and negative introspection of goals,
    Shapiro et al. [1998] and Shapiro and Lesperance´ and show that these restrictions persist, if they are asserted of
    [2001], where goals and goal expansion were mod-  the initial situations.
    elled, but goal contraction was not.                The remainder of the paper is organized as follows. In
                                                      Sec. 2, we give a brief review of the situation calculus, Re-
                                                      iter’s theory of action, and Shapiro et al.’s [1998] framework
1  Introduction                                       for representing knowledge expansion in the situation calcu-
                                                      lus. In Sec. 3, we introduce our framework for goal change,
One of the commonsense abilities people possess is the abil- and in Sec. 4, we investigate properties of this framework. In
ity to predict the behaviour of others. We attribute goals Sec. 5, we present an example, and in Sec. 6, we conclude,
and beliefs to others and assume they will act on their be- discuss related work, and suggest avenues for future work.
liefs to achieve their goals. One strategy for endowing ma-
chines with a similar ability is to explicitly model the beliefs 2 Representation of Action and Knowledge
and goals of agents and assume they are acting to achieve
their goals in accordance with their beliefs. In dynamic The basis of our framework for goal change is an action the-
environments, the beliefs and goals of agents are likely to ory [Reiter, 2001] based on the situation calculus [McCarthy
change. Although there has been much discussion of be- and Hayes, 1969; Levesque et al., 1998]. The situation calcu-
lief change (e.g., [Gardenfors,¨ 1988; Spohn, 1988]), goal lus is a predicate calculus language for representing dynam-
change has not received much attention. In this paper, we ically changing domains. A situation represents a possible
propose a method for specifying and reasoning about goal state of the domain. There is a set of initial situations cor-
change in the framework of Reiter’s [2001] theory of ac- responding to the ways the agents believe the domain might
tion in the situation calculus [McCarthy and Hayes, 1969; be initially. The actual initial state of the domain is repre-
Levesque et al., 1998]. We thus inherit Reiter’s solution to the sented by the distinguished initial situation constant, S0. The
frame problem, and iterated goal change is achieved seam- term do(a, s) denotes the unique situation that results from
lessly using sequences of actions. Our approach to goal con- the agent doing action a in situation s. Thus, the situations
traction is simpler than most approaches to belief revision and can be structured into a set of trees, where the root of each
relies on using the history of requests rather than a speciﬁca- tree is an initial situation and the arcs are actions. The se-
tion of entrenchment. This work extends the framework de- quence of actions that produces a situation is called the his-
veloped by Shapiro et al. [1998] and Shapiro and Lesperance´ tory of the situation. s  s0 (s ≺ s0, resp.) means there is a
[2001], where goals and goal expansion were modelled but (nonempty, resp.) path from situation s to situation s0. The
goal contraction was not.                             initial situations are deﬁned as those having an empty history:
                                                            def     0          0
  We model agents that adopt goals if they are requested to Init(s) = ¬∃a, s .s = do(a, s ).
do so and they do not already have a conﬂicting goal. They Predicates and functions whose value may change from
maintain their goals unless they are explicitly requested to situation to situation (and whose last argument is a situa-
drop them by the agent who requested the goal in the ﬁrst tion) are called ﬂuents. For instance, we might use the ﬂuentINROOM(Agt, R1, S) to represent the fact that agent Agt is in only change in knowledge that occurs in moving from s
room R1 in situation S. The effects of actions on ﬂuents are to do(a, s) is that it is known (by all agents) that the ac-
deﬁned using successor state axioms [Reiter, 2001], which tion a has been successfully executed. This is true because
provide a succinct representation for both effect axioms and the K-alternative2 situations to do(a, s) are the situations
frame axioms [McCarthy and Hayes, 1969].              that result from doing a in a K-alternative situation to s
                                                                                                  0
  We will be quantifying over formulae, so we assume that where a is possible to execute (denoted by Poss(a, s )). For
we have an encoding of formulae as ﬁrst-order terms (we can the action INFORM(infr, agt, φ), the idea is that in mov-
adapt De Giacomo et al.’s [2000] axioms for this purpose, but ing from s to do(INFORM(infr, agt, φ), s), agt not only
we omit the details here). Therefore, we will freely quantify knows that the action has been executed (as above), but it
over formulae here. To simplify notation, we ignore the de- also knows that φ holds. In this case, the K-alternative
tails of the encoding and use formulae directly instead of the situations to do(a, s) for agt are the situations that result
                                                      from performing a in a K-alternative situation to s where
terms that represent them. We use ψ to denote a formula that                                            3
can contain the situation constants Now and Then, and φ to a is possible to execute, except the ones where φ is false.
denote a formula that can contain Now but not Then. We use As usual, we say that an agent knows a formula φ in
φ s (ψ s, s0 , resp.) to denote the formula that results from s, if φ holds in all situations K-accessible from s, i.e.,
 [ ]  [   ]                                                          def 0       0        0
substituting s for Now in φ (s for Now and s0 for Then, resp.). Know(agt, φ, s) = ∀s .K(agt, s , s) ⊃ φ[s ].
  To axiomatize a dynamic domain in the situation calculus, Following Shapiro et al. [1998], we say that an agent can
we use Reiter’s [2001] action theory, which consists of (1) only execute an inform action if it knows that the content of
successor state axioms for each ﬂuent (including K and W the action is true.
introduced below); (2) initial state axioms, which describe
the initial state of the domain and the initial mental states of Axiom 2.2
the agents; (3) precondition axioms, which specify the con- Poss(INFORM(infr, agt, φ), s) ≡ Know(infr, φ, s).
ditions under which the distinguished predicate Poss(A, S)
holds, i.e., when it is physically possible to execute an action Since we are dealing with knowledge here, not belief, we
A in situation S; (4) unique names axioms for the actions, and assert that K is (initially) reﬂexive.4
domain-independent foundational axioms (we adopt the ones
given by Levesque et al. [1998] which accommodate multiple Axiom 2.3 Init(s) ⊃ K(agt, s, s).
initial situations, but we do not describe them further here);
and (5) the axioms to encode formulae as terms.         Following Scherl and Levesque, we also assert that initial
                                                      situations can only be K-related to other initial situations. We
  Moore [1985] deﬁned a possible-worlds semantics for a
                                                      use an initial state axiom for this purpose:
logic of knowledge in the situation calculus by treating situa-
tions as possible worlds. Scherl and Levesque [2003] adapted
                                                                K  agt, s0, s    s       s0 .
this to Reiter’s theory of action. Scherl and Levesque gave a Axiom 2.4 ( ) ∧ Init( ) ⊃ Init( )
successor state axiom for K that states how actions, includ-
ing sensing actions, affect knowledge. Shapiro et al. [1998] This axiom and the successor state axiom for K imply that
                                                      only situations with the same history can be K-related. Intro-
adapted this axiom to handle multiple agents and INFORM
                                  0                   spection will be discussed in Sec. 4.
actions, which we adopt here. K(agt, s , s) will be used to
denote that in situation s, agt thinks that situation s0 might be
the actual situation. Note that the order of the situation argu- 3 Goal Change
ments is reversed from the convention in modal logic for ac-
cessibility relations. INFORM(infr, agt, φ) is the action of the Just as an agent’s beliefs can change, its goals should also be
agent infr informing another agent, agt, that φ holds. Here able to change. For example, if an agent’s owner requests it to
is Shapiro et al.’s [1998] successor state axiom for K.1 do something, the agent’s goals should change to reﬂect the
                                                      request. We extend the framework developed by Shapiro et
                                                         [    ]                         [    ]
Axiom 2.1                                             al. 1998 and Shapiro and Lesperance´ 2001 , where goals
                                                      and goal expansion were modelled but not goal contraction.
            00
    K(agt, s , do(a, s)) ≡                              Following Cohen and Levesque [1990], we model goals us-
    ∃s0.K(agt, s0, s) ∧ s00 = do(a, s0) ∧ Poss(a, s0) ∧
                                           0          ing an accessibility relation over possible worlds (situations,
        ∀infr, φ.a = INFORM(infr, agt, φ) ⊃ φ[s ]
                                                         2We say that S0 is a K-alternative situation to S for Agt or S0
                                                                                   0
First note that for any action other than an INFORM ac- is K-related to S for Agt, if K(Agt, S , S) holds. We may drop Agt
tion directed towards agt, the speciﬁcation ensures that the when it is understood from the context.
                                                         3Note that here all agents are aware of all actions that occur, in-
  1Since we are using terms for formulae in our underlying repre- cluding inform actions, so we have a broadcast model of commu-
                                           0
sentation, INFORM(infr, agt, φ) = INFORM(infr, agt, φ ), only if nication. In Shapiro and Lesperance´ [2001], encrypted speech acts
φ and φ0 are the same term. It would not be difﬁcult to modify our were introduced, ensuring that only the intended recipient of a mes-
representation so that the equality holds only if φ and φ0 are the rep- sage could know its contents.
resentations of equivalent formulae. We adopt the convention that 4We do not handle belief revision here, but a treatment of belief
unbound variables are universally quantiﬁed in the widest scope. revision in our framework was discussed in [Shapiro et al., 2000].in our case). The accessible worlds are the ones that are com- As noted by Konolige and Pollack [1993], one has to be
patible with what the agent wants to be the case. Cohen and careful when using this deﬁnition of a goal. Suppose an agent
Levesque’s accessibility relation for goals, G, was a subset has a conjunctive goal, ψ ∧ ψ0. According to this deﬁnition
of their accessibility relation for beliefs. This constraint pre- of Goal, both ψ and ψ0 are also goals. Therefore, we could
cludes an agent wanting something that it believes is impossi- imagine a rational agent working to achieve one of the con-
ble (unless its goals are inconsistent). In our case, we deﬁne juncts as a subgoal. But it is easy to think of circumstances
G in terms of a more primitive accessibility relation, which where achieving only one component of a conjunctive goal is
we call W and is intended to model what the agent wants in- undesirable. For example, I may have as a goal to be hold-
dependently of what it knows. We can then deﬁne Cohen and ing the bomb and that the bomb be defused. However, I want
Levesque’s goal accessibility relation, G, to be the intersec- these to be true simultaneously and I do not have the goal to
tion5 of W and K.                                     be holding the bomb if it is not also defused. As Konolige
  An agent’s goals are future oriented. For example, an and Pollack did for their intention modality (I), we consider
agent might want some property to hold eventually, i.e., the formulae that are an agent’s “only goals”, i.e., formulae that
agent’s goal is of the form Eventually(ψ), for some formula are true in all and only the W -paths:
ψ. We evaluate formulae such as these with respect to a path OGoal(agt, ψ, s) =def
of situations rather than a single situation, and we call such ∀s0, s00.K(agt, s00, s) ∧ s00  s0 ⊃
formulae path formulae. Cohen and Levesque used inﬁnite                     (W (agt, s0, s) ≡ ψ[s00, s0]).
time-lines to evaluate such formulae, but for simplicity, we
evaluate path formulae with respect to ﬁnite paths of situa- We now give the successor state axiom for W .
                                                                 0      −        0
tions which we represent by pairs of situations, (Now, Then), W +(agt, a, s , s) (W (agt, a, s , s), resp.), which is deﬁned
                                                                                             0
such that Now  Then. Now  corresponds to the “current below, denotes the conditions under which s is added to
time” on the path of situations deﬁned by the sequence of (dropped from, resp.) W due to action a:
situations in the history of Then. Path formulae may con-
tain two situation constants, Now and Then. For exam- Axiom  3.1
ple, ∃r.INROOM(JOHN, r, Now)∧¬INROOM(JOHN,  r, Then)   W (agt, s0, do(a, s)) ≡
could be used to denote the goal that John eventually leaves (W +(agt, a, s0, s) ∨ (W (agt, s0, s) ∧ ¬W −(agt, a, s0, s))).
the room he is in currently.
  Our W relation, like our K relation, is a relation on situa- An agent’s goals are expanded when it is requested
tions. While K only relates situations with the same histories, to do something by another agent. After the
W  can relate situations with different histories. Intuitively, REQUEST(requester, agt, ψ) action occurs, agt should
W (Agt, S0, S) holds if in situation S, Agt considers that in S0 adopt the goal that ψ, unless it currently has a conﬂicting
everything that it wants to be true is actually true. For exam- goal (i.e., we assume agents are maximally cooperative).
ple, if the agent wants to become a millionaire in S, then in Therefore, the REQUEST(requester, agt, ψ) action should
                                                      cause agt to drop any paths in W where ψ does not hold.
all situations W -related to S, the agent is a millionaire, but                                     −
these situations can be arbitrarily far in the future. This action is taken into account in the deﬁnition of W :
  Recall that the situations in the W accessibility relation are W −(agt, a, s0, s) =def
                                                                      00
the ones that the agent wants to actualize independently of ∃requester, ψ, s .a = REQUEST(requester, agt, ψ) ∧
what it knows. Following Cohen and Levesque, we want the   ¬Goal(agt, ¬ψ, s) ∧ K(agt, s00, s) ∧ s00  s0 ∧
goals of the agent to be compatible with what it knows. The ¬ψ[do(a, s00), s0].
situations that the agent wants to actualize should be on a path               0
from a situation that the agent considers possible. Therefore, According to this deﬁnition, s will be dropped from W , if for
the situations that will be used to determine the goals of an some requester and ψ, a is the REQUEST(requester, agt, ψ)
agent will be the W -accessible situations that are also com- action and agt does not have a conﬂicting goal, i.e., the goal
                                                      that ¬ψ in s6, and s0 K-intersects some s00 such that ψ does
patible with what the agent knows, in the sense that there is                 00 0
                                                  0   not hold on the path (do(a, s ), s ). The reason that we check
K-accessible situation in their history. We will say that S                    00  0              00 0
                00         00        00   0           whether ¬ψ holds at (do(a, s ), s ) rather than at (s , s ) is
KAgt,S-intersects S if K(Agt, S , S) and S  S . We will
suppress Agt or S if they are understood from the context. We to handle goals that are relative to the current time. If, for
deﬁne the goals of agt in s to be those formulae that are true example, ψ states that the very next action should be to get
in all the situations s0 that are W -accessible from s and that some coffee, then we need to check whether the next action
                        00                            after the request is getting the coffee. If we checked ¬ψ at
K-intersect some situation, s :                         00 0
                                                      (s , s ), then the next action would be the REQUEST action.
 Goal(agt, ψ, s) =def                                   If the agent gets a request for ψ and it already has the goal
 ∀s0, s00.W (agt, s0, s) ∧ K(agt, s00, s) ∧ s00  s0 ⊃ ψ[s00, s0]. that ¬ψ, then it does not adopt the goal that ψ, otherwise its
          00
Note that s corresponds to the “current situation” (or the 6Note that according to the deﬁnition of Goal, if the agent has
current time) in the path deﬁned by s0.               a goal that implies ¬ψ, then it also has the goal that ¬ψ, i.e., if
                                                               0               0 0   0         0
                                                      Goal(Agt, ψ , S) holds and ∀s, s .ψ [s, s ] ⊃ ¬ψ[s, s ] holds, then
  5As we will see below, the operation used on W and K to obtain Goal(Agt, ¬ψ, S) also holds. In other words, if the agent has a con-
G is not quite intersection, but a related operation. ﬂicting goal that implies ¬ψ, then ψ will not be adopted as a goal.                                                                                                      S0
goal state would become inconsistent and it would want ev-                            W
erything. This is a simple way of handling goal conﬂicts. A
more interesting method would be to give more credence to

requests from certain individuals, or requests of certain types. CANCELREQUEST (Requester, Agt, ψ)
For example, if an agent gets a request from its owner that
conﬂicts with a previous request from someone else, it should                   S
drop the previous request and adopt its owner’s request in-

stead. We reserve a more sophisticated handling of conﬂict-                 ∗
ing requests for future work.                                              A               W
                                                                                 ∗
  We assume that request actions are always possible to exe-                    S
cute, although executability conditions could easily be added.

Axiom 3.2 Poss(REQUEST(reqr, agt, ψ), s).                   REQUEST(Requester, Agt, ψ)
                                                                              S1
  We  now turn our attention to goal contraction. Sup-
pose that the owner of an agent asks it to do ψ and           Figure 1: An example of goal contraction.
later changes his mind. The owner should be able to
tell the agent to stop working on ψ. We use the ac-
                                                      S also cause S0 to be dropped from W , then S0 is returned
tion CANCELREQUEST(requester, agt, ψ) for this purpose.
This action causes agt to drop the goal that ψ.  A    to  W   after the  CANCELREQUEST(Requester,  Agt, ψ)
                                                      action  is  executed in   S.      In  other  words,
CANCELREQUEST   action can only be executed if a corre-                                         0
                                                      W +(Agt, CANCELREQUEST(Requester, Agt, ψ), S , S)
sponding REQUEST action has occurred in the past.                                                   0
                                                      holds  because the  following hold:  W  (Agt, S , S1),
Axiom 3.3 Poss(CANCELREQUEST(reqr, agt, ψ), s) ≡      do(REQUEST(Requester, Agt, ψ), S1)              S,
                                  0
         do(REQUEST(reqr, agt, ψ), s )  s            CANCELREQUEST(Requester,  Agt, ψ)            cancels
                                                      REQUEST(Requester, Agt, ψ)), and for every  situation
                                                           ∗  ∗
  We  handle CANCELREQUEST    actions by determining  do(A  , S ) between do(REQUEST(Requester, Agt, ψ), S1)
what the W relation would have been if the correspond- and S, ¬W −(Agt, A∗, S0, S∗) holds. Note that for our
ing REQUEST  action had never happened.  Suppose a    deﬁnition of W + to work properly, we must assume that
CANCELREQUEST(Requester, Agt, ψ) action occurs in situa- there is only one REQUEST action in the history that is
tion S. We restore the W relation to the way it was before the cancelled by each CANCELREQUEST. This assumption will
corresponding REQUEST occurred. Then, starting just after be relaxed in future work.
                                        ∗  ∗
the REQUEST, we look at all the situations do(A , S ) in the
                                       0
history of S and remove from W any situation S that satisﬁes 4 Properties
W −(Agt, A, S0, S∗); such situations S0 should be removed
to reﬂect the adoption of a subsequent request. We ﬁrst de- We now consider some properties of goal change. Let Σ con-
                           0
ﬁne the predicate CANCELS(a, a ), which says that action a sist of the foundational, encoding, and unique names axioms,
                 0
cancels the action a . In our case, only CANCELREQUEST and the axioms from Sections 2 and 3. First, we show that
actions cancel the corresponding REQUEST’s:           our theory supports goal expansion. If an agent does not have
                                                      ¬ψ  as a goal, then a request for ψ causes it to adopt ψ as a
                0 def
    CANCELS(a, a ) =                                  goal.
     ∃reqr, ψ.a = CANCELREQUEST(reqr, agt, ψ) ∧       Theorem  4.1
              0
             a = REQUEST(reqr, agt, ψ).                Σ |= ∀agt, ψ, requester, s.¬Goal(agt, ¬ψ, s) ⊃
  We  now deﬁne W +  which states the conditions under        Goal(agt, ψ, do(REQUEST(requester, agt, ψ), s))
which s0 is added to W + after a is executed in s:
                                                        We  also show the conditions under which an agent’s only
                                                                                                      0
  W +(agt, a, s0, s) =def                             goals are expanded. If an agent has the only goal that ψ, ψ is
                 0                                    requested of the agent, the agent knows that the request does
     (∃si.W (agt, s , si) ∧
                                                      not affect the truth value of ψ, and ψ0 does not conﬂict with
         (∃a1.do(a1, si)  s ∧ CANCELS(agt, a, a1) ∧
                ∗ ∗                ∗  ∗               the agent’s goals, then its only goals expand to include ψ0.
             ∀a  , s .do(a1, si) ≺ do(a , s )  s ⊃
                           −      ∗  0 ∗
                       ¬W   (agt, a , s , s )))       Theorem  4.2
To help explain this deﬁnition, we will refer to Fig. 1, where Σ |= ∀a, agt, ψ, ψ0, reqr, s.
                                                  0                                                 0
a segment of a situation forest is shown. The situation S   OGoal  agt, ψ, s a   REQUEST  reqr, agt, ψ
                               0                                  (       ) ∧  =         (          ) ∧
is not W -related to S. However, S was W -related to S1,    Know(agt, [∀then.Poss(a, Now) ⊃
which is in the history of S. The next action after S1 in the     (ψ[Now, then] ≡ ψ[do(a, Now), then])], s) ∧
history of S was REQUEST(Requester, Agt, ψ). We suppose      Goal  agt, ψ0, s
 0                                                          ¬     (   ¬     ) ⊃
S was dropped from W after the REQUEST. If none of the         OGoal(agt, ψ ∧ ψ0, do(a, s)).
actions between do(REQUEST(Requester, Agt, ψ), S1) and  Next, we examine the persistence of goals. A goal ψ per- W . We will need the following deﬁnitions of transitivity and
sists over an action a, if a is not a cancel request, and the Euclideanness, starting in a situation s. Note that the order of
agent knows that if ψ holds then a does not change its value. the situations is reversed from the traditional deﬁnitions.

                                                                    def
Theorem 4.3                                            Ktrans(agt, s) = ∀s1, s2.K(agt, s1, s) ∧ K(agt, s2, s1) ⊃
                                                                                    K(agt, s2, s).
Σ |= ∀a, agt, ψ, s.                                               def
                                                       Keuc(agt, s) = ∀s , s .K(agt, s , s) ∧ K(agt, s , s) ⊃
      Goal(agt, ψ, s) ∧                                                1 2        1             2
              0                              0                                      K(agt, s , s ).
      (∀reqr, ψ .a 6= CANCELREQUEST(reqr, agt, ψ )) ∧                                       2  1
      Know(agt, [∀then.Poss(a, Now) ∧ ψ[Now, then] ⊃
                         ψ[do(a, Now), then]], s) ⊃     Theorem 6 of Scherl and Levesque [2003] showed that if
        Goal(agt, ψ, do(a, s)).                       K  is initially reﬂexive, and transitive or Euclidean, then the
                                                      successor state axiom for K guarantees that the properties
  We have a similar result for “only goals”.          are preserved over executable sequences of actions. This re-
                                                      sult carries over here. First, we show that reﬂexivity is pre-
Theorem 4.4
                                                      served. Recall that we asserted that K was initially reﬂexive
 Σ |= ∀a, agt, ψ, s.                                  in Axiom 2.3. Our successor state axiom for K preserves
       OGoal(agt, ψ, s) ∧                             reﬂexivity over all executable sequences of actions.
       [∀requester, ψ0.
                                     0
         (a = REQUEST(requester, agt, ψ ) ⊃           Theorem  4.6
           Goal(agt, ¬ψ0, s)) ∧
                                           0                 Σ |= ∀agt, s.Executable(s) ⊃ K(agt, s, s),
         a 6= CANCELREQUEST(requester, agt, ψ )] ∧
       Know(agt, [∀then.Poss(a, Now) ⊃                                  def   0      0               0
                                                      where Executable(s) = ∀a, s .do(a, s )  s ⊃ Poss(a, s ).
           (ψ[Now, then] ≡ ψ[do(a, Now), then])], s) ⊃
             OGoal(agt, ψ, do(a, s)).
                                                        Similarly, if K is initially transitive and Euclidean, then it
                                                      remains so over any executable sequence of actions.
  We now show a property about only goal contraction. Sup-
pose that an agent only has the goal that ψ in s, and just after Theorem 4.7
s, reqr requests ψ0 of the agent. In some future situation s00,
reqr cancels its request that ψ0, yielding the situation s0. We Σ |= (∀agt, s.Init(s) ⊃ Ktrans(agt, s) ∧ Keuc(agt, s)) ⊃
assume that there was only one request of the agent for ψ0      (∀agt, s.Executable(s) ⊃ Ktrans(agt, s)) ∧
from reqr, and that no other REQUEST or CANCELREQUEST           (∀agt, s.Executable(s) ⊃ Keuc(agt, s)),
actions occurred between s and s0. We also assume that ψ al-
ways persists (this condition can be weakened; we assumed it For positive introspection of goals, we need a constraint
to simplify the proof). Then, we can show that the agent only similar to transitivity, but that involves both K and W . We
has the goal that ψ in s. In other words, the request for ψ0 call this constraint cross-transitivity:
was indeed cancelled, and the other “only goals” persisted.
                                                            CrossTrans(agt, s) =def
Theorem 4.5                                                  ∀s1, s2, s3.K(agt, s1, s) ∧ K(agt, s2, s1) ∧
                                                                       W (agt, s , s ) ∧ s  s ⊃
 Σ |= ∀agt, ψ, ψ0, reqr, s, s0, s00. OGoal(agt, ψ, s) ∧                        3 1    2    3
                              0      0                                   W  (agt, s3, s).
        do(REQUEST(reqr, agt, ψ ), s)  s ∧
         0                               0   00
        s = do(CANCELREQUEST(reqr,  agt, ψ ), s ) ∧
                                     0       00
        [∀s1, s2.do(REQUEST(reqr, agt, ψ ), s1)  s ∧ If this constraint is satisﬁed, and K is transitive, then the
                                     0       00
               do(REQUEST(reqr, agt, ψ ), s2)  s ⊃   agents will have positive introspection of goals:
                 s1 = s2] ∧
        [∀s∗, a∗.                                     Theorem  4.8
                               0          ∗  ∗
          do(REQUEST(reqr, agt, ψ ), s) ≺ do(a , s ) ∧
              ∗ ∗     00                                 Σ |= ∀agt, s, ψ.Ktrans(agt, s) ∧ CrossTrans(agt, s) ⊃
          do(a , s )  s ⊃
                  0  00                                                (Goal(agt, ψ, s) ⊃
           (¬∃reqr , ψ .
              ∗                       0      00                           Know(agt, Goal(agt, ψ), s)).
             a  = CANCELREQUEST(reqr   , agt, ψ ) ∨
              ∗                0      00
             a  = REQUEST(reqr , agt, ψ ))] ∧
        [∀a, s1, s2.ψ(s1, s2) ≡ ψ(do(a, s1), s2)] ⊃
                        0                               For negative introspection of goals, we need a constraint
          OGoal(agt, ψ, s ).                          similar to Euclideanness, which we call cross-Euclideanness:

  Just as agents introspect their knowledge, we want agents  CrossEuc(agt, s) =def
to be able to introspect their goals, i.e., if an agent has a goal ∀s1, s2, s3.K(agt, s1, s) ∧ K(agt, s2, s) ∧
(does not have a goal, resp.) that ψ, it should know that it has       W (agt, s3, s) ∧ s2  s3 ⊃
(does not have, resp.) ψ as a goal. We identify constraints               W (agt, s3, s1).
that yield these properties. They are constraints on K and