          Database-Text Alignment via Structured Multilabel Classiﬁcation

                                Benjamin Snyder and Regina Barzilay
                        Computer Science and Artiﬁcial Intelligence Laboratory
                                 Massachusetts Institute of Technology
                              {bsnyder,regina}@csail.mit.edu


                    Abstract                          pairs cannot be used directly for system training without more
                                                      reﬁned alignment of their components. Such an alignment
    This paper addresses the task of aligning a database should explicitly link database entries to the sentences that
    with a corresponding text. The goal is to link in- verbalize their content.
    dividual database entries with sentences that ver-
                                                        In this paper, we investigate a supervised learning approach
    balize the same information. By providing explicit
                                                      to aligning database entries and sentences. For example, con-
    semantics-to-text links, these alignments can aid
                                                      sider a database containing statistics on an American football
    the training of natural language generation and in-
                                                      game and the corresponding newspaper summary. Figure 1
    formation extraction systems. Beyond these prag-
                                                      shows an excerpt from such a database and several summary
    matic beneﬁts, the alignment problem is appeal-
                                                      sentences along with the target alignment.
    ing from a modeling perspective: the mappings be-
    tween database entries and text sentences exhibit   Text-database alignment differs in several important re-
    rich structural dependencies, unique to this task. spects from word alignment in machine translation. First, the
    Thus, the key challenge is to make use of as many databases and texts are not exactly parallel: many database
    global dependencies as possible without sacriﬁc-  entries may not be verbalized in a text, and conversely, some
    ing tractability. To this end, we cast text-database sentences may contain information not found in a database.
    alignment as a structured multilabel classiﬁcation Second, the number of items to be aligned is greater than the
    task where each sentence is labeled with a subset of number of words in translated sentences. A typical database
    matching database entries. In contrast to existing may contain hundreds of entries compared to an average of
    multilabel classiﬁers, our approach operates over 25 words in a newspaper sentence. Finally, the database and
    arbitrary global features of inputs and proposed la- text units to be aligned exhibit rich internal structure and
    bels. We compare our model with a baseline clas-  complex interdependencies. Thus, the database schema pro-
    siﬁer that makes locally optimal decisions. Our re- vides a key for mining semantic relations between entries and
    sults show that the proposed model yields a 15%   corresponding sentences. For instance, in Figure 1 we can
    relative reduction in error, and compares favorably see that the three entries aligned to the ﬁnal sentence bear a
    with human performance.                           strong relationship to one another: the interception leads to a
                                                      drive which culminates in a touchdown run. This relationship
                                                      and many others like it can be determined by examining the
1  Introduction                                       database structure.
Uncovering the mapping between text and its underlying se- One possible approach is to formulate semantics-to-text
mantic representation lies at the core of natural language alignment as simple binary classiﬁcation of sentence-entry
processing. For instance, the goal of information extraction pairs. By considering the content overlap between a database
is to structurally represent the semantic content of a given entry and a sentence, the classiﬁer determines whether they
text. Natural language generation, on the other hand, seeks are aligned. This approach, however, fails to capture depen-
to create such texts from structured, non-linguistic represen- dencies between local alignment decisions such as the one we
tations. Training both information extraction and natural lan- just saw. Local alignments could also lead to overmatching
guage generation systems generally requires annotated data when a sentence contains a single anchor that locally matches
that speciﬁes the mapping between structured representations multiple database entries. For instance, the ﬁnal sentence in
and corresponding fragments of text. Creating these map- Figure 1 contains the name “Brown” and the number “2.” Be-
pings by hand is prohibitively expensive.             sides matching an entry in the play-by-play table, these an-
  An alternative source of data for learning text-to-semantics chors also match the second entry in the fumbles table.1 By
mappings are parallel collections of databases and their cor- making independent decisions for each of these entries, a lo-
responding texts. Such parallel collections are abundant and
are readily available in multiple domains, including terror- 1In American Football, a “fumble” occurs when a ball has been
ism, sports, ﬁnance, and weather. However, text-database dropped and may be recovered by either team.

                                                IJCAI-07
                                                  1713                                                      Research has focused on developing local ranking models
                                                      aiming to minimize the number of incorrect labels predicted
                                                      above correct ones, often ignoring threshold selection or
                                                      treating it as a secondary concern [Elisseeff and Weston,
                                                      2001; Crammer and Singer, 2002; McDonald et al., 2005;
                                                      Schapire and Singer, 1999].
                                                        Our approach shares the initial local ranking step with tra-
                                                      ditional multilabel classiﬁers. However, in a task with struc-
                                                      tured labels, where the set of correct labels exhibit compati-
                                                      bility properties, it is insufﬁcient to choose a cutoff by merely
                                                      looking at the local ranking scores. Therefore, we treat rank-
                                                      ing as a mere pruning step and learn to make intelligent
                                                      threshold selections based on ranking scores as well as re-
                                                      lations between entries. By considering collective properties
                                                      of various label sets, we can mitigate ranking errors.
                                                        Ghamrawi and McCallum  [2005] propose an approach to
                                                      multilabel classiﬁcation using Conditional Random Fields.
                                                      Their approach models co-occurrence dependencies between
Figure 1: Sample target alignment between the NFL database pairs of class labels and individual input features. Our ap-
and summary text.                                     proach, on the other hand, learns weights for features deﬁned
                                                      jointly on the input and sets of (structured) labels. Also, our
                                                      global feature function is not constrained to examining pairs
cal classiﬁer may erroneously align them both to the same of labels, but instead operates over arbitrary label sets.
sentence.                                               Alignment  The problem of word alignment of parallel
  To capture global features of alignments, we cast our prob- bilingual corpora has been extensively studied in machine
lem as a structured multilabel classiﬁcation task. In the mul- translation. While most of the research focuses on un-
tilabel framework, each instance can be assigned any subset supervised models [Brown et al., 1993], recently a num-
of the labels. In our case, we treat the sentences as instances ber of supervised discriminative approaches have been pro-
and label them with the subset of database entries that match posed [Taskar et al., 2005; Lacoste-Julien et al., 2006].
in content. By jointly considering a sentence with an entire Taskar et al. [2005] cast alignment as a graph matching prob-
set of candidate entries, our method ensures the global coher- lem and solve it in an optimization framework. Their model
ence of the aligned set. Moreover, we guide the alignment ﬁnds the global alignment which maximizes word-pair align-
towards sets of entries with favorable structural properties. ment scores, subject to a hard fertility constraint. Recently,
This task is accomplished by using a model that operates over they have reformulated the optimization problem to instead
arbitrary global features of the sentence and proposed entry apply soft constraints on alignment fertility as well as con-
set. However, the number of potential entry sets per sen- trol for other properties speciﬁc to word alignment [Lacoste-
tence is exponential, and therefore this feature space cannot Julien et al., 2006].
be searched exhaustively. To focus on promising label sets,
                                                        Our model differs in that it can consider arbitrary features
we ﬁrst rank all the database entries based on their individual
                                                      of the alignment decisions. For instance, depending on the
match to the input sentence. We then only consider entry sets
                                                      structural properties of the aligned objects, we often wish to
formed by choosing a cut-off in this ranking. Our model then
                                                      encourage, rather than penalize, additional alignments.
selects among the remaining sets by examining their global
alignment features. Although the target entry set may not be
among these candidates, we train our model to choose the set 3 Problem Formulation
closest to the target in Hamming distance.            In an alignment problem each input consists of a set of x vari-
  We evaluate our algorithm on a corpus of manually aligned ables L and a set of y variables R. For each input (L, R) there
text-database pairs in the sports domain. To assess the con- is a target alignment consisting of edges between individual
tribution of our global model, we compare our method with x and individual y variables: A ⊆ L × R. Note that an in-
a local classiﬁer which treats every sentence-entry pair in- dividual x or y variable may occur many times in such an
dependently. Our method achieves a 15% relative reduction alignment.
in error over this baseline, demonstrating the contribution of
                                                        In a structured alignment problem, rather than taking on
global features in our task.
                                                      categorical or numerical values, each x variable encodes an
                                                      element from a set of permissible structures X , and each y
2  Related Work                                       value similarly represents a structure from Y. For example,
Multilabel classiﬁcation A typical multilabel classiﬁer has in our case the x variables are sentences in a text, and the
two stages: ﬁrst, the labels of each input are ranked by a y variables encode entries in a relational database. Thus, an
local scoring function. Then, a regression model predicts input (L, R) represents a text-database pair for a particular
a threshold as a function of the label ranking scores. Fi- NFL football game, and the target alignment A is the set of
nally, all the labels above the predicted threshold are returned. all sentence-entry pairs referring to the same fact or event.

                                                IJCAI-07
                                                  1714  Given a set of inputs and their true alignments, our goal each sentence. In other words, each sentence is an indepen-
is to learn a mapping from inputs to alignments which mini- dent instance that must be labeled with a subset of database
mizes the errors in the predicted alignments.         entries. In essence, by treating entries as structured labels of
                                                      sentences, we reformulate alignment as a structured multil-
4  Modeling Assumptions                               abel classiﬁcation task. The key advantage of our approach
                                                      lies in its ability to consider arbitrary global features of each
Unfortunately, for a particular input (L, R) with |L| = m sentence and its proposed label set. However, since we can-
and |R| = n,thereare2mn   possible alignments. For in- not possibly examine every subset of labels, we need to intel-
stance, in our scenario, where (L, R) is a text-database pair ligently prune the decision space. This pruning is driven by
with around 50 sentences and 330 database entries, it is in- local alignments: for each sentence, all the database entries
feasible to search through this entire space. However, if some are ranked by their individual alignment likelihood. We then
local decisions in the alignments are assumed to be indepen- only consider sets of entries consistent with the ranking. That
dent of others, we can learn a model which makes optimal is, for every predicted label, the labels ranked above it must be
partial alignment decisions and then combines them into a predicted as well. Now that the number of considered candi-
full alignment. Next we describe several degrees of indepen- dates is linear in the number of entries, we can train a model
dence between local alignment decisions that might occur. to choose the one with optimal global characteristics. The
  Full Independence In the case of full independence, the latter stage of this approach is similar in spirit to global parse
likelihood of any pair (x, y) ∈ L × R being aligned is inde- reranking [Collins and Koo, 2005]. However, our approach
pendent of the alignment of any pair (x,y) ∈ L × R when constrains the decision space through local ranking of labels
either x = x or y = y. Assuming this complete indepen- rather than an n-best list produced by a generative model.
dence, we can train a local binary classiﬁer using the m × n Below we formally describe the training and decoding pro-
(x, y) pairs from each of our inputs.                 cedures for text-database alignment.
  Partial Independence A weaker, asymmetric indepen-
dence might occur in one of two ways. Consider any two 5.1 Model Structure
                         
pairs (x, y) ∈ L × R and (x ,y ) ∈ L × R. If the alignment                                  L     |L|  m
                                        x  x        The model takes as an input a set of sentences with =
decisions for these pairs are independent only if = then and a set of database entries R with |R| = n. Each sentence-
we say that the alignments are left-side partially independent. entry pair (x, y) ∈ L × R is represented as a local feature
If, on the other hand, the alignment decisions are independent
                                                     vector Φx,y(x, y). Each component of this vector is a bi-
only if y = y , then the alignments are right-side partially in-                th
                                                      nary feature. For instance, the i component of this vector
dependent.
                                                      may indicate whether the sentence and entry contain the same
  To illustrate these ideas, consider their application to our
                                                      number:
task of text-database alignment. Left-side partial indepen-         
dence would occur if the set of entries verbalized in a sentence       1  if x and y contain the same number
                                                      (Φx,y(x, y))i =
is independent of those chosen for any other sentence. But at          0  otherwise
the same time, the entries to be verbalized in a particular sen-
tence are chosen jointly and dependently – if, for example, a In addition, our model captures dependencies among mul-
sentence mentioning a score is more likely now to mention a tiple entries aligned to the same sentence. We represent a
play which led to the score. We could thus train a model to sentence x ∈ L paired with a set of candidate entries Y ⊆ R
choose the optimal aligned set of entries individually for each with the global feature vector Φx(x, Y ). The components
sentence.                                             here are also binary features. For example, the ith may indi-
                                                      cate whether all the entries in Y match the same name in the
                                                      sentence:
5  Algorithm                                                         
                                                                        1  ∀y ∈ Y contain the same name
To strike an appropriate balance between tractability and (Φx(x, Y ))i =
model richness, we base our text-database alignment method              0  otherwise
on a partial independence assumption. In particular, we as-
sume that alignment decisions for each sentence are indepen- Our model predicts alignments in two basic steps.
dent of other alignment decisions. At the same time, we allow Step One The goal of this step is to prune the decision space
dependencies within the set of database entries aligned to a by inducing a ranking of database entries for each sen-
sentence. Following the terminology introduced in Section 4, tence x ∈ L. To do so, for each each entry y ∈ R,the
this model makes a left-side partial independence assump- model maps the feature vector Φx,y(x, y) to a real num-
tion. We believe that this is a natural choice for this task be- ber. This mapping can take the form of a linear model,
cause a typical sentence conveys several facts that are seman-
tically related in a meaningful way. When these facts are rep-             Φx,y(x, y) · α1
resented in a database, we can capture their inter-relations by
examining the structural links of the corresponding database where α1 is the local parameter vector.
entries.                                                  We then order the entries in R: y1,y2,y3,...,yn such
  As a result of this independence assumption, we can train that Φx,y(x, yi) · α1 ≥ Φx,y(x, yi+1) · α1, ∀i.
a model to make optimal alignment decisions separately for

                                                IJCAI-07
                                                  1715 Step  Two   Given  a  particular ranking of entries
                                                               ←         x, {}             H
    y1,y2,...,yn, for each i ∈  0, 1, ..., n,wedeﬁne                  Φx(    )                =2
                                                           y   ←         x, {y }           H
    the set of i initial elements Yi = {y1,...,yi}. The goal - 1      Φx(    1 )              =3
                                  ∗                        y   ←         x, {y ,y }        H
    of this step is to choose a cut-off i and return Yi∗ as + 2       Φx(    1  2 )           =2
    the aligned set of entries. To do so, our model computes + y3 ←∗  Φx(x, {y1,y2,y3})    H  =1
    a score for each i ∈ 0, 1,...,n based on the global -  y4  ←      Φx(x, {y1,y2,y3,y4}) H  =2
    feature vector Φx(x, Yi)
                                                      Table 1: To select the training target for the global model, we
                                                                     ∗
                     Φx(x, Yi) · α2                   select the cut-off i which minimizes the Hamming distance
                                                      H to the true label set. “+” and “-” indicate whether a label is
    where α2 is the global parameter vector. The ﬁnal output                               ∗
                        ∗                             in the true label set or not. In this example, i =3, since the
    of the model is Yi∗ ,fori =argmaxi Φx(x, Yi) · α2.
                                                      set {y1,y2,y3} has the minimum Hamming distance.
5.2  Training the Model
We are given a training corpus with text-database pairs (L, R) 6 Features
and alignments A ⊆ L × R.                             In this section we describe local and global features used by
 Training for Step One  For the label ranking model   our model.
    Φx,y(x, y) · α1, the scores returned by a classiﬁer or
    ranking model may be used. Standard training tech- Local Features
    niques can be applied to learn this model. In fact, we We assume that a high overlap in names and numbers in-
    employed an SVM  classiﬁer with a quadratic kernel as creases the likelihood that a given sentence-entry pair is
    it yielded the best results for our task.         aligned. Thus, our local alignment is driven by anchor-based
                                                      matching. A feature vector generated for each sentence-entry
 Training for Step Two The global model Φx(x, Yi) · α2
                                                      pair captures various statistics about name and number over-
    is trained using the label ranking returned by the local
                                                      lap. To further reﬁne the matching process, these features
    model. For each sentence x ∈ L it considers all en-
                                                      also represent the unigrams and bigrams surrounding each
    try sets Y0, ..., Yn formed by varying the cut-off point of
                                                      matched name and number. In addition, the feature vector
    the initial ranking. However, the true alignment may not
                                                      includes the type of database entry as certain entry types (i.e.,
    be among these sets: the ranking may have incorrectly
                                                      scoring summary) are more commonly verbalized in text.
    placed an unaligned entry above an aligned entry, in ef-
                                                      Close to 60,000 local features are generated. See Table 2 for
    fect pruning away the true target. Therefore, to identify
                                                      a list of local feature templates.
    a new target alignment set Yi∗ , we need to identify the
    closest remaining entry set.                      Global Features
    As our similarity metric between two sets A and B,we
                                                      Our global model jointly considers a sentence with an entire
    use the Hamming distance H(A, B) (deﬁned as the car-
    dinality of the symmetric difference of A and B). For set of candidate entries, seeking alignments with favorable
                                                      structural properties. We select global features that express
    each input (L, R), and each sentence x ∈ L, we identify
    the cut-off in the ranking which produces the entry set these properties, thereby allowing our model to correct local
    closest in Hamming distance to the true label set T : decisions. Two simple global features that we used are the
                                                      number of aligned entries and the Hamming distance between
                  ∗
                 i  =argminH(Yi,T)                    aligned entries and the set predicted by a local model. We can
                           i                          group the remaining global features into three classes based
    This process of identifying a training target for the on the type of dependency they capture:
    global model is illustrated in Table 1.             • Co-occurrence of entry types A simple analysis of the
    Once all the training targets in the corpus have been aligned corpus reveals that certain entry types tend to
    identiﬁed through this procedure, the global linear   be aligned together to the same sentence. For instance,
    model is learned using a variant of the Perceptron    entries from the play-by-play table are often verbalized
    algorithm [Collins and Duffy, 2002]. This algorithm   together with entries from the scoring-summary table.
    encourages a setting of the parameter vector α2 that  To model this property, we introduce features for each
    will assign the highest score to the global feature vector commonly occurring set of entry types. These features
                                  ∗
    associated with the optimal cut-off i .               parallel the label-pair co-occurrences modeled in Gham-
                                                          rawi and McCallum [2005], but are not limited to pairs.
α2 ← 0                                                  • Local match overlap A common error of local align-
For each  (L, R) and each sentence    x ∈ L:              ments is overmatching. A number that appears once
       max
      i    ←  arg maxi Φx(x, Yi) · α2                     in a sentence may be erroneously matched to multiple
      if imax = i∗, set:                                 database entries during local alignment. For instance,
            α2 ← α2 +Φx(x, Yi∗ )                          consider the example in Figure 2: the number 4 in the
            α2 ← α2 − Φx(x, Yimax )                       sentence causes an overmatch with two database entries
                                                          that contain this number. By examining the entire set

                                                IJCAI-07
                                                  1716 NAME  MATCH=(name category in entry) LEX=(bigrams)                         Precision  Recall   F-measure
 NUM  MATCH=(num category in entry) LEX=(bigrams)      SVM baseline          84.33%    70.67%    76.90%
 ENTRY  TYPE=(entry type)                              Multilabel Global     87.26%   74.48%     80.31%
 COUNT  NUM  MATCHES=(count of num matches)            Threshold Oracle      94.13%    85.76%    89.75%
 COUNT  NAME  MATCHES=(count of name matches)          Multilabel Regression 77.65%    64.08%    70.21%
 %NUMS=(percent of nums in entry matched)              Graph Matching        73.36%    64.47%    68.63%
 %NAMES=(percent of names in entry matched)
                                                      Table 4: 10-fold cross validation results for the baseline, our
Table 2: Local feature templates. Text enclosed by brackets global multilabel model, an oracle, and two other approaches.
is replaced as appropriate. Also, various backoffs are used,
such as using unigrams or no lexicalization at all in the ﬁrst 7 Evaluation Setup
two features.
                                                      Corpus For our evaluation, we used the NFL football corpus
                                                      previously used by Barzilay and Lapata [2005]. This corpus
 COUNT=(number of entries in set)                     contains text-database pairs for 466 football games played
 DIFF=(hamming distance to local prediction)          over the 2003 and 2004 seasons. The database contains a
 ENTRY  TYPES=(combination of entry types)            wealth of statistics describing the performance of individual
 PLAYS ALONE=(plays w/o corresponding scores)         players and their teams. It includes a scoring summary and
 SCORES  ALONE=(scores w/o corresponding plays)       a play-by-play summary giving details of the most important
                                                      events in the game together with temporal (i.e., time remain-
 PAIRS=(corresponding play/score pairs)
                                                      ing) and positional (i.e., location in the ﬁeld) information.
 MATCHED   DRIVE=(drive with its plays or score)      This information is organized into several table types includ-
 UNMATCHED   DRIVE=(drive with other plays or scores) ing aggregate statistics, scoring summary, team comparison,
 MATCHED1   ENTRIES=(# entries matched by num)        drivechart,andplaybyplay. Each game is typically repre-
 MATCHED2   ENTRIES=(# entries matched by name)       sented by 330 database entries. The accompanying texts are
 SHARE1  ENTRIES=(# entries sharing nums)             written by Associated Press journalists and typically contain
 SHARE2  ENTRIES=(# entries sharing name)             50 sentences.
 UNMATCHED1   ENTRIES=(# entries unmatched by num)      Annotation In order to train and evaluate our model, we
 UNMATCHED2   ENTRIES=(# entries unmatched by name)   had a human annotator explicitly mark the linked sentence-
 MATCHED   NUMS=(# of matched nums in sentence)       entry pairs for a set of 78 games. We also conducted a human
                                                      interannotator agreement study on a smaller set of 10 games.
 SHARED  NUMS=(# of shared nums in sentence)
                                                      We compute a Kappa statistic over the chance of agreement
 MATCHED   NAMES=(# of matched names in sentence)     for both positive and negative alignment decisions. We found
 SHARED  NAMES=(# of shared names in sentence)        high agreement between annotators, yielding a Kappa score
                                                      of 0.73.
           Table 3: Global feature templates.           On average, 24 sentence-entry pairs (out of 330 × 50)are
                                                      aligned per game. These alignments include about 6% of all
                                                      database entries and about 28% of all sentences. Most aligned
    of proposed entries simultaneously, we can separately sentences are aligned to more than one database entry.
    count the entries that match distinct sentence anchors as Training and Testing Regime From 78 manually anno-
    well as those that share anchors. The latter number indi- tated texts, we obtain about 1,250,000 entry-sentence pairs,
    cates the degree of overmatching and our model should from which 1,900 represent positive alignments. Given the
    learn to discourage such erroneous alignments.    relatively low number of positive examples, we opted to use
                                                      10-way cross validation for training and testing our algo-
  • Domain-speciﬁc semantic constraints Besides these rithm. We compute precision and recall using aligned pairs
    generic global features, we further reﬁne the alignments as positive examples and unaligned pairs as negative exam-
    using the database semantics deﬁned by its schema. We ples.
    can express a semantic relation between entries by ana-
    lyzing their structural links in the database. For exam- 8 Results
    ple, when summarizing the result of a drive,anyplay The results of the evaluation are shown in Table 4. We ﬁrst
    that occurred during the drive is likely to be mentioned compare our global model to a local classiﬁer. This base-
    as well. While the type co-occurrence feature described line model makes independent alignment decisions for each
    above would capture the correlation between these two sentence-entry pair and is implemented using an SVM classi-
    entry types, it would fail to distinguish this case from ﬁer with a quadratic kernel. The local features used are those
    semantically unrelated drives and plays. We engineered described in Section 6. Our method achieves a 3.4% absolute
    several domain-speciﬁc features of this variety.  reduction in error which corresponds to a 15% relative re-
                                                      duction in error. The global model predicts a different align-
  Overall, 247 global features were generated. See Table 3 ment for 239 out of 3,732 sentences in the corpus. Of these
for a complete list of the global feature templates.  changes, 170 are improvements over the local model, while in

                                                IJCAI-07
                                                  1717