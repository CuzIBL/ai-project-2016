                            Artificial Neural Network for Sequence Learning 

                                Sorin Moga                                             Philippe Gaussier 
                    IASC / ENST Bretagne / GET                                ETIS / Neurocyber / U. of Cergy 
                    BP 832, Brest, 29285, France                           6, av. Ponceau, Cergy, 95014, France 
                    sorin. moga @ enst-bretagne.fr.                                    gaussier® ensea.fr. 


                           Abstract                                     ular intervals. In these models, time proceeds by intervals of 
                                                                        At, and the interval between 2 items of a sequence is con•
     This poster shows an artificial neural network ca•
                                                                        sidered as a few units of At (usually less than 10). In this 
     pable of learning a temporal sequence. Directly 
                                                                        section, we introduce the model       for timing sequence learn•
      inspired from a hippocampus model [Banquet et                                                         1
                                                                        ing with a variable and a long range time interval and we 
     al, 1998], this architecture allows an autonomous 
                                                                        evaluate it. Our model (Fig. 1 -left) is based on the idea that a 
     robot to learn how to imitate a sequence of move•
                                                                        prediction (P-type) neuron learns the timing between 2 items, 
     ments with the correct timing. 
                                                                        or, to be more precise, learns to predict the end of this time in•
                                                                        terval. This time interval starts with the firing of a derivation 
1 Introduction                                                          (D-type) neuron and ends with the firing of an input (E-type) 
This article considers the problem of learning to predict               neuron. The P-type neuron learns this interval using the ac•
events, i.e. to forecast the future behavior of a system us•            tivity of the granular (G-type) group of neurons. 
ing past experience. This problem has often been viewed 
and formalized in neural network theory as so-called tempo•
ral sequence learning. Studying such sequences is a topic 
of research in several domains such as robotic trajectory 
planning, speech or vision processing. For most of these, 
neural networks provide two distinct mechanisms: one for 
spatial information and the other for temporal information. 
The main mechanism stores the sequence events regardless 
of the temporal dependences between them. In parallel, or 
later, the second mechanism, the so-called short time mem•
ory (STM), extracts and learns the temporal relationships be•
                                                                        Figure 1: Left : The overview of the neural model allowing 
tween the events. Moreover, we have shown in previous 
                                                                        time prediction. The G     are time base neurons, P is the pre•
works [Gaussier and Moga, 1998; Andry et al, 2001] that                                           i
                                                                        diction neuron, D and E are formal neurons. Right: detailed 
the capability of learning a temporal sequence is one of most 
                                                                        activity of the P-type neuron. The P neuron firing predict the 
important features of a learning by imitation system. As a 
                                                                        learned time interval. 
capability of learning by observation, imitation is a strong 
learning paradigm for autonomous systems. Imitation can 
improve and accelerate the learning of sensory/motor associ•               Let us consider a simple example: we present the first item 
ations. In our work, oriented to the design of a neural network         and, one second later, we present the second item. The length 

architecture allowing learning by imitation, we are involved            of the interval to be learned is T0 = l.s. The first item forces 
in the first level of imitation [Whiten and Ham, 1992]. This            the D neuron to fire. The firing of the D neuron resets all 
"proto-imitation" level plays a key role in understanding the           the activity of the G neurons. Starting at this instant, the G 
principles of the perception/action mechanisms necessary to             neuron's activity is expressed by Eq. 1 . One second later, 
perform higher order behaviors and it is likely that the proto-         the second item forces the E neuron to fire. The firing of the 
imitation is triggered by a perception ambiguity. In our ap•            E neuron enables the update of the weight between the P and 
proach, the starting point for an ''imitating behavior" imple•          the G neurons i.e. enables the learning of the To interval. 
mentation is the capability of learning temporal sequences of           Finally, when the first item is presented again the D neuron 
movements.                                                              fires again. 920 milliseconds later, i.e. 80 milliseconds before 

2 Temporal sequence learning model                                         1The model is inspired by the functions of two brain structures 
                                                                        involved in memory and time learning: the cerebellum and the hip•
Almost all neural models of sequence learning use a discrete            pocampus (see [Banquet et al.  1998] for further neurobioiogical rcf-
temporal dimension by sampling the continuous time at reg•              erences) 


POSTER PAPERS                                                                                                                        1507  To, the P neuron fires (Fig. 1-right) and predicts an imminent other words, all possibles sequences. Consequently, the size 
 firing of the E neuron.                                       of the CA3 group is the square of the input group (CC). The 
                                                               output group (RO) is a Winner Take All neurons group. A 
                                                               neuron of the RO group has the same signification as a CC 
                                                        (1)    neuron. The RO outputs are connected to the EC inputs via 
 i - position of the neuron in the group (the ith cell of the battery); one-to-one secondary unconditional links. 
    and - time constant and the standard deviation associated with The architecture allows the learning of all kind of simple 
 the ith neuron; - instant of the last reset of the battery.   or cyclic sequences. The size of learned sequences is limited 
                                                               only by the system memory capacity. 
3 Sequence learning architecture 
                                                               4 Conclusion 
Timing learning models are currently used by neurobiologist 
modelers for conditioning simulation iBullock et al, 1994;     The timing learning model and the associated neural net•
Grossberg and Merrill, 1992]. Alternatively, the proposed      works were successfully utilized in [Gaussier and Moga, 
model permits the temporal sequence of events to be learned    1998; Moga, 2000] to teach an autonomous robot different 
and predicted. In our context, a simple sequence is defined    "dances". The proposed model allows the correct timing to 
as an enumeration of events with the associated timing (eg.    be predicted and it concords with Weber's law. Even if We•
"A,B,C) and a cyclic sequence as periodic simple sequence      ber's law concordance is not a prerequisite, it corresponds to 
(eg. "A,B,C,A,B,C,A,... ) with the associated timing. The      a strong constraint of neurobiological inspired models of per•
main idea is to use several batteries of G neurons for learning ception and learning: if the prediction precision is constant 
the timing between two consecutive events and a group of P     then it is not possible to have reinforcement due to repetitive 
type neurons for learning the eveni sequencing. The global     experiments. In addition, this model was successfully em•
architecture is shown in Fig. 2. The input group (CC) can be   ployed [Andry et ai, 2001] to build a learning model based 
viewed as the input interface. Any neuron of this group repre• on the prediction of rhythms as a reward signal and for spatio-
sents a sequence event and it is ON while the corresponding    temporal transition learning in autonomous robot navigation. 
input event is present; otherwise it is OFF. Each CC neuron is These results prove that the proposed neural network archi•
one-to-one linked with EC group of neurons. The EC group       tecture can serve both as a starting point for understanding 
is made up of D-type neurons. Each EC neuron is linked         imitation mechanisms, and as an effective learning algorithm 
with unconditional links to all neurons of a battery in the DG for autonomous robotics. 
group. In the same way, an EC neuron is connected with un•
conditional links to all neurons of the corresponding column   References 
of the CA3 group. The DG group integrates several batteries 
                                                               [Andry et ai, 2001] P. Andry, P. Gaussier, S. Moga, and J. Nadcl. 
                                                                  Learning and communication via imitation: an autonomous robot 
                                                                  perspective. IEEE Transactions on Systems, Man and Cybernet•
                                                                  ics, Part A, 31(5):431 -442, 2001. 
                                                               [Banquet et al, 1998] J.P. Banquet, P. Gaussier, J.L. Contreras-
                                                                  Vidal, and Y. Burnod. The cortical-hippocampal system as a 
                                                                  multirange temporal processor: A neural model. In R. Park and 
                                                                  D. Levin, editors, Fundamentals of neural network modeling for 
                                                                  neuropsychologists, Boston, 1998. MIT Press. 
                                                               [Bullock et al, 1994] D. Bullock, J.C. Fiala, and S. Grossberg. A 
                                                                  neural model of timed response learning in the cerebellum. Neu•
                                                                  ral Networks, 7(6/7): 1101-1114, 1994. 
                                                               [Gaussier and Moga, 1998] P. Gaussier and S. Moga. From 
                                                                  perception-action loops to imitation processes: A bottom-up 
                                                                 approach of learning by imitation. Applied Artificial Intelli-
                                                                 gence: An international Journal, 12(7-8):701-727, 1998. 
Figure 2: Detailed connectivity of the event prediction net•   [Grossberg and Merrill, 1992] S. Grossberg and J. W. L. Merrill. A 
work. The circle size in DG is associated with the time con•     neural network model of adaptively timed reinforcement learning 
stants (mi) of the G type neurons.                               and hippocampal dynamics. Cognitive Brain Research, 1:3-38, 
                                                                  1992. 
                                                               [Moga, 20001 S. Moga. Apprendre par imitation : une nouvelle 
of G-type neurons. A DG battery is equivalent to a Gi group      voie d'apprentissage pour les robots autonomes. PhD thesis, 
of neurons shown in section 2. Each DG neuron is connected       University de Cergy-Pontoise, 2000. 
via conditional links to all neurons of the corresponding row 
                                                               [Whiten and Ham, 1992] A. Whiten and R. Ham. On the nature and 
in the CA3 group. The size of the CC group (respectively EC) 
                                                                 evolution of imitation in the animal kingdom: Reappraisal of a 
is constrained by the maximum length of sequences. Alterna•
                                                                 century of research. In P.J.B. Slater, J.S. Rosenblatt, C. Beer, and 
tively, the size of a DG battery is a function of the prediction 
                                                                 M. Milinski, editors, Advances in the study of behavior, pages 
precision of the time interval between two events of the se•
                                                                 239-283, San Diego, CA, 1992. Academic Press. 
quence. This architecture can learn all event combinations, in 


1508                                                                                                   POSTER PAPERS 