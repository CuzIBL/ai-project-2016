              Game-Tree Search with Combinatorially Large Belief States

                            Austin Parker, Dana Nau, V.S. Subrahmanian
                       Department of Computer Science, University of Maryland
                                    College Park, MD, 20742, USA
                                 Email: {austinjp,nau,vs}@cs.umd.edu


                    Abstract                          kriegspiel chess, Civilization, StarCraft, Quake3, Counter-
                                                      Strike, and FreeCiv. More speciﬁcally:
    In games such as kriegspiel chess (a chess variant
    where players have no direct knowledge of the op- • Belief-state size. Bridge, poker, and scrabble have rela-
    ponent’s pieces’ locations) the belief state’s sizes tively small belief states. At the start of a bridge hand, the
    dwarf those of other partial information games like size of each player’s belief state is about 10,000,000 after
    bridge, scrabble, and poker–and there is no easy    the dummy’s cards have been exposed; and this number
    way to generate states satisfying the given observa- decreases exponentially as the game proceeds. Although
    tions. We show that statistical sampling approaches 10,000,000 may seem like a large number, it is dwarfed by
    can be developed to do well in such games.          the belief-state sizes in several other games. For example,
                                                        in kriegspiel chess,1 the size of each belief state at mid-
    We show that it is not necessary for the random
                                                        game is well above 1013; and in the small world map for
    sample to consist only of game boards that satisfy
                                                        FreeCiv, the belief-state size is about 1030.
    each and every one of a player’s observations. In
    fact, we win 24% more often by beginning with     • Uncertainty model. The uncertainty in bridge, poker, and
    such completely consistent boards and gradually     scrabble is due to external factors that can easily be mod-
    switching (as the game progressed) to boards that   eled stochastically: the random deal of the cards in bridge
    are merely consistent with the latest observation.  or poker, and the random choice of a tile in Scrabble. Thus
                                                        it is easy to tell whether or not a state s is consistent with
    This surprising result is explained by noting that as
                                                        a belief state b, and to assign a probability to s given b.
    the game progresses, a board that is consistent with
    the last move becomes more and more likely to be    In games such as kriegspiel chess, the uncertainty arises
    consistent with the entire set of observations, even from lack of observability of the opponent’s actions. This
    if we have no idea what sequence of moves might     uncertainty has no simple stochastic model. Instead,
    have actually generated this board.                 telling whether a state s is consistent with the current be-
                                                        lief state b means checking whether there is a history (i.e.,
                                                        a sequence of moves) that is consistent with b and leads to
1  Introduction                                         s. In the average case, this takes exponential time.
One of the biggest difﬁculties in using game-tree search al- • Simplifying approximations. In bridge and poker, usually
gorithms in imperfect-information games is that the game the statistical sampling is not done on the game itself, but
trees have huge branching factors. Usually the belief-state on a simpliﬁed approximation in which the state space and
size (the number of current states that are consistent with ev- belief states are much smaller. In bridge, the approxima-
erything a player knows about the game) is combinatorially tion is done by treating various sets of states as if they
large. Hence the number of moves that the opponent might were equivalent, a technique that was ﬁrst used in the game
be able to make, and the number of states that these moves of sprouts [Applegate et al., 1991]. In poker, a linear-
might lead to, are also quite large.                    programming approximation has been used [Billings et al.,
                                                             ]
  The best known way to circumvent this problem is to   2003 . In kriegspiel chess, it is unclear how or whether
do statistical sampling: to generate a set of random game such an approximation could be constructed.
boards consistent with the current belief state, do a perfect- To summarize, our objective is to determine how to make
information game-tree search on each of those game boards, game-tree search work successfully in imperfect-information
and average the minimax values. This has worked well in games that have huge belief states, no simple stochastic
games such as bridge [Smith et al., 1998; Ginsberg, 1999], model of uncertainty, and no obvious way to construct a sim-
scrabble [Sheppard, 2002], and poker [Billings et al., 2003]. pliﬁed approximation of the game. Our results are:
  The success of statistical sampling in the above games
relates, at least in part, to several conditions that do not 1Kriegspiel chess is like ordinary chess except that neither player
hold in various other imperfect-information games, such as can see the other’s pieces. Section 3 gives a fuller description.      procedure Choose-move(S)                        sired number of states in the statistical sample, and i is how
       M  ←  {moves applicable to states in S}        many moves the players have played so far.
       for every s ∈ S and every m ∈ M do             • LOS  (Last Observation Sampling) If there are fewer than
          vs,m ← Evaluate-board(γ(s, m))
                        P                               k last-observation consistent states, then let S contain all
       return argmaxm∈M    s∈S vs,mP (s)                of them; otherwise let S contain k such states chosen at
                                                        random. Return Choose-move(S).
Figure 1: Abstract statistical-sampling algorithm for move eval- • AOS (All Observation Sampling): Let S = ∅. Generate
uation. Evaluate-board is a perfect-information search algorithm a random history hs , . . . , s i. If the history satisﬁes O ,
such as alpha-beta.                                                      1      i                      ij
                                                        then add si to S. Do this repeatedly until |S| = k. Return
                                                        Choose-move(S).
1. We describe several algorithms for generating the random • AOSP (All Observation Sampling with Pool): AOSP re-
   sample of game boards used in the tree search. AOSP  turns both a move and a set of states (a pool) for pj to
   generates game boards that are consistent with the entire use as input to AOSP next move. Every state in the
   sequence O of observations that a player has made during pool is to be consistent with Oij, though we do not as-
   the game. LOS only requires consistency with the last sume that all such states are in the pool. Let S0 be the
   observation oi. HS behaves like AOSP at the beginning of pool AOSP returned last time, and M = {all of the
   the game, but as the game progresses it gradually switches other player’s possible responses to pj’s last move}. Let
   over to behaving like LOS.                           S1  =  {γ(s, m) | s ∈ S0, m  ∈ M,  m  is applicable
2. We analyze the performance of our algorithms theoreti- to s, and γ(s, m) satisﬁes Oij}. If |S1| < k, then let
   cally. Surprisingly, our analysis suggests that there are S2 = S1; otherwise let S2 contain k states chosen at
   cases in which LOS will play well and HS will do better random from S1. Let m = Choose-move(S2). Return
   than AOSP.                                           (m, {γ(s, m) | s ∈ S1}).
                                                      • HS  (Hybrid Sampling): Like AOSP, HS returns a move
3. Our experimental tests in the game of kriegspiel chess
                                                        and a set of states. Compute S and S same as in AOSP.
   conﬁrm our analysis’ hypotheses. In our experiments,                           1     2
                                                        If |S | < k then let S be a set of k − |S | random last-
   Timed LOS (LOS with a time limit) did much better than   2              3                2
                                                        observation consistent states; otherwise S = ∅. Let m =
   random play, Timed AOSP did much better than Timed                                      3
                                                        Choose-move(S   ∪S  ). Return (m, {γ(s, m) | s ∈ S }).
   LOS; and Timed HS did much better than Timed AOSP.                  2   3                         1
                                                        Analyzing the performance of these algorithms is impos-
2  Game-Tree Search with Statistical Sampling         sible without making simplifying assumptions, but there is
                                                      more than one set of assumptions one might make. Below we
To describe how statistical sampling is used for game-tree
                                                      do two analyses, based on two different sets of assumptions.
search in imperfect-information games, we need an abstract
                                                      The differing assumptions lead to differing conclusions about
model for the kinds of games where it is used. For simplicity,
                                                      which algorithm will do better.
we assume the game is zero-sum and there are two players
                                                      Analysis 1: Suppose each state has exactly b children, for
p1, p2 who move in alternation.
  As the game progresses, the players’ moves will generate some constant b. Suppose that we know all of pj’s moves but
                                                      not the other player’s moves. If the number of states is very
a sequence of states Si = hs0, s1, . . .i called the game his-
                                                      large (e.g., 1013 or 1030 as described earlier), then during the
tory. At each state si, each player pj will be able to make an
                                                      early stages of the game, the number of states grows expo-
observation oij of si; usually oij will include complete infor-
                                                                          bi/2                  i
mation about pj’s position and partial information about the nentially, with roughly possible states at the ’th move.
                                                                              s
other player’s position. At si, player pj’s observation history Suppose that for each state where it is the other player’s
                                                                                 O
is Oij = ho1j, o2j, . . . , oiji, and pj’s belief state is bij = {all move, the observation history ij eliminates, on the aver-
                                                                      1/c
states that satisfy Oij}.                             age, some fraction of that player’s possible moves, where
  Our sampling algorithms will be based on the following c > 1. Then the number of possible states at the i’th move
                                                                     i/2
properties of a state s: s is last-observation consistent if it given Oij is (b/c) . Thus the probability of any individual
                                                                                                i/2
is consistent with oij, and all-observation consistent if it is state at depth i being consistent with Oij is (1/c) , which
consistent with Oij.                                  approaches 0 at an exponential rate as i increases.
  Figure 1 shows an abstract version of statistical game-tree Thus, if the game continues to grow as a tree with a branch-
search. S is the sample set of states, γ(s, m) is the state pro- ing factor of b, then our analysis suggests the following:
duced by performing move m in state s, Evaluate-board
is a perfect-information game-tree-search algorithm such as • AOS will be computationally intractable. The probability
                                                        of a random history being consistent with bi is likely to be
alpha-beta, and P is a probability distribution over the states          i/2
in S. Some additional code must be added to handle the case something like 1/c . Thus, in order to produce a sam-
                                                                                                      i/2
where a move m is applicable to some states but not others; ple of size k, AOS will probably need to generate k · c
this code tends to be game-speciﬁc and we discuss it further histories, taking exponential time.
in Section 4.                                         • AOSP is much more efﬁcient computationally than AOS,
  We now can deﬁne four different sampling algorithms that but its sample set S2 will decrease in size as the game pro-
provide input for Choose-move. In each case, k is the de- gresses. The probability of a state s’s successors being  consistent with bi is 1/c, since s is already known to be Since both sets of assumptions represent extremal cases,
  consistent with bi−1. Hence the amount of time needed our hypotheses are that in many games the actual perfor-
  to generate k states for S2 does not increase as quickly as mance is likely to be somewhere in between, such that HS
  it would if we generated the states from random histories will perform somewhat better than AOSP. In other words, we
  like AOS does. It is still the case, however, that as the game hypothesize that in many games, if last-observation consis-
  progresses, S2 will soon become too small for the results tent boards are included in the statistical sample later in the
  to have much statistical signiﬁcance and AOSP’s play will game, this will help rather than hurt the evaluations. Section
  begin to resemble random play.                      5 describes our experimental test of that hypothesis.
• Each board generated by LOS is unlikely to be consistent
  with the current belief state; thus the values computed by 3 Kriegspiel Chess
  LOS are likely to be close to random.               As our test domain, we chose the game of kriegspiel chess
• At the beginning of the game, HS will behave identically [Li, 1994; 1995]. This game is like chess except that neither
  to AOSP. As the game proceeds and the size of S2 de- player can see the other’s pieces. When player x captures one
  creases, HS will put more and more randomly generated of player y’s pieces, a referee announces that he/she has made
  boards into S3, thus making the results more noisy. Thus a capture but not what piece was captured, and the referee re-
  HS’s quality of play is likely to be worse than AOSP’s. moves the captured piece from y’s board but does not say
                                                      what piece captured it. When x tries to make a move that is
Analysis 2: If there are n possible states in the game, then illegal (an attempted pawn take, or moving into check, or at-
the number of moves at each level cannot continue to grow tempting to jump an opponent’s piece), the referee announces
exponentially, but will eventually ﬂatten out. The game that the move is illegal but not why. When x puts y’s king in
“tree” will be a graph rather than a tree, with n nodes (at check, the referee tells both players that y’s king is in check,
most) at each depth, one for each possible state. There will and gives them partial information about how the check oc-
be b edges from each node at depth i to nodes at depth curred (namely by rank, ﬁle, long diagonal, short diagonal,
i + 1, 1/c of which are consistent with any given obser- knight, or some combination of the above). Both players hear
vation; suppose these edges go to a random set of nodes. all referee announcements.
Then for each state s, the probability (under certain indepen- Twenty moves into a kriegspiel chess game, a conservative
dence assumptions) that it is reachable in i moves is about estimate is that at each node of the game tree, the current
             i−3             i−1
min(1, (n − 1)  ((b/c)/(n − 1)) ). In other words, the sequence of observations is consistent with more than 1013
probability that a randomly chosen state s has a history con- board positions. Because of this uncertainty, kriegspiel chess
sistent with Oij approaches 1 at exponentially. This suggests is a notoriously difﬁcult game to win [Li, 1994; 1995]; most
the following:                                        games end in draws.
• As the game proceeds, the amount of time needed by AOS
  will eventually level off; its upper bound will be n times 4 Implementation of the Algorithms
  the amount of time needed by each call to the classical For Choose-move’s Evaluate-board subroutine, we took
  game-tree search algorithm.                         the GPL’ed chess program provided by GNU and modiﬁed it
• Rather than degrading to random play as in Analysis 1, to return a minimax value for a particular board. Note that for
  AOSP’s quality of play will eventually level off at some each s ∈ S we call the evaluation function |M| times, where
  level above that, depending on the number of states avail- |M| is the number of applicable moves (20-40 in kriegspiel).
  able in the pool.                                   The only exception to this is the case where a move m ∈ M
• As the game proceeds, the probability of a randomly gen- is not legal in some state s ∈ S; in this case we omit s when
  erated board being consistent with the current belief state computing the average value for m. As shown in Figure 1,
  will increase toward 1; thus LOS will produce increasingly we then return the move with the highest average value.
  good quality of play. However, its play will be limited by
  the fact that it has no good way to assign relative probabil- 4.1 Algorithms with Time Limits
  ities to its randomly generated boards.             In order to make fair comparisons among LOS, AOSP, and
• At the beginning of the game, HS will behave identically HS, they cannot be implemented in the exact way described
  to AOSP. As the game proceeds and AOSP’s sample size in Section 2. They must be modiﬁed so that one of the inputs
  decreases, HS will ﬁll up the rest of the sample with ran- to the algorithm is t, the amount of time available to decide
  domly generated boards—but as the game proceeds, it will on a move, so that the algorithm can do as well as it can in
  become increasingly likely that these randomly chosen that amount of time. The modiﬁed algorithms—Timed LOS,
  boards are consistent with the current belief state. Thus Timed AOSP, and Timed HS—are described below.
  HS’s quality of play is likely to be better than AOSP’s. We have implemented all three of these algorithms, using
                                                      a combination of C and C++. In the next few months, we in-
Summary.  With the ﬁrst set of assumptions, AOSP is likely tend to make our implementations publicly available, both as
to perform much better than LOS, and somewhat better than open-source software and as a kriegspiel-chess game server
HS. With the second set of assumptions, it is unclear which running on our web site.
of LOS and AOSP will be better, but HS is likely to perform Timed LOS: Rather than taking the set S as input as shown
better than AOS, AOSP, and LOS.                       in Figure 1, Timed LOS generates the members of S one ata time and evaluates them as they are generated, so that it Timed LOS, and (3) Timed HS would perform somewhat
can generate and evaluate as many boards as it can during the better than Timed AOSP. The third hypothesis caused some
time available. Once the time is up, it returns the move whose controversy because it was based on a notion that not all
average value is highest, as shown in Figure 1.       of the authors believed: that the computation time spent in-
  Timed AOSP:  Timed AOSP maintains a pool of states  troducing and evaluating last-observation consistent boards
P  =  {s1, . . . , sp} that are known to be consistent with would not be better spent trying to ﬁnd and evaluate more
the current belief state b. Using an estimate of how long all-observation consistent boards.
Evaluate-board will take on each board, it calculates some To test our hypotheses, we played all three algorithms
number of boards kt that it can evaluate during the available against each other and against a player who moved at random.
time t. The estimate is deliberately a little low, to try to keep Each player plays approximately half of the games as white
Timed AOSP from running overtime and to ensure that there and half of the games as black. All experiments were run
will be time left over to attempt to generate more consistent on Xeon 2.6GHz chips with 500 MB RAM, running Linux.
boards. There are three cases:                        Each player was allowed to spend 30 seconds deciding each
                                                      move, including moves which are decided after an attempted
• If p   ≥    kt then  Timed  AOSP   calls Choose-
                                                      illegal move.
  move({s1, . . . , sk }), and returns the recommended move.
                 t                                      Figure 2 shows the results for the algorithms versus
• If 0 < p < kt then Timed AOSP calls Choose-move(P ),
  and returns the recommended move.                   the random player, Figure 3 shows the results of head-to-
                                                      head tests of the three algorithms. The results include the
• If p = 0 then Timed AOSP returns a random move.     wins/losses/draws, and each player’s average material value
During whatever remains of the available time, AOSP tries at each move of the game (using the standard chess value for
to generate more histories that are consistent with b; and for each piece). We observe the following:
every such history, it adds the resultant board to the pool (see 1. All three algorithms played much better than the random
section 4.2 below).                                      player, conﬁrming our ﬁrst hypothesis. The large number
  Each time the referee makes an announcement, Timed     of draws is unsurprising, since kriegspiel chess is a noto-
AOSP must update the pool to be consistent with the an-  riously difﬁcult game to win.
nouncement. This can cause the pool to either shrink (when
Timed AOSP is told a move is illegal) or to grow (when 2. Timed AOSP and Timed HS both played much better than
Timed AOSP is told that the opponent has moved). This com- Timed LOS, conﬁrming our second hypothesis.
putation occurs at the beginning of AOSP’s turn.      3. Timed AOSP and Timed HS played about equally well
  If the pool were allowed to grow unchecked, it could poten- versus a random player, but Timed HS did signiﬁcantly
tially get quite large; hence we limit its size to 20,000 boards. better than Timed AOSP when the two were played head-
If the number of boards in the pool ever goes higher than to-head. Furthermore, as shown in Figure 4, Timed HS did
this, we remove enough boards to get to the number of boards this using a substantial number of last-observation consis-
down to 10,000. Because the 30 second time limit allows only tent boards as the game progressed.
enough time to call Choose-move on a set about 350 boards
from the pool, this is believed adequate.             The third observation is very interesting, because it suggests
  Timed HS:  Timed HS works the same as Timed AOSP,   that our hypothesis about last-observation consistent boards
                                                      is correct: they become more useful as the game progresses,
with one exception. If 0 ≤ p < kt, then Timed HS gen-
erates a set R of p − k random boards that are consistent because they are more likely to be consistent with the current
                    t                                 belief state. Even though we do not know what probabilities
with oij (called last-observation consistent boards), and calls
Choose-move(P  ∪ R). This rules out the possibility of ever to assign to them in the last line of Choose-move, they still
having to make a random move. It also restricts the amount provide useful information.
of time that Timed HS can spend generating additional boards
to put into the pool.                                 6   Related Work
4.2  Consistent History Generation                    The best-known work on imperfect-information games in-
                                                                                    [
The algorithm for generating additional histories consistent cludes work on the games of bridge Smith et al., 1998; Gins-
                                                               ]         [             ]         [
with b does a depth ﬁrst search through the space of game berg, 1999 , scrabble Sheppard, 2002 , and poker Billings
                                                      et al., 2003]; we discussed this work in Section 1.
histories. At each node, the known game history (Oij) speci-
ﬁes the possible branches. Whenever the algorithm reaches The existing literature on kriegspiel chess is rather small,
a node with multiple branches (corresponding to an oppo- and we believe ours is the ﬁrst attempt to create a kriegspiel
nent’s hidden move in the game history), it randomly orders chess program capable of reasonable play throughout the en-
the branches and proceeds searching according to that order. tire game. Two books have been written on how to play
                                                      kriegspiel chess [Li, 1994; 1995]. [Wetherell et al., 1972]
                                                      have implemented a program to act as the referee who sees
5  Experiments                                        the entire kriegspiel-chess game board and tells each player
Our experimental hypotheses (based on the analyses in Sec- the information described in the second paragraph of Section
tion 2) were that (1) Timed LOS would perform better than 3. [Sakuta et al., 2001] have implemented a search strategy
random play, (2) Timed AOSP would perform better than for some imperfect-information games that are simpler than                              LOS v RAND Material Graph                                                              AOSP v LOS Material Graph
       40                                                                                     40
                                          LOS material when white                                                              AOSP material when white
       35                                 LOS material when black                             35                               AOSP material when black
                                        RAND material when white                                                                 LOS material when white
       30                               RAND material when black                              30                                 LOS material when black
       25                                                                                     25
       20                                                                                     20
       15                                                                                     15
                                                                                           Material  Value
    Material  Value
       10                                                                                     10
        5                                                                                      5
        0                                                                                      0
           0           50           100           150          200          250                   0        50       100      150       200      250       300      350
                                         Move                                                                                   Move

                             AOSP v RAND Material Graph                                                               HS v LOS Material Graph
       40                                                                                     40
                                        AOSP material when white                                                                   HS material when white
       35                               AOSP material when black                              35                                   HS material when black
                                        RAND material when white                                                                 LOS material when white
       30                               RAND material when black                              30                                 LOS material when black
       25                                                                                     25
       20                                                                                     20
       15                                                                                     15
                                                                                           Material  Value
    Material  Value
       10                                                                                     10
        5                                                                                      5
        0                                                                                      0
           0           50           100           150          200          250                   0        50       100      150       200      250       300      350
                                         Move                                                                                   Move

                              HS v RAND Material Graph                                                                HS v AOSP Material Graph
       40                                                                                     40
                                            HS material when white                                                                 HS material when white
       35                                   HS material when black                            35                                   HS material when black
                                        RAND material when white                                                               AOSP material when white
       30                               RAND material when black                              30                               AOSP material when black
       25                                                                                     25
       20                                                                                     20
       15                                                                                     15
                                                                                           Material  Value
    Material  Value
       10                                                                                     10
        5                                                                                      5
        0                                                                                      0
           0           50           100           150          200          250                   0        50       100      150       200      250       300      350
                                         Move                                                                                   Move
     Algorithms          Win (%)       Loss (%)        Draw (%)        Runs               Algorithms          Win (%)          Loss (%)         Draw (%)        Runs
     LOS v rand          39  ±  2      0 ±   0.3       61  ±  2         559               AOSP v LOS          31  ±  4.8       0 ±  1           69  ±  4.8        190
     AOSP v rand         63  ±  2      0 ±   0.3       37  ±  2         560               HS v LOS            38  ±  5         0.5  ±  1        61  ±  5          190
     HS v rand           65  ±  2      0.5  ±  0.3     35  ±  2         558               HS v AOSP           13.3  ±  0.4     10.7  ±  0.4     76  ±  0.5      1669

Figure 2:     Wins/losses/draws percentages plus or minus a 95% con-                   Figure 3:     Wins/losses/draws percentages plus or minus a 95% con-
ﬁdence interval and average material value at each move, in games                      ﬁdence interval and average material value at each move, in head-
between Timed LOS, Timed AOSP, Timed HS, and a random player.                          to-head comparisons of Timed LOS, Timed AOSP, and Timed HS.
Material value is a heuristic measure of a player’s ability. We assign
material value as follows: queen is worth 9, rook 5, bishop 3, knight
3, and pawn 1. The sum of all a player’s pieces material value after
a particular move is the player’s material value for that move.