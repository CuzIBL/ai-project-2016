              Document Summarization using Conditional Random Fields
                  Dou Shen1, Jian-Tao Sun2, Hua Li2, Qiang Yang1, Zheng Chen2
                           1Department of Computer Science and Engineering
                     Hong Kong University of Science and Technology, Hong Kong
                                       {dshen, qyang}@cse.ust.hk
                           2Microsoft Research Asia, 49 Zhichun Road, China
                                 {jtsun, huli, zhengc}@microsoft.com

                    Abstract                          document while an abstract-summary may employ words and
                                                      phrases that do not appear in the original document [Mani,
    Many methods, including supervised and unsuper-   1999]. The summarization task can also be categorized as ei-
    vised algorithms, have been developed for extrac- ther generic or query-oriented. A query-oriented summary
    tive document summarization. Most supervised      presents the information that is most relevant to the given
    methods consider the summarization task as a two- queries, while a generic summary gives an overall sense of
    class classiﬁcation problem and classify each sen- the document’s content [Goldstein et al., 1999]. In addition
    tence individually without leveraging the relation- to single document summarization, which has been ﬁrst stud-
    ship among sentences. The unsupervised methods    ied in this ﬁeld for years, researchers have started to work on
    use heuristic rules to select the most informative multi-document summarization whose goal is to generate a
    sentences into a summary directly, which are hard summary from multiple documents that cover similar infor-
    to generalize. In this paper, we present a Con-   mation. In this paper, we focus on generic single-document
    ditional Random Fields (CRF) based framework      sentence extraction which forms the basis for other summa-
    to keep the merits of the above two kinds of ap-  rization tasks and is still a hot research topic [Yeh et al., 2005;
    proaches while avoiding their disadvantages. What Mihalcea, 2005].
    is more, the proposed framework can take the out-
    comes of previous methods as features and seam-     In the past, extractive summarizers have been mostly based
    lessly integrate them. The key idea of our approach on scoring sentences in the source document based on a set
    is to treat the summarization task as a sequence la- of predeﬁned features [Mani and Bloedorn, 1998]. These fea-
    beling problem. In this view, each document is a  tures include linguistic features and statistical features, such
    sequence of sentences and the summarization pro-  as location, rhetorical structure [Marcu, 1997], presence or
    cedure labels the sentences by 1 and 0. The label absence of certain syntactic features [Pollock and Zamora,
    of a sentence depends on the assignment of labels 1975], presence of proper names, statistical measures of term
    of others. We compared our proposed approach      prominence [Luhn, 1958], similarity between sentences, and
    with eight existing methods on an open benchmark  measures of prominence of certain semantic concepts and re-
    data set. The results show that our approach can  lationships [Gong and Liu, 2001]. Two kinds of approaches
    improve the performance by more than 7.1% and     have been designed to leverage the above features, supervised
    12.1% over the best supervised baseline and unsu- and unsupervised. In most supervised approaches [Kupiec et
    pervised baseline respectively in terms of two pop- al., 1995; Yeh et al., 2005], summarization is seen as a two-
    ular metrics F1 and ROUGE-2. Detailed analysis    class classiﬁcation problem and the sentences are treated in-
    of the improvement is presented as well.          dividually. However, we observe that the individual treatment
                                                      of the sentences cannot take full advantage of the relationship
                                                      between the sentences. For example, intuitively, two neigh-
1  Introduction                                       boring sentences with similar contents should not be put into
Document summarization has attracted much attention since a summary together, but when treated individually, this in-
the original work by Luhn [Luhn, 1958], which has found formation is lost. Sequential learning systems such as Hid-
wide-ranging applications especially with the explosion of den Markov Models have also been applied, but they can-
documents on the Internet. Besides its main role of help- not fully exploit the rich linguistic features mentioned above
ing readers to catch the main points of a long document with since they have to assume independence among the features
less effort, it is also helpful as a preprocessing step for some for tractability [Conroy and O’leary, 2001]. On the other
text mining tasks such as document classiﬁcation [Shen et al., hand, unsupervised approaches rely on heuristic rules that are
2004].                                                difﬁcult to generalize. What is ideal for us is to develop a
  Document summarization can be categorized along two machine learning method based on a training corpus of doc-
different dimensions: abstract-based and extract-based. An uments, which can take full advantage of the inter-sentence
extract-summary consists of sentences extracted from the relationship and rich features which may be dependent.

                                                IJCAI-07
                                                  2862  In this paper, we tackle the extractive summarization prob- ture space is small by taking some special assumptions, they
lem in a different manner from the above approaches. We present two open problems [McCallum et al., 2000]. Firstly,
take the summarization task as a sequence labeling problem when the feature space is large and the features are not in-
instead of a simple classiﬁcation problem on individual sen- dependent or are even overlapping in appearance, the train-
tences. In our approach, each document is considered as a ing process will become intractable. Therefore this approach
sequence of sentences and the objective of extractive summa- cannot fully exploit the potential useful features that we have
rization is to label the sentences in the sequence with 1 and mentioned above for the summarization task due to the com-
0, where a label of 1 indicates that the sentence is a sum- putational inefﬁciency. Secondly, the above approaches set
mary sentence while 0 denotes a non-summary sentence. The the HMM parameters to maximize the likelihood of the ob-
label of one sentence is expected to impact on the labels of servation sequence. By doing so, the approach fails to predict
other sentences that are nearby. To accomplish this task, we the sequence labels given the observation sequences in many
apply conditional random ﬁeld (CRF) [Lafferty et al., 2001] situations because they inappropriately use a generative joint-
in this paper, which is a state-of-the-art sequence labeling model in order to solve a discriminative conditional problem
method. With CRF, we provide a framework for leverag- when observations are given. Our work in this paper is aimed
ing all the features even if they may be complex, overlap- at solving such problems by CRF.
ping and not independent. Thus we can fully incorporate our Many unsupervised methods have been developed for doc-
knowledge and intuition of extractive summarization by in- ument summarization by exploiting different features and re-
troducing proper features more effectively. Besides that, the lationships of the sentences as we mentioned above, such
framework can ensemble the outcomes of other summariza- as rhetorical structures [Marcu, 1997], lexical chains [Barzi-
tion methods in a uniﬁed way by designing features for them. lay and Elbadad, 1997], the hidden topics in the documents
Our CRF-based approach carries out the summarization task [Gong and Liu, 2001] and graphs based on the similarity of
in a discriminative manner, by conditioning the whole la- sentences [Mihalcea, 2005]. The methods based on the last
bel sequence on the sentence sequence, which can maximize two features require less extra resources and efforts while still
the likelihood of the global label sequence as well as max- achieve better performances compared to other methods, as
imize the consistency among the different labels in the se- shown in [Gong and Liu, 2001] and [Mihalcea, 2005]. There-
quence. As a result, this approach overcomes many of the fore, we now review these two works in more detail and com-
disadvantages of the previous supervised and unsupervised pare our approach with them in the experiments.
approaches. The experimental results on an open benchmark In [Gong and Liu, 2001], the authors observed that hidden
data set from DUC01 (http://duc.nist.gov/) show that our pro- topics can be discovered in a document as well as the projec-
posed approach can improve the performance compared to tion of each sentence on each topic through Latent Semantic
the state-of-the-art summarization approaches.        Analysis [Deerwester et al., 1990]. They selected the sen-
                                                      tences which have the large projections on the salient topics
                                                      to form the summary. In Mihalcea’s work [Mihalcea, 2005],
2  Related Work                                       she constructed a graph in which each node is a sentence
Supervised extractive summarization approaches treat the and the weight of the edge linking two nodes is the simi-
summarization task as a two-class classiﬁcation problem at larity between the corresponding sentences. The direction
the sentence level, where the summary sentences are posi- of the edges can be decided by the appearance order of the
tive samples while the non-summary sentences are negative sentences. After constructing the graph, she employed some
samples. After representing each sentence by a vector of fea- graph-based ranking algorithms like HITS [Kleinberg, 1999]
tures, the classiﬁcation function can be trained in two differ- and PageRank [Brin and Page, 1998] to decide the importance
ent manners. One is in a discriminative way with well-known of a vertex (sentence) which can take into account the global
algorithms such as Support Vector Machines (SVM) [Yeh et information recursively computed from the entire graph.
al., 2005]. Although such classiﬁers are effective, they as- Some previous work has also considered to reduce the re-
sume that the sentences are independent and classify each dundancy in summary. A typical method is based on the cri-
sentence individually without leveraging the relation among teria of Maximal Marginal Relevance (MMR) [Carbonell et
the sentences. Hidden Markov Model based methods attempt al., 1997]. According to MMR, a sentence is chosen for in-
to break this assumption [Conroy and O’leary, 2001].In clusion in summary such that it is maximally similar to the
Conroy et al’s work, there are two kinds of states, where document and dissimilar to the already-selected sentences.
one kind corresponds to the summary states and the other This approach works in an ad hoc manner and tends to se-
corresponds to non-summary states. The observations are lect long sentences. However, in this paper, the redundancy
sentences that are represented by a vector of three features. is controlled by a probabilistic model which can be learned
Given the training data, the state-transition probabilities and automatically.
the state-speciﬁc observation probabilities can be estimated
by the Baum-Welch algorithm or an EM algorithm [Rabiner, 3 A CRF-based Summarization Approach
1990]. Given a new document, the probability that a sentence
corresponds to a summary state can be calculated. Finally, 3.1 Motivation
the trained model can be used to select the most likely sum- Our intuition comes from our observations on how humans
mary sentences. Although such approaches can handle the summarize a document by posing the problem as a sequence
positional dependence and feature dependence when the fea- labeling problem. A document can be regarded as a sequence

                                                IJCAI-07
                                                  2863of sentences that can be partitioned into several segments Parameters Estimation
where each segment is relatively coherent in content. In order Let Λ={λk,μl} be the set of weights in a CRF
to generate a summary with good coverage and low redun- model. Λ is usually estimated by a maximum  likeli-
dancy, we need to select a representative sentence from each hood procedure, that is, by maximizing the conditional log-
segment. Therefore, we have to read the document from the likelihood of the labeled sequences in the training data Ψ=
beginning to the end and judge the informativeness of each {(X1,Y1),...,(XN ,YN ))}, which is deﬁned as:
sentence while reading. If we encounter a sentence which is               
informative enough, we will put it into the summary. After         LΛ =       log(PΛ(Yj|Xj))          (2)
reading more sentences and encountering better ones, the de-            j=1..N
cision on a previous sentence may be changed. Therefore,
the procedure of summarization is kind of sequence labeling. To avoid overﬁtting, some regularization methods are em-
The goal is to produce a label sequence corresponding to the ployed [Peng and McCallum, 2006]. A common method is
sentence sequence with a label of 1 denoting the summary to add a Gaussian prior over the parameters:
sentences and 0 denoting the non-summary sentences.                                    2        2
                                                                                        λk       μl
                                                        LΛ =       log(PΛ(Yj|Xj)) −        −          (3)
  However, the informativeness cannot be easily measured                               2σ2       2σ2
directly by machines. Fortunately, the sentences can be char- j=1..N                 k   k    l    l
acterized by some features such as their lengths, positions in 2   2
the article and the terms that they contain. The judgment cri- where σk and σl are the variances of the Gaussian priors.
teria can be learned from the ground-truth samples generated Various methods can be used to optimize LΛ, including It-
by people. In other words, given a sequence of sentences rep- erative Scaling algorithms such as GIS and IIS [Lafferty et al.,
resented by certain features, our goal is to label the sentences 2001]. It has been found that a quasi-Newton method such
so that the likelihood of the label sequence given the whole as L-BFGS converges signiﬁcantly faster [Sha and Pereira,
sentence sequence is maximized. In this paper, we use CRF 2003; Malouf, 2002]. Therefore, in this paper, we use L-
as a tool to model this sequence labeling problem.    BFGS.
                                                      Inference
3.2  Conditional Random Fields                        Given the conditional probability of the state sequence de-
For a random variable over data sequences to be labeled X, ﬁned by a CRF in (1) and the parameters Λ, the most probable
and a random variable over corresponding label sequences labeling sequence can be obtained as
Y , Conditional Random Fields (CRF) provide a probabilistic           ∗
                                                                    Y  =  argmaxY PΛ(Y |X)            (4)
framework for calculating the probability of Y globally con-
ditioned on X [Lafferty et al., 2001]. X and Y may have which can be efﬁciently calculated with the Viterbi algo-
a natural graph structure. In this paper, we use a common rithm [Rabiner, 1990]. The marginal probability of states at
special-case structure, which is a linear chain suitable for se- each position in the sequence can be computed by a dynamic
quence labeling. We further assume that there is a one-to-one programming inference procedure similar to the forward-
correspondence between states and labels (two states/labels backward procedure for HMM [Lafferty et al., 2001].We
in our problem: summary sentence and non-summary sen- can deﬁne the “forward values” αi(y|X) by setting α1(y|X)
tence). Given an observation sequence (sentence sequence equal to the probability of starting with state y and then iterate
here) X =(x1,...,xT  ) and the corresponding state se- as follows:
                                                                        
quence Y =(y1,...,yT ), the probability of Y conditioned                                   
on X deﬁned in CRFs, P (Y |X), is as follows:               αi+1(y|X)=      αi(y |X)exp (Λi(y ,y,X))  (5)
         ⎛                                  ⎞                            y
                                                              
   1     ⎝                                  ⎠         where Λi(y ,y,X) is deﬁned by:
     exp      λkfk(yi−1,yi,X)+     μlgl(yi,X)   (1)
  ZX
           i,k                  i,l                                      
                                                                                      
                                                           Λi(y ,y,X)=      λkfk(yi = y ,yi+1 = y, X)
where ZX is the normalization constant that makes the prob-               k
ability of all state sequences sum to one; fk(yi−1,yi,X) is                
an arbitrary feature function over the entire observation se-            +     μlgl(yi+1 = y, X)      (6)
quence and the states at positions i and i − 1 while gl(yi,X)                l
is a feature function of state at position i and the observation        
                                                       Then ZX  equals to y αT (y|X). The “backward values”
sequence; λk and μl are the weights learned for the feature
                                                      βi(y|X) can be deﬁned similarly. After that, we calculate
functions fk and gl, reﬂecting the conﬁdence of feature func-
tions. The feature functions can describe any aspect of a tran- the marginal probability of each sentence being a summary
                                                      sentence given the whole sentence sequence by:
sition from yi−1 to yi as well as yi and the global character-
istics of X. For example, fk may have value 1 when yi−1 is                        |   ∗    |
                                                                        |     αi(1 X)  βi(1 X)
a summary sentence while yi is not a summary sentence and       P (yi =1X)=                           (7)
                                                                                     ZX
the similarity between xi−1 and xi is larger than a threshold;
gl has a value 1 when yi is a summary sentence and xi has Thus we can order the sentences based on P (yi =1|X) and
upper-case words.                                     select the top ones into the summary.

                                                IJCAI-07
                                                  28643.3  Feature Space                                    HITS  Scores: as shown in the related work section, a docu-
Many features have been designed for document summariza- ment can be treated as a graph and after applying a graph-
tion and can be leveraged through CRF models. In this paper, based ranking algorithm such as HITS or PageRank, each
we use some common features which are widely used in the sentence gets a score reﬂecting its importance. According to
supervised summarization methods as well as several features [Mihalcea, 2005] and our own experimental results, the au-
induced from the unsupervised methods. The detailed study thority score of HITS on the directed backward graph is more
of other sophisticated features such as the rhetorical relations effective than other graph-based methods. Therefore, we con-
between sentences is left for future work.            sider only these authority scores and take them as features.
Basic Features                                        4   Experiments and Results
The basic features are the commonly used features in pre-
                                                      In this section, we conduct experiments to test our CRF-
vious summarization approaches, which can be extracted di-
                                                      based summarization approach empirically. The data set is
rectly without complicated computation [Yeh et al., 2005].
                                                      an open benchmark data set which contains 147 document-
Given a sentence xi , the features are deﬁned as follows.
                                                      summary pairs from Document Understanding Conference
Position: the position of xi along the sentence sequence of a
                                                      (DUC) 2001 (http://duc.nist.gov/). We use it because it is for
document. If xi appears at the beginning of the document, the
                                                      generic single-document extraction task that we are interested
feature “Pos” is set to be 1; if it is at the end of the document,
                                                      in and it is well preprocessed. We denoted it by DUC01.
“Pos” is 2; Otherwise, “Pos” is set to be 3.
                                                        For the supervised summarization methods, we need to
Length: the number of terms contained in xi after removing
                                                      split the data set into training data set and test data set. In
the words according to a stop-word list.
                                                      order to remove the uncertainty of a data split, a 10-fold cross
Log Likelihood: the log likelihood of xi being gener-
                                                      validation procedure is applied in our experiments, where 9
ated by the document, logP(xi|D). This is calculated by
                                                     folds are used for training and one fold for test. Though we
         k  i       k|             k  i
  wk N(w  ,x )logp(w  D) where N(w  ,x ) is the num-
                                 |                    do not need to split the data set for unsupervised methods, we
ber of occurrences of wk in xi and p(wk D) can be estimated apply the unsupervised methods on the same test data as the
by N(wk,D)/      N(wj,D).
               wj                                     supervised methods, for the convenience of comparison.
Thematic Words: these are the most frequent words in the We use two methods to evaluate the results. The ﬁrst one is
document after the stop words are removed. Sentences con- by Precision, Recall and F1 which are widely used in Infor-
taining more thematic words are more likely to be summary mation Retrieval [Van Rijsbergen, 1979]. For each document,
sentences. We use this feature to record the number of the- the manually extracted sentences are considered as the refer-
matic words in xi .                                   ence summary (denoted by Sref ). This approach compares
Indicator Words: some words are indicators of summary the candidate summary (denoted by Scand) with the reference
sentences, such as “in summary” and “in conclusion”. This summary and computes the precision, recall and F1 values as
feature is to denote whether xi contains such words.  shown in equation (8). We report only F1 for simplicity, since
Upper Case Words:  some proper names are often impor- we come to similar conclusions in our experiments in terms
tant and presented through upper-case words, as well as some of any of the three measurements.
other words the authors want to emphasize. We use this fea-                      
                                                            |           |    |           |
ture to reﬂect whether xi contains the upper-case words.     Sref  Scand      Sref  Scand        2pr
                                                        p =              r =              F1 =        (8)
Similarity to Neighboring Sentences: we deﬁne features          Scand            Sref           p + r
to record the similarity between a sentence and its neighbors.
“Sim to Pre N” and “Sim to Next N” (N = 1, 2, 3) record the A second evaluation method is by the ROUGE toolkit,
                                                      which is based on N-gram statistics [Lin and Hovy, 2003].
similarity of xi to the previous three sentences and next three
sentences respectively. The similarity measurement we use in This tool is adopted by DUC for automatic summarization
this work is the cosine similarity.                   evaluation that was found to highly correlate with human
                                                                              [                  ]
  There are some other popular features such as the number evaluations. According to Lin and Hovy, 2003 , among
of words in the sentence which are also present in the title, the evaluation methods implemented in ROUGE, ROUGE-
and the position of the sentence in its paragraph. However, N (N=1, 2) is relatively simple and works well in most cases.
since the information about the title and the paragraph is not Therefore, we employ only ROUGE-2 for simplicity.
available in the dataset that we are working on, we do not 4.1 Baselines
consider such features in this paper.
                                                      We compare our proposed method with both supervised and
Complex Features                                      unsupervised methods. Among the supervised methods,
LSA  Scores: by decomposing the word-sentence matrix  we choose Support Vector Machine (SVM), Naive Bayes
through Singular Vector Decomposition , we can obtain the (NB), Logistic Regression (LR) and Hidden Markov Model
hidden topics in a document as well as the projection of each (HMM). SVM is one of the state-of-the-art classiﬁers. HMM
sentence on each topic [Gong and Liu, 2001]. Then we can extends NB by considering the sequential information, while
use the projections as scores to rank sentences and select the LR is a discriminative version of NB. At the same time, LR
top sentences into summary. In this paper, we can also treat can be considered as a linear chain CRF model of order zero
such projections as features to reﬂect the importance of the and CRF is a discriminative version of HMM. That is, CRF
sentences.                                            combines the merits of HMM and LR. Recent literature has

                                                IJCAI-07
                                                  2865claimed the advantages of the discriminative models in clas- ods to incorporate the complex features. The results are
siﬁcation problems and the effectiveness of sequential infor- shown in Table 3. Compared to the results only based on
mation in sequence processing [Sutton and McCallum, 2006]. the basic features, as shown in Table 2, we see that the per-
Therefore, a detailed comparison among these methods can formance of all the supervised methods are improved signiﬁ-
make it clear whether CRF really hold these advantages in cantly. After incorporating the complex features, CRF is still
our summarization problem.                            the best method, which improves the values of ROUGE-2 and
  We also compare our approach with four unsupervised F1 achieved by the best baselines by more than 7.1% and
methods. The simplest being to select sentences randomly 8.8%. Compared with the best unsupervised method HITS,
from the document is denoted as RANDOM. The approach  the CRF based on both kinds of features improves the per-
selecting the lead sentences, which is taken as the baseline formance by 12.1% and 13.9% in terms of ROUGE-2 and
popularly on the DUC01 dataset, is denoted as LEAD. A sim- F1, respectively. In fact, the complex features are the out-
ilar method is to select the lead sentence in each paragraph. comes of the unsupervised methods LSA and HITS. To lever-
Since the information about the paragraphs is not available in age the complex features through the supervised methods can
DUC01, we do not include this method as a baseline. Two be thought as a way of combining the outcomes of different
other unsupervised methods we compare include Gong’s al- methods. In order to test the effectiveness of CRF on combin-
gorithm based on LSA and Mihalcea’s algorithm based on ing the outcomes, we compared it to the linear combination
graph analysis. Among the several options of Mihalcea’s al- method used to combine the results of LSA, HITS and CRF
gorithm, the method based on the authority score of HITS on based only on the basic features. By tuning the weight of
the directed backward graph is the best. It is taken by us for each method for combination, the best result we can obtain
comparison. These two unsupervised methods are denoted by on DUC01 is 0.458 and 0.392 in terms of ROUGE-2 and F1
LSA and HITS respectively.                            respectively, where the improvement is not as signiﬁcant as
                                                      CRF based on all the features. Therefore, we can conclude
4.2  Results and Analysis                             that CRF provides an effective way to combine the outcomes
Performance based on the basic features               of different methods by treating the outcomes as features.
The ﬁrst experiment compares our CRF-based method with
the eight baselines, only using the basic features. Tables 1         NB     LR     SVM    HMM     CRF
and 2 show the results of all the methods in terms of ROUGE- ROUGE-2 0.436 0.450  0.449   0.451  0.483
2 and F 1. We can see that RANDOM is the worst method       F1      0.372  0.383  0.385   0.380  0.419
as expected, while CRF is the best in terms of both evalua-
tion metrics. HITS beats all other baselines, which conﬁrms Table 3: Results of supervised methods with all features
the effectiveness of graph-based approaches for discovering          NB     LR     SVM    HMM     CRF
the importance of sentences. LEAD, by simply selecting the ROUGE-2  0.414  0.427  0.425   0.422  0.470
lead sentences, achieves a similar performance to LSA. Both
                                                            F1      0.351  0.365  0.360   0.363  0.411
HMM and LR improve the performance as compared to NB
due to the advantages of leveraging sequential information Table 4: Results of supervised methods with less training data
and discriminative models. LR and SVM achieve similar per-
formance on the summarization problem. By combining the Effect of the size of the training data
advantages of HMM and LR together, CRF makes a further In order to study the impact of the size of the training data
improvement by 8.4% and 11.1% over both HMM and LR in on the supervised methods, we conduct a third experiment.
terms of ROUGE-2 and F1, respectively. In fact, CRF is not We change the training data and test data in the 10-fold cross
just a discriminative version of HMM; it is a more powerful validation procedure, where one fold is for training and the
method in exploiting dependent features. Due to the same other nine folds for test. Table 4 shows the results based on
reason, CRF outperforms HITS by 5.3% and 5.7% in terms both the basic features and the complex features. We can see
of ROUGE-2 and F1, respectively.                      that the performances of all the supervised methods shown in
               RANDOM      LEAD    LSA    HITS        Table 4 are not as good as those given in Table 3, which is
    ROUGE-2      0.245     0.377   0.382  0.431       consistent with our intuition, that is we can obtain more pre-
                                                      cise parameters of the models with more training data. An-
       F1        0.202     0.311   0.324  0.368
                                                      other observation is that the gap in the performance between
        Table 1: Results of unsupervised methods      CRF-based methods and the other four supervised methods
                                                      is clearly larger when the size of the training data is small.
               NB     LR    SVM    HMM     CRF        The reason is that CRF performs better with less training data
   ROUGE-2    0.394  0.415  0.416   0.419  0.454      than HMM  since it does not require the features to specify
      F1      0.336  0.349  0.343   0.350  0.389      completely a state or observation [Lafferty et al., 2001].On
                                                      the other side, HMM, as a generative model, spends a lot of
 Table 2: Results of supervised methods with basic features resources on modeling the generative models which are not
                                                      particularly relevant to the task of inferring the class labels.
Incorporation of the complex features                 The bad performance of NB, LR and SVM may be due to the
The second experiment is to test the effectiveness of the com- fact that they tend to be overﬁtting with a small amount of
plex features as well as the capability of the supervised meth- training data.

                                                IJCAI-07
                                                  2866