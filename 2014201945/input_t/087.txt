               Learning to Classify Texts Using Positive and Unlabeled Data 

                                Xiaoli Li                                      Bing Liu 
                         School of Computing                    Department of Computer Science 
                 National University of Singapore/               University of Illinois at Chicago 
                       Singapore-MIT Alliance                        851 South Morgan Street 
                           Singapore 117543                          Chicago, IL 60607-7053 
                        lixl@comp.nus.edu.sg                              liub@cs.uic.edu 


                        Abstract                               domains, especially those involving online sources [Nigam et 
                                                               al 1998; Liu et ai, 2002]. 
    In traditional text classification, a classifier is built 
                                                                  In [Liu et al, 2002; Yu et al, 2002], two techniques are 
    using labeled training documents of every class. This 
                                                               proposed to solve the problem. One is based on the EM al•
    paper studies a different problem. Given a set P of 
                                                               gorithm [Dempster et al., 1977] (called S-EM) and the other 
    documents of a particular class (called positive class) 
                                                               is based on Support Vector Machine (SVM) [Vapnik, 1995] 
    and a set U of unlabeled documents that contains 
                                                               (called PEBL). However, both techniques have some major 
    documents from class P and also other types of 
                                                               shortcomings. S-EM is not accurate because of its weak 
    documents (called negative class documents), we 
                                                               classifier. PEBL is not robust because it performs well in 
    want to build a classifier to classify the documents in 
                                                               certain situations and fails badly in others. We will discuss 
    U into documents from P and documents not from P. 
                                                               these two techniques in detail in Section 2 and compare their 
    The key feature of this problem is that there is no 
                                                               results with the proposed technique in Section 4. 
    labeled negative document, which makes traditional 
                                                                  As discussed in our earlier work [Liu et al., 2002], 
    text classification techniques inapplicable. In this 
                                                               positive class based learning occurs in many applications. 
    paper, we propose an effective technique to solve the 
                                                               With the growing volume of text documents on the Web, 
    problem. It combines the Rocchio method and the 
                                                               Internet news feeds, and digital libraries, one often wants 
    SVM technique for classifier building. Experimental 
                                                               to find those documents that are related to one's interest. 
    results show that the new method outperforms ex•
                                                               For instance, one may want to build a repository of ma•
    isting methods significantly. 
                                                               chine learning (ML) papers. One can start with an initial 
1 Introduction                                                 set of ML papers (e.g., an 1CML Proceedings). One can 
                                                               then find those ML papers from related online journals or 
Text classification is an important problem and has been       conference series, e.g., AI journal, AAAI, IJCAI, etc. 
studied extensively in information retrieval and machine          The ability to build classifiers without negative train•
learning. To build a text classifier, the user first collects a ing data is particularly useful if one needs to find positive 
set of training examples, which are labeled with               documents from many text collections or sources. Given a 
pre-defined classes (labeling is often done manually). A       new collection, the algorithm can be run to find those 
classification algorithm is then applied to the training data  positive documents. Following the above example, given a 
to build a classifier. This approach to building classifiers is collection of AAAI papers (unlabeled set), one can run the 
called supervised learning/classification because the          algorithm to identify those ML papers. Given a set of 
training examples/documents all have pre-labeled classes.      SIGIR papers, one can run the algorithm again to find 
   This paper studies a special form of semi-supervised text   those ML papers. In general, one cannot use the classifier 
classification. This problem can be regarded as a two-class    built using the AAAI collection to classify the SIGIR 
(positive and negative) classification problem, where there    collection because they are from different domains. In 
are only labeled positive training data, but no labeled nega•  traditional classification, labeling of negative documents 
tive training data. Due to the lack of negative training data, is needed for each collection. A user would obviously 
the classifier building is thus semi-supervised. Since tradi•  prefer techniques that can provide accurate classification 
tional classification techniques require both labeled positive without manual labeling any negative documents. 
and negative examples to build a classifier, they are thus not   This paper proposes a more effective and robust technique 
suitable for this problem. Although it is possible to manually to solve the problem. It is based on the Rocchio method 
label some negative examples, it is labor-intensive and very   [Rocchio, 1971] and SVM. The idea is to first use Rocchio to 
time consuming. In this research, we want to build a classifier extract some reliable negative documents from the unlabeled 
using only a set of positive examples and a set of unlabeled   set and then apply SVM iteratively to build and to select a 
examples. Collecting unlabeled examples or documents is        classifier. Experimental results show that the new method 
normally easy and inexpensive in many text or Web page         outperforms existing methods significantly. 


LEARNING                                                                                                              587  2 Related Work                                                gam et al., 1998; Blum & Mitchell, 1998; Goldman & Zhou, 
                                                               2000; Basu et al, 2002; Muslea et al, 2002; Bockhorst & 
 Many studies on text classification have been conducted in    Craven, 2002]. It has been shown that the unlabeled data 
 the past. Existing techniques including Rocchio, naive Bayes  helps classification. This is different from our work, as we do 
 (NB), SVM, and many others [e.g., Rocchio, 1971; Lewis &      not have any labeled negative training data. 
 Gale, 1994; Vapnik, 1995; Joachims, 1999; Nigam et al, 
 1998; Yang & Liu, 1999]. These existing techniques, how•      3 The Proposed Technique 
 ever, all require labeled training data of all classes. They are 
 not designed for the positive class based classification.     This section presents the proposed approach, which also 
    In [Denis, 1998], a theoretical study of PAC learning      consists of two steps: (1) extracting some reliable negative 
 from positive and unlabeled examples under the statistical    documents from the unlabeled set, (2) applying SVM 
 query model [Kearns, 1998] is reported. [Letouzey et al,      iteratively to build a classifier. Below, we present these 
 2000] presents an algorithm for learning using a modified     two steps in turn. In Section 4, we show that our technique 
 decision tree algorithm based on the statistical query        is much more robust than existing techniques. 
 model. It is not for text classification, but for normal data. 
 In [Muggleton, 2001], Muggleton studied the problem in a      3.1 Finding reliable negative documents 
 Baycsian framework where the distribution of functions 
                                                               This sub-section gives two methods for finding reliable 
and examples are assumed known. The result is similar to 
                                                               negative documents: (1) Rocchio and (2) Rocchio with 
that in [Liu et al, 2002] in the noiseless case. [Liu et al, 
                                                               clustering. The second method often results in better classi•
2002] extends the result to the noisy case. The purpose of 
                                                               fiers, especially when the positive set is small. The key re•
this paper is to propose a robust practical method to im•
                                                               quirement for this step is that the identified negative docu•
prove existing techniques. 
                                                               ments from the unlabeled set must be reliable or pure, i.e., 
    In [Liu et al, 2002], Liu et al. proposed a method         with no or very few positive documents, because SVM (used 
(called S-EM) to solve the problem in the, text domain. It is  in our second step) is very sensitive to noise. 
based on naive Bayesian classification (NB) and the EM 
algorithm [Dempster et al, 1977]. The main idea of the         3.1.1 Method 1: Rocchio 
method is to first use a spy technique to identify some        This method treats the entire unlabeled set U as negative 
reliable negative documents from the unlabeled set. It then    documents and then uses the positive set P and U as the 
runs EM to build the final classifier. Since NB is not a       training data to build a Rocchio classifier. The classifier is 
strong classifier for texts, we will show that the proposed    then used to classify U. Those documents that are classified 
technique is much more accurate than S-EM.                     as negative are considered (reliable) negative data, denoted 
    In [Yu et al., 2002], Yu et al. proposed a SVM based       by RN. The algorithm is shown in Figure 1. 
technique (called PEBL) to classify Web pages given 
                                                                 1. Assign the unlabeled set U the negative class, and the 
positive and unlabeled pages. The core idea is the same as 
                                                                     positive set P the positive class; 
that in [Liu et al., 2002], i.e., (1) identifying a set of re•
liable negative documents from the unlabeled set (called         2. Let  
strong negative documents in PEBL), and (2) building a 
classifier using SVM. The difference between the two             3. Let  
techniques is that for both steps the two techniques use 
different methods. In [Yu et al., 2002], strong negative 
documents are those documents that do not contain any            4. for each document d in U do 
features of the positive data. After a set of strong negative    5. if sim then 
documents is identified, SVM is applied iteratively to           6.  
build a classifier. PEBL is sensitive to the number of              Figure 1: Rocchio extraction using U as negative 
positive examples. When the positive data is small, the 
results are often very poor. The proposed method differs         In Rocchio classification, each document d is represented 

from PEBL in that we perform negative data extraction          as a vector [Salton & McGill, 1983], d = (q1,q2,...,qn). Each 
from the unlabeled set using the Rocchio method and 
                                                               element qi in d represents a word w1 and is calculated as the 
clustering. Although our second step also runs SVM it•
                                                               combination of term frequency (tf) and inverse document 
eratively to build a classifier, there is a key difference. Our 
                                                              frequency (idf), i.e., qi=tf * idf. tf is the number of times that 
technique selects a good classifier from a set of classifiers                          i
built by SVM, while PEBL does not. The proposed method         word w, occurs in d, while 
performs well consistently under a variety of conditions. 
   In [Scholkopf et al, 1999], one-class SVM is proposed.      Here is the total number of documents and < is the 
This technique uses only positive data to build a SVM 
                                                               number of documents where word wt occurs at least once. 
classifier. However, our experiment results show that its         Building a classifier is achieved by constructing positive 
classification performance is poor.                            and negative prototype vectors and (lines 2 and 3 in 
   Another line of related work is the use of a small labeled  Figure 1). and parameters adjust the relative impact of 
set of every class and a large unlabeled set for learning [Ni• positive and negative training examples. = 16 and = 4 are 


588                                                                                                           LEARNING recommended in [Buckley et al, 1994].                         distance (similarity) to and . If a document is located 
   In classification, for each test document it simply uses   on the right-hand-side of//, it is classified as negative oth•
the cosine measure {Salton & McGill, 1983] to compute the     erwise it is classified as positive. However, the positive and 
similarity (sim) of with each prototype vector. The class     negative classes in the data cannot be separated by H well. In 
whose prototype vector is more similar to is assigned to      Figure 2, the positive documents within the regions 1 and 2 
the test document (lines 4-6 in Figure 1). Those documents    will be misclassified as negative documents. 
classified as negative form the negative set RN. 
   In general, it is also possible to use other classification 
methods (e.g., naive Bayesian, SVM) to extract negative data 
from the unlabeled set. However, not all classification tech•
niques perform well in the absence of a "pure" negative 
training set. We experimented with SVM, naive Bayesian 
and Rocchio, and observed that Rocchio produces the best 
results. It is able to extract a large number of true negative 
documents from U with very high precision. 
   The reason that Rocchio works well is as follow: In our     Figure 2: Rocchio classifier is unable to remove some posi•
positive class based learning, the unlabeled set U typically                      tive examples in U 
has the following characteristics: 
1. The proportion of positive documents in U is very small.       In order to further "purify" RN, we need to deal with the 
   Thus, they do not affect very much.                        above problem. We propose the following approach. 
2. The negative documents in U are of diverse topics. Thus,       This approach uses clustering to partition RN into many 
   in the vector space, they cover a very large region.       similarity groups (or clusters). It then uses Rocchio again to 
Since the positive set P is usually homogenous (focusing on   build a classifier using each cluster and the positive set P. 
one topic), they cover a much smaller region in the vector    The classifier is then applied to identify likely positive 
space. Assume that there is a true decision surface S that    documents in the cluster and delete them. The idea is to 
separates positive and negative data. Then, the positive pro• identify and remove some positive documents in RN in a 
totype vector will be closer to S than the negative proto•    localized manner, which gives better accuracy. Since both 
type vector due to the vector summation in Rocchio (line      the cluster and the positive set are homogeneous, they allow 
2 and 3 of Figure 1). Because of this reason, when we apply   Rocchio to build better prototype vectors. 
the similarity computation (in line 5 of Figure 1) to classify    The clustering technique that we use is K-means, which is 
documents, many negative documents will be classified as      an efficient technique. The K-means method needs the input 
positive because they are closer to . This explains why       cluster number k. From our experiments in Section 4, we 
Rocchio can extract negative documents with high precision,   observe that the choice of k does not affect classification 
and positive documents with low precision (but very high      results much as long as it is not too small. Too few clusters 
recall). Our experiments show that this is indeed the case.   may not be effective because the documents in a cluster can 
                                                              still be diverse. Then, Rocchio still cannot build an accurate 
   After some reliable negative documents are found from U 
                                                              classifier. Too many clusters will not cause much problem. 
by Rocchio, we can run SVM using P and RN. Experimental 
results show that this simple approach works very well. Note      This new method can further purify RN without removing 
that we could actually use and in Figure 1 as the final       too many negative documents from RN. The detailed algo•
classifier without using SVM. However, it does not perform    rithm is given in Figure 3. 
well because it tends to classify too many negative docu•         Note that in line 1 we still perform the initial Rocchio 
ments as positive documents (low precision for positive).     extraction as discussed in Section 3.1.1. Thus, the input data 
SVM using RN and P as training data can correct the situa•    for clustering is RN, not U. The reason is that the purity of RN 
tion and produce a more accurate final classifier.            is higher, which allows us to produce better clusters without 
                                                              the influence of too many noisy (positive) documents in U. 
3.1.2 Method 2: Rocchio with Clustering                       Lines 2-3 perform the standard K-means clustering of RN, 
                                                              which produces k clusters, N   N  , ..., N . Based on these 
Rocchio is a linear classifier based on cosine similarity.                                 1   2       k
                                                              clusters, we construct a positive prototype vector pf and a 
When the decision boundary is non-linear or does not con•     negative prototype vector n for the positive set P arid each 
form to the separating plane resulted from cosine similarity, cluster (lines 5 and 6). Line 8 starts the 
Rocchio may still extract some positive documents and put 
                                                              extraction. For each document we try to find the 
them in RN. This will damage the SVM classifier later. Be-
                                                              nearest positive prototype vector to d     (line 9). If the 
low, we propose an enhancement to the Rocchio approach in                                               1
                                                              similarity sim is less than the similarity between d, and 
order to purify RN further, i.e., to discard some likely positive 
                                                              any negative prototype vector n , we put it in our final 
documents from RN. 
                                                              negative set RN' (line 10). The reason for using the proce•
   Figure 2 shows a possible scenario where some positive 
                                                              dures in lines 9 and 10 is that we want to be conservative in 
documents in U may still be in RN. and represent the 
                                                              removing likely positive documents from RN, i.e., not to 
positive and negative prototype vectors respectively. H is the 
                                                              remove too many negative documents. 
decision hyperplane produced by Rocchio. It has the same 


LEARNING                                                                                                             589      1. Perform the algorithm in Figure 1 and generate the     from and put them in the negative set RN, then the last 
         initial negative set RN;                              SVM classifier will be extremely poor. This is the problem 
     2. Choose k initial cluster centers                       with PEBL, which also runs SVM iteratively. In our algo•
         randomly from RN;                                     rithm, we decide whether to use the first SVM classifier or 
     3. Perform K-means clustering to produce k clusters,      the last one (line 7). Basically, we use the SVM classifier at 
                                                               convergence (called S  , line 6) to classify the positive set P. 
         i.e.N,N, N      ;                                                          last
                        k                                      If too many positive documents in P are classified as 
     4. for, j=1to K 
                                                               negative, it indicates that SVM has gone wrong. We then use 
     5.                                                        the first SVM classifier , Otherwise, we use as the 
                                                               final classifier. We choose "as the threshold because we 
     6.                                                        want to be very conservative. Since SVM is very sensitive to 
                                                               noise, when noise is large, the resulting classifier is often 
                                                               very poor. Since our first classifier is always quite strong, 
     7. ; 
                                                               even without catching the last classifier which may be better, 
     8. for each document do                                   it is acceptable. 
     9.Find the nearest positive prototype vectorto               Note that this strategy is not applicable to PEBL because 

                where v = arg max sim                          PEBL's step 1 extracts too few negative documents from U. 
                              j                                Its first SVM classifier is thus very inaccurate. Step 1 of our 
     10. if there exist a  
                                                               proposed technique is able to extract a large number of 
                sim then 
                                                               negative documents from U. Hence, our first SVM classifier 
     11.                                                       is always quite good, although it may not be the best. 
                                                                  Note also that neither the first nor the last SVM classifier 
        Figure 3: Rocchio extraction with clustering. 
                                                               may be the best. This is the case for both PEBL and our 
    After RN' is determined, we can build the final classifier algorithm. In many cases, a classifier somewhere in the 
 using SVM, which takes P and RN' as the positive and          middle is the best. However, it is hard to catch it. We leave 
negative training data respectively.                           this issue to our future research. 

3.2 Step 2: Classifier building                                4 Empirical Evaluation 
This step builds the final classifier by running SVM itera-    This section evaluates the proposed techniques using the 
tively with the document sets P and RN or RN' depending on     Reuters-21578 text collection , which is commonly used 
the method used in step 1. Let Q be the set of the remaining   in evaluating text classification methods. We will also 
unlabeled documents, The algo•                                 compare the proposed techniques with S-EM and PEBL. 
rithm for this second step is given in Figure 4.                  The Reuters-21578 collection contains 21578 text docu•
  1. Every document in P is assigned the class label +1;       ments. We used only the most populous 10 out of the 135 
  2. Every document in RN (RN') is assigned the label -1;      topic categories. Table 1 gives the number of documents in 
 3. Use P and RN (or RN") to train a SVM classifier S„ with    each of the ten topic categories. In our experiments, each 
     / = 1 initially and with each iteration (line 3-5);       category is used as the positive class, and the rest of the 
 4. Classify Q using S,. Let the set of documents in that     categories as the negative class. This gives us 10 datasets. 
     are classified as negative be W\                           Table 1: Categories and numbers of documents in Reuters 
 5. if W = then stop; 
     else  

         goto (3); 
                                                                  Our task is to identify positive documents from the 
 6. Use the last SVM classifier to classify P\ 
                                                               unlabeled set. The construction of each dataset for our 
 7. if more than positive are classified as negative then 
                                                              experiments is done as follows: Firstly, we randomly select 
       use as the final classifier; 
                                                                  of the documents from the positive class and the negative 
     else use as the final classifier; 
                                                              class, and put them into P and N classes respectively. The 
         Figure 4: Constructing the final classifier.         remaining documents from both classes form the 
   The reason that we run SVM iteratively (lines 3-5) is that unlabeled set U. Our training set for each dataset consists of 
the reliable negative set RN from step 1 may not be suffi•    P and U. N is not used as we do not want to change the class 
ciently large to build the best classifier. SVM classifiers (S, in distribution of the unlabeled set V. We also used t/as the test 
line 3) can be used to iteratively extract more negative      set in our experiments because our objective is to recover 
documents from The iteration stops when there is no           those positive documents in U. We do not need separate test 
negative document that can be extracted from [line 5).        sets. In our experiments, we use 7 a values to create different 
   There is, however, a danger in running SVM iteratively.    settings, i.e.,  
Since SVM is very sensitive to noise, if some iteration of 
SVM goes wrong and extracts many positive documents              http://www.rcscarch.att.com/~lcwis/rcuters21578.html 


590                                                                                                           LEARNING 4.1 Evaluation measures                                       to show the accuracy results (as noted earlier, accuracy does 
                                                              not fully reflect the performance of our system). 
Two popular measures used for evaluating text classification 
are the F value and breakeven point. F value is defined as, F =          Table 2: Experiment results for 
          wherep is the precision and r is the recall. F value 
measures the performance of a system on a particular class 
(in our case, the positive class). Breakeven point is the value 
at which recall and precision are equal. However, breakeven 
point is not suitable for our task as it only evaluates the sort•
ing order of class probabilities of documents. It does not give 
indication of classification performance. F value, on the other 
hand, reflects an average effect of both precision and recall. 
This is suitable for our purpose, as we want to identify posi•
tive documents. It is undesirable to have either too small a 
precision or too small a recall. 
   In our experimental results, we also report accuracies. It, 
however, should be noted that accuracy does not fully reflect 
the performance of our system, as our datasets has a large 
proportion of negative documents. We believe this reflects 
realistic situations. In such cases, the accuracy can be high, 
but few positive documents may be identified. 

4.2 Experimental results 
We now present the experimental results. We use Roc-SVM 
and Roc-Clu-SVM to denote the classification techniques 
that employ Rocchio and Rocchio with clustering to extract 
reliable negative set respectively (both methods use SVM for 
classifier building). We observe from our experiments that 
using Rocchio and Rocchio with clustering alone for classi•
fication do not provide good classification results. SVM 
improves the results significantly. 
   For comparison, we include the classification results of 
NB, S-EM and PEBL. Here, NB treats all the documents in 
the unlabeled set as negative. SVM for the noisy situation (V 
as negative) performs poorly because SVM docs not tolerate 
noise well. Thus, its results are not listed (in many cases, its F 
values are close to 0). In both Roc-SVM and Roc-Clu-SVM, 
we used the linear SVM as [Yang & Liu, 1999] reports that 
linear SVM gives slightly better results than non-linear 
models on the Reuters dataset. For our experiments, we im•
plemented PEBL as it is not publicly available. For SVM, we 
used the system [Joachims, 1999]. PEBL also used                         Figure 5 Average results for all a settings 
         S-EM is our earlier system. It is publicly available 
at http://www.cs.uic download.html. From Figure 5, we can draw the following conclusions: 
   Table 2 shows the classification results of various tech•  1. S-EM's results are quite consistent under different set•
niques in terms of F value and accuracy (Ace) for a = 15%        tings. However, its results are worse than Roc-SVM and 
(the positive set is small). The final row of the table gives the Roc-Clu-SVM. The reason is that the negative documents 
average result of each column. We used 10 clusters (i.e., k =    extracted from U by its spy technique are not that reliable, 
10) for /:-means clustering in Roc-Clu-SVM (later we will        and S-EM uses a weaker classifier, NB. 
see that the number of clusters does not matter much).        2. PEBL's results are extremely poor when the number of 
   We observe that Roc-Clu-SVM produces better results           positive documents is small. We believe that this is be•
than Roc-SVM. Both Roc-SVM and Roc-Clu-SVM outper•               cause its strategy of extracting the initial set of strong 
form NB, S-EM and PEBL. PEBL is extremely poor in this           negative documents could easily go wrong without suf•
case. In fact, PEBL performs poorly when the number of           ficient positive data. Even when the number of positive 
positive documents is small. When the number of positive         documents is large, it may also go wrong. For example, 
documents is large, it usually performs well (see Table 3 with   for a = 55%, one F value (for the dataset, trade) is only 
a = 45%). Both Roc-SVM and Roc-Clu-SVM perform well              0.073. This shows that PEBL is not robust. 
consistently. We summarize the average F value results of all 3. Both Roc-SVM and Roc-Clu-SVM are robust with dif•
a settings in Figure 5. Due to space limitations, we are unable  ferent numbers of positive documents. This is important 


LEARNING                                                                                                             591 