          Robust Ontology Acquisition from Machine-Readable Dictionaries

            Eric Nichols                     Francis Bond                    Daniel Flickinger
    Nara Inst. of Science and Technology NTT Communication Science Labs             CSLI
              Nara, Japan             Nippon Telegraph and Telephone Co.       Stanford University
        eric-n@is.naist.jp                    Keihanna, Japan                  California, U.S.A.
                                      bond@cslab.kecl.ntt.co.jp           danf@csli.stanford.edu

                    Abstract                            Our basic approach is to parse dictionary deÔ¨Ånition sen-
                                                      tences with multiple shallow and deep processors, generating
    In this paper, we outline the development of a    semantic representations of varying speciÔ¨Åcity. The seman-
    system that automatically constructs ontologies by tic representation used is robust minimal recursion semantics
    extracting knowledge from dictionary deÔ¨Ånition    (RMRS: Section 2.2). We then extract ontological relations
    sentences using Robust Minimal Recursion Se-      using the most informative semantic representation for each
    mantics (RMRS), a semantic formalism that per-    deÔ¨Ånition sentence.
    mits underspeciÔ¨Åcation. We show that by com-
                                                        In this paper we discuss the construction of an ontology for
    bining deep and shallow parsing resources through
                                                      Japanese using the the Japanese Semantic Database Lexeed
    the common formalism of RMRS, we can extract
                                                      [Kasahara et al., 2004]. The deep parser uses the Japanese
    ontological relations in greater quality and quan-
                                                      Grammar JACY  [Siegel and Bender, 2002] and the shallow
    tity. Our approach also has the advantages of re-
                                                      parser is based on the morphological analyzer ChaSen.
    quiring a very small amount of rules and being
                                                        We carried out two evaluations. The Ô¨Årst gives an automat-
    easily adaptable to any language with RMRS re-
                                                      ically obtainable measure by comparing the extracted onto-
    sources.
                                                      logical relations by verifying the existence of the relations in
                                                      exisiting WordNet [Fellbaum, 1998]and GoiTaikei [Ikehara
1  Introduction                                       et al., 1997] ontologies. The second is a small scale human
Ontologies are an important resource in natural language pro- evaluation of the results.
cessing. They have been shown to be useful in tasks such
machine translation, question answering, and word-sense dis- 2 Resources
ambiguation, among others where information about the rela-
tionship and similarity of words can be exploited. While there 2.1 The Lexeed Semantic Database of Japanese
are large, hand-crafted ontologies available for several lan- The Lexeed Semantic Database of Japanese is a machine
guages, such as WordNet for English [Fellbaum, 1998] and readable dictionary that covers the most common words in
GoiTaikei for Japanese [Ikehara et al., 1997], these resources Japanese [Kasahara et al., 2004]. It is built based on a series
are difÔ¨Åcult to construct and maintain entirely by hand. They of psycholinguistic experiments where words from two ex-
are, however, of proven utility in many NLP tasks, such as isting machine-readable dictionaries were presented to mul-
PP-attachment, where results using WordNet approach hu- tiple subjects who ranked them on a familiarity scale from
man accuracy (88.1% vs 88.2%), while the best methods us- one to seven, with seven being the most familiar [Amano and
ing automatically constructed hierarchies still lag behind (at Kondo, 1999]. Lexeed consists of all open class words with
84.6%) [Pantel and Lin, 2000]. Therefore, there is still a need a familiarity greater than or equal to Ô¨Åve. An example entry
to improve methods of both fully-automated and supervised for the word ¬†√Ä{¬ß  doraiba¬Ø ‚Äúdriver‚Äù is given in Fig-
construction of ontologies.                           ure 1, with English glosses added. The underlined material
  There is a great deal of work on the creation of ontolo- was not in Lexeed originally, we add it in this paper. doraiba¬Ø
gies from machine readable dictionaries (a good summary is ‚Äúdriver‚Äù has a familiarity of 6.55, and three senses. Lexeed
[Wilkes et al., 1996]), mainly for English. Recently, there has 28,000 words divided into 46,000 senses and deÔ¨Åned with
has also been interest in Japanese [Tsurumaru et al., 1991; 75,000 deÔ¨Ånition sentences.
Tokunaga et al., 2001; Bond et al., 2004]. Most approaches Useful hypernym relations can also be extracted from
use either a specialized parser or a set of regular expressions large corpora using relatively simple patterns (e.g., [Pantel et
tuned to a particular dictionary, often with hundreds of rules. al., 2004]). However, even a large newspaper corpus does
In this paper, we take advantage of recent advances in both not include all the familiar words of a language, let alone
deep parsing and semantic representation to combine general those words occurring in useful patterns [Amano and Kondo,
purpose deep and shallow parsing technologies with a simple 1999]. Therefore it makes sense to extract data from machine
special relation extractor.                           readable dictionaries (MRDs).              Ô£Æ                                                                                  Ô£π
                HEADWORD      ¬†√Ä{¬ß      doraiba-
              Ô£Ø                                                                                  Ô£∫
              Ô£ØPOS            noun     Lexical-type noun-lex                                     Ô£∫
              Ô£Ø                                                                                  Ô£∫
              Ô£ØFAMILIARITY    6.5 [1‚Äì7]                                                          Ô£∫
              Ô£Ø               Ô£Æ                                                                 Ô£πÔ£∫
              Ô£Ø                              Ô£Æ     F1   Wh0                                   Ô£π Ô£∫
              Ô£Ø                               S1       /     /                                   Ô£∫
              Ô£Ø               Ô£Ø              Ô£Ø                                                 Ô£∫Ô£∫Ô£∫
              Ô£Ø               Ô£Ø              Ô£Ø     screw turn (screwdriver)                    Ô£∫Ô£∫Ô£∫
              Ô£Ø               Ô£ØDEFINITION    Ô£∞  0  F1   k F 0 √≥ e 8c     e & 1 < 8 2d  ¬∞    Ô£ªÔ£∫Ô£∫
              Ô£Ø               Ô£Ø               S1       / /        /   /  /       / /    /   /   Ô£∫Ô£∫
              Ô£Ø               Ô£Ø                                                                 Ô£∫Ô£∫
              Ô£ØSENSE  1       Ô£Ø                    A tool for inserting and removing screws .   Ô£∫Ô£∫
              Ô£Ø               Ô£Ø                                                                 Ô£∫Ô£∫
              Ô£Ø               Ô£Ø              ¬∞                                                 Ô£∫Ô£∫
              Ô£Ø               Ô£ØHYPERNYM          1 equipment ‚Äútool‚Äù                             Ô£∫Ô£∫
              Ô£Ø               Ô£∞                                                                 Ô£ªÔ£∫
              Ô£Ø                SEM. CLASS    h942:tooli  (‚äÇ 893:equipment)                       Ô£∫
              Ô£Ø                                                                                  Ô£∫
              Ô£Ø                WORDNET       screwdriver1 (‚äÇ tool1)                              Ô£∫
              Ô£Ø               Ô£Æ              ¬∑                           ¬∏Ô£π                      Ô£∫
              Ô£Ø                                   √¥ ¬•  k  √æ U 2d   0                           Ô£∫
              Ô£Ø                               S1        / /    /   /  /                          Ô£∫
              Ô£Ø               Ô£ØDEFINITION                                 Ô£∫                      Ô£∫
              Ô£Ø               Ô£Ø                   Someone  who drives a car Ô£∫                    Ô£∫
              Ô£Ø               Ô£Ø                                           Ô£∫                      Ô£∫
              Ô£ØSENSE  2       Ô£ØHYPERNYM      0 1 hito ‚Äúperson‚Äù            Ô£∫                      Ô£∫
              Ô£Ø               Ô£Ø                                           Ô£∫                      Ô£∫
              Ô£Ø               Ô£∞SEM. CLASS    h292:driveri   (‚äÇ 4:person)Ô£ª                        Ô£∫
              Ô£Ø                                                                                  Ô£∫
              Ô£Ø                                                                                  Ô£∫
              Ô£Ø                WORDNET       driver1 (‚äÇ person1)                                 Ô£∫
              Ô£Ø               Ô£Æ                  Ô£Æ                                     Ô£πÔ£π        Ô£∫
              Ô£Ø                                    S   ¬ã√Ç¬¨   /@ /  /2 /¬Æ ¬ä /X /G /¬Ü√Ä¬≠ /        Ô£∫
              Ô£Ø                                     1                                            Ô£∫
              Ô£Ø               Ô£Ø                  Ô£Ø                                     Ô£∫Ô£∫        Ô£∫
              Ô£Ø               Ô£Ø                  Ô£Ø     In golf, a long-distance club.  Ô£∫Ô£∫        Ô£∫
              Ô£Ø               Ô£ØDEFINITION        Ô£∞     √ç ¬á  }¬ö¬†                       Ô£ªÔ£∫        Ô£∫
              Ô£Ø               Ô£Ø                    S2      /     /  /                   Ô£∫        Ô£∫
              Ô£Ø               Ô£Ø                                                         Ô£∫        Ô£∫
              Ô£ØSENSE  3       Ô£Ø                        A number one wood .              Ô£∫        Ô£∫
              Ô£Ø               Ô£Ø                                                         Ô£∫        Ô£∫
              Ô£Ø               Ô£ØHYPERNYM           ¬Ü√Ä¬≠  2 kurabu ‚Äúclub‚Äù                  Ô£∫        Ô£∫
              Ô£Ø               Ô£Ø                                                         Ô£∫        Ô£∫
              Ô£∞               Ô£∞WORDNET    SENSE   driver5 (‚äÇ club5)                     Ô£ª        Ô£ª

                               DOMAIN             ¬ã√Ç¬¨  1 gorufu ‚Äúgolf‚Äù

                 Figure 1: Entry for the Word doraiba- ‚Äúdriver‚Äù from Lexeed (with English glosses)


 hook(h1)                                                          hook(h9)
       proposition    m rel(h1,h3:)
             qeq(h3:,h17)
        jidousha   n(h4,x5:)                                             jidousha   n(h1,x2)
       udef  rel(h6,x5:)                                                o rel(h3,u4)
             RSTR(h6,h7:)
             BODY(h6,h8:)
             qeq(h7:,h4)
        unten  s 2(h9,e11:present:)                                      unten  s(h5,e6)
             ARG1(h9,x10:)                                              suru  rel(h7,e8)
             ARG2(h9,x5:)
        hito  n(h12,x10:)                                                hito  n(h9,x10)
             ING(h12:,h10001:)
       udef  rel(h13,x10:)
             RSTR(h13,h14:)
             BODY(h13,h15:)
             qeq(h14:,h12)
       proposition    m rel(h10001,h16:)
             qeq(h16:,h9)
       unknown   rel(h17,e2:present:)
             ARG2(h17,x10:)

           RMRS from JACY (deep)                                  RMRS from ChaSen (shallow)
jidosha¬Ø  wo unten    suru hito    ‚Äò‚Äòa person who     drives a   car (lit:     car-A C C  drive  do person)‚Äô‚Äô
                                      Real predicates are shown in bold font.

                              Figure 2: Deep and Shallow RMRS results for doraiba¬Ø22.2  Parsing Resources                                  1. let Pi be the number of real predicates in the deÔ¨Åning
We used the robust minimal recursion semantics (RMRS) de-  sentence

signed in the Deep Thought project Callmeier et al. [2004],  ‚Ä¢ IF Pi = 1 (there is a unique real predicate)
with tools from the Deep Linguistic Processing with HPSG       return: hsynonym: headword, predicatei
Initiative (DELPH-IN: http://www.delph-in.net/).
                                                        2. Initialize a stack of semantic relations to be processed
Robust Minimal Recursion Semantics                         with the semantic relation from the deÔ¨Åning sentence‚Äôs
Robust Minimal Recursion Semantics is a form of Ô¨Çat seman- HOOK (the highest scoping handle)
tics which is designed to allow deep and shallow process-
                                                        3. Pop a semantic relation from the stack and check it
ing to use a compatible semantic representation, while being
                                                           against special predicates that require additional pro-
rich enough to support generalized quantiÔ¨Åers [Frank, 2004].
                                                           cessing
The full representation is basically the same as minimal re-
cursion semantics [Copestake et al., 2003]: a bag of labeled ‚Ä¢ When a relation indicating coordination or con-
elementary predicates and their arguments, a list of scoping   junction is found, locate all of its arguments and
constraints, and a handle that provides a hook into the repre- push them onto the stack for processing
sentation. The main difference is that handles must be unique, ‚Ä¢ IF a special predicate is found, extract its relations
and there is an explicit distinction between grammatical and   and add them to the stack
real predicates.                                             ‚Ä¢ ELSE IF the current semantic relation is a real
  The representation can be underspeciÔ¨Åed in three ways:       predicate, add it to list of extracted semantic heads
relationships can be omitted (such as message types, quan-
tiÔ¨Åers and so on); predicate-argument relations can be omit- Repeat until stack is empty
ted; and predicate names can be simpliÔ¨Åed. Predicate names 4. Return the ontological relations in the list of extracted
are deÔ¨Åned in such a way as to be as compatible as possi-  semantic heads in the form: hrelation: headword,
ble among different analysis engines (e.g. lemma-pos-sense, semantic headi
where sense is optional and the part of speech (pos) is drawn Step 1. checks for a synonym relation, shown by a deÔ¨Åning
from a small set of general types (noun, verb, sahen (ver- sentence containing a genus term with no differentia. Such
                         unten  s
bal noun, . . . )). The predicate is less speciÔ¨Åc than a sentence will have a semantic representation with only a
unten  s 2 and thus subsumes it. In order to simplify the single real predicate.
combination of different analyses, the results are indexed to In Step 2., for more complicated deÔ¨Åning sentences, we
the position in the original input sentence.          try and Ô¨Ånd the genus term, looking Ô¨Årst at the predicate with
  Examples of deep and shallow results for the same sen-
     √¥ ¬•  k √æ U 2d 0                                 the widest scope. This is given by the RMRS‚Äôs HOOK. The
tence                 jidosha¬Ø wo unten suru hito ‚Äúa per- default ontological relation for the genus term is a hypernym.
son who drives a car (lit: car-ACC drive do person)‚Äù are given Step 3. processes each semantic relation in the stack by
in Figure 2 (omitting the indexing). Real predicates are pre- searching for special predicates that require additional pro-
Ô¨Åxed by an underbar ( ). The deep parse gives information cessing in order to retrieve the semantic head. Special pred-
about the scope, message types and argument structure, while icates include explicit relation names (such as ryaku ‚Äúabbre-
the shallow parse gives little more than a list of real and gram- viation‚Äù) and some grammatical predicates. This step iden-
matical predicates with a hook.                       tiÔ¨Åes and processes special predicates, adding any results to
Deep Parser (JACY and PET)                            the stack of unprocessed semantic relations. If a relation is
The Japanese grammar JACY [Siegel and Bender, 2002] was not identiÔ¨Åed as being a special predicate, and it is a non-
run with the PET System for the high-efÔ¨Åciency processing grammatical predicate, then it is accepted as a semantic head,
of typed feature structures [Callmeier, 2002].        and it is added to the list of extracted relations. Step 3 is re-
                                                      peated until the stack is empty.
Shallow Parser (based on ChaSen)                        Special predicates also give information about type of on-
The part-of-speech tagger, ChaSen [Matsumoto et al., 2000] tological relation that has been identiÔ¨Åed. They can con-
was used for shallow processing of Japanese. Predicate Ô¨Årm an implicit hypernym such as with isshu ‚Äúone type‚Äù in
names were produced by transliterating the pronunciation Japanese or identify an entirely different relation, as in the
Ô¨Åeld and mapping the part-of-speech codes to the RMRS su- case of the relation part, which identiÔ¨Åes a meronym rela-
per types. The part-of-speech codes were also used to judge tionship in English or meisho ‚ÄúhonoriÔ¨Åc name‚Äù identifying a
whether predicates were real or grammatical. Since Japanese name relation in Japanese. Specials predicates can also ex-
is a head-Ô¨Ånal language, the hook value was set to be the han- tract non-ontological relations such as domain.
dle of the rightmost real predicate.                    Step 4. returns the list of all non-grammatical predicates
                                                      once all semantic heads have been processed for special rela-
3  Ontology Construction                              tions and no new results are produced.
As outlined in Section 1, our approach to ontology construc- This processing is following in the long tradition of pars-
tion is to process a deÔ¨Ånition sentence with shallow and deep ing such special relationships (also called ‚Äúempty heads‚Äù,
parsers and extract ontological relations from the most infor- ‚Äúfunction nouns‚Äù or ‚Äúrelators‚Äù) [Guthrie et al., 1990; Wilkes
mative RMRS output. Here, we describe the algorithm used et al., 1996]. Our main innovation is to extract them from
to extract ontological relations from an RMRS structure: the semantic representations produced by a deep and shallow  Special predicate Ontological relation               lower coverage, but allow us to extract some of the knowl-
  Japanese                                             edge given explicitly in the lexicon.
  isshu n 1      hypernym
  hitotsu n 2    hypernym                                Although the vast majority of relations extracted are hyper-
  soushou n 1    hyponym                               nym and synonym relations, we extract several other kinds of
  ryakushou s 1  abbreviation                          knowledge, and are thus are closer to an ontology than a sim-
  ryaku s 1      abbreviation                          ple thesaurus.
  keishou n 1    name:honoriÔ¨Åc                           We carried out two evaluations. The Ô¨Årst was an automatic
  zokushou n 1   name:slang                            evaluation, comparing our extracted triples hrelation:
  meishou n 1    name                                  word1, word2i with existing resources. The second was a
  bubun n 1      meronym                               small scale hand evaluation of a sample of the relations.
  ichibu n 1     meronym
                                                       4.1  VeriÔ¨Åcation with Hand-crafted Ontologies
 Table 1: Special predicates and their associated ontological
 relations                                             Because we are interested in comparing lexical semantics
                                                       across languages, we compared the extracted ontology with
                                                       resources in both the same and different languages.
 parsing, rather than using regular expressions or specially de- We veriÔ¨Åed our results by comparing the hypernym links
 signed parsers.                                       to the manually constructed Japanese ontology GT. It is a hi-
                                                       erarchy of 2,710 semantic classes, deÔ¨Åned for over 264,312
 4  Results and Evaluation                             nouns [Ikehara et al., 1997]. The semantic classes are mostly
 We summarize the relationships acquired in Table 2. The Ô¨Årst deÔ¨Åned for nouns (and verbal nouns), although there is some
 two lines show thesaurus type relations: hypernyms and syn- information for verbs and adjectives. Senses are linked to
 onyms. The remaining four lines show other relations: ab- GT semantic classes by the following heuristic: look up the
 breviations, names, meronyms and domains. Hypernyms and semantic classes C for both the headword (wi) and genus
 synonyms are by far the most common relations: fewer than term(s) (wg). If at least one of the index word‚Äôs classes is
 10% of entries are marked with an explicit relationship. subsumed by at least one of the genus‚Äô classes, then we con-
                                                       sider the relationship conÔ¨Årmed (1).
   Results are shown for Lexeed using only the RMRS pro-
 duced by ChaSen, using the results for JACY, and using
 the deepest possible result (JACY if it exists, backing off to
                                                            ‚àÉ(ch, cg) : {ch ‚äÇ cg; ch ‚àà C(wh); cg ‚àà C(wg)} (1)
 ChaSen).
                                                         In the event of an explicit hyponym relationship indicated
                Results for ChaSen                     between the headword and the genus, the test is reversed: we
Relation     Noun   Sahen    Verb  Other   Total       look for an instance of the genus‚Äô class being subsumed by
hypernym    42,235  8,176   9,237  3,346  62,994       the headword‚Äôs class (cg ‚äÇ ch).
synonym      7,278    776   2,005   933   10,992         To test cross-linguistically, we looked up the headwords
Total       49,513  8,952  11,242  4,279  73,986
                                                       in a translation lexicon (ALT-J/E [Ikehara et al., 1991] and
                                                              [          ]
                 Results for JACY                      EDICT   Breen, 2004 ) and then did the conÔ¨Årmation on the
Relation     Noun   Sahen    Verb  Other   Total       set of translations ci ‚äÇ C(T (wi)). Although looking up the
hypernym    31,374  6,748   6,619  2,029  46,770       translation adds noise, the additional Ô¨Ålter of the relationship
synonym      7,831    801   2,220  1,048  11,900       triple effectively Ô¨Ålters it out again.
abbreviation  154       7                   161          For example, for ¬†√Ä{¬ß    3 doraiba-3 ‚Äúdriver3‚Äù, GT
domain        392      28                   420        does not Ô¨Ånd any relationship, as it does not have the golf
other         247                           247        club semantic class label for ¬†√Ä{¬ß  doraiba-. However,
Total       39,998  7,584   8,839  3,077  59,498       looking up T (¬†√Ä{¬ß   ) gives {driver, screwdriver} and
                                                       the extracted hypernym is ¬Ü√Ä¬≠ kurabu ‚Äúclub‚Äù. WordNet
                Results for Deepest                                                2
                                                       recognizes that driver5 is a kind of wood8 which is a kind
Relation     Noun   Sahen    Verb  Other   Total                                                     [
hypernym    45,014  9,647  10,305  3,299  68,265       of club5 (using senses and relations from WordNet 2.0 Fell-
synonym      81,51    827   2,257  1,254  12,489       baum, 1998]). We thus simultaneously conÔ¨Årm the link is
abbreviation  154       7                   161        good; Ô¨Ånd an appropriate translation for this sense of ¬†√Ä
domain        392      28                   420        {¬ß   (and its hypernym); and link these to the appropriate
other         247                           247        WordNet synsems.
Total       53,958  10,509 12,562  4,553  81,582         The results of the evaluation for Lexeed are shown in Ta-
                                                       ble 3. Parts of speech are classiÔ¨Åed as ‚ÄúNoun‚Äù, ‚ÄúVerb‚Äù, ‚ÄúSa-
     Table 2: Results of Ontology Extraction (Lexeed)  hen (Verbal Noun)‚Äù and ‚ÄúOther‚Äù. Relations veriÔ¨Åed in ei-
                                                       ther GT or WordNet are classed as veriÔ¨Åed. In these results,
   As one would expect, the word based analysis using  we only extract relations from the Ô¨Årst deÔ¨Ånition sentence for
 ChaSen Ô¨Ånds more actual relationships, but does not pro- each headword or when there is evidence of a synonym rela-
 vide enough information to Ô¨Ånd anything beyond implicit hy- tion, as other deÔ¨Ånition sentences often provide clariÔ¨Åcation
 pernyms and synonyms. The grammar based analyses have of the Ô¨Årst sentence and may not contain useful ontologicalinformation. However, extracting relations from all deÔ¨Åni- sources. We showed that, by using a well deÔ¨Åned seman-
tion sentences results in a net loss in conÔ¨Årmation of less than tic representation, the extraction can be generalized so much
Ô¨Åve percent while extracting over 5,000 additional relations. that it can be used on very different dictionaries from differ-
This suggests that even secondary deÔ¨Ånition sentences con- ent languages. This is an improvement on the common ap-
tain information that can be exploited in building ontologies. proach to using more and more detailed regular expressions
  Our results using JACY achieve a conÔ¨Årmation rate of (e.g. Tokunaga et al. [2001]). Although this provides a quick
63.31% for nouns only and 55.74% overall, besting Toku- start, the results are not generally reusable. In comparison,
naga et al. [2001], who reported 61.4% for nouns only. Our the ChaSen-RMRS engine is immediately useful for a variety
method also allows us to extract multiple relations from a of tasks, such as question answering and information extrac-
single sentence by processing coordinate clauses. This al- tion [Callmeier et al., 2004]
lowed us to extract an extra 3,300 relations. Using the deepest The other innovation of our approach is the cross-lingual
RMRS parse available, we conÔ¨Årmed 57.68% of the noun re- evaluation. As a by-product of the evaluation we enhance the
lations and 50.49% overall. This is comparable to our results existing resources (such as GT or WordNet) by linking them,
reported in [Bond et al., 2004] with one important difference: so that information can be shared between them. Further, we
we are now extracting over 10,000 more conÔ¨Årmed ontologi- hope to use the cross-lingual links to Ô¨Åll in gaps in the mono-
cal relations.                                        lingual resources. Finally, we can trivially extract links from
  GT and WordNet both lack complete cover - over half the the GT ontology to WordNet, thus combining two useful re-
relations were conÔ¨Årmed with only one resource. This shows sources and allowing us to compare them in detail.
that the machine readable dictionary is a useful source of There are several areas to address in future work as we
these relations. Cross lingual checking was surprisingly ef- continue to pursue ontology acquisition. First, and foremost,
fective, resources in one language can be used to bootstrap in order to increase the quality of the ontological relations
those in another, as seen in the Euro WordNet project. that are extracted, we need to improve the quality of the
4.2  Human Evaluation                                 parsers to generate RMRS. With our HPSG parsers, this can
                                                      be addressed by adjusting the parse ranking model to take
One problem with using existing ontological resources to ver- into account the special features of dictionary deÔ¨Ånition sen-
ify new relations is that only relations which are subsumed by tences. In addition we are currently increasing the coverage
the ontology being used for comparison can be veriÔ¨Åed. This by adding in treatments of more grammatical phenomena.
poses a considerable problem for researchers who wish to ex-
                                                        Another area of great interest is the acquisition of other
tract new relations: be it from domains where such resources
                                                      ontological relations. For example, if we extend our special
are unavailable, or in cases where existing resources are lim-
                                                      predicates to include the relation produced by various forms
ited in scope, such as for verbs. In this case, it makes more
                                                      of negation, we may be able to extract antonym relations.
sense to evaluate a selection of the results retrieved by hand
than to rely completely on existing ontologies for veriÔ¨Åcation. Finally, we would also like to use the links created during
  In this spirit, we conducted a hand-veriÔ¨Åcation of a selec- evaluation which link our ontologies to hand-crafted ontolo-
tion of our automatically acquired relations. 1,471 relations gies, to furtherlink together senses of words across languages.
were selected using a stratiÔ¨Åed method over the entirety of our This kind of cross-lingual ontology would be of great use in
results (every 35th relationship, ordered by link-type and then applications like machine translation.
headword). In this evaluation we only consider synonyms and
any relationships extracted from the Ô¨Årst sentence: the sec- 6 Conclusion
ond and subsequent deÔ¨Ånition sentences tend to contain other
non-hypernomic information. The results were then evalu- We have demonstrated how deep and shallow processing
ated by native speakers of Japanese were given the deÔ¨Ånition techniques can be used together to enrich the acquisition
word, the semantic head we retrieved, and the posited relation of ontological information by constructing an ontology for
type and asked to evaluate if the relation was accurate. They Japanese. Our approach requires few rules and is thus easy to
had access to the original lexicon.                   maintain and expand, and it can be easily extended to cover
  The human judges found the relations presented to them to any language that has RMRS resources. In future research,
be accurate 88.99% of the time. In the 162 relations that were we plan to extend our processing to retrieve more ontological
judged unacceptable, it was also determined that a relation relations and to investigate means of improving the accuracy
did exist in 95 cases, but it was incorrect (i.e. a synonym of output of both deep and shallow processors.
in place of a hypernym and so on). These errors had three
sources: the most common was a lack of identiÔ¨Åed explicit
relationships; the next was lack of information from the shal- References
low parse and the last was errors in the argument structure of [Amano and Kondo, 1999] Shigeaki Amano and Tadahisa Kondo.
the deep parse. Tokunaga et al. [2001] report slightly higher Nihongo-no Goi-Tokusei (Lexical properties of Japanese). San-
results for extracting noun relationships only (91.8%). seido, 1999.
                                                      [Bond et al., 2004] Francis Bond, Eric Nichols, Sanae Fujita, and
5  Discussion and Future Work                           Takaaki Tanaka. Acquiring an ontology for a fundamental vo-
We were able to successfully combine deep and shallow pro- cabulary. In 20th International Conference on Computational
cessing to extract ontological information from lexical re- Linguistics: COLING-2004, pages 1319‚Äì1325, Geneva, 2004.