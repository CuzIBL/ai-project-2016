   A Hybrid Discriminative/Generative Approach for Modeling Human Activities  

Jonathan Lester1, Tanzeem Choudhury2, Nicky Kern3, Gaetano Borriello2,4 and Blake Hannaford1 
      1Department of Electrical Engineering, University of Washington, Seattle WA 98195, USA 
                            2Intel Research Seattle, Seattle, WA 98105, USA 
     3Department of Computer Science, Darmstadt University of Technology, Darmstadt, Germany 
        4Department of Computer Science, University of Washington, Seattle WA 98195, USA 

                    Abstract                          typically accelerometers on several locations on the body 
                                                      [Bao and Intille, 2004; Kern et al., 2003]. The placement of 
    Accurate recognition and tracking of human        sensors in multiple pre-defined locations can be quite 
    activities is an important goal of ubiquitous     obtrusive and is one of the limitations of such an approach. 
    computing. Recent advances in the development of  While the ultimate goal is to embed these devices into 
    multi-modal wearable sensors enable us to gather  clothing, this technology is far from being commercially 
    rich datasets of human activities. However, the   available and widely accepted. As a result, a single sensing 
    problem of automatically identifying the most     device that can be integrated into existing mobile platforms, 
    useful features for modeling such activities remains such as a cell phone, will be more appealing to users and is 
    largely unsolved. In this paper we present a hybrid likely to garner greater user acceptance. Work by [Bao and 
    approach to recognizing activities, which combines Intille, 2004] has shown that an appropriate sensor subset 
    boosting to discriminatively select useful features (two locations), does not effect the recognition scores 
    and learn an ensemble of static classifiers to    significantly (by less than 5%) compared to a system with 
    recognize different activities, with hidden Markov five sensors; whereas the use of a single sensor reduced the 
    models (HMMs) to capture the temporal             average accuracy by 35%. Our hypothesis is that 
    regularities and smoothness of activities. We tested incorporating multiple sensor modalities will offset the 
    the activity recognition system using over 12 hours information lost by using a single sensing device. 
    of wearable-sensor data collected by volunteers in Furthermore, multiple modalities will be better suited to 
    natural unconstrained environments. The models    record the rich perceptual cues that are present in the 
    succeeded in identifying a small set of maximally environment, cues that a single modality often fails to 
    informative features, and were able identify ten  capture. Multiple modalities have already shown promise in 
    different human activities with an accuracy of    earlier activity recognition experiments [Lukowicz et al., 
    95%.                                              2002].  
                                                        To capture the diverse cues from movement, sound, light, 
1   Introduction                                      etc., about ongoing activities, we have built a very small 
The task of modeling human activities from body-worn  sensing unit (2.53 sq. in.) that includes eight different 
sensors has received increasing attention in recent years, sensors: accelerometer, audio, IR/visible light, high-
especially in the ubiquitous computing (Ubicomp) field frequency light, barometric pressure, humidity, temperature, 
[Bao and Intille, 2004; Lukowicz et al., 2004; Patterson et and compass. Using these sensors, we have collected a large 
al., 2003]. Although originally most of the research in annotated dataset of various human activities from two 
activity recognition was done using vision sensors [Gavrila, volunteers over a period of six weeks. We compute over six 
1999; Pentland, 1996], it has increasingly become     hundred different features from these eight sensor 
dominated by various types of wearable sensors, like  modalities, which attempt to capture various attributes of the 
accelerometers and audio. A fertile application domain for raw signal. 
activity recognition is in the health care arena, especially in Often in activity recognition, the choice of sensors and 
elder care support, long-term health-monitoring, and  the features derived from them are driven by human 
assisting those with cognitive disorders. In addition, activity intuition and by what is easily available, rather than by 
recognition is an important component for modeling higher performance or practicality. Using the right features is 
level human behavior, tracking routines, rituals, and social crucial for recognition. We are working towards developing 
interactions.                                         a framework that allows us to systematically identify 
  The majority of research using wearable devices, has modalities and features that are most useful for machine 
concentrated on using multiple sensors of a single modality, recognition and discrimination of natural human activities. In the end, we want models that accurately recognize and different portions of the data. Furthermore, when calculating 
track a variety of activities and a system that is lightweight some features (e.g. the integral features) we incorporate a 
enough to run on devices like cell phones, which many longer time window that varies from several seconds to as 
people already carry. Thus, minimizing the computation long as a minute. We restrict the time windows to only use 
cost of our recognition system is also an important goal.  data from the past, so that our system functions without any 
  The two main approaches that are used for classification latency.  
in machine learning are: (i) generative techniques that 
                                                      Feature Selection and Discriminative Activity Models 
model the underlying distributions of the classes and (ii) 
                                                      Earlier work has shown that discriminative methods often 
discriminative techniques that only focus on learning the 
                                                      outperform generative models in classification tasks [Ng 
class boundaries [Rubinstein and Hastie, 1997]. Both of 
                                                      and Jordan, 2002]. Additionally, techniques such as bagging 
these approaches have been used extensively in the vision 
                                                      and boosting that combine a set of weak classifiers can 
and the wearable sensing communities for recognizing 
                                                      further improve accuracy, without over-fitting to the 
various human behavior and activities. The work presented 
                                                      training data [Schapire, 1999]. [Viola and Jones, 2001] have 
in this paper is a hybrid approach that combines the two 
                                                      shown that boosting can be used not only as a method for 
techniques. First, a modified version of AdaBoost proposed 
                                                      combining classifiers but also as a method for selecting 
by [Viola and Jones, 2001], is used to automatically select 
                                                      discriminative features. We use their proposed approach to 
the best features and to learn an ensemble of discriminative 
                                                      select only a fraction of the total features, and to train very 
static classifiers for the activities we wish to recognize. 
                                                      simple ensemble classifiers to recognize a broad set of 
Second, the classification margins from the static classifiers 
                                                      activities. 
are used to compute the posterior probabilities, which are 
then used as inputs into HMM models. The discriminative Capturing Temporal Regularities 
classifiers are tuned to make different activities more The activities people perform have certain natural 
distinguishable from each other, while the HMM layer on regularities and temporal smoothness, e.g. people do not 
top of the static classification stage ensures temporal abruptly switch back and forth between walking and driving 
smoothness and allows us to continuously track the    a car; thus, the recent history can help in predicting the 
activities.                                           present. Using a sequence of posterior probabilities 
  The rest of the paper is organized as follows: Section 2 computed from the instantaneous classifiers, we train 
provides an overview of the activity recognition system. Hidden Markov Models (HMMs) that significantly improve 
Section 3 presents the feature selection and discriminative the performance and smoothness of our recognition system. 
classifier training method. Section 4 describes how the By incorporating the static classification results we 
results from the classifiers are combined with HMMs.  overcome the weakness of HMMs as effective classifiers 
Section 5 describes our experimental results and the  [Jaakkola and Haussler, 1999].  
performance of the system, and Section 6 discusses our 
conclusions and possible future directions            3   Selecting the Right Features  
                                                      Given a rich set of sensor data and features, our classifiers 
2   Activity Recognition System Overview              will work best if we select the right features that enable the 
The first problem we address is the systematic identification classifiers to discriminate well between classes, and if we 
of modalities and features that are well suited for accurate remove features that are not useful or which might even 
recognition of natural human activities. The second problem confuse the classifiers. Although it might be possible to 
we tackle is how these features can be effectively used to hand pick the optimal features for certain activities, this is 
develop models that accurately recognize and track various not a viable solution when the number of activities become 
activities. Below we give a brief overview of the different large or when the sensor signals are not intuitive. In such 
components in our activity recognition system.        scenarios, automatic techniques for finding the right set of 
                                                      features become increasingly important. A practical activity-
Sensing and Feature Extraction                        recognition system will use a minimal number of features 
Using a shoulder mounted multi-sensor board (Figure 1(A)), and the simplest possible models needed for high accuracy.  
we collect approximately 18,000 samples of data per 
second. To reduce the dimensionality and to bring out 
details in the data we compute a total of 651 features; which 3.1 Feature Selection and Activity Classification 
include linear and mel-scale FFT frequency coefficients,    using Boosted Decision Stumps 
cepstral coefficients, spectral entropy, band pass filter In this paper, we assume that people engage in N different 
coefficients, integrals, mean and variances. We combine the type of activities. Given the set of activities 
features from various sensors to produce a 651 dimensional A = {A1N ,...,A } , we also assume that we have a set of 
feature vector at 4Hz. However, since we have sensors with training data for each of those activities. Each sample in the 
                                                                                               =
different sampling rates, there can be multiple instances of a training set consists of a feature vector f {f1K ,..., f }  
feature within the 0.25 second window; that operate on extracted from the sensors. For each activity Ai  we are Figure 1: Flow diagram describing the classification system presented in this paper. (A) Our sensor board records a sequence of raw sensor 
recordings (B) from which we compute our feature vector. We pick the top fifty features per class, from our feature vector, and (C) supply 
them as inputs to our ensemble of decision stumps classifier. (D) Each decision stumps classifier outputs a margin at time t. (E) This 
sequence of margins can then be converted to probabilities by fitting them to a sigmoid. (F) The sequence of probabilities is then supplied 
to ten HMM classifiers (G) each of which outputs a likelihood. (H) The class with the highest likelihood is the classified class. 
interested in finding a ranking of the feature set    only use results from the decision-stump based classifier in 
  iii=
R   {r1K ,...,r } based on their usefulness in recognizing the later sections. The decision stump finds the optimal 
         i                                    τi                θi
activity A . Moreover, we want to find a cut-off point  for threshold m  for each feature fm that minimizes the 
                                                 τ                               i    =         >θi
the ranked feature set such that adding features beyond i  weighted error such that h(f)mm 1 if fmm and 
                                                        i    =−
does not significantly improve the accuracy of the classifier h(f)mm 1otherwise.  
Ci , i.e. ∆(error(Cii (f ,...,f i )),  error(Cii (f ,...,f i ))) ≤ε. 
                   rr1N               rr1  τ            For the boosted static classifiers, the classification margin 
                          τi         τi
The reason behind estimating  is that, if  N  then we for a data point can reflect the confidence in that prediction 
can reduce the computational complexity of our classifiers [Schapire et al., 1997].  The margin of an example is the 
by not extracting the less useful features. Since our final weighted fraction of the weak classifiers votes assigned to 
goal is to have the classifiers run on devices that users carry the correct class.  
or wear, the computational costs of the classifiers are                         τi
                                                                                  αiih(f) i
critical.                                                               i i = ∑ m1= mm   m
                  i                                                   m(f )        τi
  For each activity A , we iteratively train an ensemble of                          αi      
                       iii=                                                      ∑ t1= m
weak binary classifiers H {h1N ,...,h } (Figure 1(C)) and 
                 iii=                                                  iiii=
obtain a ranking R  {r1K ,...,r } for the features using the          H(ff ) sign(m( ))
variation of the AdaBoost algorithm proposed by [Viola and However, constructing classifiers to output a posterior 
Jones, 2001]. The weak classifiers are constrained to use probability is very useful, especially if we want to combine 
only one feature, and at each iteration m of boosting we the results of the multiple classifiers later on. One method of 
select the feature and the associated weak learner    computing posterior probability directly is to fit a sigmoid 
 i                                    εi
h(f)mmthat minimizes the training error mm(f ) on the function to the output of the ensemble classifier [Platt, 
                       εi
weighted data. The error mm(f )  is used to re-weight the 1999] (Figure 1(E)). In our case, the posterior probabilities 
                                             αi
data for the next iteration and to compute the weight m for are derived as follows - 
 i
h(f). At the end of this process, we have a ranking for                   ϕ i i
 mm                                                                      e m(f )
the features based on how useful each feature is in              i  i =ϕ
                                                              p(C |f )ϕ   i i   , where  is a constant  
discriminating Ai  from the other activities A j (j≠ i), and            e m(f )+1
                                   i
we also have a set of weak classifiers h(f)mmand weights A static classifier predicts the label for each data point 
                  αi
for those classifiers m . The final output is a weighted independently. Most of the time this independence 
combination of the weak classifiers, and by estimating the assumption is clearly invalid and the prediction of previous 
error of Ci  as a function of the number of features used, we data points can help with the current classification. A 
can also find τi for Ci . So, for a given data point, the temporal model that uses the confidence of the predictions 
prediction of Ci is                                   of the classifiers Csi  instead of the raw features f i is likely 
                                                      to have a greater impact on the performance. The ability to 
                           τi
              H()iiif =α sign(  h (f ))               recognize activities in continuous time chunks would also 
                         ∑ m1= mm   m
                                                      allow us to learn how people transition between activities 
  Each classifier Ci  uses the top τi  features, which is a and thereby allow us to learn more about people’s behavior 
fraction of the total number of features available, i.e. and activity patterns. In the next section, we describe how 
 i =  ii
f   (f1 ,...,fτi ) .                                  we combine the confidence values of the static classifiers to 
  We tried two different weak classifiers in our system: (i) build time-series models of the activities. 
a discriminative decision-stump and (ii) a generative naïve 
Bayes model (conditional probability distributions are 4  Incorporating Prediction History using 
modeled using histograms that have 100 bins/dimension) as Hidden Markov Models 
our weak classifier. In our experiments, the decision stump 
                                                      HMMs have been successfully used in modeling different 
consistently outperformed the naïve Bayes classifier, so we 
                                                      types of time-series data, e.g. in speech recognition, gesture                                                                      Accelerometer 37.7%
                                                                Ambient Light (IR-Vis) 2.5%
                                                                          Audio  23.9%
                                                                 Barometric Pressure 12.9%
                                                                    Digital Compass 2.1%
                                                                   Hi-Freq Vis Light 3.3%
                                                                         IR Light 3.6%
                                                                   Relative Humidity 4.1%
                                                                Temp. from Barometer 3.2%
                                                           Temp. from Relative Humidity 3.2%
                                                                      Visible Light 3.3%
                                                 Table 2: The percentage of features from the top 50 that originated 
                                                 from the different sensors, averaged across all activity classes. 
                                                  
 Figure 2: Testing error rates per class as a function of the number Alternatively, we could have trained the various states of 
 of features selected. After 50 features are selected most of the 
 testing errors for the classes have leveled off. The data graphed a single HMM to recognize the different activity classes and 
 here is averaged from several smaller feature selection runs. to learn the transition characteristic between activities. We 
                                                 choose not to do that here as our activities are primitive and 
 tracking etc. We use HMMs to capture the temporal a single transition statistic is not very meaningful. However, 
 dynamics; but instead of directly using the raw features we believe that the output of these HMMs could be used to 
 selected in the previous section, we trained our HMMs train a single dynamic model of more complex behavior 
 using the posterior probabilities of the static classifiers. The where the transition statistics would also be more 
 advantage of using the posterior probabilities is that we can informative.  
 take advantage of the results from the discriminatively 
 trained classifier, as well as reduce the complexity of the 5 Experiments 
 HMMs. The earlier work of [Jaakkola and Haussler, 1999] 
 has also shown the benefits of combining generative models To validate our approach, we recorded 12 hours of data 
 into discriminative classifiers by deriving kernel functions consisting of a large number of activities (such as sitting, 
 from probability models. [Clarkson and Pentland, 1999; walking, jogging, riding a bike, driving a car, etc.) using the 
 Oliver et al., 2002] have used the output of an HMM model wearable multi-sensor board.  The dataset was collected 
 as input to another HMM. [Yin et al., 2004] have used the across multiple days, by two volunteers (who are not the 
 output of static classifiers directly into HMMs for speech researchers) in various indoor and outdoor locations.  The 
 reading application; however they do not compute the recordings were done in long stretches (one hour on 
 margin or class posterior probability of these classifiers, average), where the duration of the activities themselves 
 which can be more effective than the raw outputs [Platt, ranged from seconds (e.g. entering a building), to hours 
 1999].                                          (e.g. driving a car). The volunteers were asked to go about 
                                λ                performing a series of activities naturally without any 
  For each activity, a new HMM model i (Figure 1(F)) is 
learned using a sequence of examples rather than individual specific constraints on the order, for example “go to 
                                                 building X and walk around inside”. To capture day-to-day 
instances. We construct a new input feature space based on 
                                                 variations in the activities we collected multiple instances of 
the posterior class probabilities, which is  
                                                 the various activities over the course of six weeks. On 
                   p(C1 |f 1 )                 average we have about an hour of data per activity and 
                                                 around 100 instances per activity.  
                 = 
                f  #
                                                 Feature Selection 
                   p(CN |f N )
                                               For the feature selection stage, we selected 80% of the total 
                                                 data available for each class for training. Based on the 
                                                                               i
  Given a set of observations {ff12 , ,..., f T } for each activity, training examples we derived a ranking R for the features 
                              λ
 we learn the parameters of the HMM i  using the standard for each activity individually using the boosted decision 
expectation-maximization (EM) method. During testing, we stump procedure described in section 3.1. Figure 2 shows 
have a continuous sequence S, which we use to compute the the testing error as a function of the number of features used 
                ( )   λ
 likelihood value Lι t  for i  at time t using a sliding for classification. From the results we see that classification 
 window of duration ∆t  (Figure 1(G)) –          error tapers off at around τ=i 50  features for most classes. 
                                                 If we were to pick more features beyond the top 50 our 
                 =λff    f    S
             Litt1tti(t) P( ,++ ,...,+ | , )     performance only improves slightly with the testing error 
  The final segmentation and classification is based on the only improving <1% for 600 features. The practical 
 HMM that has the highest likelihood value,      advantage of features selection is that we can significantly 
                                                 reduce the computational burden on our resource 
 i.e. C (t)= maxL (t)  (Figure 1(H)).  
    iii                                          constrained devices, without drastically affecting the Figure 3: Output of the static decision stumps classifiers (at 4Hz), and the HMM classifiers (trained with output probabilities of the static 
classifiers) for a continuous 90 minute segment of the data. The results are overlaid on top of the ground truth which was obtained by 
annotating video recorded from a webcam worn by our volunteers. The video was only used for determining ground truth and not as an 
additional sensor input. 
 
performance. Moreover, by performing boosting (re-
                                                      Continuous classification results 
weighting the data and selecting discriminatory features 
                                                      Although the decision stumps results from Table 3 are quite 
successively based on the error), we perform much better 
                                                      good on their own, Figure 3 illustrates the classification 
than taking a non-boosted (no re-weighting) approach to 
                                                      errors encountered for a continuous trace. The majority of 
selecting the best 50 features. The accuracy ((true positive + 
                                                      the trace tends to be correctly classified by the decision 
true negative) / (total # of examples)) for the boosted 
                                                      stumps; but, with some scattered misclassifications. The 
features selection was on average ~11% higher than the 
                                                      addition of the HMM layer on top of the static classifier 
non-boosted method. Table 2 lists the contribution of the 
                                                      helps to smooth these classification errors as shown by the 
different sensors to the final classifier. The majority of the 
                                                      line in Figure 3.   
top 50 features came from the accelerometer, audio and 
                                                        The parameters of the HMMs were trained using 20 
barometric pressure sensors. Barometric pressure data was 
                                                      example scenes (on average 30 minutes of scenes) for each 
useful in distinguishing activities that involved floor 
                                                      class. Each HMM had two hidden states and Gaussian 
transitions (e.g. walking up/down stairs, elevator up/down); 
                                                      observation probabilities. Classification was performed 
the sensor is sensitive enough to pick up pressure 
                                                      using a 15 second sliding window with 5 second overlap. 
differences between a single floor. 
                                                      Table 4 shows the sliding window performance results for 
Static Classification Results                         the HMM, using the posterior probabilities as inputs, tested 
Using the top 50 features we tested the performance of the with concatenated test scenes. The overall accuracy in this 
ensemble classifier for two different weak classifiers – (i) case was 95%. It is interesting to note that the points in 
decision stump (discriminative) and (ii) naïve Bayes  Figure 3 where the HMM and ground truth differ appear to 
(generative). The total duration of our test dataset was five be somewhat natural and realistic; for example, classifying a 
and a half hours. The decision stumps outperformed the region without any ground truth between walking and sitting 
naïve Bayes classifiers by a large percentage. Table 3 shows as standing. In fact, the HMM output reveals some 
the precision (true positive/(true positive + false positive)) deficiencies in the ground truth. For example, some 
and recall (true positive/(true positive + false negative)) segments whose ground truth was marked as walking are in 
numbers for the 10 activities in the dataset using the fact standing (as determined by post-analysis of the video by 
ensemble of decision stumps. Table 5 lists the average the experimenters), and are correctly recognized as standing 
precision and recall numbers for the naïve Bayes as well as by the HMM. 
decision stump classifiers.                             To compare the performance to a more standard HMM 
                                                      approach, we trained a new set of HMMs that used the top 
                                                      50 raw features as inputs rather than the output of the static 
                                                      classifiers. The performance of these HMMs was 