A Dual-layer CRFs Based Joint Decoding Method for Cascaded Segmentation and
                                           Labeling Tasks
                        Yanxin Shi                                 Mengqiu Wang
             Language Technologies Institute              Language Technologies Institute
               School of Computer Science                   School of Computer Science
                Carnegie Mellon University                   Carnegie Mellon University
                   yanxins@cs.cmu.edu                           mengqiu@cs.cmu.edu

                    Abstract                          diction of earlier tasks [Sutton and McCallum, 2005a].Sev-
                                                      eral new techniques have been proposed recently to address
    Many problems in NLP require solving a cas-
                                                      these problems. Sutton et al. [2004] introduced the Dynamic
    cade of subtasks. Traditional pipeline approaches
                                                      Conditional Random Fields (DCRFs) to perform joint train-
    yield to error propagation and prohibit joint train- ing/decoding of subtasks. One disadvantage of this model
    ing/decoding between subtasks. Existing solutions
                                                      is that exact inference is generally intractable and can be-
    to this problem do not guarantee non-violation
                                                      come prohibitively expensive for large datasets. Sutton and
    of hard-constraints imposed by subtasks and thus  McCallum  [2005a] presented an alternative model by decou-
    give rise to inconsistent results, especially in cases
                                                      pling the joint training and only performing joint decoding.
    where segmentation task precedes labeling task.
                                                      Kudo  et al. [2004] presented another Conditional Random
    We present a method that performs joint decod-    Field (CRF) [Lafferty et al., 2001] based model that per-
    ing of separately trained Conditional Random Field
                                                      forms Japanese word segmentation and POS tagging jointly.
    (CRF) models, while guarding against violations of
                                                      Another popular approach of joint decoding for cascaded
    hard-constraints. Evaluated on Chinese word seg-  tasks is to combine multiple predicting tasks into a single
    mentation and part-of-speech (POS) tagging tasks,
                                                      tagging or labeling task [Luo, 2003; Ng and Low, 2004;
    our proposed method achieved state-of-the-art per-
                                                      Yi and Palmer, 2005; Miller et al., 2000].
    formance on both the Penn Chinese Treebank and
    First SIGHAN Bakeoff datasets. On both segmen-      However, all aforementioned approaches do not work well
    tation and POS tagging tasks, the proposed method for cases where a segmentation task comes before a labeling
    consistently improves over baseline methods that  task. That is because in such cases, the segmentation task
    do not perform joint decoding.                    imposes hard-constraints that cannot be violated in succes-
                                                      sive tasks. For example, if a Chinese POS tagger assigns
                                                      different POS labels to characters within the same word, as
1  Introduction                                       deﬁned by a word segmenter, the word will not get a single
There exists a class of problems which involves solving a cas- consistent POS labels. Similarly, the constituent constraints
cade of segmentation and labeling subtasks in Natural Lan- imposed by syntactic parsing and NP-chunking tasks disallow
guage Processing (NLP) and Computational Biology. For in- argument overlaps in semantic role labeling [Pradhan et al.,
stance, a semantic role labeling (SRL) system relies heavily 2004]. From a graphical modeling’s perspective, those mod-
on syntactic parsing or noun-phrase chunking (NP-chunking) els all assign nodes to the smallest units in the base segmen-
to segment (or group) words into constituents. Based on tation task (e.g., in the case of Chinese word segmentation,
the constituent structure, it then identiﬁes semantic argu- the smallest unit is one Chinese character). As a result, those
ments and assigns labels to them [Xue and Palmer, 2004; models cannot ensure consistency between the segmentation
Pradhan et al., 2004]. And for Asian languages such as and labeling tasks. For instance, [Ng and Low, 2004] can only
Japanese and Chinese that do not delimit words by space, evaluate POS tagging results on a per-character basis, instead
solving word segmentation problem is prerequisite for solv- of a per-word basis. Hindered by the same problem, [Kudo
ing part-of-speech (POS) labeling problem. Another exam- et al., 2004] only considered words predeﬁned in a lexicon
ple in the Computational Biology ﬁeld is the DNA coding for constructing possible Japanese word segmentation paths,
region detection task followed by sequence similarity based which puts limit on the generality of their model.
gene function annotation [Burge and Karlin, 1997].      To tackle this problem, we propose a dual-layer CRFs
  Most previous approaches treat cascaded tasks as processes based method that exploits joint decoding of cascaded se-
chained in a pipeline. A common shortcoming of those ap- quence segmentation and labeling tasks that guards against
proaches is that errors introduced in upstream tasks prop- violations of those hard-constraints imposed by segmentation
agate through the pipeline and cannot be easily recovered. task. In this method, we model the segmentation and labeling
Moreover, the pipeline structure prohibits the use of predic- tasks by dual-layer CRFs. At decoding time, we ﬁrst perform
tions of tasks later in the chain to help making better pre- individual decoding in each layer. Upon these individual de-

                                                IJCAI-07
                                                  1707codings, a probabilistic framework is constructed in order to Note that the joint probability P (S, T|C) is factorized into
ﬁnd the most probable joint decodings for both subtasks. At two terms, P (T|W(C,S)) and P (S|C). The ﬁrst term repre-
training time, we trained a cascade of individual CRFs for the sents the probability of a POS tagging sequence T built upon
subtasks, for given our application’s scale, joint training is the segmentation S over sentence C, while the second term
much more expensive [Sutton and McCallum, 2005a].Evalu- represents the probability of the segmentation sequence S.
ated on Chinese word segmentation and part-of-speech (POS) Maximizing the product of these two terms can be viewed as
tagging tasks, our proposed method achieved state-of-the-art a reranking process. For a particular sentence C, we maintain
performance on both the Penn Chinese Treebank [Xue et al., a list of all possible segmentations over this sentence sorted
2002] and First SIGHAN Bakeoff datasets [Sproat and Emer- by the their probability P (S|C). For each segmentation S in
son, 2003]. On both segmentation and POS tagging tasks, the this list, we can ﬁnd a POS tagging sequence T over S that
proposed method consistently improves over baseline meth- maximizes the probability P (T|W(C,S)). Using the product
ods that do not perform joint decoding. In particular, we re- of these two probabilities, we can then rerank the segmenta-
port the best published performance on the AS open track of tion sequences. The segmentation sequence S that is reranked
the First SIGHAN Bakeoff dataset and also the best average to be the top of the list of all possible segmentations is the
performance on the four open tracks.                  ﬁnal segmentation sequence output, and the most probable
  To facilitate our discussion, in later sections we will use POS tagging sequence along with this segmentation is our ﬁ-
Chinese segmentation and POS tagging as a working exam- nal POS tagging output. Such a ﬁnal pair always maximizes
ple to illustrate the proposed approach, though it should be the joint probability P (S, T|C).
clear that the model is applicable to any cascaded sequence Intuitively, given a segmentation over a sentence, if the
labeling problem.                                     maximum of probabilities of all POS tagging sequences built
                                                      upon this segmentation is very small, it can be a signal that
2  Joint Decoding for Cascaded Sequence               tells us there is high chance that the segmentation is incorrect.
   Segmentation and Labeling Tasks                    In this case, we may be able to ﬁnd another segmentation that
                                                      does not have a probability as high as the ﬁrst one, but the
In this section, using Chinese sentence segmentation and POS best POS tagging sequence built upon this segmentation has
tagging as an example, we present a joint decoding method a much more reasonable probability, so that the joint proba-
applicable for cascaded segmentation and labeling tasks. bility P (S, T|C) is increased.
2.1  A Uniﬁed Framework to Combine Chinese            2.2  N-Best List Approximation for Decoding
     Sentence Segmentation and POS Tagging            To ﬁnd the most probable segmentation and POS tagging se-
                                                      quence pair, exact inference by enumerating over all possi-
Let C  =  {C1,C2, ..., Cn} denote the observed Chinese
                       th                             ble segmentation is generally intractable, since the number of
sentence where Ci is the i Chinese character in the sen- possible segmentations over a sentence is exponential to the
tence, S = {S1,S2, ..., Sn} denote a segmentation sequence
                ∈{      }                             number of characters in the sentence.
over C where Si     B,I   represents segmentation tags  To overcome this problem, we propose a N-best list ap-
(Begin and Inside of a word), T = {T1,T2, ..., Tm} de-
                                    ≤            ∈    proximation method. Instead of exhaustively computing the
note a POS tagging sequence where m    n and Tj       list of all possible segmentations, we restrict our rerank-
{thesetofpossiblePOSlabels}. Our goal is to ﬁnd a seg-
                                                      ing targets to the N-best list S = {S1, S2, ..., SN},where
mentation sequence and a POS tagging sequence that max-
                                                      {S1, S2, ..., SN} is ranked by the probability P (S|C). Then,
                            |  1     ˆ     ˆ
imize the joint probability P (S, T C) .LetS and T denote the approximated solution that maximizes the joint probabil-
the most likely segmentation and POS tagging sequences for ity P (S, T|C) can be formally described as:
a given Chinese sentence, respectively. By applying chain
    ˆ    ˆ                                                  < Sˆ, Tˆ > =argmaxP   (S, T|C)
rule, S and T can be obtained as follows:                                  S∈S,T
     <  Sˆ, Tˆ > =argmaxP   (S, T|C)                                  =argmaxP    (T|W(C,S))P (S|C)   (3)
                     S,T                                                   S∈S,T
               =argmaxP     (T|S, C)P (S|C)     (1)     Comparing to other similar work that uses N-best lists
                     S,T                              and SVM   for reranking [Daume and Marcu, 2004; Asa-
               =argmaxP     (T|W(C,S))P (S|C)   (2)   hara et al., 2003], or perform rule-based post-processing for
                     S,T                              error correction [Xue and Shen, 2003; Gao et al., 2004;
                                                      Ng and Low, 2004], our method has a unique advantage that
Equation 1 can be rewritten as Equation 2, since given a se-
                      {            }                  it outputs not just the best segmentation and POS sequence
quence of characters C = C1,C2, ..., Cn and a segmenta- but also a joint probability estimate. This probability esti-
tion S over it, a sentence can be interpreted as a sequence of mate allows more natural integration with higher level NLP
words W(C,S)   {  1   2       }.
             =  W  ,W , ..., Wm                       applications that are also based on probabilistic models, and
                                                      even reserves room for further joint inference.
  1Note that a segmentation-POS tagging sequence pair is mean-
ingful only when the POS tagging sequence T is labeled on the basis 3 Dual-layer Conditional Random Fields
of the segmentation result S, or the pair of S and T is consistent. In
our proposed method, the joint probabilities P (S, T|C) of inconsis- In Section 2, we have already factorized the joint probabil-
tent pairs of S and T are deﬁned to be 0.             ity into two terms P (S|C) and P (T|W(C,S)). Notice that

                                                IJCAI-07
                                                  1708both terms are probabilities of a whole label sequence given
some observed sequences. Thus, we use Conditional Ran-           Tj-1    Tj          Tj1
dom Fields (CRFs) [Lafferty et al., 2001] to deﬁne these two       CD       JJ          NN
probability terms.
  CRFs deﬁne conditional probability, P (Z|X), by Markov        Wj-1    Wj      Wj1
random ﬁelds. In the case of Chinese segmentation and POS                                        Second
                                                                 Si-1    Si      Si1    Si2
tagging, the Markov random ﬁelds in CRFs are chain struc-                                         Layer
                                                         First     BBBI
ture, where X is the sequence of characters or words, and Z is Layer
the segmentation tags for characters (B or I, used to indicate
                                                                 Ci-1    Ci     Ci1     Ci2
word boundaries) or the POS labels for words (NN, VV, JJ,
etc.). The conditional probability is deﬁned as:
                         T  K                       Figure 1: Dual-layer CRFs. P (S, T|C), the joint probability
                 1
      P (Z|X)=       exp (      λ f (Z, X,t))   (4)   of a segmentation sequence S and a POS tagging sequence T
                N(X)             k k
                          t=1 k=1                     given sentence C is modeled by the dual-layer CRFs. In the
                                                      ﬁrst layer CRF, the observed nodes are the characters in the
where N(X)  is a normalization term to guarantee that the sentence and the hidden nodes are segmentation tags for these
summation of the probability of all label sequences is one. characters. In the second layer CRF, given the segmentation
               th
fk(Z, X,t) is the k localfeaturefunction at sequence po- results from the ﬁrst layer, characters combine to form ”su-
                                             {   }
sition t. It maps a pair of X and Z and an index t to 0,1 . pernodes” (words). These words are the observed variables,
(λ1, ..., λK ) is a weight vector to be learned from training set. and POS tagging labels for them are the hidden variables.
  We model separately the two probability terms deﬁned in
             |          |
our model (P (S C) and P (T W(C,S))) using the dual-layer                 [                     ]
                                  |                   scaling algorithm (IIS) Della Pietra et al., 1997 to maxi-
CRFs (Figure 1). The probability P (S, T C) that we want to mize the log-likelihood of the ﬁrst layer CRF. Then we learn
maximize can be written as:                                        λ  {          }
                                                      the parameters = λ1, ..., λKT also using IIS, to maximize
   P (S, T|C)=P    (T|W(C,S))P (S|C)            (5)   the log-likelihood of the second layer CRF. A detailed deriva-
                      1           1                   tion of this learning algorithm for each learning step can be
             =               ×                        found in [Lafferty et al., 2001].
                 NT (W(C,S))    NS(C)
                       m  KT                        4   Features for CRFs
                 × exp (      λkfk(T, W(C,S),j))
                       j=1 k=1                        Features for Word Segmentation
                                                      The features we used for word segmentation are listed in the
                       n  KS
                 ×                                    top half of Table 1. Feature (1.1)-(1.5) are the basic segmenta-
                   exp (      μkgk(S, C,i))     (6)   tion features we adopted from [Ng and Low, 2004]. In (1.6),
                       i=1 k=1
                                                      LBegin(C0), LEnd(C0) and LMid(C0) represent the maxi-
where m and n are the number of words and characters in the mum length of words found in a lexicon that contain the cur-
sentence, respectively, NT (W(C,S)) and NS(C) are the nor- rent character as either the ﬁrst, last or middle character, re-
malizing terms to ensure the sum of the probabilities over all spectively. In (1.7), Single(C0) indicates whether the current
possible S and T is one. {λk} and {μk} are the parameters character can be found as a single word in the lexicon.
for the ﬁrst and the second layer CRFs, respectively, fk and Besides the adopted basic features mentioned above, we
gk are the localfeaturefunctions for the ﬁrst and the sec- also experimented with additional semantic features (Table
ond layer CRFs, respectively. Their properties and functions 1, (1.8)-(1.9)). In these features, Sem(C0) refers to the se-
are the same as common CRFs described before.         mantic class of current character, and Sem(C−1), Sem(C1)
  The N-best list of segmentation sequences S and the represent the semantic class of characters one position to the
value of their corresponding probabilities P (S|C)(S ∈S) left and right of the current character, respectively. We ob-
can be obtained using modiﬁed Viterbi algorithm and A* tained a character’s semantic class from HowNet [Dong and
search [Schwartz and Chow, 1990] in the ﬁrst layer CRF. Dong, 2006]. Since many characters have multiple semantic
Given a particular sentence segmentation S, the most proba- classes deﬁned by HowNet, it is a non-trivial task to choose
ble POS tagging sequence T and its probability P (T|W(C,S)) among the different semantic classes. We performed contex-
can be inferred by the Viterbi algorithm [Lafferty et al., 2001] tual disambiguation of characters’ semantic classes by calcu-
in the second layer CRF. Having the N-best list of segmen- lating semantic class similarities. For example, let us assume
tation sequences and their corresponding most probable POS the current character is (look,read) in a word context of
tagging sequences, we can use the joint decoding method pro- (read newspaper). The character (look) has two seman-
posed in Section 2 to ﬁnd the optimal pair of segmentation tic classes in HowNet, i.e. (read)and(doctor). To
and its POS tagging deﬁned by Equation 3.             determine which class is more appropriate, we check the ex-
  We divide the learning process into two: one for learning ample words illustrating the meanings of the two semantic
the ﬁrst layer segmentation CRF, and one for learning the sec- classes given by HowNet. For (read), the example word
ond layer POS tagging CRF. First we learn the parameters μ is (read book); for (doctor), the example word is
 {          }
=  μ1, ..., μKS using algorithm based on improved iterative (see a doctor). We then calculated the semantic class

                                                IJCAI-07
                                                  1709         Segmentation features                        The second best segmentation which has probability 0.36 is:
         (1.1) Cn,n∈ [−2, 2]
         (1.2) CnCn+1,n∈ [−2, 1]                         (foreign owned)(company)(production)
         (1.3) C−1C1                                      (situation)(situation)(relatively)(good)
                (  )
         (1.4) Pu C0                                  The  only difference from the ﬁrst sequence  is that
         (1.5) T (C−2)T (C−1)T (C0)T (C1)T (C2)
                                                        (relatively good) was segmented into two words
         (1.6) LBegin(C0), LEnd(C0)
         (1.7) Single(C0)                              (relatively)(good). Despite the lower probability, the
         (1.8) Sem(C0)                                second segmentation is more appropriate, since the two char-
         (1.9) Sem(Cn)Sem(Cn+1),n∈−1, 0               acters that compose the word (relatively good) carry
         POS tagging features                         their own meanings as individual words.
         (2.1) Wn,n∈ [−2, 2]                            The traditional methods would have stopped here and use
         (2.2) WnWn+1,n∈ [−2, 1]                      the ﬁrst segmentation as the ﬁnal output, though it is actually
         (2.3) W−1W1                                  incorrect according to the gold-standard. Our joint decoding
                            ∈ [−1 1]
         (2.4) Wn−1WnWn+1,n      ,                    method further performs POS tagging based on each of the
                (  )  ∈ [−2 2]
         (2.5) Cn W0 ,n    ,                          segmentation sequences. The POS tagging sequence with the
                (   )
         (2.6) Len W0                                 highest probability (0.23) assigned to the ﬁrst segmentation
         (2.7) Other morphological features           is:
             Table 1: Feature templates list            (NN   ) (NN ) (NN  ) (NN  ) (NN  )
                                                        (VV  ) (PU )
similarity scores between (newspaper)and(book), and   where NN represents noun, VV represents other verb, and
 (newspaper)and(illness), using HowNet’s built-in sim- PU represents punctuation. The second segmentation was
ilarity measure function. Since (newspaper)and(book)  assigned the following POS label sequence with the highest
both have semantic class (document), their maximum    probability 0.45:
similarity score is 0.95, where the maximum similarity score
between  (newspaper)and(illness) is 0.03. Therefore,    (NN   ) (NN ) (NN  ) (NN  ) (NN  )
Sem(C0)Sem(C1)=(read)(document). Similarly,             (AD  ) (VA ) (PU )
we can ﬁgure out Sem(C−1)Sem(C0).ForSem(C0),we        where AD represents adverb, VA represents predicative ad-
simply picked the top four frequent semantic classes ranked jective.
by HowNet, and used ”NONE” for absent values.           The best POS sequence arising from the second segmen-
                                                      tation is more discriminative than the best sequence based
Features for POS Tagging                              on the ﬁrst segmentation, which indicates the second seg-
The bottom half of Table 1 summarizes the feature templates mentation is more informative for POS tagging. The joint
we employed for POS tagging. W0 denotes the current word. probability of the second segmentation and POS tagging se-
W−n  and Wn refer to the words n positions to the left and
                                                 th   quence (0.16) is higher than the joint probability of the ﬁrst
right of the current word, respectively. Cn(W0) is the n one (0.12), and therefore our method reranks the second one
character in current word. If the number of characters in the as the best output. According to the gold-standard, the sec-
word is less than 5, we use ”NONE” for absent characters. ond segmentation and POS tagging sequences are indeed the
Len(W0)  is the number of characters in the current word. correct sequences.
We also used a group of binary features for each word, which
are used to represent the morphological properties of current
word, e.g. whether the current word is punctuation, number, 6 Results
foreign name, etc.                                    We evaluate our model using the Penn Chinese Treebank
                                                      (CTB) [Xue et al., 2002] and open tracks from the First In-
5  An Illustrating Example of the Joint               ternational SIGHAN Chinese Word Segmentation Bakeoff
   Decoding Method                                    datasets [Sproat and Emerson, 2003].
In this section, we use an illustrating example to motivate our Using a linear-cascade of CRFs with the same set of fea-
proposed method. This example found in the real output of tures listed in Table 1 as baseline, we compared the perfor-
our system gives suggestive evidences that POS tagging helps mance of our proposed method. The accuracies of both word
predicting the right segmentation, and the right segmentation segmentation and POS tagging are measured by recall (R),
                                                                                             2RP
is more likely to get a better POS tagging sequence. We are precision (P), and F-measure which equals to R+P . For seg-
only showing a snippet of the full sentence due to space limit: mentation, recall is the percentage of correct words that were
                                                      produced by the segmenter, and precision is the percentage of
   The production and sales situation of foreign owned automatically segmented words that are correct. For POS tag-
             companies is relatively good.            ging, recall is the percentage of all gold-standard words that
                                                      are correctly segmented and labeled by our system, and pre-
The segmentation that has the highest probability (0.52) is:
                                                      cision is percentage of words returned by our system that are
   (foreign owned)(company)(production)               correctly segmented and labeled. We chose a N value of 20
    (situation)(situation)(relatively good)           for using in the N-best list, based on cross-validation results.

                                                IJCAI-07
                                                  17106.1  Results of Segmentation                          average of our system over the same runs, where a bolded en-
For segmentation, we ﬁrst evaluated our joint decoding try indicates our system performs better on average than the
method on the CTB corpus. 10-fold cross-validation was per- other site. Our results are shown in the last row of the table.
formed on this corpus. Results are summarized in Table 2. In the ofﬁcial runs, no team achieved best results on more
                                                      than one open track. We achieved the best runs on AS open
                 1    2    3     4     5    6         (ASo) track with a F1 score of 96.8%, 1.1% higher than the
   Baseline    97.3% 97.2% 95.4% 96.7% 96.2% 93.1%    second best system [Peng et al., 2004]. Comparing to Peng et
   Joint decoding 97.4% 97.3% 95.7% 96.9% 96.4% 93.4% al. [2004], whose CRFs based Chinese segmenter were also
                 7    8    9     10    average        evaluated on all four open tracks, we achieved higher perfor-
   Baseline    95.9% 94.8% 95.7% 96.2 % 95.85%        mance on three out of the four tracks. Our average F1 score
   Joint decoding 96.0% 95.2% 95.9% 96.3% 96.05%      over all four tracks is 94.1%, 0.5% higher than that of Peng
                                                      et al.’s system. Comparing with other sites using the average
Table 2: Comparison of 10-fold cross-validation segmenta- measures in the right-most two columns, we outperformed
tion results on CTB corpus. Each column represents one out seven out of the nine sites. And the two sites that have higher
of the 10-fold cross-validation results. The last column is the average performance than us both did signiﬁcantly better on
average result over the 10 folds.                     the CTB open (CTBo) track. The ofﬁcial results showed
                                                      that almost all systems obtained the worst performance on
  As can been seen in Table 2, the results in all of the 10- the CTBo track, due to inconsistent segmentation style in the
fold tests improved with our joint decoding method. We training and testing sets [Sproat and Emerson, 2003].
conducted pairwise t-test and our joint decoding method was
found to be statistically signiﬁcantly better than the baseline
                            −4                                        ASo  CTBo  HKo  PKo  S-Avg O-Avg
method under conﬁdence level 5.0 (p-values).             S01               88.1%     95.3% 91.7% 92.2%
  We also evaluated our proposed method on the open tracks S02             91.2%           91.2% 89.1%
of the SIGHAN Bakeoff datasets. These datasets are designed S03      87.2% 82.9% 88.6% 92.5% 87.8% 94.1%
only for evaluation of segmentation results, and no POS tag- S04                     93.7% 93.7% 95.2%
ging information were provided in the training corpus. How- S07                      94.0% 94.0% 95.2%
ever, since the learning of the POS tagging model and the seg- S08              95.6% 93.8% 94.7% 95.2%
mentation model is decoupled, we can use a separate training S10           90.1%     95.9% 93.0% 92.2%
corpus to learn the second layer POS tagging CRF model, and S11      90.4% 88.4% 87.9% 88.6% 88.8% 94.1%
still be able to take advantage of the proposed joint decoding Peng et al. ’04 95.7% 89.4% 94.6% 94.6% 93.6% 94.1%
method. The results comparing to the baseline method are Our System  96.8% 89.1% 95.2% 95.2%    94.1%
summarized in Table 3.
                                                      Table 4: Comparisons against other systems (this table is
                      AS             CTB              adopted from Peng et al. 2004)
                 P    R    F1    P     R    F1
   Baseline    96.7% 96.8% 96.7% 88.5% 88.3% 88.4%
   Joint Decoding 96.9% 96.7% 96.8% 89.4% 88.7% 89.1% 6.2  Results of POS Tagging
                      PK              HK              Since the Bakeoff competition does not provide gold-standard
                 P    R    F1    P     R    F1        POS tagging outputs, we only used CTB corpus to compare
   Baseline    94.9% 94.9% 94.9% 94.9% 95.5% 95.2%    the POS tagging results of our joint decoding method with the
   Joint Decoding 95.3% 95.0% 95.2% 95.0% 95.4% 95.2% baseline method. We performed 10-fold cross-validation on
                                                      the CTB corpus. The results are summarized in Table 5.
Table 3: Overall results on First SIGHAN Bakeoff open
tracks. P stands for precision, R stands for recall, F1 stands         1     2    3     4    5     6
for the F1 measure.                                      Baseline    93.8% 93.7% 90.2% 92.0% 93.3% 87.2%
                                                         Joint Decoding 94.0% 93.9% 90.4% 92.2% 93.4% 87.5%
  For comparison of our results against previous work and              7     8    9    10     average
other systems, we summarize the results on the four open Baseline    92.2% 90.8% 91.5% 92.0 % 91.67%
tracks in Table 4. We adopted the table used in [Peng et al., Joint Decoding 92.4% 91.0% 91.7% 92.1% 91.86%
2004] for consistency and ease of comparison. There were 12
participating teams (sites) in the ofﬁcial runs of the First In- Table 5: Comparison of 10-fold cross-validation POS tagging
ternational SIGHAN Bakeoff, here we only show the 8 teams results on CTB corpus. Each column represents one out of
that participated in at least one of the four open tracks. Each the 10-fold cross-validation results. The last column is the
row represents a site, and each cell gives the F1 score of a average result over the 10 folds.
site on one of the open tracks. The second to ﬁfth columns
contain results on the 4 open tracks, where a bold entry in- From Table 5 we can see that our joint decoding method
dicates the best performance on that track. Column S-Avg has higher accuracy in each one of the 10 fold tests than the
contains the average performance of the site over the tracks it baseline method. Pairwise t-test showed that our method was
participated, where a bold entry indicates that this site on av- found to be signiﬁcantly better than the baseline method un-
erage performs better than our system; column O-Avg is the der the signiﬁcance level of 3.3−5 (p-value). This improve-

                                                IJCAI-07
                                                  1711