  Towards a Computational Model of Melody IdentiÔ¨Åcation in Polyphonic Music

                  S√∏ren Tjagvad Madsen                           Gerhard Widmer
              Austrian Research Institute for         Department of Computational Perception
               ArtiÔ¨Åcial Intelligence, Vienna             Johannes Kepler University, Linz
                   soren.madsen@ofai.at                        gerhard.widmer@jku.at


                    Abstract                          MIDI Ô¨Åle contains the ‚Äòmain melody‚Äô [Rizo et al., 2006;
                                                      Friberg and Ahlb¬®ack, 2006]. In both cases a statistical ap-
    This paper presents Ô¨Årst steps towards a sim-     proach was taken ‚Äì learning properties of melodic and non-
    ple, robust computational model of automatic      melodic tracks. Ideas for converting polyphonic tracks into
    melody identiÔ¨Åcation. Based on results from mu-   melodically meaningful monophonic sequences have also
    sic psychology that indicate a relationship between been proposed [Uitdenbogerd and Zobel, 1998].
    melodic complexity and a listener‚Äôs attention, we   This paper presents Ô¨Årst steps towards a simple, robust
    postulate a relationship between musical complex- computational model of automatic melody note identiÔ¨Åcation.
    ity and the probability of a musical line to be per- Based on results from musicology and music psychology that
    ceived as the melody. We introduce a simple mea-  indicate a relationship between melodic complexity and a lis-
    sure of melodic complexity, present an algorithm  tener‚Äôs attention, we postulate that the notes making up the
    for predicting the most likely melody note at any melody line may be identiÔ¨Åed by calculating and integrating
    point in a piece, and show experimentally that this some measures of perceived complexity over time. We will
    simple approach works surprisingly well in rather introduce a simple, straightforward measure of melodic com-
    complex music.                                    plexity based on entropy, present an algorithm for predicting
                                                      the most likely melody note at any point in a piece, and show
1  Introduction                                       experimentally that this very simple approach works surpris-
Melody is a central dimension in almost all music. Human ingly well in picking out the melody notes in quite complex
listeners are very effective in (unconsciously) picking out polyphonic music. Still, the results are still far below what
those notes in a ‚Äì possibly complex ‚Äì multi-voice piece that we can expect humans to achieve, and we will discuss a num-
constitute the melodic line. Melody is also an important as- ber of possible extensions of the approach towards a more
pect in music-related computer applications, for instance, in comprehensive and effective computational model.
Music Information Retrieval (e.g., in music databases that of-
fer retrieval by melodic motifs [Weyde and Datzko, 2005] or 2 Complexity and Melody Perception
Query by Humming [Birmingham et al., 2006]).          The basic motivation for our model of melody identiÔ¨Åca-
  It is not easy to unequivocally deÔ¨Åne the concept of tion is the observation, which has been made many times
‚Äòmelody‚Äô. In a sense, the melody is the most prominent line in the literature on music cognition, that there seems to be
in a polyphonic (multi-voice) piece of music. Although in a connection between the complexity of a musical line, and
Western music, the melody is often found among the higher the amount of attention that will be devoted to it on the
notes, this is not always the case. Also, even in composi- part of a listener. A voice introducing new or surprising
tions that are explicitly structured into individual lines by the musical material will potentially attract the listener‚Äôs atten-
composer (such as, e.g., orchestral pieces consisting of mono- tion. However, if the new material is constantly repeated,
phonic instrument voices), the melody is by no means always we will pay less and less attention to it and become ha-
represented by (or ‚Äòappearing in‚Äô) the same line throughout a bituated or accustomed to the stimulus. Less attention is
piece. In a way, which notes constitute the melody is deÔ¨Åned required from the listener and the voice will fall into the
by where the listeners perceive the most interesting things to background [Snyder, 2000]. The notion of musical sur-
be going on in the music, or what they sense to be the most prise is also related to the concept of ‚Äòexpectation‚Äô as it
coherent path through the complex interweaving of musical has been put forth in recent music theories [Narmour, 1990;
lines. Thus, though our experience tells us that hearing the Huron, 2006]. If we assume that the melody is the musical
melody is a rather simple and intuitive task for humans, it is line that commands most attention and presents most new in-
by no means a simple task to be formalised in a machine. formation, it seems natural to investigate melodic complexity
  In popular music, it is sometimes assumed that the melody measures as a basis for melody detection algorithms.
does not change between the instruments present. Some work Indeed, the idea of using information-theoretic complex-
has been done on predicting which one of the tracks in a ity measures to characterise aspects of musical development

                                                IJCAI-07
                                                   459is not at all new. For instance, to cite just two, in [Dubnov pitch
et al., 2006], a measure of Information Rate computed over 6
a piece of music was shown to correlate in signiÔ¨Åcant ways    a
with familiarity ratings and emotional force response proÔ¨Åles
by human human subjects. In [Li and Sleep, 2005] it was            b
shown that kernel-based machine learning methods using a                              c
compression-based similarity measure on audio features per-                                   time-
form very well in automatic musical genre classiÔ¨Åcation.                  wi+2 -     wi+3 -
  In the current paper, we intend to show that the complexity      wi+1 -
or information content of a sequence of notes may be directly
                                                              wi   -
related to the degree to which the note sequence is perceived
as being part of the melody. Our approach is to start with a       Figure 1: Sliding the window
very simple (or simplistic) measure of complexity based only
on note-level entropies, in order to Ô¨Årst understand the in-
Ô¨Çuence of this simple parameter. In the next phases of the notes in the current window end at the same time, the next
project, more complex complexity measures based on pattern window will thus begin right after, which makes it possible
compression and top-down heuristics derived from music the- for the window to be empty. Only then will the second of the
ory will be added, one by one.                        above cases apply (the change is the entry of the next note).
                                                        Figure 1 shows the positions of the window when sliding
3  A Computational Model                              over three notes a, b,andc. Window wi contains a and b,
                                                      wi+1 contains only b, wi+2 is empty and wi+3 contains c.
The basic idea of the model consists in calculating a series of From the notes belonging to the same voice (instrument) in
complexity values locally, over short-term musical segments,
                                   1                  the window, we calculate a complexity value. We do that for
and for each individual voice in a piece. Based on these each voice present in the window. The most complex voice
series of local complexity estimates, the melody is then re- is expected to be the one that the listener will focus on in this
constructed note by note by a simple algorithm (section 3.4). time period. The complexity measures and the melody note
  The information measures will be calculated from the prediction method are explained below.
structural core of music alone: a digital representation of the
printed music score. Though the model works with arbitrary 3.2 Entropy Measures in Musical Dimensions
MIDI Ô¨Åles which may represent actual performances, it will
                                                      Shannon‚Äôs entropy [Shannon, 1948] is a measure of random-
not consider performance aspects like expressive dynamics,
                                                      ness or uncertainty in a signal. If the predictability is high,
articulation, timbre, etc. These may well contain a lot of use-
                                                      the entropy is low, and vice versa.
ful information for decoding the melody (in fact, expressive
                                                        Let X =  {x1,x2,...,xn} and p(x)=Pr(X   =  x) then
music performance is a means used by performers to eluci-
                                                      the entropy H(x) is deÔ¨Åned as:
date the musical structure of a piece [Gabrielsson, 1999]),
                                                                             
but we want to exclusively focus on music-structural aspects      H  X     ‚àí    p x      p x
Ô¨Årst, in order not to mix different factors in our investigation.   (  )=         ( )log2 ( )         (1)
                                                                             x‚ààX
3.1  The Sliding Window                                 X  could for example be the set of MIDI pitch numbers
The algorithm operates by in turn examining a small subset of and p(x) would then be the probability (estimated by the fre-
the notes in the score. A Ô¨Åxed length window (with respect to quency) of a certain pitch. In the case that only one type of
duration) is slid from left to right over the score. At each step, event (one pitch) is present in the window, that event is highly
the window is advanced to where the next ‚Äòchange‚Äô happens predictable or not surprising at all, and the entropy is 0. En-
so no window will contain exactly the same set of notes, but at tropy is maximised when the probability distribution over the
the same time all possibilities of placing the window resulting present events is uniform.
in different content have been examined. The Ô¨Årst window We are going to calculate entropy of ‚Äòfeatures‚Äô extracted
starts at time 0. It is then moved ahead in time until the end from the notes in monophonic lines. We will use features re-
of the piece. At each step, the next window will begin at lated to pitch and duration of the notes. A lot of features are
whatever of the following two situations occurs Ô¨Årst: possible: MIDI pitch number, MIDI interval, pitch contour,
                                                      pitch class, note duration, inter onset interval etc. (cf. [Con-
 1. offset of Ô¨Årst ending note in current window      klin, 2006]). We have used the following three measures in
 2. onset of next note after current window           the model presented here:
  In the Ô¨Årst case, the change occurs since a note ‚Äòleaves‚Äô the 1. Pitch class (C): count the occurrences of different pitch
current window; the next window will begin right after the classes present (the term pitch class is used to refer the
Ô¨Årst occurring offset of a note in the current window. If all ‚Äòname‚Äô of a note, i.e., the pitch irrespective of the octave,
                                                          such as C, D, etc.);
  1We assume that a polyphonic piece has already been ‚Äòstreamed‚Äô
into individual voices. That is another non-trivial music analysis 2. MIDI Interval (I): count the occurrences of each melodic
problem, but recent work of ours [Madsen and Widmer, 2006] indi- interval present (e.g., minor second up, major third
cates that it can be solved quite effectively, via heuristic search. down,...);

                                                IJCAI-07
                                                   460 3. Note duration (D): count the number of note duration windows
    classes present, where note classes are derived by dis- 6
    cretisation (a duration is given its own class if it is not
                                                           w1 -             w4 -
    within 10% of an existing class).
                                                              w2 -             w5 -
  With each measure we extract events from a given se-             w3 -
quence of notes, and calculate entropy from the frequencies
                                                          p   p      p      p    p
of these events (HC, HI ,HD).                              1   2      3      4    5      -prediction period
  HC  and HI are thought to capture opposite cases. HC
                                                          (1) (1,2) (2,3)   (4)  (4,5) overlapping windows
will result in high entropy when calculated on notes that form
            H
a scale, while I will result in low entropy. In situations Figure 2: Prediction periods and windows overlapping them.
where there are more different intervals than pitch classes
(e.g. an ‚Äòalberti bass‚Äô, or a triad chord played in arpeggio
up and down), HI will produce a higher entropy than HC . simpler patterns. Before turning to these more complex mea-
  So far rhythm and pitch are treated separately. We have sures and the assumptions they make, we would like to in-
also included a measure HCID weighting the above three vestigate the power of a simple and well-understood measure
                 1             1
measures: HCID = 4 (HC + HI )+ 2 HD.                  like entropy.
  Entropy is also deÔ¨Åned for a pair of random variables with
joint distribution:                                   3.4  Predicting Melody Notes
                      
       H X, Y    ‚àí         p x, y    p x, y           Given the set of windows described above and an entropy
        (     )=            (   )log2[ (  )]    (2)   value for each voice present in each window we will predict
                   x‚ààX y‚ààY                            the notes expected to belong to the melody. We consider in
  We will test two joint entropy measures: Pitch class in re- turn the notes in the interval between the starting points of
lation to duration (HC,D) and interval plus duration (HI,D). two consecutive windows ‚Äì the prediction period. The pre-
These are expected to be more speciÔ¨Åc discriminators. diction period pi is thus the interval between the beginning of
  As melodic intervals are meant to be calculated from suc- window wi and the beginning of wi+1 (see Figure 2).
cessive single musical events (rather than between chords), We want to mark, in each prediction period, the notes that
we will apply these measures only to individual lines in the pertain to the most complex voice. Complexity measures
music ‚Äì instrumental parts. In the few cases where it does from each window a note appears in will inÔ¨Çuence the pre-
happen that a part contains simultaneous notes (e.g., a vio- diction. In a prediction period pi, we will consider the set
lin), only the top note is used in the entropy calculation. o(pi) of all windows that overlap this period. For pi the set
                                                      will contain all windows that have not ended at the start time
3.3  An Alternative: Complexity via Compression       of pi+1. Figure 2 gives an example of prediction periods and
The entropy function is a purely statistical measure related to overlapping windows ‚Äì e.g. o(p2) is the set {w1,w2}.
the frequency of events. No relationships between events is For each voice in each window, a complexity value was
measured ‚Äì e.g. the events abcabcabc and abcbcacab    calculated by the time the windows were calculated. The av-
will result in the same entropy value. Humans, however, erage complexity value for each voice present in the windows
would probably describe the Ô¨Årst string as three occurrences in o(pi) is calculated. Based on these values, we can now
of the substring abc ‚Äìweinferstructure. According to  rank the voices according to their average complexity over
Snyder, we perceive music in the most structured way pos- o(pi), and a ‚Äòwinning‚Äô voice is found. Every note in wi (the
sible [Snyder, 2000]. To take this into account, complexity window where pi begins) gets its melody attribute set to true
measures based on compression could be considered. Music if it is part of the winning voice, and to false otherwise.
that can be compressed a great deal (in a lossless way) can In each prediction period, exactly the windows overlapping
then be considered less complex than music that cannot be (or partly overlapping) this period are contributing to the Ô¨Ånal
compressed. Methods exist that substitute recurring patterns score of each voice. The policy is to mark all notes in the
with a new event, and store the description of that pattern only entire window wi starting at pi.Whenwi+1 occurs before wi
once, e.g. run-length encoding or LZW compression [Ziv and has ended, the contribution from this new window can change
Lempel, 1977]. This idea has been discussed in several musi- the prediction of wi from that point in time and onwards. A
cal application contexts (e.g., in Music Information Retrieval new prediction period pi+1 begins ‚Äì including all windows
[Li and Sleep, 2005] or in automated music analysis and pat- now present at this time, and the notes‚Äô melody attribute is
tern discovery [Lartillot, 2006]). However, these compres- reset accordingly. So if a note is only contained in a single
sion algorithms are not well suited for compressing the short prediction period, its status will only be set once. A long note
sequences that we are dealing with. Special algorithms for contained in a number of prediction periods will Ô¨Ånally be
compressing short sequences will be needed.           judged by the period it last occurs in.
  Shmulevich and Povel [Shmulevich and Povel, 2000] have Thus the predicted notes may belong to different voices
examined methods for measuring the complexity of short from period to period ‚Äì the role as the most prominent voice
rhythmic patterns which are supposed to repeat inÔ¨Ånitely. may change quickly. We are not just predicting an entire
Tanguiane‚Äôs measure [Tanguiane, 1993] is based on the idea voice to be the most interesting, but every note is considered.
that a rhythmic pattern can be described as elaborations of In case there are several voices that share the highest com-

                                                IJCAI-07
                                                   461plexity value for a given prediction period, the voice with the                    Haydn      Mozart
highest pitch will be predicted (e.g., of two voices playing in Total number of notes 5832    13428
octaves, the higher one is chosen).                       Number of melody notes    2555       2295
                                                          Melody note percentage   43.8 %     17.1 %
4  Experiments                                            Number of voices            4         10
                                                          Duration                11:38 min  6:55 min
4.1  The Musical Test Corpus
To perform experiments we need music which is composed                Table 1: The test data
for different parts, and encoded in such a way that each part
is separately available. Furthermore, since our complexity these situations it is also difÔ¨Åcult to tell what a listener will
measure assumes monophonic music, each voice in the piece actually listen to).
should be close to monophonic. This places some restric- In any case, the annotations made by the musicologists
tions on the experiments we are able to do. A typical piano were taken to be authoritative; they were adopted unchanged
sonata, lacking the explicit voice annotation (or being one and used as ground truth for the evaluation. Table 1 shows
non-monophonic part), will not be an appropriate choice. some information about the test data.
  Since the model presented here does not take into account 4.3 Evaluation Method
any performance aspects but only the musical surface (score),
we will use MIDI Ô¨Åles generated from the MuseData for- We can now measure how well the predicted notes correspond
mat (http://www.musedata.org). The durations of the notes to the annotated melody in the score. We express this in terms
in these Ô¨Åles are nicely quantised. The model will run on all of recall (R) and precision (P )values[van Rijsbergen, 1979].
types of MIDI Ô¨Åles, but performed music tends to bias the Recall is the number of correctly predicted notes (true posi-
rhythm complexity. Two pieces of music were chosen to be tives, TP) divided by the total number of notes in the melody.
annotated and used in the experiment:                 Precision is TP divided by the total number of notes predicted
                                                      (TP + FP (false positives)). The F-measure combines recall
 1. Haydn, F.J.: String quartet No 58 op. 54, No. 2, in C and precision into one value:
    major, 1st movement
                                                                                    2RP
 2. Mozart, W.A.: Symphony No 40 in G minor (KV 550),                F  R, P     ‚àí
                                                                       (    )=1    R    P             (3)
    1st movement                                                                     +
                                                        A high rate of correctly predicted notes will result in high
  This is not an awful lot of data, but since the music will values of recall, precision and F-measure (close to 1.0).
have to be annotated manually, this will have to do for our
initial experiments.                                  4.4  Results
                                                      We performed prediction experiments with four different
4.2  Annotating Melody Notes                          window sizes (1-4 seconds) and with the six different entropy
Melody annotation is non-trivial and rather tedious task. A measures described above. Table 2 shows recall, precision
trained musicologist was asked to serve as expert annotator. and F-measure values from all experiments with the two eval-
She was given a piano roll representation of the music with uation pieces. In addition, the columns marked P show the
‚Äòclickable‚Äô notes and simple playback options for listening to value of the F-measure achieved by the simple strategy of al-
the MIDI sound. The annotator, who was not aware of the ways picking the highest note(seebelow).Thehighestvalues
purpose of this task, was instructed to mark notes she would in each row are printed in bold (ignoring the P columns).
consider as ‚Äòmelody‚Äô.                                   The string quartet turned out to be the less complex of the
  The test pieces turned out to have quite distinguishable two pieces. This is not much of a surprise. It is easier to
melodic lines. The annotator solved the task by marking the discriminate between 4 than 10 voices, and also the compo-
notes that she was humming during listening to the pieces. sitional structures of the pieces are quite different. Overall
Some immediate differences between the ‚Äòtrue‚Äô concept of the joint pitch class and duration measure HC,D was found
melody and some assumptions behind our complexity-based to have the greatest predictive power, generally followed by
melody prediction model became immediately clear after the weighted combination HCID. Pitch class seems to be the
talking to the annotator:                             single most important measure in the string quartet. In total,
  Our model assumes that there is always one most complex the joint measures perform better than the measures based on
voice present, but a melody was not found to be present at all a single feature.
times. Furthermore, melodic lines were sometimes marked as We can conclude that there is indeed a correlation between
overlapping, which the model does not allow. The annotator melody and complexity in both pieces. The precision value
chose not to mark thematic lines that clearly were a (melodic) of 0.60 in the best symphony experiment with a resulting F-
response in another voice to the melody rather than a contin- measure of 0.51 (window size 3 seconds) tells us that 60 % of
uation of the melody line. Our model might mark both the the predicted notes in the symphony are truly melody notes.
melody and the response. Another source of error is situa- In the string quartet, starting in bar 105 (see Figure 3) the
tions where the melodic line consists of long sustained tones second violin is alternating between a single note and notes
while the accompanying notes are doing all the action. The from a descending scale, making the voice very attractive
model will erroneously predict an accompanying voice. (In (lots of different notes and intervals) while the ‚Äòreal melody‚Äô

                                                IJCAI-07
                                                   462                               Haydn                                          Mozart
 Win         P    HC    HI    HD    HCID    HC,D   HI,D     P    HC     HI    HD   HCID    HC,D    HI,D
       R    0.91  0.83  0.79  0.67   0.84    0.87   0.80   0.27  0.36  0.31  0.32   0.41    0.47   0.32
  1s   P    0.96  0.78  0.73  0.80   0.81    0.81   0.74   0.61  0.41  0.31  0.52   0.54    0.54   0.32
       F    0.94  0.81  0.76  0.73   0.83    0.84   0.77   0.37  0.38  0.31  0.40   0.47    0.51   0.32
       R    0.91  0.83  0.80  0.64   0.80    0.87   0.81   0.23  0.35  0.33  0.27   0.37    0.45   0.37
  2s   P    0.96  0.81  0.75  0.81   0.82    0.87   0.76   0.58  0.41  0.36  0.52   0.57    0.58   0.41
       F    0.93  0.82  0.77  0.71   0.81    0.87   0.78   0.33  0.38  0.35  0.36   0.45    0.51   0.39
       R    0.91  0.83  0.79  0.63   0.78    0.84   0.80   0.20  0.33  0.28  0.24   0.33    0.45   0.36
  3s   P    0.97  0.83  0.75  0.81   0.83    0.87   0.78   0.53  0.40  0.31  0.49   0.54    0.60   0.42
       F    0.94  0.83  0.77  0.71   0.81    0.85   0.79   0.29  0.36  0.29  0.33   0.41    0.51   0.38
       R    0.93  0.84  0.76  0.59   0.74    0.80   0.79   0.18  0.34  0.24  0.19   0.31    0.44   0.33
  4s   P    0.96  0.84  0.74  0.78   0.84    0.85   0.78   0.50  0.40  0.28  0.41   0.55    0.61   0.41
       F    0.95  0.84  0.75  0.67   0.78    0.83   0.79   0.26  0.37  0.26  0.26   0.40    0.51   0.36

                       Table 2: Recall, precision, and F-measure for melody note predictions.
                                                                           

                                                         Fl.
   Vl. I                                                          f
                                                                          
                               
   Vl. II                                 
                                                   Ob.
                                                                  f                      p
                                                                           
   Vla.
                                                         Cl.
                                                                  f
   Vlc.                                                                    
                                                        Fg.
                                                                  f             p
     Figure 3: The string quartet, measures 105-108                        
                                                        Cor.
                                                                 f
in the Ô¨Årst violin is playing fewer different notes, but has               
a more varied rhythm. We took a closer look at this pas- Cor.
sage. Setting the window size to 2 seconds, the measures          f
HD, HCID,andHC,D    recognise the upper voice as melody
       H   H      H                                    Vl. I
whereas  C , I ,and I,D suggest the lower. The measures           f             p
based on intervals are naturally led astray in this case, and the
measure based solely on pitch class is also.           Vl. II
  The reader may also ask if it would not be more effective       f             p
to just always predict the highest note as the melody note ‚Äì
                                                        Vla.
after all, that is where the melody is most often, at least in    f
relatively simple music. We checked against this baseline.                               p
The results are shown in the columns labeled P in Table 2. Vc.
Indeed, it turns out that in Hadyn string quartet, the simple Cb. f                      p
strategy of always picking the highest note outperforms all
of our heuristics ‚Äì at least in terms of global precision and Figure 4: The symphony, measures 17-22
recall, though not necessarily in terms of the local musical
coherence of the resulting melodic line.
                                                      rectly catches the entry of the theme in bar 19, but the bassoon
  In the more complex Mozart piece, however, we witness
                                                      (Fg.) is falsely predicted in bar 17-19 ‚Äì the wind instruments
that the highest note prediction strategy was outperformed by
                                                      play very similar lines, but because the bassoon continues a
most of our methods. In the symphony movement the melody
                                                      bit further than the others it becomes the most complex.
is not on top as often. Also, the melody role is taken by dif-
ferent instruments at different times. Figure 4 shows 6 bars
(bar 17-22) from the symphony. In the Ô¨Årst three, the Ô¨Çute 5 Discussion
(top voice) was annotated to be the melody, but the melody In our opinion, the current results, though based on a rather
then moves to the Ô¨Årst violin in bar 19. In bar 21 the Ô¨Årst limited test corpus, indicate that it makes sense to consider
oboe enters on a high-pitched long note ‚Äì above the melody. musical complexity as an important factor in computational
Such high-pitched non-melodic notes (doubling chord tones) models of melody perception. The results of the experiments
occur frequently in the movement. The HC,D measure cor- show that a simple entropy based incremental algorithm can

                                                IJCAI-07
                                                   463