                         A Dual-Pathway Neural Network Model of
                     Control Relinquishment in Motor Skill Learning

                                   Ashish Gupta & David C. Noelle
                      Department of Electrical Engineering and Computer Science
                                          Vanderbilt University
                            {ashish.gupta, david.noelle}@vanderbilt.edu

                    Abstract                          processes are implemented by two largely separate neural net-
                                                      works in the brain [Bapi et al., 2000; Hikosaka et al., 2002;
    Cognitive psychologists have long recognized that Wolpert et al., 2001]. Both networks have the capability to
    the acquisition of a motor skill involves a transi- individually acquire motor skills, but they typically coordi-
    tion from attention-demanding controlled process- nate with each other during learning. The controlled pathway
    ing to more ﬂuent automatic processing. Neurosci- includes dorsolateral prefrontal cortex (DLPFC), anterior cin-
    entiﬁc studies suggest that controlled and automatic gulate cortex (ACC), anterior parts of the cerebellum, anterior
    processing rely on two largely distinct neural path- parts of the basal ganglia, and the pre-supplementary motor
    ways. The controlled pathway, which includes the  area (preSMA). This pathway is seen as acquiring represen-
    prefrontal cortex, is seen as acquiring declarative tations of motor skills that are primarily declarative. Declar-
    representations of skills. In comparison, the au- ative representations are formed very quickly, and they guide
    tomatic pathway is thought to develop procedural  skill execution during the early stages of learning. The sec-
    representations. Automaticity in motor skill learn- ond network, which we call the automatic pathway, includes
    ing involves a reduction in dependence on frontal areas like the supplementary motor area (SMA), primary mo-
    systems and an increased reliance on the automatic tor cortex, lateral parts of the cerebellum, and lateral parts
    pathway. In this paper, we propose a biologically of the basal ganglia. As a skill becomes well practiced, this
    plausible computational model of motor skill auto- network slowly encodes a procedural representation of the
    maticity. This model offers a dual-pathway neuro- skill. With practice, the involvement of the frontal controlled
    computational account of the translation of declar- pathway decreases, and the skill comes to be primarily exe-
    ative knowledge into procedural knowledge during  cuted by the automatic pathway. The modulation of frontal
    motor learning. In support of the model, we re-   involvement is thought to be governed by a separate coordi-
    view some previously reported human experimen-    nation mechanism, perhaps embodied in the preSMA and the
    tal results involving the learning of a sequential key ACC [Hikosaka et al., 2002].
    pressing task, and we demonstrate, through simula-
    tion, how the model provides a parsimonious expla-  This paper addresses a key question concerning this pro-
    nation for these results.                         cess - are the information processing properties of these brain
                                                      regions, as they are currently understood, sufﬁcient to account
                                                      for the behavioral shift in skill learning? To address this ques-
1  Introduction                                       tion, we have explored a neurocomputational model of motor
Learned motor skills are central to most human activities. skill learning that is based on the dual-pathway hypothesis.
Learning plays a critical role in our abilities to walk, talk, We report the results of simulation experiments involving a
cook, type, and play games like ping-pong, for example. The sequential key pressing task. In these simulations, keys are
importance of learning in human motor performance has led pressed using a two joint planar arm. The arm learns to trace
many robotics researchers to examine machine learning ap- out a sequence of trajectories such that the end effector suc-
proaches to motor control. We currently lack a clear and com- cessively moves from one key to the next in a trained sequen-
plete computational account of how humans acquire motor tial order.
skills, however. In hopes of addressing this deﬁcit, this paper In our model, the controlled pathway learns a declarative
offers some insights into the neurocomputational structure of representation of the task: the key sequence. When executing
motor skill learning.                                 the task, the prefrontal cortex (PFC) in the controlled path-
  One of the central ﬁndings of cognitive research into skill way actively maintains an abstract representation of the next
learning involves the process of automaticity, through which key to be pressed. This representation of the desired key,
ﬂuency at a skill is improved by gradually shifting from a along with the current state of the arm, is then transformed
declarative representation of the task to a more procedural by the network into an appropriate reaching trajectory toward
representation [Anderson, 1981]. A growing body of neu- that key. Once the current target key has been pressed, the
roscientiﬁc evidence suggests that declarative and procedural PFC rapidly updates to encode the next key in the sequence,

                                                IJCAI-07
                                                   405and the next reach is produced. Thus, the controlled pathway constant number of units surpassing their ﬁring threshold. In
needs only to learn the sequence of keys during task learning, our model, this mechanism both encourages learning through
depending on a pre-trained motor area to translate the PFC the development of sparse neural representations and it helps
representation of each target key into an appropriate reaching to make neural network outputs interpretable.
motion.
  In contrast, the automatic pathway of our model learns the 2.2 Cognitive Control
entire motor skill from scratch. It acquires a procedural repre- Cognitive control involves the ability to behave according to
sentation of the skill by learning the entire motion trajectory rules or goals instead of responding in a reﬂexive manner.
needed for the complete sequence of key presses. This path- Prefrontal cortex (PFC) is critical for robust cognitive con-
way learns more slowly than the controlled pathway, because trol [OReilly and Munakata, 2001]. Dense recurrent connec-
much more detailed knowledge must be learned.         tivity in PFC allows it to actively maintain information in ﬁr-
  As the automatic pathway becomes proﬁcient in executing ing rate patterns, and it is thought that this active maintenance
the sequence, the involvement of the controlled pathway is of task relevant information is central to task directed behav-
withdrawn. In our model, this shift is driven by a cognitive ior. Also, interactions with the midbrain allow the PFC to
control mechanism. This mechanism monitors performance rapidly update its state, based on task requirements [Rougier
error and modulates the weight given to the controlled path- et al., 2005]. We have incorporated both active maintenance
way appropriately. When error is high, the contribution of and rapid updating in the PFC component of our model.
the fast-learning controlled pathway is strengthened. As er- The strength of cognitive control can be modulated based
ror falls, the contribution of the automatic pathway is allowed on the task requirements. Botvinick et al. [2001] proposed
to dominate.                                          that the anterior cingulate cortex (ACC) monitors the amount
                                                      of conﬂict between parallel neural pathways and strengthens
2  Background                                         cognitive control when conﬂict is high. In our model, perfor-
                                                      mance error is seen as a sign of conﬂict. Thus, we modulate
2.1  Leabra                                           the strength of cognitive control between trials, in proportion
Our model uses the Leabra modeling framework [OReilly and to the amount of error experienced on previous trials.
Munakata, 2001]. Leabra offers a collection of integrated
cognitive modeling formalisms that are grounded in known 2.3 Motor Skill Learning
properties of cortical circuits but are sufﬁciently abstract to A wide variety of sequential key pressing tasks have been
support the simulation of behaviors arising from large neu- used to investigate human motor skill learning [Bapi et al.,
ral systems. It includes dendritic integration using a point 2000; Hikosaka et al., 2002; Rand et al., 2001], and a num-
neuron approximation, a ﬁring rate model of neural coding, ber of interesting ﬁndings have resulted. There is a period of
bidirectional excitation between cortical regions, fast feed- rapid improvement in performance during the early stages of
forward and feedback inhibition, and a mechanism for synap- training. During this stage, learning is effector independent
tic plasticity. Of particular relevance to the current model (e.g., switching hands does not substantially degrade perfor-
are Leabra’s synaptic learning rules and its lateral inhibition mance). Further, interfering with the frontal systems involved
mechanism.                                            in the controlled pathway during this period seriously disrupts
  Leabra modiﬁes the strength of synaptic connections in performance. Interfering with the automatic pathway, how-
two ways. An error correction learning algorithm changes ever, does not affect performance during this early period.
synaptic weights so as to improve network task performance. After extensive training, the execution of the skill becomes
Unlike the backpropagation of error algorithm, however, more automatized. The skill becomes relatively effector de-
Leabra’s error correction scheme does not require the biolog- pendent. Also, performance remains robust if the controlled
ically implausible communication of error information back- pathway is disrupted.
ward across synapses. In addition to this error-correction Additionally, studies of choking under pressure have sug-
mechanism, Leabra also incorporates a Hebbian correlational gested that errors in performance in the face of stress may
learning rule. This means that synaptic weights will continue have different causes early and late in learning [Beilock et
to change even when task performance is essentially perfect. al., 2004]. Early in learning, when the controlled pathway
  The effects of inhibitory interneurons tend to be strong and dominates, errors may arise due to a failure to engage cog-
fast in cortex. This allows inhibition to act in a regulatory nitive control systems. With a well practiced skill, however,
role, mediating the positive feedback of bidirectional exci- degraded performance may be due to the excessive exertion
tatory connections between brain regions. Simulation stud- of unnecessary cognitive control. These results are also re-
ies have shown that a combination of fast feedforward and ﬂected in our model.
feedback inhibition can produce a kind of “set-point dynam-
ics”, where the mean ﬁring rate of cells in a given region 2.4 Previous Computational Models
remains relatively constant in the face of moderate changes Ours is certainly not the ﬁrst computational model of mo-
to the mean strength of inputs. Leabra implements this dy- tor skill learning. For example, Wolpert et al [1998; 2001]
namic using a k-Winners-Take-All (kWTA) inhibition func- proposed MOSAIC, a model for sensorimotor control. MO-
tion that quickly modulates the amount of pooled inhibition SAIC consists of multiple modules, where each module con-
presented to a layer of simulated cortical neural units based sists of a pair of forward and inverse models. While MO-
on the layer’s level of input activity. This results in a roughly SAIC has many strengths, it does not address the issue of

                                                IJCAI-07
                                                   406representational change in skill learning. There is no mecha-
nism for early declarative representations, making MOSAIC
somewhat analogous to our automatic pathway.
  The automatic pathway in our model is largely based on
the previous Leabra networks of Gupta and Noelle [2005b;
2005a]. These networks were used to explore the neurocom-
putational principles underlying skill savings and the transfer
of knowledge from one skill to another.
  Nakahara et al. [2001] proposed a skill learning model that
is very similar in general architecture to our own. There are
a number of important differences between our models, how-
ever. First, their model does not focus on the question of dif-
ferences in declarative and procedural represntations of the Figure 1: A two joint planar arm and a keyboard. The state of
skill. Instead, the early dominance of the controlled path- the arm at any point in time is given by the vector of joint an-
way is driven by differential learning rates, with the con- gles (q1, q2). The arm produces motion trajectories such that
trolled pathway made to learn faster. In contrast, our model its end effector moves from one key to the next, in sequence.
is novel in showing that declarative and procedural represen-
tations can naturally emerge from neural encodings, and this
difference in encoding easily explains the difference in the 4 The Network
speeds of learning. Also, unlike our model, the Nakahara Figure 2 shows the Leabra network used for our simulations.
model does not include a mechanism for dynamically adjust- The Sensory Input layer provides the current state of the arm
ing cognitive control — the relative contribution of the con- as input to the network and the Motor Output layer is to pro-
trolled pathway. While the previous model does include a duce the desired arm state for the next time step. Each joint
“coordinator”, the function of this mechanism is not the same. angle is encoded over a pool of 15 neural units. Each of the
Hence, in their model, once a skill has been automatized, its 15 units has a preferred angle, ranging from −10◦ to 130◦,
controlled execution based on task demands is not possible. in 10◦ increments. To encode a given joint angle, the closest
This is inconsistent with the behavioral observations. Lastly, unit with regard to preference, as well as its two neighbors,
our model critically depends on the active maintenance of tar- are set to their maximal ﬁring rates. Similarly, patterns of
get key representations in the PFC and the rapid updating of activity over each row of 15 units in the Motor Output are
these representations as keys are pressed, while the Nakahara decoded by identifying the preferred angle of the unit in the
model incorporates no such mechanism.                 middle of the three adjacent units that are all active. Other
  The biggest point of difference between our model and the patterns of activity in the Motor Output layer are considered
previous models of skill learning is that our model grounds to be ill-formed. With each joint angle encoded over 15 units
the previous more-abstract theories in well established neu- in this way, the complete arm conﬁguration is encoded over
rocomputational mechanisms. In other words, our model 30 units.
demonstrates that the declarative/procedural translation the- The network is composed of two pathways: the controlled
ory ﬁts naturally with Leabra neurocomputational primitives, pathway on the left and the automatic pathway on the right.
and our instantiation takes a step toward the generation of In the automatic pathway, the Sensory Input layer inﬂuences
quantitative predictions for the model.               the Motor Output layer via the Automatic Path layer. This
                                                      is similar to the network used by Gupta and Noelle [2005a;
3  Tasks                                              2005b], with one addition. A contextual hidden layer has
                                                      been added to this pathway, which provides a copy of the Au-
We have used our model to simulate the learning of key press- tomatic Path layer activity at the previous time step as input
ing motor sequences. Our model controls a simulated 2-joint to the Automatic Path layer during the next time step. Con-
planar arm which moves over a 9-key keyboard, as show in nection weights from the Automatic Path layer to the Mo-
in Figure 1. The state of the arm at any point in time is rep- tor Output are not allowed to exceed 50% of the maximum
resented by the vector (q1, q2), where q1 and q2 are the two weight value allowed by Leabra (implemented by setting the
joint angles. The joint angles range between 0◦ and 120◦. relative weight scaling parameter to 0.5). This restriction al-
Movements are to be generated in such a way that the end lows the controlled pathway to strongly dominate over the
effector follows a straight line trajectory from the position automatic pathway by strengthening the controlled pathway’s
of the previous key to the position of the next key in the inﬂuence on the Motor Output layer beyond what is possi-
sequence. The arm starts over of the bottom-left key. The ble for the automatic pathway. This dominance occurs when
motion trajectory is discretized at equidistant time intervals, cognitive control is strong. When cognitive control is weak,
and hence, any trajectory is represented as a sequence of arm however, the automatic pathway weights can still be strong
states over the successive time steps. During training, the arm enough to drive appropriate outputs.
is essentially guided along the desired trajectory, with differ- In the controlled pathway, the Sensory Input layer provides
ences between the motor output of the arm controller and the input to the PFC layer. This layer generates a declarative rep-
conﬁguration of the arm, as speciﬁed by the guide, acting as resentation of the key sequence, by sequentially activating a
a measure of error to drive synaptic weight change.   single unit in the PFC Output layer corresponding to the cur-

                                                IJCAI-07
                                                   407                       Table 1: Network Performance (SSE) During Early Stages of Learning.
         Sequence    Both Pathways (High Control) Controlled Pathway Alone Automatic Pathway Alone
         Sequence 1                  12.4 (±5.1)             22.2 (±6.4)            296.4 (±25.6)
         Sequence 2                  19.2 (±2.2)             21.6 (±2.9)             214.6 (±9.4)
         Sequence 3                  16.8 (±2.5)             18.2 (±3.7)            234.0 (±22.7)

                                                      control for the previous trial. α, β and λ are constants, with
                                                      values of 1, 0 and 0.6 respectively, determined by an ad hoc
                                                      search. Conflict is a normalized measure of performance
                                                      error, and it is computed as follows:
                                                                                Error − θ
                                                                     Conflict =
                                                                                    γ
                                                      where Error is the sum squared error (SSE) produced in the
                                                      Motor Output layer during the previous trial. θ and γ are
                                                      constants with values of 10 and 80, determined by an ad hoc
                                                      parameter search. If the value of Control is less than 0.15,it
                                                      is thresholded to 0. If the value of Control is greater than 1, it
                                                      is set to 1. Hence, the magnitude of control is approximately
                                                      proportional to a running average of output error over previ-
                                                      ous trials. When error has been high, control will be high,
                                                      and the inﬂuence of the controlled pathway will be strong.
                                                        The focus of this work is on the learning of speciﬁc mo-
                                                      tor skills, rather than on the development of basic motor
Figure 2: The Leabra network. Each gray box corresponds competence. Thus, it was assumed that the system included
to a neural processing unit. Each arrow represents complete the means to generate a reaching motion to a single target
interconnectivity between the units in two layers. The dashed key, with the identity of that key being actively maintained
line from the Motor Output layer to the Sensory Input layer in PFC. This PFC-controlled reaching process was imple-
signiﬁes that, when the arm is unguided, the output at the mented in the pathway from the PFC Output, through the
previous time step is the input for the next time step. Motor Area, to the Motor Output. This portion of the net-
                                                      work was pre-trained to capture fundamental motor compe-
rent target key. The PFC Context layer feeds the PFC layer tence. During pre-training, the network experienced every
activity from the previous time step. The PFC Output layer, possible arm conﬁguration along with every possible target
as well as the Sensory Input layer, provide input to the Mo- key, and it was trained, using Leabra’s standard synaptic mod-
tor Area layer. The Motor Area layer translates the current iﬁcation rules, to produce the next time step of an appropri-
key target, in PFC Output, and the current Sensory Input into ate reaching response. Once this pre-training was complete,
an appropriate action at the Motor Output. It is important to learning was disabled for all projections going into or out of
note that, during training, the PFC Output layer receives an the Motor Area layer.
explicit error signal (as does the Motor Output layer), driv- In order to examine the learning properties of our model,
ing the PFC to learn to produce the correct sequence of target we trained it to produce three randomly generated 10-key se-
keys. Finally, the PFC layer also provides input to the Au- quences. Each simulation involved the learning of one of
tomatic Path layer. This input helps guide learning for the these sequences. Random generation of the key sequences
automatic execution of the sequence.                  resulted, at the ﬁner level of arm motion time steps, in se-
  Our model includes a cognitive control modulation mech- quences of 57, 42 and 51 arm states for the three sequences.
anism. This mechanism modulates the strength of the con- For each sequence, we examined the learning proﬁle of each
trolled pathway’s contribution to the ﬁnal motor output as of the two pathways when isolated, as well as the perfor-
well as the strength of the input going from the controlled mance of the model as a whole. Each simulation was repeated
pathway to the automatic pathway. Cognitive control is mod- ﬁve times with different random initial synaptic weights in
ulated as follows:                                    the network, and we report the mean and standard error of the
                                                      mean over these ﬁve repetitions for each measurement taken.
Controlnew =  λ Controlold +(1− λ)(αConflict+   β)
                                                      5   Results
Controlnew speciﬁes the value of control for the current trial.
This value, which is between 0 and 1, is used to scale the Initially, the automatic pathway was disabled, and only the
weights from the controlled pathway (using Leabra’s relative controlled pathway was trained. On each trial, the initial arm
weight scaling parameter). Controlold speciﬁes the value of state was presented at the network’s input, and this triggered

                                                IJCAI-07
                                                   408                          Table 2: Network Performance (SSE) After Extensive Training.
         Sequence    Both Pathways (High Control) Controlled Pathway Alone Automatic Pathway Alone
         Sequence 1                  66.4 (±4.8)             30.2 (±4.0)              29.0 (±4.5)
         Sequence 2                  36.3 (±2.2)             24.6 (±3.0)              19.3 (±2.2)
         Sequence 3                  37.4 (±3.2)             18.8 (±3.7)              11.4 (±2.5)

the selection of a target key at the PFC Output layer. A train- the observation that human performance suffers early in skill
ing signal was then provided to this layer, specifying the cor- learning when the controlled pathway is disrupted (e.g., under
rect target key. The correct target was then actively main- PFC-based working memory load).
tained in the PFC while the Motor Area layer generated the Another interesting observation is that the full model was
corresponding reaching motion. Once each reach was com- able to generate the correct sequence despite the automatic
plete, the PFC was allowed to rapidly update, based on the ac- pathway’s tendency to generate incorrect responses. It ap-
tivity in the PFC Context layer and the Sensory Input layer, pears as if the controlled pathway, which was the primary
selecting a new target key at PFC Output. A training signal contributor to the correct output, learned to compensate for
was then provided, once again, to PFC Output, and this pro- some of the erroneous activity from the automatic pathway.
cess continued until the end of the sequence, and the end of This may be the reason why the error for the isolated con-
the trial, was reached. Through this training process, the con- trolled pathway is slightly greater than the error for the full
trolled pathway learned quickly. An average of 11.8 (±1.8), model. The isolated controlled pathway might have been
18.6 (±2.0), and 13.2 (±3.1) trials were required for the con- overcompensating for an automatic pathway that was no
trolled pathway to learn the three sequences to criterion, re- longer present.
spectively.                                             Training was continued past this point. When the control
  Next, the controlled pathway was disabled in order to ex- was up-modulated to a high value, the network produced cor-
amine the learning performance of the automatic pathway. rect motor sequence due to the corresponding frontal involve-
Once again, each trial began with the initial arm position be- ment. However, as correct outputs were generated, the run-
ing provided as input. Synaptic weight changes were made ning average of error decreased and the strength of control
in response to training signals provided at the Motor Output dropped. When this happened, the controlled pathway’s con-
layer, with performance error driving learning in the stan- tribution to the motor output decreased, bringing error back
dard Leabra manner. The arm was guided from key to key in up and strengthening control. Thus, control oscillated close
the sequence, forcing the Sensory Input to always fall along to its maximum level. During this entire process, the auto-
the correct trajectory. This process continued until the motor matic pathway continued to learn. When the strength of con-
sequence was complete. An average of 83.0 (±10.4), 76.4 trol was high, the network generated correct output. Since
(±5.8)and70.2 (±7.0) trials were required for this pathway the amount of error was negligible on these trials, Leabra’s
to master the three sequences, respectively. Hence, the time error-correction learning rule played only a small role, and
required to train the automatic pathway was found to be sub- the automatic pathway learned primarily through the Hebbian
stantially greater than the time required to train the controlled component of the learning algorithm. When control dipped
pathway for all three sequences. Clearly, learning the declar- and signiﬁcant error appeared at the output, the automatic
ative sequence of key identities was easier than learning the pathway beneﬁted from the error driven learning component
nuanced motor trajectory needed to visit every key in order. of Leabra. For the three sequences, the automatic pathway
This provides an explanation for why learning in the con- needed an average of 334.4 (±42.5), 76.8 (±4.6)and233.2
trolled pathway is generally faster, allowing it to dominate (±21.4) training trials, respectively, to master the task. Once
performance early in skill acquisition.               the automatic pathway learned the sequence, the strength of
  Finally, the complete model was trained on each key se- control dropped to 0. This signiﬁed that no control was being
quence, with the control modulation mechanism determining employed and the task had been automatized.
the strength of the controlled pathway on any given trial. Ini- Network performance at this late stage of learning is shown
tially, performance error was high. This quickly resulted in in Table 2. At this point, each pathway produced reasonable
a high level of control (i.e., a control value of 1), maximally performance when isolated from the other. Interestingly, error
increasing the inﬂuence of the controlled pathway. Because increased when both pathways were incorporated and control
the controlled pathway can learn rapidly, error then dropped was set to its maximum level. Thus, our model suffers when
rapidly. This drop occurred after 15 (±1.3), 19.8 (±4.9)and excessive control is employed during the execution of an au-
15.2 (±2.3) training trials for the three sequences, respec- tomatized motor skill, just as is observed in humans who are
tively. Network performance at this point in training is shown performing a well-practiced skill under pressure [Beilock et
in Table 1, alongside the performance that arose when each al., 2004]. Late in training, as control reached its minimum
pathway was temporarily disabled at this point in training. value of 0, the automatic pathway learned to generate the cor-
Note that correct motor sequences were produced by the in- rect motor sequence without any input from the controlled
tact model and by the controlled pathway alone but not by pathway. Hence, the introduction of control resulted in un-
the automatic pathway in isolation. This is consistent with wanted frontal input, degrading performance.

                                                IJCAI-07
                                                   409