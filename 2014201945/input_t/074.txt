             Monte Carlo Theory as an Explanation of Bagging and Boosting 

                    Roberto Esposito                                         Lorenza Saitta 
                  Universita di Torino                            Universita del Piemonte Orientale 
           C.so Svizzera 185, Torino, Italy                     Spalto Marengo 33, Alessandria, Italy 
                  csposito@di.unito.it                                    saitta@mfn.unipmn.it 


                        Abstract                               from Monte Carlo theory. Section 4 is the core of the 
                                                               paper: it introduces the link between Monte Carlo theory 
     In this paper we propose the framework of 
                                                               and Ensemble Learning algorithms, and analyzes the two 
     Monte Carlo algorithms as a useful one to ana•
                                                               algorithms in the ideal situation of having access to the 
     lyze ensemble learning. In particular, this 
                                                               whole example and hypothesis spaces. Section 5 relaxes 
     framework allows one to guess when bagging 
                                                               the hypotheses of Section 4. In particular, it focuses on 
     will be useful, explains why increasing the mar•
                                                               AdaBoost's case offering an intuitive accounting of the 
     gin improves performances, and suggests a new 
                                                               generalization performances of the algorithm. Finally, 
     way of performing ensemble learning and error 
                                                               Section 6 concludes the paper and proposes future work. 
     estimation. 
                                                               2 Bagging and AdaBoost 
1 Introduction 
                                                               Bagging [Breiman, 1996] is one among the most studied 
Ensemble Learning aims at combining learned hypothe•           Ensemble Learning algorithms. It takes in input a learn•
ses for classification tasks instead of choosing one. It has   ing set Lo, an integer number T, and a (possibly weak) 
proved to be a valuable learning approach, and it is ac•       induction algorithm A. At each iteration step t the algo•
tively investigated in the Machine Learning community          rithm creates a bootstrap replicate L [Efron & Tibshirani, 
[Freund 1995; Freund & Schapire 1997; Breiman, 1996;           1993] of the original learning set, and uses it in conjunc•

Wolpert, I992|.                                                tion with A to form a new hypothesis ht. When T hy•
                                                               potheses have been learned, they are combined using a 
In addition to the advantages pointed out by Dietterich        simple majority voting rule. 
[2000], what really attracts the great interest to ensemble 
learning is its amazing effectiveness and robustness to        Breiman [1996] found a significant increase of classifi•
overfitting. In fact, ensemble classifiers, and specifically   cation accuracy, when the hypotheses are bagged, on dif•
AdaBoost, often show a drop in generalization error far        ferent datascts from the UCI repository, for both regres•
beyond the point in which the training error reaches zero.     sion and classification tasks. Moreover, in the same pa•
                                                               per, a theoretical analysis is carried on. The notion of 
In this paper wc concentrate on two approaches, namely         order correct classifier is introduced, and it is shown 
Bagging [Breiman, 1996], and Boosting, as implemented          that when A is order correct, then Bagging is expected to 
in the AdaBoost algorithm [Freund & Schapire, 1997],           behave almost optimally (i.e., it behaves like the Bayes 
and we propose an analysis of these two approaches by          classifier). Throughout the paper it is claimed that "bag•
exploiting links with Monte Carlo theory. This parallel        ging stable classifiers is not a good idea". A "stable" 
allows a deeper understanding of the basic process un•         classifier is qualitatively defined as one that does not 
derlying hypothesis combination. In particular:                show large variations in the learned hypotheses when the 
   • it suggests the conditions under which Bagging is         training set undergoes small variations. Experimental 
       likely to be better than single hypothesis learning,    analysis of Bagging's performances is provided by Bauer 
                                                               and Kohavi [1999], Quinlan [1996], and Dietterich 
   • it explains why reducing the margin [Schapire et ai, 
                                                               [2000|. 
       1998] increases the performances, 
   • it allows some reasons for robustness to overfitting to   The simplest version of AdaBoost [Freund & Schapire, 
       be conjectured.                                         1997] deals with binary classification problems, and this 
The article is organized as follows: in Section 2 we           is the one we refer to. AdaBoost maintains a weight dis•
briefly review Bagging and AdaBoost algorithms, and in         tribution over the training examples, and adjusts it at 
Section 3 we introduce basic terminology and results           each iteration. The adjusted weights are chosen so that 


LEARNING                                                                                                              499 higher values are associated to previously misclassified                 Definition 3 - A Monte Carlo algorithm is p-correct if 
examples. As a main effect, the weighting scheme forces                  the probability that it gives a correct answer to is at 
A to focus on "more difficult" examples, ensuring thus                   least p, independently of the specific problem instance n 
that all the examples will be, sooner or later, taken into               considered. 
account by the weak learner. The hypothesis combination 
                                                                         The great interest in Monte Carlo algorithms resides in 
rule is a weighted majority vote that puts more weight on 
                                                                         their amplification ability: given a problem instance 
successful hypotheses (i.e., hypotheses that incur a low 
                                                                         and a Monte Carlo algorithm A/C, if MC is run multiple 
weighted training error). 
                                                                         times on and the majority answer is taken as the result, 
                                                                         then, under mild assumptions, the probability of a correct 
Despite its apparent simplicity AdaBoost solves a diffi•
                                                                         answer exponentially increases. The conditions arc that 
cult problem: choosing example and hypothesis weights 
                                                                         MC must be consistent for and that p must be greater 
in such a way to ensure an exponential decrease in the 
                                                                         than random guess. We note that, whenever reduces 
training error committed by the boosted committee. 
                                                                         to a mapping from to Y (instead of 2 ), the algorithm 
Moreover, the choice is made without any knowledge or 
                                                                         is consistent. Let us denote by the algorithm ob•
assumption on the weak learner itself (except that the 
                                                                         tained by combining with a majority vote the answers 
weak learner is always able to outperform random 
                                                                         given by multiple runs of a Monte Carlo MC. 
guessing). In contrast, Bagging only works when "be•
nign" weak learners are used. On the other hand, 
AdaBoost seems to be more sensitive to noise than Bag•                   4 Complete Information Case 
ging [Quinlan, 1996].                                                    In this section we provide a theoretical account of the 
                                                                         links between Monte Carlo theory and bagging or boost•
As mentioned earlier, AdaBoost shows the characteristic                  ing, in the case we have complete information on the 
of being robust with respect to ovcrfitti.ig [Schapire et                learning/classification problem. More precisely, let X be 

al., 1998; Drucker & Cortes, 1996; Quinlan, 1996; Bre-                   a finite set of examples1, a target concept (binary clas•
iman, 1998; Freund & Schapire, 1998]. A rather con•                      sification), A a (weak) learner. and w be a 
vincing account of this behavior imputes to AdaBoost                     probability distribution over X. Let moreover be the 
the ability to be very successful in increasing the final                power set of X. Any intensional concept description, be•
classifier's margin over the training examples [Schapire                 longing to a given language will be mapped to an 
etal, 1998].                                                             element i)» of . , i.e., is the set of examples classified 
                                                                         by that description as belonging to co. In this way, we can 
In the effort of understanding and/or explaining                         reduce ourselves to a finite set of (extensional) hypothe•
AdaBoosfs behavior, boosting has been related to other                   ses. Let be any subset of .A prob•
existing theories, such as Game Theory [Schapire, 2001],                 ability distribution q is associated to the elements of 
logistic regression [Friedman et al., 1998; Collins et al.,                . The set 'can be thought of as the collection of the 
2000), optimization [Ratsch et al., 2002], and Brownian                  hypotheses generated by a learning algorithm A applied 
motion [Freund, 1995].                                                   to a number of training sets, or a set of hypotheses pro•
                                                                         vided by an oracle. Learning can then be simulated by 
3 Monte Carlo Algorithms                                                 extracting with replacement elements from according 
                                                                         to q (each extraction corresponds to a run of 
In this section we recall some basic notions from Monte 
                                                                         A on some training set). 
Carlo algorithms theory. In the literature, the name 
Monte Carlo often denotes a generic stochastic algo•
                                                                         Let us represent the described situation by means of Ta•
rithm; in this paper we will refer to the more restrictive 
                                                                         ble 1. Here, let be the probability that hy•
definition given by Brassard and Bratley [1988]. Let 
                                                                         pothesis correctly classifies examplebe 
be a class of problems, Y a finite set of answers for the 
                                                                         the average of such probabilities for be the ac•
problems in and be a function that maps 
                                                                         curacy of hypothesis over the whole X. 
each problem into the set of its correct answers. 
                                                                         By using the given probability distributions, we can 
Definition / - A stochastic algorithm A, mapping into                    compute the average accuracy for the whole table: 
Y, is said to be a Monte Carlo algorithm, if, when applied 
to an instance of it always terminates, providing an 
                                                                                                                                     (1) 
answer to , which may be occasionally incorrect. 

Two properties of Monte Carlo algorithms turn out to be 
relevant: 

Definition 2 - A Monte Carlo algorithm is consistent if it 
never outputs two distinct correct answers when run two 
times on the same problem instance                                             The finiteness of X is not essential; it is only assumed for 
                                                                             the sake of simplicity. 

                                                                             2 This assumption implies that the Bayes error is zero. 


500                                                                                                                             LEARNING                    Table 1 - Theoretical setting                         Condition (2) is true as long as the Bayes error is zero. 
                                                                         Condition (3) may or may not be true, depending on the 
                                                                         set 

                                                                         Let be the set of examples for which Ac•
                                                                         cording to the Monte Carlo theory, all these examples 
                                                                         will be "amplified", i.e., they will be correctly classified 
                                                                         in the limit . The application of to all 
                                                                         the rows yields an asymptotic accuracy: 
                                                                                                                                     (2) 

                                                                         By denoting by pT the expected Monte Carlo accuracy 
Given a subset Z of X, the measure of Z w.r.t. w, 
                                                                         when only a finite number T of extractions is performed, 
i.e.: 
                                                                         we obtain: 
                                                                                                                                     (3) 
Analogously, if , we define:                                             Let now be the set of hypotheses whose accuracy is 
                                                                         greater than The value 
                                                                                                                                     (4) 
Clearly the measures and reduce to and is the probability that a hypothesis "better" than bag•
       , respectively, if q and w are uniform distributions.             ging is obtained in a single extraction. Then, in an infi•
                                                                         nite number of trials, such a hypothesis will occur with a 
4.1 Monte Carlo and Bagging                                              frequency It is clear that, in the limit, Bagging is 
                                                                         surely convenient only when when because, in 
We will now establish a link between Monte Carlo algo•
                                                                         this case, there is no single hypothesis better than Bag•
rithms and Bagging. Let L         be a training set, and T an 
                                0                                        ging. When a better hypothesis will surely ap•
integer; let I be a generic bootstrap replicate of L           . In 
                                                              0          pear, soon or later. The interesting case, however, occurs 
this case, is the set of all the different hypotheses that 
                                                                         when only a finite number T of extractions is performed. 
can be obtained by applying A to . replicates. The 
                                                                         Before approaching this case, let us make some consid•
frequencies with which each is generated determine q. 
                                                                         erations on what has been described so far. 

If we look at Table 1, Bagging proceeds, so to say, by 
                                                                         Let us first notice that ensemble learning claims that am•
columns, by extracting T columns from and using them 
                                                                         plification occurs when the r        (accuracy of each of the 
to obtain a majority vote on each Considering the                                                            j
                                                                         combined hypotheses) are greater than 1/2 (condition on 
global average accuracy r, or even the exact distribution 
                                                                         the columns). Actually it may not be the case. What is 
of the r  it is not easy to say how many of the will be 
         j                                                               really required is that, for each example , more than 1/2 
correctly classified by the majority voting procedure, 
                                                                         of the learned hypotheses are correct on it (condition on 
and, then, whether to perform Bagging will be rewarding. 
                                                                         the rows). Then, Monte Carlo Theory suggests that Bag•
It is generally said [Breiman, 1996] that bagging is useful 
                                                                         ging would be successful when it is possible to find a 
when A is "unstable". We will show later that this notion 
                                                                         subset of such that . Before looking with more 
of "instability" can be made more precise. 
                                                                         details into the relationship between the rjs and the 
                                                                                  let us consider some extreme cases. 
Let us consider now a Monte Carlo interpretation of Ta•
ble 1. To the contrary of Bagging, a Monte Carlo algo•
                                                                         Let A be a weak learner that always returns the same hy•
rithm , proceeds by rows: for each(problem to be 
                                                                         pothesis regardless of the training set. The lucky 
solved), it extracts T hypotheses from and classifies 
                                                                         situation in which that single hypothesis is quite accu•
x  by majority voting. This process is repeated for each 
 k                                                                       rate over the training set docs not imply anything about 
row . This procedure is necessary, because the compo•
                                                                         the occurrence of Monte Carlo amplification. In fact, all 
nents of the Monte Carlo voting must be independent, but 
                                                                         the are equal to 1 on those examples which arc cor•
the entries in each column are not. Monte Carlo theory 
                                                                         rectly classified by and 0 otherwise. In other words, 
tells us that the correctness of can be amplified 
                                                                         whatever the accuracy of no amplification at all oc•
if: 
                                                                         curs. This is an example of a perfectly stable learner. 
   1. The T trials are independent 
   2. MC is consistent                                                   Let us consider a situation in which the global average r 
   3.                                                                    of the accuracy is a little more than 1/2. This value is at 
                                                                         the same time the average of the last column and on the 
Condition (1) is true by construction of the process (ex•
                                                                         last row in Table 1, according to (1). For the sake of il•
traction with replacement of T hypotheses for each row). 
                                                                         lustration, let q and w be uniform distributions. Let us 
                                                                        consider the following three extreme situations (a de-

     3 Let us set apart, for the moment, the computational issues. 


LEARNING                                                                                                                                501 tailed analysis of several other interesting cases is pro•     r = 1/2, and , so that no amplification is possible. 
vided by Esposito [2003]) :                                    This means that the learning procedure was not able to 
 (a) The in the last column are distributed in such            make any useful selection inside the hypothesis space. 
      a way that one half of the examples have val•            On the contrary, we would like that the weak learner has 
      ues close to one, and one half of the examples have      the nice property of focusing on the best hypotheses. In 

            values close to zero. The rjs in the last row,     the previous section we showed that the basic Monte 
      on the contrary, have all almost the same value          Carlo approach, implemented by Bagging, may fail due 
      around 1/2. (All hypotheses show the same per•           to a number of reasons; this happens, for instance, in the 
      formances and they cover almost the same exam•           cases (a) and (b) of Section 4.1. Even if not explicitly 
      ples)                                                    stated, the underling problem is that the weak learner 
 (b) The in the last column have all almost the                may not be suited enough for this kind of procedure. The 

      same value around 1/2, whereas the rjs in the last       question we arc now trying to investigate is what to do 
      row have, for one half, values close to one, and for     when such a situation occurs, in particular when we do 
      the other half close to zero. (Some hypotheses are       not want or can modify the weak learner. Then, is it pos•
      very good and other are very bad, but their coverage     sible to convert case (a) or (b) into case (c)? Or, said in 
      is uniformly distributed on the examples).               other words, is it possible to convert a learning problem 
 (c) Both distributions are uniformly valued around 1/2        in which the Monte Carlo assumptions for amplification 
      (All the hypotheses are uncertain on all examples).      do not hold into one in which they do? 

In case (a) half of the examples arc amplifiable, but Bag•     The solution to this problem can be found by thinking 
ging is not useful, because any single hypothesis classi•      again of the role of the weak learner in the Monte Carlo 
fies correctly half of the examples, so that nothing can be    process. As mentioned earlier, the learner has the duty to 
gained by the Bagging process.                                 modify the distribution from which the hypotheses are 
In case (b), the number of amplifiable examples depends        drawn (i.e., the qj of the columns) in such a way that 
on how many of them have actually values a little over         fctbctter" hypotheses are more likely to be drawn. Moreo•
1/2. But, even in the best case , Bag•                         ver, we can actually change the behavior of the weak 
ging is again not convenient. In fact, half of the single      learner through its input, i.e., by modifying the training 
hypotheses have r, = 1; then, in one over two extractions      set. In particular, we have to force the weak learner to 
(on average) a perfect hypothesis is extracted.                extract hypotheses that make the minimum value of the 
In case (c), if the values in the last columns arc all a       p(xij 's grow larger than 1/2 (in order to satisfy the Monte 
little greater than 1/2, then This is the case in              Carlo conditions of amplifiability for all the examples). 
which Bagging is convenient, because the single hy•            Since the weak learner is influenced by the training set, 
pothesis have all accuracy close to 1/2. Actually, case (c)    the solution is to modify the training set in such a way 
is the ideal case for Bagging, because amplification can       that examples with low values arc more represented, 
be obtained with the minimum effort (with "bad" hy•            in the attempt to make the weak learner try harder to be 
potheses we may obtain a large amplification).                 successful on them. What we obtain with this reasoning 
                                                               is an AdaBoost-like algorithm. In other words, when the 
The following theorem summarizes the above consid•             weak learner is unable to satisfy Monte Carlo conditions 
erations and establishes a link between Bagging and            for amplification, AdaBoost forces it to satisfy them by 
Monte Carlo amplification (proof is provided by Esposito       weighting the examples. More precisely, AdaBost tries to 
[2003]):                                                       increase the minimum with the unconscious goal of 
                                                               extending . In fact, when the weak learner satisfies 
Theorem 1 - The amplified accuracy p cannot be 
                                                               relatively mild conditions, it has been shown by Schapire 
greater than 2r, where r is the average accuracy of the 
                                                               et al. [1998] that AdaBoost is actually effective in in•
bagged hypotheses. 
                                                               creasing the minimal margin: 
Then, even by bagging single hypotheses with accuracy          Definition 4 - For any particular example the classifi•
less then 1/2 it is possible to obtain higher accuracies by    cation margin ~ is the difference between the 
Monte Carlo amplification. However, in order to reach p^       weight assigned to the correct label and the maximal 
= 1, the value of r must be at least 1/2. Even in this case,   weight assigned to any single incorrect label. 
some of the combined hypotheses are allowed to have a 
                                                               In the case of binary classification, the margin is the dif•
accuracy less than 1/2, without hindering amplification, 
                                                               ference between the weight assigned to the correct label 
provided that and that r does not go below 112. 
                                                               and the weight assigned to the incorrect one. 
                                                               Theorem 2 - In the case of binary classification, the fol•
4.2 Monte Carlo and AdaBoost                                   lowing relation holds between the margin and the Monte 
Let us notice that, if the set of hypotheses coincides         Carlo 
with the power set 2    (all possible hypotheses are con•
                      X                                                                                            (7) 
sidered), we are in the situation in which all 


502                                                                                                           LEARNING The proof of Theorem 2 derives immediately from the                      is an unbiased estimate of the Bernoulli probability p(x/). 
definition of margin and . Formula (7) explains why                      Even though the T hypotheses generated are only used to 

increasing the margin improves the performances of                       classify X1, and could then be discarded, nothing hinders 
boosting: in fact, increasing the minimum margin lets the                from recording them in the first T (or less, if there is du•
cardinality of the set increase, augmenting the number                   plication) columns of Table 1. When we consider jr?, we 
of examples for which the Monte Carlo conditions for                     repeat the whole procedure, running again A on T new 

amplifiability hold.                                                    replicates of L0 and classifying x2 Again we record the 
                                                                        new generated hypotheses (or update the probability dis•
4.3 Non-Asymptotic Case                                                 tribution q in case of repetitions). When we finish exam•
Let us consider a finite integer T. Let denote the prob•                 ining L0, we have also filled the part of the table corre•
ability that a hypothesis "better" than Bagging is ob•                  sponding to the test set, which allows estimates for 
tained in R extractions. In order to compare Bagging with               the examples in the test set to be computed. Each is 
hypothesis selection, let us consider a classification accu•            based on T M experimental values, which is the number 
racy Given Table 1, and given a number close to 0,                      of runs necessary to estimate the generalization accuracy 
let be the minimum number of components of the                          using the leave-one-out method on a number M of train•
bagged hypothesis such that:                                             ing examples. 

                                                            (8)         What is interesting is that, during learning, we also learn 
If then probability (8) is zero.                                        whether it is convenient or not to exploit Bagging for 
                                                                        classifying future unseen examples. It also turns out, ex•
Analogously, let be the set of hypotheses with rj > a 
and R(a) be the minimum number of hypothesis extrac•                    perimentally, that a much lower number of runs than 
tions such that:                                                         T-M is very often sufficient to obtain a stable estimate of 
                                                                        the sought probabilities. 
                                                            (9) 
                                                                        5.1 AdaBoost's generalization behavior 
Again, if probability (9) is zero. 
                                                                        In this section we discuss AdaBoost's generalization ca•
We can draw a graph of T (ordinate) vs. R (abscissa),                   pabilities and their interpretation in the Monte Carlo 
parameterized by The graph is problem dependent.                         framework. Having related the margin of an example 
What we can say in general is that points in the graph                  with the average probability that it is correctly classified 
above the diagonal correspond to situation for which se•                by the hypotheses learned via the weak learner allows us 
lection is better than Bagging (for the same accuracy ex,               to transfer results provided by Schapire et al. [1998] to 
Bagging requires more trials), points below the diagonal                the Monte Carlo framework. Interestingly enough, the 
correspond to situation for which selection is worse than               link may be used to give a new, more intuitive, interpre•
Bagging (for the same accuracy Bagging requires less                    tation of the margin explanation of AdaBoost's generali•
trials), and points on the diagonal correspond to situa•                zation capabilities. Moreover a nice explanation of why 
tions of indifference.                                                  the test error is often observed to decrease even after the 
                                                                        training error reaches zero can be suggested. 
5 Problems with Partial Information 
                                                                        To understand how generalization error can be inter•
The setting discussed in Section 4 is useful for under•                 preted in the Monte Carlo framework it is necessary to 
standing the functioning of ensemble learning, but we                   deepen a little the discussion about the link between en•
need to extend it to the case of real learning problems. In             semble learning and Monte Carlo algorithms. Let us 
concrete situation, neither the set nor the example                     choose the randomization procedure (whatever it is). 
space X is available a priori. What we have is a training               Once this is done, the choice of the weak learner deter•
set and a test set To, both subsets of X, and a                         mines the distribution of the . In other words, 
learning algorithm A for generating hypotheses. We learn                when the two major parameters of the ensemble algo•
hypotheses, possibly consistent with L(), and estimate the              rithm are fixed, we can think of as a theoretical 
generalization error on                                                 property of the examples. 
                                                                        Once the ensemble process starts, we compute the esti•
If we consider the problem from the Monte Carlo per•                    mations The accuracy of the estimates increases 
spective and we go back to Table 1, we can think to pro•                with the number of iterations performed. Whether the 
ceed as follows. At the beginning we have, on the rows,                 final rule will classify correctly or not any example, is a 
the training and the test examples, but the columns are                 matter of two things: the value of the underlying exact 
empty. Let us consider the first example Let A 

run on T replicates of L0 and let us compute which 


                                                                             5 The datasets used, as well as part of the experimental results, 
     4                                                                       can be found at the URL: 
      In this paper we do not consider to use cross-validation or 
                                                                                 http://www.di. unito.it/~csposito/mcandboost 
     leavc-onc-out. 


LEARNING                                                                                                                               503 