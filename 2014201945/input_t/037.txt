            Solving Constraint Optimization Problems in Anytime Contexts 

                       Samir Loudni                              Patrice Boizumault 
                 Ecole des Mines de Nantes         GREYC, CNRS UMR 6072, Universite de Caen 
             F-44307 Nantes Cedex 3 - France                F-14032 Caen Cedex - France 
                    samir.loudni@emn.fr                   patrice.boizumault@info.unicaen.fr 


                     Abstract                            Section 2 describes the general context in which we take 
                                                       place. Section 3 reviews the hybridization of search algo•
    This paper presents a new hybrid method for solv•  rithms and justifies our first choices. Section 4 details our 
    ing constraint optimization problems in anytime    proposal (VNS/LDS+CP). Section 5, gives computational ex•
    contexts. Discrete optimization problems are mod•  periments on CELAR benchmarks ; both mechanisms of 
    elled as Valued CSP. Our method (VNS/LDS+CP)       VNS/LDS+CP are then finely studied. Section 6 shows how 
    combines a Variable Neighborhood Search and        VNS/LDS+CP has been successfully applied to solve a diffi•
    Limited Discrepancy Search with Constraint Prop•   cult network problem. Finally, we conclude and draw a few 
    agation to efficiently guide the search. Experiments perspectives. 
    on the CELAR benchmarks demonstrate signifi•
    cant improvements over other competing methods.    2 Anytime constraint optimization context 
    VNS/LDS+CP has been successfully applied to 
    solve a real-life anytime resource allocation prob• 2.1 Anytime algorithms 
    lem in computer networks.                          The term anytime algorithm was coined by Dean and Boddy 
                                                       in the mid-1980s in the context of their work on time-
                                                       dependent planning [Boddy and Dean, 1994]. Contrary to a 
1 Introduction 
                                                       standard algorithm, where no result is available until its end•
It is today indisputable that Constraint Programming (CP) ing, an anytime algorithm can be stopped, at any time, to pro•
fulfills industrial needs of optimization off-line. Many sys• vide a solution of increasing quality over time. 
tems which use this technology are already operational in Performance profiles describe the evolution of the solution 
different fields of activity, such as planning, scheduling and quality (produced by the algorithm) as a function of the com•
resource allocation. In on-line optimization context, prob• putation time. They provide a more precise description of the 
lems dynamically change according to the evolution of the performances and of the behavior of an algorithm than the 
external environment, and their resolution must respect strong best known solution reported by usual algorithms. In the se•
temporal constraints (anytime contexts). However, CP is not quel of this paper, we consider mean performance profiles : 
yet adapted for solving such on-line problems : no guaran• such curves are built empirically by collecting statistics on 
tee is supplied on the execution times, and current CP solvers the performance of the algorithm over many input instances. 
do not lend themselves to the combination with other search There are two kinds of anytime algorithms, namely, in-
methods which seem better adapted to respect temporal con• terruptible and contract algorithms [Zilberstein, 1996]. A 
straints, such as stochastic search methods.           contract algorithm requires that the computing time must be 
  Our objective is to conceive anytime algorithms based on known prior to its activation. It must produce a solution 
CP and to guarantee the following main properties : to pro• within a contract of time, and if it is interrupted before the 
duce in a very short time solutions of good quality, and more end of the contract, there is no guarantee about the quality 
importantly to improve them gradually as computation time of the solution. However, for an interruptible algorithm, no 
increases. To our knowledge, our proposal is one of the first information is (a priory) available about the allowed compu•
attempt to efficiently address the problem of building anytime tation time, and a solution may be asked for at any time. The 
algorithms with Constraint Programming.                algorithm must always provide a good solution, and more im•
  This paper presents a new hybrid method, called      portantly, continue to refine it. 
VNS/LDS+CP, dedicated to the efficient computation of high In this paper we are interested by the design of interruptible 
quality solutions (possibly suboptimal) in an anytime con• algorithms, since every interruptible algorithm is trivially a 
text. Our method combines a Variable Neighborhood Search contract algorithm, but the converse is not so immediate. 
[Hansen and Mladenovic, 1997] (it performs moves like local 
search), and a Limited Discrepancy Search [Harvey and Gins• 2.2 Valued Constraint Satisfaction Problems 
berg, 1995] with Constraint Propagation to efficiently guide The Valued CSP (VCSP) [Bistarelli et al., 1999; Schiex et al., 
the search.                                            1995] framework is an extension of the CSP (Constraint Satis-


CONSTRAINTS                                                                                            251 faction Problem) framework, which allows over-constrained 
 problems or preferences between solutions to be dealt with. 
   More formally, whereas a CSP is defined as a triplet 
 (V, V, C), where V is a set of variables, V a set of finite 
 domains associated to the variables and C a set of constraints 
 between the variables, a VCSP can be defined as a CSP pro•
 vided with a valuation structure S and a valuation function 
    The valuation structure S is a triplet (E, , where 
 £ is a valuation set, a total order on E, and the maxi•
 mum and the minimum element in E and _ a binary operation 
 closed on E. The valuation function defined from C to E, 
 associates a valuation to each constraint; the valuation of a 
 constraint denotes its importance. 
   Let A be an assignment of all the variables and 
 be the set of the constraints unsatisfied by A. The valuation   Intertwined hybridizations are the most attractive and rel•
 of A is the aggregation of the valuation of all the constraints evant hybridizations of algorithms where both complete and 
 in                                                            local search are closely mingled during computation. The 
   The objective is to find a complete assignment with mini•   first kind of such hybrid algorithms belongs to the family of 
 mum valuation. Specific frameworks depend on the retained     local search methods and uses ideas from CP in order to make 
 operator Classical CSP (A); Possibilistic CSP (max); Lexi•    large neighborhoods (LNS [Shaw, 1998]) more tractable. A 
 cographic CSP (U on multi-sets); Weighted CSP . As many       second kind belongs to the family of exact search and uses 
 real-life problems use an additive criterion, we only consider some local search principles to improve the partial solutions 
 weighted CSP (WCSP) in the sequel of this paper. From an      at each node of the search tree [Prestwich, 2000] or to ex•
 algorithmic point of view, WCSPS are generally the most dif•  plore a set of solutions close to the greedy path in a search 
 ficult to solve [Schiex et al., 1995].                        tree [Caseau et al, 1999]. 

                                                               3.3 Hybrid algorithms for anytime contexts 
3 Hybridizations of algorithms 
                                                               VNS/LDS+CP is an Intertwined hybridization algorithm. 
3.1 Complete search vs local search                            From local search, we have retained a Variable Neighborhood 
Exact (or complete) tree search methods, such as Branch and    Search (VNS) which extends the principle of large neigh•
Bound, are able to produce both an optimal solution, and a     borhoods (LNS) by dynamically adjusting the neighborhood 
proof of optimality. But, because of their exponential worst-  size, when the current solution is a local optimum. This 
case behavior, they may be extremely time consuming. More•     choice will partially remedy to the weaknesses of pure lo•
over, it has been experimentally observed that, due to their   cal search methods. Indeed, the more the neighborhood is 
systematic way of exploring the search space, the quality of   potentially large the more there are chances that it contains 
their intermediate solutions is usually very poor.             good solutions and thus improves quickly the current solu•
   Due to their opportunistic way of exploring the search      tion. However, as neighborhoods grow larger, finding the 
space, approximate (or incomplete) methods, based on           best neighbor may require a too expensive computational ef•
stochastic local search (as Simulated Annealing, Tabu          fort. So, we have selected the LDS partial search combined 
Search), can provide good solutions within a reasonable com•   with constraint propagation (lower bounds computation) to 
puting time. But, such methods do not guide fast enough the    efficiently explore these neighborhoods. 
search towards the best neighbor solutions. Indeed, they may 
waste a lot of time trying to improve the current solution with 4 The VNS/LDS+CP Method 
no success ; this is the case when they remain blocked in local 
                                                               VNS/LDS+CP is basically a local search method, as depicted 
minima during a prohibitive time. Such situation is not suit•
                                                               in algorithm 1. It differs from classic local search methods by 
able in an anytime context, since the quality of solutions has 
                                                               the size of the neighborhoods, which is adjusted dynamically 
to be improved gradually as fast as possible, as the comput•
                                                               during the search. It starts with an initial complete assignment 
ing time increases. Moreover, pure local search algorithms 
                                                               .s*; then, at each move, it relaxes (or unassigns variables) a 
generally require a lot of time to adjust their noise parame•
                                                               large part of the current solution s and then rebuilds it (re•
ters ; their efficiency strongly depends on the value of these 
                                                               assigns variables) by selecting the best neighbor that strictly 
parameters, which are generally application-dependent. 
                                                               improves the cost of the current solution. The algorithm ends 
                                                               when the maximum number of local moves (MAXMOVHS) is 
3.2 Hybrid algorithms 
                                                               reached. 
Hybrid algorithms [Focacci et al, ] provide appropriate com•     LDS explores the neighborhood defined by the relaxed part 
promises between both kinds of search. More precisely, they    of the solution. It benefits from constraint propagation based 
are very efficient by combining the advantages of both con-    on lower bounds computation, and on dynamic heuristics for 
straint propagation (complete search) and opportunistic ex•    variable and value ordering. Moreover, only judicious neigh•
ploration of the search space (local search).                 borhoods, related to conflict variables (i.e. variables occur-


252                                                                                                      CONSTRAINTS                                                               ploration of the search tree, and speeds up the reconstruction 
                                                              step, thus improving the performance profile of our method. 
                                                              LDS starts from the solution computed by the value heuristic, 
                                                              and successively explores solutions by increasing the number 
                                                              of discrepancies, until the fixed maximal number of discrep•
                                                              ancies is reached. 
                                                                 We have used a generalized version of LDS for n-ary trees. 
                                                              The discrepancy is measured according to the rank of the 
                                                              value chosen for every variable in the order given by the 
                                                              heuristic on values. We count a single discrepancy for the 
                                                              second cheapest value of one variable, two discrepancies for 
                                                              either the third cheapest value of one variable, or the second 
                                                              cheapest value of two variables, and so on. We only perform 
                                                              one iteration of LDS, for a fixed discrepancy. This prevents 
                                                              re-visiting leaf nodes. 

                                                              Constraint Propagation 
                                                              One of the main strengths of our approach lies in the use of 
                                                              constraint propagation to prune useless sub-trees and to guide 
                                                              the choice of values during the reconstruction, while keeping 
                                                              this step fast enough. At each node of the search tree, lower 
                                                              bounds are computed in order to locally exclude all partial 
                                                              solutions which cannot lead to complete assignments of better 
                                                              valuation than the current best solution. To our knowledge, 
                                                              no method based on large neighborhoods (in particular VNS) 
                                                              uses such a mechanism. 
ing in violated constraints), are considered. Such a choice 
                                                                 To compute lower bounds, we have adapted the following 
prevents LDS from modifying the value of conflict variables. 
                                                              algorithms LLarrosa et al. , 1999] for wcSPs : (i) Partial For•
4.1 Relaxing a solution                                       ward Checking and Directed Arc Consistency (PFC-DAC), all 
                                                              the constraints are directed, and DAC are computed from a di•
Algorithm 2 describes how to select the variables to be re•
                                                              rected constraint graph (we have used specific data-structures 
laxed. The function of line (1) computes the set v of current 
                                                              to relax the condition of static variable ordering on DAC) ; 
variables candidate to relaxation, according to a strategy Sir. 
                                                              (ii) Reversible )zfC(PFC-RDAC), constraints directions can 
A basic strategy is to select all the variables that are in con•
                                                              change dynamically during search, looking for a good di•
flict, size elements of v are randomly chosen to constitute 
                                                              rected graph causing a high lower bound ; (iii) Maintaining 
rd the set of variables to be relaxed. This choice enables a 
                                                              Reversible DAC (PFC-MRDAC), DAC are maintained during 
balance between choosing variables according to a specific 
                                                              search, propagating the effect of value pruning. 
strategy and completely at random. Experiments have shown 
that the introduction of some randomness enables the search   Variables and Values heuristics 
to escape quickly from local minima.                          Our heuristic for variable ordering first selects the variable 
4.2 Control of the Neighborhood Size                          having the lowest ratio domain cardinality divided by future 
                                                              degree. Constraint propagation, based on Forward Checking 
Initially, the neighborhood size (size) takes a minimum value. + Directed Arc Consistency, allows us to use a dynamic min•
To control the neighborhood size, different strategies have   imum inconsistency count value ordering. During search, for 
been implemented. The best strategy we have found, in•        each value, so-called Inconsistency Counts (ic) and Directed 
creases systematically size by one, each time the method      Arc Consistency counts (dac) which record the look-ahead ef•
does not improve the cost of the current solution.            fects on future (unassigned) variables, are computed. Values 
                                                              are selected by their increasing ic + dac. 
4.3 Rebuilding a solution 
Algorithm 2 defines the function Rebuild. The global vari•
                                                              5 Experimentations on CELAR Benchmarks 
ables ub and lb record the upper and lower bounds of the prob•
lem optimum. LB(s,.r,) computes a lower bound of the sub-     5.1 Instances of CELAR 
problem, limited to the variables after i (i included), discrep 
                                                              The CELAR (French Centre d 'Electronique de I'Armement) 
sets the maximum number of choices that we can diverge 
                                                              has made available a set of 1 I instances of the Radio Link Fre•
from the heuristic (discrepancies). 
                                                              quency Assignment Problem (RLFAP) [Cabon et al., 1999]. 
Limited Discrepancy Search                                    Most of them can be naturally cast as binary WCSPS. For our 
The idea of LDS [Harvey and Ginsberg, 1995] is to explore     experiments, we have selected instance 6 (which involves 200 
heuristically good solutions that might be at a limited dis•  variables, having an average of 40 values in their domain, and 
tance from greedy solution. LDS ensures a more balanced ex•   1322 constraints), instance 7 (which involves 400 variables, 


CONSTRAINTS                                                                                                          253                                                                5.3 Setting parameters for VNS/LDS+CP 
                                                               Number of discrepancies 
having an average of 40 values in their domain, and 2866 con•
straints), and instance 6-Sub 1 (which involves 28 variables,  Figure 1 (top) shows the performance profiles obtained with 
having an average of 40 values in their domain, and 314 con•   PFC-DAC, for different settings of discrcp on instance 6. 
straints) extracted from instance 6. These instances (6 and 7) Performance profiles for discrcp - 2 and 3 are almost the 
are the most difficult ones. Whereas the optimum of instances  same. We give only the curve associated to discrcp - 3. Re•
6 and 6-Sub 1 are known (respectively 3389 and 2669), the      sults indicate, as expected, that the number of discrepancies 
optimum of instance 7 is still unknown; the best known upper   has a great impact on the quality of the computed solutions. 
bound is equal to 343592.                                      LDS with (discrcp = 4) gives the best results. The poor re•
                                                               sults for (discrcp > 4) are probably due to the fact that our 
5.2 Experimental Methodology                                   value ordering does not make so many mistakes. Indeed, we 
                                                               exploit the propagation scheme to guide the value choices. 
Our method has 4 parameters : the maximum number of local      Thus, few discrepancies are necessary to repair heuristic er•
moves (MAXMOVES), the initial neighborhood size (size),        rors. In contrast, for low discrepancies (discrcp < 3), the 
the number of discrepancies (discrcp), and the propagation    value heuristic too closely limits the solutions we can find, 
scheme. For all experiments, MAXMOVES has been set to          and so, it provides poor guidance to good solutions. For the 
150 and size to 4 ; it is the best value we have found         instance 7, discrcp = 4 is also the best value. 
among the following set of values : {2,3,4,5,6}. We car•
ried out experiments with different values of discrepancies   Propagation mechanism 
(discrcp E {2,3,4,5}) and with three different propagation    We turn now to choose the propagation scheme which pro•
mechanisms : PFC-DAC, PFC-RDAC and PFC-MRDAC.                 duces significant lower bounds and, as global effect, leads to 
  For each combination of parameter settings, we ran          a better behavior of our method. Figure 1 (bottom) reports 
VNS/LDS+CP 50 times on the considered instances. Dur•         the performance profiles obtained for the three propagation 
ing each run, the best cost of the current solution has been  algorithms, with discrep = 4 on instance 6. LDS with PFC-
recorded at regular time intervals (10 seconds). All plotted  DAC leads to very substantial profits. Because of the over•
figures are mean performance profiles over the 50 runs. The   head of propagation over small neighborhoods these bene•
methods have been implemented in choco [Laburthe, 2000].      fits decrease clearly when using stronger propagation (PFC-


254                                                                                                      CONSTRAINTS                                                               Figure 4: Comparing VNS and LNS on instance O-.6-Subl. 

                                                              5.5 Study of mechanisms VNS and LDS+CP 
                                                              In order to evaluate the contribution of each component of 
                                                              VNS/LDS+CP we have carried out experiments on instance 
                                                              6-Subl, with MAX MOVES - 150, and size = 4 ; the two other 
RDAC and PFC-MRDAC). Indeed, compared to PFC-DAC,             instances being out of reach from complete searches. Five 
the two other propagation schemes perform more work per       methods have been compared : the Depth First Branch and 
node to finally obtain results very close to PFC-DAC. So, the Bound (DFBB), LDS with only one iteration, two variants of 
more complex and time-consuming propagation schemes do        LNS (LNS/CP/GR and LNS/LDS+CP) which mainly differ 
not pay-off for this context.                                 by their reconstruction mechanism, and VNS/LDS +CP. For 
                                                              the two variants of LNS, the best percentage of unassigned 
5.4 Comparisons and discussion                                variables represents 60% of the total number of variables. 
We have compared VNS/LDS+CP (discrap = <1 with PFC-              Once again, discrcp = A constitutes the best parameter 
DAC) with LNS/CP/GR [Lobjois et al, 2000], another hybrid     setting for VNS/LDS+CP. The behavior of VNS/LDS+CP is 
method which also relies on solving VCSPs in an interruptible quite similar to those observed on instances 6 and 7, which 
context, and also with two standard versions of Simulated-    clearly offers better performance profiles than the other com•
Annealing (SA) : Quick and Medium.                            peting methods. On this instance, VNS/LDS+CP almost finds 
   LNS/CP/GR is based on the principle of LNS with neigh•     the optimum in a very short time at each run. We can draw 
borhood size being constant during all the search. To rebuild some remarks : 
the relaxed variables, it uses a greedy algorithm combined       • pure LDS (or only one iteration of LDS) is completely 
with constraint propagation. But this propagation (performed       inefficient in an anytime context, even if LDS leads to 
variable per variable) is only used for selecting the best val•    better performance profiles than DFBB. 
ues for each variable, which is fundamentally different from     • the efficiency of VNS/LDS+CP is certainly partly due 
our CP based on usual propagation for WCSP. For instances 6        to the reconstruction mechanism. Indeed, the compar•
and 7, the percentage of unassigned variables represents 40%       ison between performance profiles of LNS/CP/GR and 
of the total number of variables [Lobjois et a/., 2000].           LNS/LDS+CP show that, with an effective propagation 
   Figure 2 compares the performances of the four methods.         (lower bounds computation) combined with LDS, LNS 
The performance profile of VNS/LDS+CP is always better             obtains a gain in quality of 7% after 20 seconds. 
than those of the two versions of SA. At the beginning, the 
profile of VNS/LDS CP is very close to that of LNS/CP/GR.        • the use of variable size neighborhoods is a key point 
But after few seconds of computation (< 20 seconds on in•          in the efficiency of VNS/LDS+CP. Indeed, it produces 
                                                                   better performance profiles than LNS/LDS+CP. After 2 
stance 6 and < 35 seconds on instance 7), VNS/LDS+CP 
                                                                   seconds, VNS obtains a gain in quality of 9% ; this gain 
becomes very effective and always provides solutions of bet•
                                                                   reaches a value of 5% after 15 seconds. This amelio•
ter quality, thus clearly outperforming LNS/CP/GR on both 
                                                                   ration comes from the speed of the exploration of rela•
instances. This behavior can be explained by the fact that, 
                                                                   tively small neighborhoods (in particular during the first 
at the beginning, the size of the neighborhood is relatively 
                                                                   moves of VNS). This greatly improves the quality of the 
small and consequently the benefits of constraint propaga•
                                                                   computed upper bound which will enable a better prun•
tion are poor. But as soon as this size becomes sufficiently 
                                                                   ing at the next reconstruction step. This is not the case 
large, our propagation mechanism (lower bounds computa•
                                                                   for LNS, which needs much more time to obtain good 
tion) produces more pruning, and becomes very effective. 
                                                                   upper bounds, due to the important size of the neighbor•
This leads to a better compromise between quality and time 
                                                                   hoods. 
for VNS/LDS+CP. This confirms our choice for computing 
significant lower bounds. Note however, the good anytime         To evaluate the improvement speed of the quality of 
behavior of LNS/CP/GR compared with those of SA.              solutions provided by VNS and LNS, figure 4 compares 


CONSTRAINTS                                                                                                          255 