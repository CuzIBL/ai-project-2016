              SegGen: a Genetic Algorithm for Linear Text Segmentation

                           S.Lamprier, T.Amghar, B.Levrat and F.Saubion
                                      LERIA, Universit´e d’Angers
                                 2, Bd Lavoisier 49045 Angers (France)
                         {lamprier,amghar,levrat,saubion}@info.univ-angers.fr


                    Abstract                          ations in ﬁxed size windows and thus create boundaries in the
                                                      text where the local cohesion is the lowest.
    This paper describes SegGen, a new algorithm for    In this paper, we introduce SegGen a genetic algorithm to
    linear text segmentation on general corpuses. It  achieve a statistical linear segmentation of texts. Section 2
    aims to segment texts into thematic homogeneous   presents the main motivations of our work. Our segmentation
    parts. Several existing methods have been used    algorithm is described in section 3. Then, section 4 describes
    for this purpose, based on a sequential creation of an experimental study of the algorithm in order to tune its pa-
    boundaries. Here, we propose to consider bound-   rameters. Finally, section 5 evaluates SegGen by comparing
    aries simultaneously thanks to a genetic algorithm. it with other segmentation systems.
    SegGen uses two criteria: maximization of the in-
    ternal cohesion of the formed segments and min-
    imization of the similarity of the adjacent seg-  2   Motivations and Preliminary Works
    ments. First experimental results are promising and In most of existing segmentation approaches, the relation-
    SegGen appears to be very competitive compared    ships between sentences are usually very local. For exam-
    with existing methods.                            ple, the methods addressing segmentation by means of lex-
                                                      ical chains1 mainly use the repetitions of the terms in order
                                                      to deﬁne thematic boundaries. More precisely, these meth-
1  Introduction                                       ods cut the texts where the number of lexical chains is mini-
The purpose of automatic text segmentation is to identify the mal. Nevertheless, the context of these multiple occurrences
most important thematic breaks in a document in order to is not addressed neither the signiﬁcance of simultaneous lex-
                                                      ical chains at a given position in the text.
cut it into homogeneous units, disconnected from other ad-
jacent parts [Salton et al., 1996]. More precisely, segmen- According to the preceding remark, we attempted to pro-
tation partitions a text by determining boundaries between pose an alternative approach to the segmentation of texts by
contiguous segments related to different topics, deﬁning so taking into account a more complete view of the texts. In
                                                      [          ]
semantically coherent parts of text that are sufﬁciently large Bellot, 2000 , P. Bellot has shown that there exists a strong
to expose some aspect of a given subject. Thematic segmen- relationship between clustering and text segmentation. His
tation of texts can also be seen as a grouping process of basic hypothesis states that it is possible to set a boundary between
units (words, sentences, paragraphs...) in order to highlight two adjacent sentences belonging to two different semantic
local semantical coherences [Kozima, 1993]. The granularity classes. This assumption seems too strong since text segmen-
level of the segmentation depends on the size of the units. tation not only depends on the similarity of the sentences, but
                                                      must also consider their layout in the text. Indeed, discourse
  The increasing interest in text segmentation is mainly ex-
                                                      structures of documents may be very diverse and a part of a
plained by the number of its applications such as text align-
                                                      text related to a particular topic may contain sentences de-
ment, document summarization, information extraction, or
                                                      viating somewhat from it. These sentences are likely to be
information retrieval [Baeza-Yates and Ribeiro-Neto, 1999].
                                                      classiﬁed differently from their neighbors. However, this cer-
Text segmentation can be indeed very useful for these tasks
                                                      tainly does not imply that a boundary has necessarily to be
by providing the structure of a document in terms of the dif-
                                                      set there. Moreover, this assumption is too dependent on the
ferent topics it covers [McDonald and Chen, 2002].
                                                      chosen clustering mechanism, no existing clustering method
  Many segmentation methods have been proposed and we
                                                      being fully reliable.
focus here on the most general and signiﬁcant methods that
                                            [
rely on statistical approaches such as Text Tiling Hearst, 1Lexical chains are formed between two occurrences of a same
1997],C99[Choi, 2000], DotPlotting [Reynar, 2000] or Seg- term [Galley et al., 2003][Utiyama and Isahara, 2001] and occa-
menter [Kan et al., 1998]. These methods perform an analysis sionally between synonyms and terms having statistical associations
of the distribution of the words in the text, in order to deter- such as generalization/specialization or part-whole/whole-part rela-
mine the thematic changes by means of lexical inventory vari- tionships [Morris and Hirst, 1991]

                                                IJCAI-07
                                                  1647  However, we were convinced that a preliminary cluster- teria to optimize: the internal cohesion of the segments and
ing could provide a more complete view of the sentences the dissimilarity between adjacent ones. As usual for multi-
relations. Therefore, we have deﬁned a ﬁrst segmentation objective problems, these two criteria are negatively corre-
method, called ClassStruggle, that uses an initial clustering lated. Indeed, the internal cohesion tends to increase with
of the sentences of the text based on their similarity, in or- the number of boundaries whereas the dissimilarity between
der to have a global view on their semantic relations. In this adjacent segments tends to decrease with it. Following the
approach, the resulting clusters evolve by taking into account multi-objective optimization principles, we consider the ob-
their proximity in the text. Considering the clusters as topics jective functions separately in order to allow our algorithm to
of the text, ClassStruggle performs a linear traversal of the preserve enough diversity in the search process and to extract
document in order to determine the most appropriate class good segmentation proposals.
assignment for each sentence, depending on their context of Our SegGen algorithm is a variant of the ”Strength Pareto
occurrence. This process goes on as long as modiﬁcations Evolutionary Algorithm” (SPEA) [Zitzler, 1999], an elitist al-
occur in the clusters. Finally, boundaries are created between gorithm for multi-objective problems. The method uses an
sentences belonging to different classes. Due to a lack of external archive P¯ to memorize the non-dominated2 individ-
space, ClassStruggle cannot be fully described but is never- uals w.r.t. both criteria and a current population Pt. Indi-
theless used for the evaluation of SegGen (section 5). viduals are selected from these two populations in order to
  According to the deﬁnition of text segmentation by Salton generate new individuals thanks to genetic operators. These
[Salton et al., 1996], the internal cohesion of the segments new individuals constitute the next Pt and are used to update
and their semantical proximity with their neighborhood con- P¯. P¯ constitutes, at the end of the process, a set of potential
stitute important factors of an efﬁcient segmentation method. segmentations of the text. The algorithm has then to extract
But, in the case of a sequential creation of boundaries, these an unique solution from this set (see section 3.5). All docu-
characteristics cannot be computed since, when a boundary is ments do not need the same number of generations to reach a
created, the concerned segment is not yet entirely delimited. satisfactory segmentation. Therefore, our stop criterion cor-
Therefore, sequential methods need to introduce a concept of responds to a stagnation of the population evaluation.
window in which cohesion measures can be achieved. Nev-

ertheless, it is difﬁcult to determine the size of the window:         Current Population P t

a too short window may lead the algorithm not to consider                              Archive updating
some cohesion clues and a too long one may take into ac-      Mutation
                                                           Crossing Over
                                                                                   Computation
count some repetitions of terms that should indeed not be as-                     of the fitness score
sociated, since used in different contexts.
                                                                            Selection
  From this second remark, we decided to consider an ap-
                                                                            Extraction of a Solution
proach where the boundaries are considered globally. Based Temporary Population
on an evaluation of the possible segmentation schemes, such a                            External Archive P
method would have a complete view of the text and would be
able to compute coherence without using windows. Consid-      Figure 1: General functioning of SegGen
ering the segmentation problem as a combinatorial problem,
SegGen is an evolutionary algorithm that evaluates the seg-
mentations of the whole text rather than setting boundaries
incrementally. The lack of knowledge on the structure of the Algorithm 1 Pseudo-code of the Seggen algorithm
text or on the number of segments to create, induces a huge Similarities computation and populations initialization;
search space and leads us to consider a genetic algorithm to while Stop Criterion not yet encountered do
                                                                                               ∪ ¯
cope with complexity.                                     - Fitness evaluation of each individual of Pt P ;
                                                          - Selection, Crossover, Mutation;
                                                          - Replacement of Pt by the set of new individuals;
3  SegGen: a Genetic Algorithm for Text                   - Update of P¯ w.r.t. the non-dominated individuals;
   Segmentation                                         end while
                                                                                     ¯
Inspired by the mechanisms of natural selection and evo- Selection of the best individual in P .
lution, genetic algorithms [Holland, 1975; Goldberg, 1989]
have been successfully applied to the resolution of numerous
combinatorial optimization problems. The general principle 3.1 Problem Representation
of genetic algorithms consists in managing a population of Given a text of ns sentences, the individuals are binary vec-
individuals, which represents potential conﬁgurations of the
                                                      tors x of (ns − 1) elements xi; xi =1indicates that there
problem to be solved. Genetic algorithms have been used is a boundary between sentence i and i +1. For an indi-
for several text mining purposes (such as document cluster- vidual x, we consider two evaluation criteria: C(x) ∈ [0, 1],
ing [Raghavan and Agarwal, 1987]).                    which corresponds to the internal cohesion of its segments,
  As mentioned above, text segmentation can be viewed as
ﬁnding parts of text with strong intrinsic relationships, dis- 2An individual is dominated if there exists an other individual in
connected from other adjacent parts. Therefore, we consider the populations having a better score on one criterion and at least the
text segmentation as a multi-objective problem with two cri- same score on the others.

                                                IJCAI-07
                                                  1648and D(x) ∈ [0, 1], which evaluates the dissimilarity between
its adjacent segments. Our optimization problem consists in               nbseg
                              O                                                SumSim(segi)
approximating the set of optimizers :                                      =1
                                                                  C(x)=   i                          (4)
                                                                        nbseg
                      −1               −1                                    NbCouples(seg )
    O  =   x ∈{0, 1}ns  |  ∃x ∈{0, 1}ns ,                                                i
                                           (1)                       i=1
           C(x) <C(x) ∧   D(x) <D(x)
                                                        In presence of long segments, the number of couples is
  According to this deﬁnition, the optimum is not a unique greater than if all the segments    have the same size (for exam-
                                                           n+1 +  n−1    n  + n
solution but a set of compromises, called the Pareto Front. ple, 2 2  >   2    2 ). Therefore, individuals hav-
                                                      ing a lower variance in their segment size will be preferred.
3.2  Initial Population Generation                    However, this bias is limited by the second objective function.
Initial solutions are randomly and incrementally created but, Dissimilarity Between Adjacent Segments
in order to start with an heterogeneous population, individuals The similarity of a segment w.r.t. its successor is computed
are created w.r.t. the boundaries of others. The size of the as follows:
population is determined empirically (see section 4).
  Genetic algorithms may converge easier if the individuals                            
of the initial population are closer to the optimum [Goldberg,                               Sim(sj,sk)
1989]. Therefore, we tried to insert in the population an indi-             sj ∈S(seg1) sk∈S(seg2 )
                                                       SimSeg(seg1,seg2)=
vidual created by an external segmentation method. Experi-                      |S(seg1)|×|S(seg2)|
ments w.r.t. this strategy will be described in section 5.                                            (5)
                                                        with segi being a segment, sj a sentence, S(segi) the set
3.3  Fitness Function                                 of the sentences of the segment segi and |S(segi)| the cardi-
Two criteria are used to evaluate the individuals: internal co- nality of this set. This formula allows us to deﬁne the compu-
hesion and external dissimilarity. Both use similarities be- tation of the general dissimilarity between adjacent segments
tween sentences computed beforehand. According to the vec- in an individual:
torial representation of the sentences, inspired by the vectorial
model [Baeza-Yates and Ribeiro-Neto, 1999] (i.e., a vector              nbseg−1
                                                                                                  

of weights w.r.t. the set of meaningful terms), the similar-                   SimSeg(segi,segi+1)
                                                                          =1
ity sim(s1,s2) between two sentences s1 and s2 is computed D(x)=1−       i                           (6)
with a cosine measure:                                                           nbseg − 1
                       
                          t      ×                      with nbseg being the number of segments of x and segi a
                          i=1 wi,s1 wi,s2
      Sim(s1,s2)=                            (2)   segment of this individual.
                        t  w2   ×   t  w2
                        i=1  i,s1   i=1  i,s2         Fitness of the Individuals

  where t is the number of meaningful terms, wi,sj the Following [Zitzler, 1999], the computation of the ﬁtness value
weight of the term i in the sentence sj.              of each individual is realized in two steps. A hardness value
                                                      H  is given to each individual of the external archive P¯.This
Internal Cohesion                                     value is computed according to the number of individuals of
                                                                                                 ¯
The internal cohesion of segments can be computed in two Pt (the current population) that an element x ∈ P slightly
different ways by using the sentence similarities. First, it can dominates on both objective functions:
be seen as the average internal cohesion of segments:
                                                                |{   ∈    ∧  ( ) ≥  ( ) ∧  ( ) ≥  ( )}|
                      nbseg                              ( )=   y/y Pt  C  x   C y  D  x   D y
                 1          SumSim(segi)                H  x
       C(x)=       ×                           (3)                             |Pt| +1
               nbseg       NbCouples(seg  )
                       i=1               i                                                            (7)
                                                        The ﬁtness value of an individual x ∈ P¯ is equal to the
  with nbseg being the number of segments of the individual,                    ( )=   1
                                                      inverse of its hardness value: F x H(x) . The ﬁtness value
segi the segment i of the individual, SumSim(segi) the sum
                                                      of an individual y ∈ P is computed by summing the hardness
of the sentence similarities of segi and NbCouples(segi) the            t
                                                      scores of individuals x of P¯ dominating y:
number of possible couples of sentences in segi.
  Since the distribution of similarities in the text is not likely
to be homogeneous, one may probably ﬁnd very cohesive                             1
                                                            F (y)=                                  (8)
small areas. In this case, individuals representing small seg-     1+                         H(x)
                                                                         ¯
ments would have a really greater chance to obtain a good              x∈P ∧C(x)≥C(y)∧D(x)≥D(y)
score of cohesion. A normalization of the score could be per-
formed according to the size of the segments but may induce This ﬁtness function, allowing us to select individuals for
some bias. Therefore, we propose to realize the sum of each mutation and crossover, aims to diversify the search (from P¯
cohesion divided by the number of couples:            point of view).

                                                IJCAI-07
                                                  16493.4  Exploration Operators                            precision (number of exact boundaries found / number of
Three operators are used in the evolution process: selection, boundaries found ), the recall (number of exact boundaries
crossover and mutation (see ﬁg.1). At each generation, the al- found / number of boundaries of the reference) and a crite-
gorithm select NbIndiv individuals and produces NbIndiv rion, called WindowDiff [Pevzner and Hearst, 2002],which
new individuals to maintain a ﬁxed size of population. takes into account the number of boundaries between two
                               ¯                      sentences separated from a distance k.
  The individuals are selected from P and Pt according to
their ﬁtness value by ”roulette wheel” [Holland, 1975].This                       
method ﬁrst sums all the ﬁtness scores of the individuals.                    1      N−k
                                                       WinDiff(hyp, ref)=     −      =0 (|b(refi,refi+k)
Each individual gets a probability of selection equal to their              N  k     i
                                                                                       −b(hypi,hypi+k)|)
percentage of contribution in this sum.                                                              (10)
  Among the selected individuals, while the number of
                                                        where b (xi,xj) is the number of boundaries between i and
NbIndiv new individuals has not been reached yet, two par- j in a segmented text x containing N sentences, ref cor-
ents are randomly chosen in order to produce two new indi- responds to the segmentation of reference and hyp the one
viduals (the offsprings) by crossover. Here, we use a classical found with the method to evaluate. The size k of the window
single point crossover: a position is randomly chosen in the has to be set to half of the average true segment size. This
parents and the two corresponding parts of the parents are ex- criterion enables to consider the near-misses.
changed to form two children.
  Two different mutation operators are applied to these chil- 4.2 Parameters Tuning
dren: a mutation that replaces a parent by a randomly pro- The quality of the population is evaluated with a function
duced individual with a probability Pmsand a mutation used Eval(P¯) that returns the score of the best individual in P¯
with a probability Pmcthat shifts a boundary of the individ- w.r.t the aggregation function (section 3.5):
ual to the next or the previous sentence. Both mutation oper-
                                                                       ( ¯)=        ¯    ( )
ators appear complementary since the ﬁrst enables to explore       Eval P    Maxx∈P Agg  x         (11)
new areas while the second reﬁnes the existing solutions.
                                                        A study of different P¯, issued from executions of SegGen
3.5  Extraction of a Solution                         on multiples texts after various numbers of generations, has
                                                 ¯    shown that a weight α =6enables the selection of a good
When the algorithm meets the stop criterion, the archive P individual in the majority of cases. The following tests will
contains a set of potential segmentations. We have then to
                                                      use this value.
extract the best individual from this set. This choice can be
                                                        In order to adjust the probabilities of mutation Pms and
guided by an aggregation of both objective functions:
                                                      Pmc, SegGen has been ran for each couple of (Pms,Pmc)
                                                              (0 0)   (1 1)              0 2
                ( )=    ( )+   ×   ( )                between  ,   and  ,  ,usingastepof  . for each. These
             Agg x   C x   α   D x           (9)   experiments have been carried out on the set of 350 docu-
  The extracted solution is the one having the best score w.r.t. ments of the corpus T (50, 2), 10 times each in order to limit
this aggregation function. The coefﬁcient α weights the sec- random variations. The number of individuals in the popula-
ond objective compared to the ﬁrst. It acts upon the features tion is set to 10, value which appears to provide good results.
of the ﬁnal segmentation of the text and is thus tuned experi- Results of ﬁgure 2 are averages of the population evaluation
                                                                   ¯
mentally in section 4.                                function Eval(P ) on these multiple executions.

4  Experiments                                                  6.042                          40,80
                                                                                               20,80
                                                                 6.04                          40,60
4.1  Experimental Process                                                                      60,80
                                                                6.038                         40,100
                                                                                                40,0
The experiments were carried out on articles from the cor-      6.036                           0,80
pus of texts of the international conference TREC-1 [Harman, Eval
1993], which includes full articles from the Associated Press   6.034
published between 1988 and 1989. Those articles have been       6.032
gathered to form different sets of 350 documents. Separations    6.03
                                                                     0  50  100 150 200 250 300
between articles constitute the segmentation of reference.           Number of Generations
These tests based on concatenated articles may be less con-
clusive than tests performed on more homogeneous texts but  Figure 2: Evolution of Eval w.r.t. Pms,Pmc
this evaluation seems to be the most commonly used in the lit-
erature (see for example [Choi, 2000]) and this kind of bound-
                                                        The ﬁgure 2 shows the evolution of Eval(P¯) according to
aries appears to be difﬁcult enough to recognize. According
                                                      some different combinations of mutation probabilities3.We
to this principle, four corpuses have thus been created in order
                                                      may ﬁrst notice the inﬂuence of both mutation operators since
to test the behavior of the algorithm with regards to different
                                                      the curves that corresponds to a single mutation operator are
kinds of text. We note T (ns, nb) a corpus composed by texts
of ns sentences and an average of nb boundaries.We use the 3The legends correspond to the values Pms,Pmc (times 100)
corpuses T (50, 2),T(50, 4),T(100, 4),T(100, 8). The seg- and are given in the same order than the obtained score at the end of
mentation algorithms are evaluated w.r.t. three criteria: the the process (the greatest is the best).

                                                IJCAI-07
                                                  1650the lowest. The couple Pms =0.4 and Pmc =0.8 seems to   • TT: TextTiling4 [Hearst, 1997] is based on the distribu-
be the best compromise.                                   tion of the terms in the text, according to several criteria
  A study on the number of individuals NbIndiv has shown  (number of common words, new words, active chains).
that values greater than 10 allow the algorithm to converge
                                                        •          5
more quickly in term of generations but induce a greater com- C99:C99 [Choi, 2000], which seems to be the most
putation cost in term of evaluation. For instance, on the efﬁcient existing approach, uses a ”local ranking” by de-
corpus T (50, 2), with NbIndiv =20, the algorithm needs   termining, for each pair of textual units, the number of
only 150 generations to reach the score of evaluation of 6.04 surrounding pairs having a lower similarity.
      250     10
against   with  individuals. However, the number of gen- • CS: ClassStruggle, mentioned in section 2, is based on a
                        250 × 10   150 × 20
erated individuals is greater (  <         ). On the      clustering process to segment the texts.
other hand, a lower number of individuals leads to the oppo-
site problem, the number of generations is too high, which As mentioned in section 3.2, we tried to improve the ini-
implies a loss of time.                               tial population by inserting a good solution. Therefore, two
  Concerning the stop criterion, long texts may need more versions of the algorithm, S5 and SC5, have been evaluated.
time to be segmented but the quality of segmentation can be In SC5, a segmentation scheme, computed by C99, has been
the same than for shorter ones. A value of 100 iterations with- inserted in the initial population. Both use a coefﬁcient α =5
out any improvement seems to be sufﬁcient enough to reach (see section 4.2).
a good solution.                                        Since SegGen uses stochastic parameters in mutation and
                                                      crossover, the range of error has been evaluated by computing
                                                      the standard deviations, on ten executions, of the average of
      0.24                    0.7
      0.235                   0.68                    scores obtained on each corpus. Standard deviation of Win-
      0.23                    0.66                                          0 015              0 01
      0.225                   0.64                    dowDiff is located around . , of recall around . and of
      0.22                    0.62                    precision around 0.012. These values are really low w.r.t. the
      0.215                Recall
                              0.6
    WindowDiff
      0.21
                              0.58                    ranges of scores given in table 1.
      0.205
                              0.56
       0.2
        3  4  5  6  7  8        3  4  5  6  7  8
              Alpha                  Alpha            5.2  Results
      0.64                    5.5                     According to results given in table 1, ClassStruggle, having a
      0.63
                               5
      0.62                                            more complete view of the relations of the sentences thanks
      0.61                    4.5                     to the use of a clustering process, is globally more efﬁcient


    Precision  0.6
                               4                      than C99 and TextTiling. However, its incremental process
      0.59
                            Number  of Boundaries     reduces its ability to take into account the segment cohesion
      0.58                    3.5
        3  4  5  6  7  8       3  4   5  6  7  8      and the similarity between adjacent segments. SegGen over-
              Alpha                  Alpha
                                                      rides this problem and obtains really better results for all ac-
         Figure 3: Results of experiments on α        curacy criteria, especially on corpuses that do not have a lot
                                                      of boundaries to retrieve (i.e. T (50, 2) and T (100, 4)). Text-
                                                      Tiling and C99 seem to have difﬁculties to adapt themselves
  Concerning the value of the α parameter used in the aggre-
                                                 ¯    w.r.t the number of boundaries to retrieve, the length of the
gation function in order to extract a good individual from P , text has a great impact on their number of detected bound-
we have to remark that the ﬁrst objective function C favorizes aries. SegGen seems to better follow these variations.
individuals that generate a lot of boundaries, small segments
                                                        However, on corpora that have a lot of boundaries to re-
having more chances to be cohesive. At the contrary, the        (50 4)     (100 8)
second objective function D is in favor of individuals hav- trieve, i.e. T , and T , , SegGen seems to have dif-
ing few boundaries, since long segments have more chances ﬁculties to product individuals sufﬁciently segmented. This is
to own sentences faraway the following. The parameter α due to the fact that good individuals with a lot of boundaries
has thus an inﬂuence on the number of detected boundaries are more difﬁcult to ﬁnd than others. The insertion of a good
(ﬁgure 3). The best results according to WindowDiff are ob- individual in the initial population (SC5), obtained by C99,
tained around α =5. Nevertheless, an higher value enables seems to solve this problem. C99, providing segmentations
to obtain a better precision and a lower a better recall. This with a lot of boundaries, helps SegGen to ﬁnd solutions when
value may be set between 4 and 6 w.r.t. the frequency of the the search space is huge.
                                                                                6
required segmentation.                                  Additionally, a Student t-test has shown that these differ-
                                                      ences are really signiﬁcant with a 99% conﬁdence rate, all of
5  Evaluation                                         the values being higher than the p-value 2.57.
5.1  Experimental Process
                                                         4Available on: www.sims.berkeley.edu/˜hearst/.
In order to evaluate the methods, we use benchmarks created 5Available on: www.freddychoi.me.uk.
similarly to those described in section 4. Of course, in order 6The 99% Student t-test is based on the average, the standard
not to skew the results, the selected articles are different from deviation and the cardinality of a set of runs. It uses a p-value equal
those used for tuning purposes. SegGen has been compared to 2.57 to insure with a rate of conﬁdence of 99% that the difference
to the following methods to evaluate its efﬁciency:   in means of two sets is signiﬁcant.

                                                IJCAI-07
                                                  1651