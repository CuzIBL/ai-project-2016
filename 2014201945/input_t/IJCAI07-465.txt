                Face Recognition via the Overlapping Energy Histogram

                 Ronny Tjahyadi, Wanquan Liu, Senjian An and Svetha Venkatesh
                                       Department of Computing
                          Curtin University of Technology, WA 6845 Australia
                     Email:  {tjahyadi, wanquan, senjian, svetha}@cs.curtin.edu.au


                    Abstract                          database as the eigenspace in PCA requires recompilation
                                                      due to its data dependent characteristic [Turk and Pentland,
    In this paper we investigate the face recognition 1991]. Recently, the two dimensional PCA is proposed and it
    problem via the overlapping energy histogram of   has proven to be much better than Eigenfaces in terms of per-
    the DCT coefﬁcients. Particularly, we investigate formance and computational cost [Yang et al., 2004].Inor-
    some important issues relating to the recognition der to reduce the computational cost, fast transforms such as
    performance, such as the issue of selecting thresh- Discrete Cosine Transform (DCT) has been used as an alter-
    old and the number of bins. These selection meth- native. The DCT has been used for feature extraction and has
    ods utilise information obtained from the training been demonstrated to be superior to PCA in terms of compu-
    dataset. Experimentation is conducted on the Yale tation cost since recompilation is not required when adding or
    face database and results indicate that the proposed removing new images into or from the facial image database
    parameter selection methods perform well in se-   [Hafed and Levine, 2001]. Some face recognition algorithms
    lecting the threshold and number of bins. Further- incorporating DCT can be found in [Zhao et al., 2000] and
    more, we show that the proposed overlapping en-   most of them incorporate the DCT coefﬁcients directly into
    ergy histogram approach outperforms the Eigen-    Hidden Markov model and Neural Networks.
    faces, 2DPCA and energy histogram signiﬁcantly.
                                                        This paper is an extension of paper [Tjahyadi et al., 2004].
                                                      Compared to the previous paper, ﬁrst, we use the overlapping
1  Introduction                                       method to extract the DCT coefﬁcients in order to enhance the
Face recognition has many potential applications in secu- performance. Second, we introduce automatic threshold and
rity and surveillance. Over many years, several different number of bins selection to the proposed overlapping energy
techniques have been proposed to mimic the inherent hu- histogram. Finally, we do more comparisons with other tech-
man ability to recognize faces using computers and some of niques, such as Eigenfaces, 2DPCA and energy histogram.
these techniques have been successfully deployed in numer- The overlapping energy histogram is based on the DCT
ous surveillance systems, e-commerce application and com- and it measures the distribution of the DCT coefﬁcients of an
puter login systems [Zhao et al., 2000].              image. The performance of energy histogram with varying
  One successful approach to face recognition is to use the numbers of bins is investigated using six datasets constructed
Principal Component Analysis (PCA), originally proposed by from the Yale face database. In addition, a systematic thresh-
Sivorich and Kirby [Kirby and Sivorich, 1987]. PCA is an op- old selection method is proposed which utilises the distance
timal signal representation that extracts the eigenvectors from information obtained from the training dataset. The informa-
a covariance matrix constructed from an image database. This tion gathered from the threshold selection procedure is further
technique reduces the number of dimensions to represent im- used to select a suitable number of bins. The performance
ages in the database. In 1991, Turk and Pentland [Turk and of overlapping energy histogram face recognition is analyzed
Pentland, 1991] incorporated PCA into a face recognition and discussed. To illustrate the effectiveness of the technique,
system known as Eigenfaces, demonstrating promising re- comparisons are made with the Eigenfaces, 2DPCA and en-
sults in recognizing frontal images of individuals. Experi- ergy histogram techniques.
mentation with a database of 2500 images of 16 individuals
generated 96% correct classiﬁcation over various light con- 2 Preliminaries
ditions, 85% with orientation variations and 64% with size
variations.                                           2.1  The Discrete Cosine Transform
  PCA is an optimal signal representation, however this tech- DCT is a popular technique in imaging and video compres-
nique suffers from high computational cost in determining sion and was ﬁrst applied in 1974 by Ahmed et al. [Ahmed
the eigenspace for a large number of images [Kirby and et al., 1974] to transform image signals from a spatial repre-
Sivorich, 1990]. In addition, the computational cost for PCA sentation into a frequency representation. In 1992, the ﬁrst
increases when new images are added into the facial image international standard for image compression, JPEG, was es-

                                                IJCAI-07
                                                  2891tablished with the DCT as the encoder and decoder and it F 1=[DC],
uses the DCT to remove the redundancies from images. Each F 2A =[AC01,AC10,AC11],
image frame is divided into 8x8 blocks, where each block is F 2B =[DC, AC01,AC10,AC11],
transformed independently using the two-dimensional DCT F 3A =[AC01,AC02,AC10,AC11,AC12,AC20,
(2D-DCT).                                               AC21,AC22],
  Figure 1 shows the zigzag pattern used to process the 8x8 F 3B =[DC, AC01,AC02,AC10,AC11,AC12,
DCT coefﬁcients blocks by JPEG compression. Although the AC20,AC21,AC22],
total energy remains the same in the 8x8 blocks, the energy F 4=[DC, AC01,AC02,AC03,AC10,AC11,AC12
distribution changes with most energy being present in the AC13,AC20,AC21,AC22,AC23,AC30,AC31,AC32,AC33]
low frequency DCT coefﬁcients. The DC coefﬁcient, which
is located at the upper left corner, holds most of the image en- Figure 2: The feature sets for energy histogram
ergy and represents the proportional average of the 64 blocks.
The remaining 63 coefﬁcients denote the intensity changes
among the block images and are referred to as AC coefﬁ- Lay and Guan [Lay and Guan, 1999] reported that the com-
cients.                                               bination of the DC and AC coefﬁcients (F2B, F3B and F4)
                                                      yield the best performance results in image retrieval. The
                                                      feature sets F2B and F3B were shown to be more ideal than
                                                      the F4 feature set, due to the fact that as the feature block
                                                      grows, more coefﬁcients are involved in creating the energy
                                                      histogram, thus possibly, introducing more errors. The F1
                                                      feature set was observed to perform well when retrieving im-
                                                      ages that have high color similarity, whilst the F2A and F3A
                                                      feature sets were shown to have adequate retrieval perfor-
                                                      mance due to the contribution of the AC coefﬁcients which
                                                      carry the texture and edge information. However, they did
                                                      not investigate the threshold selection issue.
            Figure 1: The DCT coefﬁcients
                                                      3   Face Recognition System Design

  The DCT was reported to be the second most optimal trans- 3.1 Face Recognition System with the Overlapping
formation after PCA with an energy compaction. Although    Energy Histogram
PCA is the optimal transform in an energy packing sense, Research on face recognition has been conducted to solve
most practical transform coding systems still apply the DCT three distinct scenarios: face veriﬁcation, face identiﬁcation
as it offers numerous advantages over PCA including good and the watch list [Lu, 2003].Theaimofface veriﬁcation
computational efﬁciency whilst producing good quality im- is to verify that an individual is who he or she claims to be,
ages at suitable compression ratios.                  whereas the face identiﬁcation attempts to identify an indi-
                                                      vidual in a database with the assumption that the individual
2.2  Energy Histogram                                 is known. The watch list scenario is similar to face identiﬁ-
Histograms are commonly used in computer vision. The ad- cation, except that the individual to be identiﬁed may not be
vantages of color histograms are described in [Swain and Bal- in the database. Of these scenarios, the watch list is gener-
lard, 1990] and include invariance to image manipulations ally considered to be the most difﬁcult, as face recognition
such as rotations, translations and scale, angle of view or oc- under this scenario confronts a large number of false alarms
clusions. Despite these advantages, the histogram approach [Phillips et al., 2003].
performs poorly under different lighting conditions. It is also In this section we will use the overlapping energy his-
ineffective in distinguishing different images that have sim- togram to design a face recognition system for the watch list
ilar color distributions and suffers from inefﬁcient computa- scenario (Figure 3). It consists of feature extraction using the
tion due to its high dimensionality.                  energy histogram algorithm, and a classiﬁer which recognizes
  An energy histogram is similar to color histogram but in- images based on their feature vectors. In the training stage,
stead of counting pixel color, an energy histogram accumu- we will obtain all the DCT coefﬁcients for each training im-
lates the DCT coefﬁcients in corresponding bins. In compar- age with overlap blocks and then select the number of bins
ison, energy histogram incurs less computational cost when and threshold as outlined in the next section. In the recogni-
compared to the color histogram as its dimensions are greatly tion stage, we will only use the selected number of bins to ex-
reduced by the DCT. Lay and Guan [Lay and Guan, 1999] tract features from the testing images and classify the testing
investigated the energy histogram in image retrieval and pro- images based on the selected threshold and generated feature
posed feature sets identifying similarities of the images. The set.
feature set was obtained by applying the DCT to an individ- In feature extraction, each facial image is divided into 8x8
ual subset of each facial image and it consisted of 6 feature blocks with 75% overlapping (6 column pixels overlapped)
blocks, denoted F1, F2A, F2B, F3A, F3B, and F4 in Figure and the DCT is then computed on each block. The 75% over-
2.                                                    lapping was reported to perform better recognition rates com-

                                                IJCAI-07
                                                  2892   Training
                                     Threshold, Feature are measured against the images of other individuals in the
   Images               Energy
               DCT                   Set and Histogram 
                        Histogram                     training dataset as described Algorithm 1. This class indi-
                                     Bin Size Selection cates how different each image of an individual is when com-
                                                      pared to images of other individuals in the training dataset.

                              Database                The classiﬁcation threshold (θ) is then calculated from intra-
                                                      and inter-class information, and described in Algorithm 2.
                  Training Stage                      The training dataset requires a suitable number of images per
                                                      individual in order to obtain sufﬁcient distance information.
                   Selected Feature 
                                Threshold             From [Tjahyadi, 2004], every individual should have at least
  Unknown          Set and Bin Size
                                      Match or        4 images for training. A large training dataset should result in
  Image         Energy     Similarity
         DCT                          Unmatched
                Histogram                             better estimation of thresholds. The proposed algorithm for
                           Measurement Face Image
                                                      threshold selection is as follows:
                 Recognition Stage                    Denote
                                                         I = number of individuals
                                                           
Figure 3: The overlapping energy histogram face recognition K = number of images per individual
                                                                    
system                                                   I = {1,...,I }
                                                         K  = {1,...,K}

pared to others [Kohir and Desai, 1998]. In this paper, we Algorithm 1: Finding the Intra and inter Classes
only use the F2 feature set (Figure 4). Preliminary inves- for each image Mik where i ∈ I and k ∈ K do
                                                                         th             th
tigations have shown that the F2 feature sets achieve better Compute hik for k image of the i individual, where
recognition rates in comparison to other feature sets (F1, F3 hik is the feature vector obtained with the selected feature set
and F4) [Tjahyadi, 2004]. The energy histogram is built by and histogram bin size.
counting the number of times each DCT coefﬁcient occurs in Compute the intra distances
                                                             ik             2                         
the domain of the corresponding bin. This energy histogram  dik = hik − hik  where i ∈ I, k ∈ K and k = k
is then used as the feature vector (Ω). The threshold and bin and the inter distances
                                                             jl            2
number selection approaches are outlined in the next section. pik = hik − hjl where j ∈ I, j = i and l ∈ K
                                                      end

                                                                             ik           
          F 2=[DC, AC01,AC10,AC11]                    Get the intra class (D)={dik | k = k ,k,k∈ K, i ∈ I}
                                                                             jl
                                                      Get the inter class (P )={pik | j ∈ I, j = i, k, l ∈ K}
Figure 4: The F2 feature set for overlapping energy histogram and sort the D and P in ascending order

                                                                            ik           
                                                      Compute Dmax  = max {dik | k = k ,k,k∈ K, i ∈ I},
  To recognize a face image, the system compares the im- D
                  (Ω)                                      max is a measure of generalization among images for
age’s feature vector  to each of the feature vectors in all individuals
the database. A straightforward pattern classiﬁcation ap-                  jl
                                                      Compute Pmin = min {pik | j ∈ I, j = i, k, l ∈ K},
proach to recognition is to ﬁnd a face image n that minimises        j∈I
the corresponding Euclidean distance. In experimentation Pmin is a measure of differences between one individual
[Tjahyadi, 2004], it is discovered that the Euclidian distance against others.
performs better than neural networks on the original energy
histogram. Further, the Euclidean distance has been used in Algorithm 2: Finding the Classiﬁcation Threshold
many face recognition techniques [Turk and Pentland, 1991; The classiﬁcation threshold (θ) can be deﬁned through
                                                                                                   
Yang et al., 2004].                                   Dmax  and Pmin.IfDmax  <Pmin,thenTP    and FP  rates
                                                                                                        θ
                   = (Ω − Ω )2                     deﬁned below can reach 100% and 0% respectively. Thus,
                  n          n                  (1)   is directly deﬁned as:
where Ωn is a feature vector describing the nth face image.                D     + P
                                                                       θ =   max    min
  If n is below some chosen classiﬁcation threshold (θ),                        2                    (2)
then the new image is classiﬁed as belonging to a face im-
                                                      If Dmax >Pmin, then one needs to ﬁnd the θ that maximizes
age n, and classiﬁed as “unknown” otherwise.                                   
                                                      the TP and minimizes the FP with the following steps:
3.2  Threshold Selection                                Now, we have obtained D and P from the training dataset
                                                      which will be used to calculate True Positive (TP)andFalse
The proposed threshold selection is computed via intra and                       
                                                      Positive (FP ). The TP and FP  measure the percentage
inter class information gathered from the training dataset.
                                                      of correct classiﬁcation and misclassiﬁcation respectively and
The intra-class (D) is a set where the distances between the
                                                      are deﬁned as follows:
images of the same individual are calculated as shown in Al- TP = Q × 100%
gorithm 1. This class gives an indication of how similar the    D
                                                         FP =   L  ×  100%
images of the same individual are. The inter-class (P )isa      P 
set where the distances between the images of an individual where Q is the number of elements in D that are less than a

                                                IJCAI-07
                                                  2893given threshold. D is the number of elements in D which is In this section we present a systematic approach in select-
calculated by (K −1)×K ×I. L is the number of elements ing a suitable feature set and number of bins for face recog-
in P that are less than a given threshold. P  is the number nition. We explore the number of bins ranging from 20 to 40
                                    2
of elements in P which is calculated by K × (I − 1) × I. with an increment of 1. The selection algorithm for feature
  Next, we will select a threshold to balance the correct clas- set and number of bins is as follows:
siﬁcation and misclassiﬁcation ratio. The idea is to separate Let
                                                       W  = { }
D as N parts evenly and draw a curve of FP and TP with         2
                                                         F                     i ∈ W
different thresholds. We intend to ﬁnd the balanced point on i is the feature set where
                                                         B  =
this curve. The detail is as below.                           number of bins ranging from 20 to 40 with incre-
                                                               {21, 22,...,40}
  From  the Algorithm  1, we  have  obtained D   =    ment of 1:
{d1,d2,...,dD} where d1 ≤ d2 ≤  ... ≤ dD.Then
                                                                      F j              F     j ∈ B
we need to ﬁnd the index x1,x2,...,xN such that D is  for each histogram i with feature set i and do
                                                                                         θj
grouped into D =  {Dx1 ,Dx2 ,...,DxN } where Dxj =       Compute the classiﬁcation threshold ( i ) with the algo-

{dxj−1+1,...,dxj } for j =1, 2,...,N with xN = D,   rithm deﬁned in Algorithm 2.
                   −        −          −              end
                   x        x          xj
x0 =0.Further,xj = [ j] where j satisﬁes D × N = j
    −                            −                    Now,   we  have  obtained the  following information
and [xj] refers to rounding the number (xj) to the nearest in-
                                                      {TPj,FPj}      i ∈ W, j  ∈  B      θj
teger. This process is to divide D into N groups where N is i    i for                with  i These values
chosen subjectively depending on the database. In the exper- are the balanced correct classiﬁcation and misclassiﬁcation
iments of this paper, N is chosen as 10, which gives us very ratios with the chosen threshold.
good performance.                                                       j
                                            (θ )      for each histogram Fi with i ∈ W and j ∈ B do
  Now,   we  have   obtained the  threshold  j   =                                              
                                                        //Get number of bins that maximize the TP for each
{dx1 ,dx2 ,...,dxN }, and we can compute the TP and
FP                   (θ )                   (T )     i ∈ W
    with each element in j . Then, the derivative j is               j                        j
                                                         Si = {j | TP i = αi,j∈ B, αi =max(TP   i )}
calculated as:                                                                           j
                                                                              S                 FP
                  ΔTP                                  //Get number of bins from i that minimize the for
                       j   max(FP   )                     i ∈ W
            Tj =         ×                      (3)   each
                  ΔFP       100%                                         j                  j
                       j                                  Mi = {j ∈ Si | FP i = βi,βi =min(FP  i )}
                                                                                       j∈Si
     where max FP is the maximum value of FP;       end
                      
     ΔTPj  = TPj+1 − TPj for j =1, 2,...,N − 1;
                                                   The above procedure is to choose the bin size which max-
   and ΔFPj = FPj+1  − FPj for j =1, 2,...,N − 1;
TP    FP        TP    FP                          imizes the correct classiﬁcation ratio while minimizing the
   j and  j are the   and     values respectively when misclassiﬁcation ratio. Alternatively, we can also minimize
     we choose the threshold θj with j =1, 2,...,N;   FP                      TP
                                                         ﬁrst and then maximize  .
          If ΔFPj =0then we deﬁne Tj =0.
  To ﬁnd the classiﬁcation threshold (θ), we have to search 4 Experimental Results
    j  ∈{2, 3,...,N − 1}        T     > 1    T   <
for a 0                 such that j0−1    and  j0     Experimentation was carried out on six datasets created from
1. The threshold θ is chosen as the value in dθ . If none of
                                      j0−1                        [             ]                      15
   T                 1      θ        d                Yale database Database, 2004 . This database contains
the j values is less than ,then is set as N . Mathemati- individuals, (mostly male), with 8 images each, since face
cally, we intend to ﬁnd a point on the curve (FP-TP) with
T  =1                                                 images in the original database with strong light conﬁgura-
 j    , which can balance the rates of correct classiﬁcation tions were excluded as the excessive light cast shadow on the
and misclassiﬁcation. The above algorithm gives us a rough background requires to be preprocessed in practice. The total
approximation for this selection due to the nature of discrete number of images used in this experiment is 120. In all the
discontinuity.                                        dataset, the number of individuals for training is set to be 10
                                                      and the number of individuals for testing is set to be 15.Table
3.3  Selection of the Number of Bins                  1 shows a brief description of all datasets. For each dataset
Lay and Guan [Lay and Guan, 1999] empirically discussed we created 10 subsets via randomly selecting the training im-
the performance of six feature sets in retrieving images and ages per individual. The remaining images, not included in
identiﬁed that the F2B and F3B feature sets yielded the best each training subset, were used to construct the correspond-
performance. However, the effect of varying the number of ing testing subsets.
bins was not investigated. The effectiveness of histogram in- These datasets were used to evaluate the proposed face
dexing depends on the number of bins used. Brunelli and recognition algorithm in two scenarios. In the ﬁrst scenario,
Mich [Brunelli and Mich, 1999] suggested that an image re- the experiments were carried out on four datasets with ﬁxed
trieval system can rely on small numbers of bins without se- threshold value. The results were then compared to the Eigen-
vere degradation of retrieval performance and showed that a faces [Turk and Pentland, 1991],2DPCA[Yang et al., 2004]
bin number of 16 was sufﬁcient for image retrieval using the and energy histogram [Tjahyadi et al., 2004]. In the other
City-Block (L1) distance.                             scenario, we investigated the performance of the proposed au-

                                                IJCAI-07
                                                  2894tomatic threshold and number of bins selection algorithms on                 Overlapping EH
the remaining datasets. The query effectiveness is evaluated
using precision and recall statistics.                             Dataset  Prec. %  Recall %
                                                                     1       93.9      92.6
                        #of       #of    #of                         2       96.2      95.2
      Scenario Dataset training images training testing              3       97.7      96.7
                     per individual images images
               1         1         10    110                         4       98.4      95.4
               2         2         20    100
        1      3         3         30     90          Table 4: Overlapping Energy Histogram Performance com-
               4         4         40     80
               5         4         40     80          parisons (average rates)
        2      6         5         50     70

          Table 1: Training and testing datasets      4.2  Evaluation on Automatic Threshold and
                                                           Number of Bins Selection Algorithms
                                                      In this subsection we will examine the proposed threshold and
4.1  Evaluation on the Overlapping Energy             number of bins selection algorithms with 2 datasets in Sce-
     Histogram Face Recognition System                nario 2 where each dataset consists of 10 subsets. We select 2
                                                      subsets from dataset 5 and 6 to demonstrate the effectiveness
In this subsection we compare the overlapping energy his- of the proposed number of bins selection algorithm. Table
togram with the Eigenface, 2DPCA and energy histogram 5 shows the selected number of bins and their corresponding
with all datasets in Scenario 1 where each dataset consists accuracies for the subsets. From Figure 5, one can see that the
of 10 subsets. The threshold for each dataset (Table 2) was proposed number of bins selection performs well in selecting
selected via trial and error method such that precision and number of bins where the precision and recall are balanced
recall rates are balanced. The average results in Table 4 in- with high rates.
dicate that the overlapping energy histogram outperforms the
Eigenface, 2DPCA and energy histogram in all datasets with
higher precision and recall rates. In dataset 4, the recall rate            Selected     Precision  Recall
of energy histogram is slightly higher than the overlapping Dataset Subset Number of Bins    %        %
method, however, the precision rates are much lower. Signiﬁ- 5    10           37           97.4     94.9
cant performance of the overlapping energy histogram can be 6     10           32           100      100
seen in dataset 1 where only 1 image per individual was used
as a training image while the remaining images were used as Table 5: Numbers of Bins Selected Via Proposed Bin Selec-
testing images.                                       tion Algorithm

  Data                               Overlapping
   set  Eigenfaces  2DPCA      EH        EH
          (* 107)    (* 104)  (* 10)    (* 102)
                                                      100                         100
   1       8.75       3.10     5.3        7.0          90                         90
                                                       80                         80
   2       9.50       2.90     4.8        6.4          70                         70
                                                       60                         60

   3       10.00      2.80     4.8        6.0          50                         50


                                                       40                         acuracy  (%) 40
   4       10.50      2.60     4.7        5.6         accuracy  (%)
                                                       30                         30

                                                       20                         20

                                                       10                precision 10                precision
Table 2: Classiﬁcation Thresholds for Datasets on Scenario 1             recall                      recall
                                                       0                           0
                                                       20    25   30   35   40     20   25   30    35   40
                                                                number of bins             number of bins

                                                         (a) Dataset 5 (subset 10)  (b) Dataset 6 (subset 10)
 Data
         Eigenfaces      2DPCA           EH
  set   Prec.  Recall Prec.  Recall  Prec.  Recall       Figure 5: Performance over Various Numbers of Bins
         (%)    (%)    (%)    (%)    (%)     (%)
   1    75.5   74.9    83.0   82.7   87.5   82.2        The selected classiﬁcation thresholds and their correspond-
   2    78.8   79.3    86.9   87.3   92.4   87.7      ing accuracies are shown in Figures 6 and 7 respectively. The
   3    84.0   82.3    90.8   91.0   94.1   93.5      numbers of bins and classiﬁcation thresholds are calculated
   4    81.6   84.2    85.4   87.8   95.6   95.6      from the proposed approaches. From these ﬁgures one can
                                                      see that the threshold selection approach performs more sta-
    Table 3: Performance comparisons (average rates)  ble with dataset 6. This is due to the fact that dataset 6 has
                                                      more training images, hence, it provides more intra and inter
                                                      distances for selecting the threshold. Overall, these results in-

                                                IJCAI-07
                                                  2895