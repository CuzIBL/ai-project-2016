                         On the Foundations of Expected Expected Utility 

                                                   Craig Boutilier 
                                          Department of Computer Science 
                                                University of Toronto 
                                        Toronto, ON, M5S 3H5, CANADA 
                                                cebIy@cs.toronto.edu 


                        Abstract                               usually maintained (often by imposing constraints on trade•
                                                               off weights). A decision can be made based on this set of 
     Intelligent agents often need to assess user utility 
                                                               feasible utility functions. For example, Parcto optimal deci•
     functions in order to make decisions on their be-
                                                               sions can be identified [21; 18], or models based on mini-
     half, or predict their behavior. When uncertainty 
                                                               max regret can be used to choose a specific decision [11; 2; 
     exists over the precise nature of this utility function, 
                                                               20]. In each of these models, the uncertainty regarding the 
     one can model this uncertainty using a distribution 
                                                               utility function is characterized by the feasible utility set. 
     over utility functions. This view lies at the core of 
                                                                 Somewhat less common is work in which the system's un•
     games with incomplete information and, more re•
                                                               certainty about a user's utility function is quantified proba•
     cently, several proposals for incremental preference 
                                                               bilistically. Some recent examples include [5; 6; 1]. In this 
     elicitation. In such cases, decisions (or predicted 
                                                               work, a distribution over utility functions is assumed. The 
     behavior) are based on computing the expected ex•
                                                               expected utility of a decision is determined not just by taking 
     pected utility (EEU) of decisions with respect to the 
                                                               expectation over the outcomes of that decision, but also ex•
     distribution over utility functions. Unfortunately, 
                                                               pectation over the space of possible utility functions. We use 
     decisions made under EEU are sensitive to the pre•
                                                               the term expected expected utility (EEU) to denote the value 
     cise representation of the utility function. We ex•
                                                               of a decision computed in this way. Elicitation strategies can 
     amine the conditions under which EEU provides 
                                                               be informed using the current distribution over utility func•
     for sensible decisions by appeal to the foundational 
                                                               tions. For example, value of information can be used to de•
     axioms of decision theory. We also discuss the im•
                                                               termine whether the improvement in decision quality given 
     pact these conditions have on the enterprise of pref•
                                                               by a piece of information outweighs the cost of obtaining 
     erence elicitation more broadly. 
                                                               that information. Thus, characterizing one's uncertainty over 
                                                               possible utility functions in a probabilistic fashion, and using 
1 Introduction                                                 EEU to determine decision quality, has much to recommend 
Most work on the foundations of decision theory—               it from the point of view of elicitation. 
specifically on the justification of expected utility—has fo•    Decision making using distributions over utility functions 
cused on personal decision making, that is, settings where a   has been considered in other contexts. For example, Cyert 
decision is being made by the "holder" of the utility func•    and de Groot consider problems in sequential decision mak•
tion. Of course the decision maker may not be fully aware      ing in which uncertainty in the underlying utility function is 
of (or have fully articulated) her utility function. The pro•  represented probabilistically [8; 9]. Fishbum [10] also ad•
cess of articulation is complex, and much work in decision     dresses this problem (as we discuss below). Harsanyi's for•
analysis deals with preference elicitation and decision fram•  mulation of games with incomplete information as Bayesian 
ing to help the decision maker formulate her decision problem  games [12; 13] relies critically on distributions over payoff 
[11]. However, this work is primarily concerned with elicit•   functions, and virtually the entire literature on in this area 
ing enough information about preference tradeoffs to allow     adopts this perspective [7; 15].1 
an (approximately) optimal decision to be made. While an         In all of this work, the EEU concept is used to determine 
analyst can never be sure about the true nature of the deci•   the value of decisions in the context of an uncertain utility 
sion maker's utility function, this uncertainty is not generally function. Unfortunately, while EEU has an intuitive appeal, 
characterized explicitly, though its impact is often minimized this scheme is sensitive to positive affine transformations of 
though sensitivity analysis and related techniques. 
                                                                  'in some sense, much work in collaborative filtering [3; 16] and 
  Recent emphasis has been placed on the development of        related models [4] can be viewed as incorporating distributions over 
automated decision tools, where a decision is being made       utility functions. However, these are used for purposes of classi•
on behalf of a user whose utility function is imprecisely      fication (i.e., determining a unique utility function for a particular 
known. As in goal programming or other forms of inter•         user) and generally uncertainty in utility is not accounted for when 
active optimization, a space of possible utility functions is  making decisions. 


DECISION THEORY                                                                                                      285  the utility functions in question. Implicit in such a scheme     It is well known that utility functions are invariant under 
 is a commensurability assumption that allows the quantities   positive affine transformations. That is, the relative expected 
 present in the different utility functions to be meaningfully utility of any pair of decisions (in any decision scenario) will 
 compared and combined. This is not always the case. The       be unaltered by such a transformation of a utility function. 
 aim of this paper is to describe certain conditions under which This implies that the optimal decision in any decision sce•
 this commensurability assumption can be justified by appeal   nario is unaffected by such a transformation. 
 to the foundational axioms for decision theory as proposed by 
 von Neumann and Morgenstern [19] and Savage [17]. 
   The setting we consider is one in which an agent for a de•
 cision maker or user is uncertain about the user's preferences, 
 but wishes to recommend (or take) decisions on the user's be-
 half. Fishburn [10] has considered the problems of the foun•
 dations of expected expected utility from a somewhat differ•
 ent perspective. He considers the problem in which a decision 
 maker is uncertain about the set of consequences she might 
 face and considers combining utility functions over different 
 consequence sets. Unfortunately, his results cannot be ap•
 plied (except in a trivial way) to the situation above.2 
   We begin by defining the problem of decision making 
 given uncertainty over utility functions and the FEU con•
 cept. We then examine the sensitivity of EEU to the precise 
 representation of the underlying utility functions, and pro•
 pose an interpretation of utility uncertainty that allows one to 
 prescribe "canonical" utility function representations under 
 specific circumstances. We conclude with a brief discussion 
 of the implications these considerations have for "practical" 
 elicitation. 

 2 Expected Expected Utility 
 We begin by establishing notation and basic background with 
 a quick overview of expected utility and then define the notion 
 of expected expected utility formally. 


 The optimal decision d* w.r.t. u is that with maximum ex•
pected utility (MEU). 

    2 While our results are general, it is unclear how profitable it is to 
 model a decision maker's uncertainty about her own utility function. 
 It can be argued that such uncertainty should be viewed as "tradi•
 tional" uncertainty about future outcomes, context, etc. Rather than 
 take a stand on this issue, we simply emphasize that an agent can 
 be genuinely uncertain about a user's utility function, and that our 
 model and results apply (in a practical way) to such a setting. 

   3 If u is represented using some more concise model, u is simply 
 the vector of parameters required for that model. 


 286                                                                                                 DECISION THEORY    This definition is precisely that used in [5; 6; 1] in the con•      a utility function—to serve as a concise representation of a 
text of utility elicitation, and also that used in much other           preference function over lotteries. 
work involving uncertainty over utility [12; 8; 9]. In such                This gives rise to the question of how to choose a repre•
a state of uncertainty—or belief state—the optimal decision              sentative utility function from each equivalence class [> ] that 
is that d* with maximum EEU EU(d*,P). We denote by                       allows formal justification of the MEEU decision rule, and 
EU(P) the value of being in belief state P, assuming one is              under what circumstances such representatives exist. 
forced to make a decision: 
                                                                        3.2 A Lottery Interpretation of MEU 
                                                                         We give a formal justification for the MEEU rule under a spe•
                                                                        cific condition: we assume the existence of a known best and 
We call this generic decision rule the MEEUdecision rule, by             worst outcome. That is, each utility function with positive 
analogy with the classical MEU decision rule.                            support has the same best outcome sT and worst outcome ,s±. 
   EEU seems to be a fairly natural concept given proba•                 We also insist that the user is not indifferent to these alterna•

bilistically quantified uncertainty over utilities. The fact that       tives, that is, that ST must be strictly preferred to .s.5 We call 
it occurs in many different contexts certainly attests to this           such utility functions extremum equivalent. In many settings, 
fact. Unfortunately, the proposed definition can induce cer•             such as those involving active preference elicitation, restrict•
tain anomalies, as we examine below.                                     ing attention to a set of extremum equivalent utility functions 
                                                                         is not problematic. One simply needs to ask the user to iden•
3 Justifying MEEU                                                        tify her most and least preferred outcomes (these need not be 
                                                                         unique, but only one such representative need be identified). 
3.1 Loss of Invariance 
The results of von Neumann and Morgenstern suggest that 
the decisions one makes with respect to belief state P over 
U should be invariant to legitimate transformations of the el•
ements of U. Certainly, this would be a desirable feature of 
the MEEU decision rule. One might even claim that the de•
cision rule can only be considered useful if it satisfies this 
condition. In general, unfortunately, this is not the case. 
   As a simple illustration, suppose we have a domain with 

two outcomes s1 and s2, and a distribution P that assigns 

probability 0.5 to u1 = (1,3) and probability 0.5 to u2 = 
(2,1). Suppose we use the MEEU decision rule in this con•
text, by computing 


and choosing the decision d* with maximum expected utility 
EU(d*, P). Then a decision that accords higher probability 

to s2 will be preferred to one that gives lower probability to 

s2. However, if we transform u2 into ui2 = (20,10), the 
relative utilities of these decisions will be reversed. Thus, the 
MEEU decision rule is not insensitive to transformations of 
individual utility functions with positive support. Note that 
we are not suggesting that agent's will arbitrarily transform 

some utility functions and not others.4 Rather, the question 

is: which representation of a specific utility function (e.g., u2 
in the example) should be adopted in the first place? 
   One possible way to deal with this problem is to recognize 
that a utility function is simply a convenient (and nonunique) 
way of expressing preferences over lotteries. Rather than 
working with utility functions, we could work explicitly with 
a density over preference functions (in fact, we will do this 
implicitly below). Unfortunately, the set of lotteries over 
which a preference ordering is defined is uncountable; there•
fore, some compact representation (of the individual prefer•
ence functions) is needed. But this is precisely the role of 

   4If the same transformation is applied to all functions with posi•
tive support, the MEEU decision is unchanged. 


DECISION THEORY                                                                                                                         287                                                               Extremum equivalence is thus sufficient to ensure commen-
                                                              surability, as it puts all utility functions on a common scale. It 
                                                              is important to realize that the scale dictated by the best and 
                                                              worst outcomes cannot vary, since these are truly best and 
                                                              worst outcomes; we return to this point below. It appears to 
                                                              be much more difficult to apply this type of argument to den•
                                                              sities over utility functions that are not extremum equivalent. 
                                                                 Fishburn [101 considers the problem of EEU when a deci•
                                                              sion maker is uncertain about the nature of the consequence 
                                                              sets she will face. He proposes foundational axioms that jus•
                                                              tify the use EEU to compare decisions. However, the setting 
Here the first step refers to a compound lottery over an con• is rather different: specifically, Fishburn requires that any 
tinuous set of component (simple) lotteries, while we assume  consequences that two utility functions have in common be 
in second step that a such a compound lottery can be reduced  ranked identically. In our context, where each utility function 
to a simple lottery in an analogous way to the reduction of a lies over the same consequence set, the Fishburn axioms im•
finite compounded lottery.                                    pose overly stringent requirements. It is interesting to note 
  Thus under the assumption that one can identify a best and  that Fishburn requires something akin to extremum equiva•
worst outcome, the MEEU decision rule can be justified for    lence, namely, that there exist two consequences common to 
use with normalized (extremum equivalent) utility functions   the domains of each utility function such that one of the con•
by appeal to the foundational axioms of decision theory, and  sequences is preferred to the other in each function. 
an interpretation of uncertainty over utility as a lottery over 
the lotteries defined by the component utility functions.     4 Dealing with Small Worlds 
  We now formalize the legitimacy of EEU and MEE. 
                                                              It is important to realize that the best and worst outcomes 
                                                              with which one calibrates must either be truly best and worst 
                                                              outcomes from the decision maker's standpoint, or they them•
                                                              selves must be calibrated. Using Savage's 117] terminology, 
                                                              we must be careful to distinguish "small worlds" reasoning 
                                                              from "grand worlds." Consider the case where the set of out•
                                                              comes is restricted to the subset of outcomes that are possible 
                                                              given the set of actions in a specific decision scenario. But 
                                                              assume there exist outcomes outside the domain of the re•
                                                              stricted scenario for which the user has concrete preferences. 
                                                              Let's refer to the set of restricted outcomes as local, while the 
                                                              space of all outcomes is global. 


288                                                                                                 DECISION THEORY                                                                Unfortunately, this condition is not equivalent to the MEEU 
                                                               rule in the original small worlds domain. Specifically, this 
                                                               condition cannot generally be assessed without having some 
                                                               assessment of the global tradeoff probabilities p1, etc. In 
                                                               other words, to accurately compare two small world out•
                                                               comes given uncertainty about the local utility functions, we 
                                                               have to explicitly assess our uncertainty about the range of 
                                                               values the local extrema can take with respect to the global 
                                                               utility function. Thus while one can generally use small world 
                                                               reasoning in the classic decision-theoretic setting, its use is 
                                                               problematic in the EEU framework. 


                                                               5 Consequences for Preference Elicitation 
                                                               The considerations above have implications for practical pref•
                                                               erence elicitation. From a foundational perspective, calibra•
                                                               tion of utilities relative to known best and worst outcomes is 
                                                               required if decisions are to be based on EEU. In the case of 
                                                               incremental elicitation, where EEU is used to determine value 
                                                               of information, we must first obtain a prior over a set of cx-
                                                               tremum equivalent utility functions before engaging in such 
                                                               deliberations. Fortunately, it often seems to make sense to 
                                                               determine best and worst outcomes beforehand, and engage 
                                                               in "serious" elicitation after this initial calibration. 
                                                                 Another important question: how does one determine pri•
                                                               ors over utility functions? Utility function databases [4] could 
                                                               be used. This poses some problems regarding interpersonal 
                                                               utility comparison for which there are no especially com•
                                                               pelling solutions. When using EEU, things are a bit worse: 
                                                               we need to construct priors conditioned on the observed or 


DECISION THEORY                                                                                                      289 