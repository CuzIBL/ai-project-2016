                               Theory of Alignment Generators
                                                  and
                      Applications to Statistical Machine Translation

                            Raghavendra Udupa U.         Hemanta K. Maji
                              IBM India Research Laboratory, New Delhi
                                   {uraghave, hemantkm}@in.ibm.com

                    Abstract                          Previous approaches to the Viterbi Alignment problem have
                                                      focussed on deﬁning a graph over all possible alignments
    Viterbi Alignment and Decoding are two fundamen-  where the connectivity is based on local modiﬁcations. The
    tal search problems in Statistical Machine Trans- best known algorithm for Decoding (both in terms of speed
    lation. Both the problems are known to be NP-     and translation quality) employs a greedy search algorithm.
    hard and therefore, it is unlikely that there exists However, these approaches can look at only polynomial num-
    an optimal polynomial time algorithm for either of ber of alignments in polynomial time.
    these search problems. In this paper we charac-   In this paper, we characterize exponentially large subspaces
    terize exponentially large subspaces in the solution of the solution space of Viterbi Alignment and Decoding. We
    space of Viterbi Alignment and Decoding. Each     propose polynomial time optimal dynamic programming al-
    of these subspaces admits polynomial time opti-   gorithms to solve Viterbi Alignment and Decoding when the
    mal search algorithms. We propose a local search  search space is restricted to a particular subspace. There are
    heuristic using a neighbourhood relation on these exponentially many such subspaces. So, we perform a local
    subspaces. Experimental results show that our al- search on these subspaces under a suitable neighbourhood re-
    gorithms produce better solutions taking substan- lation. Though, there is no polynomial bound on the number
    tially less time than the previously known algo-  of iterations of the local search, experiments show that our
    rithms for these problems.                        algorithms procduce better solutions in signiﬁcantly less time
                                                      than the current algorithms.
1  Introduction                                       We introduce the notion of an alignment generator in Sec-
                                                      tion 2. There are m! distinct alignment generators (where m
Statistical Machine Translation (SMT) is a data driven ap- is the length of the source language sentence). Each align-
                           [                 ] [
proach to Machine Translation Brown et al., 1993 , Al- ment generator (g , where 1 ≤ i ≤ m!) is associated with an
                 ] [               ]                                 i
Onaizan et al., 1999 , Berger et al., 1996 . Two of the fun- exponentially large subspace of alignments (A ). The solu-
                          [               ]                                                   i
damental problems in SMT are Brown et al., 1993 :     tion space of Viterbi Alignment and Decoding can be written
      a∗ = argmax P r (f, a|e) (ViterbiAlignment)     as the union of these subspaces. We next consider the graph
              a                                       induced on the set of Ais by a neighbourhood relation and
 (e∗, a∗) = argmax P r (f, a|e) P r (e) (Decoding)    perform local search on this graph. The explicit mathematical
             e,a
                                                      deﬁnition of Ai and the neighbourhood relation are presented
Viterbi Alignment has a lot of applications in Natural Lan- in Section 3. We present polynomial time optimal algorithms
guage Processing [Wang and Waibel, 1998], [Marcu and  for Viterbi Alignment and Decoding over a particular Ai (Sec-
Wong, 2002]. While there exist simple polynomial time al- tion 4 and Section 5 respectively). Experiments show that our
gorithms for computing the Viterbi Alignment for IBM Mod- search algorithms produce better solutions taking subtantially
els 1-2, only heuristics are known for Models 3-5. Recently, less time than current algorithms (Section 6).
[Udupa and Maji, 2005a] showed that the computation of
Viterbi Alignment is NP-Hard for IBM Models 3-5.      2   Preliminaries
Decoding algorithm is an essential component of all SMT IBM Models 1-5 assume that there is a hidden alignment be-
       [                    ] [                  ]
systems Wang and Waibel, 1997 , Tillman and Ney, 2000 , tween the source and target sentences.
[Och et al., 2001], [Germann et al., 2003], [Udupa et al.,
2004]. The problem is known to be NP-Hard for IBM Mod- Deﬁnition 1 (Alignment) An alignment is a  function
els 1-5 when the language model is a bigram model [Knight, a(m, l) : {1, . . . , m} → {0, 1, . . . , l}.
1999].
                                                      {1, . . . , m} is the set of source positions and {0, 1, . . . , l} is
Unless P = NP, it is unlikely that there exist polynomial
                                                      the set of target positions. The target position 0 is known
time algorithms for either Viterbi Alignment or Decoding.
                                                                                   (m, l)      (m, l)
Therefore, there is a lot of interest in ﬁnding fast heuristics as the null position. We denote a (j) by aj . The
                                                                                             (m, l)
to ﬁnd acceptable solutions for the problems.         fertility of the target position i in alignment a is φi =              
Pm       (m, l)                                       Lemma 1   If g(m) and g0(m) are two generators then g0(m)
  j=1 δ aj   , i . If φi = 0, then the target position i
                                                                        g(m)
is an infertile position, otherwise it is a fertile position. Let can be obtained from by a series of swap operations.
{k, . . . , k + γ − 1} ⊆ {1, . . . , l} be the longest range of con- Proof: Follows from the properties of permutations.
secutive infertile positions, where γ ≥ 0. We say that align-
      (m, l)                                          We can apply a sequence of Swap  operators to modify
ment a     has an infertility width of γ.                                 (m)     (m)
                                                      any given generator g   to g0  . The source position
Representation of Alignments: Since all source positions                (m)
that are not connected to any of the target positions 1, . . . , l rv (1 ≤ v ≤ m) in g corresponds to the source position v
                                                          (m)
are assumed to be connected to the null position (0), we can in g0 . For brevity, we denote a sequence vi vi+1 . . . vj by
represent an alignment, without loss of generality, as a set vj. The source sentence is represented by f m and the target
                              0                        i                                   1
of tuples {(j, aj) |aj 6= 0}. Let m = m − φ0. Thus, a sentence is represented by el .
sequence representation of an alignment has m0 tuples. By                    1
sorting the tuples in ascending order using the second ﬁeld
as the key, a(m, l) can now be represented as a sequence 3 Framework
    (m, l)       (m, l)          (m, l)
 j1, a     . . . jm0 , a  where the a    s are non-
     j1             jm0              jk               We now describe the common framework for solving Viterbi
decreasing with increasing k. Note that there are (l + 1)m Alignment and Decoding. The solution space for Viterbi
possible alignments for a given m, l > 0. Let a(m, l)                                g(m)
                                              (v,u)  Alignment can be written as ∪g(m) Al, l , and the solution
be the alignment {1, . . . , v} → {0, . . . , u} where all the tu-                                g(m)
                                                      space of Decoding can be approximated by ∪ (m) Aγ,? for
       (m, l)                 (m, l)                                                      g
ples j, aj    such that j > v or aj   > u have been   a large enough γ. The key idea is to ﬁnd the optimal solution
removed.                                              in an exponentially large subspace A corresponding to a gen-
                                                                   (m)           (m)
                                                      erator (A = Ag  and A = Ag    for Viterbi Alignment and
Deﬁnition 2 (Generator) A generator is a bijection g(m) :         l, l          γ,?
{1, . . . , m} → {1, . . . , m}.                      Decoding respectively). Given an optimal search algorithm
                                                      for A, we use Lemma 1 to augment the search space. Our
Representation of Generators: A generator g(m) can be framework is as follows
represented as a sequence of tuples (j1, 1) . . . (jm, m). Note               (m)
that there are m! different possible generators for a given 1. Choose any generator g as the initial generator.
m  > 0. The identity function g(m)(j) = j is denoted by 2. Find the best solution for the problem in A.
g(m).
 0                                                      3. Pick a better generator g0(m) via a swap operation on
Deﬁnition 3 (g(m) −→ a(m, l)) An alignment a(m, l) (with  g(m).
                  (m, l)       (m, l)
tuple sequence j1, a     . . . jm0 , a  ) is said to
                   j1             jm0                   4. Repeat steps 2 and 3 until the solution cannot be im-
be generated by a generator g(m) (with tuple sequence     proved further.
(k1, 1) . . . (km, m)) if j1 . . . jm0 is a subsequence of
k1 . . . km.                                          3.1  Algorithms
Note that the above deﬁnition does not take into account the Viterbi Alignment
infertility width of the alignment. Hence, we reﬁne the above
                                                      The  algorithm for ﬁnding  a  good  approximate so-
deﬁnition.
                                                      lution to  Viterbi Alignment  employs  a  subroutine
                 γ
Deﬁnition 4 (g(m) −→ a(m, l)) An alignment a(m, l) is said Viterbi For Generator to ﬁnd the best solution in
                                                                                                (m)
to be γ-generated by g(m), if g(m) −→ a(m, l) and the infer- the exponentially large subspace deﬁned by Ag . The
             (m, l)                                                                            γ, l
tility width of a is at most γ.                       implementation of this subroutine is discussed in Section 4.
             g(m)
Deﬁnition 5 (Aγ, l )
                                                      Algorithm 1 Viterbi Alignment
           (m)   n             γ        o
         Ag    =  a(m, l) | g(m) −→ a(m, l)                (m)    (m)
           γ, l                                        1: g   ←  g0  .
                                                       2: while (true) do
                        (m)                                  ∗(m, l)                          (m)  m  l 
Thus, for every generator g and integer γ ≥ 0 there is 3:   a      = Viterbi For Generator   g   , f1 , e1 .
                               g(m)             N                            0(m, l)
an associated family of alignments Aγ, l for a given l ∈ . 4: Find an alignment a with higher score by using
                                                                             ∗(m, l)
        g(m)       g(m)                                     swap operations on a   .
Further, Aγ,? = ∪l Aγ, l .                                      0(m, l)    
                          (m)                          5:   if a     = NIL  then
Swap   Operation:   Let  g     be  a  generator and           break
                      0                                6:           .
(j1, 1) . . . (jk, k) . . . (jk0 , k ) . . . (jm, m) be its tuple se- 7: end if
quence. The result of a SWAP operation on the kth and  8:   g(m) ← A generator of a0(m, l).
k0th tuples in the sequence is another tuple sequence
                      0                                9: end while
(j1, 1) . . . (jk0 , k) . . . (jk, k ) . . . (jm, m). The new tuple 10: Output a∗(m, l)
sequence deﬁnes a generator g0(m). The relationship between
any two generators is given by:                                                                                (m)
Decoding                                                            (m,l−s)    g
                                                      Theorem 1  If a      ∈ Aγ, l−s such that φl−s > 0 then
Our  algorithm for  Decoding  employs  a  subroutine                       (m)
                                                      it can be obtained from g by a series of SHRINK, MERGE
Decode For Generator  to ﬁnd the best solution in the                      0
                                     g(m)             and (γ, k)-GROW operations.
exponentially large subspace deﬁned by Aγ,? . The im-
plementation of this subroutine is discussed in Section 5.                                        (m)
                                                          Proof: WLOG we assume that the generator is g0 . We
                                                      provide a construction that has m phases. In the vth step, we
                                                      construct a(m, l−s) from g(v) in the following manner:
Algorithm 2 Decoding                                                  (v,u)     0
            (m)
 1: g(m) ← g   .                                                       (m, l−s)          (v−1)
            0                                           • We construct a     (v−1,u) from g0  and employ
 2: while (true) do                                                                           (m, l−s)
     
 ∗l  ∗(m, l)                         (m)  m       a SHRINK operation on the tuple (v, v) if av = 0.
 3:   e1 , a      = Decode For Generator  g    , f1 .
 4:  Find an alignment a0(m, l) with higher score by using             (m, l−s)          (v−1)
                                                        • We construct a     (v−1,u) from g0  and employ
     swap operations on a∗(m, l) and e∗l.
                                  1                       a MERGE  operation on the tuple (v, v) if φu > 1.
 5:  if  a0(m, l) = NIL then
                                                                          (m, l−s)
 6:    break.                                           • If φu = 1: Let a      (v,u) deﬁne φt = 0 for u −
 7:  end if                                               k ≤  t ≤ u − 1 and φu−k−1 > 0, where 0 ≤ k ≤ γ.
       (m)                0(m, l)
 8:  g    ←  A generator of a  .                                    (m, l−s)              (v−1)
                                                          Construct a               from g     and apply
 9: end while                                                               v−1,u−k−1      0
                                                          (γ, k)  ROW      (v, v)            (u−k  −1) =
10: Output e∗l.                                                -G     to the    tuple. (Note: If
           1                                              0, then consider the alignment where {1, . . . , v − 1} are
                                                          all aligned to the null position)

3.2  Theory of Generators                             As these are the only possibilities in the vth phase, at the end
                                                      of the mth phase we get a(m,l−s).
In this section, we prove some important results on genera- The dynamic programs for Viterbi Alignment and Decoding
tors.                                                 are based on ideas in Lemma 2 and Theorem 1.

Structure Transformation Operations                               (m) 
                                                                 g                           l
We deﬁne a set of structure transformation operations on Lemma 3 Aγ, l  is given by the coefﬁcient of x in
generators. The application of each of these operations on
                                                                                 m        
a generator modiﬁes the structure of a generator and pro-        αγ − 2            αγ  − 1
                                       1                                  (αγ − 2)          + 1       (1)
duces an alignment. Without loss of generality , we assume         x                αγ − 1
that the generator is the identity generator g(m) and deﬁne
                                      0                              Pγ     k+1
the structural transformation operations on it. The tuple se- , where αγ = 2 + k=0 x .
           (m)
quence for g0  is (1, 1) . . . (m, m). Given an alignment Proof: Refer [Udupa and Maji, 2005b]
           (j−1)
 (j−1,i)  g0
a      ∈ Aγ,i   with φi > 0, we explain the modiﬁcations           (m)                  m   
                                                                 Ag    = (γ + 1) (γ+1)(γ+3) +1
introduced by each of these operators to the jth tuple. Theorem 2  γ,?               γ+2
                               g(j−1)           g(j)
                    (j−1,i)     0       (j,i)    0        Proof: Substitute x = 1 in Equation 1
 1. SHRINK: Extend a       ∈ Aγ,i   to a    ∈ Aγ,i
             (j,i)                                    Decode For Generator  ﬁnds the optimal solution over all
    such that a  = 0.
             j                                                             g(m)
                                                      possible alignments in Aγ,? in polynomial time.
                              g(j−1)            g(j)
      ERGE          (j−1,i)    0       (j,i)     0
 2. M      : Extend a     ∈ Aγ,i    to a    ∈ Aγ,i                            (m) 
                                                                             g         m
             (j,i)                                    Theorem 3  For a ﬁxed l, Aγ, l = Ω (2 ).
    such that aj = i.                                                            
                                              g(j−1)      Proof: Refer [Udupa and Maji, 2005b]
 3. (γ, k)-GROW (0 ≤ k ≤ γ): Extend a(j−1,i) ∈ A 0
                                              γ,i     Viterbi For  Generator ﬁnds the optimal solution over all
                   g(j)            (j,i+k+1)
       (j,i+k+1)    0                                                      g(m)
    to a       ∈ Aγ,i+k+1 such that aj     = i+k+     possible alignments in A in polynomial time.
    1.                                                                     γ, l
                                                                        n             o
By removing the infertile positions at the end, we obtain the              (m)     (m)
                                                      Lemma 4   Let S =  g1   , . . . , gN be a set of genera-
following result:                                                                   (m)
                                                                              N    gi
                    (m)                               tors. Deﬁne span (S) = ∪i=1 Aγ=l, l. Let p(.) be a poly-
          (m, l)   g0
Lemma 2  a     ∈ Aγ, l and has at least one fertile posi- nomial. If l ≥ 2 and N = O (p(m)), then there exists an
                                     (m, l)                    (m, l)        (m, l)
tion iff there exists s such that 0 ≤ s ≤ γ, a (m, l−s) ∈ alignment a such that a 6∈ span (S).
  (m)
 g0
Aγ, l−s and φl−s > 0.                                     Proof: Refer [Udupa and Maji, 2005b]
                                                      This Lemma shows that by considering any polynomially
  1by permuting the given generator g(m) to the identity generator large set of generators we can not obtain the optimal solu-
 (m)
g0                                                    tions to either Viterbi Alignment or Decoding.4  Viterbi Alignment                                      If u − k − 1 = 0, then
We  now   develop the  algorithm for the  subroutine                                 v−1
                                                                   m − ϕ0    m−2ϕ0   ϕ0 Y
Viterbi For Generator  for IBM   Model 3.    Recall        s3,k =          p0      p1      t (fp|e0)
                                                                     ϕ0
that this subroutine solves the following problem:                                     p=1
                                                                                            u−1
       ∗(m, l)                m   (m, l) l                                                Y
      a      =   argmax   P r f1 , a    |e1 .                 × n (1|eu) t (fv|eu) d (rv|u, l, m) n (0|ep) .
                       (m)
                (m, l) g
               a    ∈Aγ, l                                                                p=u−k
Our algorithm has a time complexity polynomial in m and l. We choose that operation which gives the best score. As a re-
                                     (m)    (m)       sult, B (u, v, ϕ0, ϕ) now represents the best partial alignment
Without loss of generality, we assume that g = g0 .
         ∗(m, l)                                     so far and A (u, v, ϕ0, ϕ) represents its score. We have,
Note that a    (m, l−s) (where 0 ≤ s ≤ γ and φl−s > 0)
can be obtained from g0 using the structure transformation                              v  (v, u) u
operations described in Section 3.2. Therefore, we build the A (u, v, ϕ0, ϕ) = argmax P r f1 , a |e1
                                                                          (v, u) g(v)
Viterbi alignment from left to right. We scan the tuple se-              a    ∈Aγ, u
quence from left to right in m phases and in any phase we                φu=ϕ, φ0=ϕ0
determine the best structure transformation operation for that We determine A (u, v, ϕ0, ϕ) and B (u, v, ϕ0, ϕ), for all 0 ≤
                                                                                                       m
phase.                                                u ≤  l, 0 ≤ v ≤ m,  0 < ϕ  ≤ ϕmax and 0 ≤ ϕ0  ≤  2 .
                                              v
We consider all possible partial alignments between f1 and To complete the scores of the alignments, we multiply each
 u                                                                    Ql
e1 , such that φu =  ϕ  >   0 and φ0  =   ϕ0.   Let   A (u, m, ϕ0, ϕ) by      n (0|ep) for l − γ ≤ u ≤ l.
                                              v                         p=u+1
B (u, v, ϕ0, ϕ) be the best partial alignment between f1 and
 u                           2                        Let
e  and A (u, v, ϕ0, ϕ) be its score . Here, ϕ0 is the number
 1                                                          (ˆu, ϕˆ , ϕˆ) = argmax   A (u, m, ϕ , ϕ) .
of French words aligned to e0 in the partial alignment.         0                             0
                                                                       l−γ ≤ u ≤   l
The key  idea here is to compute  A (u, v, ϕ , ϕ) and                             m
                                          0                             0  ≤ ϕ0 ≤ 2
B (u, v, ϕ0, ϕ) recursively using Dynamic Programming. In               0  < ϕ ≤ ϕmax
the vth phase (corresponding to the tuple (v, v)), we consider
                                                      The Viterbi Alignment is, therefore, B (ˆu, m, ϕˆ0, ϕˆ).
each of the structure transformation operation.
                                                      4.1  Time Complexity
 1. SHRINK: If ϕ0  >  0, the SHRINK operation extends
    B (u, v − 1, ϕ0 − 1, φ) and the score of the resulting The algorithm computes B (u, v, ϕ0, ϕ) and A (u, v, ϕ0, ϕ)
                                                                                2    
    partial alignment is                              and therefore, there are O lm ϕmax entries that need to be
                                                      computed. Note that each of these entries is computed incre-
               s1 = cA (u, v − 1, ϕ0 − 1, ϕ)          mentally by a structure transformation operation.

                        p1 (m−2ϕ0+1)(m−2ϕ0+2)           • SHRINK  operation requires O (1) time.
    where c = t (fv|NULL) 2                 .
                        p0    (m−ϕ0+1)ϕ0
                                                        • MERGE  operation requires O (1) time.
 2. MERGE: If  ϕ  >  0, the MERGE  operation extends
                                                        • (γ, k)-GROW (0 ≤ k ≤ γ) operation requires O (ϕ )
    B (u, v − 1, ϕ0, ϕ − 1) and the score of the resulting                                           max
    partial alignment is                                  time for ﬁnding the best alignment and another O (1)
                                                          time to update the score3.
               s = cA (u, v − 1, ϕ , ϕ − 1)
                2               0                     Each iteration takes O (γϕmax) time. Computation of the
                                                                               2   2 
              n(ϕ|eu)φ                                tables A and B takes O lm γϕmax  time. The ﬁnal step
    where c =        t (fv|eu) d (rv|u, l, m).
             n(ϕ−1|eu)                                of ﬁnding the Viterbi alignment from the table entries takes
                                                                     4                            2     
 3. (γ, k)-GROW: Let                                  O (mγϕmax) time . Thus, the algorithm takes O lm γϕmax
                                                      time. In practice, γ and ϕmax are constants. The time com-
          0                                                                       2
         ϕ  = argmax B (u − k − 1, v − 1, ϕ0, k) .    plexity of our algorithm is O lm .
                 k
                                               0      4.2  Space Complexity
    (γ, k)-GROW  extends B (u − k − 1, v − 1, ϕ0, ϕ ) if
                                                                     2    
    ϕ =  1. If u − k − 1 > 0, the score of the resulting There are O lm ϕmax entries in each of the two tables.
    partial alignment is                              Assuming γ and ϕmax to be constants, the space complexity
                                                      of Viterbi For Generator is O  lm2.
                                         0
            s3,k = cA (u − k − 1, v − 1, ϕ0, ϕ )
                                                      IBM  Models 4 and 5  Extending this procedure for IBM
    where
                                                      Models 4 and 5 is easy and we leave it to the reader to ﬁg-
                                     u−1              ure out the modiﬁcations.
                                     Y                                   Q
     c = n (1|eu) t (fv|eu) d (rv|u, l, m) n (0|ep) .    3                u−1
                                                         Note: The product      n (0|ep) can be calculated incre-
                                    p=u−k                                 p=u−k
                                                      mentally for each k, so that at each iterationQ only one multiplication
                                                                                       v−1
  2                                                                                        (f |   )
   A naive implementation of the table B(∗, ∗, ∗, ∗) takes O (m) needs to be done. Similarly, the score p=1 t p NULL can be
size for each element. It can instead be implemented as a table of calculated incrementallyQ over the loop on v.
                                                         4          l
decisions and a pointer to the alignment that was extended to obtain The factor u+1 n (0|ep) can be calculated incrementally over
it. This makes the size of each entry O (1).          the loop of u. So, it takes O (1) time in each iteration.5  Decoding                                               We     put   the    new    hypothesis   in   to
                                                            v   k+1  k        
The algorithm for the subroutine Decode For Generator     H1   e   , e , ϕ0, 1, rv .
is  similar  in   spirit  to   the   algorithm  for   At the end of the phase, we retain only the best hypothesis
                                                               v   00 0
Viterbi For Generator.    We provide the details for  for each H1 (e , e , ϕ0, ϕ, ρ). After m phases, we append at
IBM Model 4 as it is the most popular choice for Decoding. most γ infertile words to all hypotheses in H. The hypothesis
We assume that the language model is a trigram model. with the best score in H is the output of the algorithm.
VE is the target language vocabulary and IE ⊂ VE is the
set of infertile words. Our algorithm employs Dynamic 5.1  Time Complexity
Programming and computes the following:               At the  beginning of  vth phase, there are at most
                                                                   
   ∗L  ∗(m,L)                    m   (m,L) L             2  2
   e1 , a      =     argmax    P r f1 , a    |e1      O  |VE|  v ϕmax  distinct partial hypotheses. It takes
                         (m)
                  (m,L)  g    L                                                 γ
                 a    ∈Aγ,? , e1                      O (1) + O (ϕmax) + O  (|IE| |VE| ϕmax) time to extend
     v  00 0                                          a hypothesis.   Therefore, the algorithm takes totally
Let H1 (e , e , ϕ0, ϕ, ρ) be the set of all partial hypotheses
                      v          00 0                       3    γ  3  2 
which are translations of f1 and have e e as their last two O |VE| |IE| m ϕmax time. Now, since |VE|, |IE|, ϕmax
words (ρ is the center of cept associated with e0 and ϕ > 0
                0                                     and γ are assumed to be constant, the time complexity of the
is the fertility of e ). Observe that the scores of all par-         3
                v  00 0                               algorithm is O m .
tial hypothesis in H1 (e , e , ϕ0, ϕ, ρ) are incremented by the
same amount thereafter if the partial hypotheses are extended 5.2 Space Complexity
with the same sequence of operations. Therefore, for every                              
  v    00 0                                                               O  |V |2 m2ϕ
H1 (v, e , e , ϕ0, ϕ, ρ) it sufﬁces to work only on the best In each phase, we need E max  space. Assuming
partial hypothesis in it.                             |VE| and ϕmax  to be constant, the space complexity is
The initial partial hypothesis is h0 (., ., 0, 0, 0) with a score of O  m2
  m                                                          .
p0 . Initially, the hypothesis set H has only one hypothe-
                                            (m)
sis, h0 (., ., 0, 0, 0). We scan the tuple sequence of g0 left Extending this procedure for IBM Models 3 and 5 is easy.
to right in m phases and build the translation left to right.
In the vth phase, we extend each partial hypothesis in H 6 Experiments and Results
by employing the structure transformation operations. Let
 v−1  00 0                                            6.1  Decoding
h1  (e , e , ϕ0, ϕ, ρ) be the partial hypothesis which is be-
ing extended.                                         We trained the models using the GIZA++ tool [Och, 2001] for
  • SHRINK:    We  create a  new  partial hypothesis  the translation direction French to English. For the current set
     v  00 0                                                              γ = 1     ϕ    = 10
    h1 (e , e , ϕ0 + 1, ϕ, ρ) whose score is the score of of experiments, we set and max     . To compare
     v−1  00 0                                        our results with those of a state of the art decoder, we used the
    h    (e , e , ϕ0, ϕ, ρ) times
     1                                                Greedy decoder [Marcu and Och, 2004]. Our test data con-
                    p1 (m − 2ϕ0 − 1) (m − 2ϕ0)        sisted of a corpus of French sentences with sentence length in
        t (fv|NULL)  2                       .
                   p0     (m − ϕ0) (ϕ0 + 1)           the range 06 − 10, 11 − 15, . . . , 56 − 60. Each sentence class
    We    put    the   new     hypothesis  in    to   had 100 French sentences. In Table 1, we compare the mean
      v  00 0                                         logscores (negative logarithm of the probability) of each of
    H1 (e , e , ϕ0 + 1, ϕ, ρ).
                                                      the length classes. Lower logscore indicates better probabil-
  • MERGE:     We  create a  new  partial hypothesis
     v  00 0                                          ity score. We observe that the scores for our algorithm are
    h1 (e , e , ϕ0, ϕ + 1, ρ) whose score is the score
       v−1   00 0                                     (20%) better than the scores for Greedy algorithm. In the
    of h1  (e , e , ϕ0, ϕ, ρ) times                   same table, we report the average time required for decoding
                n (ϕ + 1|e0)      d                   for each sentence class. Our algorithm is much faster than the
                          t (f |e0) new .
                       0      v                       Greedy algorithm for most length classes. This demonstrates
                  n (ϕ|e )        dold
                                                      the power of our algorithm to search an exponentially large
    Here, dold is the distortion probability score of the last subspace in polynomial time.
    tableau before expansion,  is the distortion prob-
                           dnew                       We compare the NIST and BLEU scores of our solutions with
    ability of the expanded hypothesis after r is inserted
                                        v             the Greedy solutions. Our NIST scores are 14% better while
    into the tableau and ρ0 is the new center of the cept
                                                      our BLEU scores are 16% better than those of the Greedy
    associated with e0. We put the new hypothesis into
      v  00 0           0                             solutions.
    H1 (e , e , ϕ0, ϕ + 1, ρ ).
                                   (1)     (k)
  • (γ, k)-GROW: We choose k words e , . . . , e from 6.2  Viterbi Alignment
                       (k+1)
    IE and one word   e      from VE.   We create a   We compare our results with those of local search algorithm
                         v   0 (1)                   of GIZA++  [Och, 2001]. We set γ = 4 and ϕ   =  10.
    new partial hypothesis h1 e , e , ϕ0, 1, rv if k = 0,                                       max
     v   (k) (k+1)                                   The initial generator for our algorithm is obtained from the
    h1 e   , e   , ϕ0, 1, rv otherwise. The score of this
                           v−1  00 0                  solution of the local search algorithm.
    hypothesis is the score of h1 (e , e , ϕ0, ϕ, ρ) times In Table 3, we report the mean logscores of the alignments
                                             k        (for each length class) found by our algorithm and the local
                                   0        Y
    n (1|ek+1) t (fv|ek+1)d (rv − ρ|A (e ) , B (fv)) n (0|ep)search algorithm. Our scores are about 5% better than those
                                            p=1       of the local search algorithm.