                              Deploying Information Agents on the Web 

                                                  Craig A. Knoblock 
                                          University of Southern California 
                       Information Sciences Institute and Computer Science Department 
                                                 4676 Admiralty Way 
                                          Marina del Rey, CA 90292, USA 
                                                  knoblock@isi.edu 

                        Abstract                                 We have developed a set of core technologies to simplify 
                                                               the task of building intelligent agents for gathering and mon•
     The information resources on the Web are vast, but 
                                                               itoring information on the Web [Knoblock et al, 2003; 2001; 
     much of the Web is based on a browsing paradigm 
                                                               Barish and Knoblock, 2()02al. The technologies include the 
     that requires someone to actively seek information. 
                                                               ability to gather information from the Web, to link that infor•
     Instead, one would like to have information agents 
                                                               mation with related information, to build plans to integrate 
     that continuously attend to one's personal informa•
                                                               the various sources of data, and to efficiently execute these 
     tion needs. Such agents need to be able to extract 
                                                               plans in the Web environment. We have applied these tech-
     the relevant information from web sources, inte•
                                                               nologies to build agents for a variety of applications [Barish 
     grate data across sites, and execute efficiently in 
                                                               et al, 2000; Ambite et a/., 20021, including an application for 
     a networked environment. In this paper I describe 
                                                               monitoring travel plans from online sources. 
     the technologies we have developed to rapidly con•
                                                                 Researchers have developed a variety of agents that have 
     struct and deploy information agents on the Web. 
                                                               been deployed on the Web over the years. Some notable sys•
     This includes wrapper learning to convert online 
                                                               tems include the Internet Softbot [Etzioni and Weld, 1994], 
     sources into agent-friendly resources, query plan•
                                                               an agent that interacts with a range of Internet resources, Bar-
     ning and record linkage to integrate data across 
                                                               gainFinder [Krulwich, 19961, a comparison shopping agent 
     different sites, and streaming dataflow execution 
                                                               for CDs, ShopBot [Perkowitz et a/., 19971, a system for au•
     to efficiently execute agent plans. I also describe 
                                                               tomatically locating and incorporating new stores into a com•
     how we applied this work within the Electric Elves 
                                                               parison shopping agent, and Warren [Decker et al, 1997], a 
     project to deploy a set of agents for continuous 
                                                               system for gathering data on a financial portfolio. There has 
     monitoring of travel itineraries. 
                                                               also been a significant amount of research on the underly•
                                                               ing technologies required for developing agents on the Inter•
1 Introduction                                                 net [Levy and Weld, 2000]. As noted by Etzioni [1996], the 
                                                               Web provides a tremendous opportunity for building intelli•
There is a tremendous amount of information available on the 
                                                               gent software agents. Yet, surprisingly few have seized this 
Web, but the access to this information is largely dependent 
                                                               opportunity. This is almost certainly because there are many 
on the information providers. The individual web sites de•
                                                               technical issues that must be addressed to build such agents. 
cide what information to provide to the visitors to their site 
                                                               Our work is designed to address these issues and simplify the 
and how a visitor will access that information. There is little 
in the way of capabilities to combine information across sites task of building agents for the Web. 
and only the most primitive capabilities to monitor informa•     In this paper I first describe an example set of agents for 
tion on individual sites. Of course, sites may provide inte•   monitoring travel plans. Then 1 will briefly describe the tech•
grated access to specific data sources or sophisticated mon•   nologies that we have developed to gather data from web 
itoring capabilities on their data, but users of the Web are   sources, link data across sources, generate plans to integrate 
dependent on a site to make these capabilities available.      the data, and efficiently execute these plans. Finally, I present 
                                                               directions for future research and conclusions. 
   In contrast, imagine a world where access to information 
is driven by the consumers of the data. Where it is not only 
possible, but simple to task your own personal information     2 Information Agents for Monitoring Travel 
agents to gather specific information, monitor for changes in  As part of the Electric Elves project [Chalupsky et a/., 2001; 
the gathered data, and to notify you of important information  Ambite et al., 20021 we have applied our agent technologies 
or changes. The challenges are that the required information   to build a set of agents for various tasks including tracking 
is often embedded in HTML pages, the data is organized in      visitor schedules, monitoring meeting schedules, and moni•
different ways on different sites, there are a huge number of  toring a user's travel plans. In the case of monitoring travel 
ways the information could be combined, and it can be slow     plans, this task is particularly well-suited for applying agent 
and cumbersome to combine the information.                     technology for several reasons: a) this is a fairly compli-


1580                                                                                                INVITED SPEAKERS cated task with many possible forms of failure ranging from         price, address, phone number, latitude, longitude, and 
flight cancellations and schedule changes to hotel rooms be•        distance from the user's location. 
 ing given away when a traveler arrives late at night, b) there  These agents are scheduled to run at regular intervals, 
are a large number of online resources that can be exploited   where the agents are woken up to perform their task. The 
to anticipate problems and keep a traveler informed, and c)    agents can cancel their own task once it is complete and can 
these tasks would be tedious and impractical for a human to    change the interval in which they are run based on the in•
perform with the same level of attention that could be pro•    formation from other agents. The agents often invoke other 
vided by a set of software agents.                             agents to help them perform their tasks For example, the 
   To deploy a set of agents for monitoring a planned trip, the flight-status agent calls another agent that extracts the flight 
user first enters the travel itinerary and then specifies which status information directly from a web site and it invokes the 
aspects of the trip she would like to have the agents monitor. hotel notification agent, which in turn sends a message to the 
A set of information agents are then spawned to perform the    fax agent. 
requested monitoring activities. For the travel planning appli•  Figure 1 shows the messages that various agents generated 
cation, we developed the following set of agents to monitor a  during actual use of the system. The original set of agents 
trip:                                                          were in use for about a year and then based on feedback and 
   • A airfare-monitoring agent that tracks the current price  requests from the users we recently developed a new set of 
     of a flight itinerary. The agent sends a notification on  agents that provide improved capabilities. 
     price increases and/or decreases. A traveler might con•
     sider retickcting if the price drops significantly below  (a) Airfare-Monitoring Agent: Airfare dropped message 
     what they paid. 
                                                               The airfare tor your American Airlines itinerary (IAD - LAX) dropped to $281. 
   • A schedule-change agent that keeps track of the pub•      (b) Schedule-Change Agent: 
     lished schedule for a given flight itinerary and notifies The schedule of your United Airlines flight 1287 has changed from 7:00 PM to 
     a traveler of any change to this itinerary. Small sched•  7:31 PM. 
     ule changes occur quite frequently, especially if one pur• (c) Flight-Status Agent: Flight delayed message 
     chases tickets well in advance of a flight. Travel agents Your United Airlines flight 190 has been delayed. It was originally scheduled 
     are supposed to notify their customers of changes, but    to depart at 11:45 AM and is now scheduled to depart at 12.30 PM. The new 
     one usually arrives at the airport before discovering that arrival time is 7.59 PM. 
     the scheduled departure time has changed.                 (d) Flight-Status Agent: Flight cancelled message 
   • A flight-status agent that continually monitors the status Your Delta Air Lines flight 200 has been cancelled 
     of a flight. When a change of status or cancellation is   (e) Flight-Status Agent: Fax to a hotel message 
     detected, the traveler is immediately notified. This agent Attention : Registration Desk 
     also sends a fax to the hotel if the flight arrival is de• I am sending this message on behalf of David Pynadath, who has a reservation 
     layed past 5pm in order to ensure that the hotel room     at your hotel. David Pynadath is on United Airlines 190, which is now scheduled 
     is held for the traveler. This agent differs from what is to arrive at IAD at 7.59 PM. Since the flight will be arriving late, I would like to 
     available from commercial sites, such as ual.com, which   request that you indicate this in the reservation so that the room is not given 
     simply check the status a fixed period of time prior to the away 
     flight. In contrast, our agents maintain state and can no• (f) Earlier-Flight Agent: 
     tify the user of multiple status changes without sending  The status of your currently scheduled flight is' 
     messages that provide no new information.                 # 190 LAX (11.45 AM) - IAD (7:29 PM) 45 minutes Late 
                                                               The following United Airlines flight arrives earlier than your flight' 
     An earlier-flight agent that checks for flights that leave # 946 LAX (8:31 AM) - IAD (3.35 PM) 11 minutes Late 
     before the scheduled flight. It also checks the status of (g) Flight-Connection Agent: 
     these flights to avoid suggesting delayed or cancelled    Your connecting United Airlines flight 925 will depart at 9:45 PM (25 minutes 
     flights. This agent is particularly handy when one fin•   late) at gate C6. 
     ishes a meeting early or one wants to skip out of a par•  (h) Restaurant-Finding Agent: 
     ticularly boring meeting.                                 These are the five closest restaurants from your location. 
     A flight-connection agent that monitors a users sched•    Wingmaster's on I St. American, 1825 I St NW, 202-429-0058, $5-10, Lar 
     uled flights and if there is a connecting flight it wakes up 38.90111, Lon: -77.04158, 0.23 miles 
     a few minutes before the projected landing time, checks 
     the status and gate information of the connecting flight 
     and also searches for any earlier flights to the same des•    Figure 1: Actual messages sent by monitoring agents 
     tination that the user might be able to take instead. This 
     agent is particularly useful when there are only a few 
     minutes to make an earlier connection that is about to    3 Gathering Data from Web Sources 
     depart.                                                   A key capability for information agents is the ability to reli•
     A restaurant-finding agent that locates the nearest restau• ably access information. As the Web moves towards XML 
     rant based on the user's GPS location. On request, it sug• and Web Services, accessing data could become greatly sim•
     gests the five closest restaurants providing cuisine type, plified. However, movement in this direction has been quite 


INVITED SPEAKERS                                                                                                     1581 slow and for various reasons many sources will remain avail•
able only in HTML, so there is still a critical need to turn 
HTML sources into agent-enabled sources. 
  The challenge in building wrappers for online sources is 
how to achieve broad coverage and high accuracy with min•
imal user input. The two general approaches to this problem 
are supervised machine learning techniques [Kushmerick, 
1997; Muslea et al, 2001; Hsu and Dung, 1998] and unsu•
pervised grammar induction techniques [Lerman et al., 2001; 
Crescenzi et al, 2001; Hong and Clark, 2001]. The unsuper•
vised grammar induction techniques have the advantage of 
no user input, but they are not able to handle the full range 
of semistructured sources. In contrast, the supervised learn•
ing techniques apply to a wider set of sites, but can require a 
significant amount of labeled data to achieve high accuracy. 
  We developed an machine learning algorithm called    Figure 2: Wrapper induction, verification, and reinduction 
Stalker [Muslea et al., 2001] that requires labeled data, but process 
attempts to minimize the amount of information that must be 
provided by a user. Given labeled data, the system employs 
a greedy set covering algorithm to learn extraction rules that pair wrappers by learning a description of the content ex•
define a wrapper for a source. We minimize the amount of tracted by a wrapper [Lerman et al, 2003]. This approach 
labeled data required by decomposing the learning problem learns a pattern by using a hierarchy of pattern types, such as 
into a number of simpler subproblems, which require fewer number or capitalized word, and then learning a description 
examples to learn. The decomposition is based on the hier• of the beginning and ending of the information that is being 
archical structure of the information in a web source. This extracted. The resulting description or learned patterns are 
approach allows Stalker to learn how to extract data from then stored and compared to the information being extracted. 
complicated sites that involve lists of information and even The patterns are compared statistically to avoid false positives 
arbitrary nesting of embedded lists.                  due to examples that have not been seen before. In a large test 
  An issue for any learning system, even Stalker, is that to set, this approach was able to identify 95% of the Web sites 
achieve high accuracy the system must see the right set of ex• that had changed. 
amples. Since the expectation in a wrapper is to extract the Once the system has identified a source that has changed, 
data with 100% accuracy, finding a representative set of ex• the learned patterns can then be used to automatically rela•
amples is a critical part of the problem. Rather than relying bel the site and run the labeled examples through Stalker, the 
on the user to identify these examples, we developed an active wrapper learning system. The wrapper learning, validation, 
learning technique called Co-Testing [Muslea et al., 2000; and reinduction process are illustrated in Figure 2. 
Muslea, 2002; Muslea et al., 2003] that selects the most in•
formation examples to label. Co-Testing works by learning 4 Linking Information 
multiple classifiers using different views of the same problem. 
In the case of wrapper learning, the system exploits the fact Once data has been extracted from a web site, then one fre•
that it can learn equally well a classifier by finding landmarks quently needs to combine it with other information in order 
from the beginning of the page or by finding landmarks from to perform some task. For example, if one wants to build an 
the end of the page. The system can then exploit the fact that agent for recommending nearby restaurants, then one might 
both classifiers should agree if they have learned the same want to combine the data on a restaurant review site with the 
concept and any disagreement provides a source of training department of health site to ensure that the restaurant has an 
examples. Both classifiers are applied to the unlabeled exam• adequate health rating. The problem is that the information 
ples and the user is asked to label the examples where there on these two distinct sites will often refer to the restaurants in 
is disagreement. This allows the system to quickly identify different ways - the name, address, and phone number may 
the unusual cases in the data set to rapidly converge on an all have slight variations that preclude simply joining the two 
accurate set of extraction rules.                     sites across a single attribute. 
  Another important challenge building wrappers is to ensure To address this problem, we developed a machine learn•
that they continue to work properly over time. This problem ing approach to record linkage [Tejada et ai, 2002; 2001]. In 
has not received much attention. The exception is the work this approach the system, called ActiveAtlas, compares the 
by Kushmerick [2000] who developed an approach that uses attributes that are snared across the two data sets and learns 
the global properties of a page, such as the density of HTML two things. First, it uses a committee of decision tree learn•
tokens on a page, to determine when the page or even the spe• ers to decide whether two records are matched based on the 
cific information being extracted has changed. The limitation strength of the match of the various attributes (Figure 3). Sec•
of this approach is that it is too coarse to detect some sites ond, it improves the accuracy of these matches by learning an 
that have changed [Lerman et al., 2003].              appropriate set of weights on a library of transformation rules 
  We developed a wrapper maintenance system that can re- (Figure 4). ActiveAtlas takes an active learning approach to 


1582                                                                                   INVITED SPEAKERS Figure 3: Active Atlas learns which attributes are important to 
decide whether two records should be linked 


Figure 4: ActiveAtlas also learns the weighting of the trans-
formation rules for an application 
                                                      Figure 5: Planning by Rewriting searches through the space 
                                                      of possible transformations on a plan 
select examples for the user to label in order maximize the ac•
curacy of the matches and minimize the amount of user input. vice infrastructure provides access to online sources in a form 
Compared to other approaches to this problem [Cohen, 2000; with which agents can interact without having to construct a 
Sarawagi and Bhamidipaty, 2002], the combination of the wrapper for a site. In addition, the Semantic Web provides 
transformation weight learning and the active learning of the semantic-level descriptions of the services that are available 
rules allows the system to achieve very high accuracy in [Ankolenkar et al, 2002]. Our approach to integration plan•
matching entities.                                    ning builds on previous work on data integration [Levy, 2000] 
                                                      and applies the inverse rules approach of Duschka [1997]. 
5 Planning to Integrate Sources                         One challenge is that the sources available online often 
Once an agent has access to the sources and can link the data have restrictions on how they can be accessed in that cer•
across sources, the problem remains how to compose a set of tain inputs may be required to access a source. In the in•
information sources to perform some task. We developed an verse rules framework this means that computing a complete 
approach to automatically planning the integration of these set of answers to a query may require recursion. Since it can 
sources to answer queries. In this approach, which is im• be expensive to execute integration plans in a language such 
plemented in the Ariadne information mediator [Knoblock et as Datalog, we have developed an approach to automatically 
al, 1998; 2001], the contents of the sources available to the convert the recursive plans produced by the inverse rules al•
system are described using a common model [Ambite et al, gorithm into a streaming dataflow execution framework that 
2001]. The system uses this model to create a plan that spec• can efficiently execute these plans [Thakkar and Knoblock, 
ifies both the data sources and the specific operations to be 2003]. This execution framework is described next. 
performed to satisfy a request. 
  One of the interesting problems is that due to the large 6 Executing Plans 
search space and the need to optimize the plans, traditional Given a plan for performing some task on the Web, an agent 
planning techniques do not scale. To overcome this problem needs to be able to efficiently execute this plan. In the Web 
we developed a general-purpose planning approach, called environment, sources can be quite slow and the latencies of 
Planning by Rewriting [Ambite and Knoblock, 2001], and the sources are also unpredictable since they can be caused by 
we use it as the planner for Ariadne [Ambite and Knoblock, heavy loads on both servers and networks. Since the primary 
2000]. In Planning by Rewriting, the system starts with an bottleneck of most agent plans on the web is retrieving data 
initial, but suboptimal plan, and then the planner performs from online sources, we would like to execute information 
a local search through the space of plan transformations to requests as early as possible. To address these issues, we have 
maximize the given evaluation criterion. In the query plan• developed a streaming dataflow language and executor, called 
ning application, the planner searches through the space of Theseus [Barish and Knoblock, 2002a], which is optimized 
sources and the operations on these sources to find an effi• for the Web environment in the following three ways. First, 
cient way to process a query. Figure 5 shows a simple exam• since the executor is based on a dataflow paradigm, actions 
ple of how Planning by Rewriting searches through the space are executed as soon as the data becomes available. Second, 
of plan transformations. Researchers have explored a variety Theseus performs the actions in a plan in separate threads, so 
of approaches to this general problem of planning for infor• they can be run asynchronously and in parallel. Third, the 
mation gathering (see [Lambrecht and Kambhampati, 1997] system streams the output from one action to the next so that 
for a summary of this work).                          sequential operations can be executed in parallel. 
  We are currently exploring planning techniques for com• Theseus is similar to network query engines, such as Tele•
posing Web Services [Thakkar et al, 2003]. The Web Ser- graph [Hellerstein et al, 2000] or Tukwila [Ives et al, 2002], 


INVITED SPEAKERS                                                                                     1583                                                                                    confirmations 

Figure 6: Example plan for integrating data from three car- Figure 7: Augmented plan for speculative execution 
related sites 
                                                       7 Future Directions 

in that they are also streaming dataflow execution systems. Given the growing interest in both Web Services and the Se•
However, the network query engines focus on the efficient mantic Web [Hendler, 2001 ], we believe it will become easier 
execution of of XML queries, while Thesues provides an ex• to rapidly create and deploy agents on the Web. As more se•
pressive language for expressing information gathering and mantic information becomes available about online sources, 
monitoring plans. The Theseus language supports capabili• we plan to exploit this information to automatically discover 
ties that go beyond network query engines in that it supports and integrate new sources of information. Similarly, as web 
recursion, notification operations, and writing and reading services become available that can support transactions, we 
from databases to support monitoring tasks.           plan to move beyond gathering and monitoring of online 
                                                       sources to build agents that perform more complex tasks, such 
  Recently we developed an approach to increase the po• as not just finding the lowest price ticket, but also purchasing 
tential parallelism in a streaming dataflow execution sys• it. 
tem. This optimization technique, called speculative execu• There are many possible uses of agents for retrieving and 
tion [Barish and Knoblock, 2002b; 2003J, attempts to predict monitoring data from online sources. Ideally, users could de•
the results of an operation based on data and patterns that it fine their own tasks that they want an agent to perform. For 
has seen in the past. The predicted results can then be used to example, I might want an agent that monitors airfares and no•
speculate about the operations that will need to be performed tifies me the moment 1 can buy a ticket to Hawaii for less 
later in the plan. The system decides where to speculate by then $300. Someone else might want an agent to monitor for 
analyzing a plan and determining the critical paths. On these travel delays in their connecting airport and notify them when 
paths it then inserts a "speculate" operation, which uses in• the average delay exceeds 30 minutes. The possibilities arc 
put to earlier operations to predict the input to later opera• endless. We are currently working on what we call an Agent 
tions. The system also inserts a "confirm" operation, which Wizard, which allows the user to define new agents for mon•
ensures that the final result is correct regardless of whether the itoring tasks simply by answering a set of questions about 
prediction is correct. This approach to optimizing streaming the task. The resulting system will work similar to the Excel 
dataflow plans can achieve arbitrary speedups by speculating Chart Wizard, which converts numerical data into charts by 
on the speculations. If the system is able to make accurate asking the user a set of questions. The Agent Wizard will au•
predictions, the executor could speculate on all of the input, tomatically build the corresponding Theseus plan and sched•
execute the entire plan in parallel, and then confirm all of the ule the monitoring task for the user. 
results.                                                Another exciting direction is to deploy agents to collect and 
  Figure 6 shows an example agent plan for integrating car- learn about online data and then use the results to make pre•
related data from three online sources. This plan first uses the dictions about the world. For example, we recently developed 
Edmunds.com site to find the midsize cars priced between a system called Hamlet that advises a user about whether they 
$4000 and $12000. Next it selects out those cars made by should immediately buy a ticket on a particular flight or wait 
Oldsmobile. Then for each of those cars, in parallel it calls for a possible drop in the price [Etzioni et al, 20031. Hamlet 
both the NHTSA site to get safety reports and the Consumer makes these recommendations by collecting data on the cur•
Guide site to retrieve car reviews. Finally, all of this infor• rent pricing of flights on a particular route and then learning 
mation is combined into a single report. Figure 7 shows an a model of the pricing in order to make predictions about fu•
abstract version of the same plan with the speculation opera• ture price behavior. In a simulation using real data, Hamlet 
tions inserted into the plan. The use of speculative execution was able to save 607 simulated passengers $283,904, which 
in this plan makes it possible to invoke all three web sites in was 88.6% of the savings possible with complete knowledge 
parallel.                                             of the future price changes. Hamlet provides a compelling 
                                                      example of the potential of information agents. 
  The effectiveness of the speculation technique depends on 
making accurate predictions. We have developed a learning 
system that uses decision tree learning to make predictions 8 Conclusion 
on similar inputs and transducer learning to discover patterns The World Wide Web provides a tremendous opportunity for 
in Web navigation paths. The learning system is described in Al researchers to build, deploy and test software agents. The 
more detail in [Barish and Knoblock, 2003].           Web provides a real world environment that sidesteps many 


1584                                                                                   INVITED SPEAKERS 