  Compound       Effects   of Top-down      and  Bottom-up      Inﬂuences    on  Visual   Attention
                                   During    Action   Recognition
                               Bassam   Khadhouri   and  Yiannis Demiris
                          Department  of Electrical and Electronic Engineering
                                        Imperial College London
                                  Exhibition Road,  London  SW7   2BT
                         Email: {bassam.khadhouri,   y.demiris}@imperial.ac.uk

                    Abstract                          it results in a faster recognition of the correct behaviour being
                                                      demonstrated in the action understanding model.
    The limited visual and computational resources
    available during the perception of a human ac-
    tion makes a visual attention mechanism essential. 2  Background
    In this paper we propose an attention mechanism   Work in cognitive science suggests that the control inputs to
    that combines the saliency of top-down (or goal-  the attention mechanism can be divided into two categories:
    directed) elements, based on multiple hypotheses  stimulus-driven (or “bottom-up”) and goal-directed (or “top-
    about the demonstrated action, with the saliency of down”) [Van Essen et al., 1991]. A number of bottom-up
    bottom-up (or stimulus-driven) components. Fur-   attention models follow Treisman’s Feature Integration the-
    thermore, we use the bottom-up part to initialise the ory [Treisman and Gelade, 1980] by calculating the saliency
    top-down, hence resulting in a selection of the be- for different low-level features of the object, e.g. colour, tex-
    haviours that rightly require the limited computa- ture or movement. A winner-take-all approach is then used
    tional resources. This attention mechanism is then to decide on the most salient part of the scene (as in [Koch
    combined with an action understanding model and   and Ullman, 1985], [Itti et al., 1998], [Breazeal and Scassel-
    implemented on a robot, where we examine its per- lati, 1999]). Top-down, on the other hand, covers the goal-
    formance during the observation of object-directed directed factors, essentially the task-dependent part of the vi-
    human actions.                                    sual attention model. Wolfe [Wolfe and Gancarz, 1996] pro-
                                                      duced a biologically inspired Guided Search Model that con-
                                                      trols the bottom-up features that are relevant to the current
1  Introduction                                       task by a top-down mechanism, through varying the weight-
In an attempt to arrive at a deﬁnition for attention, Tsotsos, ing of the feature maps. However, it is not clear what the task
in his review paper [Tsotsos, 2001], arrives at the following relevant features are, particularly in the case of action recog-
proposal: “Attention is a set of strategies that attempts to re- nition.
duce the computational cost of the search processes inherent Our attention mechanism is inspired by Wolfe’s model,
in visual perception”. Our work aims at producing a model of and integrates bottom-up elements with a top-down mecha-
visual attention for dynamic scenes, emphasising the impor- nism using behaviours1 and forward models that can guide
tance of top-down knowledge in directing the attention during the robot’s attention according to the current task. A forward
action recognition.                                   model is a function that, given the current state of the sys-
  After introducing the two different (bottom-up and top- tem and a control command to be applied on it as given by
down) elements of attention, we will proceed to review a the behaviour, outputs the predicted next state. Our top-down
model of action understanding [Demiris and Johnson, 2003] part of the attention model, when observing a demonstration,
that will make use of our attention model, to correctly allo- will make a prediction of the next state for a number of dif-
cate the limited resources available to it. Subsequently, we ferent possible behaviours, producing a conﬁdence value for
will proceed to describe how the multiple hypotheses gener- each, based on the observed accuracy of the prediction. These
ated by our model while the human demonstration is unfold- conﬁdence levels are important values that can be thought of
ing can feed top-down signals to the attention mechanism to as saliencies for the top-down mechanism of our attention
direct attention to the important aspects of the demonstration. model, hence producing a principled method of quantifying
  Furthermore, we propose a method for initialising the top- the top-down part of the attention mechanism.
down part, using the saliency of the bottom-up part in our vi- In the experimental section, we will demonstrate that this
sual attention mechanism. We have implemented our model attention mechanism improves performance on action under-
on an ActivMedia Robot, running experiments observing a standing mechanisms that use multiple behaviours and for-
human acting upon various objects. These results will be pre-
sented and discussed, not only in terms of whether our atten- 1Also known as controllers or inverse models in the control liter-
tion model allocates the resources correctly, but also to see if atureFigure 1: Action understanding model [Demiris and Johnson,
2003].                                                Figure 2: Our Bottom-up model of Visual Attention. The
                                                      output is the Focus of Attention (FOA)
ward models such as [Demiris and Johnson, 2003]. This will
be done in two ways: ﬁrst by cutting down the number of 4 The  Attention Mechanism
computational cycles required for identifying the correct be-
haviour and by directing the limited computational resources In this section we will describe the design of our attention
to the relevant parts of the human demonstration, instead of mechanism, and the integration of both bottom-up and top-
the whole scene. Secondly, by using the saliency from the down elements.
bottom-up part of our visual attention mechanism to initialise
the top-down part, enabling it to select only the relevant be- 4.1 Bottom-up
haviours to the demonstrated action, instead of activating and We have implemented a bottom-up model that is mainly
running all of them.                                  based on Wolfe’s biologically inspired Guided Search 3.0
                                                      model of human visual attention and visual search [Wolfe and
3  Action  Understanding    Model                     Gancarz, 1996]. This model uses Treisman’s Feature Integra-
                                                      tion theory [Treisman and Gelade, 1980] to construct a model
Demiris’s action understanding model [Demiris and Johnson,
                                                      of human visual attention. In this model, low-level ﬁlters are
2003], shown in ﬁgure 1, identiﬁes the correct behaviour
                                                      applied to various visual stimuli in order to produce individ-
that is being observed by using forward models for a num-
                                                      ual feature maps in which high values indicate areas of inter-
ber of behaviours. By predicting what will happen next, and
                                                      est.
comparing it with what actually does happen next (from the
                                                        All of the individual feature maps are weighted and then
behaviour that is being demonstrated), conﬁdence levels are
                                                      summed  into a single activation map. Attention is guided to
generated for each of the predicted behaviours. From these,
a winner is selected by picking the predicted behaviour with peaks in the activation map, because these represent the most
                                                      salient areas in the scene. In our model, top-down task infor-
the highest conﬁdence level.
                                                      mation can inﬂuence the bottom-up feature maps by chang-
  The attention mechanism we propose in this paper can be
                                                      ing the activation map through the modifying of the weights
used to cut computational costs on this action understand-
                                                      that are applied before the summation. Our model is shown
ing model [Demiris and Johnson, 2003]. It would be far too
                                                      in ﬁgure 2. There are certain features that can make objects
computationally expensive to direct the attention of the ob-
                                                      salient. For example, brightly coloured objects are a most
server towards all the parts of the demonstration to satisfy all
                                                      typical example, or if they are moving in a way that can attract
the possible behaviours [Tsotsos, 1989]. Hence, the atten-
                                                      attention, e.g a sudden, irregular and fast movement. Each of
tion mechanism is used to restrict this, giving only one of the
                                                      the bottom-up blocks in the model represents a certain fea-
behaviours at a time the information it requires. Using this
                                                      ture that contributes towards the calculation of the saliency of
attention mechanism, we managed to cut down substantially
                                                      an object. Our implementation focuses on three bottom-up
on the computational costs, yet it was also achieved without
                                                      blocks that are feature detectors. These are: Motion, Colour
affecting the quality of the system to the extent of producing
                                                      and the Size the object occupies in the image, which not only
wrong outcomes.
                                                      accounts for the actual size of an object, but also for the dis-
  The success of our model will be demonstrated through
                                                      tance of the object from the camera, both of which are impor-
comparisons of the new results with the results from the orig-
                                                      tant in grabbing one’s attention.
inal action understanding model for a number of different be-
                                                        The remaining blocks in the model are:
haviours. If, after having cut down on all the computational
costs using our visual attention model, the ﬁnal behaviour • Fovea-effect – this models the decrease in resolution
chosen in each situation with the previous model [Demiris away from the centre of the image, because our eyes’
and Johnson, 2003] remains the same, then our attention   resolution decreases dramatically with the distance from
model will be deemed to have succeeded in its task.       the fovea [Farid et al., 2002].                                                        • Resource Allocation Algorithms – we have performed
                                                          experiments with different resource allocation algo-
                                                          rithms [Stallings, 2000] that can be employed to decide
                                                          on how to distribute resources between the behaviours.
                                                        • Internal Representations of objects and actions – this
                                                          block gives information about objects and how they
                                                          move, and interact with other objects etc.
                                                        • Purely bottom-up saliency map – this is the saliency map
                                                          representing the most salient object in the scene.
                                                      From the above ﬁve inputs, one behaviour must be chosen.
                                                      The block labelled “Where to attend for this Behaviour?” in
                                                      ﬁgure 3 has three inputs:
                                                        • Output from “Selecting ONE Behaviour” – the winner
                                                          behaviour that is selected from the previous stage is
                                                          passed on.
                                                        • Internal Representations of objects and actions – this
                                                          block gives information about objects and how they
                                                          move, and interact with other objects etc.
                                                        • Bottom-Up Saliency map inﬂuenced by top-down – this
                                                          is to give current information on where the attention of
                                                          the model is.
                                                      The output of this block inﬂuences all the bottom-up calcu-
                                                      lation blocks in order to direct the attention of our model in
                                                      such a way that it serves the current behaviour.

                                                      5   Experimental   Setup
Figure 3: The architecture of the top-down part of the model We implemented our model on an ActivMedia Peoplebot
and how it integrates with the bottom-up part         robot, equipped with a pan-tilt-zoom camera, as well as a two
                                                      degrees of freedom gripper, sonar and infrared sensors. Only
  • Winner takes all (WTA) selection as in Itti’s model [Itti the camera was used in the following sets of experiments, and
    et al., 1998].                                    the saccade generation module was switched off as it was not
                                                      needed.
  • An  attention gate mechanism as in Wolfe’s model    For these experiments, three objects were chosen: A hand,
    [Wolfe and Gancarz, 1996] which keeps a record of the a coke can, and an orange. Eight behaviours were then de-
    two most salient areas in the scene.              ﬁned:
  • A saccade generation system as in Wolfe’s model [Wolfe • Behaviour 1 - Pick coke can
    and Gancarz, 1996].
                                                        • Behaviour 2 - Move coke can
4.2  Top-down                                           • Behaviour 3 - Move hand away from coke can
Figure 3 shows our complete visual attention model which • Behaviour 4 - Pick orange
includes the top-down part. This ﬁgure speciﬁcally illustrates
how the top-down information could inﬂuence the bottom-up • Behaviour 5 - Move orange
part of the model, and vice versa.                      • Behaviour 6 - Move hand away from orange
  Our Top-down part of the model receives the list of be- • Behaviour 7 - Drop coke can
haviours from the action understanding model, described in
the previous section, together with their conﬁdence levels and • Behaviour 8 - Drop orange
their forward models. It must select only one behaviour out of Each of these behaviours has a corresponding forward model.
the many behaviours to attend to at any given point in time. Figure 4 shows the arrangement for Behaviour 1.
The block labelled “Selecting ONE Behaviour” in ﬁgure 3
has ﬁve inputs:
  • Behaviours – A list of hypotheses (potential behaviours
    that explain the demonstration) is passed in, one of
    which must be selected.
  • Conﬁdence Levels – The current conﬁdence levels for
    each behaviour.                                           Figure 4: Behaviour1 - Picking a coke can                                                          every eighth frame, since there are eight behaviours in
                                                          total.
                                                        • Our Attention model is added to the action understand-
                                                          ing model using the strategy of “highest conﬁdence level
                                                          always wins”, which means the behaviour with the pre-
                                                          vious highest conﬁdence level gets the next computa-
                                                          tion.
                                                        • Our Attention model is added to the action understand-
                                                          ing model using a combination of the “round robin” and
                                                          the “highest conﬁdence level always wins” strategies to
                                                          select between the behaviours.
                                                      Finally, we also ran another set of experiments by adding to
                                                      these implementations initialisation for the top-down part us-
                                                      ing bottom-up saliencies.
Figure 5: Images to show bottom-up block processing a scene
of a hand picking a coke can                          6   Experimental   Results
                                                      We used 26 different videos, performing 130 experiments, us-
  All the other behaviours are implemented in the same way. ing the different scheduling algorithms above, while varying
Forward models were hand coded using kinematic rules to some of the model’s parameters. The results for behaviour
output the prediction of the next state. The output from the 6 are shown in ﬁgure 6 as an example of a typical output to
forward model, which is a prediction of the actual next state, demonstrate how our system can work on top of the action un-
is compared with the next state. Based on this comparison, a derstanding model, cutting down its computational costs by
conﬁdence level is generated for this behaviour by either re- up to 87.5% (because every behaviour is now only being pro-
warding it with one conﬁdence point if the prediction is suc- cessed once in every 8 frames), and still producing the correct
cessful, or otherwise punishing it by subtracting one conﬁ- results to determine which behaviour is being demonstrated.
dence point.                                          But more importantly, it directs the limited computational re-
  Figure 5 shows an input example of what the robot sees sources to the relevant areas in the scene, instead of analysing
when a behaviour is carried out (in this case, it is the demon- the whole scene.
stration of a hand picking a coke can). A background was In addition to this, the above results were substantially im-
chosen where these object’s colours were minimally present. proved by adding initialisation to the top-down part using the
These are only snapshots of some frames.              bottom-up saliencies to our attention model . Therefore, in
  The bottom-up block detects and tracks the presence of the the case of a scene where the orange does not exist, as shown
coke can, the orange and/or the hand in the scene, depending in ﬁgure 5, our bottom-up block would detect the coke can
on what the top-down part of the attention model requires. and the hand as being salient objects. Using previously saved
The output of this bottom-up block are the corresponding lo- colour histograms, our system recognises that these salient
cations of where the hand, the coke can and/or the orange are objects are a coke can and a hand. This result is passed to the
in the scene. This information is then passed to the top-down top-down part of our attention model, which in turn will only
part of the model for intelligent processing. The CAMShift select the behaviours that are involved with these objects, as
algorithm [Bradski, 1998] was used to assist in doing this. opposed to previously selecting every behaviour that exists in
We used a hue and saturation histogram back-projection of the database.
camera images taken at a pixel resolution of 160 × 120 and at Results from behaviour 1, where no orange was present
30 frames per second. The corresponding histograms of the in the scene, are shown in ﬁgure 7 as an example for this
three objects used in our experiments were pre-saved into the initialisation process of only selecting the relevant behaviours
robot’s memory, and used during the experiments as a simple using the bottom-up saliencies. The results are compared to
method of object recognition.                         the previous implementation without this initialisation. It can
  Four different implementations were experimented with be seen that this initialisation process speeds up the correct
each of the eight behaviours:                         recognition of the correct behaviour. Furthermore, it will also
                                                      serve in allowing scalability to be added to our model.
  • A  pure implementation of the action understanding  As can be seen from ﬁgure 6, our attention model not only
    model without our attention model. Hence there was no still gives the correct results for the recognition of behaviour
    layer of intelligence to cut down on computational costs, 6, but it does it with the saving of up to 87.5% of the to-
    i.e. each behaviour gets to carry out all the computations tal computational costs. Furthermore, it returns better results
    it requires at each frame.                        in recognising the correct behaviour by isolating it from the
  • Our Attention model is added to the action understand- other wrong behaviours, due to the focusing on the correct
    ing model using a “round robin” scheduling algorithm areas of the scene only, instead of the entire image. These
    (equal time sharing) [Stallings, 2000] to select between successful results were also seen for all of the other seven
    the behaviours. Therefore, each behaviour is processed behaviours that were tested.                                                             Figure 7: Behaviour 1 - Pick coke can

                                                     Behaviour 6 in ﬁgure 6 shows that when a “round robin”
                                                   scheduling algorithm is applied, the correct behaviour is still
                                                   picked, but it ends up with a lower conﬁdence value that is
                                                   quite close to the other resulting conﬁdence values of the
                                                   other behaviours. The reduction in computational costs using
                                                   this algorithm has resulted in a decrease on the separability
                                                   of the behaviours. This is because there are n frames in the
                                                   demonstrated scene (in these experiments, n is 60), and each
                                                   behaviour is only processed once every m frames, where m
                                                   is the number of behaviours (in these experiments, m is 8)
                                                   meaning a total number of n/m computations per behaviour
                                                   (which is 7 in these experiments, hence, only a maximum
                                                   score of 7 for the winning behaviour). Behaviour 6 in this
                                                   case scores 5 out of 7, still enough to make it the winning be-
                                                   haviour, but much lower than the pure implementation of the
                                                   action understanding model without the use of any attention
                                                   mechanism.
                                                     When  “highest conﬁdence level always wins” is used, the
                                                   opposite effect to “round robin” can be seen: attention acts
                                                   like an accelerator to the winning behaviour once it recog-
                                                   nises who is the winner, suppressing all the others. The prob-
                                                   lem with purely using the scheduling algorithm of “highest
                                                   conﬁdence level always wins”, is that it may not always ini-
                                                   tialise correctly, as can be seen in ﬁgure 6, hence taking some
                                                   time before converging on the correct behaviour.
                                                     To alleviate this problem, we used the “round robin”
Figure 6: Behaviour 6 - Move hand away from orange scheduling algorithm as an initialisation step for the “high-
                                                   est conﬁdence level always wins” which then acts as an ac-