                                  Determining Expert Proﬁles
                           (With an Application to Expert Finding)

                                Krisztian Balog and Maarten de Rijke
                                    ISLA, University of Amsterdam
                                   Kruislaan 403, 1098 SJ Amsterdam
                                  kbalog,mdr@science.uva.nl

                    Abstract                          for experts, but not in isolation—the desired output should be
                                                      more than a ranked list of person names [Hawking, 2004].
    The proﬁle of an individual is a record of the types Context and evidence are needed to help users of expertise
    and areas of skills of that individual (“topical pro- ﬁnding systems decide whom to contact when seeking ex-
    ﬁle”) plus a description of her collaboration net- pertise in some area. E.g., given an expert whose name is
    work (“social proﬁle”). In this paper we deﬁne    returned in response to a query, what are her areas of exper-
    and formalize the task of automatically determin- tise? Who does she work with? What are her contact details?
    ing an expert proﬁle of a person from a heteroge- Is she well-connected, just in case she is not able to help us
    neous corpus made up of a large organization’s in- herself?
    tranet. We propose multiple models for address-
                                                        The main aim of this paper is to introduce the task of de-
    ing the topical proﬁling task. Our main methods
                                                      termining an expert’s proﬁle—i.e., a concise description of
    build on ideas from information retrieval, while re-
                                                      the areas in which she is an expert plus a description of her
    ﬁnements bring in ﬁltering (allowing an area into a
                                                      collaboration environment—, and to devise and assess algo-
    person’s proﬁle only if she is among the top rank-
                                                      rithms that address this proﬁling task. To make matters more
    ing experts in the area). An evaluation based on the
                                                      concrete, let us look at an expert ﬁnding system that is cur-
    W3C-corpus made available by TREC, shows sig-
                                                      rently being developed; it started out as “a ranked list of per-
    niﬁcant improvements of the reﬁned methods over
                                                      son names” system and is now evolving so as to include the
    the baseline. We apply our proﬁling algorithms to
                                                      type of context and evidence discussed above. Figure 1 pro-
    signiﬁcantly enhance the performance of a state-of-
                                                      vides a screen dump. In Figure 1 we see the information dis-
    the-art expert ﬁnding algorithm and to help users of
    an operational expert search system ﬁnd the person
    they would contact, given a speciﬁc problem, topic
    or information need. Finally, we address the task
    of determining a social proﬁle for a given person,
    using graph-based methods.

1  Introduction
Some of the most valuable knowledge in an enterprise re-
sides in the minds of its employees. Enterprises must com-
bine digital information with the knowledge and experience
of employees. Expert ﬁnding addresses the task of ﬁnding
the right person with the appropriate skills and knowledge: Figure 1: Screen dump of the expert search interface.
“Who are the experts on topic X?” The task has recently re-
ceived increased attention, especially since the launch of an played for one person (one of the hits produced in response to
expert ﬁnding task as part of the enterprise track at TREC in a query on “authoring tools”). In the top row we see the per-
2005 [TREC, 2005]. Given a query (describing the area in son’s name (optionally his internal id or username), and his
which expertise is being sought), participating systems have relevance for the given topical query. Below this, the contact
to return a ranked list of person names in response.  details (e-mail, web address, phone, fax number) are shown.
  Like most tasks assessed at retrieval evaluation platforms The keywords serve as a type of context, in the form of a
such as TREC, NTCIR, CLEF, and INEX, the expert ﬁnding “tag cloud,” describing the general interests and activities of
task is an abstraction of a real task. The abstractions are im- the person; these keywords are extracted from documents that
portant when trying to set up experiments that will lead to the person is associated with. The candidate’s topical proﬁle
stable and re-usable test sets [Voorhees and Harman, 2005]. is presented as a list of knowledge areas, and the level of com-
But when people search for expertise, they are often looking petence in each (which is reﬂected by the size of the bars in

                                                IJCAI-07
                                                  2657our example). The relative ranking is shown when the person similar databases of the organization into one data warehouse
is among the top experts given that ﬁeld. (As an aside the full that can easily be mined. Most of this early work was per-
interface also includes links to documents associated with the formed by the Knowledge Management and Computer Sup-
person, as well as a link to a ﬁgure depicting the candidate’s ported Cooperative Work community, usually called yellow
social proﬁle; see Section 5 for more on the latter.) pages, people-ﬁnding systems or expertise-management [EC-
  Our main contribution in this paper is the introduction of SCW, 1999]. Most of the tools rely on people to self-assess
expert proﬁling as a task, together with algorithms for ad- their skill against a predeﬁned set of keywords, and there is a
dressing the task. We ﬁrst ask whether existing expert ﬁnd- need for intelligent technologies that could enhance the pro-
ing algorithms can be used for topical proﬁling—effectively, cess of updating proﬁles [Becerra-Fernandez, 2000].
these algorithms build up a matrix with experts along one di- More recently there has been a move to automatically
mension, and topical areas along the other: given an area, de- extract such representations from heterogeneous document
termine the candidate experts with the highest expertise lev- collections such as those found within a corporate in-
els. Can these algorithms be “inverted”: given a candidate, tranet [Craswell et al., 2001]. However, until recently much
ﬁnd the areas for which her expertise levels are highest? of the work in this area has been performed in industry
  Our answer to this question is a clear “No”—implying that with only sketchy solutions, tailored to speciﬁc organizational
expert ﬁnding and expert proﬁling are two distinct tasks. The needs, and without formal evaluations.
next question, then, becomes: How can we compute expert TREC 2005  [TREC, 2005] has introduced the expert ﬁnd-
proﬁles? We propose two models for extracting expert pro- ing task and provided a common platform with the Enterprise
ﬁles; the ﬁrst uses information retrieval techniques to obtain Search Track for researchers to evaluate and assess methods
a set of relevant documents for a given knowledge area, and and techniques. The following scenario is presented: Given
aggregates the relevance of those documents that are associ- a crawl of the World Wide Web Consortium’s web site, a list
ated with the given person. Our second model represents both of candidate experts and a set of topics, the task is to ﬁnd ex-
candidates and knowledge areas as a set of keywords, and the perts (provide a ranked list of candidates) for each of these
skills of an individual are estimated based on the overlap be- topics. This scenario is ideal for measuring the accuracy and
tween these sets. We demonstrate that both models perform effectiveness of different methods, and for making a fair com-
signiﬁcantly better than the “inverted” expert search results, parison between the performance of expert ﬁnder systems.
which serves as our baseline. Moreover, we introduce a ﬁl- To the best of our knowledge, the task introduced in this
tering algorithm, which rejects areas to be part of the individ- paper—expert proﬁling—is new. More precisely, topical ex-
ual’s proﬁle, if there is not enough evidence found to support pert proﬁling has not been previously identiﬁed as a task
that the person has reasonably high knowledge on that topic, amenable to computational approaches. In contrast, social
compared to others within the enterprise.             proﬁling (ﬁnding collaboration networks around an expert) is
  While proﬁling algorithms are important for feeding the a task that has been gaining increasing attention, especially
sort of interface described above, they are also helpful in from researchers with a background in social network analy-
other ways within expertise ﬁnding scenarios: we show that sis. See, e.g., [Abrol et al., 2002] for an industrial example.
they can be used for re-ranking expert search results. Our
re-ranking method is very effective, improving upon state-of- 3 Topical Proﬁles
the-art expert ﬁnding methods in terms of mean average pre-
cision, mean reciprocal rank, as well as precision@5 scores. In this section we deﬁne what a topical proﬁle is, and propose
                                                      two methods for creating such proﬁles.
  Colleagues and collaborators play an important role in the
value of a person as an expert: an “isolated” expert might be A topical proﬁle of an individual is a record of the types
able to answer speciﬁc questions, but a well-connected ex- and areas of skills and knowledge of that individual, to-
pert might put us on track to explore new or additional ar- gether with an identiﬁcation of levels of ‘competency’ in each
eas [Cross et al., 2001].Asocial proﬁle of a person contains (“What does expert Y know?”). We model the proﬁle of a
information about her collaborative network. We propose to candidate as a vector, where each element of the vector corre-
capture the social proﬁle of a person by examining the docu- sponds the person’s skills on the given knowledge area. This
ments associated with her, and determining which other peo- skill is expressed by a score (not a probability), reﬂecting the
ple are also associated with those documents.         person’s knowledge on the given topic.
  In Section 2 we provide background on expert ﬁnding and 3.1 Algorithm
proﬁling. Section 3 is devoted to topical proﬁling. In Sec-
tion 4 we put expert proﬁles to work to improve expert ﬁnd- The output of a proﬁling algorithm is a ranked list of knowl-
ing algorithms. Then, in Section 5 we turn to social proﬁles. edge areas, the estimated level of competency in each as well
We conclude in Section 6.                             as the evidence that supports these results (e.g., a list of doc-
                                                      uments). The task of determining expert proﬁles is naturally
                                                      decomposed into two stages.
2  Background
                                                        1. Discovering and identifying possible knowledge areas.
Initial approaches to expert ﬁnding employed a database
housing the skills and knowledge of each individual in the or- 2. Measuring the person’s competency in these areas.
ganization [Maron et al., 1986; Davenport and Prusak, 1998], We assume that a list of possible knowledge areas (KA =
and were mainly focused on how to unify disparate and dis- {kai|i =1,...,n}) is given, and restrict ourselves to

                                                IJCAI-07
                                                  2658stage 2). We represent the proﬁle of a person ca as a vector The speciﬁc choice of language modeling (LM) techniques
of n values, where the ith element of the vector corresponds is pragmatic. For the topical proﬁling task, we could have
to the knowledge area kai, and score(ca, kai) reﬂects the in- used any other information retrieval method for ranking docu-
dividual’s knowledge in the given area:               ments. Our recent work on expert search used LM techniques,
 proﬁle(ca)=                                          and by re-using that work we can analyze, and obtain a bet-
     score(ca, ka ), score(ca, ka ),...,score(ca, ka ) ter understanding of, differences and similarities between the
                1             2                n      expert ﬁnding and proﬁling tasks.
Baseline                                                Conceptually, this method is similar to the expert ﬁnding
As a baseline topical proﬁling method we use the results gen- method Model 2, introduced by [Balog et al., 2006], but as-
erated by an (existing) expert search method [Balog et al., sociations are not turned into probabilities, thus their strength
2006]. The expert search method estimates pES(ca|q): what is not estimated—practically (and realistically) speaking, we
is the probability of a candidate ca being an expert given simply cannot capture the extent to which the candidate is re-
the query topic (knowledge area) q? Let rank ES(ca, q)= sponsible for a document’s content, compared to other indi-
1,...,m be the rank of candidate ca on topic q, where the viduals that may also be associated with the same document.
ranking of candidates is proportional to pES(ca|q):
                                                      Method 2
       pES(cai|q) ≥ pES(caj|q)                        Our next method takes a completely different approach,
           ⇒  rankES(cai,q) ≤ rankES(caj,q).          where the proﬁling scores are estimated using keyword sim-
                                                      ilarity of candidates and knowledge areas. We ﬁrst tokenize
We can use both the scores and the ranking generated by the
                                                      documents, and remove standard stopwords (no stemming is
expert search method to estimate the level of competence (or
                                                      applied), then extract the top 20 keywords for each docu-
knowledge) of a given candidates. That is
                                                      ment, using the TF·IDF weighting formula [Baeza-Yates and
  • Baseline(probability): score(ca, ka)=pES(ca|ka)   Ribeiro-Neto, 1999]. Let KW(d) be the set of keywords that
  • Baseline(rank): score(ca, ka)=1/rank ES(ca)       are extracted from document d.
                                                                                                       ka
A shortcoming of forming scores this way is that they are rel- We can obtain the set of keywords of a knowledge area
                                                      by looking at a query-biased subset of documents Dka, using
ative to the capabilities of other candidates, and do not reﬂect n                   ka
the individual’s absolute knowledge. Hence, given a knowl- the top documents retrieved using as the query and the
edge area, we assume the candidate’s skill to be higher if she W3C corpus as the document collection. Then we use all
is a higher ranked expert on the corresponding topic. keywords from these documents to form a list of keywords of
                                                      the given area. Formally:
Method 1                                                                     
                                                                    KWka  =         KW(d)             (3)
We now describe the ﬁrst of two proﬁling methods that go                      d∈Dka
beyond the baseline. The intuition behind this ﬁrst method is Similarly, we can obtain keywords of individuals, by taking
that a person’s skill can be represented as a score over docu- keywords of documents that they are associated with:
ments that are relevant given a knowledge area.                          
                                                                 KW    =               KW(d)
  For each knowledge area ka a query-biased subset of docu-          ca    d∈D,A(d,ca)=1              (4)
ments Dka is obtained by using the top n documents retrieved
                                                      Having the set of keywords both for knowledge areas and for
for the query ka. We iterate over the relevant documents,
                                                      candidates in hand, we estimate the proﬁle scores with the
and sum up the relevance of those that are associated with the
                                                      ratio of co-occuring keywords:
given candidate. Formally, the score of an individual ca given
the knowledge area ka is:                                    score(ca, ka)=|KW    ∩ KW   |/|KW   |.
                                                                              ka      ca      ka     (5)
  score(ca, ka)=        relevance(d, ka)A(d, ca).
                  d∈Dka                         (1)   Filtering
The association method A(d, ca) returns 1 if the name or We introduce a ﬁltering technique that is to be applied on top
the e-mail address of person ca appears in the document d; of an existing proﬁling method. In the experimental section
otherwise it returns 0. The recognition of candidates is ap- we present its performance both on Method 1 and on Method
proached as a (restricted and) specialized named entity recog- 2. The intuition behind the method is to provide us with a
nition task. We do not differentiate between the roles of the natural cut-off point that will restrict the number of people re-
person (author, contact person, mail recipient, etc.), or the turned in a proﬁling setting so as to only retain experts whose
level of the contribution the person may have made to d. topical proﬁle we are highly conﬁdent about: a knowledge
  To estimate the relevance of a document, we use stan- area can be part of an individual’s proﬁle if and only if the
dard generative language model techniques [Baeza-Yates person is among the top ranked experts on that ﬁeld. This
and Ribeiro-Neto, 1999]. Speciﬁcally, relevance(d, ka)= means that she has a reasonable knowledge on the given topic
p(ka|θd) expresses how likely the document d would gener- both individually and compared to others.
ate a certain knowledge area ka. The document model is con- We allow a given knowledge area to appear in a candidate’s
structed by taking a product of a linear combination of the proﬁle only if the individual scores within the top f among
background model p(t) and the smoothed estimate for each all candidates on that ﬁeld. Actually, we create a ranking of
term t ∈ q:                                           experts, using the proﬁle scores, and hence solve an expert
                                                   ﬁnding task. To do that, we need a list of potential expert
       p(q|θd)=   t∈q  (1 − λ)p(t|d)+λp(t)      (2)   candidates, which we assume to be given. Then we use the

                                                IJCAI-07
                                                  2659         Method              MAP    MRR                                retrieved         ﬁltered
         Baseline(probability) 0.320 0.397                Method     MAP    MRR    removed   error rate
         Baseline(rank)      0.203  0.244                 Method 1   0.407  0.503        ––
         Method 1            0.407  0.503                    f=150   0.403  0.509     0.330     0.100
         Method 2            0.397  0.486                    f=100   0.395  0.511     0.508     0.116
                                                             f=50    0.395  0.535     0.737     0.156
Table 1: Results of the topical proﬁling methods. The        f=30    0.392  0.558     0.846     0.193
columns are MAP: Mean Average Precision, and MRR: Mean       f=20    0.388  0.584     0.900     0.232
Reciprocal Rank. Best scores are in boldface.                f=15    0.408  0.649     0.926     0.277
                                                             f=10    0.385  0.677     0.951     0.309
                                                             f= 5    0.350  0.654     0.978     0.392
results of the expert ﬁnding task to reﬁne the output of the
                                                          Method 2   0.397  0.486        ––
proﬁling method. Formally,
                                                             f=200   0.355  0.463     0.625     0.058
 score(ca, ka)=                                             f=150   0.383  0.511     0.718     0.065
     
        score(ca, ka).                                       f=100   0.372  0.511     0.813     0.075
                                                                   0.303  0.476     0.907     0.082
         if |{ca |score(ca ,ka) <score(ca, ka)}| <f          f=50
                                                             f=30    0.266  0.450     0.944     0.094
        0,            otherwise
                                                             f=20    0.247  0.461     0.962     0.108
3.2  Evaluation                                              f=15    0.249  0.466     0.972     0.118
                                                             f=10    0.229  0.438     0.981     0.132
We performed experiments to answer the following ques-       f=5     0.286  0.463     0.990     0.176
tions: Is “inverted expert ﬁnding” a viable solution to the
proﬁling problem? How well do Method 1 and Method 2   Table 2: Results of ﬁltering on the topical proﬁling meth-
perform? And what is the impact of ﬁltering?          ods. The columns are MAP: Mean Average Precision, MRR:
Experimental Setup                                    Mean Reciprocal Rank, removed: fraction of the original re-
The document collection we use is the W3C corpus [W3C, sults that is ﬁltered out, and error rate: fraction of incorrectly
2005], a heterogenous document repository containing a mix- ﬁltered out proﬁle elements. Best scores are in boldface.
ture of different document types crawled from the W3C web-
site. The corpus contains 330,037 documents, adding up to matrix is calculated and then the values are sorted along one
5.7GB. A list of 1,092 candidate experts was made available, of the dimensions. However, when one is developing algo-
where each candidate is described with a unique candidate id, rithms for ﬁlling that matrix, different aspects of the data may
name(s) and one or more e-mail addresses. We took the top- need to be taken into account: documents on a topic are ex-
ics created within the expert ﬁnding task of the 2005 edition amined for expert ﬁnding, and documents associated with a
of the TREC Enterprise track: 50 in total; these are the topics speciﬁc person are considered for expert proﬁling.
for which experts have to be sought.                    Finally, both Method 1 and Method 2 achieved fairly high
Proﬁling                                              MAP and MRR scores on the proﬁling task, with Method 1
In our evaluation methodology we utilize the fact that the signiﬁcantly outperforming Method 2.
TREC 2005 topics are actually names of W3C working
                                                      Filtering
groups, and experts on a given topic are members of the corre-
sponding working group. A person may be member of multi- Recall that ﬁltering (as deﬁned above) allows a knowledge
                                                      area to appear in the individual’s proﬁle only if the person is
ple working groups, meaning that she is an expert on multiple      f                              f
topics. We use the W3C working group names as knowledge among the top ranked experts on that topic. Low values
areas, and consider a knowledge area to be part of the individ- imply that the proﬁle will contain only the expertise areas of
ual’s proﬁle if the person is a member of the corresponding a person. As a consequence of ﬁltering, an individual’s pro-
working group. That is, we reverse the original TREC expert ﬁle may become empty, in which case we get a smaller, but
search assessments.                                   far more precise result set. The questions we should ask are:
  Table 1 reports the results of our experiments. The answer how much do we gain for the experts that we retain, and how
to our ﬁrst question (Can an expert search algorithm be “in- many valid proﬁle elements do we lose (i.e., what is the er-
verted” to obtain an effective topical proﬁling method?) is ror ratio)? See Table 2: for Method 1 and 2 we can obtain
a clear “No” since both proﬁling methods signiﬁcantly out- signiﬁcant improvements (in terms of MRR scores) when ﬁl-
                                                      tering, where the original method (with no ﬁltering) acts as
perform both baselines; the probability baseline signiﬁcantly  2
outperforms the rank baseline.1 Hence, expert ﬁnding and a baseline. Thus, ﬁltering has an early precision enhancing
topical proﬁling are two different tasks. Their mathematical effect. However, in most cases the MAP scores drop, which
foundation is common, since in both cases a candidate-topic suggests that recall drops: we lose knowledge areas. This is
                                                      conﬁrmed by an inspection of the error ratios. The two proﬁl-
  1To determine whether the observed differences are statistically ing methods behave somewhat differently w.r.t. this measure,
signiﬁcant, we use the two-tailed Wilcoxon Matchedpair Signed-
Ranks Test, and look for improvements at a signiﬁcance level of 2Here, we used the (non-paired) Mann-Whitney U test (two
0.05.                                                 tailed) to establish signiﬁcance.

                                                IJCAI-07
                                                  2660              #rel MAP MRR    P@5   P@10 P@20         5   Social Proﬁles
   EF (baseline) 576 0.196 0.531 0.336 0.332 0.269
     + Method 1:                                      Collaborators play an important role when one is searching
   (A)        576 0.209* 0.659* 0.396* 0.326 0.267    for expertise. People that an individual is working with are
   (B) λ =0.5 576 0.197 0.584* 0.376* 0.324 0.267     part of her personal workspace, and can serve as a back-
     + Method 2:                                      ground, or context, in which the system’s recommendations
   (A)        576 0.181 0.576* 0.340 0.292 0.242
      λ =0.7                                          should be interpreted. This collaboration network can also
   (B)        576 0.188 0.559* 0.344 0.306 0.254      help us to explore the roles of the individuals within an orga-
                                                      nization. We might have a speciﬁc, well-deﬁned need, where
Table 3: Results of reranking expert ﬁnding results using in-
                                                      we are looking for an expert, or even for a “specialist.” An-
dividual’s proﬁle. The columns are: reranking method, num-
                                                      other typical user scenario is to ﬁnd a “librarian,” who has
ber of relevant retrieved candidates, mean average precision,
                                                      access to a wide range of knowledge, and can direct us to a
mean reciprocal rank, precision after 5, 10 and 20 candidates
                                                      specialist, after the request has been narrowed down.
retrieved. Best results bold face; * denotes signiﬁcant im-
provements over the baseline.
                                                      5.1  Collaboration network
when ﬁltering is applied. But in both cases ﬁltering substan- We interpret the social proﬁle as a collaboration network, and
tially reduces the size of the result set, and at the same time, describe an algorithm for building such a network.
they keep the error ratio of the ﬁltering low. The drop in MAP A collaboration network CN is a directed graph (V,E),
scores indicates that we lose appropriate knowledge areas that where the nodes correspond to people, and a weighted di-
were initially ranked highly, while the rise in MRR indicates rected edge (x, y) ∈ E indicates the strength of the collabora-
that the remaining appropriate ones are ranked higher. tion between x and y. Given a topic t,atopical collaboration
                                                      network CN(t) is a special CN where we restrict ourselves
4  An Application to Expert Finding                   to collaborations (between people) relevant for t.
                                                        Given our enterprise (personal workspace) setting we can
In this section we describe an application of the extracted
                                                      create a topical collaboration network CN(q) given the user’s
topical proﬁles to expert ﬁnding. Our approach takes the re-
                                                      query q. The level of the collaboration between two people
sults of an existing expert ﬁnding method—treated as a black
                                                      x and y is estimated by the relevance of the documents Dxy
box—as input, and adjust the results using the individuals’
                                                      that are associated with both x and y. The weight of the edge
proﬁles: if a knowledge area ranks low on a person’s proﬁle,
                                                      between the two individuals is expressed using
we push the candidate down on the list of experts returned to
                                                                         
the user. We expect this idea to have a precision enhancing ef- w(x, y)=         relevance(d, q)      (6)
fect, possibly hurting recall. Since we take the expert ﬁnding              d∈Dxy
method used to be a black box, we do not have any infor-
                                                      where Dxy = {d ∈ Dq|A(x, d) ∧ A(y, d)}. A query-biased
mation about the applied scoring method, which leaves us no
                                                      subset of documents Dq is obtained by using the top n docu-
other option than to use the ranking of the expert ﬁnding re- ments retrieved for the query q, and A(x, d) is a binary func-
sults: we do not make any assumptions about the scores. We tion denoting whether the person x is associated with the doc-
combine the reciprocal of these ranks either in a multiplica- ument d (see Section 3 for details).
tive or in an additive way: i.e., rank (ca, ka)=
                              EF                        The topical collaboration network CN(q) is built using the
   (A)=          1           1                        following algorithm:
            rankEF (ca,ka) rankPR(ca,ka)
                     1                   1
   (B)=λ     +             +(1−   λ)                                                           Dq
                rankEF (ca,ka)      rankPR(ca,ka)     Init Obtain a query-biased subset of documents
Table 3 shows the results of our reranking methods; we only Step 1 Calculate the topical relevance of each individual
include scores with the best performing λ parameter for (B).              
                                                         ∀x ∈ V : R(x, q)=             relevance(d, q) (7)
Method 1 achieved the highest scores with equal weights on                   d∈Dq ∧A(x,d)
both the expert ﬁnding and proﬁling rankings, while Method
2 operated best when less changes were allowed on the orig- Step 2 Calculate the level of collaboration w(x, y) between
inal expert search results. All conﬁgurations improve MRR individuals using Formula 6.
and P@5 over the baseline, and this fact conﬁrms that proﬁl-
ing can be used for improving upon an existing expert ﬁnding Step 3 Make the edges directed and normalize them using
method in terms of early precision. Moreover, this special the individuals’ topical relevance. We allow nodes to be
application of the extracted proﬁles allows us to make further connected with themselves.
comparisons between the proﬁling methods: Method 1 out-                             w(x, y)
                                                              ∀y ∈ V  : w(x, y)=
performs Method 2, here and on the original proﬁling task.          x               R(x, q)           (8)
  The combination methods we presented here are fairly sim-                            
                                                                       w(x, x)=1−            w(x, y)
ple, but still proved to have a positive impact on application                           y∈Vx         (9)
of the proﬁles. Further improvements could be pursued us-
ing more sophisticated methods for combining the retrieval where Vx denotes the set of nodes connected to x: Vx =
results; consult [Kamps and de Rijke, 2004] for an overview. {y ∈ V |w(x, y) > 0}.

                                                IJCAI-07
                                                  2661