    Learning Algorithms for Software Agents in Uncertain and Untrusted Market 
                                                   Environments 

                                         Thomas Tran and Robin Cohen 
                               School of Computer Science, University of Waterloo 
                                          Waterloo, ON, Canada N2L 3G1 
                                       {tt5tran, rcohen}@math.uwaterloo.ca 


   The problem of how to develop algorithms that guide the     function fb is incrementally learned in an RL framework: 
 behaviour of personal, intelligent software agents participat•
 ing in electronic marketplaces is a subject of increasing inter•
 est from both the academic and industrial research commu•      where a is called the learning rate The rep•
 nities. Since a multi-agent electronic market environment is, utation rating of s is then updated based on whether or not 
 by its very nature, open, dynamic, uncertain, and untrusted,  the true value of good g is greater than or equal to the value 
 it is very important that participant agents are equipped with demanded by b. Our reputation updating scheme implements 
 effective and feasible learning algorithms in order to achieve the traditional ideas that reputation should be difficult to build 
 their goals. In this paper, we propose algorithms for buying  up but easy to tear down, and that a transaction with higher 
 and selling agents in electronic marketplaces, based on repu• value should be more appreciated than a lower one. The set 
 tation modelling and reinforcement learning (RL).             of reputable and disreputable sellers are accord•
   We model the agent environment as an open marketplace       ingly re-calculated based on the updated reputation rating of 
 which is populated with economic agents (buyers and sell•     s. 
 ers), freely entering or leaving the market. The process of     In our selling algorithm, a seller s makes use of an ex•
 buying and selling goods is realized via a 3-phase mecha•     pected profit function where (g,p,b) represents seller 
 nism: (i) A buyer announces its request for a good, (ii) Sellers s expected profit if it sells good g at price p to buyer b. Seller 
                                                               s chooses a price to sell good g to buyer b such that its 
 submit bids for delivering such goods. (iii) The buyer eval•
                                                               expected profit is maximized. After the transaction, the ex•
 uates the submitted bids and selects a suitable seller. Thus, 
                                                               pected profit function hs is learned incrementally using RL: 
 the buying and selling process can be viewed as an auction 
 where a seller is said to be winning the auction if it is able 
 to sell its good to the buyer. We assume that the quality of a where is the actual profit of seller s when it sells 
 good offered by different sellers may not be the same, a seller good g at price p to buyer 6, and is defined as follows: 
 may alter the quality of its goods, and there may be dishonest 
 sellers in the market. We also assume that a buyer can exam•                                   if .s wins the auction 
 ine the quality of the good it purchases only after it receives                                otherwise. 
 that good from the selected seller.                           where (g, b) is the cost of seller s to produce good g for 
   In our approach, buying agents learn to avoid the risk of   buyer b. Our selling algorithm also allows sellers to alter the 
 purchasing low quality goods and to maximize their expected   quality of their goods in order to meet the buyers' needs and 
 value of goods by dynamically maintaining sets of reputable   to further increase their future profit, depending on the suc•
 and disreputable sellers. Selling agents learn to maximize    cess of their previous sales with the buyers. 
 their expected profits by adjusting product prices and option•  We believe that our approach should lead to improved sat•
 ally altering the quality of their goods.                     isfaction for buyers and sellers, since buyers should be less at 
                                                               risk of purchasing low quality goods when maintaining sets 
   In our buying algorithm, a buyer b uses an expected value 
                                                               of reputable and disreputable sellers, and since sellers are al•
 function /6, where fb(g,p,s) represents buyer b's expected 
 value of buying good g at price p from seller s. Buyer b main• lowed to adjust both price and quality to meet the buyers' 
 tains reputation ratings for all sellers, and chooses among its demands. 
                                                                 We have performed experimentation to measure the value 
 set of reputable sellers Sb a seller s that offers good g at 
price p with maximum expected value. In addition, with a       of our model on both microscopic and macroscopic levels. 
 small probability p, buyer b chooses to explore (rather than  On the micro level, we were interested in examining the indi•
 exploit) the marketplace to discover new reputable sellers by vidual benefit of agents, particularly their level of satisfaction. 
randomly selecting a seller 5, provided that s is not from the Our experimental results show that in both modest and large 
 set of disreputable sellers Sbdr. After paying seller s and re• sized marketplaces, buyers following the proposed buying al•
 ceiving good g, buyer b can examine the quality q of g and   gorithm (i.e., using the combination of RL and reputation 
calculate the true value vb(g,p,q) of g. The expected value   modelling) will achieve better satisfaction than buyers using 


POSTER PAPERS                                                                                                      1475  RL alone, and that sellers following the proposed selling al•
 gorithm (i.e., using RL and adjusting product quality) will 
 make better profit than sellers using only RL. On the macro 
 level, we studied how a market populated with our buyers and 
 sellers would behave as a whole. Our results demonstrate that 
 such a market can reach an equilibrium state where the agent 
 population remains stable (as some sellers who repeatedly fail 
 to sell their goods will decide to leave the market), and this 
 equilibrium is optimal for the participant agents. 

   We report some experimental results confirming the satis•
 faction of buyers following the proposed algorithm in a large 
 sized marketplace. The simulated market is populated with 
 160 sellers and 120 buyers where each buyer participates in 
 5000 auctions. The seller population is equally divided into 
 four groups: Group A offers goods with quality chosen ran•
 domly from the quality interval [32, 42]. Group B consists of 
dishonest sellers, who try to attract buyers with high quality 
goods (q = 45) and then cheat them with really low quality 
 ones (q = 1). Sellers in group C use RL but do not consider 
 adjusting product quality; they offer goods with fixed quality 
39. Sellers in group D follow the proposed selling algorithm 
and offer goods with initial quality 39. The buyer population 
 is divided equally into two groups: Group I uses RL alone    Figure 1: Histograms of true product values obtained by a buyer 
and group II follows the proposed buying algorithm. We set    using RL alone (a), and a buyer using the proposed algorithm (b). 
quality equal to cost to support the common idea that it costs 
more to produce high quality goods. Also, we set the true 
product value vb = 3.bq - p, the demanded product value 
tf6 = 100, the learning rate a = 1 and exploration rate p = 1 
initially with both decreased over time by factor 0.9997 down 
to amin— pmin =0.1. The results reported here are based 
on the average taken over the respective populations of the 
two groups of buyers. 

   Figure 1(a) and (b) present the histograms of true prod•
uct values obtained by a buyer using RL alone, and by a 
buyer following the proposed buying algorithm, respectively. 
Clearly, the buyer following the proposed algorithm receives 
more goods with higher value (vb = 110) and fewer goods 
with lower values (vb = 65... 105), and is therefore better 
satisfied. In particular, the buyer following the proposed al•
gorithm makes about 2350 more purchases with high product 
value of 110 (or 15.67 times greater) than those purchases 
made by the buyer using RL alone. 

   We are also interested in seeing how much better the buyer 
following the proposed algorithm is able to avoid interaction 
with the dishonest sellers. Figure 2(a) and (b) show the profits 
made by the dishonest sellers from the buyer using RL alone, 
and from the buyer following the proposed algorithm, respec•  Figure 2: Profits made by the dishonest sellers from the buyer using 
tively. We notice that graph (a) is higher than graph (b), indi• RL alone (a), and the buyer using the proposed algorithm (b). 
cating that the dishonest sellers are able to make more profit 
from those buyers that only use RL but do not model sell•        In general, our work demonstrates that reputation mod•
ers' reputation. Moreover, the profit in graph (b) is reduced elling can be used in combination with reinforcement learn•
to zero after about 2700 auctions, implying that in the long  ing to design intelligent learning agents that participate in 
run the dishonest sellers are not able to make any profit from electronic marketplaces. This research also aims to provide a 
the buyer following the proposed algorithm, because they are  principled framework for building effective economic agents 
rated as disreputable sellers and therefore no longer chosen  and desirable electronic market environments. 
by the buyer. 


1476                                                                                                  POSTER PAPERS 