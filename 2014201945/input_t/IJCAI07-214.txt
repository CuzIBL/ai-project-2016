            Collaborative Inductive Logic Programming for Path Planning

                                  Jian Huang   and  Adrian R. Pearce
                                  NICTA Victoria Research Laboratory
                      Department of Computer Science and Software Engineering
                            The University of Melbourne, Victoria, Australia
                                  {jhua,adrian}@csse.unimelb.edu.au

                    Abstract                          of the collaboration scheme would work, i.e. learning in iso-
                                                      lation or communicating everything. Therefore, the interac-
    In distributed systems, learning does not necessar- tion between agents while performing a learning task needs
    ily involve the participation of agents directly in to be elaborated, such that agents draw together knowledge
    the inductive process itself. Instead, many systems when necessary. Further, they should draw only the neces-
    frequently employ multiple instances of induction sary knowledge together.
    separately. In this paper, we develop and evalu-    In prior work published by the authors [Huang and Pearce,
    ate a new approach for learning in distributed sys- 2006a], the possible synergy between program execution and
    tems that tightly integrates processes of induction induction has been demonstrated for inducing missing predi-
    between agents, based on inductive logic program- cates in a distributed program setting. Under the multi-agent
    ming techniques. The paper’s main contribution is interactive learning framework, MAILS, agents are equipped
    the integration of an epistemic approach to reason- with background knowledge, expressed as logic programs,
    ing about knowledge with inverse entailment dur-  and they reason about what they know, based on their collab-
    ing induction. The new approach facilitates a sys- oratively engagement in learning tasks, through communicat-
    tematic approach to the sharing of knowledge and  ing positive and negative examples (based on the prior suc-
    invention of predicates only when required. We    cess and failure of goals from the perspective of each agent).
    illustrate the approach using the well-known path Recently, the approach has been formalized for a wider range
    planning problem and compare results empirically  of problem solving tasks based on the (more generalized)
    to (multiple instances of) single agent-based induc- problem of collaborative inductive logic programming (C-
    tion over varying distributions of data. Given a cho- ILP) [Huang and Pearce, 2006b].
    sen path planning algorithm, our algorithm enables  In this paper, we further develop the work by extending and
    agents to combine their local knowledge in an ef- integrating the epistemic aspects of the approach and better
    fective way to avoid central control while signiﬁ- evaluate the approach for an extended task. We illustrate the
    cantly reducing communication costs.              approach using the well-known path planning problem in a
                                                      distributed setting, where path information (such as reacha-
                                                      bility and cost) is distributed over different agents. Although
1  Introduction                                       each agent perceives only partial information about the en-
The problem of true multi-agent learning has far more com- vironment, our approach enables them to combine their lo-
plexity than simply having each agent perform localized in- cal perceptions in an effective way and collaboratively work
duction in isolation (see [Stone and Veloso, 2000; Kazakov out the path from a source to a destination, which no agent
and Kudenko, 2001]). Weiß and Dillenbourg clearly identify would be able to do in isolation. We empirically show that
this problem “interaction does not just serve the purpose of the approach shows promise for avoiding central control and
data exchange, but typically is in the spirit of a cooperative, reducing communication costs involved.
negotiated search for a solution of the learning task” [Weiß The collaborative inductive logic programming (C-ILP)
and Dillenbourg, 1999].                               technique is based on an inverse resolution approach to learn-
  The reason that interaction and cooperation during learn- ing [Muggleton and Raedt, 1994]. We follow in the tradi-
ing is important, is because the crucial knowledge necessary tion of prior work on context sensitive models and decision-
in learning a hypothesis is typically distributed over a number theoretic ILP for efﬁciently constraining the search and ﬁnd-
of agents. This gives rise not only to the problem that no indi- ing optimal models [Srinivasan, 2001]. For our knowledge-
vidual agent can accomplish the learning task alone, but also based needs of distribution, this involves scoring hypothesis
the problem of knowing what background knowledge from during induction: which model is the optimal choice for the
each agent is required for constructing the global hypothesis, current context relative to each agents viewpoint and goals?
given that sharing complete knowledge is often not feasible. An important aspect of our approach is that it seeks to in-
Due to the above two constraints, neither of the two extremes tegrate processes of both deductive and inductive inferenc-

                                                IJCAI-07
                                                  1327ing during problem solving. Our research views the synergy planning problem and use the distributed path planning prob-
of combining both processes as an effective way of acquir- lem to show empirically the advantages of the approach in
ing new knowledge while performing reasoning; such that an reducing communication costs while allowing agents to col-
agent performing induction may have a number of deductive laboratively learn through interaction.
subroutines that can be used at its discretion, and vice versa. As in logic programming domain, capital letters are used
  Section 2 deﬁnes the problem of collaborative ILP. Section to denote free variables and small letters bound. The term
3 and 4 describe details of our proposed induction technique reachable(a,b) stands for “b is reachable from a”. The
involving distributed knowledge sources when applied to the term link(a,b) means “there exists a link from a to b”.
distributed path planning problem. Section 5 reports on the The link term can also include extra arguments containing
empirical results addressing the advantages of our approach. information about the link (such as cost) but for illustration
Section 6 looks at some existing work on path planning in we stick to the two-argument form. We assume each car is
multi-agent environments and other distributed problem solv- equipped with the following background knowledge:
ing techniques in situations where no centralized control is 1. link(A,B) → reachable(A,B)
possible.
                                                        2. reachable(A,B)  ∧ reachable(B,C)   →
2  The Collaborative ILP Problem                          reachable(A,C)
The process of inductive logic programming is often deﬁned The ﬁrst background knowledge simply captures the mean-
as such: when provided with some background knowledge B ing that if there exists a link from A to B, then it’s reach-
and examples E of a concept, an ILP algorithm constructs a able from A to B. Likewise, the second clause says that if it’s
hypothesis H such that B ∧ H |= E [Muggleton, 1995].In reachable from A to B and it’s reachable from B to C, then
multi-agent systems, ILP involves generating hypotheses us- it’s reachable from A to C. A car also records links that it
ing the collective background knowledge. More formally, the has gone through previously in history in its knowledge base,
process of collaborative ILP (C-ILP) in multi-agent systems in the form of link(A,B). In another word, if a car could
can be deﬁned as follows.                             perform deductive reasoning, it would infer based on the
                                                      background knowledge and the knowledge it has gained his-
Deﬁnition 1 The collaborative ILP problem is deﬁned by the
                                                      torically, given any query in the form reachable(A,B),
set of agents A; the background knowledge Bi, where i ∈ A,
                                                      whether it is reachable from one location to another.
for each agent i; and the set of positive and negative exam-
     +       −                                          On the other hand, under an inductive framework, given the
ples E and E   for each agent i. Further, B =   Bi
     i       i                              i∈A      same query reachable(A,B), the car can come up with
                                     E+ =       E+
is the set of all background knowledge and i∈A  i    hypotheses H, together with its background knowledge B,
     −          −
and E  =   i∈A Ei are the sets of all positive/negative ex- to explain this query, i.e. H ∧ B |= reachable(A,B).
amples. Then collaborative ILP can be viewed as the process Viewed from a slightly different perspective, the inductive
of collaboratively generating the hypothesis H such that the technique can be used to uncover a path from one location to
following conditions hold:                            another since if a path does exist, the inductive process will
 1. Prior Satisﬁability: B ∧ E− |=                  at some stage generate a hypothesis containing only link
                                 −                    terms, which effectively corresponds to the actual path from
 2. Posterior Satisﬁability: B ∧ H ∧ E |= 
                                                      A to B.
                  B |= E+
 3. Prior Necessity:                                    Equipped with an inductive process and some simple back-
 4. Posterior Sufﬁciency: B ∧ H |= E+, and            ground knowledge as the above, our approach allows a car to
                              +                       issue a query in the form reachable(A,B) while seeking
 5. ¬∃i ∈ A such that Bi ∧ H |= E
                                                      a path from A to B. When engaged in answering this query,
  The ﬁrst four conditions are adapted from ILP in a sin- the cars being consulted attempt to induce, by performing ILP
gle agent setting [Muggleton and Raedt, 1994] and are gen- technique such as inverse resolution, a series of hypotheses to
eralized to allow hypothesis generation over the agents’ total explain this query based on their own background knowledge.
background knowledge. The ﬁfth condition asserts that there Fig.1 illustrates the process of inverse resolution while gen-
is no individual agent who is able to induce the hypothesis erating hypotheses to explain the query reachable(a,g)
based solely on its own background knowledge.         given  a  link  history link(c,d),     link(c,e),
  Due to constraints associated with resource bounded multi- link(d,e), link(d,f), link(f,g).   The back-
agent systems, bringing distributed background knowledge ground knowledge used at each step is shown on the left and
together into one agent to execute a centralized ILP algorithm the hypotheses generated along the way are shown on the
is often infeasible in practice. Therefore, inductively gener- right branches. The hypothesis Hn = reachable(a,c)∧
ating the hypothesis in multi-agent systems relies on care- link(c,d) ∧ link(d,f) ∧ link(f,g) in the example
ful exchange of information between agents during learning, is interpreted as: reachable(a,g) (the query) is true so
for which we believe epistemic reasoning plays an important long as reachable(a,c) is true given that link(c,d),
role.                                                 link(d,f)   and link(f,g)  are all known to be true.
                                                        Surely, a hypothesis generated by a single agent doesn’t
3  Path Planning using Induction                      always correspond to a path since knowledge of an individual
In this section and the sections following, we demonstrate is often incomplete. Just as what happens in the previous
an application of the C-ILP approach to the distributed path example, based on its local knowledge, the car in the example

                                                IJCAI-07
                                                  1328                                      ¬ link(A,B), reachable(A,B)P reachable(a,c) , link(c,d), link(d,f), link(f,g)
                                                         PP         Hn
             ¬ reachable(A,B), ¬ reachable(B,C), reachable(A,C)P ···
                                                  PP   
     ¬ reachable(A,B), ¬ reachable(B,C), reachable(A,C)P reachable(a,c) , reachable(c,g)
                                          PP         H1
                                         reachable(a,g)
                                              E

Figure 1: Inverse resolution: background knowledge used is shown on the left branches and hypotheses generated on the right.

GENHYPO(Query)                                        3.2  Deduction Directed Search
 1: HypList ←{Query}, HypHistory ← ∅
 2: while HypList = ∅ do                             Inductively generating hypotheses in an uninformed way de-
 3:    Choose hypothesis H from HypList               scribed above can make search space intractable very quickly.
 4:    if ∃ T in H such that DIJKSTRA(T , Path) is true then
 5:        Replace T with Pathand store H into HypHistory For this reason, the basic algorithm is extended so that it
 6:    else                                           allows a path searching subroutine, such as Dijkstra’s algo-
 7:        Generate all subsequent hypotheses HypAll based on H rithm, to be employed as a heuristic for identifying promis-
 8:        if HypAll = ∅ then
 9:            HypHistory ←{H}∪HypHistory             ing hypotheses and pruning away search space in a mindful
10:         else                                      way. Dijkstra is run on each reachable term contained in
11:             HypList ← HypAll ∪ HypList            hypothesis H to uncover a path based on historical link in-
12: SCOREHYPO(HypHistory)
13: return all H in HypHistory in the order of score. formation. For example, if link(c,d), link(d,f) and
                                                      link(f,g)   are all known, then the path searching subrou-
Figure 2: Algorithm for hypothesis generation utilizing de- tine will uncover a path from c to g in hypothesis H =
ductive shortest path subroutine and scoring.         reachable(a,c)    ∧ reachable(c,g)    and will change
                                                      the hypothesis to H = reachable(a,c)∧link(c,d)∧
                                                      link(d,f)   ∧ link(f,g)   without having to go though
is unable to ﬁnd out a path from a to g. However, returning the inverse resolution a large number of times to arrive at the
                  H
a hypothesis such as n is more helpful than simply failing same hypothesis.
in a multi-agent environment and we will show shortly how By integrating both deductive and inductive processes, our
this partial solution can be used during future endeavors to approach allows an agent performing induction to employ de-
uncover the full path.                                ductive subroutines that can be used at its discretion. For ex-
3.1  Hypothesize Paths by Induction                   ample, an agent may have a subroutine for ﬁnding the short-
                                                      est path while also having a subroutine ﬁnding any particular
  Discovering the partial solution relies on generating the path. This aspect of the research has its own signiﬁcance be-
hypotheses in a controlled fashion. The basic algorithm for cause deductive inference and inductive inference often take
doing so is sketched out in Fig. 2. The algorithm starts by two independent paths. Our approach has shown that they can
choosing the ﬁrst hypothesis H from HypList, initialized be combined tightly together as an effective way of acquiring
to contain only the Query, and applying inverse resolution new knowledge while performing reasoning. It also sheds a
using H and each background knowledge. The resulting hy- light on programming inductive agents at a higher level of
potheses, if there is any, is then stored back to the HypList. abstraction in which what algorithm an agent actually runs
If no further hypothesis is returned by the inverse resolution doesn’t have to be hard coded. Instead, a number of different
process, then take H out of the HypList and store it into deductive subroutines may be employed and these deductive
HypHistory. The algorithm keeps picking up the next hy- subroutines can be utilized by agents when required. Based
pothesis in the HypList until it becomes empty. In this way, on what an agent is committed to do at a particular moment,
all possible hypotheses that can be generated starting from the it selects the suitable subroutine to execute as part of problem
Query itself are explored.                            solving while executing the same induction process.
  Because every hypothesis, which explains the query, can be
the one that contains the solution, they all need to be gener-
ated. Therefore, the complexity of the algorithm in the worst 4 Collaborative Path Planning
case involves expanding starting from Query with each of In the previous section, we have demonstrated how induction
the background knowledge and unifying with every possible allows an agent to not only ﬁnd out a path if it exists but
known location until all hypotheses become longer than the also ‘guess’ a hypothetical path which can be pursued fur-
total of known path. If l denotes the number of known lo- ther. In this section, we explore the interactive aspects which
cations, k denotes the number of known links and b denotes enable multiple agents with distributed knowledge to collab-
the number of background knowledge, then the complexity oratively ﬁnd out a path. Take the example in Fig. 3 and
of the algorithm in the worst case is O((l × b)k). However, assume car A is interested in going from a to l. Posted as
because many of the generated hypotheses can be discarded a collaborative ILP problem as deﬁned in section 2, the path
halfway through the search before they become meaningless, planning problem becomes: “collaboratively ﬁnd a hypoth-
the average case complexity is signiﬁcantly lower.    esis H such that the example E = reachable(a,l)  is

                                                IJCAI-07
                                                  1329Figure 3: Example showing path information being dis-
tributed among four agents. One path from a to l is
a-d-g-j-l.

explainable using the total background knowledge B of all
agents”. It can be observed from the ﬁgure that one such
hypothesis would be H = link(a,d)  ∧ link(d,g)   ∧
link(g,j)  ∧ link(j,l).
  Generally speaking, in a distributed setting, the pursuit of
a global hypothesis involves the following key elements: (i) Figure 4: Interaction and information passing among the cars
the global inductive problem must be decomposed into a se- in Fig. 3 when searching for a path from a to l.
ries of localized inductive problems that can be solved by in-
dividual agents; (ii) an individual agent’s inductive process CPP(Query, Know)
must enable it to contribute a partial solution to the problem; 1: Hyp ← GENHYPO(Query) // induce the path by itself
and (iii) the agents must carefully maintain their knowledge 2: if PATHFOUND(Hyp) then
                                                       3:    Path←  RETRIEVEPATH(Know)
and systematically exchange information such that the partial 4: return Path
solutions can be integrated together to form the ﬁnal solu- 5: for ∀i ∈ A do
tion. While element (ii) has been described thoroughly in the 6: Hyps ← Hyps∪ ASK(i, Query)
                                                       7: if Hyps = ∅ then
previous sections, here we provide a description to what is 8: return FAIL
involved in (i) and (iii).                             9: if PATHFOUND(Hyps) then
                                                       10:    Path← RETRIEVEPATH(Know)
  Consider the example in Fig. 3 again. The interaction steps 11: return Path
can be summarized as follows:                          12: while Hyps = ∅ do
                                                       13:    Query ← CHOOSEBEST(Hyps) // hypothesis to pursue next
  1A:E              = reachable(a, l)                  14:    Know ← GENKNOW(Query) // generate new knowledge
  2AASKS    C:   E  = reachable(a, l)                  15:    Hyps ← Hyps −{Query}
                                                                 Query Know
  3CINDUCES:     H  = reachable(a, g),link(g, j),link(j, l) 16: CPP(  ,    )
                                                       17: return FAIL
 4CREPLIES:      H  = reachable(a, g)
 5ADEDUCES:      K1 = Ka(Kc(reachable(g, l)))
                                                      Figure 5: Algorithm for collaborative path planning that com-
                 K2 = Ka(∃iKi(reachable(a, g)) →
                      Ka(reachable(a, l)))            bines agent interaction, induction and epistemic reasoning.
  6A:E              = reachable(a, g)
 7AASKS     B:   E  = reachable(a, g)
 8BINDUCES:      H  = reachable(a, c),link(c, d),link(d, g) found eventually. Of course, this requires car A to go back to
 9BREPLIES:      H  = reachable(a, c)                 its knowledge base and retrieve what has been inferred before
  10 A DEDUCES:  K3 = Ka(Kb(reachable(c, g)))         about who knows what. The actual transfer of link informa-
                 K4 = Ka(∃iKi(reachable(a, c)) →      tion will then take place. The interaction among the three cars
                      Ka(reachable(a, g)))            in this example is shown in Fig. 4.
                              (  )
 11         A :  E  = reachable a, c                    Our general algorithm for collaborative path planning is
 12  A INDUCES:  H  = link(a, c)
                                                      given in Fig. 5. When engaged in answering a Query,an
  Car A starts (step 1) with E = reachable(a,l) which agent ﬁrst attempts to solve it by itself (line 1 to 4). If it suc-
it wants to construct an H to explain. Assume car A asks ceeds, it goes back to its knowledge base, retrieves the Path,
car C ﬁrst. Car C will perform the induction and obtain a returns it and ﬁnishes. If it fails to ﬁnd the path itself, it asks
hypothesis, say H = reachable(a,g) ∧ link(g,j)   ∧    every other agent in the team (line 5 to 11). If no hypothesis
link(j,l). It returns reachable(a,g)   back to car A. is received from any other agent, it fails since the path doesn’t
Car A infers that car C knows reachable(g,l) (by per- exist. If any hypothesis indicates the path has been found, it
forming reasoning on the deﬁnition of reachable) (step goes back to its knowledge base, retrieves the Path, returns
5). Therefore, it knows that as long as someone knows (or it and ﬁnishes. Otherwise (line 12 to 17), it picks the most
can explain) reachable(a,g), the path can be found.   promising hypothesis among all returned by the other agents
At this stage (step 6), the overall problem has changed. and proceeds with it as the new Query, until all those hy-
Car A is now interested in constructing an H to explain potheses have been tried in which case it fails since the path
E  =  reachable(a,g). Later on, through collabora-    doesn’t exist. During retrieval of the Path, it bases on the
tion with car B, they would be able to induce the path knowledge in its knowledge base to decide whom to request
from a to g. Since car A remembers that car C knows   for the actual link information.
reachable(g,l), the full path from a to l would thus be Here, communication saving comes from three aspects: 1)

                                                IJCAI-07
                                                  1330Figure 6: LEFT: shows communication costs (amount of information transferred) associated with the C-ILP approach to
collaborative path planning. MIDDLE: compares communication costs using the C-ILP approach with a centralized approach,
with a graph of 120 links for different numbers of agents. RIGHT: shows communication savings as the information per agent
increases, using 3 agents and graphs of different sizes.

communication of link information doesn’t happen until the left shows the increasing of communication costs associ-
a path has been fully worked out by keeping track of who ated with the proposed C-ILP approach as the total number
knows what as epistemic information; 2) if car D knows a of agents in the system arises. The middle graph compares
thousand nodes, only the ones that lead to node l will ever communication costs using the C-ILP approach against the
be transferred across; 3) instead of returning all generated centralized approach, with a graph of 120 links and varying
hypotheses back to the initiator, a scoring method can be number of agents. We noticed that communication savings
adopted to discriminate the hypotheses further. For example, with the C-ILP approach are signiﬁcant when the total num-
we have used a variation of the minimum description length ber of agents is small. As the number of agents increases
(MDL) metric to favor shorter hypotheses but using more (along with the entropy of the system) the beneﬁt decreases
link terms in our implementation. However, it is noticed and ﬁnally the cost using C-ILP exceeds that of the central-
that regardless of what scoring method is being used, just ized approach. A similar situation occurs when using graphs
returning the hypothesis with the highest score to the query of other sizes. We believe this can be explained in terms of
initiator often makes the entire approach incomplete. This is the participation of agents during the solution of the C-ILP
due to the fact that each agent can make no assumption about problem. As the number of agents increases, the link infor-
other agents’ knowledge status, while evaluating a hypothesis mation is more evenly distributed over agents and each agent
and the scores assigned only reﬂect its own knowledge of the solves a smaller partial sub-problem. As a result, each agent
world. Therefore, it can often be the case that a suboptimal has less knowledge which makes it harder to come up with
hypothesis to one agent may well be what the other party is useful hypotheses. Consequently, communication costs can
actually looking for. Generally speaking, the best one can do override the beneﬁt gained from induction. We explore this
is to increase the likelihood of returning a better hypothesis in aspect and illustrate in the graph on the right the relationship
earlier attempts by having the agents progressively returning between communication costs and partial knowledge repre-
starting from the hypothesis with the highest score, one at a sented as “links per agent”, L. It is found that the C-ILP ap-
time, until either all hypotheses are returned or the other party proach outperforms the centralized approach uniformly with
is satisﬁed.                                          different numbers of agents and graph sizes when each agent
                                                      has, roughly speaking, 30 links or more.
5  Experiments and Analysis
Some preliminary experimental results were shown in     More sophisticated epistemic reasoning also promise to ex-
[Huang and Pearce, 2006b] focusing on pairwise commu- tend the basic techniques presented above to make it more
nication costs during interaction between two agents. More cost effective. As previously commented, better scoring tech-
thorough experiments have been performed and the results niques than we have used here are possible, facilitating the ex-
reported in this paper analyze the effect in communication change of additional epistemic information which would lead
costs with different numbers of agents, A, and with varying to additional savings in communication. For example, agents
graph sizes, G. In our experiments A varies from 2 to 6 and may beneﬁt from gathering and considering hypotheses from
G varies from 60 to 120. The experiments involve distribut- more than one agent before pursuing further; they may dis-
ing the total G links randomly over the A agents. We ran 100 criminate information from one source against another; they
trials for every different value of A and G using the C-ILP may know who is more likely to know the answer to a partic-
approach and compared this against a centralized approach in ular query; they may even know based on some prior knowl-
terms of the total communication cost involved (measured as edge whom to avoid asking some particular queries. In gen-
the number of “terms” transferred). The centralized approach eral, we believe performing reasoning at epistemic level will
involves having every agent (one at a time) transferring across play a key role in tackling these problems [van der Hoek,
distributed path information to the query initiator before exe- 2001]. Nevertheless, our model accommodates the treatment
cuting a path ﬁnding algorithm.                       of reasoning at epistemic level using the K operator and the
  Results are summarized and plotted in Fig. 3. The one on knowledge base.

                                                IJCAI-07
                                                  1331