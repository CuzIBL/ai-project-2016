                       Fast and Complete Symbolic Plan Recognition

                         Dorit Avrahami-Zilberbrand      and  Gal A. Kaminka
                                     Computer Science Department
                                       Bar Ilan University, Israel
                                      {avrahad1,galk}@cs.biu.ac.il


                    Abstract                          vations may be of continuous actions, maintained over time.
                                                      For instance, an observation of a soccer player may include
    Recent applications of plan recognition face sev- its team name, uniform number, current position, velocity,
    eral open challenges: (i) matching observations   etc. The computational cost of matching such observations
    to the plan library is costly, especially with com- against all possible plan-steps is non-trivial, and grows in the
    plex multi-featured observations; (ii) computing  complexity of the observation tuple. However, existing inves-
    recognition hypotheses is expensive. We present   tigations ignore this cost. Second, with few exceptions, exist-
    techniques for addressing these challenges. First, ing algorithms focus on the current state query (e.g.,[Tambe
    we show a novel application of machine-learning   and Rosenbloom, 1995; Bui, 2003]). Some go as far as to
    decision-tree to efﬁciently map multi-featured ob- ignore all [Tambe and Rosenbloom, 1995] or portions [Wærn
    servations to matching plan steps. Second, we pro- and Stenborg, 1995] of the observation history, and are un-
    vide efﬁcient lazy-commitment recognition algo-   able to utilize negative evidence (where an expected action
    rithms that avoid enumerating hypotheses with ev- was not observed).
    ery observation, instead only carrying out book-    This paper focuses on a set of efﬁcient algorithms that
    keeping incrementally. The algorithms answer      tackle these challenges: First, we develop a method for auto-
    queries as to the current state of the agent, as well as matically generating a matching decision-tree that efﬁciently
    its history of selected states. We provide empirical matches multi-feature observations, to the plan library. Sec-
    results demonstrating their efﬁciency and capabili- ond, we provide algorithms for efﬁciently answering the cur-
    ties.                                             rent state and state history queries. These lazy-commitment
                                                      algorithms avoid computation of hypotheses on every step (as
1  Introduction                                                        [                 ]
Plan recognition is the process of inferring another agent’s other algorithms do Geib and Harp, 2004 ). Instead, they use
plans, based on observations of its interaction with its en- linear-time (current state) and polynomial-time (state-history)
vironment. Recent applications of plan recognition require bookkeeping with every observation, which allows extraction
observing agents whose behavior is reactive [Rao, 1994], in of hypotheses only as needed. Our algorithms are complete,
that the observed agent may interrupt plan execution, switch in that they admit all recognition hypotheses consistent with
to a different plan, etc. Such applications include intrusion the history of observations; they are symbolic in that they pro-
detection applications [Geib and Harp, 2004], virtual train- vide hypotheses with no ranking (probabilistic or otherwise).
ing environments [Tambe and Rosenbloom, 1995], and visual We explore the performance of the recognition algorithms
monitoring [Bui, 2003].                               with simulated data, and show that they are signiﬁcantly
  In general, plan recognition relies on a plan library of plans faster than previous techniques. Their efﬁciency and com-
potentially executed by the observed agent. Typically, the pleteness make them particularly suited for hybrid plan recog-
                                                                           [                  ]
plan library is composed of top-level plans that are hierar- nition approaches (e.g., Geib and Harp, 2004 ) in which a
chically decomposed. The recognizer matches observations symbolic recognizer ﬁlters inconsistent hypotheses, passing
to speciﬁc plan steps in the library. It may then infer an- them to a probabilistic inference engine.
swers to plan recognition queries, such as the currently se- 2 Background and Related Work
lected top-level plans (current state query), or the ordered We focus this brief discussion on closely related work, partic-
sequence of (completed or interrupted) selected plans (state ularly allowing recognition of interruptible plans. See [Car-
history query).                                       rbery, 2001] for a recent survey of general plan recognition.
  Existing work leaves several challenges open (see Section Several investigations have utilized multi-featured obser-
2 for details). First, most existing work assumes observations vations (also of continuous actions), but did not address the
to be of atomic instantaneous actions. However, observa- efﬁciency of matching observations to the plan library, in con-
tions in recent applications are often complex multi-featured trast to our work: RESC [Tambe and Rosenbloom, 1995] and
tuples, involving symbolic, discrete, and continuous compo- RESL [Kaminka and Tambe, 2000] use a hierarchical rep-
nents (e.g., multiple actuators of the agent). Moreover, obser- resentation (similar to what we use) to maintain a single hy-pothesis (RESC) or multiple hypotheses (RESL) as to the cur-

rent state of an observed agent. Both algorithms ignore ob-                   root
servation history in the current state hypotheses, and do not
address state history, in contrast to our algorithms.
           [                 ]                                2 1               1 2          2 3
  Geib et al. Geib and Harp, 2004 developed PHATT, a hy-        defend        attack        score
brid recognizer, where a symbolic algorithm ﬁlters inconsis-
tent hypotheses before they are considered probabilistically.
PHATT assumes instantaneous, atomic actions, and takes a          clear
generate-and-test approach: With each observation, the sym- 1 2          1     1   2       1     2   3
                                                        position turn position position turn pass position turn kick
bolic algorithm generates a pending set of possible expected
observations, which are matched against the next observation      Approach 
to maintain correct state history hypotheses. The size of the       ball
pending set may grow exponentially [Geib, 2004]. In con- 2     2                2      2    2       2
                                                         without with          without With without with 
trast, our work decouples the current state and state history ball ball         ball  ball   ball  ball
queries, and incrementally maintains hypotheses implicitly, Figure 1: Example plan library. Circled numbers denote times-
without predicting impending observations. The hypotheses tamps (Section 4).
are thus computed only when needed (when hopefully, many is visible within shooting distance. If all the above conditions
of them have been ruled out).                         are satisﬁed, the plan matches the observation.
  Other investigations assume atomic observations, and do At any given time, the observed agent is assumed to be ex-
                                [
not consider the cost of matching. Wærn and Stenborg, ecuting a plan decomposition path, root-to-leaf through de-
    ]
1995 explores plan-recognition with limited observation his- composition edges. Figure 1 shows an example portion of a
                                             [
tory, to facilitate recognition of reactive behavior. Retz- plan library, inspired by the behavior hierarchies of RoboCup
            ]
Schmidt, 1991 develops an approach based on matching sub- soccer teams (e.g. [Kaminka and Tambe, 2000]). The ﬁg-
graphs of the plan library. However, the approach does not ure shows decomposition edges (solid arrows) and sequen-
allow for interruptions of plans.                     tial edges (dashed arrows). The top level plans are defend,
  Our work differs signiﬁcantly from probabilistic ap- attack, and score. The ﬁgure does not show the observa-
proaches, though it complements them in principle (as tion conditions associated with plan steps. For presentation
                          [         ]
demonstrated by Geib et al.). Bui, 2003 explores proba- clarity, we show the decomposition edges only to the ﬁrst
bilistic reactive recognition extending hidden Markov mod- (in temporal order) child plans. Thus in the ﬁgure, the path
                              [
els, focusing on current state query. Pynadath and Wellman, root → defend → turn → with ball can be an hypothe-
    ]
2000 explores a probabilistic grammar representation for ef- sis as to the current plan of an observed player. In realistic
ﬁcient plan-recognition. None of these considers the cost of settings, likely more than one path will match an observa-
matching observations, nor separation of state history from tion tuple, and this may result in a set of such decomposition
current state queries.                                paths, i.e., a set of hypotheses as to the current state of the
3  Matching Observations to the Plan Library          observed agent (answering a current state query).
As commonly done in plan recognition work (e.g., [Bui,  An observed agent is assumed to change its internal state
2003]), we utilize a hierarchical representation of the plan in two ways. First, it may follow a sequential edge to the
library (Section 3.1). We present a method for efﬁciently next plan step. Second, it may reactively interrupt plan ex-
matching multi-feature observations to the library (3.2). ecution at any time, and select a new (ﬁrst) plan. For in-
3.1  The Plan Library                                 stance, suppose the agent was executing root → defend →
                                                      turn →   with ball, and then interrupted execution of this
We represent the plan library as a single-root directed acyclic plan. It may now choose root → attack → pass, but not
connected graph, where vertices denote plan steps, and edges root → attack → turn → withball.
can be of two types: vertical edges decompose plan steps into
sub-steps, and sequential edges specify the expected tempo- 3.2 Efﬁcient Matching
ral order of execution. For the discussion, we refer to the The ﬁrst phase of recognition, common to all recognition ap-
children of the root node as top-level plans, and to all other proaches, matches the observations made by the recognizer
nodes simply as plans. However, we use the term plan here in to plans in the plan library. In contrast with previous work,
its general sense, inclusive of reaction plans, behaviors, and we consider complex observations, that consist of a tuple of
recipes. Indeed, to represent behavior-based agents (where observed features, including states of the world that pertain
typically behaviors execute over a number of time-steps), to the agent (e.g.,a soccer player’s uniform number), actions
plans may have a sequential self-cycle, to allow them to be taken (e.g., kick), and execution conditions maintained (e.g.,
re-selected. However, no cycles are allowed hierarchically. speed = 200). Matching such observations to plans can be
  Each plan has an associated set of conditions on observable expensive, if we go over all plans and for each plan check all
features of the agent and its actions. When these conditions observed features. This, in fact, is what previous work essen-
hold, the observations are said to match the plan. For exam- tially proposes (e.g.,[Kaminka and Tambe, 2000]).
ple, a kick-ball-to-goal plan (of a robotic soccer player) may To speed this process, we augment the plan library with
have the following features: The ball must be visible, the dis- a Feature Decision Tree (FDT), which efﬁciently maps ob-
tance to the ball is within a given range, and the opponent goal servations to matching nodes in the plan library. An FDTis a decision tree, where nodes correspond to features, and Algorithm 1 CSQ(Matching results M, Library g, Time-stamp t)
branches to conditions on their values. Determining the plans 1: for all v ∈ M do
that match a set of observation features is efﬁciently achieved 2: P ropagateUp(v, g, t)
by traversing the FDT top-down, taking branches that corre- 3: for all v ∈ M do
spond to the observed values of features, until a leaf node is 4: while tagged(v, t) ∧ ¬∃ChildT agged(t) do
reached. Each leaf node points at the plans that match the 5: delete_tag(v, t)
conjunctive set of observations along the top-down path. Ide- 6: v ← parent(v)
ally, each leaf nodes points to only one plan, though this may
not be possible due to inherent ambiguity in the plan library.
  An FDT can be automatically constructed, similarly to a phases. First, it calls the P ropagateUp algorithm (Algorithm
machine learning (ML) decision tree [Ross, 1992] but with 2), to tag complete paths in the plan-library that match the
important differences (see below). We map the plan library current observation, but taking into account previous observa-
into a set of training examples, and then use a modiﬁed tree tion. The set of matching plans M is assumed to be ordered
construction algorithm to construct the FDT. Each plan step by depth, parents before children (see below). Then (lines
becomes an example, where the observation conditions be- 3–6) it goes over the resulting tags to eliminate any that are
come attribute values, and the class is the plan step. Features hierarchically inconsistent, i.e., where a parent is tagged, but
not tested by a plan step are treated as all attribute values. Af- none of its children is tagged. CSQ is meant to be called with
ter generating the training set, the construction of the FDT is every new observation. The tags made on the plan-library are
done similar to that of a decision tree with missing attribute used to save information from one run to the next.
values (for lack of space, see [Ross, 1992] for details). The PropagateUp algorithm (Algorithm 2) uses time-
  There are important differences with ML tree construction stamps to tag nodes in the plan library that are consistent
processes. The goal is to construct an FDT that is specialized with the current and previous observations. To do this, it
to the "training examples". Every plan step example appears propagates tags up along decomposition edges. However, the
exactly once, and no pruning step is taken (as is commonly propagation process is not a simple matter of following from
done in ML decision trees).                           child to parent. A plan may match the current observation, yet
  The use of the FDT to efﬁciently match multi-featured ob- be temporally inconsistent, when a history of observations is
servations to plans is a novel application of methods from considered. For instance, suppose that the ﬁrst observation
machine learning to plan recognition. The beneﬁts to plan matches the position plans (Figure 1). The FDT would point
recognition are signiﬁcant: The matching time is dictated by the propagation algorithm to the four instances of position
the height of the FDT, rather than the size of the library (L). (marked with a circled 1), under defend (twice), attack, and
Let F be the number of distinct observable features. In a the- score. However, two of the instances are temporally incon-
oretical worst case, plans test all possible features, and thus sistent (crossed out in the ﬁgure): The second instance of po-
the height of the FDT is O(F ). In the worst-case, the leaf sition (under defend) cannot be a ﬁrst observation, since we
in the FDT would point to O(l) plans, where l is the maxi- should have observed either clear or approachball before
mum number of plans that are ambiguously consistent with a it. Similarly, position under score is inconsistent because
single observation (l << L). Thus the complexity of match- its parent had to have followed attack, which was not yet
ing observations to plans would be at worst O(F + l). This observed. This reasoning about hypothesis consistency over
should be contrasted with a O(F L) used in previous work time is a key novelty compared to [Tambe and Rosenbloom,
([Kaminka and Tambe, 2000]). As with any decision tree, 1995; Kaminka and Tambe, 2000].
there is a one-time cost of constructing the FDT, and storage To disqualify hypotheses that are temporally inconsistent,
overhead in using it. However, these costs were not found to PropagateUp exploits the sequential edges and the time-
be a hindrance in the experiments we conducted (see Section stamps. It assumes that the calls to it have been made in order
5).                                                   of increasing depth (as discussed above). This allows an as-
4  Recognition Algorithms                             sumption (line 5) that matching parents are already tagged or
                                                      do not have any associated observable features (and are thus
We now present algorithms for answering the current state
                                                      compatible with all observations). Line 6 checks for temporal
query (Section 4.1), and the state history query (4.2).
                                                      consistency. Time stamp t is temporally consistent if one of
4.1  Current State Query Algorithms                   three cases holds: (a) the node in question was tagged at time
An important query in reactive plan recognition is with re- t − 1 (i.e., it is continuing in a self-cycle); or (b) the node
spect to the current plan step selected by the observed agent. follows a sequential edge from a plan that was successfully
In most hierarchical plan-libraries—as in ours—this query tagged at time t − 1; or (c) the node is a ﬁrst child (there is
translates to determining the decomposition paths (root-to- no sequential edge leading into it). A ﬁrst child may be se-
leaves) that are consistent with the observations, and poten- lected at any time (e.g., if another plan was interrupted). If
tially are being executed by the observed agent. Each such neither of these cases is applicable, then the node is not part
path is a current-state hypothesis.                   of a temporally-consistent hypothesis (lines 11–12), and its
  CSQ (Algorithm 1) is an efﬁcient algorithm for answering tag should be deleted, along with all tags that it has caused in
the current state query. CSQ’s inputs include the plan library climbing up the graph. This ﬁnal deletion of all failing tags
and pointers to the plan-steps matching the current observa- takes place in lines 15–17.
tion (e.g., as stored in an FDT leaf). It then works in two Figure 1 shows the process in action (the circled numbersAlgorithm 2 PropagateUp(Node w, Plan Library g, Time-stamp t) Suppose we now make observations at time t = 3 that
 1: T agged ← ∅                                       match kick.  The score plan is the only plan consistent
 2: propagateUpSuccess ← true                         with t =  3, though both defend and attack are tagged
 3: v ← w                                             for times t = {1, 2}. However, after having made the ob-
 4: while v 6= root(g) ∧ propagateUpSuccess ∧ ¬tagged(v, t) servation at t = 3, we can safely rule out the possibility
   do                                                 that defend was ever selected by the agent, because score
 5:  if tagged(parent(v), t) ∨ features(parent(v)) = ∅ then can only follow attack, and the lack of evidence for ei-
 6:    if        tagged(v, t    −        1)      ∨    ther clear or approach ball at time t = 3 (which would
       ∃P reviousSeqEdgeT aggedW ith(v, t − 1)   ∨    have made defend a possibility at this time) can be used to
       NoSeqEdges(v) then
 7:      tag(v, t)                                    rule it out. Thus we infer that the sequence of plan paths
 8:      T agged ← T agged ∪ {v}                      that was selected by the robot is attack → position (at
 9:      v ← parent(v)                                t =  1), attack → turn at t = 2 (though we cannot be
10:      propagateUpSuccess ← true                    sure which one of turn’s children was selected), and ﬁnally
11:    else                                           score →  kick. If we had only wanted the current-state hy-
12:      propagateUpSuccess ← false                   potheses for time t = 3, we would not need to modify hy-
13:  else                                             potheses for time t = 2. However, generating the state history
14:    propagateUpSuccess ← false                     hypotheses requires us to do so.
     ¬propagateUpSuccess
15: if                  then                            We use an incrementally-maintained structure, the Hy-
16:  for all a ∈ T agged do
17:    delete_tag(a, t)                               potheses Graph (described below), that holds hypotheses ac-
                                                      cording to time stamps. With every time stamp t, we can use
                                                      the structure to eliminate hypotheses that were tagged at time
in the ﬁgure denote the time-stamps). Assume that after the t − 1, that have become invalid. This also allows separation
matching algorithm returns (at time t = 1), the Propagate be- of the current-state hypotheses from the state history hypothe-
                                                                                                    [
gins with the four position instances. It immediately fails to ses, something not addressed with previous work (e.g., Geib
                                                                            ]
tag the instance that follows clear and approachball, since and Harp, 2004; Bui, 2003 ).
these were not tagged at t = 0. The position instance un-
                                                           Time 
der score is initially tagged, but in propagating the tag up, stamp
the parent score fails, because it follows attack, and attack
is not tagged t = 0. Therefore, all tags t = 1 will be      1     defend-position   attack-position
removed from score and its child position. The two re-
maining instances successfully tag up and down, and result
                                                              defend- Defend- attack- attack- score- score-
in possible hypotheses root → defend → position and           turn-        turn- turn-  turn- turn-
                                                            2        turn-
root → attack → position.                                     without      without with ball without with ball
Complexity Analysis. For each plan instance that matches      ball   with ball ball     ball
the observations, the propagation traverses the height of the
plan library, expected to be O(log L). Note that previous   3                  score-kick
works (e.g.,[Kaminka and Tambe, 2000]) have the same prop-    Figure 2: An example extracting graph G0.
agation complexity, but do not ﬁlter temporal-inconsistency.
                                                        The hypotheses graph is a connected graph G0, whose ver-
Also, CSQ utilizes time-stamps on the plan library, rather
                                                      tices correspond to successfully-tagged paths in the plan li-
than external data structures (e.g., [Geib and Harp, 2004]).
                                                      brary (i.e., hypotheses). Edges in G0 connect hypothesis ver-
4.2  History of States Query Algorithms               tices tagged with time stamp t to hypothesis vertices tagged
The time stamps used by the CSQ algorithm can be used to with time stamp t + 1. G0 is therefore constructed in levels,
also answer queries about sequence of plan steps taken by where each level represents hypotheses that hold at the cor-
the agent from time t = 0 until now, given the history of responding time stamp. For each set of observations made
                                                                          0
observations. Answering this query, however, is not a trivial at time ti, we add to G a level ti, with nodes for all current
collection of all possible current state hypotheses as gener- state hypotheses that were successfully tagged t = t0. We
ated at times t = 0, . . . , now, since observations (and lack then create edges between vertices x1, . . . , xn in level ti to
thereof—negative evidence) at time tk may rule out current- vertices y1, . . . , ym in level ti−1 in the following manner: If
state hypotheses that were consistent at time tk−1.   xi is not part of a sequence (i.e., it is a ﬁrst child), then we
  An example may serve to illustrate. Continuing the exam- connect xi to each vertex yj, (j = 1...m); otherwise, if xi is
ple above, suppose the observation at time t = 2 matches part of a sequence, we connect xi to yj if any of the plans in
the turn plan (three instances). The tag t = 2 propagates yj has a sequential edge to a plan in xi. Finally, if xi is equal
successfully and there are six possible current-state hypothe- to yj, we connect them to allow for the self-cycles.
ses for time t = 2 (we omit the common  root preﬁx):    To generate all sequences of plan paths that are consistent
                                                                                      0
defend →   turn →  without ball, defend →  turn →     with the observations, we traverse G from the last level ti
with ball, attack → turn →   without ball, attack →   backwards, to level ti−1, and on to the ﬁrst level. Paths that
turn →   with ball, score →  turn  →  without ball,   connect level ti to level t = 1 denote valid state histories. To
score → turn → with ball.                             illustrate, Figure 2 shows G0 for the example above, t = 3.                                                              −4 Depth 3      −3 Depth 4      −3 Depth 5
Complexity Analysis. Let L be the worst-case number of     x 10             x 10            x 10
plans that match a single observation. For each node in G0 6              1.5              4
with time stamp t (of which there could be at most O(L)), we 4             1
check all nodes in time stamp t−1 (again, O(L)), thus a factor                             2
of L2 for each additional level. Thus over N observations, the 2          0.5
                        2                                 0                0               0
worst-case runtime is O(NL ).                               1  3 5  7
                                                              −3             1 3  5 7        1 3  5 7
                                                           x 10
5  Experiments                                            6             0.015            0.04
We show results of experiments evaluating these techniques 4             0.01
with simulated plan libraries and observation sequences. We                              0.02
controlled key parameters, such as the library size L, and the 2        0.005
                                                          0                0               0
number of features used by each single plan f (f ≤ 10), and 1  3 5  7        1 3  5 7        1 3  5 7
the structure of temporal edges. In the experiments below, L 0.01        0.03             0.1


was set by modifying the number of top-level plans (children Average  runtime in sec
of the root node), and the depth of the library. The branching           0.02
                                                        0.005                            0.05
factor was ﬁxed at 3. The maximum length of observation                  0.01
sequence was 10.
                                                          0                0               0
  We generated valid sequences of observations by simulat-  1  3 5  7        1 3  5 7        1 3  5 7
ing execution and selection of plan steps. The process ran-         Number of actions in each node
domly chose a path in the library and used all the features in
this path to generate observations. Based on existence of se- Figure 3: Runtime of FDT (solid line) and RESL (dashed).
quential edges, the process chose to either continue execution Totally 
                                                           Ordered    One         Last       Unordered
along a sequential edge, or jump to a new ﬁrst child. In all
experiments, we contrasted the results with RESL [Kaminka
and Tambe, 2000], the most relevant of the related works.
5.1  Matching Experiments
A ﬁrst set of experiments compares matching run-time using        Figure 4: Sequential Links types.
FDT and RESL, as the plan library grows in size. We gen-
erated different-sized libraries by varying the library depth, ordered: all children of same parent form a single chain; (b)
and number of top-level plans. To demonstrate the scale-up First: ﬁrst child has sequential edge to all its siblings; (c)
offered by the FDT as the observation complexity grows, we Last: siblings have sequential edges leading to the last sib-
also vary f (1,3,5,7). For each of these values, we generated ling; (d) Unordered: no ordering constraints between nodes.
180 random observations sets based on the plan-libraries, and Top-level plans are always unordered.
averaged the run-time for matching these using RESL and us- Propagation Accuracy. A key advantage of CSQ over RESL
ing an automatically constructed FDT.                 is its ability to use sequential edges and the history of obser-
  The average matching runtime is shown in Figure 3. The vations to rule out hypotheses that are temporally inconsistent
ﬁgures are arranged in a 3 × 3 matrix. The rows correspond (Section 4.1). Given a sequence of observations, we expect to
to the number of top-level plans (5, 50, and 100, respectively, see fewer current state hypotheses in comparison with RESL.
top-down). The columns correspond to library depths of 3,4 We again varied the library size through the number of top-
and 5. Thus the bottom right ﬁgure shows the results for the level plans (10,50,100) and the depth of the plan library (3–
largest library, approximately 12,101 nodes. The FDTs for 6). We vary the temporal structure of the library as described
these included 200–2000 nodes, depending on the number of above. Trials were conducted with sequences of 10–40 obser-
features associated with each plan (f). In all ﬁgures, the hor- vations. We recorded the number of hypotheses maintained
izontal (X) axis shows f, and the vertical axis shows the av- after each observation was propagated.
erage matching time in seconds. Each point in a ﬁgure is the Figure 5 shows the effect of sequential edges types on the
average of 180 runs.                                  number of hypotheses. There are four ﬁgures, each for dif-
  Clearly, the use of the FDT leads to very signiﬁcant im- ferent depth (3–6). The X axis shows the number of top-level
provements in the matching time, compared to RESL—and plans, while the Y axis measures the average number of hy-
even when each plan is associated with a single atomic ob- potheses across all trials of the same conﬁguration. Each data
servation. Furthermore, its growth curve indicates that its point reﬂects the average number of hypotheses over 3000 in-
beneﬁts are maintained even as the observations increase in dividual observations, organized as 120 random observation
complexity.                                           sequences (each 10–40 observations in length), based on the
                                                      generated libraries.
5.2  Query Answering Algorithms                         The ﬁgures show that totally-ordered libraries allow CSQ
We now turn to evaluate the algorithms answering the current- to maximally use past observations, and thus result in less
state and state-history queries. These answers depend criti- hypotheses. In contrast, unordered libraries have no sequen-
cally on the temporal structure of the plan library, in terms of tial edges, and thus do not gain information from a history
sequential edges. We follow [Geib and Harp, 2004] in vary- of observations. Thus the number of hypotheses generated in
ing temporal structure in several ways (Fig. 4): (a) Totally this case is exactly the same as generated by RESL—which