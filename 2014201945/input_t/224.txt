                         A Statistical Model for Flexible String Similarity 

                                                   Atsuhiro Takasu 
                                          National Institute of Informatics 
                             2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan 
                                                   takasu@nii.ac.jp 

                        Abstract 

     This paper proposes a statistical model for defining 
     string similarity. The proposed model is based on 
     hidden Markov model and defines string similar•
     ity as the combination of similarities of substrings. 
     The proposed model has an advantage that the sim•
     ilarity is flexibly defined and complex parameters 
     for the similarity are learnable from training data. 

 1 Introduction 
 String matching is an important problem. Many studies have 
been done on this problem and developed methods are ap•                    Figure 1: An example of DVHMM 
plied to various problems such as approximate information 
retrieval from OCR processed and spoken documents, pattern 
extraction from sensor data and so on.                         a base string and one character in a compared string. A state 
                                                               (1,0) means that the length of the base (resp. compared) string 
   In order to measure the similarity of strings, edit distance 
                                                               is 1 (resp. 0), i.e., a delete operation, whereas a state (0,1) cor•
and DP matching have been frequently used. In the edit dis•
                                                               responds to an insert operation. A state (1,1) corresponds to 
tance, similarity is defined as the minimum number of oper•
                                                              both a replacement operation and equivalent mapping. Gen•
ations of insertion, deletion and replacement required to con•
                                                               erally, the state corresponding to a pair (i,j) produces a pair 
vert one string to another. The DP matching allows us to use 
                                                               of strings whose base string (resp. compared string) length 
weights of the operations which enable flexible definition of 
                                                               is i (resp. j) with certain probability. States are categorized 
string similarity according to objective problems. However, 
                                                               into non-null state that produces a pair of base and compared 
weights should be determined depending on the problem and 
                                                               strings, and null state that produces null output and controls 
it is hard work to find appropriate weights manually. 
                                                              state transitions. 
   This problem motivates us to develop a statistical model 
                                                                 Figure 1 shows an example of DVHMM that consists of 
which has high expressive power of string similarity and 
                                                              five non-null states which define the similarity of pairs of 
whose parameters can be learned from training data. This pa•
                                                              substrings of length (1,0),(0,1),(1,1),(2,1) and (1,2). In this 
per proposes a statical model called dual and variable length 
                                                              figure, output symbols are omitted due to space restrictions. 
hidden Markov model (DVHMM) and applies it to structured 
                                                              Suppose the alphabet is {a,b}. Then, the output symbols of 
string analysis. 
                                                              the state (2,1) are 
                                                               {(aa,a),(aa,b),(ab,a),(ab,b),(ba,a), (ba,b),(bb,a),(bb,b)} and 
2 Statistical Model for String Similarity                     output probability is asigned to each output symbol. 
For a base string and a compared string, DVHMM defines           DVHMM defines joint probability distribution of a pair of 
their similarity by decomposing them into pairs of substrings strings. Let us consider a base string "ab" and a compared 
and combining the similarities of the substrings.             string "a". Then, the DVHMM in Figure 1 produces the pair 
   A DVHMM is a form of Hidden Markov Model (HMM).            of strings (ab, a) by one of the following six sequences of 
Instead of producing a string, state transitions of DVHMM     state transitions. 
produce a pair of strings. Each state of the DVHMM defines 
the similarity of pairs of strings of fixed lengths in the form 
of output probability. A state is characterized by a pair of 
lengths. For example, a state characterized by a pair (2,1) of 
lengths defines similarities of two consecutive characters in Then, the joint probability of (ab,a) is obtained by summing 


1420                                                                                                  POSTER PAPERS                                                                3 Preliminary Experiment 
                                                               We applied the proposed method to bibliographic matching 
                                                               which matches references in academic articles with records 
                                                               in bibliographic databases. Reference information is effec•
                                                               tively used in digital libraries such as CiteSeer [Lawrence, 
                                                               1999]. In bibliographic references, bibliographic components 
                                                               such as author's name and article title are located in a specific 
                                                               order and separated by delimiters. The syntactical structure 
                                                               of bibliographic reference can be represented with graphical 
                                                               structure of finite automaton where each state represents a 
                                                               bibliographic component. A DVHMM for bibliographic ref•
                                                               erences is obtained by replacing each state with a component 
 Figure 2: An example of DVHMM for strings consisting of       DVHMM like Figure 2 where each component DVHMM de•
two components                                                 fines the similarity of the corresponding bibliographic com•
                                                               ponent. For example, because journal names are often ab•
the probabilities of all the five sequences of transitions. For• breviated, higher probabilities are assigned to deletion er•
mally, for a base string b and a compared string c, the joint  rors in the DVHMM for journal name whereas low proba•
probability of them is obtained by                             bilities are assigned to the deletion errors for page because 
                                                               it is seldom abbreviated in references. In this way, the simi•
                                                        (1)    larity is changed depending on the bibliographic components, 
                                                               and consequently, more accurate similarity model can be con•
                                                               structed for structured strings. 
where Q is a set of state transitions producing (b,c) and        We carried out an experiment on approximate string match•
P(b, c, q) is the joint probability of (b, c) along the state tran• ing. In this experiment, we prepared 1,575 references 
sition q. The joint probability is used as the similarity of a appeared in Japanese academic articles and corresponding 
pair of strings.                                               records in a bibliographic database, then applied 5-fold cross-
   DVHMM inherits HMM's ability to represent syntactical       validation, i.e., divided them into 5 groups, trained DVHMM 
structure. This ability enables DVHMM to change similar•       using 4 groups of them, and made bibliographic matching us•
ity definition depending on the part of strings. Let us con•   ing remaining one group. Matching result is ranked records 
sider strings consisting of two components delimited by spe•   in the database according to the similarity. We used edit dis•
cial characters. For example, base string consists of two parts tance as baseline similarity and compared the performance of 
delimited by colon and compared string is concatenation of     the proposed method with the edit distance. The following 
two parts without delimiters. Then, the DVHMM depicted in      table shows the average accuracy that the correct record is 
Figure 2 defines the similarity of these strings, i.e., a com• ranked within top m records. 
ponent DVHMM C\ defines similarity of prefix component 

whereas a component DVHMM C2 defines the similarity of 
suffix component. State N3 defines the delimiter, which pro•
duce a pair of colon and null string with probability 1.0. For a 

given pair (ua:ab", "ab") of string, the DVHMM may separate      As shown in the table the proposed method achieved higher 
the pair into ("a","a") as a prefix component and ("b","b") as matching accuracy. 
a suffix component, and similarities of these components are 
measured by different similarity measures, i.e., C1 and C2.    4 Conclusion 
respectively. In this case, similarity can be calculated by the 
                                                               This paper proposed a statistical model for defining string 
joint probability of the pair of string produced by the most 
                                                               similarity. The proposed model can represent similarity of 
likely state transition, i.e., 
                                                               strings with the similarities of substrings such as traditional 
                                                        (2)    edit distance and DP matching. However, the proposed model 
                                                               can define the similarity more flexible way. This paper shows 
                                                               the proposed model can be applied to the matching of struc•
where Q is the same set in expression (1). 
                                                               tured strings. 
   Probabilities of DVHMM can be estimated from train•
ing data by the expectation-maximization technique             References 
efficientlytTakasu, 2002]. For a given pair (b,c) of strings, 
the similarity (2) can be calculated efficiently by a dy•      [Lawrence, 1999] S. Lawrence, C. L. Giles, and K. D. Bol-
namic programming algorithm. We omit the details of the           lacker. Digital libraries and autonomous citation indexing. 
algorithms due to space restriction.                              IEEE Computer, 32(6):67-71, June 1999. 
   Compared with DP matching, DVHMM enables to                 [Takasu, 2002] A. Takasu and K. Aihara. DVHMM: Variable 
   • define the weights in a more detailed manner, and            Length Text Recognition Error Model. In Proceedings of 
                                                                  International Conference on Pattern Recognition 2002. 
   • calculate the weights systematically. 


POSTER PAPERS                                                                                                       1421 