                                                                                    Q
                A Probabilistic Lexical Approach to Textual Entailment                

                            Oren Glickman, Ido Dagan, Moshe Koppel  
                                         Bar Ilan University 
                                   Computer Science Department 
                                          Ramat-Gan, Iarael 
                               {glikmao, dagan, koppel}@cs.biu.ac.il 

                    Abstract 
                                                    A Probabilistic Setting  
   The textual entailment problem is to determine if a We propose a general generative probabilistic setting for 
   given text entails a given hypothesis. This paper textual entailment. We assume that a language source gen-
   describes first a general generative probabilistic erates texts within the context of some state of affairs. Thus, 
   setting for textual entailment. We then focus on the texts are generated along with hidden truth assignments to 
   sub-task of recognizing whether the lexical con- hypotheses. We define two types of events over the corre-
   cepts present in the hypothesis are entailed from sponding probability space: 
   the text. This problem is recast as one of text cate- I) For a hypothesis h, we denote as Trh the random variable 
   gorization in which the classes are the vocabulary whose value is the truth value assigned to h in the world of 
   words. We  make novel use of NaÃ¯ve Bayes to      the generated text. Correspondingly, Trh=1 is the event of h 
   model the problem in an entirely unsupervised    being assigned a truth value of 1 (True). 
   fashion. Empirical tests suggest that the method is II) For a text t, we use t to denote also the event that the 
   effective and compares favorably with state-of-the- generated text is t. 
   art heuristic scoring approaches.                Textual entailment relationship: We say that t probabilis-

                                                    tically entails h (denoted as t N h) if t increases the likeli-
Textual Entailment                                  hood of h being true, that is if P(Trh = 1| t) > P(Trh = 1). 
Many  Natural Language Processing (NLP) applications Entailment confidence: We quantify the marginal amount 
need to recognize when the meaning of one text can be ex- of information contributed by the text to assessing the truth 
pressed by, or inferred from, another text. Information Re- of the hypothesis relative to its prior with the pointwise mu-
trieval (IR), Question Answering (QA), Information Extrac- tual information: I(Trh=1,t)=log(P(Trh = 1| t) / P(Trh = 1)). 
tion (IE) and text summarization are examples of applica-
tions that need to assess such semantic overlap between text An Unsupervised Lexical Model  
segments. Textual Entailment Recognition has recently been The proposed setting above provides the necessary ground-
proposed as an application independent task to capture such ing for probabilistic modeling of textual entailment. How-
semantic inferences and variability [Dagan et al., 2005]. A ever, it is important to bear in mind that it is not trivial to 
text t textually entails a hypothesis h if t implies the truth of estimate the constituent probabilities in the definition of 
h. Textual entailment captures generically a broad range of textual entailment since the truth assignments of hypotheses 
inferences that are relevant for multiple applications. For for the corpusâ€™ texts are not observed.  
example, a QA system has to identify texts that entail the 
expected answer. Given the question "Where was Harry Lexical Entailment as Text classification 
Reasoner born?", a text that includes the sentence "Harry As modeling the full extent of the textual entailment prob-
                                                    lem is a long term research goal, we focus on a sub task we 
Reasonerâ€™s birthplace is Iowa" entails the expected answer 
                                                    term lexical entailment - recognizing if the individual lexi-
form "Harry Reasoner was born in Iowa." In many cases, 
though, entailment inference is uncertain and has a probabil- cal concepts in a hypothesis are entailed from a given text. 
istic nature. For example, a text that includes the sentence When estimating the entailment probability we assume 
                                                                                              h 
"Harry Reasoner is returning to his Iowa hometown to get that the truth probability of a term in a hypothesis is inde-
                                                    pendent of the truth of the other terms in h, obtaining: 
married." does not deterministically entail the above answer      O

                                                      P(Trh = 1| t) = u P hP(Tru=1|t) 
form. Yet, it is clear that it does add substantial information  O                                (1) 
about the correctness of the hypothesized assertion.  P(Trh = 1) = u P hP(Tru=1) 
                                                    At this point, it is perhaps best to think of the entailment 


                                                    problem as a text classification task in which the classes are 


  Â 


     Â¦Â¨Â§
Â©Â§
Â¦Â¦Â¥Â©Â¤  !"#$%Â¢&'
Â¡(Â©)*+Â¨+Â¨Â©,-Â¢Â¥


    Â¡Â£Â¢Â¥Â¤                                           an abstract binary notion of lexical truth (for the different 


              #Â£34 56%Â¢Â¥(Â£78'9157
:<;
Â¥/Â§6Â©Â©,.=5>Â£? ? >Â£@3


.Â¥/Â©021Â©+Â¨+2Â¤                       words in the vocabulary). First, we construct the initial la-


               Â¦D"? Â¤ >Â¥Â¤ Â©JÂ©? #Â¨*, ? >0 Â¦K%Â¢JÂ¥Â¢Â©Â¦DLÂ£MÂ¤ 5Â§
Â¦ I
&'
Â¡ A/B9CCBDAEÂ¥CÂ¥FGÂ¥GHDIÂ¡Â¢Â¤          beling based solely on the explicit presence or absence of correspond to potential questions, semantic queries or IE 
each u in t. Then we apply NaÃ¯ve Bayes in an unsupervised relations. We created a set of candidate entailing texts for 
fashion that derives analytically from the defined probabilis- the given set of test hypotheses, by following common prac-
tic setting.                                        tice of morphological and WordNet-based expansion.  Boo-
                                                    lean search (with expanded words) was performed at the 
Initial Labeling                                    paragraph level over the full Reuters corpus. Paragraphs 
As an initial approximation, we assume that for any docu- containing all original words of the hypothesis or their mor-
                                                u 
ment in the corpus the truth value corresponding to a term phological derivations were excluded from the result set and 
                                          u 
is determined by the explicit presence or absence of in that selected a random set of 20 texts for each of the hypotheses.  
document.                                             The resulting dataset was given to two judges to be anno-
  In some respects the initial labeling is similar to systems 
                                                    tated for entailment. Corresponding to the notion of textual 
that perform a Boolean search (with no expansion) on the entailment, judges were asked to annotate a text-hypothesis 
keywords of a textual hypothesis in order to find candidate pair as true if, given the text, they could infer with some 
(entailing) texts. Of course, due to the semantic variability 
                                                    confidence that the hypothesis is true. They were instructed 
of language, similar meanings could be expressed in differ-
                                                    to annotate the example as false if either they believed the 
ent wordings, which is addressed in the subsequent model. hypothesis to be false given the text or if the text is unre-
The initial labeling, however, may provide useful estimates lated to the hypothesis. A subset of 200 pairs was cross-
for this model.                                     annotated for agreement, resulting in a moderate Kappa 
NaÃ¯ve Bayes Refinement                              statistic of 0.6. Overall, the annotators deemed 48% of the 
Following the standard naÃ¯ve Bayes assumption, we can text-hypothesis pairs as positive examples of entailment. 
rewrite the probability P(Tr =1|t) as in (2). In this way we 
                       u                            Empirical Results 
are able to estimate P(Tru=1|t) based on the prior P(v| Tru=1) We trained our model on the Reuters corpus, classified the 
                         v            v
and the lexical probabilities P( | Tru=1) and P( | Tru=0) for text-hypothesis pairs of the dataset and compared the 
    u  v               V
every ,  in the vocabulary . These probabilities are easily modelâ€™s prediction with the human judgments. The resulting 
estimated from the corpus given the initial modelâ€™s estimate 
                                                    (macro) average accuracy was 70%. Since our dataset did 
of truth assignments, assuming a multinomial event model 
                                                    not include texts containing all content words of the hy-


for documents and Laplace smoothing ([McCallum and Ni- potheses, the baseline model would have predicted none of 
                      U
gam, 1998]).                         U




                         S                          the pairs to be correct (i.e. the text entails the hypothesis) 


                V            V


     U     U


V                        U              U
                  (Tr  1)   T  (v | Tr 1)           yielding an average accuracy of only 52%.  


                    u      v t      u


             R              S
                   V


 (Tru  1| t)                     V            (2)     We  also compared our systemâ€™s ranking ability. The en-
                               T
                T   (Tr   c)      (v | Tr c)
               c {0,1} u       v t     u            tailment confidence score was used to rank the various texts 
                                                    of each hypothesis. The average confidence weighted score 
  From above equations we have a refined probability esti-
                                                    (cws) was measured for each hypothesis. The resulting cws 
mate for P(Tr =1| t) and P(Tr =1) for any arbitrary text t and 
           h            h                           macro average was 0.54 compared to average cws of 0.49 
hypothesis h. The criterion for turning probability estimates 
                                                    for random ordering. For further comparison, a state of the 
into classification decisions is derived analytically from our 
                                                    art idf semantic overlap measure [Saggion et al., 2004; 
proposed probabilistic setting of textual entailment. We 
                                                    Monz and de Rijke, 2001] achieved a score of 0.51. Though 
classify positively for entailment if P(Tr =1| t) > P(Tr =1) 
                                 h           h      our model performs just slightly better, the results are statis-
and assign a confidence score of log(P(Tr =1|t) / P(Tr =1)) 
                                  h          h      tically significant at the 0.02 level. 
for ranking purposes. In fact, the empirical evaluation 
showed this analytic threshold to be almost optimal.  References 
1  Empirical Evaluation                             [Dagan  et al., 2005] Ido Dagan, Oren Glickman and 
                                                       Bernardo Magnini. The PASCAL  Recognising Textual 
Experimental Setup                                     Entailment Challenge. PASCAL Challenges Workshop. 
Though empirical modeling of semantic inferences between [McCallum and Nigam, 1998] Andrew McCallum and Ka-
texts is commonly done within application settings, there is mal Nigam. A Comparison of Event Models for Naive 
no common dataset available to specifically evaluate a tex- Bayes Text Classification. AAAI-98 Workshop on 
tual entailment system. In order to test our model we there- "Learning for Text Categorization". 
fore needed an appropriate set of text-hypothesis pairs. We 
chose the information seeking setting, common in applica- [Munz and de Rijke, 2001] Christof Monz, Maarten de Ri-
tions such as QA and IR, in which a hypothesis is given and jke. Light-Weight Entailment Checking for Computa-
it is necessary to identify texts that entail it. The evaluation tional Semantics. The third workshop on inference in 
criterion is application-independent based on human judg- computational semantics (ICoS-3). 
ment of textual entailment.                         [Saggion et al., 2004] Horacio Saggion, Rob Gaizauskas, 
  Experiments were done on the Reuters Corpus Volume 1. Mark Hepple, Ian Roberts and Mark A. Greenwood. Ex-
An annotator chose 50 sentential hypotheses from the cor- ploring the Performance of Boolean Retrieval Strategies 
pus sentences. We required that the hypotheses convey a For Open Domain Question Answering. SIGIR04 Work-
reasonable information need in such a way that they might shop on Information Retrieval for Question Answering.   