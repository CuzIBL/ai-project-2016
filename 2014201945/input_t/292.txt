                   Broadcast News Navigator (BNN) Demonstration 
                                          Mark Maybury 
                                 Information Technology Division 
                                     The MITRE Corporation 
                                       202 Burlington Road 
                                    Bedford, MA 01730, USA 
                                        mavburv(a),mitre. org 
                                 www, mitre. or2/resources/centers/it 

                   Summary 
  The Broadcast News Navigator (BNN) is a fully im• 2 Named Entity Search and Retrieval 
 plemented system that incorporates image, speech, BNN supports the retrieval of stories based on user 
  and language processing together with visualization query, either keyword, named entity, or topics. For ex•
  and user preference modeling to support intelligent, ample, the user can specify source, date ranges, key•
 personalized access to broadcast news video. The  words, subjects, or named entities. As show in Figure 1, 
  demonstration will illustrate the use of the system's after selecting news programs (e.g., CNN NewsNight, 
  underlying machine learning enabled story segmen• ABC World News Tonight, Fox News) and indicating 
 tation and processing, called the Broadcast News  date ranges (in this case January 6-9, 2003), a user can 
  Editor (BNE). A live, scenario-based demonstration simply type in keywords in the text box (e.g., "Korean 
 will illustrate the use of named entity search, tempo• weapons of mass destruction"). In addition, if a user is 
 ral visualization of entities, story clustering and geo- unfamiliar with retrieval terms, they can display an al•
 spatial story visualization, discovery of entity rela• phabetic listing of all the named entities extracted for the 
 tions, and personalized multimedia summary genera• time period and from the programs of interest, such as 
 tion. By transforming access from sequential to di• shown in the person, organization, and location searchers 
 rect search and providing hierarchical hyperlinked in Figure 1. Note the evidence of information extraction 
 summaries, we will demonstrate how users can ac•  errors such as "English" under location or "reserve" un•
 cess topics and entity specific news clusters nearly der organization. We will demonstrate how information 
 three times as fast as direct search of digital video. In extraction [Aberdeen et al., 1995] on noisy data such as 
 short, we will demonstrate intelligent news on de• closed caption or speech transcription (as opposed to less 
 mand enabled by a suite of Al technologies.       errorful newswire text) drops from about 90% precision 
                                                   and recall to about 70-80%. 
1 Intelligent Segmentation 
                                                   If the user selects "North Korea" in Figure 1, they are 
Fundamental to BNN is the exploitation of text, audio, provided access to the 39 stories detected during the 
and imagery streams and associated cues which are used week, as presented in the "Story Skim" display shown in 
to detect story and commercial segment boundaries and the left of Figure 2. In this case the system shows the 
to select media elements to use for summaries and mul• source and date, the top 3 named entities in each story, 
timodal displays. We will demonstrate how certain cross and a representative key frame from each selected seg•
media cues such as language content (e.g., frequent ment extracted using heuristics based one the type of 
weather or sports terms, funding and/or copyright no• story segment (e.g., anchor, reporter, interview). Note 
tices), discourse cues (e.g., "coming up next"), music the stories range from several sources (CNN, CNN 
(e.g., characteristic jingles), silence indicating breaks to Money Line, CNN NewsNight with Aaron Brown), dates, 
commercial, and visual cues (e.g., logos, anchor booth vs and times of day. The media elements used in "story 
report shots) help signal program start/end, anchor/report skim" and "story details" were selected after careful em•
shots, commercials, and/or story shifts. Underlying BNN pirical study of the optimal combination of multimedia 
is a set of machine learned, time-enhanced finite state elements for video retrieval and extraction tasks [Merlino 
automata modeling news structure that take into account and Maybury, 1999], The current system [Maybury 2003] 
the above cues and probabilistic, temporal models of allows the user to interactively customize these to their prefer•
event occurrence [Boykin and Merlino, 2000].       ence. 


INTELLIGENT SYSTEMS DEMONSTRATIONS                                                            1639                                                     sociated with geospatial regions, animated over time. 
                                                    Finally, users can interactively run data mining algo•
                                                    rithms to discover relationships among named entities 
                                                    (e.g., people associated with locations or organizations), 
                                                    and automatic detection of topic clusters. In addition, 
                                                    users can set profiles that specify their media (e.g., text 
                                                    summary, image key frames, summary), and navigation 
                                                    preferences (e.g., overviews or not, links to related sto•
                                                    ries). We demonstrate live how BNN users can find video 
                                                    stories and answer questions about two to three times as 
                                                    fast as with original sources, with no performance loss. 


     Figure 1. Text and Named Entity Search Menus 


                                                     Figure 3. Entity and Trend Analysis; Geospatial Display 

                                                    Acknowledgments 
                                                    BNN is the product of numerous contributors including 
                                                    Stanley Boykin, Andy Merlino, Warren Grieff, Jay Ponte, 
                                                    Chris Clifton, and Chad McHenry. 

                                                    References 
                                                    [Aberdeen et al., 1995] Aberdeen, J., Burger, J., Day, D., 
                                                    Hirschman, L., Robinson, P., and Vilain, M. 1995. Description 
 Figure 2. January 2003 North Korean "Story Skim'* and 
                                                    of the Alembic System Used for MUC-6. In Proceedings of the 
                  "Story Details" 
                                                    Sixth Message Understanding Conference, 141-155. 
 3 Relevancy Feedback                               ARPA/ITO, 6-8. Columbia, MD. 
 Users can navigate directly from the Story Skim of Fig• [Boykin and Merlino, 2000] Boykin, S. and Merlino, M. Feb. 
 ure 2 on the left to a "Story Details** display as shown on 2000. A. Machine learning of event segmentation for news on 
 the right. "Story Details" include the key frame, one line demand. Communications of the ACM. Vol 43(2): 35-41. 
 summary (the story line containing the most named enti•
 ties), all extracted named entities, and pointers to video [Merlino and Maybury, 1999] Merlino, A. and Maybury, M. 
 source, transcript, and relevant stories. The user can ei• 1999. An Empirical Study of the Optimal Presentation of Mul•
 ther review the story or engage in further query refine• timedia Summaries of Broadcast News. Mani, I. and Maybury, 
ment, accomplished with an underlying Local Context M. (eds.) Automated Text Summarization, MIT Press. 
Analysis (LCA) algorithm. 
                                                    [Maybury 2003] Maybury, M. 2003. Broadcast News 
4 Visualization and Discovery                       Understanding and Navigation. Innovative Applications 
                                                    of Artificial Intelligence. Acapulco, Mexico. 12-14 
As shown in Figure 3, users can visualize named entity August, 2003 
frequencies by collection, source, or date range, visualize 
temporal occurrences, and display story occurrences as•


 1640                                                         INTELLIGENT SYSTEMS DEMONSTRATIONS 