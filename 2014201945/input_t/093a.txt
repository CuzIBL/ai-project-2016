                                    Natural Object Recognition: 
                 A Theoretical Framework and Its Implementation 

                                Thomas M. Strat and Martin A. Fischler* 
                                            Artificial Intelligence Center 
                                                   SRI International 
                                              333 Ravenswood Avenue 
                                           Menlo Park, California 94025 

                       Abstract 

     Most work in visual recognition by computer 
     has focused on recognizing objects by their ge­
    ometric shape, or by the presence or absence of 
    some prespecified collection of locally measur­
     able attributes (e.g., spectral reflectance, tex-
     ture, or distinguished markings). On the other 
     hand, most entities in the natural world defy 
     compact description of their shapes, and have 
     no characteristic features with discriminatory 
     power. As a result, image-understanding re­
     search has achieved little success toward recog­
     nition in natural scenes. We offer a funda-
     mentally new approach t.o visual recognition 
     that avoids these limitations and has been used 
     to recognize trees, bushes, grass, and trails in 
     ground-level scenes of a natural environment. 

1 Introduction 

The key scientific question addressed by our research 
has been the design of a computer vision system that,           Figure 1: A natural outdoor scene of the experimenta­
can approach human level performance in the interpre­           tion site. 
tation of natural scenes such as that shown in Fig­
ure 1. We offer a. new paradigm for the design of 
computer vision systems that holds promise for achiev­               into homogeneous regions using a single partition 
ing near-human competence, and report the experimen­                 ing algorithm applied to the entire image. If that 
tal results of a system implementing that theory which               partitioning is wrong, then the interpretation must 
demonstrates its recognition abilities in a natural do­              also be wrong, no matter how a system assigns se­
main of limited geographic extent,. The purpose of this              mantic labels to those regions. Unfortunately, uni­
paper is t.o review the key ideas underlying our ap­                 versal partitioning algorithms are notoriously poor 
proach (discussed in detail in previous publications [12,            delineators of natural objects in ground-level scenes. 
13]) and to focus on the results of an ongoing experi­
mental evaluation of these ideas as embodied in an im­          Shape — Many man-made artifacts can be recognized 
plemented system called Condor.                                      by matching a 3D geometric model with features 
   When examining the reasons why the traditional ap­                extracted from an image [l, 2, 4, 6, 7, 9, 15], but 
proaches to computer vision fail in the interpretation of            most natural objects cannot be so recognized. Nat 
ground-level scenes of the natural world, four fundamen­             ural objects are assigned names on the basis of their 
tal problems become apparent:                                        setting, appearance, and context, rather than their 
                                                                     possession of any particular shape. 
Universal partitioning — Most scene-understanding 
     systems begin with the segmentation of an image            Computational complexity The object recogni­
                                                                     tion problem is NP-hard [16]. As a result, computa­
   * Supported by the Defense Advanced Research Projects             tion time must increase exponentially as additional 
Agency under Contracts DACA7G-85-C-U004, DACA76-90-                  classes are added to the recognition vocabulary, un­
C-0021, and 89F737.300                                               less a strategy to avoid the combinatoric behavior is 


1264 Vision                                                                     success of any individual operator. 
                                                                Candidate Comparison — Hypotheses are accepted 
                                                                    only if they are consistent with all other members of 
                                                                    a clique (consistent subset). Candidate hypotheses 
                                                                    for each label are ranked so that the best candidates 
                                                                    for each label can be considered before the oth•
                                                                    ers. Ranking the candidates ensures that, the largest 
                                                                    cliques can be found early in the search, thereby 
                                                                    limiting the computational complexity of the entire 
                                                                    paradigm to a linear growth as the recognition vo•
                                                                    cabulary is expanded. By constructing only a small 
                                                                    number of cliques for each image, the approach loses 
                                                                    any guarantee of finding the largest clique, but as•
                                                                    sures the availability of a credible answer compatible 
                                                                    with the computational resources of the system. 
                                                                Clique Formation — Consistency is enforced by pro•
                                                                    cedures (controlled by context sets) that detect 
                                                                     and reject physically impossible combinations of hy•
      Figure 2: Conceptual architecture of Condor.                   potheses. The clique that most completely explains 
                                                                     the available data is offered as the interpretation of 
                                                                     an image. Thus, individual objects are labeled on 
     incorporated. Such provisions are a necessary com-              the basis of their role in the context, of the complete 
     ponent of any recognition system that can be scaled             clique, rather than solely on the basis of individual 
     to embrace a real domain.                                       merit. 
Contextual knowledge — Despite general 
                                                                  The invocation of all processing elements throughout 
     agreement that recognition is an intelligent process 
                                                                the system is governed by context. All processing ac-
     requiring the application of stored knowledge [3, 5, 
                                                                tions are controlled by context sets, and are invoked 
     14], computer vision researchers typically use artifi•
                                                                only when their context sets are satisfied. Thus, the 
     cial intelligence techniques only at the highest levels 
                                                                actual sequence of computations (and the labeling deci•
     of reasoning. The design of an approach that, allows 
                                                                sions that are made) are influenced by contextual infor•
     stored knowledge to control the lower levels of image 
                                                                mation, which is represented by prior knowledge about 
     processing has proved elusive. 
                                                                the environment and by the computational state of the 
   Except for the continuing work at the University of          system. 
Massachusetts [3], the understanding of natural scenes 
has received surprisingly little attention in the last          Definition: A context set, C'Sk, is a collection of con•
decade.                                                              text, elements that are sufficient for inferring some 
                                                                     relation or carrying out some operation on an image. 
2 Approach                                                      Syntactically, a context set is embedded in a context rule 
A new paradigm for computer vision systems has been             denoted by 
developed, which addresses all four of the problems de•
scribed above. The key provision of this novel approach 
is a mechanism for the application of stored knowledge          where L is the name of the class associated with the 
at all levels of visual processing. A context set, wliich       context set, A is an action to be performed, and the C\ 
explicitly specifies the conditions and assumptions nec•        comprise a set of conditions that define a context. 
essary for successful invocation, is associated with every 
procedure employed by the recognition system.                   Example: The context rule 
   The architecture is organized into three modules as de•
                                                                     SKY : {SKY IS-CLEAR, CAMERA IS-HORIZONTAL 
picted in Figure 2 and described below (a more complete 
                                                                        RGB-IS-AVAILABLF } => BLUE-REGIONS 
description is also available [13]): 
Candidate Generation —                                               defines a set of conditions under which it is appropri•
     Hypotheses concerning the presence in a scene of                ate to use the operator BLUE-REG IONS to delineate 
     specific categories of objects are generated by de•             candidate sky hypotheses. 
     lineating regions in an image using special-purpose 
     operators whose invocation is controlled by context          There is a collection of context rules for every class 
     sets, thereby avoiding the need for universal parti•       in the recognition vocabulary, and each collection con-
     tioning algorithms. The employment of large num•           tains rules of three types: candidate generation, candi•
     bers of operators ensures that quality hypotheses          date comparison, and consistency determination. In the•
     can be generated in nearly every context and pro-          ory, Condor performs the actions A that are associated 
     vides redundancy that decreases the reliance on the        with every satisfied context, set. 

                                                                                             Strat and Fischler 1265                                                                  Figure 4: A perspective view of the 3D model produced 
                                                                 from the analysis of the image shown in Figure 1. 

                                                                 nized, it. is a good idea to look specifically for similar 
                                                                 bushes in the image. This tactic is implemented by a 
                                                                 candidate-generation context set that includes a context 
                                                                 element that, is satisfied only when a bush is in a clique. 
          Figure 3: Result, of analyzing Figure 1. 
                                                                 4 Evaluation scenario 

 3 The recognition process                                       The approach has been implemented in the form of a 
                                                                 complete end-to-end vision system, known as Condor. 
 For each label in the active recognition vocabulary, all        Images that are monochromatic or color, monocular or 
 candidate-generation context sets are evaluated. The            stereo, provide the input to the system, along with a 
 operators associated with those that are satisfied are          terrain database containing prior knowledge about the 
 executed, producing candidates for each class. The              environment. Condor produces a 3D model of the envi­
 candidate-comparison context sets that are satisfied are        ronment labeled with terms from its recognition vocab­
 then used to evaluate each candidate for a class, and if        ulary which is stored in the Core Knowledge Structure 
 all such evaluators prefer one candidate over another, a        (CKS) [10, 11] and can be superimposed on the input, im­
 preference ordering is established between them. These          age (Figure 3) or viewed from another perspective (Fig­
 preference relations are assembled to form part.ial or­         ure 4). The model is used to update the terrain database 
 ders over the candidates, one partial order for each class.     for use by Condor during the analysis of subsequent im-
  Next, a search for mutually coherent, sets of candidates is    agery. 
 conducted by incrementally building cliques of consistent         To evaluate the Condor approach, we selected a two-
 candidates, beginning with empty cliques. A candidate           square-mile region of foothills immediately south of the 
  is nominated for inclusion into a clique by choosing one       Stanford University campus as our site for experimen-
 of the candidates at the top of one of the partial orders.      tation. This area contains a mixture of oak forest and 
 Consistency-determination context sets that are satisfied       widely scattered oak trees distributed across an expanse 
 are used to test the consistency of a nominee with can          of gently rolling, grass-covered hills and is criss-crossed 
 didat.es already in the clique. A consistent nominee is         by a network of trails. 
 added to the clique; an inconsistent one is removed from          We chose 14 classes for the recognition vocabulary on 
 further consideration with that clique. Further candi­          the basis of their prevalence in the experimentation site 
 dates are added to the clique until none remain. Addi-          and their importance for navigation. These terms are: 
 tional cliques are generated in a similar fashion as com­             {sky, ground, geometric-horizon, foliage, bush, 
  putational resources permit. Ultimately, one clique is             tree-trunk, tree-crown, trail, skyline, raised-object, 
 selected as the best semantic labeling of the image on                 complete-sky, complete-ground, grass, tree} 
  the basis of the portion of the image that is explained          Procedures have been devised to extract, evaluate, and 
  and the reliability of the operators that contributed to       check the consistency of candidates for each of these 
  the clique.                                                    classes. Context sets have been constructed to control 
    The interaction among context sets is significant. 'The      the invocation of each of those procedures. Currently 
 addition of a candidate to a clique may provide context         the knowledge base contains 88 procedures whose invo­
  that could trigger a previously unsatisfied context set        cation is governed by 156 context sets. All the results 
  to generate new candidates or establish new preference         described in this paper have been generated using this 
 orderings. For example, once one bush has been recog-           knowledge base. 

1266 Vision Figure 8: The composite model resulting from the anal                    Figure 9: The ground-truth database. 
ysis of the image sequence in Figure 7. 

     them. No trunk was detectable in the foliage to the        into a single continuous trail. Furthermore, everything 
     left of the image, so Condor labeled it as bush.           that was labeled tree actually is a tree. 

Image 6 — The texture in the lower corners of the               5.3 Experiment 3 
     sixth image was found to more closely resemble 
     foliage than grass, so these regions were erroneously      Regardless of the architecture, know ledge-based vision 
     identified as bushes. Beause they are very near the        systems are difficult, to build. If the programmer needed 
     camera, they occupy a significant part, of the image,      to specify in advance all the information necessary 
     but the 3D model created for them reveals that they        for successful recognition, his task would be hopeless. 
     are less than 2 feet. tall.                                Therefore, it is essential that a vision system have the 
                                                                ability to improve its competence autonomously, thereby 
Image 7 — Several more trees, grass areas, and part             learning through experience how to recognize the objects 
     of the trail are recognized in the seventh image.          in its environment.. 
Image 8 The primary tree is recognized despite the 
                                                                Assertion 3 Using context allows Condor to learn how 
     strong shadows, but the lower portion of the trunk 
                                                                to recognize natural objects, 
     was missed by all the trunk operators. Most, of the 
     tree crown operators were unable to provide a de­            To test the validity of this assertion, we return to the 
     cent candidate because of the overhanging branches         first image of the sequence used in Experiment 2 (Fig­
     in the upper-right, corner -■ the only operator that       ure 7). When originally analyzed, Condor recognized the 
     succeeded was the one that predicts the crown based        trail and part of the grass, but not the trees. 
     on the size and location of the trunk. The combined          Condor was tasked to reanalyze the first image, this 
     effects of the incomplete trunk, the nearness of the       time making use of the contents of the entire database 
     tree, and the lack of range data account for poor          constructed during the analysis of the sequence of eight 
     extraction of the tree crown.                              images. The resulting interpretation is depicted in Fig­
  This experiment, illustrates how Condor is able to use        ure 10. 
the results of analyzing one image to assist the analy            Two trees that could not be extracted on the first pass 
sis of other images. Although some trees and parts of           are now identified. Condor employed a tree-trunk opera­
the trail were missed in several images, the 3D model           tor whose context, set. requires knowledge of the approxi­
that results is nearly complete. Figure 8 shows an aerial       mate location of a tree in the field of view. The operator 
view of the composite model contained in the CKS after          projects a deformable 3D model of the trunk onto the 
processing all eight, images. For comparison, Figure 9          image, and optimizes its fit to extract, the trunk. This 
portrays a model of the objects actually present on the         operator successfully identified two of the trees without 
ground, which was constructed by physically measuring           contradicting any of the original recognition results. 
the locations and sizes of the individual objects. Note           This experiment (along with others not. described 
that all of the trees that were visible in at least one image   here) illustrates that the ability to use prior recognition 
have been correctly labeled, although some of them were         results as context while interpreting subsequent images 
misplaced. Most of the trail has been detected, enough          enables Condor to improve its performance as its expo­
to allow a spatial reasoning process to link the portions       sure to its environment increases. 

                                                                                             Strat and Fischler 1267                                                                                   System," International Journal of Computer Vision, 
                                                                                  Vol. 2, No. 3, pp. 209 250 (January 1989). 
                                                                              [4] Faugeras, CD., and M. Hebert, "A 3-D Recognition 
                                                                                  and Positioning Algorithm using Geometrical Matching 
                                                                                  Between Primitive Surfaces," Proceedings 8th Interna-
                                                                                  tional Joint Conference on Artificial Intelligence, Karl•
                                                                                  sruhe, West Germany, pp. 996-1002 (August 1983). 
                                                                              [5] Garvey, Thomas D., "Perceptual Strategies for Purpo­
                                                                                  sive Vision," Ph.D. Dissertation, Department of Elec­
                                                                                  trical Engineering, Stanford University, Stanford, CA 
                                                                                  (December 1975). 
                                                                              [6] Grimson, W.E.L., and T. Lozano-Perez, "Model-Based 
                                                                                  Recognition from Sparse Range or Tactile Data," In•
Figure 10: The results of analyzing the first image from                           ternational Journal of Robotics Research, Vol. 3, No. 3, 
Figure 7 with and without the information extracted                               pp. 3-35 (1984). 
from subsequent images.                                                       [7] Huttenlocher, Daniel P., and Shimon Ulman, "Rec­
                                                                                  ognizing Solid Objects by Alignment," Proceedings: 
                                                                                   DARPA Image Understanding Workshop, Cambridge, 
6 Conclusion                                                                      MA, pp. 1114-1122 (April 1988). 
                                                                              [8] Kass, Michael, Andrew Witkin, and Demitri Terzopou-
In its present embodiment, Condor is still a demonstra­                           los, "Snakes: Active Contour Models," Proceedings, 
tion system that should be evaluated primarily in terms                            ICCV, London, England, pp. 259-268 (June 1987). 
of its architectural design and innovative mechanisms, 
                                                                              [9] Ponce, Jean, and David J Kriegman, "On Recogniz­
rattier than its absolute performance. Wliile Condor has 
                                                                                  ing and Positioning Curved 3D Objects from Image 
demonstrated a recognition ability approaching human-                             Contours," Proceedings: DARPA Image Understanding 
level performance on some natural scenes, it is still per­                         Workshop, Palo Alto, CA, pp. 461 470 (May 1989). 
forming at a level considerably short of its ultimate po­
                                                                             [10] Smith, Grahame B., and Thomas M. Strat, "A 
tential (even for the Stanford experimentation site). The 
                                                                                   Knowledge-Based Architecture for Organizing Sensory 
knowledge acquisition mechanisms, which are a key as­                              Data," International Autonomous Systems Congress 
pect of the architecture, should allow continued improve­                          Proceedings, Amsterdam, Netherlands (December 
ment in performance with exposure to additional site                               1986). 
imagery. 
                                                                             [11] Strat, Thomas M., and Grahame B. Smith, "The Core 
   A new paradigm for image understanding has been                                 Knowledge System," Technical Note 426, Artificial In­
proposed, and used to recognize natural features in                                telligence Center, SRI International, MenJo Park, CA, 
ground-level scenes of a geographically limited environ­                           (October 1987). 
 ment. This context based approach is exciting because 
                                                                             [12] Strat, Thomas M., and Martin A. Fischler, "A Context-
 it deemphasizes the role of image partitioning and em-                            Based Recognition System for Natural Scenes and 
 phasizes the recognition context in a way that has not                            Complex Domains," Proceedings, DARPA Image Un•
 been attempted before. This new focus could lead to                               derstanding Workshop, Pittsburgh, PA, pp. 456 472 
 the construction of vision systems that are significantly                         (September 1990). 
 more capable than those available today.                                    [13] Strat, Thomas M., "Natural Object. Recognition," 
                                                                                   Ph.D. Dissertation, Department of Computer Science, 
 7 Acknowledgment                                                                  Stanford University, Stanford, CA (December 1990). 

 Condor includes soft ware provided by many present and                      [14] Tenenbaum, Jay M., "On Locating Objects by Their 
 former members of the Perception Croup at SRI. In                                 Distinguishing Features in Multisensory Images," Com•
                                                                                   puter Graphics and Image Processing, pp. 308 320 (De­
 addition, Marty Tenenbaum, Jean-Claude Latombe, and 
                                                                                   cember 1973). 
 Lynn Quam have contributed to the research reported 
 here.                                                                       [15] Thompson, D.W., and J.L. Mundy, "Three-
                                                                                   Dimensional Model Matching from an Unconstrained 
 References                                                                        Viewpoint," in Proc. IEEE Int. Conf. on Robotics and 
                                                                                   Automation, pp. 208-220, 1987. 
    [1] Holies, R.C., R. Horaud, and M.J. Hannah, "3DPO:                     [16] Tsotsos, John K., "A Complexity Level Analysis of 
        A 3D Part. Orientation System,'" in Proceedings 8th                        Immediate Vision," International Journal of Computer 
        International Joint Conferencf on Artificial Intelli-                      Visum, Vol. 1, No. 4, pp. 303 320 (1988). 
        gence, Karlsruhe, West Germany, pp. 11 16 -1120 (Au­
        gust. 1983). 
    [2] Brooks, Rodney A., "Model-Based 3-D Interpretations 
        of 2-D Images," IEEE Trans fictions on Pattern Analy•
        sts and Machine Intelligence, Vol. 5, No. 2, pp. 140-150 
        (March 1983). 
    [3] Draper, Bruce A., Robert T. Collins, John Brolio, Allen 
        R. Hanson, and Edward M. Riseman, "The Schema 

 1268 Vision 