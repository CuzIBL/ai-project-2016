                          Explanation-Based Feature Construction

                         Shiau Hong Lim, Li-Lun Wang       and  Gerald DeJong
                                       Dept. of Computer Science
                               University of Illinois, Urbana-Champaign
                                {shonglim,lwang4,mrebl}@cs.uiuc.edu


                    Abstract                          to reduce the dimensionality of the input features. But of-
                                                      ten the high-level features that simplify the task are complex
    Choosing good features to represent objects can be nonlinear combinations of the native features. We believe the
    crucial to the success of supervised machine learn- most effective approach is to incorporate additional informa-
    ing algorithms. Good high-level features are those tion in the form of prior world knowledge. In this direction,
    that concentrate information about the classiﬁca- one approach [Gabrilovich and Markovitch, 2005] utilizes the
    tion task. Such features can often be constructed as large repository of the Open Directory Project to aid in natural
    non-linear combinations of raw or native input fea- language classiﬁcation. We address a very different problem
    tures such as the pixels of an image. Using many  of handwritten Chinese character recognition. Our additional
    nonlinear combinations, as do SVMs, can dilute the world knowledge is derived from a relatively small, imper-
    classiﬁcation information necessitating many train- fect, and abstract prior domain theory.
    ing examples. On the other hand, searching even     Explanation-based learning (EBL) is a method of dynam-
    a modestly-expressive space of nonlinear functions ically incorporating prior domain knowledge into the learn-
    for high-information ones can be intractable. We  ing process by explaining training examples. In our charac-
    describe an approach to feature construction where ter recognition task for example, we know that not all pixels
    task-relevant discriminative features are automati- in the input image are equally important. [Sun and DeJong,
    cally constructed, guided by an explanation-based 2005] used this observation to learn specialized Feature Ker-
    interaction of training examples and prior domain nel Functions for support vector machines. These embody
    knowledge. We show that in the challenging task of a specially constructed distance metric that is automatically
    distinguishing handwritten Chinese characters, our tailored to the learning task at hand. That approach automati-
    automatic feature-construction approach performs  cally discovers the pixels in the images that are more helpful
    particularly well on the most difﬁcult and complex in distinguishing between classes; the feature kernel function
    character pairs.                                  magniﬁes their contribution.
                                                        However, we know that it is not the raw pixels that intrin-
1  Introduction                                       sically distinguish one character from one another. Rather,
Sensitivity to appropriate features is crucial to the success of the pixels are due to strokes of a writing implement and these
supervised learning. The appropriateness of a feature set de- strokes in relation to one another distinguish the characters.
pends on its relevance to the particular task. Various notions Not telling the learner of these abstract relationships means
of relevance have been proposed [Blum and Langley, 1997; that it must perform the moral equivalent of inventing the no-
Kohavi and John, 1997] and statistical tools to evaluate and tion of strokes from repeated exposure to patterns of raw pix-
select relevant feature sets are available (e.g. hypothesis els, making the learning task artiﬁcially difﬁcult. Our system
testing, random probes, cross-validation). Unfortunately, learns a classiﬁer that operates directly on the native features
most feature construction strategies focus on feature sub- but which appreciates the abstractions of the domain theory
set selection (e.g. ﬁlters [Almuallim and Dietterich, 1991; as illustrated by the training examples.
Kira and Rendell, 1992], wrappers [Kohavi and John, 1997], In section 2, we describe what makes a good high-level fea-
embedded methods [Guyon et al., 2006]) from either a pre- ture. We then detail the role of explanations and give our gen-
determined set or a space deﬁned by some feature construc- eral algorithm in section 3. In section 4 we illustrate our ap-
tion operators [Markovitch and Rosenstein, 2002] and require proach with detailed feature construction algorithms for Chi-
many training examples to evaluate.                   nese character recognition, and in section 5 we show some
  In challenging domains, the “native”, observable features experimental results. Section 6 concludes.
(e.g. pixel values of an image) are high-dimensional and en-
code a large amount of mostly irrelevant information. There 2 High Level Features and Generalization
are standard statistical techniques such as principal compo- The criteria for feature construction are usually based on
nents analysis (PCA) and linear discriminant analysis (LDA) how well a particular set of features retains the information

                                                IJCAI-07
                                                   931about the class while discarding as much irrelevant and re- any input object with regard to the particular task.
dundant information as possible. Information-theoretic meth-
ods, based on mutual information, channel coding and rate- 3 Explanation-based Feature Construction
distortion theorems have been applied to this problem [Battiti,
                                                      In classical EBL, an “explanation” is a logical proof that
1994; Tishby et al., 1999; Torkkola, 2003].Let and be
                                        X     Y       shows how the class label of a particular labeled example
random variables that represent the input and the label respec- can be derived from the observed inputs. But our version is
tively, and there is an underlying joint-distribution on ( ).
                                             X, Y     weaker. We only require the explanation to identify potential
It can be shown [Feder and Merhav, 1994] that the optimal
                           1  ( |  )                  low level evidence for the assigned classiﬁcation label. We
Bayes error is upper bounded by 2 H Y X . Therefore, a fea- then use training data to calibrate and evaluate the strength of
ture (  ) that retains as much information as possible about
   F  X                                               that evidence.
the label will have ( | ( )) ≤ ( |  )+ ,where    0
               H  Y F  X     H Y  X          >        Our prior knowledge includes ideal stroke models of the
represents the amount of information loss that we are willing characters of interest (roughly of the sort one obtains from a
to tolerate. On the other hand, discarding irrelevant infor-
                                                      vector font) and the model of a stroke as a connected straight
mation can be achieved by minimizing H(F (X)|Y ) while
                        (  | (  ))                    line of ﬁnite width.
satisfying the condition on H Y F X . Intuitively, this im- Feature construction is performed by the following steps
plies that most information about the class label is preserved,
                                                      which we state abstractly and describe speciﬁcally in the con-
while irrelevant information (e.g. within-class variations) is
                                                      text of the Chinese character domain.
discarded. We show how this bounds the actual risk for the
binary case in the Appendix, regardless of what hypothesis 1. Explain each training example to obtain the associa-
space is used.                                            tion between the assigned label and the observed na-
  When comparing alternative features, each satisfying    tive features mediated by high-level domain theory
H(Y |F (X)) ≤ H(Y  |X)+, we therefore prefer the one     concepts. After this step, each pixel is associated with
with the smallest H(F (X)|Y ). Alternatively, we may aim at a stroke (the line that most likely made it) constrained
minimizing the following functional:                      so that the line conﬁgurations match the stroke require-
                              1                           ments of the assigned character.
        J(F )=H(F   (X)|Y )+   H(Y |F (X))              2. Using the prior knowledge, identify 1) high-level fea-
                                                         tures that are similar in both categories, and 2) high-
Unfortunately, without additional knowledge about the un- level features that are different between the cate-
derlying probability distribution, it is impossible to accu- gories. The ﬁrst set form our reference strokes. These
rately estimate the conditional entropy empirically from the can be conﬁdently found in new test images since a simi-
data when the training set is small. For example, when all lar stroke should be present for either instance type. The
the training examples have different X, one can simply de- second set are information-bearing; they are character
ﬁne a feature F based on the nearest neighbor rule (itself a dependent.
classiﬁer) and empirically, with a naive estimator, achieve 3. With the generated explanations, evaluate each po-
ˆ(  )=0
J F      . There is no reason to believe that the feature tential similarity statistically using the training set,
 (  )
F X   and the resulting classiﬁer will generalize to unseen keeping the ones that can be detected efﬁciently and
examples. In this sense, building a right feature is as hard as with high conﬁdence. These are strokes that are easily
building the right classiﬁer, that is, it does not work without found in an unlabeled image and form a frame of refer-
any inductive bias.                                       ence to guide us to the high class-distinguishing infor-
  However, it is possible that for some tasks, there exist fea- mation.
tures that are known apriorito have J(F ) ≈ 0. Such features
capture our knowledge about patterns that are unique to a par- 4. Using the training examples, optimize the process
ticular class of objects. What is not known, however, is a re- of ﬁnding detection features from the reference fea-
liable way to detect or extract the feature from any unlabeled tures. This identiﬁes the high information image regions
input. The problem of constructing a good feature can there- w.r.t. the reference strokes. The regions chosen to be
fore be viewed as the problem of building a good detector for larger if over the training set there is greater variance of
such “high-level” features, based on the training data. If we the location of the detection strokes w.r.t. the reference
can ensure that the detector produces the right output for the strokes and tighter otherwise.
right reason, i.e., it detects the intended high-level feature, Generally, ﬁnding lines in an image is problematic. Many
then we will have high conﬁdence that the resulting feature lines will be missed and often non-lines will be found. The
will generalize well.                                 process can be expensive. However, this is only done for la-
  How do we verify that a detector produces the right output beled examples during the learning phase. Thus, we know
for the right reason? Doing so statistically, if possible at all, what lines we should ﬁnd and their approximate geometrical
will require too many training examples for many tasks. In- conﬁguration. This greatly improves the line-ﬁnder’s perfor-
stead, if available domain knowledge can be used to build ex- mance. But what if we can ﬁnd no reference strokes? If there
planations for the training examples, then they can be used to are no easily-found similarities between the categories, then
verify whether a feature’s output is consistent with our prior the two classes must be very different; the classiﬁcation task
knowledge. We show how to use this idea to automatically should be simple. Many features and algorithms should be
construct features that focus on the most informative part of able to differentiate them, and our knowledge-based approach

                                                IJCAI-07
                                                   932is unnecessary. Next we examine this process in more detail serve as “reference strokes.” Finding them allows the target
for Chinese characters.                               region to be more accurately identiﬁed.

4  Classifying Handwritten Chinese                    4.1  Building Explanations
   Characters                                         Our prior model of each character is a graph, where nodes
                                                      represent a stroke and edges represent the relationship be-
Ofﬂine handwritten Chinese character recognition remains a tween strokes. Each stroke is itself modeled as a line seg-
challenging task due to the large variability in writing styles ment with 5 parameters (x, y, θ, l, t) denoting its center, di-
and the similarity of many characters. Approaches are ei- rection, length and thickness. Such models can either be
ther structural or feature-based [Suen et al., 2003].Thefor- hand-speciﬁed, or obtained from existing character-stroke
mer extract strokes from a new input image and try to match database.1 The model need not be highly accurate as the ex-
the extracted strokes to the known stroke-level models. Ex- planation process relies primarily on its structural informa-
tracting strokes is unreliable and consequently the model- tion. The model is used to explain each training example by
matching process is problematic. Feature-based approaches ﬁnding the most likely parameters for each requisite character
utilize statistics on well-designed features and have proven to stroke.
be more robust. However, the features are hand-crafted and In general, searching for the best set of parameters is a
it is not easy to exploit prior knowledge during the learning combinatorial problem for the general graph. This may still
process; similar characters are difﬁcult to differentiate using be acceptable since the size of the graph is small and the pro-
such globally-deﬁned features.                        cess is done only once for each character during training.
  In this paper, we focus our attention to the task of distin- For efﬁciency, we structure these graphs into trees to em-
guishing pairs of similar characters. In our approach automat- ploy a dynamic programming approach to produce the expla-
ically constructed features are tailored to best differentiate the nations. We use an algorithm based on [Felzenszwalb and
characters.                                           Huttenlocher, 2000]. Our implementation uses two automati-
  Consider the pair of Chinese characters in Figure 1. cally generated trees, focusing on horizontally and vertically
                                                      oriented strokes separately. Figure 3 shows a character model
                                                      and an example explanation.


      Figure 1: Two very similar Chinese characters

  They are almost identical except the leftmost radical. Ex- Figure 3: A Character Model and an Explained Example
tracting a global feature that summarizes the whole character
dilutes the class-relevant information concentrated on the far
left of the image.                                    4.2  Identifying Potential Similarities
  Once the informative region has been identiﬁed, there is Given the models for a particular pair of characters, we per-
still much variability in the exact location of the informa- form graph matching to identify strokes that are similar in
tive region. Figure 2 illustrates the variability among the ﬁrst terms of location, direction and length. The result of this pro-
character of the pair.                                cess is the identiﬁcation of a set of strokes M which have a
                                                      match in both characters. We refer to this set as the matching
                                                      set M. These are the candidates for reference strokes. Figure
                                                      4 shows an example.
                                                      4.3  Finding Efﬁcient Reference Stroke Detector
                                                      Any efﬁcient feature extractor can be used in this step. Since
           Figure 2: Within-class Variability         we are concerned with lines, we use a Hough transform
                                                      [Forsyth and Ponce, 2002]. In particular, we perform a Hough
  Attempting to deﬁne an absolute set of pixels (say, one 3rd transform on an input image, and look for a local minimum in
of the image from the left) would result in noisy features. a speciﬁed region which reﬂects the variability of the match-
Too small the region we risk missing the important stroke for ing set stroke in the training data. We refer to this as the
some of the characters, too large the region our advantage of “Hough detector”. Not every stroke in M can be reliably de-
focused feature is lost. This is where we utilize our knowl- tected by the Hough detector. We use the following algorithm
edge about similarities between the two characters. The three
long, roughly vertical strokes present in both characters may 1For example, the Wen Quan Yi Project, http://wenq.org/

                                                IJCAI-07
                                                   933   Figure 4: The strokes in M are shown as dotted lines

                                                               Figure 5: The ideal “target” rectangles
to select from the matching set a set of reference strokes that
can be reliably detected. The explanation for each training
example is used to measure how accurately the Hough detec- feature point with the smallest score is selected. If none of
tor detects a particular stroke.                      the feature points qualiﬁes, then the edge of the image is used
                                                      as the deﬁnition of the target window. Figure 6 illustrates this.
 1. Initialize the set of reference stroke R to empty

 2. For each stroke S in M                                                  top anchor
     (a) Find the range of directions and offsets for this
        stroke among all the training examples (from the
        explanations), namely, ﬁnd the smallest bounding
                              ¯
        rectangle with the center (θ, ρ¯), the width Δθ,and
        the height Δρ.
     (b) For each α ∈{0.8, 1, 1.2, 1.4, 1.6} and each β ∈
        {0.8, 1, 1.2, 1.4, 1.6}
                                                                            right anchor
        i. Deﬁne the bounded region in Hough space as a
                             ¯
          rectangle centered at (θ, ρ¯) with width αΔθ and
          height βΔθ.                                 Figure 6: The actual “target” rectangles with respect to the
       ii. For each training example                  feature-points. Note that there are no feature-points for the
                                                      left and the bottom edge.
        A. Search for the highest peak in the region
        B. Check whether the peak is within a threshold We assume a joint-distribution on the location of the ref-
           distance τ from the actual stroke orientation
                             (   )                    erence strokes and the target “window” as deﬁned by the
       iii. Record the hit ratio H α, β (percentage of ref- feature-points. Each reference stroke is parameterized by
          erence strokes correctly detected using the spec- the direction and the offset Ri =(ρi,θi) obtained from the
          iﬁed parameters)                            Hough detector. Each target window is parameterized by 4
              ∗     ∗                (   )
     (c) Find α and β with the highest H α, β         parameters L =(l1,l2,l3,l4) which correspond to left, top,
              ∗  ∗
     (d) if H(α ,β ) >H0 then add S to R              right and the bottom of the window. For example, k refer-
                                                      ence strokes and one target window form a joint-distribution
  The range of the detector window (α and β) in the above
                                                      on (R, L) where R =(R1,R2,...,Rk). The joint distribu-
algorithm is chosen for simplicity. The thresholds τ (distance
                                                      tion is estimated from the training examples, since we know
in Hough space) and H0 are optimized using cross-validation.
                                                      both R and L from the explanations. For unlabeled examples,
4.4  Learning the ﬁnal Feature                        we ﬁrst apply the Hough detector to localize the reference
                                                      strokes, r =(r1,...,rk), then ﬁnd the maximum-likelihood
Once reference strokes are identiﬁed, the system estimates location of the window according to the conditional proba-
the informative region relative to the parameters of the refer- bility P (L|R = r). Assuming that the joint-distribution is
ence strokes. We use a simple deﬁnition for our “informative                     
                                              M       Gaussian with mean
region”. In each character, every stroke that is not in is                    μR
considered a potentially informative stroke. From the expla-                  μL
nations, we know the location of these strokes in the training
examples. Using these locations, we ﬁnd the smallest rectan- and covariance        
                                                                         ΣRR   ΣRL
gle that includes each stroke. Whenever there are overlapping                           ,
strokes, the two rectangles are combined into a single larger            ΣLR   ΣLL
rectangle bounding both strokes. Figure 5 illustrates this. the conditional is itself Gaussian with mean
  Feature points, which can be the center or endpoints of a
                                                                      =    +Σ     Σ−1 ( −    )
reference stroke, receive a distance score with respect to each  μL|R    μL    LR  RR r   μR
                                                 +
edge of the target window, where the score is deﬁne as aδ and covariance
  . This combines the mean distance ( ) to the window edge
bσ                              δ                                Σ    =Σ     − Σ   Σ−1 Σ
and its standard deviation given the reference strokes. The        L|R    LL    LR  RR   RL  .

                                                IJCAI-07
                                                   934 Pair  SVM    SVM(EBL)    Pair  SVM    SVM(EBL)       Acknowledgements
  1    18.0      18.0      16    6.8       6.8
                                                      This material is based upon work supported by the National
  2    17.8      17.0      17    6.8       6.8
                                                      Science Foundation under Award NSF IIS 04-13161. Any
  3    14.3      14.3      18    6.5       6.5
                                                      opinions, ﬁndings, and conclusions or recommendations ex-
  4    13.0      5.8       19    6.5       6.5
                                                      pressed in this publication are those of the authors and do not
  5    13.0      13.0      20    6.3       5.3
                                                      necessarily reﬂect the views of the National Science Founda-
  6    11.0      8.3       21    6.3       6.3
                                                      tion.
  7     8.5      8.5       22    6.3       6.3
  8     8.0      7.0       23    6.0       6.0
  9     7.8      7.8       24    5.8       5.8        Appendix
  10    7.5      8.8       25    5.8       5.0        We show how a feature f(X) with small H(f(X)|Y ) and
  11    7.5      8.5       26    5.8       5.3        small H(Y |f(X)) leads to better generalization bound in
  12    7.0      3.0       27    5.5       3.5        terms of Rademacher complexity, for the speciﬁc case of bi-
  13    7.0      5.8       28    5.5       5.5        nary classiﬁcation. We make use of the following theorem:
  14    7.0      2.0       29    5.5       5.5        Theorem  1. [Bartlett and Mendelson, 2002] Let P be a
  15    7.0      3.8       30    5.5       5.3        probability distribution on X×{±1},letF be a set of {±1}-
                                                                              X        (     )n
                      %                               valued functions deﬁned on , and let Xi,Yi i=1 be train-
     Table 1: Error Rate ( ) (5-fold cross-validation) ing samples drawn according to P n. With probability at least
                                                      1 − δ, every function f in F satisﬁes
5  Experiments                                                                                 
                                                                       ˆ              Rn(F )     ln(1/δ)
                                                       P (Y = f(X)) ≤ Pn(Y = f(X)) +       +
We evaluate our system on pairwise classiﬁcations between                                2         2n
difﬁcult pairs of characters. We use the ETL9B database (a  ˆ
popular database of more than 3000 Chinese and Japanese where Pn is the empirical risk. Rn(F ) is the Rademacher
characters, each with 200 examples). We ﬁrst learn a  complexity of F , given by
literature-standard multiclass classiﬁer using linear discrim-                    n                   
                                                                                2            
inants to identify 100 most difﬁcult pairs (i.e. pairs of charac- Rn(F )=Eσ1...n EX1...n sup | σif(Xi)| X1,...,Xn
ters that result in greatest confusion). These are, as expected,            f∈F n i=1
pairs of very similar characters. We use the weighted direc-
tion code histogram (WDH) [Kimura et al., 1997] as features. where σ1, ..., σn are independent {±1}-valued random
These features are generally the best or among the best for variables.
handwritten Chinese character recognition [Ding, 2005]. The following lemma shows that Rn(G) is bounded if
  For each pair of characters, we learn a classiﬁer using a H(f(X)|Y ) is bounded.
linear support vector machine. We observe that the support Lemma 1. Given discriminative feature f ∗ with
vector machine performs signiﬁcantly better than those with H(f ∗(X)|Y ) ≤ β<1,whereY    takes values from
linear discriminants. For our system, we use the same classi- {±1}, the Rademacher complexity of a set G of {±1}-valued
ﬁer, but the input to the SVM are the WDH features extracted functions is bounded as follows
only from the target feature window found with respect to the
detected reference strokes. Table 1 shows the results of the                         4
                                                                        Rn(G)  ≤ β +
experiment on the 30 most challenging pairs of characters.                           n
Even though the SVM is generally robust in the presence of
                                                      Proof. From the concavity of entropy, it can be shown that
irrelevant features, our system managed to achieve signiﬁcant
                                                      given the label Y = y, there exists v such that
improvement on many of these pairs.2
                                                                    ∗                          ∗
                                                      Pv|y  =   Pr(f (x)=vy|y)=     max   Pr(f  (x)=u|y)
                                                                                  u:f ∗(x)=u
6Conclusion                                                        β
                                                            ≥   1 − 2  .                               (1)
We believe that the key to generalization is to incorporate
                                                                                             ∗( )
available domain knowledge into the learning process. We We will call this vy the “typical” value of f x given y.
                                                      Given the training samples (X1,Y1),...,(Xn,Yn),andthe
show that tailored discriminative features can be constructed                                 −     +
from comparisons of generative models built according to the Rademacher random variables σ1,...,σn,letn and n de-
                                                                                                = −1
prior domain knowledge. This approach is particularly attrac- note the expected number of examples with Y and
                                                         =+1                 (   =   )
tive in problems where training examples are few but high Y     according to P Y    y . The expected num-
                                                                             ∗( )
level domain knowledge is available, as demonstrated in the ber of examples where f x is typical is then given by
                                                       − =   −          + =   +
task of classifying handwritten Chinese characters.   nt    n Pv|−1 and nt   n Pv|+1 respectively.
                                                        Consider the Rademacher average deﬁned in Theorem 1.
  2                                                   Suppose that the hypothesis space G contains all {±1}-valued
   We note that in several cases the examples in the database are                              ∗
mislabaled and our algorithm could achieve better results if these functions, that is, there is always a hypothesis g ∈Gthat
are corrected, but we decided not to modify the original database to attains the maximum Rademacher average. However, regard-
                                                                       ∗
retain its integrity.                                 less of the function g chosen, only one label can be assigned

                                                IJCAI-07
                                                   935