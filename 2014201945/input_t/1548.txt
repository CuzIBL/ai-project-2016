                          Lifted First-Order Probabilistic Inference

                       Rodrigo de Salvo Braz     and  Eyal Amir   and  Dan Roth
                              University of Illinois at Urbana-Champaign
                                    Department of Computer Science
                              201 N Goodwin Ave, Urbana, IL 61801-2302
                         braz@uiuc.edu,       {eyal,danr}@cs.uiuc.edu

                    Abstract                          stantiate a random variable per patient. However this is not
                                                      necessary since one can reason about individuals on a gen-
    Most probabilistic inference algorithms are speci- eral level, provided one knows the population size, in order
    ﬁed and processed on a propositional level. In the to answer that query in a much shorter time.
    last decade, many proposals for algorithms accept-
    ing ﬁrst-order speciﬁcations have been presented,   In such a scenario it would be possible to devise a way of
    but in the inference stage they still operate on a using the available model to answer the query without consid-
    mostly propositional representation level. [Poole, ering each individual. However, this would require a manual
    2003] presented a method to perform inference di- devising of a process speciﬁc to the model or query in ques-
    rectly on the ﬁrst-order level, but this method is tion. What is missing to date is an algorithm that can receive
    limited to special cases. In this paper we present the a general ﬁrst-order model and automatically answer queries
    ﬁrst exact inference algorithm that operates directly like these without computional waste.
    on a ﬁrst-order level, and that can be applied to any A ﬁrst step in this direction was given by [Poole, 2003],
    ﬁrst-order model (speciﬁed in a language that gen- which proposes a generalized version of the variable elimina-
    eralizes undirected graphical models). Our exper- tion algorithm ([Zhang and Poole, 1994]) that is lifted, that is,
    iments show superior performance in comparison    deals with groups of random variables at a ﬁrst-order level.
    with propositional exact inference.               The algorithm receives a speciﬁcation in which parameter-
                                                      ized random variables stand for all of their instantiations and
1  Introduction                                       then eliminates them in a way that is equivalent to, but much
                                                      cheaper than, eliminating all their instantiations at once.
Probabilistic inference algorithms are widely employed in ar-
                                                                       [         ]
tiﬁcial intelligence. However, most of them do not accept The algorithm in Poole, 2003 , however, works only for a
ﬁrst-order speciﬁcations of models, which can abstract over very particular type of model because its only elimination op-
classes of objects, requiring instead propositional ones which eration is what we call inversion elimination, which requires
are longer and redundant because they must be speciﬁed vari- special conditions explained later. These special conditions
able by variable.                                     may sometimes be met by carefully chosen elimination order-
  In the last decade, many proposals for algorithms accept- ings, but in certain cases no such ordering exists and inversion
ing ﬁrst-order speciﬁcations have been presented [Ngo and elimination cannot be applied at all steps. This introduces the
Haddawy, 1995; Ng and Subrahmanian, 1992; Jaeger, 1997; need for another type of elimination, counting elimination,
Kersting and De Raedt, 2000; Friedman et al., 1999; Pfeffer which can always be applied but costs more. By putting these
et al., 1999; Poole, 1993; Anderson et al., 2002; Richardson two operations together we present the ﬁrst algorithm capable
and Domingos, 2004; Laskey, 2005], most of which based on of dealing with any ﬁrst-order probabilistic model that op-
the theoretic framework of [Halpern, 1990]. However, these erates directly on ﬁrst-order representations, without resort-
solutions perform inference at a mostly propositional level, ing to a propositional level. We also show that the algorithm
that is, dealing with the random variables instantiated from is correct and provide experimental results comparing it to a
the ﬁrst-order, parameterized variables in the ﬁrst-order spec- propositional algorithm.
iﬁcation (usually only the relevant random variables will be
present in the propositional version). In domains with a large
number of objects this may be both costly and essentially un- 2 Motivation
necessary. For example, a medical application can be about
a large population of people infected with a certain disease A probabilistic model over a set of random variables is de-
and have a model of the probability of death of a person (any ﬁned by a set of dependencies, each of them on a subset of
person) with that disease. To answer the query “what is the those variables. In a propositional model, each dependency
probability that someone will die of this disease?”, an algo- explicitly refers to the variables it affects. For example, con-
rithm that depends on propositionalization would have to in- sider a Markov network involving a potential function, or fac-tor, such as:                                         the propositional model formed by all possible instantiations



                                                      of its logical variables. Following [Poole, 2003], we call these
                       ¡
                      ¢ 0.7, if epidemic ∧ sick,      parameterized factors parfactors.


     φ(epidemic, sick) = 0.3, if epidemic ∧ ¬sick,      This semantics immediately provides an inference al-
                       ¡
                       £ 0.5, otherwise.              gorithm for such a representation, namely the one in
                                                      which we apply any regular propositional inference al-
  In fact, this type of potential function will be common gorithm to the propositionalized model, but this would
enough in this paper that we deﬁne “if α then β p” to mean be overkill. For example, in order to solve the query


                                                      P (death(john)|sick(john)) it is only necessary to con-
                        ¡


                        ¢ p,    if α ∧ β,
                                                      sider the instantiations for P erson = john, ignoring
          φ(V ar(α, β)) = 1 − p, if α ∧ ¬β,


                        ¡                             other values. One could also consider general queries
                        £ 0.5,  otherwise.            such as P (sick(P erson)|death(P erson)) that do not re-
                                                      quire any instantiations at all in order to be solved.
where α and β are boolean formulas on binary random vari-
                                                      An extreme example of the beneﬁt of directly using the
ables and V ar(α, β) is the set of these random variables. If
                                                      ﬁrst-order representation is given by adding the parfactor
p is omitted, it is assumed to be 1. “β p” is the same as
                                                      “if               then            ” to the model and
“if > then β p” and “if α then β p else q” stands for both death(P erson)    someDeath
                                                      considering the query                     . The tree
“if α then β p” and “if ¬α then β q”. So we can write a                  P (someDeath|epidemics)
model in the more readable fashion:1                  width of the propositionalized graphical model is the popu-
                                                      lation size, while the query can in fact be answered in time
  if epidemic then sick 0.7   if sick then death 0.4  independent from the population size (a similar example is
                                                      shown in ﬁg. 4). It is therefore desirable to have an algorithm
In most practical problems, the same factor holds on many performing lifted inference, that is, inference directly on the
different sets of variables, requiring propositional models to
repeat that factor several times, modulo the speciﬁc variables ﬁrst-order level, which instantiates parfactors only when nec-
involved each time. In our example, if we wish to keep track essary.
of whether each member of a population is sick (with distinct The languages we mentioned before allow parameterized
variables sick(john), sick(mary), . . . ), we would have to speciﬁcations of probabilistic models. However, no corre-
write                                                 sponding ﬁrst-order inference algorithm has been provided;
                                                      inference is still performed by generating some proposition-
          epidemic    sick john .
        if        then   (    ) 0 7                   alized form of the model and using regular propositional in-
        if sick(john) then death(john) 0.4            ference algorithms on them (although some systems, like
        if epidemic then sick(mary) 0.7               SPOOK in  [Pfeffer et al., 1999], beneﬁt from the ﬁrst-order
        if sick(mary) then death(mary) 0.4 . . .      structure in some ways). In this paper we present an al-
                                                      gorithm which performs exact lifted inference on ﬁrst-order
This renders the model speciﬁcation unnecessarily complex models.
and redundant. Moreover, an inference algorithm will con- It is also useful to allow deterministic constraints on the
sider each of those factors separately, even though there is logical variables of parfactors. For example,
some structure across them that should be exploited.
  Currently, the most common way of dealing with these sit- if sick(P erson1) ∧ roommate(P erson1, P erson2)
uations is to keep the original model and use it for each sepa- then sick(P erson2) 0.8, P erson1 6= P erson2 (1)
rate object (in this case, each person) as needed. This however
does not help when different instances of the factor need to be diabetes(P erson) 0.01, P erson 6= john ∧ P erson 6= mary
used at the same time, as it would be the case to answer the
query P (sick(john) ∧ sick(mary)), for example. In these The constraint P erson1 6= P erson2 in the ﬁrst factor states
situations, procedures speciﬁc to a given model have to be that only its instantiations satisfying this condition will be
manually tailored, in what is a time consuming solution. considered. In the second factor, the potential of 0.01 for
  A natural way around this problem is to specify recurring the random variable diabetes(P erson) is assigned only for
factors in a parameterized way. This would allow us to ex- instantiations in which P erson is distinct from john and
press the same as above in the more succint way       mary.
         if epidemic then sick(P erson) 0.7
         if sick(P erson) then death(P erson) 0.4     3   Language, notation and semantics
where P erson (and, in our notation, words starting with a Our language and semantics are essentially the same as
capital) is a typed logical variable assuming any value from those in [Poole, 2003], that is, those of a Markov network
                                                      speciﬁed in a ﬁrst-order language that allows parameterized
the set of people involved in the problem. The semantics of           2
this representation is simply that it should be equivalent to random variables, and are also similar to Markov logic
                                                      networks [Richardson and Domingos, 2004]. A parfactor is
  1The reason we deﬁne the model with this “conditional” poten- a triad (φ, A, C) representing the applications of a potential
tial function rather than with usual conditional probabilities is that function φ on all instantiations of a tuple of logical atoms
we concern ourselves with Markov networks (undirected models)
only in this paper.                                      2Poole discusses some aspects of directed models, however.A  according to assignments to the logical variables in PROCEDURE FOVE(G, Q)
these atoms that satisfy a constraint formula C. At this G a set of parfactors, Q a set of random variables (the query).
point, we restrict ourselves to constraints with a ﬁnite 1. If RV (G) = Q, return G.
number of solutions so as to have ﬁnite models only (this 2. G ← SHATTER(G, Q) (ﬁgure 2).
prevents us from using function symbols – more on this in 3. E ← FIND-ELIMINABLE(G, Q).
                                                         4. G     g  G  RV  g and RV E  intersect .
section 6). For example, (1) is represented by the parfactor E ← { ∈   :   ( )      (  )      }
                                                         5. GE¯ ← G \ GE .
(φ, A, C), where φ is the appropriate potential function, A is 0
                                                         6. g ← ELIMINATE(GE, E).
{sick(P erson1),roommate(P erson2), sick(P erson2)}         0     0
                                                         7. G ← {g } ∪ GE¯ .
and C is P erson1 6= P erson2.                           8. Return FOVE(G0, Q).
  Note that we are in no way committed to the “if . . . then”
construction used, which is simply a notation for a speciﬁc PROCEDURE FIND-ELIMINABLE(G, Q)
                                                       G a set of parfactors, Q RV G , G shattered against Q.
type of potential function. Any potential function is allowed,           ⊂    ( )
                                                         1. Choose e from AG \ Q.
and random variables can be multivalued rather than binary 2. G ← {g ∈ G : RV (g) and RV (e) intersect}.
only.                                                       e
                                                         3. If LV (e) = LV (Ge) ({e} is inversion-eliminable)
  Just as with regular undirected graphical models, here the return {e}.
joint probability distribution is determined by the product of 4. Return FIND-COUNT-ELIMINABLE(G, Q, {e}).
all potential functions given an assignment to all random vari-
ables (which are instantiations of atoms in parfactors, and PROCEDURE ELIMINATE(G, E)
                                                       G a set of parfactors, E ⊂ RV (G).
therefore ground atoms). The only difference is that in a   0
                                                         1. A ← AG \ E.
ﬁrst-order model this product involves all instantiations of all      |ΘG|/|Θg| 0

                                                         2. g ← (    φ       , A , C ) (fusion, section 4.4).
parfactors. Given a set of parfactors G, the joint distribution  g∈G  g           G
                                                         3. If LV (E) = LV (g) (E is inversion-eliminable)
deﬁned by it is                                                                0      0
                                                           return parfactor ( ¡ e φg(A θ, e), A , Cg).
                                                         4. Return


           P (RV (G)) ∝ Y   Y   φg(Agθ)         (2)                               k       0 |Vi| 0


                                                                   ¡              
                                                           ( ¡  · · ·  N  ! . . . N ! φ (v , A ) , A , >)
                                                              N1     Nu  1     n  i  g i
                        g∈G θ∈Θg                           (as detailed in section 4.3).
where RV (G) is the set of all random variables (ground PROCEDURE FIND-COUNT-ELIMINABLE(G,  Q, E)
atoms) involved in all instantiations of all its parfactors, Θg G a set of parfactors, Q ⊆ RV (G), E ⊆ AG \ Q.
is the set of all assignments, or substitutions, to the logical 1. If AGE \ E is ground (E is counting-eliminable)
variables of g that satisfy its constraint (the solutions to the return E.
                                                         2. Choose a non-ground atom e ∈ A \ E.
constraint), φg is the potential function in g, Ag is the tuple                     G
                                                         3. Return FIND-COUNT-ELIMINABLE(G, Q, E ∪ {e}).
of atoms in g and Agθ is the instantiation of this tuple given
an assignment θ to logical variables.
                                                          Figure 1: First-order variable elimination algorithm.
  Further notation include, for a parfactor g, Cg for the con-
straint in g and, for a set of parfactors G, AG for the atoms
in ,    for the total constraint   and    for the set
  G  CG                    Vg∈G Cg     ΘG             the variable elimination (VE, [Zhang and Poole, 1994]) algo-
of solutions of CG. For any object α, LV (α) and RV (α) are rithm which calculates the total marginal by dividing it into
the sets of logical and random variables in α, respectively. smaller partial marginalizations, each on a single variable.
Finally, all sets of parfactors are implicitly assumed to be The main contribution of this paper is a ﬁrst-order version of
standardized apart, that is, logical variables are renamed if VE, FOVE, which is shown in Figure 1 and works in a simi-
necessary so that no logical variable is used in more than one lar way by eliminating one (but maybe more) atoms and their
parfactor in the set.                                 respective constraints at each step. The advantage of FOVE
                                                      is that, by eliminating an atom with its associated constraints,
4  Inference                                          we are effectively eliminating all of its groundings in a lifted
The inference problem is, given a set of random variables way, with a cost that is sometimes independent of the number
(ground atoms) Q representing a query, to calculate the mar- of groundings.
ginal probability of Q given a model G (queries involving a
condition can be issued by adding parfactors representing this 4.1 FOVE correctness
condition to G). This is                              We now show that FOVE is correct. The algorithm works in
                                                      the following way: suppose we want to eliminate the atoms
               P (Q) ∝   X    φ(G)                    in a set E at a given step of it. Then we can write
                       RV (G)\Q


                                                             P (Q) ∝   ¢    φ(G)
where PRV (G)\Q is a summation over all assignments to ran-         RV (G)\Q


dom variables not in Q and φ(G) is a shorthand notation for
                                                                                  ¢
                                                                  =      ¢            φ(GE)φ(GE¯ )
the right-hand side of equation (2).                                RV (G)\Q\RV (E) RV (E)


  Calculating this summation by brute force is intractable,
                                                                                        ¢
but one can use independencies in the model to do it more         =      ¢       φ(GE¯ )    φ(GE)
efﬁciently. In propositional models, one way of doing this is       RV (G)\Q\RV (E)    RV (E)where RV (E) is the set of random variables resulting from (because of shattering)


all instantiations of E in G, GE is the subset of parfactors in


                                                                      ¢         ¢    ¡ ¢        ¢
G depending on RV (E), and GE¯ is G \ GE.                         =  ¡   φg(Agθ1) . . . φg(Agθn)


                                                                      eθ1            eθn
                                                                                       
  If we can represent        φ(GE ) as the potential                  


                     PRV  (E)                                                                   0
                                                                                         ¢
of a single parfactor g0, (deﬁned such that φ(g0) =               =      ¢  φg(Agθ) =       φg(A θ, eθ)
                                                                    θ∈Θg eθ          θ∈Θg eθ
      φg(Ag θ)), we can reduce the original marginal
Qθ∈Θg                                                                 
                                      0          0                              0
                                                                  =      ¢  φ (A θ, e) (by renaming)
PRV  (G)\Q φ(G) to a marginal on a model G = GE¯ ∪ {g }                      g


which involves fewer random variables:                              θ∈Θg e
                                                                      
                                                                  =     φ0(A0θ) = φ(g0)



                                                                    θ∈Θg


                          ¢             ¢
P (Q) ∝  ¢    φ(G) =              φ(GE¯ )    φ(GE)
       RV (G)\Q      RV (G)\Q\RV (E)   RV (E)              0               0  0            0
                                                       for g a new parfactor (φ , A , Cg) where A is a tuple of the
                            0                         atoms distinct from e in A , φ0(A0θ) = φ (A  θ), and
            ¢                                                                g                g   g
     =              φ(GE¯ )φ(g )                                                         Peθ
       RV (G)\Q\RV (E)                                Cg is the constraint formula of g.


                             0               0          Note that the initial sum of products becomes a product of
                                    ¢
     =      ¢       φ(GE¯ ∪ {g }) =      φ(G )        sums, hence the name inversion elimination. Also note that
       RV (G)\Q\RV (E)           RV (G0)\Q            the sum providing φ0 is over the assignments on the parame-
                                                      terized random variables. Therefore this elimination method
                                                      does not depend on the number of groundings, but on the
  There are two ways, described below, of calculating a par- number of assignments to the parameterized random variable,
factor g0 such that φ(g0) =     φ(G  ): (1) inversion which is much smaller.
                        PRV  (E)    E                   The condition LV (e) = LV (g) is essential for this method
elimination or (2) counting elimination. (1) is the preferable
                                                      to work because it guarantees that the random variables being
one because it does not depend on the number of objects in
                                                      summed out have a one-to-one correspondence to the instan-
the domain or, in other words, the size of RV (E). However,
                                                      tiations of g. This is a condition not taken into account by
this method requires certain conditions on (explained later)
                                   E                  [Poole, 2003], whose method eliminates all random variables
that may be impossible to satisfy for any in the atoms of .
                                 E              G     not in the query by inversion elimination, one by one. How-
(2) is less favorable as it depends on the size of (it is
                                        RV (E)        ever, the proof above should make it clear that this is not al-
still better than propositionalization, though), but it is always
                                                      ways possible. A numerical contradiction can be found by
possible to ﬁnd an E on which it can be applied.
                                                      trying to answer the query r for p(X) ∧ q(Y ) ∧ r 0.8, with
  In the two next subsections, we assume that GE has been type of X being {a} and type of Y being {b, c}, since neither
replaced by an equivalent parfactor g. This operation is called p(X) or p(Y ) is suitable for inversion elimination. The cor-
fusion and is explained in section 4.4. We are thus left with rect answer is ≈ 0.78, but eliminating p(X) and then q(Y )
                                                      by inversion produces ≈ 0.75.
the problem of expressing PRV (E) φ(g) as a parfactor.
  Finally, we assume that the parfactors and query have been 4.3 Counting elimination
shattered, as explained in section 4.5. The main property of When we cannot ﬁnd an atom e in G satisfying the conditions
shattered parfactors and query is that any two atoms in them for inversion elimination, we can resort to counting elimina-
have groundings which are either identical or completely dis- tion, which is based on counting arguments.
joint. Why this matters will be explained as inversion and Counting elimination can be done on a set of atoms E such
counting elimination are explained.
                                                      that the remaining atoms in g (and consequently GE) are all
                                                      ground. We can always ﬁnd such an E in G, since the set of
                                                      non-ground atoms in G is such a set. We however try to ﬁnd
4.2  Inversion elimination                            the smallest such E since the cost of the method depends on
                                                      the size of RV (E). Note that counting elimination is only
                                                      justiﬁed for |E| > 1 since |E| = 1 implies that E is inversion
Inversion elimination assumes that E is a unary set {e} such eliminable.
that              , where      is the set of logical vari- Once we have a proper E, let A0 be the remaining atoms in
   LV (e) = LV (g)      LV (α)                                        0
ables in α. Let θ1 . . . θn be an enumeration of Θg. Then g. Then, because A is ground,



                                                                                            0
                                                                             ¢


                                                                 ¢   φ(g) =          φg(Eθ, A θ)
                    


                                                                RV (E)      RV (E) θ∈Θg
               ¢
    ¢   φ(g) =         φg(Agθ)
                                                                                            0

   RV (e)     RV (e) θ∈Θg                                                =   ¢       φg(Eθ, A )



                                                                            RV (E) θ∈Θg
                    ¢
            = ¢  · · · φg(Agθ1) . . . φg(Agθn)
              eθ1   eθ


                     n                                  The last term above deﬁnes a potential function φ0 on A0.
                            ¢
            = ¢  φg(Agθ1) · · · φg(Agθn)              The result obtained from counting elimination is a new par-
                                                             0    0  0
              eθ1           eθn                       factor g = (φ , A , >).  In order to calculate this term, we present a counting argu- as Ej θ or not, otherwise we would not know whether to have
ment. Given an assignment on RV (E),                  one less option from Rj (for the cases where Emθ 6= Ej θ)
                                                      or not to have to make a choice at all (in those cases where


                           k
                           
                                                      Emθ  = Ej θ and the choice has already been made for Emθ
               φ (Eθ, A0) =  φ (v , A0)|Vi|
                g             g  i                    and therefore for Ej θ). This information is available since
                           i
           θ∈Θg                                       Em  and Ej must be either identical or not uniﬁable, as stated
                                                      above. From this reasoning,
by grouping all applications of φg with the same vi, where


v1, . . . , vk are the different assignments to Eθ and Vi is the                        k
                                                                                        


                                                                               ~    ~            0 |Vi|


                                                                     ¢     ¢
set of different Eθ’s assigned vi.                         ¢   φ(g) =   · · · N1! . . . Nn! φg(vi, A )
  Now assume for a moment that E is in fact just one atom
                                                          RV (E)      N~1  N~u          i
e. This means that the vi’s are the possible values for in-
                        k     |Vi|
stances of e. Note that Qi φg(vi) is a function of vi  with
and |V |, but not of V . In other words, it only matters how
     i            i                                             ~
many instances of e are assigned vi by a given assignment |Vi| = Y(|Ns(j),i| − |{m : m < j, Em 6= Ej , Rm = Rj }|),
on RV (e), but not which of them. Different assignments will j
induce different vectors (V1, . . . , Vk), but if they induce the
                                 ~                                                   ~
same vector (|V1|, . . . , |Vn|) (denoted N), that product will where s(j) is such that Ss(j) = Rj , Ns(j) is the vector corre-
be the same. Also, given a vector N~ , the number of assign- sponding to the counting of assigments on Ss(j) = Rj , with
                 ~                           ~ 3       ~
ments inducing it is N!, the multinomial coefﬁcient of N (in Ns(j),i being the number of random variables in Rj assigned
the particular case where e is a binary variable, this becomes vi,j .
 |RV (e)| = |RV (e)| ). We can therefore group assignments Finally, we consider the case where the condition that for
  N~ 0      N~1 
                                                      any two atoms E  , E in E, LV (E ) ∩ LV (E ) =  ∅ is
according to N~ and write                                            m   j            m         j
                                                      not satisﬁed. We can reduce this case to the previous one
                            k


                                                      by multiplying away the logical variables violating the con-
                                      ~


                         ~           0 Ni
                      ¢
           ¢   φ(g) =    N!   φg(vi, A )              dition. To multiply a logical variable vector Z¯ away from a
                                                                                           0     0  0  0
          RV (E)      N~    i                         parfactor h, we calculate a new parfactor h = (φ , A , C )
                                                             0
                                                      where A  is the same as Ah but for the removal of the logi-
                                                                    ¯   0
                                                      cal variables in Z, C = C|LV (h)\Z¯ and, for any θ ∈ Θh0 ,
                                                       0  0                    0
                                                      φ (A θ) =    0  ¯ φh(Ahθ θ), where C|W¯ , the restriction
  Let us now consider the case where E contains multi-          Qθ ∈C|Z
                                                      of C to a vector of logical variables W¯ , is deﬁned as the con-
ple atoms. Let E1, . . . , En be an enumeration of E and
                                                      straint ∃V¯ C for V¯ = LV (C) \ W¯ . This is simply the for-
R1, . . . , Rn be their respective groundings. Let us also as-
                                                      mula describing the solutions of C restricted to variables in
sume that for any two atoms Em, Ej in E, their groundings
                                                      W¯ (for equational formulas without function symbols this can
Rm, Rj are identical or disjoint. This condition is satisﬁed
by shattered sets of parfactors, as discussed in 4.5. Moreover, be simpliﬁed to an equational formula without quantiﬁers).
we also assume that any two atoms in E are either identical Multiplying away is an expensive operation that depends
or not uniﬁable at all, according to Cg. This is also granted directly on the domain size. We are currently working on
for shattered sets of parfactors. For now, we also demand that more sophisticated counting arguments that minimize its use.
for any two atoms Em, Ej in E, LV (Em) ∩ LV (Ej ) = ∅,
leaving the case where this is false for later.       4.4  Fusion
  Let S1, . . . , Su be an enumeration of {Rj : 1 ≤ j ≤ n},
that is, a sequence of unique R ’s. We can consider each We now explain how a set of parfactors G can be replaced by
                           j                          a single, equivalent parfactor fs(G) = (φ0, A , C ), with
assignment as a composition of assignments on each Si and                                     G   G
                                                       0                     |Θg |/|ΘG|
write                                                 φ (AGθ) = Qg∈G  φg(Agθ)        for any θ ∈ ΘG.


                             k


                                                                                      
                             


                                      0 |Vi|                                                   |Θg|/|ΘG|


                    ¢    ¢
         ¢   φ(g) =    · · ·   φg(vi, A )                φ(G) =        φg(Agθ) =        φg(Agθ)



        RV (E)      S1    Su i                                 g∈G θ∈Θg         g∈G θ∈ΘG


                                                                     
                                                                              |Θg|/|ΘG|
                                                             =         φg(Agθ)
  As before, |Vi| is the number of Eθ’s assigned vi, but vi is
a tuple assignment to Eθ. |V | can be calculated by choosing,  θ∈ΘG g∈G
                       i                                         
                                                                     0
for each component vi,j , how many random variables in Rj    =      φ (AGθ) = φ(fs(G))

can be assigned vi,j (this choice can be made in this fashion  θ∈ΘG
because atoms in E do not share logical variables). This is
simply |R |, the number of random variables in R , unless
        j                                  j            The crucial step is the one in which we replace each origi-
some other component vi,m, with m < j, Em 6= Ej and
Rm  = Rj , has already committed a random variable in Rj nal set of constraint solutions Θg by the global constraint so-
for itself. For this reason, it is important to know from the lution set ΘG. When this happens, each original instantiation
beginning whether Emθ is either the same random variable of a parfactor is now instantiated |ΘG|/|Θg| many times more
                                                      than before, but the power |Θg|/|ΘG| preserves the original
  3                           (N~1+···+N~n)!
   Deﬁned as N~ ! = (N~ 1, . . . , N~n)! =            potential value.
                                N~1!...N~n!