             Probabilistic Mobile Manipulation in Dynamic Environments,
                              with Application to Opening Doors

                                Anna Petrovskaya and Andrew Y. Ng
                                          Stanford University
                                     Computer Science Department
                                     { anya, ang }@cs.stanford.edu

                    Abstract
    In recent years, probabilistic approaches have
    found many successful applications to mobile robot
    localization, and to object state estimation for ma-
    nipulation. In this paper, we propose a uniﬁed
    approach to these two problems that dynamically
    models the objects to be manipulated and local-
    izes the robot at the same time. Our approach
    applies in the common setting where only a low-
    resolution (10cm) grid-map of a building is avail-
    able, but we also have a high-resolution (0.1cm)
    model of the object to be manipulated. Our method
    is based on deﬁning a unifying probabilistic model
    over these two representations. The resulting algo-
    rithm works in real-time, and estimates the position
    of objects with sufﬁcient precision for manipulation Figure 1: STAIR robot platform manipulating a door during one of
    tasks. We apply our approach to the task of navigat- our experiments.
    ing from one ofﬁce to another (including manipu-
    lating doors). Our approach, successfully tested on
                                                           ]
    multiple doors, allows the robot to navigate through 1999a ). In much of this literature, the environment is mod-
    a hallway to an ofﬁce door, grasp and turn the door eled as static (unchanging), and there is no interaction be-
    handle, and continuously manipulate the door as it tween the robot and the environment. More recently, a num-
    moves into the ofﬁce.                             ber of authors have developed models for non-static environ-
                                                      ments. For example, [Biswas et al., 2002; Anguelov et al.,
                                                      2004; 2002; H¨ahnel et al., 2003] use an off-line EM algo-
1  Introduction                                       rithm to differentiate between static and non-static parts of an
Many believe that general-purpose robots will soon inhabit environment. A few algorithms also perform on-line mapping
home/ofﬁce environments and carry out a large variety of while taking into account non-static information. [Wolf and
tasks, for example fetching items, delivering messages, or Sukhatme, 2004] use separate occupancy grids for dynamic
cleaning up a room. At a bare minimum, such robots must obstacles (e.g., moving people) and static obstacles; [Stach-
navigate in these environments as well as interact with them. niss and Burgard, 2005] maintain clusters of local grid maps
In this paper, we present a uniﬁed probabilistic approach to corresponding to different observed conﬁgurations of the en-
state estimation for simultaneous manipulation (of objects in vironment; and [Biber and Duckett, 2005] model temporal
the environment) as well as global navigation. Using this ap- changes of local maps.
proach, we successfully enable a mobile manipulation plat- Robots typically interact with the environment using ma-
form to navigate from far away up to a door, manipulate the nipulators. Most work on manipulation focuses on properties
door handle so as to open the door, and enter an ofﬁce while of speciﬁc objects to be manipulated, rather than on moving
simultaneously continuing to manipulate the door. This work in or understanding the global environment (e.g. [Shekhar,
was done as part of the STAIR (STanford Artiﬁcial Intelli- 1986; Moll and Erdmann, 2003]). With a few exceptions
gence Robot) project, which has the long-term goal of build- (e.g., [Petrovskaya et al., 2006; Slaets et al., 2004]), most
ing a useful robotic assistant that can carry out home/ofﬁce of this literature also does not have probabilistic basis, and
tasks such as those described above.                  thus at ﬁrst blush it appears difﬁcult to derive a single unify-
  Over the last decade, probabilistic techniques have found ing model that seamlessly integrates navigation and manipu-
great success in mobile robot navigation (e.g., [Fox et al., lation.

                                                IJCAI-07
                                                  2178  The task of mobile manipulation combines both navigation
and manipulation. Most current work in mobile manipulation
treats these as two tasks to be solved separately: First, mobile
robotics techniques are used to navigate to a speciﬁc point;
then, a separate set of techniques is used to localize objects to
be manipulated. For example, in the context of door opening,
navigation and manipulation of the door handle were consid-
ered in [Rhee et al., 2004] and [Petersson et al., 2000].In
both approaches, navigation to the door was performed as a
separate task. The door handle is then localized only after
the robot is already in front of the door, and a combination
of visual servoing and tactile feedback is then used to grasp
the door handle, and ﬁnally the door is opened by having the
robot follow (with some compliance) a pre-scripted set of mo-
tions. Localization during door opening or while entering the
doorway was not considered.
  In this paper, we present a uniﬁed, real-time, algorithm that Figure 2: Dynamic Bayesian network model of the robot pose Xt,
simultaneously models the position of the robot within the en- object state αt, measurements zt, and controls ut.
vironment, as well as the objects to be manipulated. It allows
                                                        At each time step t, we give the robot a new motion com-
us to consider manipulation of large objects, such as doors, u                           z
ﬁling cabinets and chairs. When the state of these objects mand, t, and obtain a new measurement t from its sensors.
changes, it signiﬁcantly impacts navigation tasks. Thus our The robot pose and the object state evolve over time, and at
                                                      time t are denoted by Xt and αt respectively. We model Xt,
goal is to simultaneously model a dynamic environment as α z    u
well as localize ourselves within it. Because this objective t, t,and t jointly using the dynamic Bayesian network
is reminiscent to that of simultaneous localization and map- shown in Figure 2. In detail, given the robot pose and a new
ping (SLAM), we will ﬁnd that we can borrow many ideas control, the pose evolves according to a probabilistic motion
from SLAM ([Thrun et al., 2005]). However, our objective is model derived from robot kinematics:
also different in two signiﬁcant ways: First, the environment            p(Xt|Xt−1,ut).
changes very signiﬁcantly as we interact with (manipulate)
it, and second, the precision required (1-5mm) for manipula- The object state evolves according to:
tion is 1-2 orders of magnitude higher than is typical for most           p(αt|αt−1).
SLAM applications.
  Tested successfully on multiple doors, our approach en- Similarly, sensor measurements are governed by a measure-
ables our robot to navigate towards, manipulate, and move ment model (discussed in section 2.3 in more detail):

through a door. (Figure 1.) In contrast to prior art on door              p(zt|αt,Xt).
opening, we are able to estimate parameters with high pre-
cision even during motion of the robot. Thus no additional We deﬁne the robot trajectory to be a vector of all robot poses
                                                                                    Xt  =(X   ,X , ..., X )
delay is required to locate the door handle once the robot up to the current time step, written 1 2    t .
                                                                      zt    ut
reaches the door. Further, using the same, seamlessly inte- Similarly, we write and to denote all measurements and
                                                                      t
grated probabilistic model, the robot is able to precisely esti- controls up to time .
mate the position of the door even while the robot and/or door 2.2 Representation of environment
are in motion, so that the robot can continuously manipulate
the door even while it is passing through it.         Following standard practice in mobile robot navigation, we
                                                      represent the environment using an occupancy grid map (Fig-
2  Representation                                     ure 3a) of the form typically constructed by mobile robots us-
                                                      ing SLAM. These coarse maps typically use grid cells that
2.1  Probabilistic model and notation                 are 10cm x 10cm, and are thus well suited to navigation
One of our tasks is to determine the robot’s position and ori- where 10cm resolution is acceptable. However, manipulation
entation within an environment. We denote the robot’s pose tasks require 1-5mm precision, and constructing a 2mm grid
by X =(x, y, θ). In this paper we will restrict our attention map of an entire building is clearly impractical—both from
to manipulating a single dynamic object placed in the envi- a memory storage point of view, and because these maps are
ronment. Concretely, consider an example where the position typically built using noisy sensors. Consequently, we choose
of the object is known (a reasonable assumption for doors, to use a combination of high and low resolution maps. We use
ﬁling cabinets, elevators, etc.), but whose shape is governed a high resolution map only for the parts of environment (i.e.,
by an object state parameter α. For example α could be the the objects) we are interested in manipulating. In the present
angle at which a door is open, or the extent to which a drawer paper, we use models comprising polygonal objects (“poly-
is pulled out of a ﬁling cabinet.1                    gon models”) to represent these objects at high-resolution;
  1In our door-opening application, α ∈is a real number denot- n, including settings where α also captures the position/orientation
ing the angle of the door. The generalization to vector-valued α ∈ of the object being manipulated, offers no special difﬁculties.

                                                IJCAI-07
                                                  2179           (a)                             (b)                                    (c)
Figure 3: (a) Occupancy grid map. (b) Actual environment. (c) Our representation: polygon model is “pasted” onto a grid map. The green
box shows the bounding box of the polygon model; and the black lines show the polygon model. (Best viewed in color.)
                                                      inaccurate—the building walls, chairs, etc., are unlikely to
                                                      be aligned with the global 10cm grid—and thus we wish to
                                                      model the 10cm grid map as probabilistically impeding the
                                                      laser ray in a way that is noisier than the more precise poly-
                                                      gon model.
                                                        In detail, the 10cm grids are usually only partially occu-
                                                      pied, and thus there is a chance of the laser passing through it
                                                      entirely. Thus, rather than simply modeling each grid cell as
           (a)                     (b)                occupied or unoccupied, we will instead associate with each
   Figure 4: Example of laser ray traveling through grid cells. grid cell a probability that a laser ray terminates within that
                                                      grid cell. Because our map has multiple resolutions, it is in-
this representation is well-suited to modeling doors, ﬁling sufﬁcient to associate with each grid cell (depending on the
cabinets, straight walls, etc. Figure 3c shows an example type of material, say) a probability of that grid cell impeding
polygon model of a door together with the surrounding grid the laser. To understand this, consider the toy map shown in
map. Our polygon models also allow us to model the changes Figure 4, which we can choose to represent via either a low-
in the shape of articulated objects (e.g., opening doors or ﬁl- resolution (10cm x 10cm) grid, or a higher-resolution (5cm x
ing cabinets) in a very natural and efﬁcient manner, simply 5cm) grid. If we model a grid-cell as having a probability p of
by letting the position or orientation of some of the polygons impeding a laser, then the chance of the laser being impeded
be parameters.                                        by the 10cm x 10cm region in Figure 4a is p, whereas the
  Thus, a complete representation of the environment con- chance for the map on the right is p3 (since it passes through
sists of a combination of an occupancy grid map and a poly- three grid-cells). Clearly, it is undesirable that the measure-
gon model. Further, the polygon model’s shape is governed ment model change just because we chose to represent an ob-
by object’s state parameter α.                        ject at a different resolution.
  Our choice of this combination of models is motivated by There are a variety of solutions to this, but we consider the
our goal of having the robot be able to open any door (and en- most natural one to be the probabilistic interpretation of occu-
ter any ofﬁce) in our ofﬁce building. Since all ofﬁces in our pancy grid maps proposed by [Eliazar and Parr, 2004].Their
building are built on a common theme, all doors are essen- interpretation was motivated by the observation that the more
tially identical, and thus it sufﬁces to build only a single poly- naive model (using a ﬁxed probability p for each grid cell)
gon model of a door (via careful measurement). Wherever a shows anomalous effects depending on the angle at which
door is present in the building, this same polygon model can a laser travels relative to the grid lines, even if all the grid
then be rapidly “pasted” onto a 10cm-resolution grid map that cells are the same resolution. However, the same interpreta-
has been built via standard SLAM techniques. This allows us tion turns out to also elegantly address our problem of using
to very rapidly acquire a map of the entire building, including multi-resolution maps.
0.1cm-resolution models of all the doors in it.
                                                        In this model, each cell of a grid map is associated with an
2.3  Measurement model                                opacity ρ.2 The probability of a laser ray being interrupted
                                                      by this cell depends both on the opacity and on the distance
This section describes the measurement model P (zt|Xt,αt)
used in our approach. For this work, we focused on us- the ray travels within the cell. In detail, the probability of a
ing a single sensor: a SICK laser scanner. Because our ray terminating (i.e., being interrupted) while traveling from
map comprises both low-resolution (10cm-grid cells) and
high-resolution (1-mm, polygon model) components, we de- 2The chance of a laser terminating/being interrupted is a decreas-
sire a measurement model that has a consistent interpreta- ing function of ρ, so this parameter is perhaps better thought of as
tion regardless of the resolution at which the map is repre- “transparency” rather than “opacity.” However, for consistency we
sented. Speciﬁcally, we know that the 10cm grid cells are will use [Eliazar and Parr, 2004]’s terminology.

                                                IJCAI-07
                                                  2180point r1 to point r2 in a medium of opacity ρ is deﬁned as: The second factor encodes object state posterior, conditioned
                                                      on the robot trajectory:
                                   − ||r1−r2||
       P (terminate(ρ, r ,r )) = 1 − e ρ
                      1  2                                                       t  t  t
                                                                      St = p(αt|X ,z ,u ).
Immediately, we see that the probabilities of the ray termi-
                                                      The factor Rt will be approximated using a set of particles;
nating under the maps in Figure 4a or 4b are the same, since   S
the total distance is the same in either case (assuming that the factor t, which estimates the angle of the door, will be
all the grid-cells have the same opacity ρ). Thus, this model approximated using a Gaussian distribution (one Gaussian
allows us to give a consistent probabilistic interpretation to per particle).
multi-resolution maps.
  More generally, suppose a laser travels in a direction that 3.2 Robot trajectory estimation
(if it were unimpeded) would take it through N different re- Within each particle we record a guess of the robot trajec-
                                                            t
gions in the map. Here, a “region” can be a grid cell (from tory X , and a Gaussian approximation St to the object state.
the low-resolution map) or a polygonal region (from the poly-                 qt  =(Xt,[m],S[m])
                                                      We will denote a particle by m        t   and a col-
gon map), such as a polygon that represents the shape of                     t   Q  =  {qt }
                                                      lection of particles at time by t  m m. We compute
a door, or one that represents part of the door-frame. We Q            Q                          t
   r ,r ,...,r                                          t recursively from t−1. Suppose that at time step , parti-
let 0 1      N denote the points at which the laser ray     Q                            R
would transition from one region to another (if it were to pass cles in t−1 are distributed according to t−1. We compute
                                                                                 Q¯
through all regions unimpeded), with r0 denoting the origin an intermediate set of particles t by sampling a guess of
                      ρ ,...,ρ                        robot pose at time t from the motion model. Thus, particles
of the laser ray. We also let 1 N denote the opacities of ¯
these regions. The probability of the ray terminating within in Qt are distributed according to the robot trajectory predic-
the i-th region is then:                              tion distribution:
                   iY−1                                                ¯       t  t−1 t
                                                                      Rt = p(X  |z  ,u ).
P (terminate(ρi ,ri−1,ri)) (1 − P (terminate(ρk ,rk−1,rk)))
                   k=1
                                                      To ensure that particles in Qt are distributed according to
                               iY−1
                   −||r −r ||/ρ   −||r  −r ||/ρ       R                            Q                  Q¯
             =(1− e   i−1 i  i )  e  k−1  k  k .        t (asymptotically), we generate t by sampling from t
                               k=1                    with replacement in proportion to importance weights given
                                                         w  = R /R¯
This allows us to deﬁne the probability that the laser termi- by t t t. Section 3.4 explains how these weights are
nates at any speciﬁc range r. Finally, if the laser terminates computed. For now, we note that since only the latest robot
at a certain range r, we model the actual observed laser mea- pose is used in the update equations, we do not need to actu-
surement z to be the range corrupted by Gaussian noise: ally store entire trajectories in each particle. Thus the memory
                                                      storage requirements per particle do not grow with t.
                              2
                 z = r + N (0,σ  )              (1)
                              rng                     3.3  Object state estimation
3  Inference                                          We use a Gaussian/extended Kalman ﬁlter (EKF) approxima-
                                                      tion to estimate the object state posterior, S . Thus we keep
3.1  Rao-Blackwellization                                                                  t
                                                      track of the mean μt and variance σt of the approximating
                                                                                          [ ]  [ ]
We now describe an inference algorithm that reasons about Gaussian in each particle: qt =(Xt,[m],μm ,σm ).
the robot trajectory and the object state based on a set of mea-             m            t    t
                                                        Since St involves only the latest object state αt (and not
surements and controls. Speciﬁcally, we compute the follow- the entire object state history αt), storage and computation
ing belief:                                                                             t
                            t  t t                    requirements here also do not grow with .Wehave:
               Belt = p(αt,X |z ,u ).
                                                          S   =   p(α |Xt,zt,ut)
Note that the belief includes the entire robot trajectory up to t    t
                                                                           t  t−1  t        t t−1  t
time t, but only the latest object state. This choice turns out ∝ p(zt|αt,X ,z  ,u ) p(αt|X ,z   ,u )
                                                                                       −1
to be important for deriving an efﬁcient Rao-Blackwellized    =   p(z |α ,X ) p(α |Xt,zt ,ut).        (2)
ﬁlter. (This is a consequence of the fact that the current be-       t t   t    t
lief about the state of the door depends on the entire past The ﬁrst step above follows from Bayes’ rule; the second step
trajectory—which, e.g., indicates which of the past sensor follows from the conditional independence assumptions of
measurements were directed at the door. A similar deriva- our model (Figure 2). The expression (2) is a product of a
tion is also used in [Montemerlo, 2003; Murphy and Russell, measurement likelihood term and an object state (dynamical
                                                                                                   ¯
2001].)                                               model) prediction term, which is deﬁned (similarly to Rt)as:
  In detail, we apply a Rao-Blackwellized particle ﬁlter S¯ =  p(α |Xt,zt−1,ut)
(RBPF), where in each particle we encode the entire robot tra- t  t
jectory and a posterior distribution of the object state. Thus,                        t−1 t−1  t
                                                            =        p(αt|αt−1)p(αt−1|X  ,z   ,u )dαt−1
we split up the belief into two conditional factors:             αt−1
                    t t  t       t  t  t
         Bel  = p(X  |z ,u )p(α |X ,z ,u ).                           t−1  t−1  t
             t                t                       Because p(αt−1|X   ,z   ,u ) is already approximated as
The ﬁrst factor encodes the robot trajectory posterior: a Gaussian (represented by a Rao-Blackwellized particle
                                                      from the previous timestep) and we use a linear-Gaussian
                          t t  t
                 Rt = p(X  |z ,u ).                   model for p(αt|αt−1), we can easily compute the mean and

                                                IJCAI-07
                                                  2181                                                      a product of two Gaussians, and can thus be carried out in
                                                      closed form.
                                                      3.5  Using Scaling Series to increase precision
                                                      For mobile robot navigation, 10cm precision is usually ac-
                                                      ceptable and gives reasonable performance. Thus in deployed
                                                      implementations it is fairly common practice to assume a
                                                      large laser noise variance and use only a few laser rays per
                                                      measurement update, which results in an approximation to
                                                      the next-state Rt that has fairly large variance. However, to
                        (a)                           perform manipulation tasks we require sub-centimeter preci-
                                                      sion in localization. Achieving this requires that we use most
                                                      of the laser measurements in every update, and assume a re-
                                                      alistic (small) variance in the laser readings. This results in a
                                                      very peaked measurement model, in which most of the prob-
                                                      ability mass of our robot’s position estimate is supported by
                                                      a very small region (of perhaps 1-5mm diameter). A con-
                                                      sequence of this is that it becomes difﬁcult during the usual
                                                      importance sampling step to draw a sufﬁcient number of par-
                                                      ticles from this region to represent it well.
                                                        In [Petrovskaya et al., 2006], a tactile localization appli-
                        (b)                           cation was considered that also had the similar problem of
                                                      a very sharply peaked measurement model. They proposed
                                                      a “Scaling series algorithm” to efﬁciently produce a much
                                                      more informed proposal distribution, one that is concentrated
                                                      around the areas of high probability mass. We refer the reader
                                                      to [Petrovskaya et al., 2006] for details on the scaling series,
                                                      but brieﬂy, the algorithm works by performing a series of suc-
                                                      cessive reﬁnements, generating an increasingly informative
                                                      proposal distribution at each step of the series. The successive
                                                      reﬁnements are performed by gradually annealing the noise
                                                      variance parameter within the measurement model from an
                                                      artiﬁcially high value down to a realistic variance setting.
                       (c)                              In our setting, we applied the scaling series algorithm to
Figure 5: Robot localization with estimation of door state. The choose the proposal distribution on each step of importance
robot is denoted via the small rectangle; the rays emanating from sampling in our particle ﬁlter. To do this, we annealed the
the robot show the laser range scans; and the estimated door angle measurement noise variance parameter σrng in Equation 1
is also shown in the ﬁgures. The sequence of three images show the and performed a series of successive reﬁnements. This re-
robot approaching, opening, and having passed through the door. sulted in a much more informed proposal distribution, which
                                                      allowed us to perform localization using only about 100 par-
          ¯
variance of St above in closed form. Similarly, by using a ticles per step.
Laplace approximation to obtain a Gaussian approximation
                       p(z |α ,X )
to the measurement model  t t   t , using Equation (2) 4  Experimental Results
we can also compute the mean and variance of St in closed
form.                                                 We apply our algorithm to the task of manipulating door
                                                      handles and doors. The STAIR (STanford Artiﬁcial Intelli-
3.4  Computing importance weights                     gence Robot) project is an ambitious, long-term (10-15 year)
                                                      project that seeks to build a useful home/ofﬁce robotic assis-
Brieﬂy, following the derivation in [Montemerlo, 2003],it
                                                w     tant. Thus the ability to use doors and enter ofﬁces and con-
is straightforward to show that the importance weights t ference rooms is of great practical importance to the robot.
should be:                                              We obtained 10cm resolution occupancy grid map by us-
                   p(Xt|zt,ut)                        ing standard SLAM algorithms with a mobile robot equipped
 w   =   R /R¯ =               = E ¯ [ p(z |α ,X )]
   t       t  t   p(Xt|zt−1,ut)    St   t  t  t       with a laser. (See Figure 3a.) Further, as discussed in Sec-
                                                      tion 2.2, because all doors in our building are essentially iden-
In words, the importance weights are the expected value tical, it is possible to build a single precise polygon model of
(over the object state prediction distribution) of the measure- a door, and then rapidly “paste” the same model into the grid
                                                 ¯
ment likelihood. Since the two terms p(zt|αt,Xt) and St map at all places where a door exists. Our polygon model in-
are already approximated as Gaussians (as described in Sec- cludes the door itself, the door frame, and a small surround-
tion 3.3), this expectation can be expressed as an integral over ing region, and also encodes the position of the door hinge.

                                                IJCAI-07
                                                  2182