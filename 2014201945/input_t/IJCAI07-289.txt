            Automatic Acquisition of Context-Specific Lexical Paraphrases 

                 Shiqi Zhao, Ting Liu, Xincheng Yuan, Sheng Li, and Yu Zhang 
                  Information Retrieval Laboratory, Harbin Institute of Technology 
                      No. 27 Jiaohua Street, Nangang, Harbin, China, 150006 
                        {zhaosq, tliu, xcyuan, lisheng, zhangyu}@ir-lab.org 


                   Abstract                      words can be incorporated into the statistical MT process. 
                                                 Specifically, paraphrases of unseen words can be translated 
    Lexical paraphrasing aims at acquiring word-level rather than leave the words untranslated [Callison-Burch et 
    paraphrases. It is critical for many Natural Lan-
                                                 al., 2006]. 
    guage Processing (NLP) applications, such as   Two broad approaches to lexical paraphrasing have domi-
    Question Answering (QA), Information Extraction nated the literature. One approach acquires paraphrases 
    (IE), and Machine Translation (MT). Since the 
                                                 from dictionaries, such as WordNet. Some researchers ex-
    meaning and usage of a word can vary in distinct tract WordNet synonyms as paraphrases [Langkilde and 
    contexts, different paraphrases should be acquired Knight, 1998], while some others use looser definitions 
    according to the contexts. However, most of the 
                                                 [Barzilay and Elhadad, 1997]. In general, the correspon-
    existing researches focus on constructing para- dence between paraphrasing and types of lexical relations 
    phrase corpora, in which little contextual con- defined in WordNet is not clear [Barzilay and McKeown, 
    straints for paraphrase application are imposed. 
                                                 2001]. In Chinese, CilinE has been exploited for paraphras-
    This paper presents a method that automatically ing in stead of WordNet [Li et al., 2005]. 
    acquires context-specific lexical paraphrases. In The other approach collects lexical paraphrases from 
    this method, the obtained paraphrases of a word 
                                                 monolingual or bilingual corpora. Lin [1998] identified 
    depend on the specific sentence the word occurs in. words that are similar in meaning by measuring the similar-
    Two stages are included, i.e. candidate paraphrase ity of the contextual words. Barzilay and McKeown [2001] 
    extraction and paraphrase validation, both of which 
                                                 extracted paraphrases from a corpus of multiple English 
    are mainly based on web mining. Evaluations are translations of the same source text. Bannard and Calli-
    conducted on a news title corpus and the presented son-Burch [2005] derived paraphrases using bilingual par-
    method is compared with a paraphrasing method 
                                                 allel corpora. Wu and Zhou [2003] extracted lexical para-
    that exploits a Chinese thesaurus of synonyms -- phrases with multiple resources, including a monolingual 
    Tongyi Cilin (Extended) (CilinE for short). Results dictionary, a bilingual corpus, and a monolingual corpus. 
    show that the f-measure of our method (0.4852) is These methods facilitate the acquisition of paraphrases. 
    significantly higher than that using CilinE (0.1127). However, none of them specify the contexts in which the 
    In addition, over 85% of the correct paraphrases paraphrases can be adapted. This problem is crucial as al-
    derived by our method cannot be found in CilinE, most all paraphrases can only be adapted in certain contexts. 
    which suggests that our method is effective in ac- Recently, topic adaptation for paraphrasing has been re-
    quiring out-of-thesaurus paraphrases.        searched. For example, Kaji and Kurohashi [2005] selected 
                                                 lexical paraphrases according to different topics. However, 
1 Introduction                                   the topics are limited and predefined. Thus, their method 
Paraphrases are alternative ways that convey the same in- cannot paraphrase a word according to any given context. 
formation. Paraphrasing tasks can be classified as lexical, This paper addresses the problem of context-specific 
phrase-level, sentence-level, and discourse-level. Lexical paraphrasing (CSP), which aims at acquiring specific para-
paraphrasing aims to acquire paraphrases of words. phrases according to a given context. In lexical CSP, words 
  Lexical paraphrasing is important in many NLP applica- are to be paraphrased. Accordingly, a specific context 
tions since it is an effective solution to the problem of “word means a sentence in which a word occurs. Specifically, if a 
mismatch”. For example, in QA, expanding a question by word occurs in different sentences, then different para-
paraphrasing its content words can make it easier to find the phrases should be extracted within each sentence. 
answer [Hermjakob et al., 2002]. In IE, words and phrases The remainder of the paper is organized as follows: Sec-
in the IE patterns should be paraphrased in order to extract tion 2 introduces the context-specific paraphrasing method 
the target information expressed in various ways [Shinyama in detail. Section 3 describes the experiments and results. 
and Sekine, 2003]. In MT, paraphrases of unseen source Conclusion and future work are presented in Section 4. 


                                            IJCAI-07
                                             17892   Method                                       2.1.2  Procedure of Candidate Paraphrase Extraction 
                                                 Two steps are included in candidate paraphrase extraction: 
Two main stages are included in the method: candidate Step1: Query S on the web and retrieve similar sentences. 
paraphrase extraction and paraphrase validation. For a given Obviously, only similar sentences of the given sentence S 
sentence S, in the first stage, a set of similar sentences are 
                                        1        need to be considered when extracting candidate para-
retrieved from the web using a search engine (Baidu  in the phrases since if two words are context-specific paraphrases 
experiments). From the similar sentences, candidate para- they should occur in identical or at least similar sentences. 
phrases for words in S are extracted by measuring syntactic In this step, S is searched on the web using Baidu. From the 
similarities. The candidates are filtered using part-of-speech retrieved snippets, sentences whose similarities with S ex-
(POS) information. In the second stage, candidate para-
                                                 ceed a predefined threshold TCE (TCE=0.3 in our case) are 
phrases are validated using a combined similarity measure- retained for further candidate extraction (these sentences are 
ment, which integrates co-occurrence similarity, syntactic called candidate sentences hereafter). Word overlapping rate 
similarity, and semantic similarity. Both the web and CilinE (WOR) is used here for computing the similarity between S 
are exploited in the validation stage. 
                                                 and any candidate sentence SC: 
2.1  Candidate Paraphrase Extraction                                     S  S
                                                                        |    C |            (1) 
                                                          WOR(S, SC )
2.1.1  Motivation                                                     max(| S |,| SC |)
Candidate paraphrase extraction is based on a web mining 
method. A similar method has been exploited for para- where “SSC” denotes the common words in both S and SC. 
phrasing answer patterns in QA [Ravichandran and Hovy, “|.|” denotes the number of words. 
2002]. Using the web as a paraphrasing resource has three Step2: Extract candidates according to syntactic similar-
advantages compared with conventional resources (mono- ity. As stated in Principle 2, lexical paraphrases usually play 
lingual parallel corpora, monolingual unparallel corpora, similar syntactic functions in sentences. This is an important 
and bilingual parallel corpora). First, the web is not domain clue for candidate extraction. In this step, sentence S and all 
limited. Almost all kinds of topics and contexts can be cov- the candidate sentences obtained in the Step1 are first parsed 
ered. Second, the scale of the web is extremely large, which by a Chinese dependency parser, in which 24 dependency 
makes it feasible to find any specific context on it. In addi- relations (e.g. SBV, VOB, ATT…) are defined. Figure 1 de-
tion, the web is dynamic, which means that new words and picts the dependency tree of an input sentence. 
concepts can be retrieved from the web.           
  The method for candidate paraphrase extraction is based Sentence:  
on two principles:                                 (He) (likes) (Chinese) (culture) (.) 
                                                   
  Principle 1: Authors on the web create information in- Dependency Tree: 
dependently. Thus their "vocabularies" vary greatly [Cui et 
al., 2002]. 
  This principle means that different people tend to use dif-
ferent words to express the same meaning. In other words, if 
a concept is widely discussed on the web, then various ex-                            
pressions (lexical paraphrases) will be found in the corre- Figure 1: An example of dependency trees 
sponding web documents. However, a principle for detect-  
ing these paraphrases and extracting them from the web is In a dependency tree of a sentence, two words and their 
needed. Therefore, the second principle is introduced. dependency relation are represented as a triple. For example, 
  Principle 2: Lexical paraphrases play similar syntactic “< , SBV,  >” is a triple. The criterion shown in Fig-
functions in sentences.                          ure 2 is used for extracting candidate paraphrases: 
                                                  
  The second principle indicates that paraphrases of a given Given: 
word w can be derived by extracting words whose syntactic S: original sentence;  
functions are similar with w.                        SC: candidate sentence; 
  In fact, the principles above have been used in recogniz- DT(S): dependency tree of S;  
ing paraphrases in previous work. Shinyama et al. [2002] DT(SC): dependency tree of SC; 
acquired paraphrases using different reports on the same <w1, rel, w2>: a triple in DT(S); 
event of the same day (based on Principle 1). Lin [1998] <w1', rel', w2'>: a triple in DT(SC). 
clustered similar words by measuring syntactic similarities Criterion: 
(based on Principle 2). The rationality of the principles has If rel=rel' and w2=w2' and w1 w1' 
been verified in their work.                           then w1' is extracted as a candidate paraphrase of w1. 
                                                     If w1=w1' and rel=rel' and w2 w2' 
                                                       then w2' is extracted as a candidate paraphrase of w2. 
                                                 Figure 2: Criterion for candidate paraphrase extraction 
   1 http://www.baidu.com 


                                            IJCAI-07
                                             1790  It is obvious that, a word and its paraphrases should have where tf(t, Sni(S)) denotes the term frequency of term t in 
identical POS. Therefore, if the word w and its candidate snippets Sni(S). tf(t, CCD) is t's term frequency counted on a 
paraphrase w’ have different POSes, w’ is filtered. China Daily Corpus (CCD). max(tf(t’, CCD)) is the largest 
                                                 term frequency obtained on the corpus. Note that the itf part 
2.2  Paraphrase Validation                       in the equation is similar to the idf part in tf idf heuristic 
Since the constraints in the candidate extraction stage are which is widely used in NLP and Information Retrieval (IR) 
quite loose for the sake of recall, there exists much noise in applications. The underlying hypothesis is that the words 
the candidates. The experiments show that over 70% of the occur frequently in the whole corpus should be “punished” 
candidates are incorrect. Therefore, a paraphrase validation when weighing the words. 
stage is necessary.                                The VSM similarity between w and w’ is calculated as the 
  Paraphrase validation is one of the key issues in the re- cosine similarity between V(S) and V(S’): 
search of paraphrasing. Hence many methods have been 
                                                                              V (S) V (S')   (3) 
presented. For example, Barzilay and McKeown [2001] SimVSM (w, w') cos(V (S),V (S'))
recognized phrasal paraphrases using rules automatically                     V (S)  V (S')
extracted from the contexts. However, the method must be 
                                                 where “ ” denotes the inner product of two vectors. “ ” 
based on monolingual parallel corpora. Bannard and Calli-
                                                 denotes the length of a vector. 
son-Burch [2005] validated paraphrases by computing the 
                                                   Sim  : In order to compute the syntactic similarity, 
probability that two phrases can be translated to (or from) SYN
                                                 Sni(S) and Sni(S’) are first parsed using the same depend-
the same foreign language phrases. Nevertheless, a large 
                                                 ency parser described above. The syntactic similarity is cal-
bilingual corpus is needed. Lin [1998] identified lexical 
                                                 culated with the same method as described in [Lin, 1998b], 
paraphrases based on Distributional Hypothesis, which com-
                                                 which is rewritten in Equation (4). The similarity is calcu-
putes the similarity of two words’ contexts to judge whether 
                                                 lated through the surrounding contextual words which have 
they are paraphrases. 
                                                 dependency relationships with the investigated words ac-
  The main disadvantage of the above methods is that none 
                                                 cording to the parsing results. 
of them can determine whether two words are paraphrases 
within a certain sentence. In other words, they are not con-          (I(w,rel,t) I(w',rel,t))
text-specific paraphrasing methods. In our work, a novel         (rel,t) T (w) T (w')
                                                   Sim  (w, w')                            (4) 
paraphrase validation method is proposed, in which both SYN          I(w,rel,t)   I(w',rel,t)
web information and a thesaurus are exploited.                 ()rel,t) T (w) (rel,t) T ( w'
2.2.1  Paraphrase Validation Using Web Mining    where T(w) denotes the set of words which have the de-
Generally, when a query is searched using a search engine, pendency relation rel with w. I(w,rel,t) is the point-wise 
the retrieved snippets are related to the query and can be mutual information, as defined in Equation (5): 
viewed as “description” of the query. Therefore, it can be 
                                                                         p(w,rel,t)
assumed that if two queries can retrieve similar snippets, I(w,rel,t) log                  (5) 
then they are similar.                                              p(w | rel) p(t | rel) p(rel)
  This assumption is used in paraphrase validation. In detail, 
let w be a paraphrased word in sentence S, w’ be a candidate   SimVSM and SimSYN measure the snippet-based similarity 
paraphrase of w within S, and S’ be a sentence constructed of two words from different aspects. SimVSM can also be 
by replacing w with w’ in S. If similar snippets are retrieved called co-occurrence similarity since it measures whether w 
by searching S and S’, then we can say that replacing w with and w’ co-occur with similar words in the snippets. All 
w’ does not notably change the meaning of S. In other words, words in the snippets are assumed to be independent with 
w and w’ can be viewed as paraphrases in S.      each other and no syntactic relations are considered. In con-
  Suppose Sni(S) and Sni(S’) are the snippets corresponding trast, SimSYN measures whether w and w’ play similar syn-
to S and S’ respectively. Here, sentences that do not contain tactic functions in the snippets. Only the words that have 
w (w’) are removed from Sni(S) (Sni(S’)) to filter noise. dependency relations with w (or w’) in the snippets are 
  Two similarity measurements are defined to measure the counted and the dependency relation types are taken into 
snippet-based similarity between w and w’, i.e. the Vector account. 
Space Model (VSM) similarity (SimVSM) and the syntactic 2.2.2 Paraphrase Validation Using CilinE 
similarity (SimSYN). 
                                                 Beside SimVSM and SimSYN, the semantic similarity (SimSEM) 
  SimVSM: In VSM, snippets Sni(S) and Sni(S’) are repre- is also investigated for paraphrase validation. 
sented as vectors V(S) and V(S’). The weight of each word is 
                                                   SimSEM: CilinE is organized as a hierarchy of five levels, 
calculated using a tf itf heuristic (Equation 2). in which the first level is the highest and the fifth is the 
                                                 lowest (Figure 3 (a)). Given two words, the lower their 
                             max(tf (t',CCD ))                 
   tf itf (t, Sni(S)) tf (t, Sni(S)) log t'   (2) common ancestor node is, the more similar their word 
                                tf (t,CCD )      senses are. Each word in CilinE has a sense code, determin-
                                                 ing its position in each level of the hierarchy (Figure 3 (b)). 


                                            IJCAI-07
                                             1791                                                 news titles are usually well-formed sentences. On the other 
                                                 hand, in many applications, such as QA, IE, and 
                                                 multi-document summarization, the words and sentences to 
   (a)                            Root 
                                                 be paraphrased are usually from news articles. The news 
                …                 Level 1        titles are from the “important news” section of “Sina news2”. 
                     …            Level 2        All titles from March 15, 2006 to April 5, 2006 are 
                                                 downloaded. After removing some duplicated ones, 257 
                  …               Level 3        titles are left for constructing the test data. Likewise, another 
                                                 210 titles from April 6, 2006 to April 30, 2006 are 
                                  Level 4        downloaded to form the development data. 
                                                   The metrics in the experiments are macro-averaged preci-
            … 
                                  Level 5        sion, recall, and f-measure. Let M1, …, MT be T paraphras-
                                                 ing methods to be compared (in our experiments, the com-
   (b) Sense code: Da15B02#                      pared methods are MCSP, MCilinE, MCSP-CAN, MVSM+SYN, 
                                                 M      , and M   , which will be described in the next 
      D a 15 B 02#                                VSM+SEM    SYN+SEM
                                                 section), N the number of sentences in test data, nt  the 
    Level 1  Level 2  Level 3  Level 4  Level 5                                           i
                                                 number of words in the i-th sentence that can be para-
Figure 3: Hierarchy of CilinE and an example of word sense code phrased by method Mt (1tT), ntij the number of acquired 
                                                 paraphrases for the j-th paraphrased word in the i-th sen-
  For word w and its candidate paraphrase w’, wsi and ws j’ tence using method Mt, mtij the number of correct para-
denote the i-th sense of w and the j-th sense of w’ (Note that phrases (judged manually) in the ntij paraphrases. The preci-
a word may have more than one word sense). SimSEM of w sion of method Mt is defined as: 
and w’ is defined in Equation (6): 
                                                                     N nti     N
                                                                         mtij
                       L(F(wsi ,ws j '))                precision(M t )         nti         (8) 
      SimSEM (w,w') max                      (6)                     i 11j ntij i 1
                   i, j
                           LTotal

where L(F(wsi, ws j’)) is the lowest ancestor node that two Compared with precision, recall is more difficult to cal-
sense codes have in the hierarchy. LTotal is the number of culate since it is impossible to enumerate all paraphrases 
total levels (LTotal =5). For w and w’, the maximal similarity that a word has within a context. Therefore, an approximate 
of their senses is defined as the semantic similarity. approach is used to calculate recall of each method. Spe-
  Obviously, SimSEM only measures the semantic distance cifically, for the j-th paraphrased word in the i-th sentence, 
between two words, in which no context information is con- all its correct paraphrases acquired by the T methods are put 
sidered. However, it is useful in paraphrase validation as a together (with duplication removed). Let ni be the number of 
supplement to the snippet-based similarity. In our future words in the i-th sentence that can be paraphrased by at least 
work, a refined semantic similarity measurement [Lin, one method, mij the total number of correct paraphrases for 
1998a] will be investigated.                     the j-th word. We assume that mij is the number of para-
                                                 phrases that the word can really have within this specific 
2.2.3  Linear Combination of Similarities        sentence. Then the recall of method M  is defined as: 
The three similarities defined above measure the similarity                  t

                                                                    N nti    N
of two words from different sides. In order to integrate the            mtij
similarities, we get them linearly combined:             recall(M t )         ni           (9) 
                                                                   i 11j mij i 1
 Sim  (w, w')
   COM                                     (7)     Note that, the recall of a method will be over-estimated 
     Sim  w w      Sim  w w     Sim   w w
    *  VSM ( , ') *  SYN ( , ') *  SEM ( , ')    using the definition of Equation (9), since some correct 
where  , , and are positive and     1 . The com- paraphrases may be absent. However, it is reasonable to get 
bined similarity Sim  is used in paraphrase validation. a set of methods compared in this way. 
                COM                                                   M
Detailedly, for word w and its candidate paraphrase w’, if The f-measure of method t is defined as: 
SimCOM(w,w’)>T (T is a predefined threshold), then the can-
                                                                  2 precision(M t ) recall(M t )
didate w’ will be validated as a true paraphrase. Otherwise, f measure(M t )               (10) 
                                                                   precision(M ) recall(M )
w’ will be filtered.  , , and T are estimated using a                       t         t
development set (Section 3.2.1). 
                                                 3.2 Results and Analysis 
3 Evaluation 
                                                 3.2.1  Comparison between MCSP and MCilinE 
3.1  Data and Metrics                            In this section, we compare the CSP method (MCSP) with the 
                                                 method extracting CilinE synonyms as paraphrases (M ). 
In order to evaluate the CSP method, a sentence corpus is                                 CilinE
needed. In our experiments, a corpus of news titles is used                                                  
as test data. The reasons are two folded. On the one hand, 2 http://news.sina.com.cn 


                                            IJCAI-07
                                             1792In MCilinE, word sense disambiguation (WSD) is first con- It can be found that MCSP outperforms MCSP-CAN greatly in 
ducted. A supervised method based on Bayesian Model is precision, which indicates that the validation method is ef-
used in the WSD module, which can achieve a precision of fective in filtering incorrect candidates. At the same time, 
89.67% in our evaluation. Then, all synonyms of a word recall decreases after validation, which suggests that some 
under the chosen sense are extracted as its paraphrases. In correct paraphrases are filtered by mistake. Nevertheless, 
MCSP, the development data is used to determine the pa- the increase in F-measure demonstrates the effectiveness of 
rameters. The parameters for getting highest f-measure paraphrase validation. 
scores on the development data are selected. As a result, the As mentioned before, three kinds of similarities are com-
coefficients , and in Equation (7) are 0.74, 0.10, and bined during paraphrase validation in MCSP. The contribu-
0.16 respectively. The similarity threshold T is 0.12. The tion of each one should be evaluated. Therefore we compare 
comparison results are shown in Table 1:         MCSP with MVSM+SYN (combining SimVSM and SimSYN), 
                                                 MVSM+SEM (combining SimVSM and SimSEM), and MSYN+SEM 
 Method Precision Recall            F-measure    (combining SimSYN and SimSEM). 

 MCSP       0.6380 0.3914 0.4852                   For the three methods to be compared, the coeffi-
 MCilinE    0.0630 0.5346 0.1127                 cients , and in Equation (7) and the similarity thresh-
                                                 old T are also estimated using the development data (Table 
Table 1: Comparison between MCSP and MCilinE
                                                 3). The comparison results are shown in Table 4. 
                                                  
  It can be seen from Table 1 that the precision of MCilinE is 
quite low, which shows that most synonyms defined in Method                           T 
CilinE are not paraphrases in specific contexts. On the other MVSM+SYN 0.12 0.88  -   0.10 
hand, the recall of MCSP is lower than MCilinE, this is mainly MVSM+SEM 0.44 -  0.56  0.26 
because CilinE can provide some correct paraphrases that MSYN+SEM - 0.86 0.14 0.06 
are not used in web documents. However, it is found that Table 3: Parameters for the methods to be compared 
over 85% of the correct paraphrases derived in MCSP are not  
synonyms in CilinE. This suggests that MCSP is effective in Method Precision Recall  F-measure 

extracting “new” paraphrases. An example of the derived MCSP 0.6380 0.3914 0.4852 
paraphrases of the two methods is illustrated in Figure 4 MVSM+SYN 0.4587 0.4059 0.4307 
(words in bold are manually judged correct paraphrases): MVSM+SEM 0.5036 0.3800 0.4332 
                                                  MSYN+SEM   0.5194 0.4028 0.4537 
 Sentence          48                            Table 4: Evaluation of each similarity measurement 
         (Tourist boat sinks off Bahrain, 48 persons died)  
  Results    /sink -- /wreck;                      We can find from Table 4 that eliminating each similarity 
    of       /tourist boat --  /sunken ship, /ferry in the paraphrase validation can produce a notable degrada-
   MCSP   boat,  /passenger ship, /pleasure boat; tion in precision (drop 28.10%, 21.07%, and 18.59%, re-
             /die -- /die;                       spectively) and f-measure (drop 11.23%, 10.72%, and 
  Results    /sink --  /deposit,  /open caisson, 6.49%, respectively), while the impact on recall is slight. 
    of     /subside, /submerge, /sag,  /sag,      The comparison results suggest that each of the similarity 
  MCilinE  /fall, /subside;                      measurements is useful in filtering incorrect candidates and 
           /person -- /personage, /denizen,      the combination of all the three similarities can achieve the 
         /personality, /candidate, /scholar;     best performance. 
             /die -- /be murdered, /be in distress, We believe that three major factors should be taken into 
             /meet with disaster, /suffer injury, consideration in paraphrase validation, that is, whether two 
         /die,   /be murdered, /be in danger,    words co-occur with similar contextual words, whether they 
         /suffer, /die in a disaster;            play similar syntactic functions in sentences, and whether 

Figure 4: Example of the derived paraphrases of MCSP and MCilinE their semantic distance is small. The combined similarity in 
                                                 Equation (7) integrates all these factors. Hence the 
                                                 f-measure is significantly enhanced. 
3.2.2  Evaluation of Validation Methods 
In this section, we first evaluate the paraphrase validation 3.2.3 Error Analysis 
                                                            3
method. Therefore, we compare MCSP with the method that False positives  are analyzed after experiments. It is found 
only extracts candidate paraphrases as described in Section that nearly 84% of the false positives are due to the reason 
2.1 without validation (MCSP-CAN). The comparison results that non-paraphrases occur in similar contexts. For example, 
are shown in Table 2.                            in sentence “                      (Ding Junhui 
                                                 failed to enter the final of the snooker match)”, “
 Method Precision Recall            F-measure    (final)” is paraphrased into “ (main draw match)”, 

 MCSP       0.6380 0.3914 0.4852 
 M          0.2822 0.5026 0.3615                                                                  
   CSP-CAN                                         3
Table 2: Comparison between M  and M                 False positives are word pairs recognized as paraphrases, but 
                      CSP    CSP-CAN             actually are not. 


                                            IJCAI-07
                                             1793