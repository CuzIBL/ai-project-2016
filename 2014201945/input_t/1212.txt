           Maintaining      Coherent     Perceptual    Information     Using   Anchoring

                       Amy   Loutﬁ,  Silvia Coradeschi  and Alessandro   Safﬁotti
                            Center for Applied Autonomous    Sensor Systems
                                           Orebro¨ University
                                        Orebro,¨ Sweden  701-82
                                            www.aass.oru.se

                    Abstract                          the preservation of object consistency, so that new informa-
                                                      tion about previously seen objects is also correctly attributed.
    The purpose of this paper is to address the prob- All the while, the insertion and/or removal of objects from
    lem of maintaining coherent perceptual information the environment needs to be considered and accounted for.
    in a mobile robotic system working over extended  From a cognitive perspective, the maintenance of perceptual
    periods of time, interacting with a user and using information is an integral part of the binding problem [Black-
    multiple sensing modalities to gather information more, 2003]. That is, how the conjunction of properties are
    about the environment and speciﬁc objects. We     represented, ranging from the binding of shape and colour
    present a system which is able to use spatial and in detecting blue triangles or red squares to the binding that
    olfactory sensors to patrol a corridor and execute must occur between and within the senses: “the way the smell
    user requested tasks. To cope with perceptual main- and touch and sight of the sandwich in your hand all seem to
    tenance we present an extension of the anchoring  belong to the same object” [Blackmore, 2003] (p.250).
    framework capable of maintaining the correspon-     For robotic systems, an important ingredient for maintain-
    dence between sensor data and the symbolic de-    ing perceptual information is an internal structure to store a
    scriptions referring to objects. It is also capable of representation of an object. Such an internal structure needs
    tracking and acquiring information from observa-  to satisfy a series of requirements. On one hand, perception
    tions derived from sensor-data as well as informa- management [Ronnie et al., 2003], an extension of sensor
    tion from a priori symbolic concepts. The general management  [Adrian, 1993], is required to integrate high-
    system is described and an experimental validation level information about the state of the object in order to make
    on a mobile robot is presented.                   situation dependent decisions, direct control and select sens-
                                                      ing actions. On the other hand, tracking and data association
                                                      are also fundamental ingredients necessary to propagate in-
1  Introduction                                       formation about coherent perceptions over time [D.Schulz et
Consider a scenario where a mobile robot is patrolling a cor- al., 2003]. A third requirement, especially in the context of
ridor. Its task is to discover new objects and gather infor- a cognitive robot, involves processes, which can create and
mation about them using both traditional modalities such as maintain the link between high-level information (e.g. sym-
vision and sonar and also non-traditional modalities such as bols) and low-level percepts.
an electronic nose. A user is able to monitor the robot, sug- In this paper, we show how the concept of anchoring can
gest actions to improve perceptual performance and request be used as a tool to confront some of the issues relating to
the robot to perform speciﬁc tasks. Tasks are requested from perception management. The anchoring framework [Corade-
the user using a symbolic representation consisting of natural schi and Safﬁotti, 2000] aims at deﬁning a theoretical basis
language concepts. While no requests by the user are given, for grounding symbols to percepts originating from physical
the robot autonomously prioritises tasks alternating between objects. We present an extension of the framework that is
patrolling the corridor and inspecting objects or simply wait- able to cope with perception management considering multi-
ing on stand-by.                                      sensing resources and temporal factors. The pivot of this ex-
  An important facet to this scenario, and scenarios of a simi- tension is the use of anchors as internal representations of
lar nature, is the ability to maintain coherent perceptual infor- objects that integrate symbolic and perceptual information
mation. This means that the system should be able to main- across time and across sensing modalities. Our ultimate aim
tain the correspondence between the symbolic representation is to shed light on this important aspect of cognitive robotics
of objects (requests from the user) and the perceptual data that as applications extend into realistic environments involving
refers to them. The system should collect information from human-robot interactions and lifelong acquisition of knowl-
different sensing modalities working concurrently and/or se- edge.
quentially and correctly attribute that information to its inter- We begin our discussions with a description and review of
nal representation of the object. The system should include the anchoring framework in Section 2. We then present amodiﬁcation of the anchoring framework in Section 3 which and a signature, a collection of property values meant to pro-
is adapted for the task of perception maintanance. We pro- vide the (best) estimate of the values of the observable prop-
ceed by detailing the robotic system architecture used in our erties of the object.
experiments. Section 5 gives the implementation details and
provides a performance example of the complete system. The 3 Anchoring for Perception Management
paper concludes with a summary of the presented work.
                                                      In this section, we present our extension to the anchoring
2  The  Anchoring   Framework                         framework. What makes this contribution unique is that we
                                                      extend the applications of anchoring beyond its traditional
To date, the anchoring framework presented by [Coradeschi use of data abstraction to also include percepts from differ-
and Safﬁotti, 2000] has mainly been considered in the context ent modalities that may be accessible at different times.
of abstraction of perceptual information. This includes asso- To effectively present our extension, we refer to the three
ciation of words to visually recognised objects [Knoblauch et abstract functionalities deﬁned by [Coradeschi and Safﬁotti,
al., 2004], managing of dynamic object anchoring for high- 2000]. used to manage anchors, namely, Find, Reacquire,
level reasoning [Chella et al., 2004] and preliminary works and Track. The functionalities have been developed for the
considering people tracking applications [Kleinehagenbrock consideration of top-down approaches for information acqui-
et al., 2002]. A good overview of the range of applications sition (i.e. imposed a priori symbolic concepts). In this paper,
of the anchoring concept is found in 2004 Robotics and Au- we revise these existing functionalities to include bottom-up
tonomous Systems special issue on anchoring symbols to sen- approaches so that anchors can be created by perceptual ob-
sor data [Coradeschi and Safﬁotti, 2003].             servations derived from interactions with the environment.
  Before we present our extension of the framework, we Bottom-up approaches have previously been considered on
summarise here the basic elements of the computational the- anchoring frameworks [Knoblauch et al., 2004] but never
ory of anchoring. See ?? for a full account. The theory con- in conjunction with top-down approaches. We advocate the
siders an autonomous system that includes a symbol system presence of both approaches, in particular for robotic systems
and a perceptual system, and it focuses on the problem of interacting with a human user. To accomplish this, an addi-
creating and maintaining a correspondence between symbols tional Acquire functionality is introduced.
and percepts that refer to the same physical object. The main
ingredients of anchoring are the following [Coradeschi and 3.1 Creation of Anchors
Safﬁotti, 2000]:
                                                      The creation of anchors can occur in both a top-down and
  • A symbol system including: a set X = {x1, x2, . . .} bottom-up fashion. Bottom-up acquisition is driven by an
    of individual symbols (variables and constants); a set event originating from a sensing resource (e.g. the recogni-
    P  = {p1, p2, . . .} of predicate symbols; and an infer- tion of a segmented region in an image) when perceptual in-
    ence mechanism whose details are not relevant here. formation which cannot be associated to any existing anchor
  • A perceptual system including: a set Π = {π1, π2, . . .} is perceived. Top-down acquisition occurs when a symbol
    of percepts; a set Φ = {φ1, φ2, . . .} of attributes; and needs to be anchored to a percept, such a call may originate
    perceptual routines whose details are not relevant here. from an external user or a top-level module (e.g. planner).
    A percept is a structured collection of measurements as- Acquire Initiates a new anchor whenever a percept is re-
    sumed to originate from the same physical object; an  ceived which currently does not match any existing an-
    attribute φi is a measurable property of percepts, with chor. It takes a percept π, and return an anchor α de-
    values in the domain Di.                              ﬁned at t and undeﬁned elsewhere. To make this prob-
  The symbol system manipulates individual symbols, like  lem tractable, a priori information is given with regards
’cup-21’, which are meant to denote physical objects and as- to which percepts to consider. In bottom-up acquisi-
sociates each individual symbol with a set of symbolic pred- tion, a randomly generated symbol is attributed to the
icates, like ’red’, that assert properties of the corresponding anchor. Furthermore, information about the object and
object. The perceptual system generates percepts and as-  its properties are included into the world model used by
sociates each percept with the observed values of a set of the planner, in this way the object can be reasoned about
measurable attributes. The task of anchoring is to create, and acted upon.
and maintain in time, the correspondence between individual Find Takes a symbol x and a symbolic description and re-
symbols and percepts that refer to the same physical objects. turns an anchor α deﬁned at t (and possibly undeﬁned
  The symbol-percept correspondence is reiﬁed in an inter- elsewhere). It checks if existing anchors that have al-
nal data structure α, called an anchor. Since new percepts ready been created by the Acquire satisfy the symbolic
are generated continuously within the perceptual system, this description, and in that case, it selects one. Otherwise, it
correspondence is indexed by time. It is important that the performs a similar check with existing percepts (in case,
connections are dynamic, since the same symbol may be con- the description does not satisfy the constraint of percepts
nected to new percepts every time a new observation of the considered by the Acquire). If a matching percept is
corresponding object is acquired.                         found an anchor is created. Matching of anchor or per-
  At every moment t, α(t) contains: a symbol, meant to de- cept can be either partial or complete. It is partial if all
note an object; a percept, generated by observing that object; the observed properties in the percept or anchor match                                                              User goals &  tasks
                     Symbolic System                                     Planner (top-level & recovery)
                                                                Interface
                       door5
                                     cup-22                               Plan   Problem (state & goal)
                   table1    room23
                                                                          Plan executor & monitor
                                  FIND
                                                                     Request Anchors,Status Destination Status

                                                                       Anchoring      Navigation
  TRACK             Anchoring Module                                                   Planner
                   Anch-1         Anch-1 cup-22
                   Visual         Visual & Visual &             Commands Classes Percepts Behaviours Status
                   Description    odour odour
                                                                  Odour         Vision       Fuzzy Control
                                                                 Processing    Processing
                                ACQUIRE
                                                                                          Commands Status
                                                              Commands Data      Images
                                                                                             Robot,control,
                                                                  E-Nose
                    Perceptual System                                          CCD Camera    odometry etc..

                                                      Figure 2: Overview of the robotic system which uses the an-
                                                      choring module. Arrows indicate the ﬂow of information.
Figure 1: Graphical illustration of the extended anchoring
functionalities where bottom-up and top-down information is when it is appropriate to remove anchors from the system.
possible and different sensing modalities are used.   Anchors could be removed if they are not relevant for the
                                                      current task, because the object to which it refers has been
    the description, but there are some properties in the de- physically removed from the environment or the reliability of
    scription that have not been observed.            the perceptual information has expired. Anchors may also
                                                      need to be removed if they have been associated to invalid
3.2  Maintenance  of Anchors                          perceptual data such as sensory glitches. We currently adopt
                                                      simple solutions in which objects that are not perceived when
At each perceptual cycle, when new perceptual information
                                                      expected decrease in a “life” value of the respective anchor.
is received, it is important to determine if the new perceptual
                                                      When  the anchor has no remaining life, the anchor is re-
information should be associated to existing anchors. The
                                                      moved. The converse could be implemented where anchors
following functionality addresses the problem of tracking ob-
                                                      are created with initially lowlife values and persistent per-
jects over time. In this extension, we include the previous
                                                      cepts increase its life value. The decreasing life of anchors is
Reacquire functionality as an integral part of the Track and
                                                      shown in Figure 4. A more adequate strategy to handle the
make no special distinction for it.
                                                      maintenance of anchors may also be to include a “long term”
Track The track functionality takes an anchor α deﬁned for memory where anchors may be stored for future use.
    t − k and extends its deﬁnition to t. The track assures
    that the percept pointed to by the anchor is the most re- 3.4 Integration of the Functionalities
    cent and adequate perceptual representation of the ob-
                                                      The event-based functionalities are now restricted to the
    ject. We consider that the signatures can be updated as                                          Find
                                                      and        while the     functionality is regularly called.
    well as replaced but by preserving the anchor structure Acquire      Track
                                                      Figure 1 shows an overview and an example of the framework
    we afﬁrm the persistence of the object so that it can be
                                                      and its functionalities. In the example, anchors are created
    used even when the object is out of view. This facili-
                                                      bottom-up from the visual percepts of a cup. Later, additional
    tates the maintenance of information while the robot is
                                                      features of that object are required, for example, the olfactory
    moving as well as maintaining a longer term and stable
                                                      property. These features are stored in the anchor. When a
    representation of the world on a symbolic level without
                                                      top-down request is sent to the anchor module to ﬁnd a cup
    catering to perceptual glitches.
                                                      with matching properties denoted by the symbol “cup-22”,
                                                      the Find functionality anchors the symbol to the perceptual
3.3  Deletion of Anchors                              data.
By having an anchor structure maintained over time, it is pos- As seen in the ﬁgure, properties can be collected at differ-
sible to preserve the perceptual information even if the object ent time points using different modalities. Even when certain
is not currently perceived (caused by the object being out of perceptual properties are updated, such as the smell property,
view and/or by the inaccuracy in the measurement of percep- which may change over time, other perceptual properties are
tual data). The challenge is to determine if the association maintained. Conversely, if the visual percepts of an anchor is
of new percepts is justiﬁed or whether certain anchors should replaced, the smell property previously obtained is not lost.
be removed. Mechanisms for destroying anchors when the In this way, the anchor is used to compensate for any dynam-
corresponding object has been removed need to be in place. ically changing features of an object. Furthermore, the per-
This is a difﬁcult problem, because conceptually it is not clear ceptual description of anchors can be accessed by the planner                                           Room T1209




                                                    r 1   Room T1210
                                                    o


                                 Room T1203 WC            Conference


                                                    rrid


                                                    o
                                                    C

                                          storage

                              x
                                     Corridor 2            Corridor 3


                                 Room T1201
                                                       Room T1204 Room T1206


Figure 3: (Left) The local space shows the detected objects, the robot is located in the center of the space. Grey areas in the
space are regions that are unexplored. Objects are represented by their visual percepts and are placed within the local space.
In this screen, the robot identiﬁes 2 garbage cans, denoted by the percepts Gar-1 and Gar-2. (Middle) The a priori map of the
ofﬁce environment to be patrolled. The robot starting position is shown at point X and a path of the robot is denoted by the
dotted line. (Right) The olfactory interface.

to reason about perceptual knowledge. In certain cases, this level planner, which then translates into several behaviours
may result in speciﬁc calls to perceptual actions in order to being activated e.g. “Go near to Gar-22, Touch Gar-2” and
disambiguate between similar objects.                 calls to an odour server which activates the respective pumps
                                                      on valves on the nose. The odour classiﬁcation provides the
4  The  System  Architecture                          smell description e.g. “gar-22 smells ethanol” and the per-
                                                      ceptual information is updated. Here the anchoring mod-
In this section, we present our own instantiation of the ex- ule “polices” each event signalling to the respective modules
tended anchoring framework discussed. We begin our de- when certain process need to be activated and when they have
scription at the sensor level and proceed to the higher levels reached completion.
which include a planner and user interfaces. An overview of
                                                        In our instance of the anchoring module, the track function-
the robotic system is given in Figure 2.
                                                      ality is achieved by performing a fuzzy matching algorithm
4.1  Sensing modalities and control                   between newly created percepts and previously stored an-
                                                      chors in order to partly deal with sensor noise. However, the
Our physical robot is a Magellan Pro compact robot and in purpose of the anchoring framework allows different strate-
the experiments we use its infrared sensors, sonars and tac- gies for the track functionality. A part of the future aims to
tile sensors. In addition, a CCD camera is mounted on the integrate more advanced solutions into the existing platform.
robot and the robot is able to recognise pre-deﬁned signa-
tures of objects using standard visual techniques. Perhaps 4.3 Planner
the most novel of sensors on the robot is an electronic nose.
The electronic nose consists of 32 conducting black polymer PTLplanner [Karlsson, 2001] is a planner for partially observ-
sensors, pattern recognition and classiﬁcation components, able domains with uncertainty (probabilities). It searches in
and an electronic repository of odours stored in the on-board a space of epistemic states, or e-states for short, where an e-
computer in the robot. The classiﬁcation algorithm uses the state represents the agent’s incomplete and uncertain knowl-
odour repository as a training set for online recognition of edge about the world at some point in time. Although much of
new odours. To navigate the robot, a collection of basic be- the planning component is standard, it is still worth empha-
haviours is used. These behaviours are based on fuzzy control sising that the planner can reason about perceptive actions,
techniques and can be combined and reasoned about through such as looking at or smelling an object. The consequence is
use of a behaviour planner (B-plan) explained in [Safﬁotti et that calls to perceptual actions may be made in order to gather
al., 1995].                                           more information about the environment.
4.2  Anchoring  Module                                4.4  Interfaces
The anchoring module, besides creating and maintaining the In addition to the computations mentioned in the previous
anchor data structure, also serves a secondary purpose to section for control, perception and autonomy, the system also
function as a ﬂag between top-level tasks given by a plan- has a number of processes for displaying the internal state of
ner and low-level sensor data. Although not immediately evi- the robot as well as its current model of the external world.
dent this function is important in order to co-ordinate percep- This model of the external world includes locally perceived
tual processes such as a smelling action which may take up objects and a gridmap of the environment built from sensor
to several minutes. In such a case, speciﬁc calls to percep- data. This is shown in Figure 3. In the left window, the local
tual actions e.g. “Smell gar-22” are generated from the top- view of the robot shows the incoming percepts of the vision                   1
                    Gar-1 Gar-1 track Gar-1        track                         Gar-27
                   0
                   1
                    Gar-2                          track
                   0     Gar-2 track      Gar-16                                 Gar-35
                   1
                    Gar-3
                   0                   Gar-24


Figure 4: The top row shows the camera images at different time points, the middle row shows the activity at the anchoring
level. Grey bars indicate anchors with olfactory properties. The bottom row shows the corresponding local perceptual space
given the changing representation of visual percepts.

and spatial modules. In the center ﬁgure, a map of the envi- by giving to the robot a sample of the smelling object and re-
ronment is shown. Additional interfaces include a live feed quest to ﬁnd similar objects. Finally top-down requests can
of the images viewed from the CCD camera and an olfactory be given to ﬁnd objects by giving to the system a symbolic
interface which shows clusters and data points for a loaded description of the object. The anchor that most matches the
repository (Figure 3 (Right)). Certain points can be interac- description will be returned.
tively selected to generate new plans for perceptual actions.
It also shows the symbolic representation preserving the elec- 5.1 Results
tronic perception of odours used to classify new odours. More The a priori information given to the system consists of a
information about the olfactory interface and the categorisa- rough map of the environment, shown in Figure 3 (Middle),
tion of odours can be found in [Loutﬁ and Coradeschi, 2004; and a repository of interesting objects, namely garbage cans
2005].                                                placed outside ofﬁces. The robot patrolled the corridors for
                                                      a period of 4 days, with intermittent breaks during the day
5  Experiments                                        and longer breaks during the evening for charging the bat-
                                                      teries. At any given time, garbage cans would be removed,
The general experiment is performed in a series of corridors. displaced, or added into the environment. The total distance
In each corridor there may be several objects, in this case covered by the robot is approximately 1.2 km without the in-
garbage cans. The robot automatically toggles between the clusion of the extra movement caused by smelling actions and
task of patrolling the corridor, inspecting objects and waiting over 70 odour samples were collected.
for commands from the user. Patrolling the corridor involves The local space of the robot together with the visual image
moving from corridor to corridor in a discovery for new ob- from the camera as well as the creation, deletion and updat-
jects and recognition of previous objects. When an inspect ing of anchors is depicted in Figure 4. The ﬁgure contains
is invoked, the robot visits each object collecting the odour four snapshots throughout an experimental run described as
property. The inspect is usually autonomously invoked when follows:
new objects are detected.
  The purpose of the experiment is to evaluate the ability • Scene 1 - The robot begins patrolling the corridor, two
of the extended anchoring framework to maitain an internal visual percepts are detected and two anchors denoted by
representation of the objects in the corridors for an extended Gar-1 and Gar-2, are created. An inspect is performed
period of time. Throughout the autonomous activity of pa- and both anchors obtain olfactory properties, shown in
trolling the corridor, a user may interrupt tasks by requesting the Figure by the grey colouring. Since the anchors are
the acquisition of speciﬁc objects. Object requests can be created in a bottom-up fashion their labels are arbitrary.
given by using the image feed from the camera and directly • Scene 2 - As the robot continues its patrol, another ob-
selecting a region in the screen. The sensory signature of the ject is inserted into the environment at a later time. Note
object will be matched against current anchors and current however, that the previous two anchors are still main-
execution of the patrol will be interrupted to include a plan to tained by the track functionality. Although the local
visit and inspect the selected object. Object can be requested space shows only the current percepts, the anchoring