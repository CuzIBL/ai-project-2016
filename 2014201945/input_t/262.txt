                  A lookahead strategy for solving large planning problems* 

                                                    Vincent Vidal 
                                             CRIL - Universite d'Artois 
                                             rue de 1'Universite - SP 16 
                                             62307 Lens Cedex, France 
                                               vidal@cril.univ-artois.fr 

                        Abstract                                 The determination of an heuristic value for each state as 
                                                              performed in the FF planner [Hoffmann and Nebel, 2001] 
     Relaxed plans are used in the heuristic search plan•     offers a way to compute such lookahead plans. FF creates 
     ner FF for computing a numerical heuristic and ex•       a planning graph [Blum and Furst, 1997] for each encoun•
     tracting helpful actions. We present a novel way         tered state S, using the relaxed problem obtained by ignoring 
     for extracting information from the relaxed plan         deletes of actions and using S as initial state. A relaxed plan 
     and for dealing with helpful actions, by consider•       is then extracted in polynomial time and space from this plan•
     ing the high quality of the relaxed plans. In numer•     ning graph. The length in number of actions of the relaxed 
     ous domains, the performance of heuristic search         plan corresponds to the heuristic evaluation of the state for 
     planning and the size of the problems that can be        which it is calculated. Generally, the relaxed plan for a state 
     handled have been drastically improved.                  S is not valid for S, as deletes of actions are ignored during 
                                                              its computation. In numerous benchmark domains, we can 
1 Computing and using lookahead states                        observe that relaxed plans have a very good quality because 
                                                              they contain a lot of actions that belong to solution plans. We 
In classical forward state-space search algorithms, a node in propose a way of computing lookahead plans from these re•
the search graph represents a planning state and an arc start• laxed plans, by trying as most actions as possible from them 
ing from that node represents the application of one action to and keeping the ones that can be collected into a valid plan. 
this state, that leads to a new state. In order to ensure com•   The lookahead algorithm and the modifications to the 
pleteness, all actions that can be applied to one state must be search algorithm are the following (all details can be found 
considered. The order in which these states will then be con• in [Vidal, 2002]). Each time a state S is evaluated, it is en•
sidered for development depends on the overall search strat•  tered into the open list. The relaxed plan extracted by the 
egy: depth-first, breadth-first, best-first...                evaluation function is used to compute a lookahead plan P 
  Let us now imagine that for each evaluated state S, we      which leads to a state S" reachable from S. If P is more than 
knew a valid plan P that could be applied to S and would      one action long, S' is evaluated and added to the open list. 
lead to a state closer to the goal than the direct descendants Let P be a relaxed plan for a state S. A lookahead plan P' 
of 5. It could then be interesting to apply P to 5, and use   is computed as follows: all actions of P are observed in turn. 
the resulting state S' as a new node in the search. This state When an action a is applicable to 5, it is added to the end of 
could be simply considered as a new descendant of S.          P' and S is updated (by the application of a). When all ac•
  We have then two kinds of arcs in the search graph: the     tions of P have been tried, this process is iterated without the 
ones that come from the direct application of an action to a  actions that have been applied, until no action can be used. 
state, and the ones that come from the application of a valid    Completeness and correctness of search algorithms are pre•
plan to a state S and lead to a state S' reachable from S. We served by this process, because no information is lost: all ac•
will call such states lookahead states, as they are computed  tions that can be applied to a state are still considered, and be•
by the application of a plan to a node S but are considered in cause the nodes that are added by lookahead plans are reach•
the search tree as direct descendants of S. Nodes created for able from the states they are connected to. The only modifi•
lookahead states will be called lookahead nodes. Plans label• cation is the addition of new nodes, corresponding to states 
ing arcs that lead to lookahead nodes will be called lookahead that can be reached from the initial state. 
plans. Once a goal state is found, the solution plan is then 
the concatenation of single actions for arcs leading to classi• 2 Using helpful actions: the "optimistic" 
cal nodes and lookahead plans for arcs leading to lookahead 
nodes.                                                            best-first search algorithm 
   *This work has been supported in part by the IUT de Lens, the In classical search algorithms, all actions that can be applied 
CNRS and the Region Nord/Pas-de-Calais under the TACT Pro•    to a node are considered the same way: the states that they 
gramme.                                                       lead to are evaluated by an heuristic function and are then or-


1524                                                                                                  POSTER PAPERS  dered, but there is no notion of preference over the actions  S can potentially be developed with rescue actions. As the 
 themselves. Such a notion of preference during search has     union of helpful actions and rescue actions is equal to the set 
 been introduced in the FF planner, with the concept of help•  of all the actions that can be applied to 5, completeness and 
ful actions. Once a relaxed plan is extracted for a state S, the correctness are preserved. 
 actions of the relaxed plan that are executable in S are con•
 sidered as helpful, while the other actions are forgotten by the 3 Experimental evaluation 
 local search algorithm of FF. This strategy appeared to be too We compare four planners: FF v2.3, and three different set•
 restrictive, so the set of helpful actions is augmented in FF by tings of our planning system called YAHSP (which stands for 
 all actions executable in S that produce fluents that were con•
                                                               Yet Another Heuristic Search Planner1) implemented in Ob•
 sidered as subgoals at the first level of the planning graph, jective Caml: BFS (Best First Search: classical WA* search, 
 during the extraction of the relaxed plan. The main draw•     with W = 3. The heuristic is based on the computation of a 
 back of this strategy, as used in FF, is that it does not preserve relaxed plan as in FF), OBFS (Optimistic Best First Search: 
 completeness: the actions executable in a state S that are not identical to BFS, with preference of helpful actions over res•
 considered as helpful are simply lost. FF switches to a com•  cue actions), and LOBFS (Lookahead Optimistic Best First 
plete best-first algorithm when no solution is found.          Search: identical to OBFS, with lookahead states). 
   We present a way to use such a notion of helpful actions       We report here complete results for Logistics domain (see 
 in complete search algorithms, that we call optimistic search Figure 1) and show in Table 1 some data about the largest 
algorithms because they give a maximum trust to the infor•     problems solved by FF, OBFS and LOBFS, in order to realize 
 mations returned by the computation of the heuristic. The     the progress accomplished in the size of the problems that can 
principles are the following:                                  be solved by a STRIPS planner, for five different domains. 
   • Several classes of actions are created. In our implemen•
     tation, we only use two of them: helpful actions (the re• Acknowledgments 
     stricted ones), and rescue actions that are all the actions Thanks a lot to Pierre Regnier for his help... 
     that are not helpful. 
   • When a newly created state S is evaluated, the heuris•    References 
     tic function returns the numerical estimation of the state [Blum and Furst, 1997] A. Blum and M. Furst. Fast planning 
     and also the actions executable in S partitioned into their  through planning-graphs analysis. Artificial Intelligence, 90(1-
     different classes. For each class, one node is created for   2):281-300, 1997. 
     the state 5, that contains the actions of that class.     [Hoffmann and Nebel, 2001] J. Hoffmann and B. Nebel. The FF 
   • Nodes containing helpful actions are always preferred        planning system: Fast plan generation through heuristic search. 
     for development over nodes containing rescue actions,       JAIR, 14:253-302,2001. 
     whatever their numerical heuristic values are.            [Vidal, 2002] V. Vidal. A lookahead strategy for heuristic search 
                                                                  planning. Technical Report 2002-35-R, IRIT, Universite Paul 
   No information is lost by this process. The way nodes are 
                                                                  Sabatier, Toulouse, France, 2002. 
developed is simply modified: a state S is developed first with 
helpful actions, some other nodes are developed, and then         1 http://www.cril.univ-artois.fr/~vidal/yahsp.html 


 POSTER PAPERS                                                                                                       1525 