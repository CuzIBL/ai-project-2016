   Selective Supervision: Guiding Supervised Learning with Decision-Theoretic
                                          Active Learning

                            Ashish Kapoor, Eric Horvitz and Sumit Basu
                                          Microsoft Research
                             1 Microsoft Way, Redmond, WA 98052, USA
                       {akapoor, horvitz, sumitb}@microsoft.com

                    Abstract                            Given the cost of labeling previously unlabeled cases and
                                                      the cost of misclassiﬁcation—which may be different for dif-
    An inescapable bottleneck with learning from large ferent classes—we seek to quantify the expected gain in ex-
    data sets is the high cost of labeling training data. pected value associated with seeking information on an unla-
    Unsupervised learning methods have promised to    beled data point. This expected gain, which corresponds to
    lower the cost of tagging by leveraging notions of the value of information provided by labeling, is the guid-
    similarity among data points to assign tags. How- ing principle for the active learning framework. We shall
    ever, unsupervised and semi-supervised learning   show how we can employ this value of information in learn-
    techniques often provide poor results due to errors ing within the Gaussian Process classiﬁcation framework, and
    in estimation. We look at methods that guide the  describe the applicability of the approach to both supervised
    allocation of human effort for labeling data so as to and semi-supervised scenarios.
    get the greatest boosts in discriminatory power with After a review of some key work in active learning, we de-
    increasing amounts of work. We focus on the ap-   scribe the active learning framework that uses expected value-
    plication of value of information to Gaussian Pro- of-information (VOI) criterion to triage labeling. Then, we
    cess classiﬁers and explore the effectiveness of the present concepts and computational issues with the use of
    method on the task of classifying voice messages. Gaussian Process classiﬁcation, and we show how the meth-
                                                      ods can be extended to handle semi-supervised learning. We
1  Introduction                                       highlight the effectiveness of the framework on the task of
Increased sensing and decreased storage costs are leading to classifying voice messages and we conclude with experimen-
the growing availability of large data sets. However, data re- tal results and discussion.
sources are often unavailable for machine learning and rea-
soning because of the high cost of labeling cases. As an ex- 2 Background
ample, we may have access to several thousand voice mes- Interest has been growing in recent years in active learn-
sages stored on a server and wish to build a classiﬁcation ing. Numerous heuristics and schemes have been proposed
system that could automatically classify voicemail messages for choosing unlabeled points for tagging. For example, Fre-
into different categories. Unfortunately, performing super- und et al. 1997 propose disagreement among the commit-
vised learning with the data set would require the manual ef- tee of classiﬁers as a criterion for active learning. Tong and
fort of listening to voice messages and applying labels. Koller, 2000 explore the selection of unlabeled cases to query
  Unsupervised learning shows promise for reducing the ef- based on minimizing the version space within the support
fort required for tagging, such as its use in preparing data vector machines (SVM) formulation. Within the Gaussian
sets for supervised learning. However, pure unsupervised Process framework, the method of choice has been to look
learning, based on notions of clusters and similarity, is often at the expected informativeness of an unlabeled data point
fraught with labeling errors.                         [MacKay, 1992; Lawrence et al., 2002]. Speciﬁcally, the idea
  We believe that there is a rich space of opportunities within is to choose to query cases that are expected to maximally
the realm of complementary computing [Horvitz and Paek, inﬂuence the posterior distribution over the set of possible
2007] for machine learning. We focus on the ideal coupling classiﬁers. Additional studies have sought to combine ac-
of human supervision with unsupervised methods and we dis- tive learning with semi-supervised learning [McCallum and
cuss selective supervision, the use of value-of-information to Nigam, 1998; Muslea et al., 2002; Zhu et al., 2003].
triage human tagging efforts. The active-learning method All of these methods inherently focus on minimizing the
considers both the cost required to tag data as well as the misclassiﬁcation rate. We focus on the value of moving to
costs associated with the use of a classiﬁer in a real-world set- a decision-theoretic framework in active learning, where we
ting. We show how we can minimize the total cost associated consider the costs and risks in real-world currencies and em-
with the construction and use of classiﬁcation systems, where ploy computations of expected value of information to bal-
costs are measured in currencies such as monetary quantities ance the cost of misdiagnosis with the costs of providing la-
or other valuable resources.                          bels.

                                                IJCAI-07
                                                   8773  Decision-Theoretic Active Learning                 data points:
                                                                 
                                                                                  ∗              ∗
A linear classiﬁer parameterized by w classiﬁes a test point JU      R12  − pi · p   R21pi ·  − p
                                     T                         =        (1    )   i +       (1   i )  (2)
x according to: sign(f(x)), where f(x)=w x. Given a set          i∈U
of training data points XL = {x1, .., xn}, with class labels ∗
                                                      Here, p =  p(ti =1|xi) is the true conditional density of
TL = {t1, .., tn},whereti ∈{1, −1}, the goal of a learning  i
algorithm is to learn the parameters w. Most classiﬁcation the class label given the data point. As we do not have the
                                                      true conditional, we cannot compute this expression exactly.
techniques focus on minimizing classiﬁcation error. How-                        p∗     p
ever, preferences about the relative numbers of false positives However, we can approximate i with i; thus, we approxi-
                                                      mate the total risk on the unlabeled data points as:
and negatives produced by a classiﬁcation system can vary by          
person and task. These preferences can be expressed in terms     JU ≈    (R12 + R21)(1 − pi) · pi     (3)
of real-world measures of cost such as a monetary value and           i∈U
we can seek to minimize the expected cost for the use of a
                                                      Now, let Ci denote the cost of knowing the class label of xi.
classiﬁer over time. Additionally, we have the cost of tag-                 C              R      R
ging cases for training, which can vary for cases in different We assume that the costs i and the risks 12 and 21 are
classes or with other problem-speciﬁc variables.      measured with the same currency. This assumption does not
  We aim to quantify the values of acquiring labels of differ- impose signiﬁcant constraints as different currencies can be
ent data points and to use computations of these values as a transformed into a single utility by using appropriate real-
                                                      world conversions.
guiding principle in active learning. Intuitively, knowing the        J     J                1
label of one or more currently unlabeled points may reduce Given the risks ( L and U ), we approximate the expected
                                                                                   J¯   JL+JU
the total risk in the classiﬁcation task. On the other hand, la- misclassiﬁcation cost per point as = n+m . Assuming a
bels are acquired at a price. The difference in the reduction in closed world, where the system only encounters the n + m
the total expected cost of the use of the classiﬁer, which we points in XL ∪XU , the expected cost is the sum of the total
                                                      risk (Jall =(n + m)J¯) and the cost of obtaining the labels:
shall refer to as the risk, and the cost of acquiring a new label                         
is the expected value of information for learning that label.
                                                              U  = Jall +   Ci = JL + JU +    Ci      (4)
The real-world cost associated with the usage of a classiﬁer
                                                                         i∈L               i∈L
is a function of the number of times that a classiﬁer will be
used in the real world, so a probability distribution over usage Upon querying the new point, we may see a reduction in the
is considered in the computation of expected cost.    total risk. However, a cost is incurred when we query a label
  For simplicity, we shall focus in the discussion on two- and computing the difference in these quantities triages the
class discrimination problems. The methods discussed in the selection of cases to label. Formally, we deﬁne the VOI of
paper can be generalized in a straightforward manner to han- an unlabeled point xj as the difference in the reduction in the
dle multiple classes. We note that the work presented here total risk and the cost of obtaining the label:
makes a myopic assumption, where we only seek to label one                    j           j
                                                             VOI(xj  )=U   − U  =(Jall − Jall) − Cj   (5)
data point at a time. This can be generalized by applying
                                                             j     j
lookahead procedures that consider the acquisition of labels Here, U and Jall denote the total expected cost and the to-
for different sets of points.                         tal misclassiﬁcation risk respectively if we consider xj as la-
                                         2×2
  Let us deﬁne the risk matrix R =[Rij ] ∈ IR ,where  beled. The VOI quantiﬁes the gain in utilities in terms of the
Rij denote the cost or risk associated with classifying a data real-world currency that can be obtained by querying a point;
point belonging to class i as j. We use the index 2 to de- hence, our strategy would be to choose next for labeling the
note the class -1. We assume that the diagonal elements of R point that has the highest value of information. This results in
are zero, specifying that correct classiﬁcation incurs no cost. minimization of the total cost U that consists of the total risk
Thus, given the labeled set XL with labels TL we can train a in misclassiﬁcation as well as the labeling cost. We note that
classiﬁer f(x) and compute the total risk on the labeled data this approach differs from the earlier methods in active learn-
points as:                                            ing where the focus has been to minimize the classiﬁcation
                                                    error.
         JL =      R12(1 − pi)+     R21pi       (1)     Now, let us consider xj for querying. Note that we need to

              i∈L+             i∈L−                   compute the expression for VOI before we know the label for
                                                                        j
                                                      xj and the total risk J cannot be computed before we know
     p                                x                                 all
Here, i denotes the probability that the point i is classiﬁed the actual label tj. Similarly, Cj cannot be computed if the
              p    p     f x       |x           L
as class +1,i.e. i = (sign( ( i)) = 1 i).Further, +   costs of labels are different for different classes. We approxi-
   L
and  − are the indices of positively and negatively labeled        J j       jth
                           p                          mate the terms all for the data point with an expectation
points respectively. Note, that i is the predictive distribu-               j       j,+   j,−
                                                      of the empirical risk as: Jall ≈ pjJ + J (1 − pj).Here
tion and depending upon the classiﬁcation technique may or j,+  j,−
may not be available. Predictive distributions are available for J and J denote the total risks when xj is labeled as
Gaussian Process classiﬁcation (Section 4) and other proba- class 1 and class -1 respectively. These risks can be written
bilistic classiﬁers, including probabilistic mappings of out- as sum of risks on labeled and unlabeled data as following:
            [         ]                                   j,+    j,+   j,+          j,−   j,−    j,−
puts of SVMs Platt, 2000 .                               J   =  J   + J      and  J    = J    + J     (6)
  Beyond labeled cases, we also have a set of unlabeled data     L     U                  L      U
points XU = {xn+1, .., xn+m},thatwewishtoclassify.We     1This approximation can be used for any case, whether previ-
seek to include the total risk associated with the unlabeled ously seen or unseen, provided the density p(x) does not change.

                                                IJCAI-07
                                                   878                          1   2                                1   2
   Equal Risk (R  = 1, R  = 1) & Equal Label Cost (C  = 1, C  = 1) Asymmetric Risk (R  = 1, R  = 10) & Equal Label Cost (C  = 1, C  = 1) Equal Risk (R  = 1, R  = 1) & Asymmetric Label Cost (C1 = 1, C2 = 1.25)
         12  21                              12  21                          12  21
1.5                                1.5                                 1.5


 1                                  1                                  1


0.5                                0.5                                 0.5


 0                                  0                                  0


−0.5                               −0.5                               −0.5


−1                                  −1                                 −1


   −1   −0.5 0   0.5  1   1.5  2       −1  −0.5 0   0.5  1   1.5  2       −1  −0.5 0   0.5  1   1.5  2
                (a)                                (b)                                (c)

Figure 1: Selection of points to query for label based on the value of information. The circles represent the unlabeled cases and the radii
correspond to the VOI of labeling each case. The squares (class 1) and the triangles (class -1) represent previously labeled cases. The
different ﬁgures correspond to the following situations: (a) symmetry in the costs of both the risks and the labeling, (b) asymmetric risk, and
(c) asymmetric label costs. The cross corresponds to the selection of the next query. The curve denotes the decision boundary based on the
currently available labels.

To calculate these risks we ﬁrst compute pj,+, the resulting is marked with a cross. Figure 1(a) shows the VOI for all the
posterior probability upon adding xj as a positively labeled unlabeled data points and the case selected for the next query
example in the active set. Now, using similar expressions to when the risks and the cost of labelings are equal for both
                               j,+     j,+
equations 1 and 3 we can compute JL and JU ,therisks  classes. For this situation, cases that are nearest to the deci-
on the labeled and the unlabeled data points when xj is as- sion boundary are associated with the highest VOI. Choosing
sumed to be positively labeled. The corresponding computa- cases that minimize the objective for overall cost corresponds
               j,−    j,−                             to the selection of queries that would minimize the classiﬁ-
tions follow for JL and JU as well. Similarly, we can use
expectation of Cj if costs of labeling vary by class. cation error; hence, the points at the decision boundary are
  Thus, our strategy is to select cases for labeling that have the ones that are the most informative. Figure 1(b) illustrates
the highest VOI:                                      the situation where it is far more expensive to misclassify a
                                                      point belonging to class -1. Due to this asymmetry in risks,
              jsel =argmaxVOI(xj   )            (7)   the points that are likely to belong to class -1, but that also lay
                        j∈U
                                                      close to the decision boundary, have the highest VOI. Figure
                   VOI  x
We note that whenever  ( jsel ) is less than zero, we have 1(c) depicts the situation where obtaining a label for a point
a condition where knowing a single label does not reduce the in class -1 is 1.25 times as expensive to obtain the label for
total cost; thus, this situation can be employed as a stopping a point belonging to class 1. The VOI is highest for those
criterion. Stopping criteria for open-world situations would points that are more likely to belong to class 1 and that are
include the computation of gains in accuracy of the classiﬁer close to the decision boundary. The sample data set illustrates
over multiple uses, based on a probability distribution over how VOI can be used effectively to guide tagging supervision
expected cases and the lifespan of the system. We note that such that it minimizes both the operational and training costs
a greedy policy might indicate stopping when there is still of a classiﬁer.
potential for further reduction of the overall cost via querying We point out that we have assumed a closed system where
a set of points.                                      both the set of the labeled and the unlabeled data are avail-
  We now demonstrate the approach, starting with illustra- able beforehand. Prior work on active learning includes stud-
tions with a toy data set. We shall employ Gaussian Process ies that assume an open system, where the data points arrive
classiﬁcation (see section 4) within the active learning frame- one at a time. The methods discussed in this paper can be
work. Figure 1 shows the selection of unlabeled points to extended to handle the open system case by using the aver-
                                                                       JL
query based on the VOI criterion. The sample data consists age empirical risk ( n ) as a guiding principle as earlier used
of two half moons in a multidimensional space, where the top by Zhu et al., 2003. Note that this is not a transductive learn-
half belongs to class +1 and the bottom to the class -1. In the ing framework; the ﬁnal classiﬁcation boundary depends only
simulation, we start with a few cases that are already labeled on the labeled data. Both the labeled and the unlabeled data
and are represented as squares for class 1 and triangles for the points are used only to determine which cases to query. Once
class -1. The different graphs in the ﬁgure correspond to dif- trained, the classiﬁer can be applied to novel test points, be-
ferent settings of risks (R12 and R21) and labeling costs. We yond the original set of labeled and the unlabeled points. We
assume that C1 and C2 are the costs for querying points that shall describe in Section 4.2 extensions to handle the trans-
belong to class +1 and −1 respectively. The unlabeled points ductive case by using a semi-supervised learning algorithm
are displayed as circles and the radii correspond to the VOI to train the classiﬁer. Before that, we will pause to review
of labeling these cases. The next case selected to be queried Gaussian Process classiﬁcation.

                                                IJCAI-07
                                                   879                                Table 1: Features extracted from voice messages
                                 Prosodic features                 Metadata information
                        (∗ includes max, min, mean and variance)
                                Duration of silence∗                    Is Weekend?
                             Duration of voiced segment∗            Is AM on a work day?
                                  Absolute pitch∗                   Is PM on a work day?
                            Length of productive segment∗        Is after hours on a work day?
                                  Length of pause∗                      Size in bytes
                       Change in pitch during productive segments∗     Size in seconds
                 Rate features (syllable, silence, productive segments, pauses) Is external caller?

4  Gaussian Process Classiﬁcation                     p(sign(f(x))|x):
In this work, we explore active learning with the use of Gaus-                            T
                                                                                        w¯ x
sian Process (GP) classiﬁers. One of the advantages of using p sign f x    1|x                       (9)
                                                              (   ( (  )) =   )=Ψ(      T        )
GP classiﬁcation is that we directly model the predictive con-                        x  Σwx  +1
ditional distribution p(t|x), consequently making it easy to
compute the actual conditional probabilities without any cal- Unlike other classiﬁers, the GP classiﬁcation models the pre-
                                                                                p t|x
ibrations or post-processing. GP methods provide a Bayesian dictive conditional distribution ( ), making it easy to com-
interpretation of classiﬁcation. With the approach, the goal is pute the actual conditional probabilities without any calibra-
to infer the posterior distribution over the set of all possible tions or post-processing. Probabilistic interpretations have
classiﬁers given a training set:                      been made of other kernel classiﬁers such as SVM [Sollich,
                                                     1999] and other attempts that map the output of the classi-
          p(w|XL, TL)=p(w)     p(ti|w, xi)      (8)   ﬁers directly to the probability [Platt, 2000]. Our approach is
                            i∈L                       to use this predictive distribution in the selective-supervision
     p w                                              framework to compute expected risks and to quantify the
Here, ( ) corresponds to the prior distribution over the clas- value of information.
siﬁers and is selected typically so as to prefer parameters w
that have a small norm. Speciﬁcally, we assume a spherical 4.1 Computational Issues
Gaussian prior on the weights: w ∼N(0, I). The prior im-
poses a smoothness constraint and acts as a regularizer such As mentioned earlier, ADF or EP can be used for approximate
that it gives higher probability to the labelings that respect inference in GP classiﬁcation. However, the proposed scheme
the similarity between the data points. The likelihood terms for selecting unlabeled points is computationally expensive.
                                                                                                 3
p(ti|w, xi) incorporate the information from the labeled data Note, that computational complexity for EP is O(n ),where
and different forms of distributions can be selected. A popu- n is the size of labeled training set. In the proposed method,
lar choice is the probit likelihood: p(t|w, x)=Ψ(t · wT x). we have to compute VOI for every unlabeled data point, re-
Here, Ψ(·) denotes the cumulative density function of the quiring us to perform EP twice for every point under consid-
standard normal distribution. The posterior prefers those pa- eration.
rameters that have small norm and that are consistent with the A faster alternative is to use ADF for approximating
training data.                                        the new  posterior over the classiﬁer rather than com-
  Computing the posterior, p(w|X , T ), is non-trivial and puting EP. Speciﬁcally, to compute the new posterior
                                                       j,+
approximate inference techniques such as Assumed Density p (w|XL∪j, {TL ∪+1}) we can compute the Gaussian pro-
Filtering (ADF) or Expectation Propagation (EP) are typ- jection of the old posterior multiplied by the likelihood term
                                                             th                  j,+
ically required. The idea behind ADF is to approximate for the j data point. That is: p (w|XL∪j, {TL ∪ +1}) ≈
            p w|X  , T                                     j,+  j,+         j,+      j,+
the posterior (  L   L) as a Gaussian distribution, i.e. N (w¯ , Σw ),wherew¯  and Σw   are respectively the
p w|X  , T ≈N   w,                                                                                  T
 (   L   L)     ( ¯ Σw). Similarly, EP is another approx- mean and the covariance of p(w|XL, TL) · Ψ(1 · w xj).
imate inference technique. EP is a generalization of ADF, This is equivalent to performing ADF starting with the old
where the approximation obtained from ADF is reﬁned us- posterior p(w|XL, TL) and incorporating the likelihood term
                                                             T                         3
ing an iterative message passing scheme. We refer readers to Ψ(1 · w xj ) and does not require O(n ) operations to com-
Minka, 2001 for the details.                          pute VOI for every unlabeled data point. We can use similar
                                    p w|X , T    ∼                              j,−
  Given  the  approximate posterior  (      )         computations to approximate p (w|XL∪j, {TL ∪−1}).
N (w¯ , Σw), a frequent practice is to choose the mean
w
¯ of the distribution as the point classiﬁer. The mean, which 4.2 From Supervised to Semi-Supervised Learning
is also called the Bayes point, classiﬁes a test point according
to: sign(w¯ T x). It is relatively straightforward to generalize The underlying classiﬁer in the proposed framework is based
to the non-linear case by using the kernel trick, where the on Gaussian Processes and it can be easily extended for the
idea is to ﬁrst project the data into a higher dimensional semi-supervised case [Kapoor, 2006; Sindhwani et al., 2005].
space to make it separable [Evgeniou et al., 2000].   Speciﬁcally, at the core in the GP classiﬁcation is the kernel
  One of the byproducts of using  the GP  classiﬁca-  matrix K,whereentryKij  encodes the similarity between
tion framework is that we obtain a predictive distribution the ijth and the jth data points. Rather than using K as the

                                                IJCAI-07
                                                   880                          Caller Close / Not Close               Mobile / Non−Mobile

                                          VOI                                   VOI
                                                        52
                  50                      Random                                Random
                                                        50
                                          Uncertainity                          Uncertainity
                                                        48
                                          Entropy                               Entropy
                  45
                                                        46

                                                        44
                  40
                                                        42

                                                        40
                  35
                                                        38

                                                        36


                 Error  on Unlabeled Points 30         Error  on Unlabeled Points
                                                        34

                                                        32
                        5     10     15     20                5      10     15     20
                         Number of Labeled Points               Number of Labeled Points
                               (a)                                     (b)
                          Caller Close / Not Close               Mobile / Non−Mobile
                 1050
                                          VOI                                   VOI
                                                       1050
                 1000                     Random                                Random

                 950                      Uncertainity 1000                     Uncertainity

                 900                      Entropy       950                     Entropy

                 850                                    900
                 800
                                                        850
                 750
                                                        800
                 700
                                                        750
                 650
                Total  Cost Incurred                  Total  Cost Incurred

                 600                                    700

                 550                                    650

                        5      10     15     20               5      10     15     20
                         Number of Labeled Points               Number of Labeled Points
                               (c)                                     (d)

Figure 2: Comparison of different active learning schemes. Graphs (a) and (b) show the error on unlabeled points versus the number of
labels for classifying voicemails. Graphs (c) and (d) show the total cost incurred versus the number of labels. VOI criteria can provide good
classiﬁcation performance with signiﬁcantly lower costs. The results are averaged over 20 runs and the error bars represent the standard error.

similarity matrix for GP classiﬁcation, we can use the inverse routing of email messages with statistical classiﬁers [Horvitz
of the transformed Laplacian:                         et al., 1999].
       r(Δ) = Δ +  σI   where   Δ=D    − K              Given a set of voice messages, we ﬁrst extract features that
                                                      promise to be of value in discriminating among the target
Here, D is the diagonal matrix where the diagonal elements classes. Speciﬁcally, we look at the prosody and metadata
are: Dii =  j Kij and σ>0  is added to remove the zero that accompanies the messages.
eigenvalue from the spectrum of r(Δ). Intuitively, rather Prosodic features: We consider multiple prosodic features
than computing similarity directly via the kernel Kij ,the including syllable rate, pause structure, and pitch dynamics.
inverse of the transformed Laplacian computes the similar- We employ a pitch tracker and then extract the prosodic fea-
ity over a manifold. Thus, the unlabeled data points help tures summarized in table 1.
in classiﬁcation by populating the manifold and using the Message metadata: We also extract metadata from the voice
similarity over the manifold to guide the decision bound- messages. Speciﬁcally, we extract features that indicate the
ary. The extension of GP classiﬁcation to handle semi- day and the time of the call. Additionally, we consider the
supervised learning has been recently studied [Kapoor, 2006; size of the voicemail in bytes as well as the length of the
Sindhwani et al., 2005] and is related to the graph-based message in seconds. We also extract features that indicate
methods for semi-supervised learning. The rest of the active whether the caller is calling from outside the recipient’s orga-
learning framework can be used as it is on top of this semi- nization. Several metadata features are shown in table 1.
supervised GP classiﬁcation framework.
                                                        We now explore the selective supervision concepts applied
                                                      to the voicemail classiﬁcation challenge. The data set con-
5  Sample Challenge: Classifying Voicemail            sists of 207 labeled voice messages received by a single user
We shall now move to a challenging classiﬁcation task that over a period of 8 months. We explore the use of the methods
highlights the value of employing the selective supervision to guide the labeling efforts for supervised classiﬁcation. An-
methods. Speciﬁcally, our goal is to build a system that can notating a voicemail is tedious and shorter voicemails can be
classify voice messages in several ways, including whether labeled more quickly than the longer ones. Thus, we use the
the messages are urgent vs. non-urgent, the caller is person- asymmetric cost criterion where the cost of a label scales with
ally close vs. not close to the person being called, and to the length of the voicemail. Speciﬁcally, we assume that the
detect if the caller is calling from a mobile phone. The classi- cost of labeling voicemail is 0.01 US dollars per second of
ﬁcation task is related to prior work on the prioritization and message length. Further, for all of the experiments we assume

                                                IJCAI-07
                                                   881