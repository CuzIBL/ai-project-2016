PC-DPOP: A New Partial Centralization Algorithm for Distributed Optimization

             Adrian Petcu    and Boi Faltings                      Roger Mailler
        Ecole Polytechnique F´ed´erale de Lausanne           AI Center, SRI International
        email: {adrian.petcu, boi.faltings}@epﬂ.ch            email: mailler@ai.sri.com


                    Abstract                          where agents designated as mediators centralize parts
                                                      of the problem in dynamic and asynchronous mediation
    Fully decentralized algorithms for distributed
    constraint optimization often require excessive   sessions. Message complexity is signiﬁcantly smaller than
                                                      ADOPT’s. However, it is possible that several mediators
    amounts of communication   when  applied to
                                                      solve overlapping problems, thus needlessly duplicating
    complex  problems.   The OptAPO   algorithm
    of [Mailler and Lesser, 2004] uses a strategy of  effort. Furthermore, the asynchronous and dynamic nature
                                                      of the mediation sessions make it impossible to predict what
    partial centralization to mitigate this problem.
                                                      will be centralized where, how much of the problem will be
    We   introduce  PC-DPOP,   a   new   partial      eventually centralized, or how big a computational burden the
    centralization technique, based on the DPOP       mediators have to carry. It has been suggested in [Davin and
                [                      ]
    algorithm of Petcu and Faltings, 2005 .PC-        Modi, 2005] that often a handful of nodes centralize most of
    DPOP provides better control over what parts      the problem, and therefore carry out most of the computation.
    of the problem are centralized and allows this      DPOP  [Petcu and Faltings, 2005] is a complete algorithm
    centralization to be optimal with respect to the  based on dynamic programming which generates only a
    chosen communication structure.                   linear number of messages. However, DPOP may produce
    Unlike  OptAPO,   PC-DPOP    allows  for a        large messages and require large amounts of memory, up
    priory, exact predictions about privacy loss,     to space exponential in the induced width of the problem.
    communication,  memory   and  computational       Therefore, DPOP may be infeasible for problems with high
    requirements on all nodes and links in the network. induced width.
    Upper bounds on communication and memory            We present PC-DPOP, a new  hybrid algorithm that is
    requirements can be speciﬁed.                     controlled by a parameter k which characterizes the size of
    We  also report strong efﬁciency gains over       the largest message, and the amount of available memory.
    OptAPO in experiments on three problem domains.   The algorithm proceeds as normal DPOP, except in the dense
                                                      parts of the problem (width greater than k). These are
1  Introduction                                       clustered and centralized in the root of the cluster, which
Constraint satisfaction and optimization are powerful solves them with a centralized algorithm. Communication
                                                      requirements over any link in the network are limited thus to
paradigms that model a large range of tasks like scheduling, exp(k)
planning, optimal process control, etc. Traditionally, such . The linear number of messages is preserved.
problems were gathered into a single place, and a centralized The rest of this paper is structured as follows: Section 2
algorithm was applied in order to ﬁnd a solution. However, formally describes the optimization problem, and introduces
problems are sometimes naturally distributed, so Distributed the DPOP and OptAPO algorithms. Section 3 introduces the
Constraint Satisfaction (DisCSP) was formalized by Yokoo PC-DPOP hybrid algorithm, which is evaluated empirically
et al. in [Yokoo et al., 1992]. Here, the problem is divided in Section 4. Section 5 relates PC-DPOP to existing work.
between a set of agents, which have to communicate among Section 6 brieﬂy discusses privacy, and Section 7 concludes.
themselves to solve it. To address distributed optimization,
complete algorithms like ADOPT, OptAPO and DPOP have  2   Preliminaries
been recently introduced.                             Deﬁnition 1 A discrete distributed constraint optimization
  ADOPT   [Modi et al., 2003] is a backtracking based problem (DCOP) is a tuple < X , D, R > such that:
bound propagation mechanism.  It operates completely    •X=    {X1, ..., Xn} is a set of variables
decentralized, and asynchronously. Its downside is that it •D= {d , ..., d }
may require a very large number of small messages, thus          1    n  is a set of ﬁnite variable domains
producing important communication overheads.            •R=    {r1, ..., rm} is a set of relations, where a relation
                                                          r                            (X  , ···,X ) r  :
  OptAPO  is a hybrid between decentralized and centralized i is any function with the scope i1   ik , i
                                                          d  ×  .. × d →  R
methods. It operates as a cooperative mediation process,   i1       ik     , which denotes how much utility is

                                                IJCAI-07
                                                   167    assigned to each possible combination of values of the 2.3 DPOP: dynamic programming optimization
                                              1
    involved variables. Negative amounts mean costs.  DPOP is a distributed version of the bucket elimination
  In a DCOP, each variable and constraint is owned by an scheme from [Dechter, 2003], which works on a DFS. DPOP
agent. A simplifying assumption [Yokoo et al., 1992] is has 3 phases.
that each agent controls a virtual agent for each one of the Phase 1 - a DFS traversal of the graph is done using a
variables Xi that it owns. To simplify the notation, we use distributed DFS algorithm like in [Petcu et al., 2006].The
Xi to denote either the variable itself, or its (virtual) agent. outcome of this step is that all nodes consistently label each
  This is a multiagent instance of the valued CSP framework other as parent/child or pseudoparent/pseudochild, and edges
as deﬁned in [Schiex et al., 1995]. The goal is to ﬁnd a are identiﬁed as tree/back edges. This can be achieved for any
                    ∗
complete instantiation X for the variables Xi that maximizes graph with a linear number of messages.
the sum of utilities of all individual relations.       Phase 2 - UTIL propagation  is a bottom-up process,
  We assume here only unary and binary relations. However, which starts from the leaves and propagates upwards only
DPOP  and PC-DPOP    can easily extend to non-binary  through tree edges. The agents send UTIL messages to
constraints ([Petcu et al., 2006]).                   their parents. The subtree of a node Xi can inﬂuence
                                                      the rest of the problem only through Xi’s separator, Sepi.
2.1  Depth-First Search Trees (DFS)                   Therefore, a message contains the optimal utility obtained in
PC-DPOP works on a DFS traversal of the problem graph. the subtree for each instantiation of Sepi. Thus, messages
Deﬁnition 2 (DFS tree) A DFS arrangement of a graph G is are exponential in the separator size (bounded by the induced
a rooted tree with the same nodes and edges as G and the width).
property that adjacent nodes from the original graph fall in Phase 3 - VALUE propagation top-down, initiated by the
the same branch of the tree (e.g. X0 and X11 in Figure 1). root, when phase 2 has ﬁnished. Each node determines its
  Figure 1 shows an example DFS tree that we shall refer to optimal value based on the messages from phase 2 and the
in the rest of this paper. We distinguish between tree edges, VALUE message it has received from its parent. Then, it
shown as solid lines (e.g. X1 − X2), and back edges,shown sends this value to its children through VALUE messages.
as dashed lines (e.g. X12 − X8, X4 − X0).
                                                      3   PC-DPOP(k)    - partial centralization hybrid
Deﬁnition 3 (DFS concepts) Given a node Xi, we deﬁne:
  • parent Pi /  children Ci: these are the obvious   To overcome the space problems of DPOP, we introduce the
                                                                     k
    deﬁnitions (P4 = X2, C1 = {X2,X5}).               control parameter that bounds the message dimensionality.
                                                      This parameter should be chosen s.t. the available memory at
  • pseudo-parents PPi   are Xi’s ancestors directly
               X                   PP   = {X  }       each node and the capacity of its link with its parent is greater
    connected to i through back-edges ( 5    0 ).     than dk, where d is the maximal domain size.
  • pseudo-children PCi are Xi’s descendants directly   As with DPOP, PC-DPOP also has 3 phases: a   DFS
    connected to Xi through back-edges (PC1 = {X4}).  construction phase, an UTIL phase, and a VALUE phase.
  • Sep                  X             X
       i is the separator of i: ancestors of i which are               UTIL
    directly connected with Xi or with descendants of Xi 3.1 PC-DPOP -       Phase
    (e.g. Sep9 = {X0,X8}, Sep2 = {X0,X1}). Removing   This is where the algorithm is different from DPOP. The
    the nodes in Sepi completely disconnects the subtree propagation proceeds as in DPOP where possible, and reverts
    rooted at Xi from the rest of the problem.        to partial centralization where the width exceeds k:
                                                        1. the UTIL propagation starts bottom-up exactly like in
2.2  Optimal Asynchronous Partial Overlay                 DPOP, and proceeds as long as the dimensionality of the
Optimal Asynchronous Partial Overlay (OptAPO [Mailler     outgoing UTIL messages is below the threshold k.
and Lesser, 2005]) is a sound and optimal algorithm for
                                                        2. as soon as a node’s outgoing UTIL  message has
solving DCOPs that uses dynamic, partial centralization
                                                          more than  k dimensions, centralization begins (see
(DPC). Conceptually, DPC is a technique that discovers
                                                          Section 3.1). The node does not compute its UTIL
difﬁcult portions of a shared problem through trial and error
                                                          message, but sends to its parent a Relation message that
and centralizes these sub-problems into a mediating agent
                                                          contains the set of relations (arity at most k) that the
in order to take advantage of a fast, centralized solver.
                                                          node would have used as an input for computing the
Overall, the protocol exhibits an early, very parallel hill
                                                          UTIL message. It annotates this message with its ID.
climbing behavior which progressively transitions into a more
deliberate, controlled search for an optimal solution. In the 3. Upon receiving such a Relation message, a node tests
limit, depending on the difﬁculty of the problem and the  to see if its separator is smaller than k. The separator
tightness of the interdependences between the variables, one is determined as the intersection between the nodes on
or more agents may end up centralizing the entire problem in the root path of the current node and the set of nodes
order to guarantee that an optimal solution has been found. encountered as dimensions in the messages received
                                                          from its children.
  1Hard constraints (that explicitly forbid/enforce certain value
combinations) can be simulated with soft constraints by assigning • If this is the case, the node becomes a cluster
−∞  to disallowed tuples, and 0 to allowed tuples. Maximizing root, reconstructs the subproblem from  the
utility thus avoids assigning such value combinations to variables. incoming Relation messages and then solves it

                                                IJCAI-07
                                                   168Figure 1: A problem graph (a) and a DFS tree (b). In low-width areas the normal UTIL propagation is performed. In high
                                                                                                       k
width areas (shaded clusters C1, C2 and C3 in (b)) bounded UTIL propagation is used. All messages are of size at most d .
Clusters are centralized and solved in the cluster roots (the bold nodes X2,X9,X14).

        (see Section 3.1). Then it continues the UTIL The resulting set of relations is then packaged as a Relation
        propagation as in DPOP.                       message, annotated with the node’s ID, and sent to the parent
        Later on, during the VALUE phase, when the    (see Section 3.1). This happens as follows:
        node receives the VALUE message from its parent, 1. node Xi receives all UTIL/Relation messages from its
        it retrieves the solution from its local cache and children, if any
        informs nodes in the cluster of their optimal values
                                                          X                    U
        via VALUE messages.                             2.  i forms the  union   i of all relations in the
      • Otherwise, it cannot become cluster root and has to UTIL/Relation messages and the relations it has with its
        pass on to its parent all the relevant relations (the parent and pseudoparents
        ones received from its children and its own), that it 3. Xi matches pairs of relations in Ui s.t. by joining them
        would otherwise use to compute its UTIL message.  the resulting relation will have k dimensions or less (the
        For details, see Section 3.1.                     dimensionality of the resulting relation is the union of
                                                          the dimensions of the inputs). If the join was successful,
PC-DPOP - Centralization
                                                          remove both inputs from Ui, and add the result instead.
This process occurs in high-width areas of the problem (e.g. Try until no more joins are possible between relations in
the shaded areas in Figure 1). It is initiated by any node
                                                          Ui. This process is linear in the size of Ui.
that cannot compute and send its UTIL messages because
that would exceed the dimensionality limit imposed by k. 4. The resulting Ui setissenttoXi’s parent in a Relation
Any such node produces the union of the relations and UTIL message
messages received from children, and its own relations with This process proceeds bottom-up until a node Xr with a
its parent/pseudoparents. All these relations can be sent to separator smaller than k is reached. Xr declares itself a
its parent in a Relation message, annotated by appending the cluster root and executes the procedures from Section 3.1.
node’s ID to the path.                                  The result of this phase is that minimal, difﬁcult (high-
                                               k
  On one hand, this ensures the dimensionality limit is width) areas of the problem are identiﬁed in a distributed
                                       k
observed, as no relation with arity larger than is produced fashion. In these areas the algorithm reverts to partial
or sent over the network. On the other hand, it will allow centralization, by having nodes send to their parents not high
the cluster root to reconstruct the subproblem that has to dimensional UTIL messages, but lower arity inputs that could
be centralized, and enable the use of structure sensitive be used to generate those UTIL messages.
algorithms like DPOP, AOBB, etc.
  Alternatively, to save bandwidth, avoid overload on cluster Subproblem reconstruction
root nodes, and also improve privacy, a node can selectively Let us assume a cluster root node Xi has received a set of

join subsets of these relations/UTIL messages, s.t. the relations RCi from its children. Each relation ri ∈ RCi has a
dimensionality of each of the resulting relations is less than k. set of variables that it involves (scope(ri)), and the path that

                                                IJCAI-07
                                                   169it traveled through until it reached Xi. Xi creates an internal • the cluster root sends its UTIL message to its parent, and
copy of all the nodes found in the scopes of the relations the process continues just like in normal DPOP.
received. Then, Xi reconstructs the subtree by placing each
                                                        There  are  multiple possibilities for choosing an
internal variable Xk in its position as follows:
                                                      optimization algorithm for solving subproblems:   a
  • if Xk is an ancestor of Xi, then it is identiﬁed as such, centralized version of DPOP [Petcu and Faltings, 2005],
    because Xi knows the path from root to itself.    AOBB  [Marinescu and Dechter, 2005],etc.

  • if Xk is a child of Xi, then it is identiﬁed as such.
                                                      Algorithm 1: PC-DPOP - partial centralization DPOP.
  • otherwise, it is a descendant of Xi. In this case Xi
                                                        PC-DPOP(X   , D, R,k): each agent Xi does:
    deduces its place in the subtree by analyzing backwards
    the path recorded in the relations involving Xk.For UTIL  propagation protocol
                                  0   11     8
    example, in Figure 1, X9 receives r12, r12 and r12,all 1 wait for UT IL/Relation messages from all children
                                                                                         Pi
    annotated with the path X12 − X11 − X10 − X9. X10 is 2 if Sepi ≤ k (can send outgoing UTILi ) then
    already a child of X9, so it is then easy to see that X11 3 if incoming are all UTIL (normal DPOP node) then
      X             X     X                                                 Pi
    is  10’s child and 12 is 11’s child. Thus, the whole       compute UTILi  as in DPOP and send it to Pi
    branch X9 − X10 − X11 − X12 is reconstructed.
                                                       4   else (this means Xi is the root of a cluster)
  It is interesting to note that this technique allows for 5 reconstruct subproblem from received relations
identifying different branches as well. Consider again X9 6 solve subproblem for each s ∈Sepi and store
               9   10     11
              r   r      r                                               Pi
that also receives 13, 13 and 13 , all annotated with the path utility in UTILi and solution in local cache
X13 − X11 − X10 − X9. Following the same reasoning as                Pi
                                                       7   send UTILi   to Pi
before, X9 can infer that X13 is also a child of X11, like X12.
                                                                      X
Therefore, X12 and X13 lie in different branches.      8 else (this means i is part of a cluster)
  This makes it possible for a cluster node to reconstruct 9 Join subsets of incoming UTIL/Relation and relations
the subproblem while preserving structural information.This with (p)parent with same dimension s.t. for each join,
                                                        dim(join) ≤ k
is important because it enables the use of high-performance
                                                                   P
optimization algorithms that also take advantage of problem 10 send joins to i
                                                                                            ∗
structure. Examples include AOBB [Marinescu and Dechter, VALUE propagation(Xi gets Sepi ← Sepi from Pi)
2005], a centralized DPOP [Petcu and Faltings, 2005],etc. 11 if Xi is cluster root then
                                                                          ∗                    ∗
                                                      12   ﬁnd in cache Sol that corresponds to Sepi
Solving centralized subproblems                                                    ∗
                                                      13   assign self according to Sol
                                                                   ∗
The centralized solving occurs in the roots of the clusters 14 send Sol to nodes in my cluster via VALUE msgs
determined by the high-width areas. In the example of
                                                      15 else continue VALUE phase as in DPOP
Figure 1, such a cluster is the shaded area containing
X9,X10,X11,X12,X13.
  The root of the cluster (e.g. X9) maintains a cache table
that has as many locations as there are possible assignments 3.2 PC-DPOP - VALUE Phase
                           dk  =  d2
for its separator (in this case      locations). As   The labeling phase has determined the areas where bounded
a normal node in DPOP, the root also creates a table for inference must be applied due to excessive width. We will
the outgoing UTIL message, with as many dimensions as describe in the following the processing to be done in these
the size of the separator. Each location in the cache table areas; outside of these, the original VALUE propagation from
directly corresponds to a location in the UTIL message that DPOP applies.
is associated with a certain instantiation of the separator. The
                                                        The VALUE message that the root Xi of a cluster receives
cache table stores the best assignments of the variables in the
                                                      from its parent contains the optimal assignment of all the
centralized subproblem that correspond to each instantiation
                                                      variables in the separator Sepi of Xi (and its cluster). Then
of the separator.
                                                      Xi  can simply retrieve from its cache table the optimal
  Then the process proceeds as follows:               assignment corresponding to this particular instantiation of
  • for each instantiation of Sepi, the cluster root solves the the separator. This assignment contains its own value, and
    corresponding centralized subproblem. The resulting the values of all the nodes in the cluster. Xi can thus inform
    utility and optimal solution are stored in the location all the nodes in the cluster what their optimal values are (via
    of the UTIL message (cache table location, respectively) VALUE messages). Subsequently, the VALUE propagation
    that correspond to this instantiation.            proceeds as in DPOP.
  •         Sep
    when all   i instantiations have been tried, the UTIL 3.3 PC-DPOP - Complexity
    message for the parent contains the optimal utilities for
    each instantiation of the separator (exactly as in DPOP), In low-width areas of the problem, PC-DPOP behaves exactly
    and the cache table contains the corresponding solutions as DPOP: it generates a linear number of messages that are
    of the centralized subproblem that yield these optimal at most dk in size. In areas where the width exceeds k,the
    utilities.                                        clusters are formed.

                                                IJCAI-07
                                                   170          PC   −  DPOP(k)
Theorem 1                    requires communication              (a) maximal size of a centralized problem vs. total problem size
O(exp(k)                               O(exp(k))            12
        . Memory requirements vary from          to              PC-DPOP(2)
                                                                 PC-DPOP(3)
O(exp(w)) depending on the algorithm chosen for solving     11   PC-DPOP(4)
                                                             PC-DPOP(5)=DPOP
                     w                                              OptAPO
centralized subproblems ( is the width of the graph).       10

PROOF. Section 3.1 shows that whenever the separator of a   9
               k
node is larger than , that node is included in a cluster. It also  8
shows that within a cluster, UTIL messages with more than
                                                            7
k dimensions are never computed or stored, but their input
components sent out instead. It can be shown recursively that  6
these components have always less than k dimensions, which  5
                                                         Centralization  (max subproblem size in #vars)
proves the ﬁrst part of the claim.                          4
                                                              9     9.5    10    10.5   11    11.5   12
  Assuming that w>k, memory requirements are at least                     Number of variables (agents)
O(exp(k)).  This can easily be seen in the roots of the         (b) how many agents centralize subproblems vs. total problem size
                                                            12
clusters: they have to store the UTIL messages and the cache     PC-DPOP(2)
                                                            11   PC-DPOP(3)
                     O(exp(Sep = k))                             PC-DPOP(4)
tables, both of which are           .                        PC-DPOP(5)=DPOP
  Within a cluster root, the least memory expensive         10      OptAPO
algorithm would be a search algorithm (e.g. AOBB(1)) that   9
                                                            8
uses linear memory. The exponential size of the cache table
                                                            7
and UTIL message dominates this, so memory overall is
O(exp(k))                                                   6
         .                                                  5

  The most memory intensive option would be to use a        4


centralized version of DPOP, that is proved to be exponential #  of agents which centralize subproblems  3

in the induced width of the subtree induced by the cluster.  2
                                                              9     9.5    10    10.5   11    11.5   12
Overall, this means memory is exponential in the maximal                  Number of variables (agents)
width of any cluster, which is the overall induced width.
                                                2     Figure 2: Graph coloring: Centralization. (a) In OptAPO
                                                      there is always an agent which centralizes all the problem.
                                                      (b) In OptAPO all agents centralize some subproblem.
4  Experimental evaluation

                                                                 (b) how many agents centralize subproblems vs. total problem size
We performed experiments on 3 different problem domains:    10000
                                            2                      PC-DPOP(2)
distributed sensor networks (DSN), graph coloring (GC),            PC-DPOP(3)
                                                                   PC-DPOP(4)
and meeting scheduling (MS). Our versions of OptAPO and         PC-DPOP(5)=DPOP
                                                                      OptAPO
PC-DPOP used different centralized solvers, so in the interest
of fairness, we did not compare their runtimes. Instead, we  1000
compared the effectiveness of the centralization protocols
themselves, using 2 metrics: communication required (see
Figure 3), and amount of centralization (see Figure 2).      100
Figures 2 and 3 present the results on the GC problems.  #  of messages (log scale)
  The bound k has to be at least as large as the maximal
arity of the constraints in the problem; since these problems  10
                                                                9    9.5    10    10.5   11   11.5   12
contain only binary constraints, we ran PC-DPOP(k) with k                  Number of variables (agents)
between 2 and the width of the problem. As expected, the         (b) how many agents centralize subproblems vs. total problem size
                                                             1e+06
larger the bound k, the less centralization occurs. However,        PC-DPOP(2)
                                                                    PC-DPOP(3)
                                                                    PC-DPOP(4)
message size and memory requirements increase.                  PC-DPOP(5)=DPOP
                                                                      OptAPO
  DSN  The DSN instances are very sparse, and the induced   100000
width is 2, so PC − DPOP(k ≥ 2) always runs as DPOP:
no centralization, message size is d2 =25. In contrast,
                                                             10000
in OptAPO almost all agents centralize some part of the
problem. Additionally, in the larger instances some agents
centralize up to half the problem.                           1000

  Meeting scheduling we generated a set of relatively large Total  message size in bytes (log scale)

distributed meeting scheduling problems. The model is as      100
                                                                9     9.5   10    10.5   11    11.5  12
in [Maheswaran et al., 2004]. Brieﬂy, an optimal schedule                  Number of variables (agents)
has to be found for a set of meetings between a set of agents.
The problems were large: 10 to 100 agents, and 5 to 60 Figure 3: Graph coloring: message exchange. (a) All PC-
meetings, yielding large problems with 16 to 196 variables. DPOP variants use a linear # of messages. ; (b) Total
                                                      information exchange (bytes) is much lower for PC-DPOPs.
  2DSN and GC instances taken from [Maheswaran et al., 2004].

                                                IJCAI-07
                                                   171