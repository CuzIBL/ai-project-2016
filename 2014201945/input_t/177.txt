   Comparing Best-First Search and Dynamic Programming for Optimal Multiple 
                                              Sequence Alignment 

                               Heath Hohwald, Ignacio Thayer, Richard E. Korf 
                                           Computer Science Department 
                                       University of California, Los Angeles 
                                               Los Angeles, CA 90095 
                                        Email: {heath,iet,korf}@cs.ucla.edu 

                        Abstract                               the methodology used in comparing the two approaches, and 
                                                               present our results. Future work is discussed in Section 7, and 
     Sequence alignment is an important problem in 
                                                               we conclude in Section 8. 
     computational biology. We compare two different 
     approaches to the problem of optimally aligning 
     two or more character strings: bounded dynamic 
     programming (BDP), and divide-and-conquer fron•           2 Sequence Alignment and The Grid Problem 
     tier search (DCFS). The approaches are compared 
     in terms of time and space requirements in 2              2.1 Pairwise sequence alignment and cost function 
     through 5 dimensions with sequences of varying 
     similarity and length. While BDP performs better          Two sequences are aligned by inserting gaps into each of the 
     in two and three dimensions, it consumes more time        sequences so that each character in one sequence corresponds 
     and memory than DCFS for higher-dimensional               to a character or gap in the other. Each pair of corresponding 
     problems.                                                 symbols (gaps or characters) in the sequences can be charac•
                                                               terized as a match (two identical characters), substitution (two 
1 Introduction and Overview                                    different characters), or gap (gap in one sequence but not the 
                                                               other). For example, given the sequences ACGTACGTACGT 
Aligning multiple DNA or protein sequences, known as           and ATGTCGTCACGT, one alignment is as follows: 
sequence alignment, is an important problem in computa•
tional biology. Sequence alignment is useful for compar•
                                                               ACGTACGT-ACGT 
ing genomes and finding genes, for determining evolution•
                                                               ATGT-CGTCACGT 
ary linkage of different biological sequences, and for predict•
ing protein sequence secondary and tertiary structure [Durbin  The cost of an alignment is calculated by assigning a cost to 
et al, 1998], [Waterman, 1995]. We consider two algo•          each position of the two sequences, and then summing the 
rithms for finding an optimal alignment of two or more se•     costs over all positions. For example, a cost function might 
quences: bounded dynamic programming (BDP), and divide-        charge 0 units for matching characters, 1 unit for a substitu•
and-conquer frontier search (DCFS), a best-first search algo•  tion, and 2 units for a gap. If this cost function is applied to 
rithm.                                                         the alignment above, the result is a total cost of 5, since we 
   Dynamic programming (DP) is the traditional approach for    have two gaps (marked by a '-'), and one substitution (T for 
solving sequence alignment problems. DCFS is a more re•        C in the second position). An optimal alignment is one that 
cent approach, and the two methods have been compared for      minimizes a given cost function. For these sequences and this 
the problem of aligning two and three sequences [Korf and      cost function, this alignment is optimal. 
Zhang, 2000]. We extend this work by comparing the two 
algorithms for simultaneously aligning larger numbers of se•
quences, and find that DCFS is both faster and can solve       2.2 Multiple sequence alignment and cost function 
larger problems, suggesting that the more traditional DP ap•
proach is not the best choice for aligning more than three se• The problem of optimally aligning multiple sequences is a 
quences.                                                       natural extension of pairwise alignment: insert gaps in the 
   We begin by introducing to the multiple sequence align•     sequences such that a given cost function is minimized. For 
ment problem, and show how it can be mapped to the prob•       multiple alignments, we use the sum-of-pairs (SP) cost func•
lem of finding a lowest-cost corner-to-corner path in a d-     tion, i.e. the cost of an alignment of multiple sequences is the 
dimensional grid. We describe the dynamic programming          sum of the cost of all induced pairwise alignments. The cost 
approach in Section 3, and the DCFS algorithm in Section       of each position is still determined by a given cost function 
4. We discuss the heuristic evaluation functions we use for    such as that described in the previous section. As an exam•
sequence alignment in Section 5. In Section 6, we explain      ple, consider the following alignment of three sequences: 


SEARCH                                                                                                              1239  1) AGTTA-                                                    3 Dynamic Programming 
 2) AGCT-G 
                                                              3.1 Standard dynamic programming 
 3) -GACAG 
                                                              Dynamic programming (DP) is a general technique that can 
 Using the same cost function above, the cost of this align•
                                                              be used to find a lowest-cost path in a directed grid. Note 
 ment is 17, obtained by summing the costs of the pairwise    that any optimal path passing through a node n must include 
 alignments of sequences [1,2] (5), [1,3] (6), and [2,3] (6). an optimal path passing through one of its predecessors. To 
                                                              determine the lowest-cost path to a node n, we do not need to 
 2.3 The grid problem                                         consider all possible paths to the node; rather, we only need to 
                                                              know the costs to reach each of n's immediate predecessors. 
 The sequence alignment problem can be mapped to the prob•       This observation yields an efficient algorithm for search•
 lem of finding a lowest-cost corner-to-corner path in a di•  ing a directed grid, which we describe for the case of an x x y 
 rected grid, where each dimension corresponds to one of the  grid. We scan the grid from left to right and from the top to 
 sequences [Needleman and Wunsch, 1970]. We associate a       the bottom, and at each node n we store the cost of a lowest-
 cost with each edge in the grid, and the cost of an alignment cost path from the start node to n. This cost is the minimum 
 is the sum of the edge costs along the corresponding path.   obtained by adding the cost of the edge from the left to the 
 In the directed-grid problem, we are only allowed to move    cost of the node to the left, the cost of the edge from above 
 toward the goal, either orthogonally or diagonally.          to the cost of the node above, and the cost of the edge from 
   In two dimensions, the directed-grid problem is to find the diagonally above and left to the cost of the node diagonally 
 lowest-cost path in an x x y grid, where x and y are the lengths above and to the left. When we reach the goal node, we have 
 of the two strings. The path goes from the upper-lefthand cor• the cost of an optimal path and can trace back through the 
 ner to the lower-righthand corner, and the legal moves are to grid to find the associated path. DP has both 0(x x y) time 
 the right, down, or diagonally right and down. For exam•     and space complexity, since we store costs for all nodes and 
ple, for the two sequences in Subsection 2.1, the correspond• compute the cost at each node in constant time. DP can be 
 ing grid and the optimal solution path are shown in Figure 1. generalized to k dimensions, where the time and space com•
The horizontal move corresponds to the gap in the vertical se• plexity is 0(lk) for a hypercube with length /. 
quence, while the vertical move corresponds to the gap in the 
horizontal sequence. Diagonal moves correspond to matches     3.2 Hirschberg's divide-and-conquer method 
or substitutions. 
                                                              Using a divide-and-conquer approach proposed 
   In three dimensions, we have a three-dimensional grid of   by [Hirschberg, 1975], the space complexity of DP is 
size x x y x z and can move in one of seven directions from   reduced from This reduction allows much 
each node in the grid: to the right (along the x axis), down 
                                                              larger problems to be solved. Hirschbcrg's method is best 
(along the y axis), back (along the z axis), right and down, 
                                                              illustrated in the two-dimensional grid problem. We find 
right and back, down and back, and finally right, down, and 
                                                              a node n in the middle row of the grid that is guaranteed 
back. In general, the k-dimensional directed-grid problem 
                                                              to be on an optimal path and then recursively solve two 
seeks a lowest-cost path in a k-dimensional grid, with 2  — 
                                                      k       subproblems: finding an optimal path from the start node 
 1 possible moves from each node. Aligning k sequences of 
                                                              to n, and finding an optimal path from n to the goal node. 
length / requires a grid of size l . 
                              k                               In order to find such a node n, we first calculate the costs 
                                                              from left to right in each row from the top to the middle 
                                                              row, and then calculate costs from the right to left in each 
                                                              row from the bottom to the middle row. When we have 
                                                              forward and backward costs to reach the middle row, we 
                                                              add the corresponding entries for each node and take the 
                                                              node of minimum total cost to be node n, a node on the 
                                                              optimal corner-to-corner path. Storing these costs requires 
                                                              two rows in memory: one for the top-down computation 
                                                              and one for the bottom-up computation, thus reducing the 
                                                              space requirement from The same idea can be 
                                                              applied in k dimensions, reducing the space complexity from 

                                                              3.3 Eppstein's divide-and-conquer method 
                                                              While Hirschberg's algorithm is bidirectional, he also men•
Figure 1: Optimal alignment of the two sequences from Sub-    tioned a unidirectional version of the algorithm that he at•
section 2.1. The solid line represents the solution path, and tributed to Eppstein [Hirschberg, 1997], hereafter called Epp•
the dashed line represents a substitution.                    stein's divide-and-conquer method. The algorithm is best ex•
                                                              plained in two dimensions. Instead of maintaining two rows 
                                                              of costs, one for each direction of search, we proceed row by 


1240                                                                                                           SEARCH row from the start row to goal row and maintain only a sin•    this would represent a perfect bound (PB). Using this opti•
gle row of costs. After we pass the middle row, we maintain    mal bound with BDP is the best case scenario in terms of 
with each node a pointer back to its ancestor on the middle    performance and does not depend on any particular iterative 
row along a lowest-cost path from the initial node. When we    deepening scheme. We refer to this scenario as BDP-PB, and 
reach the goal state, we have a pointer to a node on the mid•  use this algorithm below when comparing performance with 
dle row that is on a lowest-cost corner-to-corner path. As in  DCFS. 
Hirschberg's method, we then have two smaller path-finding 
problems that we solve recursively. This algorithm also has    3.6 Disadvantages of dynamic programming 
         space complexity. 
                                                               While BDP-1UB is easy to implement in two dimensions, ex•
                                                               tending it to three or more dimensions is much more diffi•
3.4 Bounded dynamic programming 
                                                               cult. Other researchers have also noted this difficulty [Zhang, 
One limitation of both these algorithms is that they evalu•    2002]. While we were able to implement a BDP-1UB algo•
ate every node in the grid. Bounded dynamic programming        rithm written explicitly for three dimensions, we were not 
(BDP) is an extension of DP that introduces an upper bound     able to extend the implementation to four or more dimen•
on the solution cost. It was presented by [Spouge, 1989]       sions using the same approach. In higher dimensions, we 
as a method of finding optimal lattice paths. Given an up•     used a generalized implementation that explicitly checks for 
per bound on the total solution cost, we can prune nodes of    legal operators at each node. This introduces a constant fac•
equal or greater cost since they cannot lie on a solution path of tor to the time complexity of DP since processing each node 
lower cost. For each node n we compute where takes longer than it would in an implementation tailored to a 
g(n) is the cost to reach n from the initial node, and         specific dimension. 
is a lower bound on the cost of reaching the goal node from      Another drawback of DP is that it can be used to find 
node n. If this sum is equals or exceeds the upper bound, we   lowest-cost paths in directed grids, but not in more general 
know that n does not lie on a lower-cost solution path. When   grids where we allow moves in all directions. The reason is 
aligning sequences of equal length, an initial upper bound can that dynamic programming must know a priori which nodes 
be computed by directly aligning the sequences without any     are the parents of a given node. For the general shortest-
gaps.                                                          path problem, we must use a best-first search algorithm, such 
                                                               DCFS, which is a generalization of Eppstein's algorithm. 
3.5 Iterative upper bounds 
In general, a better upper bound on the solution cost will     4 Divide-and-Conquer Frontier Search 
prune more nodes. An initial bound obtained from directly 
aligning the sequences is usually much greater than the true   Divide-and-conquer frontier Search (DCFS) is a recent gen•
cost. A better approach is to use iterative deepening [Korf,   eral heuristic search algorithm [Korf, 1999]. Best-first-search 
 1985]. Starting with an upper bound that is less than the     algorithms, such as Dijkstra's algorithm [Dijkstra, 1959] or 
optimal solution cost, the algorithm will fail to reach the    A* [Hart et al, 1968], normally store both a Closed list of 
goal node by pruning too many nodes. The bound is then         nodes which have been expanded, and an Open list of nodes 
iteratively increased, and search repeated, until the goal is  which have been generated but not yet expanded. DCFS 
reached. This strategy has been applied to bounded dynamic     stores only the Open list, which corresponds to the frontier 
programming by [Ukkonen, 1985].                                of the searched area. The size of the Closed list is often much 
   Normally, the upper bound is increased to the lowest cost   larger than the size of the Open list, and DCFS reduces the 
among all nodes pruned in the current iteration. We can do     space requirement of aligning k strings of length / from 0{lh) 
better by quickly running a few shallow searches with bounds   to (){lk'x) [Korf, 1999]. 
likely to be below the optimal solution cost. By regressing the  Since DCFS does not store the Closed list, it is necessary 
depths reached on the bounds used, we can estimate the solu•   to prevent the generation of nodes that have already been ex•
tion cost, since we know the depth of the goal node. We use    panded. To do this, every node stores a list of operators to 
this predicted bound as the starting point for traditional itera• its neighbors. When a node n is expanded, the operator from 
tive deepening, thus eliminating many iterations with bounds   each neighbor n' back to n is marked as used. Therefore, 
that are too low. This method of using BDP with iterative      when n' is expanded, used operators are not applied, and n is 
upper bounds is referred to as BDP-1UB [Korf and Zhang,        not regenerated. 
2000]. The principle of iterative upper bounds can be applied    Unlike standard best-first search, when DCFS reaches the 
in conjunction with either Hirschberg's or Eppstein's algo•    goal node, it cannot retrace pointers to discover the solution 
rithm, but in practice, Eppstein's algorithm is faster and is  path, since the Closed list is not saved. Alternatively, stor•
used in the results that follow.                               ing a path with each Open node would require space linear in 
   When using iterative deepening, no iterations of the algo•  the path length for each node. In order to recover the solu•
rithm that use an upper bound less than the optimal solution   tion path, before starting the search, a hyperplane is chosen 
cost can reach the goal. On the other hand, using an up•       that divides the search space in half. Every node n on the 
per bound greater than the optimal solution cost examines      Open list beyond this hyperplane stores a pointer to the node 
more nodes than necessary. Usually we don't know the so•       in the hyperplane that is on the optimal path to n. In two di•
lution cost in advance, and have no choice but to use iterative mensions, this hyperplane is simply a row or column halfway 
deepening. However, if we knew the optimal solution cost,      along one of the dimensions. We choose the hyperplane to 


SEARCH                                                                                                              1241  split the longest dimension of the space. When the algorithm 
 encounters the goal node, it has a pointer to a node on the 
 middle plane that is on the optimal solution path. The algo•
 rithm then recurses to find an optimal path from the start node 
to the optimal middle node, and also from the middle node to 
 the goal node. 
   DCFS is a general heuristic search algorithm. We use 
 divide-and-conquer frontier A* search (DCFA*) with the cost 
 function where g(n) is the cost of a path 
 from the start node to node n, and h(n) is a heuristic estimate 
of reaching the goal from node n. 

5 Heuristic Evaluation Functions 

An accurate heuristic evaluation function is important to limit Figure 2: The five ways to partition the edges of a complete 
the number of nodes visited during search. In two dimen•
                                                               graph of four nodes, only four of which include a triangle. 
sions, we use the distance of a node from the corner-to-corner 
diagonal times the gap cost as a heuristic, since any solu•
tion path must return to the diagonal in order to arrive at the 
goal node. In general, the heuristic cost of a node at is a more accurate heuristic function, resulting in fewer nodes 
                    times the gap cost, where are the          visited during the search. 
coordinates of the goal node. 
                                                                 To guarantee that the heuristic be a lower bound, we cannot 
   In three dimensions, we can compute a better lower bound.   include the cost of aligning the same pair of sequences more 
Since we are using the sum-of-pairs cost function, we can      than once. For example, the cost of a pair of sequences that 
use the sum of the optimal pairwise alignments as a lower-     are part of a three-way alignment cannot be included in an•
bound heuristic. Obviously, the cost of an optimal pairwise    other three-way alignment, or as a pairwise alignment. Con•
alignment is always less than or equal to the cost of any other sider a complete graph with a node for each sequence, and 
alignment of the two strings as part of a multiple alignment.  an edge between every pair of nodes, representing that pair 
For example, an optimal alignment of three sequences is:       of sequences. In this graph a triangle represents a three-way 
                                                               alignment. We need to partition the edges of this graph into 
                                                               groups of single edges and triangles, without including any 
                                                               edge in more than one group, ideally in a way that maximizes 
                                                               the resulting heuristic value. 
The cost of this alignment is 44, since the costs of the align•
ment shown for the pairs [1,2], [1,3], [2,3] are 18, 13, and 13  For example, we can partition the edges of a complete 
respectively. The heuristic estimate for the cost of aligning  graph of four nodes (K4) into six single edges, or one tri•
these strings is only 43, however, since the optimal pairwise  angle and three single edges. In general, we want to include 
alignment of the pair [1,2] is only 17, as shown below.        as many three-way alignments as possible, in order to make 
                                                               the heuristic function more accurate. There are four different 
                                                               ways to partition the edges of K4 into one triplet and three 
                                                               pairs (see Figure 2). For the complete graph on five nodes, 
   The heuristic evaluation of a particular node in the grid is K5, there are 15 different ways to partition the nodes into 
a lower bound on the lowest-cost path from that node to the    two triplets and four pairs. One way of selecting which par•
goal. This corresponds to the alignment of the sequence suf•   titioning to use is to evaluate all of them and choose the one 
fixes that correspond to that node. For a three-dimensional    which gives the largest heuristic evaluation for the original se•
alignment, we precompute and store three two-dimensional       quences. The hope is that a larger heuristic evaluation of the 
matrices, one for each pair of strings. Each entry of each ma• start node is an indicator of larger heuristic values through•
trix contains the cost of optimally aligning the correspond•   out the search. We found that evaluating all possible parti•
ing remaining suffixes of the pair of strings. To compute the  tions, instead of randomly choosing one, used more time than 
overall heuristic for any node in the cube, we sum the corre•  it saved and did not yield significant savings. 
sponding elements from each of the three matrices.               We represent the three-dimensional heuristics with an oc•
   In the general case of aligning k sequences using the sum-  tree, which stores only certain parts of a cube, along with 
of-pairs cost, the alignment of any d sequences induced by     enough information to generate the other parts of the cube if 
the multiple alignment will cost at least as much as the op•   needed. [McNaughton et al., 2002] Computing parts of this 
timal alignment of those d sequences. Therefore in four or     octree on demand saves a significant amount of space. We 
more dimensions we can also include optimal alignments of      found that storing three-dimensional heuristics in an octree 
three sequences in the heuristic. While the three-dimensional  leads to an overall savings on hard problems because the time 
alignments are more expensive to compute and occupy more       used to calculate the heuristics is offset by time saved during 
space than two-dimensional alignments, including them gives    the search. 


1242                                                                                                            SEARCH              Time (s) Nodes Time (s) Nodes Time (s) Nodes Time (s) Nodes Time (s) Nodes 
  BDP-PB       59.82 77,653         59.83 77,690        60.06 220,262        78.12 21,109,562         89.79 34,838,768 
  DCFA*          0.06 5,601          0.07 5,601          0.27 32,971         38.20 762,740 57.90 1,286,730 

Table 1: Average results over 50 generated problems of generalized versions of the two algorithms on 4 dimensional problems, 
length 400. The table displays average time in seconds, the average number of nodes expanded for DCFA*, and the average 
number of nodes visited for BDP-PB. 

                      = 1                = 0.75                                   = 0.25                  = 0 
              Time (s) Nodes Time (s) Nodes Time (s) Nodes Time (s) Nodes Time (s) Nodes 
   BDP-PB        15.41 33,896         15.39 33,896        15.33 39,199        16.08 351,878         17.61 1,009,293 
   DCFA*          0.02 2,701           0.02 2,701          0.02 5,246          0.78 97,408           1.46 110,742 

Table 2: Average results over 50 generated problems of the generalized versions of the two algorithms on 5 dimensional 
problems, length 90. The table displays average time in seconds, the average number of nodes expanded for DCFA*, and the 
average number of nodes visited for BDP-PB. 

6 Comparison of the Approaches                                dimensional heuristics. We ran the algorithms using both 
6.1 Methodology                                               heuristics and reported the faster of the two times. 
We compared divide-and-conquer frontier A* (DCFA*) and        6.2 Experimental results 
bounded dynamic programming with perfect bounds (BDP-
PB) on problems of aligning 2, 3, 4 and 5 sequences. Our      Our previous work [Korf and Zhang, 2000] showed that DP 
goal was to determine which algorithm could solve harder      outperforms DCFA* in two and three dimensions, with ran•
problems within our space limits. The difficulty of a problem dom strings. Our new results corroborate these findings; 
is determined by the number, length, and similarity of the    in two dimensions, BDP-1UB aligns completely random se•
sequences. We ran the tests on a 1.8 Ghz Intel Pentium 4      quences much faster than DCFA*. For example, for length 
with 1 GB of RAM, 8 KB LI cache, and 512 KB L2 cache.         20,000 it is an average of almost 50 times faster. In three di•
For DCFA*, we always used a fixed-size hash table of 16       mensions, the disparity is somewhat smaller, with DP align•
million nodes which occupies 512 MB of memory. We tested      ing completely random sequences of length 5,500 an average 
both algorithms on both randomly-generated sequences and      of about 18 times faster. DCFA* exceeds our one hour time 
on real sequences from BAliBASE [Thomson et al, 1999].        limit for larger problems. 
   For the randomly-generated sequences, we varied se•           In four and five dimensions, however, DCFA* was able to 
quence similarity to see how it affected the performance of   solve much larger problems than BDP, due to memory con•
the algorithms. We first generated a reference sequence uni•  straints. DP allocates memory based on problem size. In four 
formly from an alphabet of four letters, simulating DNA se•   dimensions, it was able to align sequences up to length 400, 
quences, and then generated the actual sequences from the     independent of the similarity of the sequences. In contrast, 
reference sequence. Each character in the actual sequences    DCFA* was able to align four completely random sequences 
was generated independently, with a probability of match•     of length 800 in about 17 minutes. 
ing the corresponding character in the reference sequence,       Furthermore, for problems that both algorithms could 
and probability of being randomly generated, including        solve, DCFA* was significantly faster than BDP. In these ex•
the matching character. We varied from 0 1 in incre•          periments we compared DCFA* with BDP-PB, where we use 
ments of 0.25. Problem instances with = 1 are identical se•   the optimal solution cost as our initial upper bound. In a re•
quences, which are easy to align, and were run in order to get alistic setting where this bound is not known a priori, BDP 
an upper bound on solvable problem size. Problem instances    would fare even worse in comparison. The average results of 
with = 0 are the hardest problems, since the sequences are    aligning four sequences of length 400 arc shown in Table 1. 
completely random. We ran both algorithms on 50 problems      As the sequences become more similar, the performance ad•
for each similarity, dimension, and length, and averaged the  vantage of DCFA* increases. 
results. We found little variability between different random    In five dimensions, BDP-PB was able to solve problems 
trials of the same experiment.                                of length 90, whereas DCFA* was able to align completely 
   For actual sequences, we used real protein sequences from  random sequences of length 250 in about 5 minutes, and 
the BAliBASE database of benchmark alignments [Thomson        could align some random sequences of length 350. Both algo•

et al.9 1999]. Proteins are represented by strings from an al• rithms are compared on problems of aligning five sequences 
phabet of 20 amino acids. The pairwise cost function we used  of length 90 in Table 2. Comparing both tables, we see the 
charges 0 units for a match, 1 unit for a substitution, and 2 relative performance of BDP-PB on random problems de•
units for a gap. For multiple sequences we used the sum-      creases when moving from four to five sequences. While 
of-pairs cost function. For problems in four and five dimen•  BDP-PB takes about 50% longer than DCFA* to align four 
sions, there is a choice of using two-dimensional or three-   completely random sequences of length 400, it takes about 


SEARCH                                                                                                              1243 