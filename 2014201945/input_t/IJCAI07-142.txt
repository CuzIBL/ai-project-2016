     Exploiting Sensorimotor Coordination for Learning to Recognize Objects                        ∗
           Yohannes Kassahun†, Mark Edgington†, Jose de Gea†         and Frank Kirchner†    
                                            Robotics Group
                                         † University of Bremen
                       German Research Center for Artiﬁcial Intelligence (DFKI)
                           Robert-Hooke-Str. 5, D-28359, Bremen, Germany
                {kassahun, edgimar, jdegea, frank.kirchner}@informatik.uni-bremen.de

                    Abstract                          the real physical connections to the outside world are of only
                                                      sub-critical importance, and are sometimes discarded as mere
    In this paper we present a system which learns to informational encapsulated plug-ins [Fodor, 1983]. Most the-
    recognize objects through interaction by exploit- ories in cognitive psychology take this traditional approach
    ing the principle of sensorimotor coordination. The and have tried to describe the process of human thinking in
    system uses a learning architecture which is com- terms of propositional knowledge. At the same time, artiﬁcial
    posed of reactive and deliberative layers. The re- intelligence research has been dominated by methods of ab-
    active layer consists of a database of behaviors that stract symbolic processing, even when researchers have used
    are modulated to produce a desired behavior. In this robotic systems to implement them [Nilsson, 1984]. Ignoring
    work we have implemented and installed in our ar- sensorimotor inﬂuences on cognitive ability is in sharp con-
    chitecture an object manipulation behavior inspired trast to the research of William James [James, 1890] and oth-
    by the concept that infants learn about their en- ers (see [Prinz, 1987] for a review) that describe theories of
    vironment through manipulation. While manipu-     cognition based on motor acts, or a theory of cognitive func-
    lating objects, both proprioceptive data and exte- tion emerging from seminal research on sensorimotor abili-
    roceptive data are recorded. Both of these types  ties by Jean Piaget [Wilson, 2002] and the theory of affor-
    of data are combined and statistically analyzed in dances by [Gibson, 1977]. In the 1980s the linguist Lakoff
    order to extract important parameters that distinc- and the philosopher Johnson [Lakoff and Johnson, 1980] put
    tively describe the object being manipulated. This forward the idea of abstract concepts based on metaphors
    data is then clustered using the standard k-means for bodily, physical concepts; around the same time, Brooks
    algorithm and the resulting clusters are labeled. [Brooks, 1986] made a major impact on artiﬁcial intelligence
    The labeling is used to train a radial basis function research by his concepts of behavior based robotics, and inter-
    network for classifying the clusters. The perfor- action with the environment without internal representation.
    mance of the system has been tested on a kinemati- This concept provides an alternative to the traditional sense-
    cally complex walking robot capable of manipulat- reason-act cycle, and has gained wide attention ever since.
    ing objects with two legs used as arms, and it has As promising as these ideas seem to be at ﬁrst glance, one
    been found that the trained neural network is able has to carefully evaluate what exact claims can be made and
    to classify objects even when only partial sensory how these can be evaluated. Wilson identiﬁes six viewpoints
    data is available to the system. Our preliminary  for the new so-called embodied cognition approach [Wilson,
    results demonstrate that this method can be effec- 2002]:
    tively used in a robotic system which learns from
                                                        1. Cognition is situated: All Cognitive activity takes part in
    experience about its environment.
                                                          the context of a real world environment.
                                                        2. Cognition is time pressured: How does cognition work
1  Introduction                                           under the pressures of real time interaction with the en-
Recently, the psychological point of view that grants the body vironment
a more signiﬁcant role in cognition has also gained attention 3. Off-loading of cognitive work to the environment: Limits
in spatial cognition theory. Proponents of this approach claim of our information processing capabilities demand for
that we have to deal with and understand a body that needs a off-loading.
mind to make it function instead of a mind that works on ab- 4. The environment is part of the cognitive system: because
stract problems [Wilson, 2002]. These ideas differ quite radi- of dense and continuous information ﬂow between the
cally from the traditional approach that describes a cognitive mind and the environment it is not meaningful to study
process as an abstract information processing task in which just the mind.
  ∗This work is supported by the SFB/TR 8 DFG project, which is 5. Cognition is for action: Cognitive mechanisms (percep-
duly acknowledged.                                        tion/memory, etc.) must be understood in their ultimate

                                                IJCAI-07
                                                   883    contribution to situation appropriate behavior.   that learn through interaction with the environment. The sys-
                                                      tem can be easily extended to use new object-features which
 6. Off-line Cognition is body-based: Even when uncou-
                                                      distinctively describe the relevant characteristics of an object
    pled from the environment, the activity of the mind is
                                                      to be recognized.
    grounded in mechanisms that evolved for interaction
                                                        A work that is closely related to ours involves substrate
    with the environment.
                                                      classiﬁcation on the basis of proprioceptive data [Spenneberg
  We have cited all six viewpoints here, as they represent and Kirchner, 2005]. In this work, a legged robot named
an interesting perspective on the state of the art in embodied SCORPION [Kirchner et al., 2002] interacts with various
cognition. In this work we focus our attention on viewpoints substrates to generate certain substrate speciﬁc sensory feed-
3 and 5, and we use them as a theoretical starting point for back. The results of this experiment show that this method
our work. To experiment with embodied cognition, we pro- of classifying based on proprioceptive data has a promising
pose the use of a multifunctional four legged robot kinemati- potential for use in terrain classiﬁcation of unstructured en-
cally capable of walking and climbing on four legs as well as vironments. One of the important beneﬁts of terrain classiﬁ-
of grasping and manipulating objects with two legs used as cation is that it allows a terrain’s traversability to be assessed
arms. The role of manipulation acts in understanding spatial given a speciﬁc robot body.
geometries and objects goes back to the idea that cognitive This paper is organized as follows: ﬁrst, we give a short
systems ofﬂoad as much of the computational burden as pos- overview of the learning architecture which we have used
sible onto the environment to understand spatial structures. to implement object recognition through manipulation. We
Instead of generating and transforming complex mathemati- then explain the manipulation behavior and the recognition
cal models of 3-D geometries, cognitive systems use motor method used. Next, we describe our experimental scenario
acts to generate multi-modal perceptual inputs, which they and the results obtained. Finally, we provide some conclu-
use to test hypotheses about the nature of the geometric struc- sions and a future outlook.
ture at hand.
  A prerequisite for developing higher levels of cognition is 2 Learning Architecture
the process of sensorimotor coordination, in which the body
of the system plays a central role in learning to recognize The architecture we have adopted, shown in Figure 1, is a
objects [Nolﬁ and Parisi, 1999; Pfeifer and Scheier, 1999]. hybrid architecture which integrates a reactive system with a
Many researchers [Edelman, 1987; Beer, 1996; Nolﬁ, 1996; higher-level deliberative system. It is suitable for controlling
Takac, ´ 2006] have shown that sensorimotor coordination can and integrating spatial learning and representation techniques
be exploited in solving categorization problems.      in mobile robots, allowing them to explore and navigate in
  One shortcoming of most existing methods is that they are unknown environments.
able to recognize only a limited number of objects. Addition- 2.1 Reactive System
ally, most existing methods are difﬁcult to extend. A typi-
cal application of such methods is to recognize hypothetical The reactive system includes the INPUT, TRANSFER,
objects, and they are tested only in simulation or on simple ACTIVATION,andMOTOR modules of Figure 1. Proprio-
robotic platforms. Their ability to scale when used on com- ceptive and exteroceptive data produced through interaction
plex robots is neither known nor proven. From our viewpoint, with the environment are processed in the INPUT stage. This
the reasons for the shortcomings of the existing methods are stage consists of three subsystems (see Figure 2) which work
twofold: First, there is no presently ﬁrm theoretical frame- together in order to learn, distinguish and identify the percep-
work for studying correlations within and between sensori- tual states the system is in. In the manipulation based object
motor modalities for object recognition tasks. Very few ap- recognition experiment, an unsupervised classiﬁer system is
proaches apply statistical and information theoretic analyses implemented that considers both proprioceptive and extero-
                                                                                              
to study the sensorimotor coordination of data taken from real ceptive data, represented by the vectors SP and SE, respec-
robots [Lungarella et al., 2005]. Second, kinematically com- tively. This classiﬁer identiﬁes and labels clusters of simi-
plex robots capable of increasing the role of the body in the lar sensorimotor stimuli together. Additionally, it generates
                                                                                
process of learning and recognition are not commonly used. a cluster probability PC,sm(SP , SE). Each element of this
Most of the time wheeled robots with few degrees of freedom vector represents a probability estimate of the likelihood that
or simulated robotic arms are used as test beds.      a set of sensorimotor inputs belongs to a labeled cluster. The
                                                                      
  After the introduction of Brooks’ behavior based robotics cluster probability PC,sm is then used to train the two remain-
and interaction with environment [Brooks, 1986],thereap- ing classiﬁers which classify based only on the exteroceptive
pears to be a growing sense of commitment to the idea that             
                                                      sensory data vector SE or on the proprioceptive data vector
cognitive ability in a system, be it natural or artiﬁcial, has to                             
                                                      SD. These classiﬁers also generate PC estimates, PC,ext and
be studied in the context of its relation to a ’kinematically                         
competent’ physical body. Therefore, in the last years we fo- PC,prop, which are are combined with PC,sm to generate an
                                                                            
cused our research on complex legged robots which possess overall cluster probability PC,input.
a rich repertoire of sensor and motor abilities [Hilljegerdes et This overall cluster probability is mapped in the
al., 2005].                                           TRANSFER   module to a set of motor-program activation lev-
  In this paper we present an extensible embodied object els. The activation levels serve to pre-activate a selected
recognition system that can be used in complex real robots group of motor-programs. Pre-activation consists of setting

                                                IJCAI-07
                                                   884                                    Figure 1: Overall learning architecture

all the parameters (i.e. phase-shift, amplitude, frequency, ing. Positive and negative rewards combined with believed
etc.) of a motor-program, as well as a weight value which behavior information are used to learn the world model and
is used in a further stage to merge multiple motor-programs body model of the robot itself. The deliberative system is
into a resulting behavior [Kirchner et al., 2002]. During the also responsible for optimizing the existing motor-programs
learning phase of the experiment presented here, a manipula- or adding new motor-programs whose resulting behavior
tion motor-program is made active.                    cannot be obtained by combining the existing motor pro-
  The ACTIVATION  stage generates a set of joint angles for grams. Additionally, the deliberative system pre-modulates
each motor-program. At this point, it is possible for the out- the output of the TRANSFER module to affect which motor-
put of the motor-programs to be modulated by other systems. programs will be active, and post-modulates the output of
An automatic reactive control system receives proprioceptive the ACTIVATION module, modifying the properties of the
sensory feedback and modulates the motor-program output in motor-programs that are currently active.
order to realize local-reﬂex behaviors. Additionally, a higher-
level deliberative system is able to inﬂuence a resulting action 3 The Recognition System
by modulating the motor-program output. Finally, the output
from the ACTIVATION  stage is fed into the MOTOR stage, The embodied recognition system functions by manipulating
which implements a believed behavior, attempting to directly objects in order to determine their speciﬁc characteristics. A
                                                      manipulation motor-program has been implemented, added
control the robot’s actuators. We have used the term believed ACTIVATION
behavior to indicate that there is uncertainty as to whether an to the   module, and made active for the ex-
intended behavior has indeed been carried out. Likelihood periment. This motor-program uses a potential ﬁeld method
                                                      [           ]
estimation of a successful behavior execution is made possi- Khatib, 1985 to generate a trajectory for an end-effector
ble by comparing real perceptions with expected perceptions to reach an object. The basic idea is to create a mathemat-
which come from hypotheses about how the robot’s percep- ical description of a virtual potential ﬁeld acting within the
tions should change when a set of motor-programs has suc- workspace of the manipulator. Regions in the workspace that
cessfully been executed.                              are to be avoided are modelled by repulsive potentials (energy
                                                      peaks) and the target region/point is modelled by an attrac-
2.2  Deliberative System                              tive potential (energy valley). The sum of repulsive and at-
                                                      tractive potentials provides a representation of the workspace
The deliberative system is responsible for high-level process- topology. By following the gradient (i.e. the minimum poten-
ing of cluster probabilities, and it is in this system that the tial ﬁeld at each step), a path towards the goal is generated.
world model and body model are generated through learn- One fundamental difference between this method and classi-

                                                IJCAI-07
                                                   885                                    Figure 2: Sensory perception processor

cal path planning is that here ”planning” is not done in the points of the clusters as the centers of basis functions, we
usual sense. Rather, a path is incrementally computed that use the k-means clustering algorithm (in which the number
will end at the target position. This approach can be viewed of centers must be decided in advance) to determine for each
as a reactive approach since there is no deliberation involved cluster a set of centers which more accurately reﬂects the dis-
and it can be implemented on lower layers of control. Further- tribution of the cluster’s data points. The appropriate number
more, this reactiveness allows us to deal with obstacles on a of center points is determined by the performance of the re-
real-time basis, the only limitation being the time needed to sulting network on a validation set. In the implemented neu-
detect and identify objects as obstacles or goals.    ral network, we used a Gaussian function as a basis function.
  While manipulating objects, both proprioceptive data Figure 3 shows the topology of the radial basis function net-
(pressure at ﬁngertips, motor current consumption, motor an- work used for data classiﬁcation.
gular position) and exteroceptive data (color of the object,
number of corners detected on the object, number of line seg-
ments detected, and other distinctive features) are recorded.
Both of these types of data are combined to form a vector
       
X =[SP  , SE]. The resulting vector is statistically analyzed
in order to extract important parameters that distinctively de-
scribe the object being manipulated. For example, the aver-
age power consumption of the motors during the manipula-
tion phase will differ depending on an object’s weight. This
data is then clustered using the standard k-means algorithm
[MacQueen, 1967] and the resulting clusters are labeled.
  Prior to clustering, each element of a data vector is normal-
ized using
                       xi − xi
                   xi =                         (1)
                          σi
where i =1, ···,L and L is the length of a data vector X .
                        2                                      Figure 3: Radial basis function network
The mean xi and variance σi are calculated with respect to
the training data using
                     
                    1   N   n
            xi  =          x
                   N    n=1 i                         4   Experimental Setup
                                      .        (2)
            2        1    N    n     2
           σi   =  N−1    n=1(xi − xi)                The robot used for testing our system was developed in our
                                                      group, and is based on the design of the ARAMIES robot
where N is the number of data vectors in the training set. This [Hilljegerdes et al., 2005]. Our robot is a fully functional
normalization process is necessary since the elements of a ambulating robot that is robust and kinematically ﬂexible. It
data vector typically have magnitudes that differ signiﬁcantly. is equipped with various sensors that enable it to perceive
  The labeled clusters are then used to train a radial basis both proprioceptive and exteroceptive signals. On each of
function network [Bishop, 1995] (a subsystem of the INPUT the robot’s legs, there are 6 D.C. motors, 6 pressure sensors,
module) for classifying the clusters based on proprioceptive and an infrared sensor. For our experiment, the camera of the
and exteroceptive data. Rather than choosing a subset of data robot was used as a source of exteroceptive data, and the av-

                                                IJCAI-07
                                                   886erage motor current consumption of each motor was used as 5 Results
a source of proprioceptive data.                      5.1  Repeatability of Features
                                                      Table 1 shows, for each of the object, the average and stan-
                                                      dard deviation of the number of detected contours Nc,the
                                                      area (number of pixels) of the detected contours Ac,andthe
                                                      total current consumption I (in mA) of both of the robot’s
                                                      forelegs over all training sessions. This data is an indirect
                                                                                                     
                                                       Obj.   Nc      Ac         IσNc        σAc    σ(  I)
                                                         1     1    4812.2   4688.68    0    48.22  217.93
                                                         2     1    4925.77  5242.52    0    61.53  159.14
                                                         3     2    3134.15  4670.66    0    39.5   181.27
                                                         4    6.96   953.1   4916.75   0.21  10.4   319.41

                                                      Table 1: The average and standard deviation of features over
                                                      the whole training set

                                                      measure of the repeatability of a particular feature’s measure-
                                                      ments. A measurement for a feature is repeatable if the vari-
                                                      ance of the measurement over a given sample of measure-
       Figure 4: The robot manipulating an object     ments is small enough that the overlap of measurements re-
                                                      sulting from different objects is minimal. One can easily see
                                                      that the number of contours detected is the most stable fea-
  In the experiment we performed, the robot’s body is ﬁxed ture in this experiment. For getting the number of contours,
and it uses its forelegs to manipulate the different objects we used a detector which is robust against noise and changes
shown in Figure 5. The objects have differing weights and in lighting conditions. The average current consumption of
visual features. Two of the objects have the same visual fea- both legs shows the highest variance in relation to the other
tures, and cannot be distinguished from each other using only features since the end effectors of the forelegs do not grab
visual information; these objects are marked as ”A” and ”B” the object at the same point for each training session. This
in Figure 5. The faces on which the letters are written are causes the object’s center of gravity to shift with respect to
placed away from the camera of the robot so that the two ob- the end effector, and thus a variation in the average current
jects appear indistinguishable to the robot.          consumption is observed.
                                                      5.2  Recognition Rates
                                                      We tested the system’s ability to recognize the objects it was
                                                      trained for. The system was tested in three different scenar-
                                                      ios. In the ﬁrst scenario, the system was permitted to use both
                                                      exteroceptive and proprioceptive data to recognize objects. In
                                                      this case, the recognition rate was the highest, yielding only
                                                      one misclassiﬁcation in 20 trials. In the case where the sys-
                                                      tem was allowed to use only exteroceptive data, there were
                                                      7 misclassiﬁcations in 20 trials. This poorer performance is
                                                      explained by the fact that two of the objects have the same
                                                      visual features. In contrast to these results, when only propri-
                                                      oceptive data was used, there were only 3 misclassiﬁcations
                                                      in 20 trials because the weights of each object were unique.
                                                      An interesting point is that the system was able to correctly
Figure 5: Objects used in the sensorimotor-coordination ex- classify objects ”A” and ”B” in this case, which would have
periment                                              caused problems when using only exteroceptive data.

  In the training session, ﬁve manipulation acts were per- 6 Conclusion and Outlook
formed on each of the objects. For a single manipulation act, An embodied recognition system has been presented which
we took a series of images from which we calculated the av- learns to recognize objects by interacting with them. We have
erage number of contours extracted and the average area of shown that a learning system trained based on multimodal
the extracted contours. Furthermore, we calculated the total sensory information can recognize objects by using only par-
current consumption average for the motors on both of the tially available (i.e. only exteroceptive, or only propriocep-
robot’s forelegs.                                     tive) sensory data. The direct byproduct of such systems is a

                                                IJCAI-07
                                                   887