A Fully Connectionist Model Generator for Covered First-Order Logic Programs

       Sebastian Bader∗    and  Pascal Hitzler†  and Steffen Holldobler¨ ∗ and  Andreas Witzel‡
       ∗ International Center for Computational Logic, Technische Universitat¨ Dresden, Germany
                                † AIFB, Universitat¨ Karlsruhe, Germany
             ‡ Institute for Logic, Language and Computation, Universiteit van Amsterdam


                    Abstract                          necessary preliminaries in Section 2, we make the follow-
                                                      ing novel contributions in Section 3: We deﬁne a new multi-
    We present a fully connectionist system for the   dimensional embedding of semantic operators into the reals,
    learning of ﬁrst-order logic programs and the gen- we construct a feed-forward network to approximate these
    eration of corresponding models: Given a program  operators and we present a new learning method using do-
    and a set of training examples, we embed the asso- main knowledge. The resulting system is evaluated in Sec-
    ciated semantic operator into a feed-forward net- tion 4. Finally, we draw some conclusions and point out what
    work and train the network using the examples.    needs to be done in the future in Section 5. For an overview
    This results in the learning of ﬁrst-order knowledge of related work we refer to [d’Avila Garcez et al., 2002] and
    while damaged or noisy data is handled gracefully. [Bader and Hitzler, 2005].
                                                      2   Preliminaries
1  Motivation
                                                      In this section, some preliminary notions from logic program-
Three long-standing open research problems in connection- ming and connectionist systems are presented, along with the
ism are the questions of how to instantiate the power of Core Method as one approach to integrate both paradigms.
symbolic computation within a fully connectionist system
[Smolensky, 1987], how to represent and reason about struc- 2.1 First-Order Logic Programs
tured objects and structure sensitive processes [Fodor and A logic program over some ﬁrst-order language L is a set of
Pylyshyn, 1988], and how to overcome the propositional ﬁx- clauses of the form A ← L1 ∧···∧Ln, A is an atom in L,
ation [McCarthy, 1988], i.e. how to use connectionist sys- and the Li are literals in L, that is, atoms or negated atoms.
tems for symbolic learning and reasoning beyond proposi- A is called the head of the clause, the Li are called body lit-
tional logic. It has been shown that feed-forward networks are erals, and their conjunction L1 ∧···∧Ln is called the body
universal approximators and that artiﬁcial neural networks are of the clause. If n =0, A is called a fact. A clause is ground
Turing complete. Thus we know that symbolic computation if it does not contain any variables. Local variables are those
is possible in principle, but at the same time the mentioned variables occurring in some body but not in the correspond-
results are mainly theoretical.                       ing head. A logic program is covered if none of the clauses
  Here we are concerned with the model generation for ﬁrst- contain local variables.
order logic programs, i.e. sets of rules which may contain Example 1. The following is a covered logic program which
variables ranging over inﬁnite domains. Our approach is will serve as our running example.
based on the following ideas ﬁrst expressed in [Holldobler¨ et
al., 1999]: Various semantics of logic programs coincide with e(0).    %0iseven
ﬁxed points of associated semantic operators. Given that the e(s(X)) ← o(X). % the successor s(X) of an odd X is even
semantic operator is continuous on the reals, the operator can
                                                      o(X) ←¬e(X).     % X  is odd if it is not even
be approximated arbitrarily well by a feed-forward network.
In addition, if the operator is a contraction, then its ﬁxed point The Herbrand universe UL is the set of all ground terms of
can be computed by a recurrent extension of the feed-forward L, the Herbrand base BL is the set of all ground atoms, which
network.                                              we assume to be inﬁnite – indeed the case of a ﬁnite BL can
  Until now this approach was also purely theoretical for the be reduced to a propositional setting. A ground instance of
ﬁrst-order case. In this paper we show how feed-forward net- a literal or a clause is obtained by replacing all variables by
works approximating the semantic operator of a given ﬁrst- terms from UL. For a logic program P , G(P ) denotes the set
order logic program can be constructed, we show how these of all ground instances of clauses from P .
networks can be trained using input-output examples, and we A level mapping is a function assigning a natural number
demonstrate that the obtained connectionist system is robust |A|≥1 to each ground atom A. For negative ground literals
against damage and noise. In particular, and after stating we deﬁne |¬A| := |A|. A logic program P is called acyclic

                                                IJCAI-07
                                                   666if there exists a level mapping |·|such that for all clauses 2.3 The Core Method
A ←  L1∧· · ·∧Ln ∈G(P ) we have |A| > |Li| for 1 ≤ i ≤ n. In [Holldobler¨ and Kalinke, 1994; Hitzler et al., 2004] a
                                                sn    method was proposed to translate a propositional logic pro-
Example 2. Consider the program from Example 1 and let     P
denote the n-fold application of s. With |e(sn(0))| := 2n +1 gram into a neural network, such that the network will set-
and |o(sn(0))| := 2n +2, we ﬁnd that P is acyclic.    tle down in a stable state corresponding to a model of the pro-
                                                      gram. To achieve this goal, the single-step operator TP asso-
  A (Herbrand) interpretation I is a subset of BL. Those ciated with P was implemented using a connectionist system.
atoms A with A ∈ I are said to be true under I, those with This general approach is nowadays called the Core Method
A ∈ I are said to be false under I. IL denotes the set of all [Bader and Hitzler, 2005].
interpretations. An interpretation I is a (Herbrand) model of In [Holldobler¨ et al., 1999], the idea was extended to ﬁrst-
a logic program P (in symbols: I |= P )ifI is a model for order logic programs: It was shown that the TP -operator of
each clause in G(P ) in the usual sense.              acyclic programs can be represented as a continuous function
                                                      on the real numbers. Exploiting the universal approximation
                          P
Example 3. For the program   from Example 1 we have   capabilities of 3-layered feed-forward networks, it was shown
M  := {e(sn(0)) | n  }∪{o(sm(0))  | m   }|= P
                 even                odd      .       that those networks can approximate TP up to any given ac-
  Given a logic program P , the single-step operator TP : curacy. However, no algorithms for the generation of the net-
IL →IL  maps an interpretation I to the set of exactly those works from given programs were presented. This was ﬁnally
atoms A for which there is a clause A ← body ∈G(P )   done in [Bader et al., 2005] in a preliminary fashion.
such that the body is true under I. The operator TP captures
the semantics of P as the Herbrand models of the latter are 3 The FineBlend System
exactly the pre-ﬁxed points of the former, i.e. those interpre- In this section we will ﬁrst discuss a new embedding of in-
tations I with TP (I) ⊆ I. For logic programming purposes it terpretations into vectors of real numbers. This extends the
is usually preferable to consider ﬁxed points of TP , instead of approach presented in [Holldobler¨ et al., 1999] by computing
pre-ﬁxed points, as the intended meaning of programs. These m-dimensional vectors instead of a single real number, thus
ﬁxed points are called supported models of the program [Apt allowing for a higher and scalable precision. Afterwards, we
et al., 1988]. In Example 1, the (obviously intended) model will show how to construct a connectionist system approxi-
M  is supported, while BL is a model but not supported. mating the TP -operator of a given program P up to a given
  Logic programming is an established and mature paradigm accuracy ε. As mentioned above, in [Bader et al., 2005] ﬁrst
for knowledge representation and reasoning (see e.g. [Lloyd, algorithms were presented. However, the accuracy obtainable
1988]) with recent applications in areas like rational agents or in practice was limited through the use of a single real num-
semantic web technologies (e.g. [Angele and Lausen, 2004]). ber for the embedding. The approach presented here allows
                                                      for arbitrarily precise approximations. Additionally, we will
2.2  Connectionist Systems                            present a novel training method, tailored for our speciﬁc set-
                                                      ting. The system presented here is a ﬁne blend of techniques
A connectionist system is a network of simple computational from the Supervised Growing Neural Gas (SGNG) [Fritzke,
units, which accumulate real numbers from their inputs and 1998] and the approach presented in [Bader et al., 2005].
send a real number to their output. Each unit’s output is con-
nected to other units’ inputs with a certain real-valued weight. 3.1 Embedding
Those units without incoming connections are called input Obviously, we need to link the space of interpretations and
units, those without outgoing ones are called output units. the space of real vectors in order to feed the former into a
  We will consider 3-layered feed-forward networks, i.e. net- connectionist system. To this end, we will ﬁrst extend level
works without cycles where the outputs of units in one layer mappings to a multi-dimensional setting, and then use them
are only connected to the inputs of units in the next layer. The to represent interpretations as real vectors.
ﬁrst and last layers contain the input and output units respec- Deﬁnition 4. An m-dimensional level mapping is a bijective
                                                                             +
tively, the intermediate layer is called the hidden layer. function · : BL → (N , {1,...,m}).ForA ∈BL,if
  Each unit has an input function which uses the connections’ A =(l, d), then l and d are called level and dimension of
weights to merge its inputs into one single value, and an out- A, respectively. Again, we deﬁne ¬A := A.
put function. An example for a so-called radial basis input Deﬁnition 5. Let b ≥ 3 and let A ∈BL be an atom with
                       n          2
function is (w, x) → i=1(xi − wi) , where the xi are A =(l, d). The m-dimensional embedding ι : BL →
                                                        m                          m
the inputs and the wi are the corresponding weights. Possible R and its extension ι : IL → R are deﬁned as ι(A):=
                                            1
output functions are the sigmoidal function (x → 1+e−x , for (ι1(A),...,ιm(A)) where
                                                                
the hidden layer) and the identity (x → x, usually used in the    −l                          
                                                                  b    if j = d
output layer). If only one unit of a layer is allowed to output ι (A):=                 ι(I):=    ι(A).
                                                         j        0               and
a value =0, the layer implements a winner-take-all behavior.          otherwise              A∈I
  Connectionist systems are successfully used for the learn- With Cm we denote the set of all embedded interpretations,
                                                          m                      m 1
ing of complex functions from raw data called training sam- i.e. C := {ι(I) | I ∈IL}⊂R .
ples. Desirable properties include robustness with respect to
                                                         1                         ¯
damage and noise; see e.g. [Rojas, 1996] for details.    For b =2, ι is not injective, as 0.012 =0.12. We use b =4.

                                                IJCAI-07
                                                   667                           y
                                                           fP (x)                 fQ(x)
                         0.3¯
                                                          0.3¯                   0.3¯

                       x                                  0.25                  0.25
                    0.3¯
                                      ι(M)
                                                                              x                     x
                                                                           0.3¯                  0.3¯
                                           x
                                        0.3¯
                                                      Figure 3: fP for the program from Example 1 and the embed-
         1          2                                 ding from Example 2 is shown on the left. A piecewise con-
Figure 1: C (left) and C (right) for b =4and M from Ex. 6.
                                                      stant approximation fQ (level l =2) is shown on the right.
       y         y         y        y
              ;         ;         ;
                                                      3.2  Construction
             x         x         x         x
                                                      In this section, we will show how to construct a connection-
  Figure 2: The ﬁrst steps while constructing the limit C2. ist network N for a given covered program P and a given
                                                      accuracy ε, such that the dimension-wise maximum distance
                                                      d(fP ,fN ):=maxx,j(|πj(fP (x)) − πj(fN (x))|) between
Example 6. Using the 1-dimensional level mapping from
                     1                                the embedded TP -operator fP and the function fN computed
Example 2, we obtain C as depicted in Figure 1 on the
                                          n           by N is at most ε. We will use a 3-layered network with a
left. Using the 2-dimensional level mapping e(s (0)) :=
(n +1, 1)    o(sn(0)) := (n +1, 2)          C2      winner-take-all hidden layer. 
         and                       , we obtain   as              −ln((b−1)ε)
depicted on the right and ι(M)=(0.1010b, 0.0101b) ≈     With l =    ln(b)  , we obtain a level l such that when-
(0.2666667, 0.0666667) for the embedding of M.        ever two interpretations I and J agree on all atoms up to level
                                                 1
  For readers familiar with fractal geometry, we note that C l in dimension j, we ﬁnd that |ιj(I) − ιj(J)|≤ε. For a cov-
is the classical Cantor set and C2 the 2-dimensional variant ered program P , we can construct a ﬁnite subset Q ⊆G(P )
of it [Barnsley, 1993]. Obviously, ι is injective for a bijec- such that for all I ∈IL, TP (I) and TQ(I) agree on all atoms
                                    m
tive level mapping and it is bijective on C . Using the m- up to level l in all dimensions, hence d(fP ,fQ) ≤ ε. Fur-
dimensional embedding, the TP -operator can be embedded thermore, we ﬁnd that the embedding fQ is constant on all
into the real vectors to obtain a real-valued function fP . hyper-squares of level l [Bader et al., 2005], i.e. we obtain a
                                                      piecewise constant function fQ such that d(fP ,fQ) ≤ ε.
Deﬁnition 7. The m-dimensional embedding  of TP , namely
     m     m                            −1
fP : C →  C  , is deﬁned as fP (x):=ι TP ι (x) .      We can now construct the feed-forward network as follows:
                                                                         H        l
      m                        T                      For each hyper-square of level , we add a unit to the hid-
  The   -dimensional embedding of P is preferable to the den layer, such that the input weights encode the position of
one introduced in [Holldobler¨ et al., 1999] and used in [Bader the center of H. The unit shall output 1 if it is selected as
et al., 2005], because it allows for scalable approximation winner, and 0 otherwise. The weight associated with the out-
precision on real computers. Otherwise, only 16 atoms could
                                                      put connections of this unit is the value of fQ on that hyper-
be represented with 32 bits.                          square. Thus, we obtain a connectionist network approximat-
  Now we introduce hyper-squares which will play an im-
                                                      ing the semantic operator TP up to the given accuracy ε.To
portant role in the sequel. Without going into detail, Figure 2 determine the winner for a given input, we designed a locally
shows the ﬁrst 4 steps in the construction of C2. The big
                      2m                              receptive activation function such that its outcome is smallest
square is ﬁrst replaced by shrunken copies of itself, the for the closest “responsible” unit. Responsible units here are
result is again replaced by 2m smaller copies and so on. The
                                2              m      deﬁned as follows: Given some hyper-square H, units which
limit of this iterative replacement is C . We will use Ci to        H
                     i                                are positioned in but not in any of its sub-hyper-squares are
denote the result of the -th replacement, i.e. Figure 2 de- default units H
    C2, C2, C2   C2                                   called           of  , and they are responsible for inputs
picts 0  1  2 and 3. Again, for readers with background from H except for inputs from sub-hyper-squares containing
in fractal geometry we note, that these are the ﬁrst 4 appli- other units. If H does not have any default units, the units po-
cations of an iterated function system [Barnsley, 1993]. The sitioned in its sub-hyper-squares are responsible for all inputs
squares occurring in the intermediate results of the construc- H
                                             H        from   as well. When all units’ activations have been (lo-
tions are referred to as hyper-squares in the sequel. l de- cally) computed, the unit with the smallest value is selected
notes a hyper-square of level l, i.e. one of the squares occur-
      Cm                    T                 l       as the winner.
ring in l . An approximation of P up to some level will                                  [          ]
                                             l          The following example is taken from Witzel, 2006 and
yield a function constant on all hyper-squares of level . used to convey the underlying intuitions. All constructions
Deﬁnition 8. The largest exclusive hyper-square of a vector work for m-dimensional embeddings in general, but for clar-
     m                                       m
u ∈ C0 and a set of vectors V = {v1,...,vk}⊆C0 , de- ity the graphs here result from a 1-dimensional level mapping.
noted by Hex(u, V ), either does not exist or is the hyper-
      H                    u ∈ H    V ∩ H = ∅        Example 9. Using the program from Example 1 and the 1-
square  of least level for which and          . The                                                f
smallest inclusive hyper-square of a non-empty set of vectors dimensional level mapping from Example 2 we obtain P and
                    m                                 fQ for level l =2as depicted in Figure 3. The corresponding
U = {u1,...,uk}⊆C0 , denoted by Hin(U), is the hyper-
square H of greatest level for which U ⊆ H.           network consists of 1 input, 4 hidden and 1 output units.


                                                IJCAI-07
                                                   6683.3  Training                                               100                                     80

In this section, we will describe the adaptation of the sys-                                        70
tem during training, i.e. how the weights and the structure
of a network are changed, given training samples with input  10                                     60

and desired output, in such a way that the distribution under-                                      50
lying the training data is better represented by the network.
                                                             1                                      40
                                                          error
This process can be used to reﬁne a network resulting from                                            #units

an incorrect program, or to train a network from scratch. The                                       30
training samples in our case come from the original (non ap-
proximated) program, but might also be observed in the real  0.1                                    20

world or given by experts. First we discuss the adaptation of                         #units (FineBlend 1)  10
                                                                                       error (FineBlend 1)
the weights and then the adaptation of the structure by adding                        #units (FineBlend 2)
                                                                                       error (FineBlend 2)
                                                            0.01                                    0
and removing units. Some of the methods used here are adap-   0      2000   4000    6000   8000   10000
tations of ideas described in [Fritzke, 1998]. For a more de-                 #examples
tailed discussion of the training algorithms and modiﬁcations
we refer to [Witzel, 2006].                                   Figure 4: FineBlend 1 versus FineBlend 2.

Adapting the weights Let x be the input, y be the desired quite obvious: If a hidden unit u fails, the receptive area is
output and u be the winner-unit from the hidden layer. To taken over by other units, thus only the speciﬁc results learned
adapt the system, we change the output weights for u towards for u’s receptive area are lost. While a corruption of the input
the desired output, i.e. wout ← η · y +(1− η) · wout. Fur- weights may cause no changes at all in the network function,
thermore, we move u towards the center c of Hin({x, u}), generally it can alter the unit’s receptive area. If the output
i.e. win ← μ · c +(1− μ) · win, where η and μ are prede- weights are corrupted, only certain inputs are effected. If the
ﬁned learning rates. Note that the winner unit is not moved damage to the system occurs during training, it will be re-
towards the input but towards the center of the smallest hyper- paired very quickly as indicated by the experiment reported
square including the unit and the input. The intention is that in Section 4.3. Noise is generally handled gracefully, because
units should be positioned in the center of the hyper-square wrong or unnecessary adjustments or reﬁnements can be un-
for which they are responsible.                       done in the further training process.

Adding new units The adjustment described above enables 4 Evaluation
a certain kind of expansion of the network by allowing units
to move to positions where they are responsible for larger ar- In this section we will discuss some preliminary experiments.
eas of the input space. A reﬁnement now should take care of In the diagrams, we use a logarithmic scale for the error axis,
densifying the network in areas where a great error is caused. and the error values are relative to ε, i.e. a value of 1 desig-
Therefore, when a unit u is selected for reﬁnement,2 we try to nates an absolute error of ε. For incorrect network initializa-
ﬁgure out the area it is responsible for and a suitable position tion, we used the following wrong program:
to add a new unit.
  If u occupies a hyper-square on its own, then the largest            e(s(X)) ←¬o(X).
such hyper-square is considered to be u’s responsibility area.         o(X) ←  e(X).
Otherwise, we take the smallest hyper-square containing u.
Now u is moved to the center of this area, and some informa- Training samples were created randomly using the semantic
tion gathered by u is used to determine a sub-hyper-square operator of the program from Example 1.
into whose center a new unit is placed, and to set up the out-
put weights for the new unit.                         4.1  Variants of Fine Blend
                                                      To illustrate the effects of varying the parameters, we use two
Removing inutile units Each unit maintains a utility value, setups: One with softer utility criteria (FineBlend 1) and one
initially set to 1, which decreases over time and increases only with stricter ones (FineBlend 2). Figure 4 shows that, start-
                                        3
if the unit contributes to the network’s output. If a unit’s ing from the incorrect initialization, the former decreases the
utility drops below a threshold, the unit will be removed. initial error, paying with an increasing number of units, while
3.4  Robustness                                       the latter signiﬁcantly decreases the number of units, paying
                                                      with an increasing error. Hence, the performance of the net-
The described system is able to handle noisy data and to cope work critically depends on the choice of the parameters. The
with damage. Indeed, the effects of damage to the system are optimal parameters obviously depend on the concrete setting,
  2The error for a given sample is ascribed to the winner unit. After e.g. the kind and amount of noise present in the training data,
a predeﬁned number of training cycles, the unit with the greatest and methods for ﬁnding them will be investigated in the fu-
accumulated error is reﬁned, if the error exceeds a given threshold. ture. For our further experiments we will use the FineBlend 1
  3The contribution of a unit is the expected increase of error if the parameters, which resulted from a mixture of intuition and
unit would be removed [Fritzke, 1998].                (non-exhaustive) comparative simulations.

                                                IJCAI-07
                                                   669      100                                    140            100                                     80

                                                                                                    70
                                             120

       10                                                    10                                     60
                                             100

                                                                                                    50
                                             80

       1                                                     1                                      40
   error                                                  error
                                               #units                                                 #units
                                             60
                                                                                                    30

                                             40
      0.1                                                    0.1                                    20

                                             20
                               #units (FineBlend 1)                                                 10
                                error (FineBlend 1)
                                 #units (SGNG)                                        #units (FineBlend 1)
                                  error (SGNG)                                         error (FineBlend 1)
      0.01                                   0              0.01                                    0
        0   2000  4000  6000  8000  10000  12000  14000       0   2000  4000  6000  8000  10000  12000  14000  16000
                       #examples                                              #examples

          Figure 5: FineBlend 1 versus SGNG.                     Figure 6: The effects of unit failure.

                                                                        y
4.2  Fine Blend versus SGNG                                           0.3¯
Figure 5 compares FineBlend 1 with SGNG [Fritzke, 1998].
Both start off similarly, but soon SGNG fails to improve fur-
ther. The increasing number of units is partly due to the fact                      M
that no error threshold is used to inhibit reﬁnement, but this

should not be the cause for the constantly high error level.                            x
The choice of SGNG parameters is rather subjective, and even                         0.3¯
though some testing was done to ﬁnd them, they might be far
from optimal. Finding the optimal parameters for SGNG is Figure 7: Iterating random inputs. The two dimensions
beyond the scope of this paper; however, it should be clear of the input vectors are plotted against each other. The ε-
that it is not perfectly suited for our speciﬁc application. This neighborhood of the ﬁxed point M is shown as a small box.
comparison to an established generic architecture shows that
                                                                                       m
our specialized architecture actually works, i.e. it is able to 3. Choose a random input vector ∈ C0 (which is not nec-
learn, and that it achieves the goal of specialization, i.e. it essarily a valid embedded interpretation) and use it as
outperforms the generic architecture in our speciﬁc setting. initial input to the network.
4.3  Unit Failure                                       4. Iterate the network until it reaches a stable state, i.e. until
                                                          the outputs stay inside an ε-neighborhood.
Figure 6 shows the effects of unit failure. A FineBlend 1
                                                                                                    T
network is (correctly) initialized and reﬁned through train- For our example program, the unique ﬁxed point of P is
                                                      M
ing with 5000 samples, then one third of its hidden units are as given in Example 3. Figure 7 shows the input space
                                                             ε                M
removed randomly, and then training is continued as if noth- and the -neighborhood of , along with all intermediate
                                                                             5
ing had happened. The network proves to handle the damage results of the iteration for random initial inputs. The ex-
gracefully and to recover quickly. The relative error exceeds ample computations converge, because the underlying pro-
1 only slightly and drops back very soon; the number of units gram is acyclic [Witzel, 2006; Holldobler¨ et al., 1999]. Af-
                                                                6
continues to increase to the previous level, recreating the re- ter at most steps, the network is stable in all cases, in fact
dundancy necessary for robustness.                    it is completely stable in the sense that all outputs stay ex-
                                                      actly the same and not only within an ε-neighborhood. This
4.4  Iterating Random Inputs                          corresponds roughly to the number of applications of our
                                                      program’s TP operator required to ﬁx the signiﬁcant atoms,
One of the original aims of the Core Method is to obtain con-
                                                      which conﬁrms that the training method really implements
nectionist systems for logic programs which, when iteratively
                                                      our intention of learning TP . The fact that even a network ob-
feeding their output back as input, settle to a stable state cor-
                                                      tained through training from scratch converges in this sense
responding to an approximation of a ﬁxed point of the pro-
                                                      further underlines the efﬁcacy of our training method.
gram’s single-step operator. In our running example, a unique
ﬁxed point is known to exist. To check whether our system
reﬂects this, we proceed as follows:                  5   Conclusions and Further Work
                                                      We have reported on new results for overcoming the propo-
 1. Train a network from scratch until the relative error sitional ﬁxation of current neural-symbolic systems: To the
    caused by the network is below 1, i.e. network outputs
            ε                                         best of our knowledge this is the ﬁrst constructive approach
    are in the -neighborhood of the desired output.   of approximating the semantic operators of ﬁrst-order logic
 2. Transform the obtained network into a recurrent one by programs as well as their least ﬁxed points in a fully connec-
    connecting the outputs to the corresponding inputs. tionist setting. We also showed how the semantic operators

                                                IJCAI-07
                                                   670