   Beyond TFIDF Weighting for Text Categorization in the Vector Space Model 

                 Pascal Soucy                                  Guy W. Mineau 
                    Coveo                                      Université Laval 
                Quebec, Canada                                 Québec, Canada 
              psoucy@coveo.com                             guy.mineau@ift.ulaval.ca 


                   Abstract                      and Liu, 1999; Brank et al., 2002; Dumais et al., 1998]. 
                                                 While this weighting method seems very appropriate for IR, 
    KNN and SVM are two machine learning         it is not clear that it is the best choice for TC problems. 
    approaches to Text Categorization (TC) based on Actually, this weighting method does not leverage the 
    the Vector Space Model. In this model, borrowed information implicitly contained in the categorization task to 
    from Information Retrieval, documents are    represent documents. 
    represented as a vector where each component is   To illustrate this, let us suppose a text collection X and two 
    associated with a particular word from the   categorization tasks A and B. Under the TFIDF weighting 
    vocabulary. Traditionally, each component value is representation, each document in X is represented by the 
                                                 same vector for both A and B. Thus, the importance of a 
    assigned using the information retrieval TFIDF 
    measure. While this weighting method seems very word in a document is seen as independent from the 
    appropriate for IR, it is not clear that it is the best categorization task. However, we believe that this should 
    choice for TC problems. Actually, this weighting not be the case in many situations. Suppose that A is the task 
    method does not leverage the information     that consists of classifying X in two categories: documents 
    implicitly contained in the categorization task to that pertain to Computers and documents that don’t. 
    represent documents. In this paper, we introduce a Intuitively, words such as computer, intel and keyboard 
    new weighting method based on statistical    would be very relevant to this task, but not words such as 
    estimation of the importance of a word for a the and of; for this reason, the former words should have a 
    specific categorization problem. This method also higher weight than the latter ones. Suppose, now that B 
    has the benefit to make feature selection implicit, consists of classifying X in two very different categories: 
    since useless features for the categorization documents written in English and documents written in 
    problem considered get a very small weight.  other languages. It is arguable that in this particular task, 
    Extensive experiments reported in the paper shows words such has the (English stop word) and les (French stop 
    that this new weighting method improves      word), are very relevant. However, under TFIDF, the would 
    significantly the classification accuracy as get a very small weight since its IDF (Inverse Document 
    measured on many categorization tasks.       Frequency) would be low. In fact, it would get the same 
                                                 weight that was assigned for task A. While this example is 
                                                 somewhat an extreme case, we believe that a weighting 
 1   Introduction                                approach could benefit from the knowledge about the 
                                                 categorization task at hand.  
 KNN and SVM are two machine learning approaches to    In this paper, we introduce a new weighting method based 
 Text Categorization (TC) based on the vector space model on statistical estimation of a word importance for a 
 [Salton et al., 1975], a model borrowed from Information particular categorization problem. This weighting also has 
Retrieval (IR). Both approaches are known to be among the the benefit that it makes feature selection implicit since 
most accurate text categorizers [Joachims, 1998a; Yang and useless features for the categorization problem considered 
Liu, 1999]. In the vector space model, documents are get a very small weight. 
represented as a vector where each component is associated    Section 2 presents both the TFIDF weighting function and 
with a particular word in the text collection vocabulary.  the new weighting method introduced in this paper. Section 
   Generally, each vector component is assigned a value 3 describes our evaluation test bed. In section 4, we report 
related to the estimated importance (some weight) of the results that show significant improvements in terms of 
word in the document. Traditionally, this weight was classification accuracy.   
assigned using the TFIDF measure [Joachims, 1998a; Yang            2   Weighting approaches in text categorization Another approach is presented in [Han 1999]. In this study, 
                                                           vector components are weighted using an iterative approach 
           2.1   TFIDF weighting                           involving the classifier at each step. For each iteration, the 
           TFIDF is the most common weighting method used to weights are slightly modified and the categorization 
           describe documents in the Vector Space Model, particularly accuracy is measured using an evaluation set (a split from 
           in IR problems. Regarding text categorization, this the training set). Convergence of weights should provide an 
           weighting function has been particularly related to two optimal set of weights. While appealing (and probably a 
           important machine learning methods: KNN and SVM. The near optimal solution if the training data is the only 
           TFIDF function weights each vector component (each of information available to the classifier), this method is 
           them relating to a word of the vocabulary) of each document generally much too slow to be used, particularly for broad 
           on the following basis. First, it incorporates the word problems (involving a large vocabulary). 
           frequency in the document. Thus, the more a word appears 2.3   A Weighting Methods based on Confidence 
           in a document (e.g., its TF, term frequency is high) the more 
           it is estimated to be significant in this document. In addition, The weighting method (named ConfWeight in the rest of the 
           IDF measures how infrequent a word is in the collection. text) introduced in this paper is based on statistical 
           This value is estimated using the whole training text confidence intervals. Let xt be the number of documents 
           collection at hand. Accordingly, if a word is very frequent in containing the word t in a text collection and n, the size of 
           the text collection, it is not considered to be particularly this text collection. We estimate the proportion of 
           representative of this document (since it occurs in most documents containing this term to be:  
           documents; for instance, stop words). In contrast, if the                 
                                                                                   2
           word is infrequent in the text collection, it is believed to be   xt + 0.5zα 2
                                                                          p% =                        (3) 
           very relevant for the document. TFIDF is commonly used in          nz+ 2
           IR to compare a query vector with a document vector using             α 2
           a similarity or distance function such as the cosine similarity Where ~p is the Wilson proportion estimate [Wilson, 1927] 
           function. There are many variants of TFIDF. The following 2
                                                           and z α/2 is a value such that Φ(zα/2) = α/2, Φ is the 
          common variant was used in our experiments, as found in 
                           1                               t-distribution (Student’s law) function when n < 30 and the 
          [Yang and Liu, 1999].                                                                   2
                                                           normal distribution one when n ≥ 30. So when n ≥ 30 , ~p is:  
           
                        ⎧           n                                         x + 1.96              
                         log(tf 1)log  if tf 1                                 t
                        ⎪    td,,+≥td                                      p% =                       (4) 
                weighttd, = ⎨       xt               (1)                      n + 3.84
                        ⎪
                        ⎩      0otherwise                   
                                                           Thus, its confidence interval at 95% is:  
           where tf  is the frequency of word t in document d, n is the                             
                 t,d                                                            p%%(1 − p )
                                                                         p% ± 1.96                    (5) 
          number of documents in the text collection and xt is the              n + 3.84
           number of documents where word t occurs. Normalization  
           to unit length is generally applied to the resulting vectors Most categorization tasks can be formulated in a way to use 
           (unnecessary with KNN and the cosine similarity function).  only binary classifiers (e.g. a classifier that decides whether 
                                                           a document belongs to a specific category or not). Thus, for 
          2.2   Supervised weighting                       a task with n categories, there will be n binary classifiers.  
          [Debole and Sebastiani, 2003] have tested and compared   For a given category, let us name ~ the equation (4) 
                                                                                         p+  
          some supervised weighting approaches that leverages on the applied to the positive documents (those who are labeled as 
          training data. These approaches are variants of TFIDF being related to the category) in the training set and ~p to 
          weighting where the idf part is modified using common                                       −
                                                           those in the negative class. Now, we use the label MinPos 
          functions used to conduct feature selection. In this paper, 
                                                           for the lower range of the confidence interval of ~p , and the 
          their best finding is a variant of the Information Gain, the                           +
                                                           label MaxNeg for the higher range of that of ~ according to 
          Gain Ratio. Respective to a category ci, the Gain Ratio of                         p−
          the term tk is:                                  (5) measured on their respective training set. Let now 
                                IG(,t c )                  MinPosRelFreq be: 
                   GR(,)t c =      ki
                       ki                            (2)    
                            − ∑  Pc()log2 Pc()
                             cc∈{},c                                                                
                               ii                                                  MinPos
                                                                  MinPosRelFreq =                     (6) 
                                                                               MinPos+ MaxNeg
          1 In [Joachims, 1998a], a slight variant is used where the tf is used                                                  
          without the logarithm function, but [Yang and Liu, 1999] reports 2 When n < 30 (which occurs for categories with few positive 
          no significant difference in classification accuracy whether the log instances), the t-distribution was used instead of the normal law; 
          is applied or not).                              thus, equations should be modified accordingly. We now define the strength of term t for category +:  more frequently (relative to the number of documents) in the 
                                                positive category than in the negative one. Therefore, this 
                                                weighting method favors features that are proportionally 
      ⎧log2 (2⋅MinPosRelFreq) if MinPos > MaxNeg
  strt,+ = ⎨                              (7)   more frequent in the positive class. This weight decreases as 
       0otherwise
      ⎩                                         MaxNeg increases. Eq. (7) scales the weight values linearly 
                                                into the [0,1] range, so that the resulting weight is 0 when a 
Therefore, weight ≠ 0 iff the word appears proportionally term occurs at the same relative frequency in both classes or 
more frequently in the + category than in the – category, proportionally more frequently in the negative set. Finally, 
even in the worst (measured by the confidence interval) Eq. (8) makes the decrease faster, to reflect the rate at which 
estimation error scenario. There might be many categories features lose their “energy” as they are more evenly 
where weight ≠ 0, since the categorization task is divided in distributed among the positives and the negatives. As a 
n binary classifiers. We name the maximum strength of t: consequence, very predictive features get a high weight, 
                                                regardless of their absolute frequency (only proportion 
                              2
                                                differences matter).    
         maxstr(ts) = max ( trtc, )       (8) 
                  ( c∈Categories )                As we are interested in weighting all training and testing 
                                                documents components in the vector space model, we must 
Maxstr(t) is a global policy technique [Debole and use (8) with individual documents, taking the document 
Sebastiani, 2003], that is, the value is that of the best term frequency into account. We define the ConfWeight of t 
classifier and is thereafter used for all n binary classifiers. in document d as:  
Using a global policy allows us to use the same document  
representation for all n binary classifiers. While local ConfWeight = log(tf +1)maxstr(t)  (9) 
policies seem intuitively more appealing than global policies   t,d     t,d
when the categorization task is divided in n binary                                           
problems, [Debole and Sebastiani, 2003] shown that global Eq. (9) is quite similar to the TFIDF equation in (1): the first 
policies are at least as good as local policies. Note that a part weights the term according to its importance for the 
value of 0 for maxstr(t) is akin to a feature selection document while the second part weights the term globally. 
deciding to reject the feature.                 However, unlike TFIDF, ConfWeight uses the categorization 
  Figure 1 presents an example to highlight the behavior of problem to determine the weight of a particular term.  
eq. (6) to (8). In this figure, MinPos is set to 0.5, which  
means that a hypothetic term occurs at least (recall that this 
value is the lower range of its relative document frequency 3   Methodology 
confidence interval) in half the documents from the positive 3.1   Corpora 
set. Then, the curves (labeled (6), (7) and (8) in the graph) 
consists of the resulting weights for different values of In this paper, three data sets previously studied in the 
MaxNeg. Eq. (6) gives more weight to terms that occur literature have been selected. These datasets are: Reuters-
                                                21578, Ohsumed and the new Reuters Corpus Vol 1. Let us 
                                                briefly describe these datasets.  
      1                                           Reuters-21578 [Lewis, 1997] is made of categories related 
     0.9                                        to business news report. It is written using a limited 
     0.8                                        vocabulary in a succinct manner. We used the ModApte 
                                                [Lewis, 1997] split. There are 90 categories having at least 
     0.7                                  (6)

    t                                           one training and one testing document. These categories are 

    h 0.6                                 (7)
    g


    i                                           highly unbalanced. Each document may be categorized in 
     0.5                                  (8)   more than one category.  
    We
     0.4                                           Ohsumed comes from a very large text collection (the 
     0.3                                        MedLine Bibliographical Index) and is rarely used with all 
     0.2                                        available categories and documents. We have chosen to split 
     0.1                                        this text collection as done in [Lewis et al., 1996]. The 
                                                result is a task comprising 49 closely related categories 
      0                                         using a very technical vocabulary. Similarly to Reuters, a 
        0   0.2  0.4   0.6  0.8   1             document may be classified in one or many categories.  
                   MaxNeg                         Finally, Reuters Corpus Vol. 1 (RCV1) [Rose et al., 2001] 
                                                is a newer text collection released by Reuters Corp. that 
       Figure 1: Weight  when vary ing M axNeg wit h a consists of one full year of new stories. There are about 
                fixed MinPos = 0.5              850,000 documents. 103 categories have documents 
                                                assigned to them. This collection is very large, thus making  it a very challenging task for learning models such as SVM number of documents that have not been labeled by the 
 and KNN, which have polynomial complexity. Particularly, classifier to the category, but that should have.  
 we were not able to use SVM with a large training set since   For any category, the classifier precision is defined as 
 SVM does not scale up very well to large text collections. A/(A+C) and the recall as A/(A+B). To combine these two 
 Using our KNN implementation, we have limited the measures in a single value, the F-measure is often used. The 
 training set to the first 100,000 documents and the testing F-measure reflects the relative importance of recall versus 
 set to the next 100,000 documents3. An average of 3.15 precision. When as much importance is granted to precision 
categories is assigned to each testing document (over as it is to recall we have the F1-measure: 
315,000 total assignments).                       
                                                                ( precision + recall)
                                                            F1 =                 (10) 
  3.2 Classifiers, feature selection and settings               2 ⋅ precision⋅ recall
 The weighting method presented in this paper is intended to 
 weight documents in the Vector Space Model. Thus, it can  The F1-measure is an estimation of the breakeven point 
 be used only with classifiers using this model. For this where precision and recall meets if classifier parameters are 
 reason, we have evaluated our method using both KNN and tuned to balance precision and recall. Since the F1 can be 
 SVM and compared the results obtained with TFIDF and evaluated for each category, we get n different F1 values.  
 GainRatio [Debole and Sebastiani, 2003] weighting.  
    We have used the SVMlight package [Joachims, 1998b]   To compare two methods, it is needed to combine all the 
and the KNN classifier described in [Yang and Liu, 1999]. F1 values. In order to do that, two approaches are often 
In our experiments with SVM, we divided each     used: the macro-F1 average and the micro-F1 average. The 
categorization task into n binary classification problems, as macro-F1 average is the simple average of all F1 values; 
usual. In contrast, KNN is able to classify a document thus each category gets the same weigh in the average. In 
among the n categories using one multi-category classifier. counterpart, the micro-F1 average weighs large categories 
To decide whether a document is classified or not in a more than smaller ones. The micro-F1 is the F1 in (10) 
particular category, thresholds were learned for each where A, B, C and D are global values instead of category-
                                                 based ones. For instance, A in the micro-F1 is the total 
category [Yang and Liu, 1999]. TFIDF experiments were 
weighted using Eq. (1) and then normalized to unit length. number of classifications made by the n classifiers that were 
                                                 good predictions. Micro-F1 has been widely used in Text 
 GainRatio experiments were weighted as done by [Debole 
                                                 Categorization [Lewis et al., 1996; Yang and Liu, 1999; 
and Sebastiani, 2003].  
                                                 Joachims, 1998a]. Table 2 includes micro-F1 results for 
   To reach optimal classification accuracy, feature selection 
                                                 SVM while Table 3 includes those of KNN. For each 
might be required. Thus, we have included feature selection 
in our tests. The Information Gain measure has been used to experiment, the best score (among TFIDF, GainRatio and 
rank the features and many thresholds have been used to ConfWeight) is bolded.  
                                                   These results show that at low Information Gain 
filter features out; with ConfWeight, in addition to the use of 
the Information Gain to select features, when maxstr (see thresholds, ConfWeight clearly outperforms both TFIDF and 
 Eq. 8) was 0, the feature was also rejected. Stop words were GainRatio. When more drastic term selection is conducted, 
 not removed and words were not stemmed.         overall scores tend to decrease for all three term weighting 
                                                 methods. Is it very interesting to note the very large 
                                                 difference between ConfWeight and TFIDF using KNN. This 
 4   Results and discussion                      difference is particularly significant for a collection of the 
 To assess classifier accuracy, a confusion matrix is created size of RCV1.  
 for each category:                                Figure 2, 3 and 4 show the curves resulting from the use of 
                     Classifier   Classifier     an increasing number of features (decreasing Information 
    
                    positive label negative label Gain thresholds) for each weighting method using KNN. 
   True positive label  A            B           Clearly, ConfWeight is the only weighting that doesn’t 
   True negative label  C            D           suffer a decrease in accuracy as low-scored features are 
                                                 added. TFIDF results are less stable than ConfWeight and 
 Table 1: Confusion matrix used to evaluate classifier accuracy GainRatio, an observation that leads us to claim that TFIDF 
                                                 is very sensitive to the choice of feature selection settings.  
 For instance, A (the true positives) is the number of   While GainRatio is less sensitive to the presence of all 
 documents labeled by the classifier to the category that are terms (relevant or not) than TFIDF, ConfWeight seems not to 
 correct predictions. Similarly, B (the false negatives) is the need term selection at all, arguably due to its inherent term 
                                                 selection mechanism. We believe that ConfWeight can be 
                                                  used without feature selection and produce very good 
 3 At the time these experiments were conducted, the LYRL2004 results. 
 split was not yet released                            IGain                      Reuters 
                 Weighting                    Ohsumed                               0.87
   threshold                     21578 
                                                                                    0.86
                   TFIDF .848                    .65 
                                                                                    0.85
       0          GainRatio .875                 .702 
                                                                                    0.84
                                                                                 F1
                 ConfWeight       .877 .706                                      -
                                                                                 o

                                                                                 r  0.83
                   TFIDF .851                    .679                            c

                                                                                 Mi 0.82
     0.001        GainRatio .875                 .703 
                                                                                    0.81
                 ConfWeight       .877 .707 
                                                                                     0.8
                   TFIDF .875                    .695 
                                                                                    0.79
     0.005        GainRatio .877                 .701 
                                                                                                  Number of features
                 ConfWeight       .882           .697 
                   TFIDF .876                    .692                                                    TFIDF
      0.01        GainRatio .877                 .696                                                    GainRatio
                 ConfWeight       .882 .697                                                              ConfWeight
                   TFIDF          .874           .693 
                                                                                                            
     0.015        GainRatio .871                 .694                       Figure 2: KNN Micro-F1s on Reuters-21578 as the number of 
                 ConfWeight       .874 .696                                                       feature increases 
                   TFIDF .842                    .658 
      0.03        GainRatio       .844 .658                                          0.7
                 ConfWeight .836                 .658 
                                                                                    0.68
 
Table 2: SVM Micro-F1s by text collection and weighting method                      0.66
                                                                                  F1

                                                                                  -
                                                                                  o

                                                                                  r 0.64

                                                                                  c

   IGain                       Reuters                                            Mi
                Weighting                 Ohsumed RCV1                              0.62
 threshold                     21578 
                 TFIDF .816 .588 .785                                                0.6

     0          GainRatio .834 .659 .792                                            0.58
               ConfWeight       .861 .683 .830 
                                                                                                   Number of features
                 TFIDF .819 .645 .812 
    .001        GainRatio .833               .66         .812                                             TFIDF
               ConfWeight       .862 .687 .833                                                            GainRatio
                                                                                                          ConfWeight
                 TFIDF .843 .621 .828 
    .005        GainRatio       .840         .661 .817                    Figure 3: KNN Micro-F1s on Ohsumed as the number of feature 
               ConfWeight       .861 .683 .833                                                        increases 
                 TFIDF .856 .640 .823                                                                       
     .01        GainRatio .834 .659 .822 

               ConfWeight       .864 .681 .824                                      0.84
                 TFIDF .85 .655 .811 
                                                                                    0.82
    .015        GainRatio .832               .654        .812 
                                                                                 1


                                                                                 F   0.8

               ConfWeight       .856 .675 .811                                   -
                                                                                 o
                                                                                 r

                 TFIDF          .832         .640 .757                           c
                                                                                    0.78
                                                                                 Mi
     .03        GainRatio .799               .639        .765 
               ConfWeight .824               .646 .749                              0.76

                                                                                    0.74
 Table 3: KNN Micro-F1s by text collection and weighting method 
                                                                                                  Number of features
 Another interesting remark is that the best overall scores on                                           TFIDF
 each corpora, both using KNN and SVM, are obtained by                                                   GainRatio
 ConfWeight (Reuters-21578: .882 with SVM and .864 with                                                  ConfWeight
 KNN; Ohsumed: .707 with SVM, .687 with KNN; RCV1 
                                                                            Figure 4: KNN Micro-F1s on RCV1 as the number of feature 
 .833 with KNN).  
                                                                                                      increases 