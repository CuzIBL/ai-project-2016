                   Delayed Duplicate Detection: Extended Abstract 

                                                  Richard E. Korf 
                                          Computer Science Department 
                                      University of California, Los Angeles 
                                               Los Angeles, CA 90095 
                                                   korf@cs.ucla.edu 


                       Abstract                                With each node, it stores a used-operator bit for each op-
                                                               erator, to indicate whether the neighboring state reached 
     Best-first search is limited by the memory                by that operator has already been generated. For exam•
     needed to store nodes in order to detect dupli•           ple, the sliding-tile puzzles require four such bits for each 
     cates. Disks can greatly expand the amount of             state, one for each direction in which a tile could move. 
     storage available, but randomly accessing a disk          When a parent node is expanded, only children that are 
     is impractical. Rather than checking newly-               reached via unused operators are generated, and the par•
     generated nodes as soon as they are generated,            ent node is deleted from memory. In each child node, the 
     we append them to a disk file, then sort the              operator that generates the parent is marked as used. 
     file, and finally scan the sorted file in one pass        When duplicate states are found in the Open list, only 
     to detect and remove duplicate nodes. This                one copy is kept, and any operator that is marked as 
     also speeds up such searches that fit entirely            used in any copy is marked as used in the retained copy. 
     in memory, by improving cache performance.                Since the closed list is not stored, reconstructing the so•
     We implement this idea for breadth-first search,          lution path requires additional work. See [Korf, 1999; 
     performing the first complete searches of the             Korf k Zhang, 2000] for two ways to do this. 
     2x7 sliding-tile puzzle, and the 18-disk, 4-peg 
                                                                 The memory required by frontier search is propor•
     Towers of Hanoi puzzle. 
                                                               tional to the maximum size of the Open list, or the width 
                                                               of the problem space, rather than the size of the space. 
                                                               For example, in the grid space mentioned above, the 
1 Introduction: The Problem                                    width of the space grows only linearly with the search 
Best-first search algorithms, such as breadth-first search     radius, while the entire space grows quadratically. As 
(BFS), Dijkstra's algorithm [Dijkstra, 1959], and A*           another example, the width of the n-disk, 3-peg Towers 
[Hart, Nilsson, k Raphael, 1968], store every node that        of Hanoi space is only 2n states, while the entire space 
is generated, in either the Open list or the Closed list.      contains 3n states. Frontier search is still limited by the 
One reason for doing this is to detect duplicate nodes,        memory required to store the Open list, however. 
and avoid expanding a state more than once. As a result, 
these algorithms are limited by the available memory.          3 Delayed Duplicate Detection (DDD) 
   In some problems, this memory limitation can be 
avoided by depth-first searches (DFS) such as depth-           Hard disks with hundreds of gigabytes of storage are 
first iterative-deepening (DFID) or iterative-deepening-       available for less than a dollar per gigabyte, which is over 
A* (IDA*) [Korf, 1985], but DFS can generate ex•               a hundred times cheaper than memory. Because of high 
ponentially more nodes than BFS. For example, in a             latency, however, a disk behaves more like a sequential 

rectangular-grid problem space, BFS will generate 0(r2)        device, such as a magnetic-tape drive, with large capac•
nodes within a radius of r, while DFID will generate           ity and high bandwidth, but only if it is accessed se•

0(3r) nodes. While there are ways of detecting some            quentially. To quickly detect duplicate states in a search 
duplicate nodes in a DFS[Taylor k Korf, 1993], they do         algorithm, however, nodes are usually stored in a hash 
not apply to all problem spaces.                               table, which is designed to be accessed randomly. 
                                                                 Our solution to this problem is rather than checking 
2 Frontier Search                                              each newly-generated node for duplicates as soon as it is 
                                                               generated, we append each node to a disk file containing 
An algorithm called frontier searc/i[Korf, 1999; Korf k        previously generated nodes. At some point later we sort 
Zhang, 2000] saves only the Open list of nodes at the          the file, thereby bringing together nodes representing the 
frontier of the search, and not the Closed list of nodes       same state. Then we scan the sorted list of nodes in one 
that have been expanded, thus saving some memory.              pass, merging any duplicate nodes. 


POSTER PAPERS                                                                                                       1539  3.1 Breadth-First Frontier Search                             4.1 Sliding-Tile Puzzles 
 As a simple example, we describe breadth-first frontier       [Schofield, 1967] published a complete breadth-first 
 search with delayed duplicate detection. BFS is normally      search of the 3 x 3 Eight puzzle. We completed a BFS for 
 implemented with a FIFO queue, which we implement             all sliding-tile puzzles up to the 2x7 Thirteen Puzzle. 
 with two disks files, an input file and an output file. Ini•  Table 1 below shows the results. The first column gives 
 tially, the input file contains the initial state. As we read the x and y dimensions of the puzzle, and the second 
 each node in the input file, we expand it, and write its      column gives the number of moves needed to reach all 
 children to the output file, with no duplicate checking.      solvable states, starting with the blank in a corner posi•
 When the input file is exhausted, we delete it. At that       tion. This is also the worst-case optimal solution length, 
point, the output file contains all the nodes at the next      for a goal with the blank in a corner. The third column 
depth, including any duplicate nodes. We then sort the         gives the number of solvable states, which is (xy)\/2, and 
nodes in the output file by their state representations,       the fourth column gives the width of the problem space, 
which brings together any duplicate nodes representing         which is the maximum number of nodes at any depth. 
the same state. Next, we linearly scan the output file, 
merging duplicate nodes and ORing their used operator            Size Moves Total States Max Width 
bits, and write one copy of each state to a new input file,     2x2 6 12" 2 
deleting the output file when we're done. This completes        2x3 21 360 44 
one level of the breadth-first search. The algorithm con•       2x4 37 20,160 1,999 
tinues until expanding the nodes in the input file doesn't      3x3 31 181,440 24,047 
generate any more nodes in the output file.                     2x5 55 1,814,400 133,107 
                                                                2x6 80 239,500,800 13,002,649 
3.2 Sorting the Disk Files                                      3x4 53 239,500,800 21,841,159 
                                                                2x7 108 43,589,145,600 1,862,320,864 
Algorithms for sorting disk files are well-known. See 
[Garcia-Molina, Ullman, & Widom, 2000], pp. 42-48.                       Table 1: Sliding-Tile Puzzle Results 
The basic algorithm is to read as much of the unsorted 
file as will fit into memory, sort it in memory using quick•     The 3x4 and 2x6 Eleven Puzzles were the largest 
sort, for example, and write the sorted portion of the         that we could solve in memory. We implemented both 
file to a new subfile. Continue until the entire original      a standard BFS algorithm, using one bit of memory per 
file has been read and written into a set of sorted sub•       state, and also breadth-first frontier search with delayed 
files. Then, all the sorted subfiles are merged in one pass,   duplicate detection. The standard BFS required 17.5 
storing the head of each file in memory, and writing the       minutes, while the frontier search with DDD required 
lowest record to a final sorted output file.                   only 9.6 minutes, on a 440 Megahertz Sun Ultra 10 work•
                                                               station. This demonstrates that DDD frontier search is 
3.3 DDD in Memory                                              useful even for problems that fit in memory. 
                                                                 The 2x7 Fourteen Puzzle was the largest we could 
Surprisingly, delayed duplicate detection is useful even       search exhaustively with our 120 gigabyte disk. At 8 
when all nodes fit in memory, resulting in reduced run•        bytes per state, this problem required about 15 gigabytes 
ning time due to improved cache performance. In the            of disk storage, and ran for 51 hours, 13 minutes. The 
standard implementation of breadth-first search in mem•        ratio of the problem size to the problem width is about 
ory, the Open list is stored in a hash table. As each          23.4, illustrating the advantage of frontier search. 
new node is generated, it is looked up in the hash table, 
which often results in a cache miss, since the hash func•      4.2 Towers of Hanoi 
tion is designed to randomly scatter the nodes. A DDD          For the standard 3-peg Towers of Hanoi problem, there 
implementation doesn't use a hash table, but a single          is a simple algorithm that guarantees the shortest path 
FIFO queue in memory, reading nodes off the head of            between any pair of states. The 4-peg Towers of Hanoi 
the queue, and appending them to the tail. Once a level        puzzle, known as Reve's puzzle, is much more interest•
of the search is completed, the queue is sorted in mem•        ing. There exists a algorithm for finding a solution, and 
ory using an algorithm such as quicksort, and the sorted       a conjecture that it generates optimal solutions, but the 
queue is scanned, merging duplicate nodes. The advan•          conjecture remains unproven. [van de Liefvoort, 1992] 
tage of this approach is that the queue is only accessed       contains a good bibliography for this problem. [Szegedy, 
at the head and tail, or at two points in between during       1999] gives bounds for the A:-peg version, but they in•
quicksort, and hence most memory references will reside        clude an unspecified constant in the exponent. 
in cache, reducing the running time.                             For the sliding-tile puzzles, all paths between any pair 
                                                               of states have the same even-odd parity, and the algo•
4 Experiments                                                  rithm described in Section 3.1 works correctly. For the 
                                                               Towers of Hanoi, however, two states can have both even 
We implemented a breadth-first search on sliding-tile          and odd length paths between them. In that case, fron•
puzzles, and the 4-Peg Towers of Hanoi problem.                tier search with delayed duplicate detection can fail by 


1540                                                                                                   POSTER PAPERS leaking into the interior of the search. One solution to      6 Acknowledgments 
this problem is to store two complete levels of the search 
                                                              Larry Taylor brought the 4-Peg Towers of Hanoi problem 
at a time. See our full paper for the details [Korf, 2003]. 
                                                              to my attention, and also used disk storage in a breadth-
   Using this algorithm, we were able to exhaustively 
                                                              first search to find duplicate operator strings [Taylor & 
search all problems through 18 disks, starting with all 
                                                              Korf, 1993]. Thanks to Jianming He for verifying the 
disks on one peg. Table 2 shows the results. The first 
                                                              Towers of Hanoi results. This research was supported 
column gives the number of disks, and the second col•
                                                              by NSF under grant No. EIA-0113313, by NASA and 
umn shows the minimum number of moves required to 
                                                              JPL under contract No. 1229784, and by the State of 
move all the disks from one peg to another. The third 
                                                              California MICRO grant No. 01-044. 
column gives the total number of states of the problem, 
which is 4n, where n is the number of disks. The fourth       References 
column shows the maximum width of the graph, starting 
from a state with all disks on one peg. In all cases, the     [Dijkstra, 1959] Dijkstra, E. 1959. A note on two prob•
optimal number of moves equals the conjectured mini•             lems in connexion with graphs. Numerische Mathe-
mal number of moves. The 18-disk problem took almost             matik 1:269-271. 
6 days to run, and at 8 bytes per state required about 30     [Garcia-Molina, Ullman, & Widom, 2000] 
gigabytes of disk space. Note that the ratio of the total        Garcia-Molina, H.; Ullman, J. D.; and Widom, J. 
number of states to the problem width for the 18-disk            2000. Database System Implementation. Upper Saddle 
problem is almost 34.5.                                          River, N.J.: Prentice-Hall. 
  Disks   Moves      Total States     Max Width               [Hart, Nilsson, & Raphael, 1968] Hart, P.; Nilsson, N.; 
      r        1                 4                3              and Raphael, B. 1968. A formal basis for the heuristic 
      2        3                16                6              determination of minimum cost paths. IEEE Trans. 
      3        5                64               30              Systems Science and Cybernetics SSC-4(2):100-107. 
      4        9               256               72           [Korf & Zhang, 2000] Korf, R., and Zhang, W. 2000. 
      5       13             1,024             282               Divide-and-conquer frontier search applied to opti•
      6       17             4,096             918               mal sequence alignment. In Proceedings of the Na•
      7       25            16,284            2,568              tional Conference on Artificial Intelligence (AAAI-
      8       33            65,536            9,060              2000), 910-916. 
      9       41           262,144          31,638 
                                                              [Korf, 1985] Korf, R. 1985. Depth-first iterative-
     10       49         1,048,576         109,890 
                                                                 deepening: An optimal admissible tree search. Ar•
     11                  4,194,304         335,292 
              65                                                 tificial Intelligence 27(1):97-109. 
     12       81        16,777,216       1,174,230 
     13       97        67,108,864       4,145,196            [Korf, 1999] Korf, R. 1999. Divide-and-conquer bidi•
     14      113      268,435,456       14,368,482               rectional search: First results. In Proceedings of the 
     15      129     1,073,741,824      48,286,104               Sixteenth International Joint Conference on Artificial 
     16      161    4,294,967,296      162,989,898               Intelligence (IJCAI-99), 1184-1189. 
     17      193   17,179,869,184      572,584,122            [Korf, 2003] Korf, R. 2003. Delayed duplicate detection: 
     18      225   68,719,476,736    1,994,549,634               initial results. In Proceedings of the IJCAI-03 Work•
                                                                 shop on Model Checking and Artificial Intelligence. 
        Table 2: 4-Peg Towers of Hanoi Results 
                                                              [Schofield, 1967] Schofield, P. 1967. Complete solution 
                                                                 of the eight puzzle. In Meltzer, B., and Michie, D., 
5 Conclusions and Further Work                                   eds., Machine Intelligence 3. New York: American El•
                                                                 sevier. 125-133. 
We showed that delaying the detection of duplicate 
                                                              [Szegedy, 1999] Szegedy, M. 1999. In how many steps 
nodes in a breadth-first search can effectively make use 
                                                                the k peg version of the towers of hanoi game can be 
of very large capacity disk-storage systems. We also 
                                                                 solved? In Proceedings of the 16th Annual Symposium 
showed how to combine this idea with frontier search. 
                                                                 on Theoretical Aspects of Computer Science (STACS 
In addition, we demonstrated that these ideas can also 
                                                                 '99), LNCS 1563. Trier, Germany: Springer-Vcrlag. 
speed up a search that occurs entirely in memory. Using 
these algorithms, we completed breadth-first searches of      [Taylor & Korf, 1993] Taylor, L., and Korf, R. 1993. 
sliding-tile puzzles with up to 43 billion nodes, and 4-peg      Pruning duplicate nodes in depth-first search. In Pro•
Towers of Hanoi problems with up to 68 billion nodes.            ceedings of the National Conference on Artificial In•
For the 4-peg Towers of Hanoi, we verified a conjecture          telligence (AAAI-93), 756-761. 
regarding optimal solution lengths to 18 disks.               [van de Liefvoort, 1992] van de Liefvoort, A. 1992. An 
  Current work is focussed on implementing these tech•          iterative algorithm for the reve's puzzle. The Com•
niques for more complex best-first search algorithms such       puter Journal 35(l):91-92. 
as Dijkstra's algorithm [Dijkstra, 1959] and A* [Hart, 
Nilsson, & Raphael, 1968]. 


POSTER PAPERS                                                                                                      1541 