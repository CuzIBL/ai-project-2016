         Trust No One: Evaluating Trust-based Filtering for Recommenders
                                    John O‚ÄôDonovan, Barry Smyth
                                      Adaptive Information Cluster
                                    Department of Computer Science
                                       University College Dublin
                                       BelÔ¨Åeld, Dublin 4, Ireland
                              john.odonovan@ucd.ie, barry.smyth@ucd.ie

                    Abstract                            [Avesani et al., 2004] describe a trust-based recommender
                                                      system in the skiing domain. However these approaches rely
    To be successful recommender systems must gain    on models of trust that are built from the direct feedback of
    the trust of users. To do this they must demonstrate users; in short, individual users are expected to indicate those
    their ability to make reliable predictions. We ar- partners that they place the most trust in and a trust model is
    gue that collaborative Ô¨Åltering recommendation al- generated from the resulting graph of relationships.
    gorithms can beneÔ¨Åt from explicit models of trust   [Massa and Bhattacharjee, 2004] build a trust model di-
    to inform their predictions. We present one such  rectly from explicit user-provided trust ratings. This work
    model of trust along with a cost-beneÔ¨Åt analysis  is carried out using the popular epinions.com service. Epin-
    that focuses on the classical trade-off that exists be- ions.com is a web site that allows users to review various
    tween recommendation coverage and prediction ac-  items (cars, books, music, etc.). In addition they can assign
    curacy.                                           a trust rating to reviewers based on the degree to which they
                                                      have found them to be helpful and reliable in the past. [Massa
                                                      and Bhattacharjee, 2004] argue that this trust data can be ex-
1  Introduction                                       tracted and used as part of the recommendation process, espe-
Recommender systems have been developed as a solu-    cially as a means to relieve the sparsity problem (lack of over-
tion to the well documented information overload problem. lapping user ratings) that has hampered traditional collabora-
[Resnick et al., 1994], [Breese et al., 1998]. These systems tive Ô¨Åltering techniques [O‚ÄôSullivan et al., 2002]. [Massa and
employ techniques from user proÔ¨Åling, machine learning and Bhattacharjee, 2004] argue that it is possible to compare users
information Ô¨Åltering to produce individual recommendations according to their degree of connectedness in the trust-graph
of items to suit users‚Äô requirements. Collaborative Ô¨Åltering encoded by Epinions.com, but do not show that this method
(CF) recommenders operate on the assumption that similar of comparison maintains recommendation accuracy.
users share similar tastes; recommendations are generated for Our benchmark algorithm uses Resnick‚Äôs standard predic-
a target user by analysing the rating histories of a set of suit- tion formula which is reproduced below as Equation 1; see
able recommendation partners.                         also [Resnick et al., 1994]. In this formula c(i) is the rating
  The traditional CF approach relies heavily on the similar- to be predicted for item i in consumer proÔ¨Åle c and p(i) is
ity between the target user and its partner as a way to weight the rating for item i by a producer proÔ¨Åle p who has rated
each partner‚Äôs predictions [Resnick et al., 1994]. In this pa- i. In addition, c and p refers to the mean ratings for c and p
per we propose that, in addition, it is possible to model the respectively. The weighting factor sim(c, p) is a measure of
trustworthiness of these partners, and to use this as another the similarity between proÔ¨Åles c and p, which is traditionally
factor to inÔ¨Çuence their prediction contributions. Indeed the calculated as Pearson‚Äôs correlation coefÔ¨Åcient.
idea of explicitly modeling and using trust in Ô¨Åltering tasks is          X
becoming increasingly popular. For example, [Golbeck and                      (p(i) ‚àí p)sim(c, p)
Hendler, 2004] presents a trust-based email Ô¨Ålter, trust scores           pP (i)
                                                                c(i) = c +    X                       (1)
in this system are calculated through inference and propaga-                     |sim(c, p)|
tion, of the form (A ‚áí B ‚áí C) ‚áí  (A ‚áí  C), where A,
B and C are users with interpersonal trust scores. The Trust-                 pPi
Mail application [Golbeck and Hendler, 2004] looks up an As we have seen above Resnick‚Äôs prediction formula dis-
email sender in the reputation/trust network, and provides an counts the contribution of a partner‚Äôs prediction according to
inline rating for each mail. These trust values can tell a user its degree of similarity with the target user so that more simi-
if a mail is important or unimportant. Trust values in this sys- lar partners have a large impact on the Ô¨Ånal ratings prediction.
tem can be deÔ¨Åned with respect to a certain topic, or on a We argue that there is another factor which might be used
general level, in a similar manner to work in [O‚ÄôDonovan and in conjunction with similarity to inÔ¨Çuence recommendation
Smyth, 2005a] and [O‚ÄôDonovan and Smyth, 2005b].       and prediction. We believe that the reliability of a partnerproÔ¨Åle to deliver accurate recommendations in the past is an-
other important factor, one that we refer to as the trust. In-
tuitively, if a proÔ¨Åle has made lots of accurate predictions in
the past, then they can be viewed as more trustworthy than
another proÔ¨Åle that has made many poor predictions. We de-
scribe a computational model of trust that can be generated
unobtrusively, during the normal operation of a CF recom-
mender system, by mining the recommendation histories of
different recommendation partners. We re-evaluate work in
[O‚ÄôDonovan and Smyth, 2005b] which shows that trust-based
methods can improve prediction accuracy when compared to
existing CF approaches. However, we describe a more com-
prehensive cost-beneÔ¨Åt analysis by considering three accu-
racy beneÔ¨Åts against changes in recommendation coverage.         Figure 1: Recommendation Error.

2  A Computational Model of Trust                     opinions of the predicted ratings, or this might be conÔ¨Årmed
Intuitively, if a recommendation partner (proÔ¨Åle) has made by evaluating the user‚Äôs actions on the basis of the rating pre-
many good predictions in the past, it can be viewed as more dictions; if a user buys a highly rated item then we might
trustworthy than one with many poor predictions. The trust assume that the high rating was justiÔ¨Åed.
model [O‚ÄôDonovan and Smyth, 2005b] is based on this idea.
We differentiate between proÔ¨Åles generating recommenda- 2.2 Trust-Based Recommendation
tions (producer proÔ¨Åles) and those receiving recommenda- We incorporate our trust-model into CF by modifying the
tions (consumer proÔ¨Åles) in a particular recommendation ses- standard Resnick prediction algorithm in 3 ways to produce
sion. To generate a predicted rating, p(i), for item i for some 3 different trust-based variations. Resnick‚Äôs standard predic-
consumer c, conventional CF systems draw on the services tion formula is given in Equation 1. Normally it uses the
of a number of producer proÔ¨Åles, combining their individual similarity between the target user proÔ¨Åle and each recommen-
recommendations according to some suitable function, such dation partner proÔ¨Åle to weight their prediction contributions,
as Resnick‚Äôs formula. (see Equation 1). Our trust model de- shown as sim(c, p) in Equation 1; Equation 6 shows our mod-
pends on whether these predicted ratings are correct relative iÔ¨Åcations to this standard equation by adding the w(c, p, i)
to the true ratings of the consumer, c(i); see Equation 2. weighting term. Our Ô¨Årst variation (WItem) modiÔ¨Åes this so
                                                      that the weighting term is a combination of item trust and pro-
          Correct(i, p, c) ‚áî |p(i) ‚àí c(i)| <   (2)   Ô¨Åle similarity; we use the harmonic mean of trust and similar-
                                                      ity. The FItem approach differs in that it uses proÔ¨Åle similar-
2.1  Item-Level Trust                                 ity as the weight factor, but Ô¨Ålters out proÔ¨Åles that fall below a
We deÔ¨Åne the item-level trust for each producer p with respect given trust level for the target item prior to recommendation.
to a given proÔ¨Åle item i to be the percentage of times that p Finally, the CItem approach uses the obvious combination of
has made a correct rating prediction for i across some set WItem and FItem.
of consumers; see Equation 3. To do this we consider the                   X
rating that p alone predicts for i, for the consumer in question.             (p(i) ‚àí p)w(c, p, i)
We deÔ¨Åne the RecSet(p) (Equation 4) to be the total set of                pP (i)
                                                                r(i) = r +    X                       (6)
rating predictions that p has made; each (rk, ik) refers to a                     |w(c, p, i)|
rating prediction, rk that p has made for item ik. Similarly,                pP (i)
CorrSet(p) is the subset of these ratings that are considered
to be correct; Equation 5.                            3   Evaluation
                                                      For the following evaluation we use the 943 proÔ¨Åles from
                |{(r , i ) ‚àà CorrSet(p) : i = i}|
  T rustI (p, i) = k  k                k        (3)   the MovieLens data-set, split into 80% as training proÔ¨Åles
                |{(rk, ik) ‚àà RecSet(p) : ik = i}|     and the remaining 20% as test proÔ¨Åles. During training we
                                                      use a leave-one-out approach to build our trust model over
          RecSet(p) = {(r1, i1), ..., (rn, in)} (4)   the training proÔ¨Åles. BrieÔ¨Çy, each training proÔ¨Åle is used as
                                                      a consumer with the remaining acting as producers. Item-
                                                      level trust values are computed on the basis of the correct-
CorrSet(p) = {(ck, ik) ‚àà RecSet(p) : Correct(ik, p, ck)} ness or otherwise of the producer predictions. During testing,
                                                (5)   we evaluate the predictions of the training proÔ¨Åles for each
  Thus, the trust of p in relation to item i is a measure of how of the items in the test proÔ¨Åles using our 4 basic algorithms
often p‚Äôs predicted ratings for i have been considered correct (Resnick, WItem, FItem, CItem).
in the past. This information can be accumulated during the In this evaluation we are especially interested in the trade-
normal course of operation of a CF recommender system in off between the coverage of a recommender (the percentage
a variety of ways. For example, users could be asked their of items that a rating can be predicted for) (Figure 2) and                                                         recommender system. 1st Workshop on Friend of a Friend,
                                                         Social Networking and the Semantic Web. Galway, Ire-
                                                         land, 2004.
                                                      [Breese et al., 1998] John S. Breese, David Heckerman, and
                                                         Carl Kadie. Empirical analysis of predictive algorithms for
                                                         collaborative Ô¨Åltering. In Gregory F. Cooper and Seraf¬¥ƒ±n
                                                         Moral, editors, Proceedings of the 14th Conference on Un-
                                                         certainty in ArtiÔ¨Åcial Intelligence (UAI-98), pages 43‚Äì52,
                                                         San Francisco, July 24‚Äì26 1998. Morgan Kaufmann.
                                                      [Golbeck and Hendler, 2004] Jennifer Golbeck and James
                                                         Hendler. Accuracy of metrics for inferring trust and repu-
                                                         tation in semantic web-based social networks. In Proceed-
                                                         ings of EKAW‚Äô04, pages LNAI 2416, p. 278 ff., 2004.
         Figure 2: Recommendation Coverage.
                                                      [Kushmerick, 2002] N. Kushmerick. Robustness analyses of
                                                         instance-based collaborative recommendation. In T. Elo-
the error over these predictions (Figure 1). The error graph maa, H. Mannila, and H. Toivonen, editors, Proceedings of
shows a positive response to error for the trust-based meth- the European Conference on Machine Learning, Helsinki,
ods, especially those that employ trust-based Ô¨Åltering and in Finland., volume 2430, pages 232‚Äì244. Lecture Notes in
particular for the higher trust-levels. For example, at a trust Computer Science Springer-Verlag Heidelberg, 2002.
level of 0.9 only those proÔ¨Åles that have previously been cor-
rect 90% or more of the time that they have been called upon [Levien, 2003] Raph Levien. Attack resistant trust metrics.
to rate an item, are included as recommendation partners for Ph.D Thesis, UC Berkeley, 2003.
the Ô¨Ålter-based approaches (FItem and CItem). And for these [Massa and Bhattacharjee, 2004] Paolo Massa and Bobby
approaches we see signiÔ¨Åcant error reductions of up to 57% Bhattacharjee. Using trust in recommender systems: an
compared to the baseline Resnick. However, the coverage re- experimental analysis. Proceedings of 2nd International
sults indicate that these error reductions come at a cost. In Conference on Trust Managment, Oxford, England, 2004.
particular, the minimal error rates at the highest trust thresh- [O‚ÄôDonovan and Smyth, 2005a] John O‚ÄôDonovan and Barry
olds reduce coverage by over 90%, which is unlikely to be Smyth. Eliciting trust values from recommendation errors.
acceptable in most recommendation scenarios. However, for In Proceedings of the 18th International FLAIRS Confer-
trust thresholds below 0.5 we get signiÔ¨Åcant error reductions ence. AAAI Press, 2005.
while preserving coverage to a reasonable degree. In partic-
ular, the error for CItem is seen to drop most rapidly up to a [O‚ÄôDonovan and Smyth, 2005b] John O‚ÄôDonovan and Barry
trust threshold of 0.2, at which point it offers 85% coverage Smyth. Trust in recommender systems. In Proceedings
and an error of 0.71; Resnick‚Äôs error is 22% higher than this. of the 10th International Conference on Intelligent User
                                                         Interfaces, pages 167‚Äì174. ACM Press, 2005.
4  Conclusions                                        [O‚ÄôMahony et al., 2002] Michael P. O‚ÄôMahony, Neil Hurley,
We believe that computational models of trust can improve and Guenole C. M. Silvestre. An attack on collabora-
the effectiveness of recommender systems. We have shown  tive Ô¨Åltering. In Proceedings of the 13th Int. Conf. on
that by integrating an item-level model of trust into standard Database and Expert Systems Applications, pages 494‚Äì
collaborative Ô¨Åltering we can increase accuracy by up to 57% 503. Springer-Verlag, 2002.
by using only the top 1% most trustworthy proÔ¨Åles as recom- [O‚ÄôSullivan et al., 2002] Derry O‚ÄôSullivan, David C. Wilson,
mendation partners. While this beneÔ¨Åt comes at a signiÔ¨Åcant and Barry Smyth. Improving case-based recommenda-
coverage cost, more reasonable coverage can be achieved  tion: A collaborative Ô¨Åltering approach. In Proceedings
with reduced error rates by less drastic Ô¨Åltering thresholds. of the Sixth European Conference on Case Based Reason-
In addition to improving prediction accuracy, we believe that ing., pages LNAI 2416, p. 278 ff., 2002.
this trust-based approach may make recommenders more ro- [Resnick et al., 1994] Paul Resnick, Neophytos Iacovou,
bust to attack by malicious users, as discussed in [O‚ÄôMahony Mitesh Suchak, Peter Bergstrom, and John Riedl. Grou-
et al., 2002], [Levien, 2003] and [Kushmerick, 2002]. This is plens: An open architecture for collaborative Ô¨Åltering of
a matter that we will investigate as part of future work. netnews. In Proceedings of ACM CSCW‚Äô94 Conference
                                                         on Computer-Supported Cooperative Work, Sharing Infor-
5  Acknowledgments                                       mation and Creating Meaning, pages 175‚Äì186, 1994.
This material is based on works supported by Science Foun-
dation Ireland under Grant No. 03/IN.3/I361
References
[Avesani et al., 2004] Paolo Avesani, Paolo Massa, and
  Roberto Tiella. Moleskiing: a trust-aware decentralized