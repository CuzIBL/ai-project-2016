                          On Modeling Multiagent Task Scheduling
                    as a Distributed Constraint Optimization Problem

                  Evan A. Sultanik   and  Pragnesh Jay Modi     and  William C. Regli
                           {eas28,pmodi,wregli}@cs.drexel.edu
                Department of Computer Science, Drexel University, Philadelphia, USA


                    Abstract                            A key step towards addressing the distributed scheduling
                                                      problem is to devise appropriate representations. In this pa-
    This paper investigates how to represent and solve per, we have three goals in mind. We desire a representa-
    multiagent task scheduling as a Distributed Con-  tion that (a) captures the problem’s distributed multiagent as-
    straint Optimization Problem (DCOP). Recently     pects, (b) gives formal guarantees on solution quality, and (c)
    multiagent researchers have adopted the C TÆMS    is amenable to distributed solving by existing methods.
    language as a standard for multiagent task schedul-
                                                        In regard to goal (a), the Coordinators Task Analysis En-
    ing. We contribute an automated mapping that
                                                      vironmental Modeling and Simulation (C TÆMS) represen-
    transforms C TÆMS  into a DCOP. Further, we
                                                      tation [Boddy et al., 2006] is a general language (based on
    propose a set of representational compromises for
                                                      the original TÆMS language [Decker, 1996]) that was jointly
    C TÆMS  that allow existing distributed algorithms
                                                      designed by several multiagent systems researchers explic-
    for DCOP to be immediately brought to bear on
                                                      itly for multiagent task scheduling problems. C TÆMS is a
    C TÆMS  problems. Next, we demonstrate a key
                                                      Hierarchical Task Network (HTN) style representation where
    advantage of a constraint based representation is
                                                      the task nodes in the network have probabilistic utility and
    the ability to leverage the representation to do efﬁ-
                                                      duration. C TÆMS  is an extremely challenging class of
    cient solving. We contribute a set of pre-processing
                                                      scheduling problem and has been adopted as a common chal-
    algorithms that leverage existing constraint propa-
                                                      lenge problem domain representation for distributed multia-
    gation techniques to do variable domain pruning on
                                                      gent task scheduling research.
    the DCOP. We show that these algorithms can result
    in 96% reduction in state space size for a given set We propose a distributed constraint reasoning approach
                                                                                           TÆMS
    of C TÆMS problems. Finally, we demonstrate up    for solving problems expressed in the C    language.
    to a 60% increase in the ability to optimally solve Our methodology is one of problem transformation in which
                                                                                        TÆMS
    C TÆMS  problems in a reasonable amount of time   we create a mapping that converts a C   instance into
    and in a distributed manner as a result of applying an instance of the Distributed Constraint Optimization Prob-
    our mapping and domain pruning algorithms.        lem (DCOP)  [Modi et al., 2005]. DCOP was devised to
                                                      model constraint reasoning problems where several agents
                                                      must communicate to ensure that solutions are globally op-
1  Introduction                                       timal. Several distributed algorithms for DCOP currently ex-
The coordinated management of inter-dependent plans or ist in the literature including distributed dynamic program-
schedules belonging to different agents is an important, com- ming (DPOP [Petcu and Faltings, 2005]), cooperative media-
plex, real-world problem. Diverse application domains such tion (OptAPO [Mailler and Lesser, 2004]) and asynchronous
as disaster rescue, small-team reconnaissance, security pa- backtracking (Adopt [Modi et al., 2005]).
trolling and others require human teams to schedule their The expressivity of C TÆMS comes at a cost; it is arguable
tasks and activities in coordination with one another. It is that the primary concern in the design of the C TÆMS lan-
envisioned that automated planning and scheduling processes guage was to comprehensively express the complexities of
in the form of agents operating on portable computing hard- the distributed scheduling problem, while less concern was
ware can assist human teams in such domains. The prob- placed on goals (b) and (c) enumerated above. Indeed, current
lem is inherently a distributed one; an agent that manages the distributed solution techniques cannot be applied straightfor-
schedule of a human user must effectively manage the inter- wardly or are unable to provide solution quality guarantees.
dependencies between its schedule and the schedules of other Thus, to make progress on this difﬁcult problem, we con-
users by exchanging information and coordinating with other tribute a set of representational compromises in the form of
agents. No single agent has a global view of the problem; a subset of C TÆMS, called DSC TÆMS, that is soluble by
instead, each must make local planning and scheduling deci- current DCOP algorithms.
sions through collaboration with other agents to ensure a high Finally, we demonstrate three key advantages of our con-
quality global schedule.                              straint based approach. First, we provide a mapping that au-

                                                IJCAI-07
                                                  1531tomatically transforms a C TÆMS problem into an equiva- 3.1 Distributed Constraint Optimization
lent DCOP. That is, the optimal solution to a given C TÆMS A DCOP is a subclass of distributed decision processes in
problem is also the optimal solution to the DCOP obtained which a set of agents are responsible for assigning the values
by applying our problem transformation mapping, i.e., our of their respective variables subject to a set of constraints. A
mapping preserves the problem exactly. Second, arguably DCOP can be deﬁned as a tuple A, V, D,F,α,σ, where
one of the primary advantages of adopting a constraint based A is a set of agents;
approach is the ability to apply existing constraint propaga- V is a set of variables, {v1,v2,...,v|V |};
tion techniques from the constraint programming literature. D is a set of domains, {D1,D2,...,D|V |}, where each
Thus, we leverage our problem transformation by applying    D ∈  D is a ﬁnite set containing the feasible values
constraint propagation pre-processing techniques to perform for its associated variable;
domain pruning to signiﬁcantly reduce the search space. We F is a set of |V |2 cost functions, one for each pair of
demonstrate a 96% reduction in state space size for a set of variables, such that fij : Di × Dj → N0 ∪ {∞}.
benchmark problems. Finally, another advantage of our ap-   Each cost function maps every possible variable as-
proach is that by mapping the C TÆMS problem into a DCOP,   signment to its associated cost, for all pairs of vari-
we are able to immediately apply existing solution techniques ables and for all possible assignments. These func-
for DCOP to the C TÆMS problem domain.                      tions can also be thought of as constraints;
                                                       α    is function α : V → A mapping variables to their
                                                            associated agent. α(vi) → aj means that it is aj’s
2  Related Work                                             responsibility to assign the value of vi; and
                                                       σ    is a function σ : F → N0 that aggregates the indi-
Numerous techniques have been  employed  to address         vidual costs1.
the problem of multiagent coordination and scheduling. The objective of a DCOP is to have each agent assign val-
Musliner, et al., map C TÆMS to a Markov decision pro- ues to its associated variables in order to minimize σ(F )
cess which is then used to generate a policy dictating when for a given assignment of the variables. This deﬁnition was
and how agents execute methods [Musliner et al., 2006]. adapted from [Davin and Modi, 2005] and has been modiﬁed
Musliner, et al., also propose distributed constraint sat- for the sake of brevity, clarity, and applicability.
isfaction as a method for negotiating a feasible schedule
by maximizing previously-calculated local expected quali- 3.2 C TÆMS
   [                  ]
ties Musliner et al., 2006 . Smith, et al., address the prob- C TÆMS is a derivative of the TÆMS modeling lan-
lem of dynamic schedule revision (due to changes in the guage [Decker, 1996] and can be used for representing in-
                                  [              ]
model) using Simple Temporal Networks Smith et al., 2006 . stances of task domains of the distributed multiagent schedul-
Phelps and Rye address this same problem through a domain- ing problem. Unlike other HTN representations, C TÆMS
independent implementation of Generalized Partial Global emphasizes modeling of the interrelationships between tasks
Planning, in which proxy methods allow for distributed ap- more so than those between agents and their environ-
proximation of the performance characteristics of potentially ment [Musliner et al., 2006]. For the sake of exposition and
            [                  ]
complex tasks Phelps and Rye, 2006 .                  formalism, we represent C TÆMS instances using set theory,
  Constraint propagation is a general family of techniques whereas the actual speciﬁcation is a grammar. We represent
that check a constraint based representation for consistency to aC TÆMS instance as a tuple N,M , T ,G,μ,φ,ω, where
reduce problem search space, often in a pre-processing phase. N is a set of agents;
Bartak´ provides a survey of the general topic in [Bartak,´ M is a set of methods;
2001]. One of the primary advantages of adopting a con- T   is a set of tasks;
straint based approach is the ability to apply constraint prop- E is a set of “Non-Local Effects”;
agation techniques such as node, arc and path consistency. As G is a special task known as the “Task Group;”
such, constraint propagation is well-studied with several algo- μ is a function μ : M → A;
rithms available that vary in complexity and pre-processing φ is a function φ : M ∪ T → T ∪ {∅} that maps
resource requirements. The ﬁrst arc consistency algorithms  methods and tasks to their parent task; and
were formalized in [Mackworth, 1977] including the widely ω is a quality accumulation function ω : M ∪ T →
used AC-3 algorithm. Bessiere,` et al., improve on average- R+ ∪{0} that returns the quality of a method or task.
case efﬁciency with the AC-6 and AC-7 algorithms [Bessiere` For T ∈ T , ω(T ) is usually deﬁned as a function of
et al., 1999]. More recently, researchers have introduced dis- the associated qualities of all X ∈ φ−1(T ).
tributed methods for arc consistency processing including the Each M ∈ M is itself a tuple, l, u, d, where
DisAC-9 algorithm [Hamadi, 2002] and the DMAC proto-   l    is the earliest start time of the method;
col [Silaghi et al., 2001].                            u    is a deadline for the method; and
                                                       d    is the expected duration of the method.
                                                      Note that l ≤ u,butl + d might not necessarily be less than
3  Formalization                                      or equal to u. Each T ∈ T is deﬁned as a similar tuple,
                                                      except tasks (as a type of virtual method aggregator) do not
This section formalizes the notion of a DCOP and speciﬁes
                                                         1
the subset of C TÆMS on which we focus.                  We use the notation “N0” to denote the non-negative integers.

                                                IJCAI-07
                                                  1532have explicit durations. Also, these bounds on execution time solving problems containing greater-than-binary con-
are inherited from parents. In other words, lφ(X) ≤ lX and straints is still an open problem [Modi et al., 2005].
uφ(X) ≥ uX . It is assumed that φ creates parent-child rela- Finite Domains. Regardless of how the problem is repre-
tionships such that the resulting hierarchy is a tree rooted at sented, time must be discretized since both the number
G. The range of φ ensures that all methods are leaves.    of variables and the cardinality of variables’ domains
  C TÆMS  prescribes four primary types of quality accumu- must be ﬁnite.
lation function (QAF): SUM,MIN,MAX, and SYNCSUM (the
qualities of the children are summed if and only if all of the 4.2 Method
children are scheduled to start execution at the same time). The representational challenge is met by creating one DCOP
  E is a tuple containing sets of functions, called “Non-Local variable for each method; the variables will be assigned the
Effects” (NLEs) in C TÆMS, that deﬁne temporal precedence start times of their associated methods. The variables’ do-
constraints between methods and tasks: E,D,F,H. Each mains will therefore contain the feasible start times of the
function in each of the sets maps pairs of methods and tasks associated method. Time is discretized into quanta for the
to a boolean; if the function maps to TRUE, then the associ- domains. Likewise, the probability distributions in C TÆMS
ated NLE holds for that pair of methods/tasks. E contains a are discretized using expected values.
set of hard “enables” NLEs (if X enables Y , then Y cannot For each agent in the C TÆMS instance, n ∈ N, create
execute until X has accumulated positive quality). D is a set an associated DCOP agent, a ∈ A. For each method, M ∈
of “disables” NLEs, which is the opposite of an enables NLE. M , create an associated variable vM ∈ V . Therefore, the
Finally, F and H are respectively “facilitates” and “hinders,” α function of the DCOP can be deﬁned as an analog of the
both being soft NLEs that either increase or decrease the qual- μ function of C TÆMS. The domains of the variables will
ity of targeted methods/tasks depending on the quality of the contain all possible start times of the method (including an
source method/task.                                   option for the method to forgo execution). In order to encode
  A “schedule” is a grammar within the C TÆMS speciﬁca- the mutex constraints,
tion for deﬁning the chosen start times of methods; it can be                  −1       −1
                                                        (∀n ∈ N :(∀(Mi,Mj)  ∈ μ   (n) × μ  (n):
formalized as a function s : M → N0 ∪ {∅}. A start time
                                                                    f  (x ∈ D ,y ∈ D ) →∞
of ∅ means that the method will not be executed. A feasible          ij      i      j              

schedule obeys both mutex and precedence constraints (i.e. an when (x<y<x+   dMi ) ∨ y<x<y+     dMj )).
agent may not execute more than one method at a time and all
                                                      In other words, for all agents n ∈ N ﬁnd all pairs of methods
NLEs are obeyed). The objective is to create a feasible sched-
                                                      Mi and Mj that share agent n and create a hard DCOP con-
ule that maximizes ω(G).
                                                      straint (i.e. of inﬁnite cost) for all pairs of equal domain val-
                                                      ues for the associated variables. This will ensure that an agent
4  Mapping    C  TÆMS  to a DCOP                      may not execute multiple methods at once. NLEs (i.e. prece-
The basis of our approach is to map a given C TÆMS rep- dence constraints) are encoded similarly. For example, the
resentation of a distributed scheduling problem to an equiva- enables NLEs are encoded as follows. Each e ∈ E is a func-
lent DCOP whose solution leads to an optimal schedule. The tion e :(M ∪T )×(M ∪T ) → B mapping pairs of methods
technical challenge lies in ensuring that the resulting DCOP’s and tasks to a boolean. Let ϕ : T × (M ∪ T ) → B be a
solution leads to an optimal schedule. The following sections function such that ϕ(X, Y ) → TRUE ⇐⇒ φ(X) → Y , and
                                                          +                            +
formalize the approach.                               let ϕ be the transitive closure of ϕ. ϕ (X, Y ) implies that
                                                      X  is in the subtree rooted at Y . Therefore,
4.1  Challenges
                                                        e(X, Y )=⇒   (∀X,Y | ϕ+(X,X) ∧ X is a method
DCOPs are a promising solution technique, but there exist             +          
several challenges that must ﬁrst be addressed:                   ∧ ϕ  (Y ,Y) ∧ Y  is a method :
                                                          X                                Y       ).
Representation. There are different semantics in which the   must have ﬁnished executing before can start
    problem can be represented: one could have a variable In other words, e(X, Y ) means that all methods in the subtree
    for each method in the C TÆMS instance that is assigned rooted at X must have ﬁnished executing before any of the
    the value of its start time, or one could have a variable for methods in the subtree rooted at Y may be executed2.For
                                                                                     +
    each instance in time that will be assigned the method each e ∈ E, if the transitive closure e (X, Y ) maps to TRUE,
    that will be executed at that time.               X  is said to precede Y in an “NLE chain.” Then,
Determinism. C TÆMS  prescribes probability distributions (∀e ∈ E :(∀X, Y  |  e(X, Y ):
    over certain parameters, such as method duration, which      (∀M  ,M   |  ϕ+(M  ,X) ∧ M  ∈ M  ∧
    is a problem since DCOPs are deterministic.                      i  j           i       i
                                                                               +
Aggregation Functions. DCOP solution algorithms do not                        ϕ  (Mj,Y) ∧ Mj  ∈ M
                                       σ
    allow for arbitrary aggregation functions ( ). For exam-               :  fij(x ∈ Di,y ∈ Dj) →∞
    ple, ADOPT requires associativity, commutativity, and
                                                                              when y<x+    dM ))).
    monotonicity of the aggregation function in order to en-                                 i
    sure optimality [Modi et al., 2005].                 2Note that this deﬁnition is slightly more restrictive than that
n-ary Constraints. Although DCOPs allow for constraints of [Boddy et al., 2006], in which Y cannot execute until X has
    of arbitrary arity, discovery of efﬁcient algorithms for accumulated positive quality: ω(X) > 0.

                                                IJCAI-07
                                                  1533  Finally, create one soft |M |-ary constraint between all of aC TÆMS instance in which all methods have an earliest start
the variables that aggregates the QAFs in the HTN.    time of zero. In this case, assuming all of the methods will
                                                      be executed, the optimal start time of a method cannot be
4.3  DCOP-Solvable   C TÆMS                           greater than the sum of the expected durations of all of the
The fundamental shortcoming of the mapping proposed in the other methods. In the general case of heterogeneous earliest
previous section is the use of n-ary constraints, which are ex- start times, we can deﬁne an upper bound on the start time of
tremely inefﬁcient (and often not supported) by current solu- a method M as the maximum ﬁnite earliest start time in M
tion techniques. DCOP-Solvable C TÆMS (DSC TÆMS)is    plus the duration of all other methods.
our proposed a subset of C TÆMS that allows for immediate
application of current DCOP algorithms.               5.2  Bound Propagation
  DSC  TÆMS  consists of only enables and disables NLEs, Although the nature of the distributed scheduling problem im-
and may only contain either: (1) all SUM and SYNCSUM  plies that a child’s bounds are inherited from (and therefore
QAFs; (2) all MAX QAFs; or (3) all MIN QAFs. In each case
                                                      cannot be looser than) its parent’s, C TÆMS neither requires
the mapping is exactly the same as that previously introduced,
           | |                                 |  |   nor enforces this. Bounds can be propagated down the tree
however, the M -ary soft constraint is decomposed into M from the root to improve upon the na¨ıve bounding. A dis-
unary constraints. Add one unary soft constraint for all meth-
                     (∀M   ∈ M  : f (∅) → ω (M ))    tributed method for implementing this procedure (requiring
ods’ variables as follows: i      i          i .      only local knowledge) is given in Algorithm 1. To calculate
  If a method is not scheduled to execute, its unary con- the bounds for the methods of agent a, the algorithm would
straint will have a cost equal to the quality that the method
                                                      be invoked as RECURSE-EXEC-BOUNDS(a, G, C, 0, ∞).
would have contributed to G had it been executed. This map-
ping will produce a DCOP with |M| variables and worst-case
O(|M|2) constraints. In case 1, when all of the QAFs are Algorithm 1 RECURSE-EXEC-BOUNDS(a, T, C, , υ)
summation, use summation for DCOP aggregation function Require: a is the agent from whose perspective we will create the bounds, T is the task
σ                                      σ                 rooting the tree whose bounds we will create, C is a C TÆMS problem instance, 
 . Likewise, in case 2, use maximization for . Finally, in is a lower bound on the bounds of T , and υ is an upper bound on the bounds of T .
the case of minimization, one can create the dual of the mini- Ensure: βa : T → (N0 ∪{∞}) × (N0 ∪{∞}) is a function mapping all tasks in
                                                                     T
mization problem and apply the MAX aggregation function. the subtree rooted at to lower and upper bounds on their start times. The subscript
                                                         a exists to emphasize the point that each agent has its own β function; the mapping
  It is theoretically possible to extend DSC TÆMS to allow of each β function is contingent upon the extent of knowledge the agent has been
for cases in addition to the three listed above, assuming n-ary given within the problem instance.
                            n                         1: l ← 
constraints are feasible for small . For example, one could 2: u ← υ
encode a DCOP containing all four types of QAF by adding 3: if VISIBLE-TO?(C, T, a) then
an n-ary soft constraint for each maximal subtree of the HTN 4: e ←EARLIEST-START-TIME(C, T )
                                                      5:  d ←DEADLINE(C, T )
that is rooted by either a MAX or MIN QAF, adding a unary 6: if e = ∞∧e>lthen
soft constraint (as usual for DSC TÆMS) for each method not 7: l ← e
a member of one such maximal subtree.                 8:  end if
                                                      9:  if d = −∞ ∧ d<uthen
                                                      10:   u ← d
  (∀Ti ∈ T | ω(Ti) is MAX or MIN ∧                    11:  end if
           +                                          12: end if
   (∀Tj ∈ ϕ (Ti,Tj):ω(Tj)  is SUM or SYNCSUM):        13: βa(T )  → (l, u)
            n                                         14: for all S ∈SUBTASKS(C, T ) do
    Create an -ary soft constraint encoding the QAFs  15:  if IS-METHOD?(C, S) then
                                                                   S
                         in the subtree rooted at Ti). 16:  This means is a method (i.e. a special type of task)
                                                      17:   if VISIBLE-TO?(C, S, a) then
                                                      18:     lm ← l
  A detailed analysis of the correctness and complexity of 19: um ← u
our mapping is available in [Sultanik, 2006].         20:     e ←EARLIEST-START-TIME(C, S)
                                                      21:     d ←DEADLINE(C, S)
                                                      22:     a ←EXPECTED-DURATION(C, S)
5  Efﬁciency Optimizations                            23:     if e = ∞∧e>lm then
                                                      24:      lm ← e
Nothing thus far in the mapping precludes domains from be- 25: end if
ing inﬁnite, which is one of the challenges (and limitations) 26: if d = −∞ ∧ d − a<um then
                                                      27:      um ← d
of using DCOP. From a practical standpoint, this is also a 28: end if
problem because most DCOP solution techniques have expo- 29:  βa(S)  → (lm,um)
nential computational complexity with respect to both the do- 30: end if
                                                      31:  else
main size and number of variables. Since the number of vari- 32: This means S is a regular task.
ables is generally inﬂexible, not only do we need to make the 33: RECURSE-EXEC-BOUNDS(a, S, C, l, u)
                                                      34:  end if
domains ﬁnite but we ideally need to make them as small as 35: end for
possible while ensuring that the solution space of the DCOP
still contains the optimal solution.
5.1  Na¨ıve Domain Bounding                           5.3  Constraint Propagation
It is possible to create a ﬁnite (although not necessarily tight) A binary constraint, fij,isarc consistent if
upper bound on the start times of the methods. Let us consider (∀di ∈ Di :(∃dj ∈ Dj : fij (di,dj) = ∞)). A DCOP

                                                IJCAI-07
                                                  1534is said to be arc consistent if all f ∈ F are arc consis- versus days. This necessitated a threshold—that we’ve set
tent [Bartak,´ 2001]. We use forward constraint propagation to 10,000 DCOP cycles—above which a C TÆMS instance
down the NLE chains to prune the domains, ensuring arc is simply declared “insoluble.” We have not found a single
consistency of the DCOP. A distributed method for constraint C TÆMS instance that has been soluble in greater than 5000
propagation is given in Algorithm 2. Note that this algorithm cycles (given a reasonable amount of computation time).
makes use of a function BROADCAST-BOUNDS(C, βa,a),      We used the DCOP algorithm Adopt [Modi et al., 2005]
which has the following postcondition: agent a’s bounds will to solve the resulting DCOPs. Of the 100 random prob-
be broadcast to all other agents that share an NLE with the lems, none were soluble by the na¨ıve domain bounding ap-
method/task associated with the given bound. Algorithm 2 proach. Applying bound propagation (Algorithm 1) to the
works by having agents continually broadcast their current na¨ıve bounding resulted in 2% of the problems becoming sol-
start time bounds for their methods; if they receive a bound uble. Applying all of our methods resulted in 26% solubil-
that violates arc consistency, they increase the lower bound ity. Using an upper one-sided paired t-test, we can say with
on their method’s start time until the constraint is arc 95% certainty that Algorithm 2 made an average domain size
consistent and re-broadcast the new bounds. Since the lower reduction of 7.62% over the domains produced from Algo-
bounds monotonically increase and are bounded above, the rithm 1. If we look at this reduction in terms of state space
algorithm must terminate. An analysis of the messaging size, however, it becomes much more signiﬁcant: an average
overhead of this algorithm is presented in §6.        94% decrease in state space size. Table 1 presents the state
                                                      space reduction efﬁciency of our constraint propagation tech-
Algorithm 2 DIST-CONSTRAINT-PROP(C, βa,a,Q)           nique in terms of problem solubility. Since constraint prop-
Require: C is a C TÆMS problem instance and βa is the associated bound function agation was fairly consistent in the percentage of state space
   for the agent, a, that is running this instance of the algorithm. Q is a queue that reduced between those problems that were soluble and those
   is continuously updated with incoming broadcasts.
 1: BROADCAST-BOUNDS(C, β, a)                         that were insoluble, this suggests that the 74% of the prob-
 2: while Q = ∅ do                                   lems that remained insoluble were due to the large state space
 3:  f, r, s, t, (l, u)←POP(Q)                      size inherent in their structure. For example, the insoluble
 4:  if r =SOURCE then
 5:   βa(s)  → (l, u)                                 problems’ state spaces were, on average, one million times as
 6:   ls ← l                                          large as those that were soluble.
 7:   us ← u
 8:   (lt,ut) ← βa(t)                                   We also conducted tests over C TÆMS problems of differ-
 9:  else                                             ing complexity (by varying the number of windows and NLE
      β (t)  → (l, u)
10:    a                                              chains). The number of windows is correlated to the number
11:   lt ← l
12:   ut ← u                                          of variables in the resulting DCOP, while the number of NLEs
13:   (ls,us) ← βa(s)                                 is correlated to the number of constraints. These data are pre-
14:  end if
15:  δ ← ls+EXPECTED-DURATION(C, s) − lt              sented in Table 2. Notice that problems bounded na¨ıvely were
16:  if δ>0 ∧ lt + δ ≤ ut then                        never soluble. Over the most complex problems with 6 win-
17:   βa(t)  → (lt + δ, ut)                           dows and 3 NLEs chains, Algorithm 2 required an average of
18:   βa(t)  → (lt + δ, ut)
19:   BROADCAST-BOUNDS(C, βa,a)                       144.94 messages (with a standard deviation of 16.13). This
20:  end if                                           was negligible in comparison to the number of messages re-
21: end while                                         quired to arrive at an optimal solution.

6  Results                                            7   Discussion
Using the C TÆMS scenario generator created for DARPA’s
                                                      We have presented a mapping from the C TÆMS modeling
COORDINATORs project, we randomly-generated a set of
                                                      language to an equivalent DCOP. We have shown that the
100 C TÆMS  instances, each with four agents, three-to-four
                                                      resulting DCOP of a subset of this language, DSC TÆMS,
windows3, one-to-three agents per window, and one-to-three
                                                      is soluble using existing techniques, and whose solution is
NLE chains. The scenario generator does not ensure the ex-
                                                      guaranteed to lead to an optimal schedule. We have empir-
istence of a feasible schedule for its resulting C TÆMS in-
                                                      ically validated our approach, using various existing tech-
stances. Even with the small simulation parameters and us-
                                                      niques from the constraint processing literature, indicating
ing all of our domain reduction techniques, the average state
                                                      that these problems are in fact soluble using our method.
space size of these problems was astronomical: on the order
of 1077. Therefore, some of the problems inevitably require We are optimistic in extending our mapping to sub-
inordinate amounts of computation time. There seems to be sume a larger subset of C TÆMS. There are also various
a phase transition in the problems, such that some are soluble heuristic techniques in the literature, such as variable order-
within the ﬁrst couple thousand cycles of the DCOP algo- ing [Chechetka and Sycara, 2005], that can be applied to the
rithm, while the rest keep searching for an optimal solution mapping while retaining formal guarantees on solution qual-
into the millions of cycles. In terms of computation time, this ity. If the resulting schedule need not be optimal (i.e. feasibil-
equates to several orders of magnitude difference: seconds ity is sufﬁcient), approximation techniques for DCOPs exist.
                                                        With the groundwork laid in solving distributed multiagent
  3“Windows” are tasks whose parent is the task group (i.e., they coordination problems with distributed constraint optimiza-
are tasks at the second layer from the root in the HTN). tion, we have many extensions in which to investigate.

                                                IJCAI-07
                                                  1535