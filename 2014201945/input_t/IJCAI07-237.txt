      Gossip-Based Aggregation of Trust in Decentralized Reputation Systems

                Ariel D. Procaccia  and  Yoram Bachrach     and  Jeffrey S. Rosenschein
                             School of Engineering and Computer Science
                                  The Hebrew University of Jerusalem
                                    {arielpro,yori,jeff}@cs.huji.ac.il


                    Abstract                          the database soon becomes a bottleneck of the system. More-
                                                      over, this approach is not robust to failures. Previous work
    Decentralized Reputation Systems have recently    on decentralized reputation schemes suffered from their own
    emerged as a prominent method of establishing     major problems: agents have to maintain complex data struc-
    trust among self-interested agents in online envi- tures, evaluation of trust is based only on local information,
    ronments. A key issue is the efﬁcient aggregation or there are restrictive assumptions on the trust model.1
    of data in the system; several approaches have been We approach this hornets’ nest by designing a novel
    proposed, but they are plagued by major shortcom- method of trust aggregation (i.e., a reputation system’s data
    ings.                                             management scheme). The method is demonstrated in this
    We put forward a novel, decentralized data man-   paper for a simple trust model, but it can be extended to more
    agement scheme grounded in gossip-based algo-     complex models.
    rithms. Rumor mongering is known to possess al-     The roots of our gossip-based approach can be traced to a
    gorithmic advantages, and indeed, our framework   seminal paper by Frieze and Grimmett [1985]: a rumor starts
    inherits many of their salient features: scalabil- with one agent; at each stage, each agent that knows the ru-
    ity, robustness, globality, and simplicity. We also mor spreads it to another agent chosen uniformly at random.
    demonstrate that our scheme motivates agents to   The authors show that the rumor reaches all agents quickly
    maintain a sparkling clean reputation, and is inher- (a result that coincides with real life). We directly rely on
    ently impervious to certain kinds of attacks.     more recent results, surveyed in the next section. It has been
                                                      shown that aggregate information, such as averages and sums
                                                      of agents’ inputs, can be calculated using similar methods of
1  Introduction                                       uniform gossip in a way that scales gracefully as the number
In open multiagent environments, self-interested agents are of agents increases. Furthermore, the approach is robust to
often tempted to employ deceit as they interact with others. failures, and the results hold even when one cannot assume a
Fortunately, dishonest agents can expect their victims to re- point-to-point connection between any two agents (as is the
taliate in future encounters. This “shadow of the future” mo- case in peer-to-peer [P2P] networks).
tivates cooperation and trustworthiness.                In our setting, each agent merely keeps its private evalua-
  However, as the size of the system grows, agents have an tion of the trustworthiness of other agents, based on its own
increasingly small chance of dealing with another agent they interactions.2 When an agent wishes to perform a transaction
already know; as a consequence, building trust in domains with another, it obtains the average evaluation of the other’s
teeming with numerous agents becomes much harder. Repu- reputation from all agents in the system, using a gossip-based
tation systems address this problem by collecting and spread- technique. Although the presented algorithms estimate the
ing reports among agents, so that agents may learn from oth- average reputation, they can be easily adapted to estimating
ers’ experience. To put it differently, agents are intimidated whether a certain agent has a high reputation in the eyes of
by the “shadow of the future” today, even though tomorrow the majority of the agents, or certain other similar metrics.
they are most likely to meet total strangers.         Thus, the framework we advocate for aggregating reputation
  Reputation systems can be decomposed into two major information accommodates more sophisticated trust models.
components: 1) the trust model, which describes whether an Some advantages are immediately self-evident. Each agent
agent is trustworthy, and 2) the data management scheme. stores very little information, which can be simply and efﬁ-
The latter component poses some interesting questions, since ciently organized, and evaluation of trust is based on global
it is imperative to efﬁciently aggregate trust-related informa- information. Additionally, this framework inherits the advan-
tion in the system. A simple solution is maintaining a central
database that contains the feedback gathered from past trans- 1The “or” is not exclusive.
actions. Unfortunately, this solution is inappropriate in dis- 2The question of how agents set this valuation is outside the
tributed environments where scalability is a major concern, as scope of this paper.

                                                IJCAI-07
                                                  1470tages of gossip-based algorithms: scalability, robustness to 2. The size of all messages sent at time t by PUSH-SUM is
failure, decentralization, and as a consequence, applicability O(t +maxi bits(xi)), where bits(xi) is the number of
in peer-to-peer networks.                                 bits in the binary representation of xi.
  We show that our scheme has two other major advantages. A major advantage of gossip-based algorithms is their ro-
An important desideratum one would like a reputation sys- bustness to failures: the aggregation persists in the face of
tem to satisfy is motivating agents to maintain an untarnished failed nodes, permanent communication failures, and other
reputation, i.e., to be absolutely trustworthy (as opposed to, unfortunate events. Further, no recovery action is required.
say, being generally trustworthy but occasionally cheating). The assumption is that nodes can detect whether their mes-
We show that our data management scheme, together with an sage has reached its destination; PUSH-SUM is modiﬁed so
extremely simple trust model, satisﬁes this property. We also that if a node detects its target failed, it sends its message to
demonstrate that our scheme is inherently resistant to some itself.
attacks (with no assumptions on the trust model). This is a Theorem 2 ([Kempe et al., 2003]). Let μ<1 be an upper
positive side effect of the exponential convergence rates of bound on the probability of message loss at each time step,
the algorithms we use.                                and let U  be the diffusion speed of uniform gossip with faults.
  In this paper we do not address the problem of designing Then:
a trust model. Rather, we suggest an approach for agents to                    2
                                                                 U  (n, δ, )=       U(n, δ, ).
aggregate distributed trust information so as to decide with                 (1 − μ)2
whom to carry out transactions.                         In several types of decentralized networks, such as P2P net-
                                                      works, point-to-point communication may not be possible. In
2  Gossip-Based Information Aggregation               these networks, it is assumed that at each stage nodes send
In this section, we survey the relevant results of Kempe, Do- messages to all their neighbors (ﬂooding). When the under-
bra and Gehrke [Kempe et al., 2003]. These algorithms allow lying graph is an expander, or at least expected to have good
us to estimate the average of values held at network nodes (in expansion, results similar to the above can be obtained. Fortu-
our case, these values will be the reputation values concern- nately, it is known that several peer-to-peer topologies induce
ing a particular agent). [Kempe et al., 2003] also shows how expander graphs [Pandurangan et al., 2001].
to calculate other functions over these values, such as the ma- In the rest of the paper, we have xi ≤ 1, and in particular
jority function and sum. Thus our algorithms can be adapted i xi ≤ n. Therefore, it is possible to redeﬁne U to be an
for other, more sophisticated models of trust.        upper bound on the number of turns required so that for all
                                                                                           s          
                                       USH   UM                                             t,i  1
  We begin by describing a simple algorithm, P -S ,to t ≥ U and all nodes i,theabsolute error  w − n k xk
compute the average of values at nodes in a network. There                                  t,i
                                                      is at most  with conﬁdence 1 − δ, and it still holds that
are n nodes in the system, and each node i holds an input
                                                      U(n, δ, )=O(log n +log1  +log1  ). Hereinafter, when
xi ≥ 0. At time t, each node i maintains a sum st,i and a                      δ      
                                                      we refer to U we have this deﬁnition in mind.
weight wt,i. The values are initialized as follows: s0,i = xi,
                                                      Remark 1. The protocol PUSH-SUM is presented in terms of
w0,i =1. At time 0, each node i sends the pair s0,i,w0,i to
itself; at every time t>0, the nodes follow the protocol given a synchronized starting point, but this assumption is not nec-
as Algorithm 1.                                       essary. A node that poses the query may use the underlying
                                                      communication mechanism to inform all other nodes of the
Algorithm 1                                           query; convergence times are asymptotically identical.
 1: procedure PUSH-SUM                                3   Our Framework
 2:   Let {(ˆsl, wˆl)}l be all the pairs sent to i at time t − 1
                                                      Let the set of agents be N = {1,...,n}. Each agent i ∈ N
 3:   st,i ← l sˆl
                                                                    rj ∈  ,               j ∈ N
 4:   wt,i ←    wˆl                                   holds a number i   [0 1] for each agent   (including
               l                                                                j
 5:   Choose a target ft(i) uniformly at random       itself). This number represents ’s reputation with respect to
                   1    1
                    st,i, wt,i  i      ft i           i, or to put it differently, the degree to which i is willing to
 6:   Send the pair ( 2 2   ) to and to ( )
       st,i                                               j
 7:       is the estimate of the average at time t    trust . As agents interact, these assessments are repeatedly
       wt,i                                           updated. We do not in general concern ourselves with how
 8: end procedure
                                                      agents set these values.
                                                        When an agent i is deliberating whether to deal with an-
     U  n, δ,                                                  j i
  Let  (    ) (the diffusion speed of uniform gossip) be an other agent , wishes to makeP an informed evaluation of the
                                                                                 rj
upper bound on the number of turns PUSH-SUM requires so                   j     k k
                                                      other’s reputation. Let r¯ = n be the average of j’s rep-
that for all t ≥ U(n, δ, ) and all nodes i,                                                      j
                                                    utation with respect to all agents. Knowledge of r¯ would
                                                       i                           j
              1     st,i  1                         give a good idea of how trustworthy is (this is, of course,
                 ·    −       xk ≤                a simple model of trust).
                xk wt,i   n      
              k               k                         We show that in this scenario, agents can use gossip-based
(the relative error is at most ) with probability at least 1 − δ. algorithms to decide with whom to carry out transactions.
                                                      Also, in such a setting, agents are encouraged to keep a com-
Theorem 1 ([Kempe et al., 2003]).                     pletely untarnished reputation. Similar results can be ob-
                           1      1
 1. U(n, δ, )=O(log n +logδ +log  ).                tained for more complex trust models.

                                                IJCAI-07
                                                  1471Algorithm 2                                           good reputation, that only occasionally cheats, would proba-
                                             j
 1: procedure EVA L -TRUST(i, j, δ, ) ievaluates r¯ with bly be able to win the conﬁdence of peers; there is seemingly
   accuracy , conﬁdence 1 − δ                        no reason why an agent should not play false now and again.
 2:   for all k ∈ N do                                Nevertheless, we consider in this section an extremely simple
                j                                     and general trust model, and show that with the data manage-
 3:       xk ← rk         Inputs to PUSH-SUM are j’s
   reputation w.r.t. agents                           ment scheme that we have presented, there is a social beneﬁt
 4:   end for                                         to having a very high reputation: the higher the agent’s repu-
 5:   run PUSH-SUM  for U = U(n, δ, ) stages         tation, the shorter the time required to close deals.
             sU,i                                                                           i
 6:   return w                                          We consider a model in which each agent has a reputa-
              U,i                                                 rthr          [                 ]
 7: end procedure                                     tion threshold i (similar to Xiong and Liu, 2003 )anda
                                                      conﬁdence level δi: agent i is willing to deal with an agent
                                                                                                 thr
                                                      j iff i knows that j’s average reputation is at least ri , with
  A  simple way to compute the average trust is via   conﬁdence 1 − δi. i evaluates j’s reputation as above, us-
PUSH-SUM.                                             ing EVA L -TRUST. Recall that when the algorithm terminates,
                                                           i                              rj   st,i
  The protocol EVA L -TRUST is given as Algorithm 2.  agent only has an -close approximation of ¯ .Ifwt,i is very
 USH   UM              U    U  n, δ,                         thr
P    -S   is executed for =   (     ) stages. At time close to ri , i would have to increase the accuracy.
U, it holds for all k ∈ N, and in particular for agent i,that
                                                                                                      i
 st,i j                                             Remark 3.  We still do not commit to the way the values r
   − r¯  ≤ , with probability 1 − δ. In other words, the                                             j
 wt,i                                                 are determined and updated, so the above trust model is quite
                                         j
algorithm returns a very good approximation of ’s average general.
reputation.
  In practice, when two agents i and j interact, i may eval-
uate j’s reputation (and vice versa) by calling EVA L -TRUST. Algorithm 3
The protocol quickly returns the approximation of r¯j, based
                                                       1: procedure DECIDE-TRUST(i, j) idecides if it wants
            rj
on the values k at the time EVA L -TRUST was called. Each to deal with j
     i                    s      w
agent keeps different values t,i and t,i for every differ- 2:  ← 1/2                         Initialization
ent query that was issued by some other agent in the system,
                                                       3:    k1 ← 0
and updates these values repeatedly according to PUSH-SUM. 4: loop
Thus, at any stage every agent participates in many parallel
                                                       5:       k2 ← U(n, δi,)
executions of PUSH-SUM.
                                                       6:       run EVA L -TRUST(j) for another k2 − k1 stages 
  A possible cause for concern is the amount of communi-
                                                          A total of k2 stages
                                                                             thr
cation each agent has to handle at every turn. However, the 7:  if st,i/wt,i <ri −  then
quick convergence of PUSH-SUM guarantees that the burden 8:        return false
                                                                                thr
will not be too great. Indeed, it is plausible to assume that 9: else if st,i/wt,i >ri +  then
the number of new interactions at each turn is bounded by a 10:    return true
       c                                   n
constant (or at worst is very small compared to ). Each 11:     end if
such new interaction results in at most two new executions 12:  k ←  k
                                         U                       1    2
of EVA L -TRUST, but the execution lasts at most turns. To 13:   ← /2
                                     c·U   O    n
conclude the point, each agent sends at most = (log ) 14:    end loop
messages per turn.                                    15: end procedure
                                              j
Remark 2. The size of messages depends on how the ri are
calculated, and as mentioned above, this issue is outside the
                                                        The procedure DECIDE-TRUST, given as Algorithm 3, is
scope of this paper. Nevertheless, there would usually be a                                      j    thr
                                               i      a straightforward method of determining whether r¯ ≥ ri .
constant number of reputation levels (say, for instance, rj ∈
                                                      Agent i increases the accuracy of the evaluation by repeatedly
{0, 0.1, 0.2,...,1}), so the message size would normally be
                                                      halving , until it is certain of the result. In this context, a
constant.
                                                      stage of EVA L -TRUST corresponds to a stage of PUSH-SUM.
  As the above method of aggregating an agent’s average                                     j   thr
reputation relies on the gossip-based algorithm PUSH-SUM, Proposition 3. Let i, j ∈ N, and Δij = |r¯ − ri |. With
it inherits all the latter’s beneﬁts, in particular robustness to probability at least 1 − δi, DECIDE-TRUST correctly decides
                                                                                       thr
failure and applicability in peer-to-peer networks.   whether agent j s reputation is at least ri after O(log n +
                                                          1       1  stages of EVA L -TRUST.3
                                                      log δi +logΔij )
4  The Beneﬁt of an Unstained Reputation
It is very desirable (indeed, crucial) that a reputation system
                                                                              rthr < rj
be able to induce truthfulness in agents. Naturally, an agent Proof. Assume w.l.o.g. that i ¯ , and that the algorithm
                                                                    t       <     /
with a stained reputation would be shunned by its peers, while reached a stage 0 where Δij 2. At this stage, it holds
an agent with a good reputation would easily solicit deals
and transactions. A further step in this direction is motivat- 3The probability is the chance that the algorithm will answer in-
ing agents never to cheat. Indeed, an agent with a generally correctly; the bound on the number of stages is always true.

                                                IJCAI-07
                                                  1472    st,i   j
that | w − r¯ |≤ (with probability 1 − δi), and therefore: strategy Strategy 2.FortheﬁrstT stages of the algorithm, the
     t,i                                                         m
                                                      manipulator i follows PUSH-SUM as usual, with the excep-
                st,i
                       j                                                 s  m              w   m       w
                    ≥ r¯ −                           tion of the updates of t,i : after updating t,i = l ˆl
                w                                               m
                 t,i                                  (as usual), i updates: st,im = wt,im . In other words, the
                                                                                                    s  m
                      rthr      −                                                                   t,i
                    =  i  +Δij                        manipulator sets its personal evaluation of the average wt,im
                       thr                                              t    ,...,T         t>T
                    >r    + .                        to be 1 at every stage =1    . For time    ,thema-
                       i                              nipulator abides by the protocol. Using this strategy, it always
                                                               st,i
                                        <    ij /    holds that   ≤ 1 for all i. In addition, for all t, it still holds
Hence, the algorithm surely terminates when  Δ   2.           wt,i
Now  the proposition follows directly from the fact that that i wt,i = n. Therefore, without augmenting the system
                          1        1
U n, δi, ij   O    n                 .
 (     Δ  )=   (log  +logδi +logΔij  )                with additional security measures, this manipulation is difﬁ-
                                                      cult to detect. We shall presently demonstrate formally that
                                                                                             s
  To conclude, Proposition 3 implies that there is a beneﬁt for the manipulation is effective in the long run: t,i converges
agent j in maintaining a high reputation: for any agent i with                               wt,i
                                                      to 1 for all i.
                      ij
a reasonable threshold, Δ is signiﬁcant, and this directly                                         T →∞
                                                                                       i ∈ N  s2T,i −→
affects the running time of DECIDE-TRUST.             Proposition 4. Under Strategy 2, for all , w2T,i  1
Remark 4. The result is limited, though, when the number of in probability.
agents n is large, as the time to evaluate an agent’s reputation            
                                                      Proof. We ﬁrst notice that st,i is monotonic increasing in
is also proportional to log n.                                                 i
                                                      stage t. Moreover, as noted above, it holds that at every stage,
                                                                                st,i
                                                         wt,i  n         i ∈ N      ≤
                                                        i    =   ,asforall     : wt,i 1, and thus:
5  Resistance to Attacks                                                     
We have seen that information about an agent’s reputation                st,i ≤   wt,i = n.
can be efﬁciently propagated, as long as all agents consis-            i       i
tently follow EVA L -TRUST. However, with reputation sys- Let , δ > 0. We must show that it is possible to choose
tems we are usually dealing with self-interested agents. In T large enough such that for all t ≥ 2T and all i ∈ N,
our context, a manipulative agent may artiﬁcially increase or st,i ≥ −  ≥ − δ
                                                      Pr[ wt,i 1    ]  1   .
decrease the overall evaluation of some agent’s reputation by            t
deviating from the protocol.                            Assume that at time it holds that:
                                                                           s
  In the framework we have presented, trust is evaluated on               i t,i
                                                                              <  1 − /2.             (1)
the basis of global knowledge, i.e., the average of all repu-             n
                                                                                             
tation values in the system. Therefore, any small coalition            st,i
                                                      Let It = {i ∈ N :   ≥ 1 − /4}, w(It)=      wt,it .It
cannot signiﬁcantly change the average reputation of some             wt,i                     i∈It
                                  j                   holds that:
agent j by setting their own valuations ri to legal values in                
[0, 1], and then following the protocol EVA L -TRUST.4           n(1 − /2) ≥    st,i
                                                                             i∈N
  This is, of course, not the case when a manipulator is al-                 
lowed to set its reputation value arbitrarily. As a simple mo-
                                                                           ≥     st,i
tivating example, consider a setting where agents propagate
                               j                                             i∈It
agent j’s average reputation (xi = ri for all i), and a ma-                  
         m                          st,i
        i                         i                                        ≥     wt,i · (1 − /4)
nipulator  wants to ensure that for all , wt,i converges to
                                                                             i∈I
a high value as the time t increases. At some stage t0,the                      t
                 s   m      n
manipulator updates t0,i to be , but except for this harsh                 = w(It)(1 − /4).
deviation follows the protocol to the letter. In particular, the
                                                                                 1−/2
                           j                            It follows that w It ≤ n ·    . The total weight of
manipulator might initially set rim = xim = n. We refer to             ( )       1−/4
                                      st,i
                                    i                 agents in N \ It is at least n − w It . There must be an agent
this strategy as Strategy 1. Clearly, for all , wt,i eventually                  (  )
converges to a value that is at least 1.              it ∈ N \ It with at least a 1/n-fraction of this weight:
  Despite the apparent effectiveness of Strategy 1, it is easily          n − w I       
                              m                                    w    ≥       ( t) ≥     .
detected. Indeed, unless for all i = i it holds that st0,i =0       t,it                             (2)
                                                                              n       4 − 
at the time t0 when the manipulator deviated by assigning
                        st,i
s  m    n                                             In order for the choice of it to be well-deﬁned, assume it is
 t0,i =  , the expressions w would eventually converge
                         t,i                          the minimal index that satisﬁes Equation (2).
to a value that is strictly greater than 1; this would clearly   
                                                        Now, let s m be the manipulator’s sum had it updated it
unmask the deceit. It is of course possible to update st ,im to  t,i                  
                                             0                                 s        s
be less than n, but it is difﬁcult to determine aprioriwhich according to the protocol, i.e., t,im = l ˆl for all messages
                                                      l sent to im. With probability 1/n (and independently of other
value to set without pushing the average reputation above 1.         m
  We now consider a more subtle way to increase the val- stages), ft(it)=i ; if this happens, it holds that:
   s
    t,i                                                      
ues wt,i , a deceit that is indeed difﬁcult to detect; we call this s ≤ w  m −  /  · w      /  · s
                                                             t+1,im  ( t+1,i   1 2   t,it )+1 2  t,it

  4                                                                ≤  w    m −  /  · w
   In fact, this holds for every coalition that does not constitute a ( t+1,i  1 2   t,it )           (3)

sizable portion of the entire set of agents.                         +1/2 · wt,it · (1 − /4).

                                                IJCAI-07
                                                  1473                                        
  For all stages t it holds that i st+1,i − i st,i =  is also true for t =0), so it is enough to consider messages at
                                                                      m
s    m − s                                                t        i  i
 t+1,i    t+1,im , as the manipulator is the only agent that time from all = .
               s                                        Therefore, for all stages t, it holds that:
might change  i t,i. Therefore, in the conditions of Equa-                   
tion (3),                                                                       
                                                                                               m
                                                         E     st+1,i −   st,i =    (Pr[ft(i)=i  ]
           st ,i −    st,i = st ,im − st ,im
            +1               +1       +1                      i          i        i= im
         i         i
                                                                                        1      1
                         = wt  ,im − st ,im                                           · ( wt,i − st,i))
                             +1       +1                                                2      2
                                                                                    
                         ≥ 1/2 · wt,it ·                                          1
                                     4                                         =        (wt,i − st,i)
                                                                                  2n
                              2                                                     i= im
                         ≥                                                           
                           32 − 8                                                1
                                                                               ≤         wt,i
                              w .                                                 2n
                         =Δ(   )                                                     i= im
                                                                                     
  So far, we have shown that for each stage t where Equa-                        1
                       m                                                       ≤        wt,i
tion (1) holds and ft(it)=i , it is the case that st ,i −                          n
                                         i  +1                                   2  i∈N
                                      n(1−/2)
  i st,i ≥ Δ(w). This can happen at most  w   times
                                        Δ( )                                      1.
before EquationP (1) no longer holds, or to put it differently,                =
         s                                                                        2
before  i t,i ≥ 1 − /2.
        n                                             The last equality follows from the fact that for all t,
  Let Xt be i.i.d. binary random variables, that are 1 iff w   n
         m                                              i  t,i = P.
ft(it)=i   . It holds that for all t where Equation (1) is         s
                                                           rj     i 0,i
true, E[Xt]=1/n. By Chernoff’s inequality, it holds that: As ¯ =  n   , and from the linearity of expectation, we
                                                      obtain that
                                                                                                   
                  T1                                                
       T −
                                   T1                                          1 1           
                1          1     −   2                       sT ,i
            Pr[      Xt ≤    ] ≤ e 2n .                E    i  1  − rj    1 E           s    −    s
               T          2n                                        ¯  =                 t+1,i     t,i
                1 t=1                                        n            n
                                                                               t=0  i          i   
                    T                                                       T1−1            
It is possible to choose 1 to be large enough such that this              1
                                           n(1−/2)                             E     s     −    s
expression is at most δ/2, and in addition 1 ·T ≥ .                    =               t+1,i      t,i
                             P    2n   1    Δ(w)                          n
                                S                                           t=0     i          i
                T              i T1,i ≥  − /
Therefore, at time 1, the average n    1     2 with                       1    1
probability 1 − δ/2.                                                   ≤   T1 ·  .
                              m                                           n    2
  Recall that after T stages (where i deviated from the pro-
                        w      n
tocol),P it still holds that i T,i = . Assume that indeed
   S
  i T1,i                                                                                       1      1
   n    ≥ 1 − /2. By modifying the proof of Theorem    In particular, since U(n, δ, )=O(log n +logδ +log  ),
3.1 from [Kempe et al., 2003], it is possible to show that PUSH-SUM is executed O(log n) stages, and thus the differ-
           T     T  n, δ,                                                        log n
after another 2 =  2(    ) stages where all agents ob- ence in the average is at most O( n ), which is quite insub-
                                      −  δ/
serve the protocol,P it holds with probability 1 2 that for stantial.
      s          S                                                                                  s
all i,  T1+T2,i − i T1,i  </2, and thus for all i and Remark 5. It is not guaranteed at time T that each t,i
      wT1+T2,i    n                                                                        1          wt,i
            s
t ≥ T   T   t,i >  −                 − δ             is close to r¯j, because the inputs were dynamically changed
     1 + 2, wt,i 1    with probability 1 .
  The proof is completed by simply choosing  T   =    during the execution of PUSH-SUM.
max{T1,T2}.                                           Remark 6. The above discussion focused on a setting where
                                                      the manipulator attempts to increase the average reputation of
  Proposition 4 implies that Strategy 2 poses a provably acute an agent. It is likewise possible for a manipulator to decrease
problem, when PUSH-SUM  is run a large number of turns. an agent’s average reputation, or indeed set it eventually to
Fortunately, PUSH-SUM converges exponentially fast, and any value it wants.
thus it is usually the case that the manipulator is not able to
signiﬁcantly affect the average reputation, as the following 6 Related Work
proposition demonstrates.
                                                              [                 ]          [
                 T  ≤ T                               P2PRep  Cornelli et al., 2002 and Xrep Damiani et al.,
Proposition P 5. Let 1 . Under Strategy 2 it holds that
     S                                                2002] are P2P reputation systems that can be piggybacked
E   i T1,i − rj ≤ T1
     n      ¯     2n .                                onto existing P2P protocols (such as Gnutella). P2PRep
                                                      allows peers to estimate trustworthiness of other peers by
Proof. Let {sˆl, wˆl} be the messages that the manipulator polling. No guarantees are given with respect to computa-
received at time t +1. The manipulator sets st+1,im = tional efﬁciency and scalability.
wt+1,im =   l wˆl. Essentially, this is equivalent to setting Aberer and Despotovic [2001] introduce a reputation sys-
for all l sˆl =ˆwl, or in other words, raising each sˆl by wˆl − sˆl. tem that consists of both a semantic model and a data manage-
At turn t it was already true that st,im = wt,im (w.l.o.g. this ment scheme. The latter relies on P-Grid [Aberer, 2001],and

                                                IJCAI-07
                                                  1474