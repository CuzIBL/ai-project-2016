                              Intelligent Multimodal Stream Processing 

                                                    Mark Maybury 
                                         Information Technology Division 
                                              The MITRE Corporation 
                                                202 Burlington Road 
                                             Bedford, MA 01730, USA 
                                                  mavbury(dlmitre. org 
                                         www, mitre, org/resources/centers/it 

                         Abstract 
  This poster describes methods to enable intelligent 
  access to multimodal information streams. We illus•
  trate these methods in two integrated systems: the 
  Broadcast News Editor (BNE) which incorporates 
  image, speech, and language processing and the 
  Broadcast News Navigator (BNN) which provides 
  search, visualization and personalized access to 
  broadcast news video. BNN enables users to perform 
  keyword and named entity search, temporally and 
  geospatially visualize entities and stories, cluster sto•
  ries, discover entity relations, and obtain personal•
  ized multimedia summaries. By transforming access 
  from sequential to direct search and providing hier•
  archical hyperlinked summaries, BNE and BNN en•
                                                                Figure 1. Multistream Broadcast News Understanding: 
  able users to access topics and entity news clusters 
                                                                                 System Architecture 
  nearly three times as fast as direct search of video. 
                                                              2. Intelligent Multimodal Segmentation 
1. Intelligent News on Demand 
                                                              BNN exploits text, audio, and imagery streams and associ•
Figure 1 illustrates the BNE and BNN systems that inte•
                                                              ated cues to detect story and commercial segment bounda•
grate components from MITRE, Oracle, Carnegie Mellon 
University and Lincoln Laboratory to process imagery,         ries and to select media elements to use for summaries and 
audio, and text to enable news on demand. Key elements        multimodal displays. Underlying BNN is a set of machine-
of BNE include scene change detection and classification      learned, time-enhanced finite state automata modeling news 
from imagery, silence and speaker change detection from       structure that take into account the above cues and prob•
audio, and named entity extraction from speech or closed      abilistic, temporal models of event occurrence [Boykin and 
caption transcripts. A correlation component extracts         Merlino 2000]. Program start/end, anchor/report shots, 
cues from across these streams to detect the start and end    commercials, and/or story shifts are inferred from cross me•
of broadcasts, commercials, and stories. Subsequently,        dia cues in text (e.g., frequent weather or sports terms, 
stories are classified and summarized, including selection    funding and/or copyright notices), discourse cues (e.g., 
of key frames, named entities, and representative sen•        "coming up next"), music (e.g., characteristic jingles), si•
tences. Finally, the user can search and explore video        lence (indicating breaks to commercial), and visual cues 
stories, provide relevancy feedback, specify media pref•      (e.g., logos, anchor vs. reporter shots). For example, as 
erences, and obtain personalized displays using the BNN       shown in Figure 2, our frequency analysis of news anchor 
web browser as shown in Figure 4 below. As detailed in        sign on terms (e.g., "hello", "welcome") or sign off terms 
[Maybury 2003], BNE and BNN transform video access from       (e.g., "that's all", "thanks for watching") occurring minutes 
sequential to direct search, providing novel navigation and   from program start enables the creation of pattern detectors 
discovery mechanisms such as topical and entity-specific news for such events. We have discovered analyzing months 
clusters. Empirical evaluations have shown that users can find worth of news, for example, that sign off* terms occur in 
stories and answer questions nearly three times as fast as    97% of news programs. 
searching digital video with no loss in precision and recall. 


POSTER PAPERS                                                                                                      1415  Figure 2. Text Analysis of Program Start and End Terms 

 Analogously, as shown in Figure 3, BNE classifies 15 
 frames per second into images associated with program start 
 (e.g., logos), commercial breaks (e.g., blackframes), single 
 and double anchor shots, and reporter shots. 


                                                                 Figure 4. Text and Named Entity Search Menus, 
                                                                 "Story Skim" Results and "Story Detail" Results 

                                                            Figure 5 illustrates a user visualizing named entity fre-
                                                            quencies and animating story occurrences associated with 
                                                            geospatial regions over time enabling information 
                                                            discovery. 


3. Search, Retrieval, and Visualization 
After BNE segments stories with multimodal cues, BNN 
supports the retrieval of stories by source, date range, 
keyword, named entity, or topic query. As exemplified in 
the upper left of Figure 4, after selecting news programs 
(e.g., CNN NewsNight, ABC World News Tonight) and 
indicating date ranges (e.g., Februrary 6-9, 2003), a user 
types in keywords in the text box. If a user is unfamiliar               Figure 5. News Visualization 
with retrieval terms, they can select from an alphabetic 
listing of all the named entities extracted for the time    Acknowledgments 
period and from the programs of interest, such as shown     This research involved collaboration among Stanley 
in the person, organization, and location lists in the upper Boykin, Andy Merlino, Warren Grieff, and Chad 
left of Figure 4 (note "Hans Blix" is highlighted). This    McHenry, Chris Clifton, John Aberdeen, John Burger, 
retrieves 14 matching stories and displays them as a        David Day, Lynette Hirschman, and Rod Holland. 
"Story Skim", the source and date, the top 3 named enti•
ties in each story, and a representative key frame from     References 
each selected segment. Finally, by selecting a story, the 
user is presented with "Story Details", including all       [Boykin and Merlino, 2000] Boykin, S. and Merlino, M. 
named entities, a text summary, and access to video and     Feb. 2000. A. Machine learning of event segmentation 
transcript sources. In empirical studies this mix of ex•    for news on demand. Communications of the ACM. Vol 
tracted media and hypertext organization enables analysts   43(2): 35-41. 
to perform searches three times faster than with video 
source.                                                     [Maybury 2003] Maybury, M. 2003. Broadcast News 
                                                            Understanding and Navigation. Innovative Applications 
                                                            of AI. Acapulco, Mexico. 12-14 August, 2003. 


1416                                                                                              POSTER PAPERS 