   Graph Connectivity Measures for Unsupervised Word Sense Disambiguation

                     Roberto Navigli                               Mirella Lapata
                Dipartimento di Informatica                     School of Informatics
             Universit`a di Roma “La Sapienza”                 University of Edinburgh
             navigli@di.uniroma1.it                           mlap@inf.ed.ac.uk

                    Abstract                          Mihalcea, 2005]. First, a graph is built representing all pos-
                                                      sible interpretations of the word sequence being disam-
    Word sense disambiguation (WSD) has been a        biguated. Graph nodes correspond to word senses, whereas
    long-standing research objective for natural lan- edges represent dependencies between senses (e.g., syno-
    guage processing. In this paper we are concerned  mymy, antonymy). Next, the graph structure is assessed to
    with developing graph-based unsupervised algo-    determine the importance of each node. Here, sense dis-
    rithms for alleviating the data requirements for  ambiguation amounts to ﬁnding the most “important” node
    large scale WSD. Under this framework, ﬁnding     for each word. Similarity-based algorithms assign a sense to
    the right sense for a given word amounts to iden- an ambiguous word by comparing each of its senses with
    tifying the most “important” node among the set of those of the words in the surrounding context [Lesk, 1986;
    graph nodes representing its senses. We propose a McCarthy et al., 2004; Mohammad and Hirst, 2006].The
    variety of measures that analyze the connectivity of sense whose deﬁnition has the highest similarity is assumed
    graph structures, thereby identifying the most rele- to be the correct one. The algorithms differ in the type of
    vant word senses. We assess their performance on  similarity measure they employ and the adopted deﬁnition
    standard datasets, and show that the best measures of context which can vary from a few words to the en-
    perform comparably to state-of-the-art.           tire corpus. In graph-based methods word senses are deter-
                                                      mined collectively by exploiting dependencies across senses,
                                                      whereas in similarity-based approaches each sense is deter-
1  Introduction                                       mined for each word individually without considering the
Word sense disambiguation (WSD), the ability to identify the senses assigned to neighboring words. Experimental com-
intended meanings of words (word senses) in context, is a parisons between the two algorithm types [Mihalcea, 2005;
central research topic in Natural Language Processing. Sense Brody et al., 2006] indicate that graph-based algorithms out-
disambiguation is often characterized as an intermediate task, perform similarity-based ones, often by a signiﬁcant margin.
which is not an end in itself, but essential for many applica- In this paper we focus on graph-based methods for un-
tions requiring broad-coverage language understanding. Ex- supervised WSD and investigate in depth the role of graph
amples include machine translation [Vickrey et al., 2005],in- structure in determining WSD performance. Speciﬁcally, we
formation retrieval [Stokoe, 2005], question answering [Ra- compare and contrast various measures of graph connectiv-
makrishnan et al., 2003], and summarisation [Barzilay and ity that assess the relative importance of a node within the
Elhadad, 1997].                                       graph. Graph theory is abundant with such measures and
  Recent advances in WSD have beneﬁted greatly from the evaluations have been undertaken in the context of studying
availability of corpora annotated with word senses. Most the structure of a hyperlinked environment [Botafogo et al.,
accurate WSD  systems to date exploit supervised meth- 1992] and within social network analysis [Hage and Harary,
ods which automatically learn cues useful for disambigua- 1995]. Our experiments attempt to establish whether some of
tion from hand-labeled data. Although supervised approaches these measures are particularly appropriate for graph-based
outperform their unsupervised alternatives (see Snyder and WSD. Such a comparative study is novel to our knowledge;
Palmer [2004] for an overview), they often require large previous work restricts itself to a single measure which is
amounts of training data to yield reliable results [Yarowsky either devised speciﬁcally for WSD [Barzilay and Elhadad,
and Florian, 2002], and their coverage is typically limited to 1997] or adopted from network analysis [Mihalcea, 2005;
the words for which sense labeled data exist. Unfortunately, Navigli and Velardi, 2005]. Our contributions are three-fold: a
creating sense tagged corpora manually is an expensive and general framework for graph-based WSD; an empirical com-
labor-intensive endeavor [Ng, 1997] which must be repeated parison of a broad range of graph connectivity measures us-
for new domains, languages, and sense inventories. Given ing standard evaluation datasets; and an investigation of the
the data requirements for supervised WSD and the current inﬂuence of the sense inventory on the resulting graph struc-
paucity of suitable data for many languages and text genres, ture and consequently on WSD.
unsupervised approaches would seem to offer near-term hope In the following section, we brieﬂy introduce the graph-
for large scale sense disambiguation.                 based WSD   algorithm considered in this paper. Then we
  Most unsupervised methods can be broadly divided in two present and motivate several measures of graph connectivity
categories, namely graph-based ones and similarity-based and explain how they are adapted to WSD. Next, we describe
ones. Graph-based algorithms often consist of two stages our evaluation methodology and present our experimental re-
[Barzilay and Elhadad, 1997; Navigli and Velardi, 2005; sults. We conclude the paper by discussing future work.

                                                IJCAI-07
                                                  16832  Graph-based WSD
                                                                    d          f      g
                                                           c
In order to isolate the impact of graph connectivity measures
on WSD, we devised a fairly general disambiguation algo-                  e                      i
rithm that has very few parameters and relies almost exclu-
sively on graph structure for inferring word senses. In com-
mon with much current work in WSD, we are assuming               b                     h
that meaning distinctions are provided by a reference lexi-              a
con, which encodes for each word a discrete set of senses.
Although our experiments will use the WordNet sense inven-        Figure 1: An example of a graph.
tory [Fellbaum, 1998], neither our graph-based algorithm nor
the proposed connectivity measures are limited to this par- 3 Connectivity Measures
ticular lexicon. Resources with alternative sense distinctions
and structure could also serve as input to our method. In this section we describe the measures of graph connectiv-
                                                      ity we consider for unsupervised WSD. Although our mea-
  We can view WordNet as a graph whose nodes are concepts sures can be applied to both directed and undirected graphs,
(represented by synsets (i.e., synonym sets)) and whose edges for WSD purposes we are assuming that we are dealing with
are semantic relations between concepts (e.g., hypernymy,
                                          =(     )    undirected graphs (we view an undirected edge as a pair of
meronymy). For each sentence we build a graph G V,E , directed edges). This is motivated by the fact that semantic
which is induced from the graph of the reference lexicon.
                             =                        relations often have an inverse counterpart (e.g., hypernymy
More formally, given a sentence σ w1,w2,...,wn,where  is the inverse relation of hyponymy).
wi is a word, we perform the following steps to construct G: We next introduce the distance function d(u, v),whichis
                  n                                  used by some of the measures discussed below:
               :=          (  )              (  )
 1. Initially, Vσ    Senses wi ,whereSenses  wi  is               length of shortest path if u ; v
                  i=1                                   d(u, v)=
                                                                  Kotherwise
    the set of senses of wi in WordNet; in other words, Vσ
    represents all possible interpretations of sentence σ.We where u ; v indicates the existence of a path from u to v,
                                                                                [                 ]
    set V := Vσ and E := ∅;                           and K is a conversion constant Botafogo et al., 1992 ,which
                                                      replaces the ∞ distance with an integer when v is not reach-
                  ∈
 2. For each node v  Vσ, we perform a depth-ﬁrst search able from u (we choose K = |V |, as the length of any simple
    of the WordNet graph: every time we encounter a node path is < |V |). As an example consider the graph in Figure 1
      ∈      =               →    →  ··· →   →
    v   Vσ (v    v) along a path v v1         vk      where d(a, i)=5, d(c, g)=4, and so on.
    v, we add all intermediate nodes and edges on the path
              
    from v to v : V := V ∪{v1,...,vk} and E := E ∪    3.1  Local Measures
    {(    )    (    )}
      v, v1 ,..., vk,v . For efﬁciency reasons, we allow Local measures of graph connectivity determine the degree of
                        ≤ 6
    paths of limited length ( edges).                 relevance of a single vertex v in a graph G. They can thus be
  We thus obtain a subgraph of the entire lexicon which in- viewed as measures of the inﬂuence of a node over the spread
cludes vertices reasonably useful for disambiguation: each of information through the network. Formally, we deﬁne a
vertex is at distance ≤ 3 edges from some vertex in the orig- local measure l as:
inal set Vσ of word senses. Given a sentence σ, our aim is                l : V → [0, 1]
to select for each word wi ∈ σ the most appropriate sense
    ∈       (  )                                      A value close to 1 indicates that a vertex is relatively impor-
Swi   Senses wi . The latter is determined by ranking each
vertex in the graph G according to its importance. In Section 3 tant, whereas a value close to 0 indicates that the vertex is
we discuss several measures that operationalize importance peripheral.
in graph-theoretic terms. Here, we will brieﬂy note that these Several local measures of graph connectivity have been
measures can be either local or global. Local measures cap- proposed in the literature (see Wasserman and Faust [1994]
ture the degree of connectivity conveyed by a single vertex in for a comprehensive overview). A large number rely on the
the graph towards all other vertices, whereas global measures notion of centrality: a node is central if it is maximally con-
estimate the overall degree of connectivity of the entire graph. nected to all other nodes. In the following, we consider three
                                                      best-known measures of centrality, namely degree, closeness,
  The choice of connectivity measure inﬂuences the selec- and betweeness [Freeman, 1979], and variations thereof. We
tion process for the highest-ranked sense. Given a local mea- also show how graph connectivity can be computed by solv-
sure l, and the set of vertices V , we induce a ranking of the
                          σ                          ing a max-ﬂow problem.
vertices rank such that rank (v) ≤ rank (v ) iff l(v) ≥
          l              l          l
l(v ). Then, for each word wi ∈ σ, we select the best-ranking In-degree Centrality The simplest way to measure ver-
sense in Senses(wi) according to rankl.Aglobal measure g tex importance is by its degree, i.e., the number of edges ter-
characterizes the overall graph structure G and is thus not minating in a given vertex:
particularly helpful in selecting a unique sense for ambigu-    indeg(v)=|{(u, v) ∈ E : u ∈ V }|
ous words – G collectively represents all interpretations of σ.
We get around this problem, by applying g iteratively to each A vertex is central, if it has a high degree. In-degree centrality
interpretation of σ and selecting the highest scoring one. An is the degree of a vertex normalized by the maximum degree:
interpretation is a subgraph G ⊆ G such that G includes
                                                                           ( )= indeg(v)
one and only one sense of each word in sentence σ and all               CD  v    |V |−1
their corresponding intermediate nodes (see step (2) above).
                                                                                         ( )=  1    ( )=
So if our sentence has ﬁve interpretations, we will measure So, according to the graph in Figure 1, CD a 8 , CD d
                                                                       3             2
the connectivity of the resulting subgraphs ﬁve times. CD(e)=CD(h)=    8 ,andCD(c)=  8 .

                                                IJCAI-07
                                                  1684Eigenvector Centrality  A more sophisticated version of
                                                                     d         f
degree centrality is eigenvector centrality. Whereas the for- c 0/1                 1/1 g
mer gives a simple count of the number of connections a                  0/1


                                                                             1/1        1/1
vertex has, the latter acknowledges that not all connections  0/1                                i
are equal. It assigns relative scores to all nodes in the graph                            0/1
based on the principle that connections to nodes having a                  e   1/1
                                                                  b  0/1
high score contribute more to the score of the node in ques-              a            h
tion [Bonacich, 1972]. PageRank [Brin and Page, 1998] and
HITS [Kleinberg, 1998] are popular variants of the eigenvec-
tor centrality measure and have been almost exclusively used Figure 2: The maximum ﬂow between nodes e and g (edges
in graph-based WSD [Mihalcea, 2005; Navigli and Velardi, are labeled with the pair ﬂow/capacity).
2005].
  PageRank determines the relevance of a node v recursively For example, the KPP for nodes a and f in Figure 1 is
based on a Markov chain model. All nodes that link to v          1+ 1 + 1 + 1 + 1 + 1 + 1 + 1
                                                           ( )=     2 2  3 4 4  5 5 =040            ( )=
contribute towards determining its relevance. Each contribu- KPP a        8             .  and KPP  f
                                                      1+1+ 1 + 1 + 1 + 1 + 1 + 1
tion is given by the page rank value of the respective node 2 2 3 3  3 4
                                                               8         =0.53, respectively.
(PR(u)) divided by the number of its neighbors:
                                                     Betweenness Centrality   The betweenness of vertex v is
                (1− )             PR(u)
       PR(v)=      α + α                              calculated as the fraction of shortest paths between node pairs
                 |V |           outdegree(u)          that pass through v [Freeman, 1979]. Formally, betweenness
                         (u,v)∈E                      is deﬁned as:
                                                                                   
The overall contribution is weighted with a damping factor                                σst(v)
α, which implements the so-called random surfer model: with    betweenness(v)=
                                                                                            σst
probability 1−α, the random surfer is expected to discontinue                   s,t∈V :s=v=t
the chain and select a random node (i.e., page), each with
         1                                            where σst is the number of shortest paths from s to t,and
relevance | | .
         V                                            σst(v) the number of shortest paths from s to t that pass
  In contrast, HITS (Hypertext Induced Topic Selection) de- through vertex v. We normalize by dividing betweenness(v)
termines two values for each node v, the authority (a(v))and by the maximum number of node pairs excluding v:
              ( )
the hub value (h v ). These are deﬁned in terms of one an-                             ( )
other in a mutual recursion:                                         C  (v)=  betweenness v
                                                                     B      (|V |−1)(|V |−2)
    h(v)=          a(u);    a(v)=         h(u)        The intuition behind betweenness is that a node is important
           u:(u,v)∈E              u:(v,u)∈E           if it is involved in a large number of paths compared to the
                                                      total set of paths. With reference to Figure 1, the pairs of ver-
Intuitively, a good hub is a node that points to many good tices (x, g) and (g,x), with x ∈{a, b, c, d, e}, are connected
authorities, whereas a good authority is a node that is pointed by two possible shortest paths, including either f or h as an
to by many good hubs. A major difference between HITS and
                                                      intermediate vertex. Thus, σxg = σgx =2and σxg(f)=
PageRank is that the former is computed dynamically on a ( )=1                                     ( )=
subgraph of relevant pages, whereas the latter takes the entire σgx f . We can now calculate betweenness f
                                                      10 · 1 =5       ( )=  5  = 5
graph structure into account.                             2    and CB  f    8·7  56 .
  If we apply HITS to the graph in Figure 1, we get the fol-                  =(     )
                     ( )=0484     ( )=0435    ( )=    Maximum Flow      Let G    V,E  be a connected graph,
lowing authority values: a d .  ,a e    .   ,a b      and let c : E → R be a capacity function such that every edge
0.404,...,a(a)=0.163,a(i)=0.132. The PageRank val-    (   ) ∈                            (   )
          ( )=      ( )=      ( )=     ( )=015         u, v   E  is associated with capacity c u, v .Wefurther
ues are PR d     PR  e    PR   b    PR  d      .  ,   distinguish two vertices, the source s and the sink t. Finally,
PR(f)=PR(g)=PR(c)=0.1,andPR(i)=PR(a)=                      :  ×   →  R
0 05                                                  let f V   V      be a function called ﬂow.
 . . While HITS yields a ﬁne-grained ranking, PageRank  Given an s-t-cut (S, T ), i.e., a partition of V into two dis-
delivers only three different ranks, ranging from central to joint sets S and T , such that s ∈ S and t ∈ T ,thes-t-ﬂow of
peripheral. Notice that, since our graphs are undirected, the the cut represents the amount of information that can be con-
authority and hub values coincide.                    veyed from s to t through the cut while obeying all capacity
Key Player Problem (KPP)    KPP is similar to the better constraints. It is deﬁned as:
                              1                                                
known closeness centrality measure [Freeman, 1979]. Here,            (    )=          (   )
a vertex is considered important if it is relatively close to all   f S, T           f u, v
other vertices [Borgatti, 2003]:                                             u∈S,v∈T
                                 1                   The maximum  s-t-ﬂow of a graph G has the highest value
                                                      among all - -cuts. For example, if we ﬁx as the source
                               d(u, v)                         s t                          e
                       u∈V :u=v                      and g as the sink (or viceversa) in the graph in Figure 2, the
             KPP(v)=
                            |V |−1                    maximum ﬂow that can be conveyed equals to the sum of the
                                                                      (  )+   (   )=1+1=2
where the numerator is the sum of the inverse shortest dis- maximum ﬂows f f,g f e, h           .Thisﬂow
                                                      is determined by taking into account the paths e → f → g
tances between v and all other nodes and the denomina-      →    →
tor is the number of nodes in the graph (excluding v). and e   h    g. In fact, Menger’s theorem states that the
                                                      maximum  s-t-ﬂow in undirected graphs corresponds to the
  1Closeness centrality is deﬁned as the total geodesic distance number of independent paths between a pair of vertices.
from a given node to all other nodes. We consider only KPP since it In the context of WSD, maximum s-t-ﬂows provide a
outperformed closeness centrality in our experiments. relevance ranking on the set of vertices: the more ﬂow is

                                                IJCAI-07
                                                  1685                                                                           (  )=  |E(G)|
conveyed from s to t, the more relevant the sink is. Ini-               ED  G     2·(|V |)
tially, the capacity of each edge (u, v) ∈ E is set to 1 and                        2
its ﬂow f(u, v) to 0. To compute an overall score for each For example, the graph in Figure 1 has edge density
vertex, we execute the following steps:                   ( )=   10 =  10 =0138
                                                      ED  G     2·(9)  72   .   .
        ∀v ∈ V score(v):=0                                        2
        ∀s, t ∈ V , s = t, do
           score(t) := score(t)+max s-t-ﬂow           4   Experimental Setup
        ∀v ∈ V , do
                             ( )                      Sense inventory    The graph connectivity measures just
           score(v) :=   score v
                      max score(u)                    described were incorporated in the disambiguation algorithm
                      u∈V                             introduced in Section 2. As explained earlier, disambigua-
  The resulting score for each vertex v ∈ V is the sum of the tion proceeds on a sentence-by-sentence basis. Each sentence
maximum ﬂows having v as a sink normalized by the max- is represented by a graph corresponding to meaning distinc-
imum score. If G is disconnected, we do not need to apply tions provided by a reference lexicon. In our experiments
the algorithm separately to each connected component, since we employed two such lexicons. The ﬁrst is WordNet 2.0
the maximum ﬂow between   and   is 0 if is not reach- [Fellbaum, 1998], a resource commonly used in WSD re-
                         s    t       t                                          [   ]
able from s. We calculate the maximum ﬂow with the Ford- search (see Snyder and Palmer 2004 ). We also used an ex-
Fulkerson [1962] algorithm based on the notion of augment- tended version of WordNet created by Navigli [2005].The
ing paths. We adopted Edmonds and Karp’s [1972] efﬁcient latter contains additional semantic relatedness edges (approx-
implementation.                                       imately 60,000) that relate associated concepts across parts
                                                      of speech (e.g., dog and bark, drink and glass). These were
3.2 Global Measures                                   automatically extracted from collocation resources (e.g., Ox-
                                                      ford Collocations, Longman Language Activator) and semi-
Global connectivity measures are concerned with the struc- automatically disambiguated.
ture of the graph as a whole rather than with individual nodes.
Here we discuss three well-known measures, namely com- Data    We selected two standard data sets for evaluat-
pactness, graph entropy, and edge density.            ing our connectivity measures, namely the SemCor corpus
                                                      [Miller et al., 1993] and the Senseval-3 English all-words
Compactness     This measure represents the extent of        [                     ]
                         [                  ]         test set Snyder and Palmer, 2004 . SemCor is a subset of
cross referencing in a graph Botafogo et al., 1992 :when the Brown corpus, and includes more than 200,000 content
compactness is high, each vertex can be easily reached from words manually tagged with WordNet senses. Senseval-3 is a
other vertices. The measure is deﬁned as:
                                                    subset of the Penn Treebank corpus and contains 2,081 con-
                    Max−         d(u, v)              tent words, again labeled with WordNet senses. We exhaus-
                                                      tively tested our measures on the SemCor dataset. The best
              ( )=        u∈V v∈V
           CO  G          Max−Min                     performing one was also evaluated on Senseval-3 and com-
                                                      pared with state-of-the-art.
where Max =  K ·|V |(|V |−1) is the maximum compactness
(i.e., for a disconnected graph) and Min = |V |(|V |−1) is Graph construction In order to speed up the graph con-
the minimum compactness (i.e., for a fully connected graph). struction process, all paths connecting pairs of senses in
The compactness of the graph in Figure 1 is: CO(G)=   both versions of WordNet were exhaustively enumerated and
(9·9·8)−176 = 472 =0819                 =  | | =9     stored in a database which was consulted at run-time during
(9·9·8)−(9·8) 576  .   (in this example, K V     ).   disambiguation. Unfortunately, the use of global connectivity
Graph Entropy     Entropy measures the amount of infor- measures makes our WSD algorithm susceptible to combina-
mation (or alternatively uncertainty) in a random variable. In torial explosion, since all possible interpretations of a given
graph-theoretic terms, high entropy indicates that many ver- sentence must be ranked (see Section 2). We used simulated
tices are equally important, whereas low entropy indicates annealing to heuristically explore the entire space of interpre-
that only a few vertices are relevant. We deﬁne a simple mea- tations for a given sentence [Cowie et al., 1992].
sure of graph entropy as:                             Baseline and Upper Bound    Our graph-based algorithm
                                                     was compared against a naive baseline that selects a sense
            H(G)=−        p(v)log(p(v))               for each word at random. As an upper bound, we used the
                      v∈V                             ﬁrst-sense heuristic which assigns all instances of an am-
                          ( )                         biguous word its most frequent sense according to the man-
where the vertex probability p v is determined by the de- ually annotated SemCor. It is important to note that current
                indeg(v)                              unsupervised WSD approaches—and also many supervised
gree distribution 2|E|     . To obtain a measure with a
                       v∈V                                                                   [
[0 1]                ( )                              ones—rarely outperform this simple heuristic McCarthy et
 ,  range, we divide H G by the maximum entropy given al., 2004].
by log|V |. For example, the distribution associated with the
                   1  3  2  3  3  2  2  3  1
graph in Figure 1 is: ( 20 , 20 , 20 , 20 , 20 , 20 , 20 , 20 , 20 ) lead-
                                  3.07                5   Results
ingtoanoverallgraphentropyH(G)=      9 =0.969.
                                  log                 Our results on SemCor are summarized in Table 1. We report
Edge Density    Finally, we propose the use of edge den- performance solely on polysemous words, i.e., words with
sity as a simple global connectivity measure. Edge density more than one WordNet sense.
is calculated as the ratio of edges in a graph over the num-
                                | |                     Let us ﬁrst concentrate on the results we obtained with
ber of edges of a complete graph with V vertices (given by the standard WordNet inventory. As can be seen, almost all
   |V |
2 · 2  ). Formally:                                   measures perform better than the random sense baseline. The

                                                IJCAI-07
                                                  1686                      WordNet        EnWordNet             100
     Measure      Prec  Rec   F1  Prec  Rec   F1           90

     Baseline      23.7 23.7 23.7 23.7  23.7 23.7          80

     InDegree      35.3 24.0 28.6 44.2  37.0 40.3          70
     Betweenness   38.4 15.5 22.1 45.0  31.1 36.8
     KPP           31.8 31.8 31.8 40.5  40.5 40.5          60

   Local HITS      31.7 17.2 22.3 39.4  31.1 34.8          50
     PageRank      35.3 24.0 28.6 44.0  36.8 40.0         F1measure(%) 40
     Maxﬂow        33.0 24.3 28.0 41.8  35.2 38.2
                                                           30
     Compactness   29.8 27.9 28.8 36.3  35.5 35.9
     GraphEntropy  30.3 28.4 29.4 30.9  30.2 30.5          20
                                                               0-11
                                                                  11-2122-3233-4344-54 55-6566-7677-9293-114115-147148-200200

   Global EdgeDense 29.9 27.9 28.9 35.6 34.6 35.1
                                                                     NumberofedgesinenrichedWordNet
     UpperBnd      68.8 68.8 68.8 68.8  68.8 68.8
                                                          Figure 3: Performance of KPP by number of edges.
Table 1: Performance of connectivity measures on SemCor.

differences are signiﬁcant both in terms of precision and re- Measure  Part of speech Prec Rec   F1
            2
call (using a χ test). HITS and Betweenness yield signiﬁ-              Nouns         61.9 61.9  61.9
cantly better precision but worse recall. The best performing KPP      Adjectives    62.8 62.8  62.8
local measure is KPP (F1 31.8%), whereas the best perform-             Verbs         36.1 36.1  36.1
ing global measure is graph entropy (F1 29.4%). KPP is sig-            Nouns         63.3 61.2  62.2
niﬁcantly better than graph entropy both in terms of preci-
                            2                              IRST-DDD    Adjectives    68.2 65.6  66.9
sion and recall (again using a χ test). We conjecture that             Verbs         51.6 49.2  50.4
the inferior performance of the global measures is due to
the use of a heuristic algorithm for searching the interpre- Table 2: Results on the Senseval-3 all words task by part of
tation space. Interestingly, PageRank yields signiﬁcantly bet- speech.
ter recall and precision than HITS. We attribute the differ-
ence in performance to the fact that PageRank implements a similarity-based algorithm. It was developed by Strappar-
the random surfer model. Finally, note that a relatively sim- ava et al. [2004] and performs domain driven disambigua-
ple measure like InDegree performs as well as PageRank (F1 tion (IRST-DDD). The approach compares the domain of the
is 28.6% for both measures). This is not entirely surprising. context surrounding the target word with the domains of its
The PageRank value of a node is proportional to its degree in senses and uses a version of WordNet augmented with do-
undirected graphs. Furthermore, research on directed graphs main labels (e.g., economy, geography). Table 2 shows how
has experimentally shown that the two measures are broadly                                 3
         [               ]                            performance varies across parts of speech. KPP performs
equivalent Upstill et al., 2003 .                     comparably to IRST-DDD for nouns and adjectives (the dif-
  We now turn to the performance of the different measures ferences in recall and precision are not statistically signiﬁ-
when the enriched WordNet (EnWordNet) is used. Here we cant). IRST-DDD yields signiﬁcantly better results for verbs.
also observe that all measures are signiﬁcantly better than the This can be explained by the fact that the enriched WordNet
baseline (in terms of precision and recall). The best perform- contains a signiﬁcantly smaller number of relatedness edges
ing global measure is Compactness (F1 35.9%). The best lo- for verbs than for nouns or adjectives and this impacts the
cal measures are InDegree, KPP and PageRank (F1 is around performance of KPP. Also note that our experiments focused
40%). KPP performs consistently well with WordNet and its primarily on graph connectivity measures. Consequently, we
enriched version. All three local measures achieve signiﬁ- employed a relatively generic WSD algorithm (see Section 2)
cantly better precision and recall than Compactness. It seems without additional tuning. For instance we could obtain im-
that local measures beneﬁt from a denser reference lexicon, proved results by considering word sequences larger than sen-
with a large number of semantic relations, whereas global tences or by weighting edges according to semantic impor-
measures are disadvantaged due to the combinatorial explo- tance (e.g., hypernymy is more important than meronymy).
sion problem discussed above. To further substantiate this, we
analyzed how KPP’s performance varies when an increasing
number of edges is considered for disambiguation. Figure 3 6 Conclusions
shows that F1 increases when a sense has a large number In this paper we presented a study of graph connectivity mea-
of edges. In fact, when more than 200 edges are taken into sures for unsupervised WSD. We evaluated a wide range of
account, KPP obtains an F1 of 85%. Notice that we are ex- local and global measures with the aim of isolating those that
cluding unambiguous words and that there are at least 1,500 are particularly suited for this task. Our results indicate that
occurrences of word senses in the SemCor corpus for each local measures yield better performance than global ones. The
interval in the graph.                                best local measures are KPP, InDegree, and PageRank. KPP
  We next assess how KPP performs on the Senseval-3 En- has a slight advantage over the other two measures, since it
glish all-words test set when using the enriched WordNet. We performs consistently well across experimental conditions.
also compare our results with the best unsupervised system Our results are in agreement with Borgatti [2003] who shows
that took part in the Senseval-3 competition2. The latter is
                                                         3F1 scores here are higher than those reported in Table 1. This is
  2See http://www.senseval.org/senseval3     for de-  expected since the Senseval-3 data set contains monosemous words
tails on the competition and participating systems.   as well.

                                                IJCAI-07
                                                  1687