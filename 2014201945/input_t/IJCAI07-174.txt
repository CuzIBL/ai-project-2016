              Grounding Abstractions in Predictive State Representations

             Brian Tanner   and  Vadim Bulitko    and  Anna Koop    and  Cosmin Paduraru
                                   Department of Computing Science
                                 Edmonton, Alberta, Canada T6G 2E8
                            {btanner, bulitko, anna, cosmin}@cs.ualberta.ca


                    Abstract                          deﬁne them has been compared to construction of the Tower
                                                      of Babel [McDonald et al., 2006]. Likewise, manually an-
    This paper proposes a systematic approach of rep- notating modern games and simulations is prohibitively time-
    resenting abstract features in terms of low-level, consuming and error-prone.
    subjective state representations. We demonstrate    This paper makes several contributions to the aforemen-
    that a mapping between the agent’s predictive state tioned problems. We propose an automated approach for
    representation and abstract features can be derived learning a mapping from agent state representations to
    automatically from high-level training data sup-  human-deﬁned abstractions using a small set of data labeled
    plied by the designer. Our empirical evaluation   by a human expert. We use a “I know it when I see it” ap-
    demonstrates that an experience-oriented state rep- proach to deﬁning abstract features; instead of programmat-
    resentation built around a single-bit sensor can rep- ically deﬁning or assigning values to the abstract features,
    resent useful abstract features such as “back against the human expert examines a number of examples and labels
    a wall”, “in a corner”, or “in a room”. As a result, them appropriately. A machine learning classiﬁcation algo-
    the agent gains virtual sensors that could be used                 [           ]
                     1                                rithm, such as C4.5 Quinlan, 1993 , can then create a classi-
    by its control policy.                            ﬁer that will appropriately label novel future experiences.
                                                        For this approach to be useful, it is important that the
1  Introduction                                       agent’s state representation allows the values of the abstract
                                                      features to generalize well between the labeled examples and
It is often useful for intelligent agents to reason at a level unseen data. We argue that agents using subjective, grounded
more abstract than their perceptions. Abstractions aggregate representations are well suited to making these generaliza-
many sensory situations into a single conﬁguration of abstract tions. A subjective, grounded approach represents the agent’s
features, allowing behavior expressed in abstract terms that state in terms of experience with its sensors and effectors.
generalize across similar situations. This generalization al- Speciﬁcally, we use a predictive representation of state: the
low humans designers to encode control policies closer to the agent’s state is stored as a vector of probabilities of outcome
level of human reasoning. For instance, using abstractions, an sensations given various sequences of action [Littman et al.,
agent’s designer can deﬁne a policy such as “avoid navigating 2002]. We believe that both concise and vague abstractions
through open areas” or “don’t stop near a doorway”.   can be characterized by patterns of interaction: abstractions
  The desire to write control policies in abstract terms is of- learned in terms of a predictive representation are portable to
ten thwarted because the policies must be implemented over novel situations with similar patterns of interaction.
the set of state variables and sensor readings available to the In a small navigation domain, we demonstrate that an
agent. In simulation, one option is to directly augment the agent using a simple classiﬁcation algorithm can learn to
environment with high-level information (e.g., each tree in identify intuitive abstractions like BACK-TO-WALL, CORNER,
a forest may be annotated as a possible cover for a soldier NARROW-CORRIDOR, and ROOM using both subjective and
agent) [Paull and Darken, 2004]. If access to the environ- objective state representations. Further, we show that in the
ment is not available, a programmer may write code to map subjective case, the learned classiﬁer allows the agent to iden-
low-level state (e.g., coordinates and obstacle detectors) to tify these abstractions in a novel environment without any ad-
higher-level abstract terms (e.g., being in a narrow corridor ditional training.
where the unit cannot move sideways) [Orkin, 2005].
  As realism of simulations used for real-life training and 2 Background and Related Work
education [Dini et al., 2006] increases, both approaches are
becoming expensive. Indeed, the number of abstract features In a typical situated agent framework, the agent (decision
and the amount of underlying software engineering needed to maker) interacts with an environment at a series of time steps.
                                                      The agent receives perceptions or observations from the envi-
  1This work was supported in part by RLAI, NSERC, iCORE, ronment at each moment and responds with actions that may
and Alberta Ingenuity.                                affect the environment. In this paper, we model the world as a

                                                IJCAI-07
                                                  1077partially observable Markov Decision Process (POMDP). We ple, consider an MDP for a navigation task where the state is
assume that at each discrete time step, there is a set of data represented using three discrete variables, x, y, θ. The ﬁrst
(called the state) that is sufﬁcient to make accurate proba- two variables, x, y represent a location, while θ denotes ro-
bilistic predictions of future experience (the Markov assump- tation or orientation in a coordinate system. One abstraction
tion). The state is not directly observable by the agent, the φi might identify the NORTH-EAST-CORNER, deﬁned as all
observation received from the environment may correspond states within 5 units of the 0, 0 corner of the environment.
to multiple different states.                         In this case:
                                                                   
  The standard POMDP model represents the agent’s current
                                                                      1  if x ∈{1, 2, 3, 4} and y ∈{1, 2, 3, 4}
state as a probability distribution over a set of unobservable φi(x, y, θ)=
                                                                      0  otherwise
situations that the agent may be in. Each of these unobserv-
able situations is called a nominal state; distributions over We generally refer to the outcomes of abstractions as ab-
nominal states are called belief states. POMDPs use the con- stract features. Abstract features allow a control algorithm to
ditional probability rule, a nominal state transition model, and make useful generalizations: to behave similarly in states that
an observation model to update the belief state with each new have different state variable combinations but similar abstract
action and observation. The transition and observation mod- features. For example, our agent may know that NORTH-
els are usually determined by a human expert and then later EAST-CORNERis a good place to recharge its batteries.
these parameters are optimized with data.
  Alternatively, history-based methods also model partially 3.1 Representing Abstractions
observable environments by considering either a ﬁxed or vari- Useful abstract features can often be invented by a human ex-
able length window of recent interactions with the environ- pert leveraging knowledge about a particular domain or task.
ment [McCallum, 1995].                                No matter what the agent’s representation, these abstract fea-
  Predictive state representations (PSR) are a third type tures are understood in the expert’s terms. Thus, a mechanism
of representation that model both observable and partially- must be found that reliably converts the agent’s state repre-
observable environments [Littman et al., 2002]. Instead of sentation into the abstract features. This is usually an exten-
focusing on previous interaction with the environment, the sive software engineering effort involving lengthy tuning via
predictive model represents state as a set of predictions about trial and error [Paull and Darken, 2004]. In games and virtual
future interactions. In a PSR, the agent’s state is repre- reality trainers the resulting abstraction is sometimes referred
sented as answers to questions about future experience in the to simply as “sensors” [Orkin, 2005] or “situation awareness
world. For example, one element of the state representation components” [Kunde and Darken, 2006].
might be “What is the probability of receiving the sequence The agent’s state representation has a strong impact on
             (o o ...o )
of observations 1 2   i if I take the sequence of actions the complexity and robustness of any script that converts the
(a a ...a )
  1 2    j ?”. Singh et al. [2004] proved that linear predic- agent’s state into abstract features. For instance, abstract fea-
tive state representations can represent all environments that tures such as BACK-TO-WALL or NARROW-CORRIDOR are
can be represented by a ﬁnite-state POMDP or a ﬁnite-length difﬁcult to concisely deﬁne as a function of x, y, θ. These
history method.                                       features can have value 1 in various disjoint locations in the
  A PSR has two components: structure and parameters. The map, making their values difﬁcult to know without explicit
structure is the set of events that the PSR makes predictions reasoning about walls or other obstacles. On the contrary, a
about, called the core tests. Each core test predicts the prob- predictive representation that stores the state as predictions
ability of observing a particular sequence of observations if about future perceptions can succinctly capture these abstrac-
a particular sequence of actions is chosen by the agent. The tions in terms of patterns of interaction with the environment.
parameters are used to update the core test values after each
new action and observation. Algorithms have been proposed 3.2 Learning Abstractions
                           [              ]
for learning the PSR parameters Singh et al., 2003 and dis- We propose a machine learning approach for automatically
covering and learning PSR structure and parameters together ﬁnding a mapping between an agent’s state representation and
[                         ]
McCracken and Bowling, 2006 .                         an expert’s understanding of abstract features. The expert can
                                                      look at a number of situations and appropriately label the ab-
3  Abstractions                                       stract feature values in each case. We call this set of labeled
                                                      examples the training set. For example, in the case of our
A state representation stores each state as a conﬁguration of mobile agent, the expert looks at a map of a particular envi-
variables. In a traditional MDP, the state is often represented ronment and labels examples of the agent being in a narrow
by a single discrete variable with a unique value for each state corridor. The agent then uses an off-the-shelf machine learn-
in the state space. In a POMDP, the state is represented by a
        n                         ∈ [0, 1]     n      ing algorithm such as a decision tree learner to learn a set
vector of continuous-valued variables   , where  is   classiﬁer that takes state variables as inputs and emits abstract
the number of underlying nominal states. In a linear PSR, the feature values as outputs.
state is also a vector of n continuous-valued variables ∈ [0, 1],
where n is the number of core tests.
  In this paper, an abstraction is a many-to-one operator φ 4 Experimental Results
that maps several conﬁgurations of state variables to a sin- For the demonstration, we chose a simple model of a path-
gle conﬁguration of a different set of variables. For exam- ﬁnding environment that allows us to evaluate our approach

                                                IJCAI-07
                                                  1078                                        Room
                                        Corridor
                                        Neither


Figure 1: Map A, used to train the agent’s virtual sensors to
recognize various abstract features.

                                                             Room
in detail. Speciﬁcally, our agent has four actions and a single, Corridor
binary observation. It is situated in a discrete grid environ- Neither
ment where some cells are open and some are blocked. The
agent occupies exactly one cell and has four possible orien-
tations (up, down, left, and right). The agent’s actions are: Figure 2: Map B, used for testing the agent’s virtual sensors.
go forward (F), turn left (L), turn right (R) , and go backward
(B). If the agent moves forward or backward and collides with As an example, consider a predictive state representation
an obstacle, the agent’s position remains unchanged. At any
                                                      with only two core tests. Core test t1 is deﬁned as seeing (1)
time step, the agent’s sensor reports 1 if the agent faces a             (F )            t        1
              0                                       after executing action . The value of 1 will be if and
blocked cell and otherwise.                           only if the agent is facing an obstacle or can reach it within
  We chose to make the grid world deterministic: the actions
                                                      one step forward. Core test t2 is deﬁned as seeing (1, 1, 1)
always succeed. Determinism greatly simpliﬁes the perfor-
                                                      while executing (R, R, R). The value of t2 will be 1 if the
mance measures and visualization of our experiments without agent had obstacles on its right, behind it, and on the left
weakening the results.                                side of it. In a deterministic environment any core test has
  We use two different maps in our experiments. The ﬁrst, the value of 1 or 0. Thus, this micro representation has four
Map A (Figure 1), has a total of 943 reachable grid locations
                                                      states: [t1 =0,t2 =0], [t1 =0,t2 =1], [t1 =1,t2 =0],
with four orientations each, for a total of 3,772 states. The
                                                      and [t1 =1,t2 =1]. These tests are compactly denoted as
second environment, Map B (Figure 2), has a total of 1,063 F1 and R1R1R1.
reachable grid locations with four orientations each, for a to- We construct the PSR representation from an accurate
tal of 4,252 states.                                  POMDP model of the environment using an adaptation of
State Representations                                 an algorithm introduced by Littman et al. for creating lin-
The agent uses two different state representations, one that ear PSRs from POMDP models [2002]. The PSR construc-
is based on objective coordinates x, y, θ and another that is tion algorithm is a polynomial algorithm that uses depth-ﬁrst
a predictive representation. As we have discussed, the ob- search to ﬁnd the set of PSR core tests and their values in all
jective x, y, θ coordinate system is useful for characteriz- of the POMDP nominal states. Our straightforward adapta-
ing certain abstractions that are tied to physical location on a tion of Littman et al.’s algorithm uses breadth-ﬁrst rather than
map. If certain areas of the map have a certain abstract fea- depth-ﬁrst search, yielding considerably shorter core tests.
ture value (such as “in a room”), then a classiﬁer learned over Abstract Features
   x, y, θ
the       state will correctly classify other states within the We chose four abstract features for our experiments, ranging
same room with very few training examples. However, if the from the formally and succinctly deﬁned BACK-TO-WALL to
agent has seen no examples of a particular room, the classiﬁer the more vague ROOM:
will have no means to identify it even if it is identical in size
and shape to another room seen previously.              1. BACK-TO-WALL  is a feature that is on when the agent
  The agent’s predictive representation is a vector of test val- would hit a wall if the backward action was taken, and
ues. Each test value corresponds to the probability of the off otherwise.
test’s observations matching those generated by the environ- 2. CORNER is a feature that is on in every grid location that
ment, conditioned on the test’s actions being executed.   has a corner where two blocked grid cells meet.

                                                IJCAI-07
                                                  1079 3. ROOM  is a feature that is on when the agent is in a room.       % Data Used for Training
    This is a difﬁcult feature to program manually due to               1%        10%         75%
    the fact that “room” is a vague human-level concept. In                  ROOM
    our approach we circumvent this problem by simply al-  Baseline 82.0% ± 0.0 82.0% ± 0.0 82.0% ± 0.0
    lowing a human designer to label certain states as room x, y, θ 80.1% ± 3.9 95.8% ± 2.6 99.9% ± 0.2
    without formally deﬁning it (Figures 1 and 2).         750 tests 90.7% ± 2.5 94.0% ± 1.0 96.7% ± 0.5
                                                                         BACK-TO-WALL
 4. NARROW-CORRIDOR   is a feature that is on in all 1-cell Baseline 79.1% ± 0.0 79.1% ± 0.0 79.1% ± 0.0
    wide corridors, labeled by a human designer. This and  x, y, θ 76.8% ± 5.2 79.1% ± 0.1 83.6% ± 1.7
    the ROOM  abstraction are not labeled entirely consis- 750 tests 93.0% ± 3.7 99.0% ± 0.5 99.6% ± 0.2
    tently within or across the two environments because of
    subjective decisions made by the human designer.  Table 1: Accuracy of a classiﬁer learned with x, y, θ repre-
                                                      sentation against a classiﬁer learned with a 750 core test PSR
 5. Finally, some grid cells are labeled as “neither” because on the ROOM and BACK-TO-WALL abstract features. Test and
    the expert knew they should not be classiﬁed as ROOM or training data sets are disjoint.
    NARROW-CORRIDOR, but there was no other abstract
    feature to label them with.
                                                      Discussion
4.1  Experiment 1:  x, y, θ vs. PSR on Map A        As expected, the x, y, θ classiﬁer was generally more ac-
                                                      curate than the PSR classiﬁer on the ROOM feature. Surpris-
In this experiment, we compare the classiﬁcation accuracy ingly, for small amounts of data, the PSR classiﬁer is actually
of decision trees learned from varying amounts of training more accurate. This indicates that the subjective state repre-
data within a single map (Map A) using both representa- sentation is able to identify the most canonical examples of
tions. We hypothesize that with few training examples, the the ROOM feature with very little data.
x, y, θ representation will generally perform better on ab- When testing the BACK-TO-WALL feature, the PSR clas-
stract features that are well characterized by spatial locality siﬁer was substantially better than the x, y, θ classiﬁer.
(e.g., the ROOM feature). Conversely, we expect the predic- BACK-TO-WALL can be characterized by a very simple pat-
tive representation to perform well for abstract features that tern of interaction even though it occurs in various locations
are well characterized by patterns of interaction (e.g., BACK- on the map in all orientations. This makes it an ideal candi-
TO-WALL).                                             date for being represented in a subjective representation in-
                                                      stead of a coordinate-based one. The decision tree that is
Experimental Method                                   learned for the PSR classiﬁer with 750 core tests is notice-
                                                      ably lengthier (31 leaf nodes) than a manually crafted clas-
All states in Map A are labeled as either positive or negative
                                                      siﬁer would be (3 leaf nodes). We believe this to be due to
examples of each abstract feature. The agent then uses the J48
                                                      overﬁtting. When the same experiment is run on the BACK-
(similar to C4.5 [Quinlan, 1993]) classiﬁcation algorithm to
                                                      TO-WALL  feature using fewer core tests (250 or fewer), the
create a separate decision tree for each abstract feature in both
                                                      3-node decision tree is found (Figure 3).
representations using the WEKA machine learning software
package [Witten and Frank, 2005]. In all of our experiments,
the reported results are for a PSR created using some subset of
                                                                          L 0 L 0
the core tests generated by our POMDP to PSR conversion al-
                         k
gorithm. This subset is the ﬁrst tests found by the algorithm.          ON    OFF
Using the full set of thousands of core tests is simply not nec-
                            P  = {1%, 10%, 75%}  P
essary. For various sample sizes               ,                    NOT
                                                                                L 1 L 0
of the examples are randomly sampled from Map A and put             WALL
into the training set, the other examples are left out and used
as a test set. The classiﬁer learned on the training set is then              ON     OFF
applied to the test set and classiﬁcation accuracy is measured.
                                                                           NOT
                                                                                       WALL
The proportion of positive examples to negative examples is               WALL
often quite biased, so all or our results report the accuracy
of a baseline classiﬁer that simply predicts the majority class
from the training data. Precision, recall, and speciﬁcity statis- Figure 3: Decision tree classiﬁer for the BACK-TO-WALL fea-
tics were also measured but are not reported as they exhibited ture learned using a predictive state representation with 250
similar trends to the accuracy. This procedure is repeated 10 or fewer core tests.
times and the mean and standard deviation of the accuracies
is reported.
  This experiment was performed on all four abstract fea- 4.2 Experiment 2: Transfer using PSR
tures, here we present the two results that represent either end In this experiment, we investigate the degradation in classiﬁ-
of the performance spectrum: ROOM and BACK-TO-WALL,   cation accuracy when a decision tree learned on training data
shown in Table 1.                                     from Map A is used to predict the abstract feature values on

                                                IJCAI-07
                                                  1080Map B. Good performance in Map B is evidence that a classi- The results in Table 2 are produced using a classiﬁer
ﬁer learned over a subjective state representation can be suc- learned over different numbers of core tests. These tests are
cessful with novel experiences that share patterns of interac- the ﬁrst k found by a breadth-ﬁrst search, meaning they may
tion with previous experiences. Note that we will not com- be quite short and ask questions only about states in the im-
pare the PSR classiﬁer’s ability to transfer to x, y, θ classi- mediate neighborhood. Most of the abstract features (BACK-
ﬁer in this experiment because the x, y, θ decision tree has TO-WALL, NARROW-CORRIDOR and CORNER) are well char-
no basis for being used in a different map. Indeed, x, y, θ acterized by short tests as evidenced by their high accuracy
locations for the abstract features are highly map-speciﬁc and with only a 10 test PSR.
not even translation or rotation invariant.
  We perform this set of experiments using varying amounts
of core tests as features for the classiﬁer. We anticipate that
some abstractions (BACK-TO-WALL and CORNER) will be
easily identiﬁed with a small number of short tests as features.
The vague, larger area abstractions like ROOM and NARROW-
CORRIDOR  may require more, longer tests. If this hypothesis
holds, accuracy on the ROOM and NARROW-CORRIDOR ab-
stractions should be worse for classiﬁers built using fewer
core tests, and better when more core tests are used.
Experimental Setup
All states in Map A and B are labeled as either positive or
negative examples of each abstract feature. Like the previous
experiment, the agent then uses the J48 algorithm to induce
decision tree classiﬁers from the training set, in this case all of
the states from Map A. The decision tree is then tested on all
examples from Map B. Because the agent has access to all of
the available training and testing data, only a single learning
trial is used and no standard deviation values are reported in
Table 2. We present the results of using 10, 50, 250, and 750
core tests.
  The results labeled Baseline correspond to predicting the
value of the abstract feature that occurred most frequently in
the training data: it is the accuracy that a classiﬁer would get
with no information about each training example except its
label.
                                                      Figure 4: Errors identifying the value of the abstract feature
           ROOM    CORRIDOR    BACK-WALL    CORNER
                                                      ROOM. Grid locations with marks indicate errors; ranging from
 Baseline  70.1%     78.9%        75%        90.6%    small circles (error in a single orientation) to large circles (error
 10 tests  87.1%     96.2%        100%       98.6%    in all four orientations).
 50 tests  88.3%     97.6%        100%       100%
 250 tests 91.5%     97.6%        100%       99.2%
                                                        The bottom rows in Table 2 (50, 250, and 750 tests) pro-
 750 tests 94.8%     97.6%        99.5%      99.8%
                                                      vide empirical support for the conjecture that larger area ab-
Table 2: Accuracy of PSR-based decision trees when training stractions may need more, longer core tests. Classiﬁcation
on Map A and testing on Map B with various amounts of tests. accuracy of the ROOM abstraction increases substantially as
                                                      more core test values are provided to the classiﬁcation algo-
                                                      rithm. The number of leaf nodes in the decision tree grows
Discussion                                            from 9 leaves with 10 core tests, to 20, 44, and ﬁnally 55
The transfer results, shown in Table 2, show the accuracy of with 50, 250, and 750 core tests respectively. This seems to
the decision trees for all four abstract features when tested on indicate that it is not the sheer volume of tests that is improv-
Map B. All of the accuracies are very good, close to perfect ing the quality of the classiﬁer: which tests are used makes a
with the exception of the ROOM abstraction. ROOM is par- difference in the accuracy of the classiﬁer.
ticularly hard, not only because it is vague, but because the A small amount of classiﬁcation accuracy was lost as we
ROOM  feature is locally aliased. That is, there are places in moved up to 750 core tests, presumably because the low ra-
Map B labeled as not ROOM that look very similar to areas tio of features to training examples allowed the classiﬁer to
in Map A labeled as ROOM. This is evident in the bottom- overﬁt the training data.
left and middle-right rooms in Figure 1. Both of these rooms Figure 4 shows the location of misclassiﬁed ROOM feature in
have sections that look locally very much like the double wide Map B. The decision tree induced from 250 tests makes mis-
area from the top of Map B in Figure 2, which is labeled as takes in cells that appear locally similar but have the opposite
not ROOM.                                             labeling in Map A. The decision tree also misclassiﬁes certain

                                                IJCAI-07
                                                  1081