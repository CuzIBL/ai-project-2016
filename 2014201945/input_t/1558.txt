              Combining Learning Constraints and Numerical Regression

                                      Dorian  Sucˇ 1,2, Ivan Bratko2
              1National ICT Australia, Sydney Laboratory at UNSW, NSW 2052, Australia
                 2Faculty of Computer and Information Science, University of Ljubljana
                                  Trˇzaˇska 25, 1000 Ljubljana, Slovenia
                                 {dorian.suc, ivan.bratko}@fri.uni-lj.si

                    Abstract                            Qualitatively faithful quantitative learning, called Q 2
                                                      learning for short, was proposed [Sucˇ et al., 2004] to rectify
    Usual numerical learning methods are primarily    the qualitative problems of numerical learning. Q 2 learning
    concerned with ﬁnding a good numerical ﬁt to data combines qualitative and numerical learning to give numer-
    and often make predictions that do not correspond ical predictions that both ﬁt the data well and are consistent
    to qualitative laws in the domain of modelling or
                                        2             with an induced qualitative model. The qualitative consis-
    expert intuition. In contrast, the idea of Q learn- tency is beneﬁcial in terms of explanation of phenomena in a
    ing is to induce qualitative constraints from training modelled domain. Quite surprisingly, a case study with Q 2
    data, and use the constraints to guide numerical re- learning shows that induced qualitative constraints can also
    gression. The resulting numerical predictions are improve numerical accuracy. This paper extends the previous
    consistent with a learned qualitative model which work in several directions.
    is beneﬁcial in terms of explanation of phenomena   One contribution of this paper is a Q2 learning scheme that
    in the modelled domain, and can also improve nu-  combines learning of monotonic qualitative constraints with
    merical accuracy. This paper proposes a method for an arbitrary numerical learner and enables us to study accu-
    combining the learning of qualitative constraints racy beneﬁts of the induced constraints. Qualitative learning
    with an arbitrary numerical learner and explores  has been previously used in a number of applications that are
    the accuracy and explanation beneﬁts of learning  mainly tied to dynamic systems and control. In these applica-
    monotonic qualitative constraints in a number of
                           2                          tions, advantages in terms of explanation and in terms of the
    domains. We show that Q  learning can correct     control performance of the induced qualitative models were
    for errors caused by the bias of the learning algo- observed. Since these models deﬁne only constraints on a
    rithm and discuss the potentials of similar hierar- class variable, a direct assessment of their accuracy beneﬁts
    chical learning schemes.                          was previously not possible. The second contribution is an
                                                      empirical evaluation in a number of domains and a demon-
                                                      stration that such regression, guided by induced qualitative
1  Introduction                                       constraints, often increases numerical accuracy.
Learning understandable models is one of the main goals of We analyze the reasons for these accuracy improvements
machine learning, but has been recently overshadowed by and show that Q2 learning corrects for errors caused by the
methods that mainly concentrate on classiﬁcation or regres- bias of a learner. In this respect Q2 learning is similar to
sion accuracy. Less effort has been devoted to improving ensembles of classiﬁers, in particular approaches that com-
the explanation strength of machine learning methods. In- bine classiﬁers constructed by different learning algorithms,
duced models are often too complex and overly detailed to e.g. combining instance and model-based learning [Quin-
provide an understandable explanation of phenomena in a lan, 1993] or stacking and its variations [Wolpert, 1992;
modelled domain. This is particularly notable with methods Gama and Brazdil, 2000; Todorovski and Dˇzeroski, 2003 ].
that achieve excellent accuracy by constructing ensembles of An important distinction of Q2 learning is the (qualitative)
classiﬁers (overview in [Dietterich, 1998]). Another problem, consistency of models at different levels of abstraction.We
illustrated and discussed in [Sucˇ et al., 2004], is that state-of- discuss advantages of similar hierarchical learning schemes
the-art numerical machine learning methods often make pre- and we demonstrate that explanation improvements do not
dictions that a knowledgeable user ﬁnds obviously incorrect necessarily come at the price of lower accuracy.
– not so much in numerical, but in qualitative terms. Such In Section 2 we describe the Q2 learning scheme proposed
qualitative errors of numerical predictors are undesirable par- in this paper. The elements and the details of Q2 learning
ticularly because they make numerical results difﬁcult to in- are described in Section 3. Then we give experimental results
terpret. The underlying mechanism in the domain is usually in various domains and study accuracy improvements using
best explained in qualitative terms. However, this is obscured bias-variance decomposition. Section 5 discusses results and
by qualitative errors in numerical predictions.       beneﬁts of Q2 learning, and gives directions for future work.2  Q2  Learning with QUIN and Qﬁlter                                       I d 1.57 
                                                                      d               >
The idea of Q2 learning is to combine qualitative and numer-
                                                                    +,+                 -,+
ical learning to ﬁnd a regression function that ﬁts the data    Y= M  (I, L)       Y= M   (I, L)
well and is consistent with an induced qualitative model. In
this paper, Q2 learning consists of two stages:
                                                      Figure 1: A qualitative tree induced from examples for the
                  1
 1. Program QUIN   (described in Section 3.1) induces a function Y = L sin(Φ), where 0 ≤ Φ ≤ π and L>0. The
    qualitative tree from numerical training examples. Qual- right leaf, which applies when Φ >π/2, says that Y is mono-
    itative trees are similar to decision trees, but have mono- tonically decreasing in Φ and monotonically increasing in L.
    tonic qualitative constraints in their leaves.
 2. Algorithm Qﬁlter (described in Section 3.2) uses the in-   Data points
                                                               Points satisfying C = M+(A)
    duced qualitative tree, plus training examples, plus class 5
    predictions of an arbitrary numerical learner, to alter the
    predictions to respect the induced qualitative tree. Qﬁl- 4
    ter is an optimization procedure that ﬁnds the minimal
    quadratic changes in class values that achieve consis- 3
    tency with the qualitative tree. In our experiments, the

    numerical learners, also called base-learners, are regres- class  C = M+(A) 2
    sion trees, model trees and locally weighted regression.
                 2                                                                          attribute A
  In this paper, a Q learner consists of a qualitative con- 1
                                                             0    1     2     3     4     5    6     7
straints learner and a numerical base-learner, and can be de-
         2
noted by Q (qual-learner, base-learner). We abbreviate the Figure 2: Achieving consistency with MQC C = M +(A):
common case Q2(QUIN, base-learner) simply as Q2base-
                                                      class values ci (denoted by circles) are changed into c i + di
learner. This learning scheme is particulary interesting be- (denoted by crosses) by minimizing the sum of squared
cause base-learner’s predictions are changed optimally in the
                                                      changes di. The arrows denote the class changes di.
sense of squared error. Therefore, the differences between
base-learner’s predictions and Q2 predictions come just from
induced qualitative constraints.                      the tree. Note that a simple qualitative tree can describe a rel-
                                                      atively complicated nonlinear function. Such qualitative trees
3  Elements of   Q2 Learning                          are induced from numerical data by learning program QUIN
                                                      [Suc,ˇ 2003].
3.1  Monotonic Qualitative Constraints,                 QUIN constructs a qualitative tree in a top-down greedy
     Qualitative Trees and QUIN                       fashion, similar to decision or regression tree learning algo-
Monotonic qualitative constraints (MQCs) are a kind of rithms. The split selection criterion is based on the minimum
monotonicity constraints that are widely used in the ﬁeld description length principle and takes into account the encod-
of qualitative reasoning and are a generalization of mono- ing complexity of the subtrees, the consistency of the MQCs
tonic function constraint used in QSIM [Kuipers, 1994].A in the subtrees with the corresponding data, and the “ambi-
simple example of an MQC is: Y = M +(X). This says    guity” of the MQCs with respect to the data (the more unam-
that Y is monotonically increasing in its dependance on X, biguous qualitative predictions the MQC can make, the bet-
i.e. whenever X increases, Y also increases. In general, ter).
MQCs can have more than one argument. For example,
       +,−                                            3.2  Qﬁlter Algorithm
Z =  M    (X, Y ) says that Z is monotonically increasing
in X and monotonically decreasing in Y . If both X and Y Qﬁlter handles each leaf of a qualitative tree separately. It
increase, then according to this constraint, Z may increase, ﬁrst splits the examples according to the qualitative tree and
decrease or stay unchanged. In such a case, an MQC cannot then changes class values to achieve consistency with MQCs
make an unambiguous prediction of the qualitative change in in corresponding leaves.
Z.                                                      Let us ﬁrst observe a simple example in Figure 2. We have
  Qualitative trees are similar to decision trees, but have eight examples (ai,ci), i=0, 1, ..., 7. Class C has values ci
monotonic qualitative constraints in the leaves. Figure 1 gives and attribute A has values ai=i. The examples are not con-
                                                                                =   +(  )
an example of a simple qualitative tree. This qualitative tree sistent with the given MQC C M A , because the MQC
                                  =   sin(Φ)          requires that ci+1 >ci which is violated at i =1and i =4.
is a qualitative model of the function Y L  , where                                      +
0 ≤ Φ ≤ π and L>0. It describes how Y qualitatively de- To achieve consistency with C = M (A), class values
pends on attributes Φ and L. The tree partitions the attribute should be changed into ci + di, where the unknown param-
space into two regions that correspond to the two leaves of eter di denotes the change in the i-th class value. Class
                                                      changes di are constrained by MQC-imposed inequalities:
  1QUIN  with a graphical user interface, Qﬁlter and lo- ci+1 + di+1 >ci + di where i =0, 1, ..., 6. These inequal-
cally weighted regression as a base-learner are available at ities can be formulated in matrix notation as Ad > b, where
http://ai.fri.uni-lj.si/dorian/q2/quin.htm.           d is a vector of unknown parameters di, vector b has ele-ments bi = ci − ci+i, and matrix A has elements ai,i = −1,
ai,i+1 =1and zeros elsewhere. In general, b and A depend
on the MQC-imposed inequalities, which in turn depend on
the MQC and on the ordering of attributes’ values.
  Therefore, ﬁnding minimal quadratic changes in class val-
ues that achieve consistency with a given MQC can be posed
as the quadratic programming optimization problem: ﬁnd
                                      T
vector d that minimizes the criterion function d Hdsuch that Figure 3: A planar two-link, two-joint robot arm. The ﬁrst
Ad  > b. In the above formulation matrix H is the identity link is extendible with length L1 ranging from 2 to 10.
matrix. In general H can be changed to differently penalize
the changes in class values as described in Section 3.3.
  Since the criterion function with diagonal matrix H is a ples, a base-learner is used to predict class values of test ex-
convex function, and because the linear constraints Ad > b amples. The same training examples are used for QUIN to
deﬁne a convex hull, a local minimum of the criterion func- induce a qualitative tree. The qualitative tree, the training
tion is a globally optimal solution. A more elaborate descrip- and the test examples with base-learner’s class predictions
tion of Qﬁlter, deﬁning also the appropriate ordering of class are then used by Qﬁlter to give predictions that are consis-
values when more than one attributes are used in an MQC, tent with the qualitative tree. This procedure is then repeated
is given in [Sucˇ and Bratko, 2003]. In previous work Qﬁlter (for example, ten times with ten-fold cross-validation) with
was used with qualitative trees derived manually from domain different training and test examples.
                                                        In the experiments we compare root relative squared er-
knowledge. Here we use it in a different and a more challeng-                                    2
ing context, where qualitative trees are induced from data. rors (RREs for short) of the base-learner and the Q learner.
                                                      Here, the RRE is the root mean squared error normalized by
                 2
3.3  Qﬁlter for Q  Learning                           the root mean squared error of average class value. The base-
Qﬁlter is supplied with a qualitative tree, training exam- learners in our study are regression and model trees [Breiman
ples with their class values and test examples with the base- et al., 1984; Quinlan, 1993], and locally weighted regres-
learner’s class predictions. Qﬁlter then adjusts the class val- sion [Atkeson et al., 1997]. The ﬁrst two base-learners were
ues of the training and the test examples to achieve consis- chosen because they are well-established numerical learners
tency with the qualitative tree.                      that provide a symbolical model. Locally weighted regres-
  One improvement of Qﬁlter is to use the base-learner’s sion (LWR for short) does not provide a model explaining
conﬁdence estimates in its predictions. In this case, Qﬁlter a studied domain, but often gives more accurate predictions
                                                      than model or regression trees. With such base-learners, the
makes smaller adjustments to the class values with higher                   2
conﬁdences at the expense of larger changes of class val- explanation beneﬁts of Q learning are even more obvious.
ues that have lower conﬁdences. This is achieved by chang- In experiments we used our implementations of these base-
ing the quadratic programming criterion function. Namely, learners. Our regression and model trees use cost-complexity
matrix H is changed from the identity to a diagonal matrix pruning [Breiman et al., 1984] and smoothing. LWR uses
with elements hi,i = wi. Weight wi is computed from the Gaussian weighting function with local optimization to set
base-learner’s conﬁdence estimate in the i-th class value. Of the kernel size at each prediction point. We also give RREs of
course, the computation of weight wi depends on a type and M5 model trees [Quinlan, 1993] and its Weka implementation
                                                      called M5Prime [Witten and Wang, 1997] to show that we are
a scale of conﬁdence estimates, but would generally be larger       2
if a numerical predictor is more conﬁdent in the i-th class not comparing Q to base-learners that perform poorly. With
                                                      all learners, default values of their parameters were used.
prediction.                                                                         2
  Based on this idea, we used a heuristic weighting function: We analyze the reasons for the Q accuracy improvements
                                 2
                          −(ci−µ)                     using bias-variance decomposition [Geman et al., 1992] and
wi =1+sign(µ−ci)(1−exp (          )), where ci denotes
                             2σ                       draw some interesting conclusions.
base-learner’s conﬁdence in the class prediction of the i-th
test example, and µ and σ denote the mean and the standard 4.2 Robot Arm Domain
deviation of base-learner’s conﬁdences over all test examples.
Therefore, the weight of a test example is between zero and Here we describe experiments in the domain of a planar two-
two. The weight of all training examples is set to two. In link, two-joint robot arm depicted in Figure 3. The angle in
experiments with locally weighted regression, conﬁdence es- the shoulder joint is denoted by Φ1 and the angle in the elbow
                                                                       Φ          Φ
timates ci were set to the sizes of conﬁdence intervals. Model joint is denoted by 2. Angle 1 is between zero and π,
and regression trees do not provide similar conﬁdence esti- while Φ2 is between −π/2 and π/2. The ﬁrst link, i.e. the
mates. For this reason, conﬁdence estimates of all test exam- link from the shoulder to the elbow joint, is extendible with
ples were set to one.                                 length L1 ranging from 2 to 10. The second link has ﬁxed
                                                      length 5. Y-coordinates of the ﬁrst and the second link ends
4  Empirical Evaluation                               are denoted by Y1 and Y2 respectively. We experimented with
                                                      four learning problems that differ in class variable (Y 1 or Y2)
4.1  Experimental Details                             and the attributes used for learning. These learning problems
Here we evaluate accuracy beneﬁts of Q2 learning with var- were deﬁned to pose increasingly more difﬁcult problems to
ious numerical base-learners. Given a set of training exam- Q2 learning.Figure 4: Comparing RREs of base-learners and Q 2 learners in learning problems A, B, C and D with 0%, 5% and 10% noise.

                                                      that in general our base-learners are much more accurate than
Table 1: RREs of LWR, model (Mt) and regression trees (Rt)
                     2                                M5Prime on these learning problems. Although we are here
and the corresponding Q learners with no noise. The last not interested in comparison of different base-learners, it is
column gives RREs of M5Prime.                         good to know that with Q2 we are not improving the base-
          Q2             Q2           Q2
     LWR     LWR   Mt      Mt    Rt     Rt   M5Pr     learners that perform poorly.
 A   0.187  0.145 0.264  0.238  0.327 0.293  0.512      The signiﬁcance of the Q2 accuracy improvements for each
 B   0.196  0.139 0.159  0.146  0.318 0.263  0.462
                                                      learning problem was tested using the resampled paired t test.
 C   0.327  0.300 0.336  0.324  0.434 0.378  0.489                        ×                  ×
 D   0.403  0.362 0.366  0.363  0.542 0.448  0.553    Four learning problems three base-learners three noise
                                                      levels gives 36 comparisons of RRE of a base-learner and a
                                                      corresponding Q2 learner. At 5% signiﬁcance level, the Q2
                                                      learners are signiﬁcantly better in 33 comparisons and about
  The easiest learning problem, called problem A, is to pre- the same in only three comparisons. The comparisons where
dict the y-coordinate of the ﬁrst link end given its length and
                  =   (   Φ )                         differences in RRE are not signiﬁcant correspond to model
angle, i.e. learning Y1 f L1, 1 . Other learning problems trees on learning problem D with all three noise levels.
require predicting the y-coordinate of the second link end us-
ing different attributes. In learning problems B and C we Bias-Variance Decomposition
                                   Φ     =Φ   +Φ
helped the learners with a derived attribute sum 1 2, To understand the reasons for the Q2 accuracy improvements
i.e. the deﬂection of the second link from the horizontal.                             [
                      =   (   Φ  Φ   Φ   )            we used bias-variance decomposition Geman et al., 1992;
Problem C is to learn Y2 f L1, 1,  2, sum , while in  Domingos, 2000], which has proved to be a very useful
problem B we also used Y1 as an attribute. Problem D re- tool for understanding machine learning algorithms. Bias-
quires learning Y2 = f(L1, Φ1, Φ2). These problems pose
                                  2                   variance decomposition in regression states that the expected
increasingly more difﬁcult problems to Q learning. The eas- squared error of a learner on test example x is the sum of the
iest is problem A, because a correct qualitative model is a irreducible noise N(x), the bias B(x) and the variance V (x).
simple qualitative tree, given also in Figure 1. Learning prob-
                           2                          The bias B(x) of the learner on an example x is the squared
lem D is the most difﬁcult for Q , since a correct qualitative difference between the true value and the mean prediction on
model cannot be expressed by a qualitative tree.      x                                         B(x)
                                                 2      over all possible training sets. Here deﬁned bias is in
  To compare accuracy of different base-learners and Q the literature called also squared bias, but we use the notation
learning we generated examples where angles Φ 1 and Φ2 from [Domingos, 2000] and call it bias. The variance V (x) is
and link length L1 were randomly generated from a uniform the expected value of the squared difference between the true
distribution. We experimented with different percentages of value and the mean prediction on x. The bias measures the
Gaussian noise in the class variable. Noise percentage p% systematic error incurred by a learner, and the variance mea-
means that the standard deviation of noise is p × dc/100, sures the error incurred by its ﬂuctuations around the central
where dc denotes the difference between maximal and min- tendency in response to different training sets. Irreducible
imal class value. We used 100 training examples and mea- noise is the error of the optimal (Bayes) model and is in gen-
sured accuracy on separate test sets of 200 examples with- eral very difﬁcult to estimate. However, we are here using an
out noise. All results are averages on 20 randomly generated artiﬁcial learning problem and can therefore measure the bias
training and test sets.                               and variance by directly simulating the deﬁnitions.
  Table 1 gives RREs of LWR, model and regression trees We used 100 training sets of size 100, generated as in the
and Q2 learning that uses these base-learners. For compar- previous experiment and measured the average bias and aver-
ison RREs of M5Prime model trees are also given. Results age variance on a test set of 810 equidistant data points. We
with zero, 5%, and 10% noise are given in Figure 4. In all of refer to these averages over different training sets and differ-
the learning problems and with all noise levels, Q 2 improves ent test examples simply as bias and variance. Comparing the
the average RREs of all base-learners. These improvements base-learners we noticed that regression trees have the highest
in accuracy depend on the base-learner and the learning prob- variance. This is in accordance with their complexity – they
lem. Generally, the improvements are the greatest with re- usually had more than 20 leaves. Model trees are smaller and
gression trees and the smallest with model trees. It is notable have the smallest variance when no noise, but with increas-Table 2: Description of data sets and average 10-fold cross-validation root relative squared errors (RREs) of base-learners and
the corresponding Q2 learners. The last column gives RREs of M5 where this is available, and M5Prime otherwise.
   Data set   Cases   Attributes  LWR    Q2LWR     Mod.tr.  Q2Mod.tr.  Reg.tr. Q2Reg.tr.   M5
  AutoMpg      398      5/8      0.361    0.380     0.374     0.386     0.459    0.405    0.383
  AutoPrice    159     16/16     0.380    0.346     0.523     0.364     0.435    0.381    0.402
   Housing     506     12/13     0.373    0.363     0.422     0.358     0.532    0.454    0.431
 MachineCpu    209      6/6      0.353    0.317     0.370     0.334     0.460    0.377    0.414
    Servo      167      2/4      0.478    0.457     0.588     0.584     0.508    0.504    0.536
 CraneSkill1   354      3/3      0.142    0.065     0.194     0.086     0.091    0.049    0.247
 CraneSkill2   618      3/3      0.249    0.169     0.190     0.159     0.191    0.165    0.215
  AntiSway     200      4/4      0.414    0.157     0.319     0.250     0.193    0.165    0.412

                                                 2                    vgain d 3  Servo qualitative tree 
ing noise the variance increases most notably. Comparing Q      d             >
learners to the corresponding base-learners we noticed that
 2
Q  always notably reduces the bias of the base-learners. This M-(pgain)     M+,-(pgain,vgain)
happens in all four learning problems, with all three base-
learners and different noise levels. For example, in problem      peakRpm d 5000 AutoPrice qualitative tree 
D with no noise, Q2 reduces bias and variance of LWR from
                                                                              >
3.85 and 2.57 to 2.13 and 1.99, respectively. Q 2 always no-      d
tably decreases the variance of regression trees, but some-     height d 53 losses d 110 
times increases the variance of LWR and model trees. The
base-learners, used here, have a bias towards linear models. It M1
seems that Q2, with less restrictive monotonicity constraints, losses d 110 engSize d 140 wheelBase d 99.8 
reduces their bias, but does not considerably increase the vari-
ance.                                                   M2       M3       M4      M5         M6      M7
  Q2 learning combines hypotheses of two different learning
                                                       M1: M-,+,-(ctyMpg,stroke,peakRpm)    M2: M+,+(curbWght,width) 
algorithms, i.e. a qualitative learner and a numerical learner. M3: M+(losses)       M4: M+,-(curbWght,ctyMpg)
In this respect it is similar to ensembles of classiﬁers and in M5: M+(wheelBase)      M7: M-(compRatio)
particular approaches that combine classiﬁers constructed by M6: M-,+,+(ctyMpg,bore,curbWght)
different learning algorithms, as for example stacking and its
variations. Such methods improve accuracy mainly by reduc- Figure 5: Qualitative trees induced from data sets Servo and
ing the error due to the bias of a learner. This is the conse- AutoPrice. MQCs in leaves of each qualitative tree give
quence of combining hypotheses that make uncorrelated er- monotonic constraints on the class variable.
rors [Dietterich, 1998]. We believe that such uncorrelated
errors lead to bias reductions also in the case of Q2 learning.
It should be noted that, although Q2 predictions are consis- Data sets CraneSkill1 and CraneSkill2 are the logged data of
tent with an induced qualitative model, they combine both two experienced human operators controlling a crane simula-
the base-learner’s predictions, and the qualitative model. tor. Such control traces are typically used to reconstruct the
                                                      underlying operator’s control skill. The learning task is to
4.3  UCI and Dynamic Domains                          predict the velocity of a crane trolley given the position of the
To explore the potentials of learning similar constraints with trolley, rope angle and its velocity. Data set AntiSway was
a wider range of learning problems we describe experiments used in reverse-engineering an industrial gantry crane con-
with eight data sets. The ﬁrst ﬁve are the smallest regres- troller. This so-called anti-sway crane is used in metallurgi-
sion data sets from the UCI repository [Blake and Merz, cal companies to reduce the swing of the load and increase
1998] with the majority of continuous attributes. A reason the productivity of transportation of slabs. The learning task
for choosing these data sets is also that Quinlan [1993] gives is to learn the control force applied to the trolley, given the
results of M5 and several other regression methods on these desired and the current trolley velocity and the position and
data sets, which enables a better comparison of Q2 to other velocity of the load relative to the trolley.
methods. These data sets are AutoMpg, AutoPrice, Housing, In all experiments, qualitative trees were considerably sim-
MachineCpu and Servo.                                 pler than other induced models. Figure 5 gives examples of
  The other three data sets are from dynamic domains where qualitative trees induced in data sets Servo and AutoPrice.
QUIN has typically been applied so far [Suc,ˇ 2003; Sucˇ and These qualitative trees are considerably simpler than model
Bratko, 2002]. It should be noted that in these domains the trees. In Servo, M5Prime induces a model tree with eleven
primary objective was to explain the underlying control skill leaves, with all four attributes appearing in all eleven linear
and to use the induced qualitative models to control a dy- models. In AutoPrice, M5Prime induces a model tree with
namic system. Until now, it was not possible to measure their ten leaves, with at least ten attributes in each linear model.
numerical accuracy or compare it to other learning methods. Ten-fold cross-validation results are given Table 2. For