                Inferring Image Templates from Classiﬁcation Decisions

                                      Arnab Dhua, Florin Cutzu
                                     Computer Science Department
                                           Indiana University
                                        Bloomington, IN   47405
                                      adhua,ﬂorin@cs.indiana.edu

                    Abstract                          of image templates,orprototypes. Given an input image
                                                      that must be classiﬁed, its degree of match to all templates
    Assuming human image classiﬁcation decisions are  from all classes is estimated, and its class is determined by
    based on estimating the degree of match between a the class of the best matching template. Our goal is to infer
    small number of stored internal templates and cer- the prototypes of each class from a set of images labeled by
    tain regions of the input images, we present an al- human subjects. Therefore, we are seeking to invert the near-
    gorithm which infers observers classiﬁcation tem- est neighbor problem. This particular inverse problem has
    plates from their classiﬁcation decisions on a set of received considerable attention in the machine learning com-
    test images. The problem is formulated as learning munity. A comprehensive, recent review of the ﬁeld is given
    prototypes from labeled data under an adjustable, in [Toussaint, 2002]. One large class of algorithms (Hart’s al-
    prototype-speciﬁc elliptical metric. The matrix of gorithm [Hart, 1968] and its numerous subsequent improve-
    the elliptical metric indicates the pixels that the ments) selects prototypes from among the labeled data points,
    template responds to. The model was applied to    a restriction that cannot be applied to our problem due to the
    human psychophysical data collected in a simple   presence of pixel noise in the test images.
    image classiﬁcation experiment.
                                                        Our algorithm belongs to the so-called prototype genera-
                                                      tion methods, which creates prototypes at new locations in
1  Introduction                                       feature space. The ﬁrst such algorithm ([Chang, 1974])re-
Consider a psychophysical experiment in which subjects clas- peatedly merged nearest neighboring points from the same
sify a set of images into two classes. The image classes are class as long as the classiﬁcation error rate did not increase.
designed such that correct responses require that the subjects [Bezdek et al., 2001] and later [Mollineda et al., 2002] re-
detect the presence of certain features in certain regions of ﬁned [Chang, 1974] by recursively merging clusters based on
the image. Given the images, and the subjects’ classiﬁcation geometrical criteria.
decisions, is it possible to infer the feature templates the sub- The nearest neighbor rule has been generalized by the use
jects have developed and employed?                    of an adaptable metric, a technique also employed in this
  This represents an inverse problem in perception, in which paper, albeit differently. In [Hastie and Tibshirani, 1996]
the goal is to invert a “direct” model for the subject’s re- the metric is locally adapted to the training point neighbor-
sponses with the goal of deriving the perceptual features used hood surrounding the query point at the time of classiﬁcation.
by the subject. The idea of employing inverse problem tech- In [Friedman, 1994] also a ﬂexible metric is used for dis-
niques is certainly not new in vision research, although it has tance calculation in a neighborhood around the query point.
been initially applied to low-level vision phenomena [Bertero However the ideas of recursive partitioning are used in de-
et al., 1988]. The psychological literature on the subject of termining the neighborhood for the query point. In [Ricci
inverting perceptual similarity data is dominated by research and Avesani, 1999] a reduced set of prototypes is selected
on multidimensional scaling methods (MDS). Metrical MDS from the training examples and a different metric is associ-
[Shepard, 1980] is probably the oldest inversion method al- ated with each of the selected prototypes. This varies from
lowing the derivation of features from similarities. A neural our approach in two ways. Firstly, the authors in [Ricci and
net-based inversion method for extracting features from judg- Avesani, 1999] select the prototypes essentially in a random
ments of similarity is presented in [Lee, 1998]. More recent manner. Secondly, we select prototypes that in general do not
work in this direction has addressed the derivation of fea- coincide with the training data points;
tures involved in higher-level perceptual phenomena [Cutzu A work whose spirit is similar to the present paper is [Xing
and Tarr, 1999; Cutzu, 2000].                         et al., 2003]: the authors discuss the problem of learning a
  The model for the subjects’ decisions in the image classi- global (that is, valid throughout feature space) elliptical met-
ﬁcation task considered in this work is a generalized nearest- ric for 1-NN classiﬁcation from classiﬁcation data. The met-
neighbor (1-NN) classiﬁer, presented in detail in Section 2. ric is ﬁtted to the subject data by solving a convex optimiza-
Each of the two image classes is represented by a small set tion problem.2  A model for prototype-based image                    2. At iteration step t there are Kt prototypes. Consider
   classiﬁcation                                          the points assigned to prototype k (k =1,...,Kt)by
                                                          Gaussian clusters. There are nk1 class 1 and nk2 class
Perceptual considerations required the use of a prototype-
                                                          2 such points, with nk = nk1 + nk2.Ifnk1 >nk2,
based image classiﬁer in which the various prototypes (the then the prototype is labeled 1, otherwise it is labeled
image templates) “specialize” in various regions of the im- 2. The points of the minority class are, therefore, mis-
age, i.e., a template pays more “attention” to some pixels than classiﬁed by this prototype. The “impurity” of the pro-
to others. This was modeled as follows. Let x ∈ Rd be an
                     d                                    totype was deﬁned as the misclassiﬁcation rate: rk =
input image and ck ∈ R one of the templates. This proto-
                                                          1 − max   nk1 , nk2 . If the impurity of prototype k is
type is characterized by a positive (semi) deﬁnite matrix Qk        nk  nk
which modulates the distance (degree of match) between the greater than some user-deﬁned threshold g, rk >g, then
template and the image:                                   prototype k is considered for being split into two proto-
                 2           T                            types (just like a node in a classiﬁcation tree is split when
          d(ck, x) =(x  − ck) Q  (x − c).       (1)
                                k                         too impure). The splitting is performed only if the split-
The elliptical metric matrix Qk speciﬁes the combination of ting reduces the impurities in the two resulting clusters.
image pixels the template ck “specializes” in. In the special If a node does get split, we obtain a class 1 and a class
case where Qk is diagonal, the distance above reduces to: 2 prototype. These “child” prototypes are placed at the
                   d                                     centers of mass of the nk1, respective nk2 points. Due
               2                         2                                                          ≥
        d(ck, x) =    Qk(i, i)[x(i) − ck(i)]    (2)       to splitting, at the end of this step there are Kt+1 Kt
                   i=1                                    prototypes.
                                                          If no prototypes are split, go to Step 4, else go to Step 3.
where Qk(i, i) ≥ 0. The pixels i for which Qk(i, i)=0
are ignored by the template ck. This distance measure is 3. Re-apply Gaussian clusters to the data set, ignoring
termed elliptical. Under the elliptic norm, the set of points point labels. Gaussian clusters is initialized with the
(each point in pixel space represents an input image) that lie Kt+1 prototypes determined at Step 2. Go to Step 2.
at equal distance to the prototype is no longer a hypersphere, 4. The algorithm also returns a global classiﬁcation error
as for the Euclidean metric, but a hyper-ellipsoid of arbitrary rate which measures the errors caused by using the pro-
shape and orientation. Each template is characterized by a totypes for classiﬁcation. This error rate is deﬁned by
different ellipsoid. Interestingly, by endowing each prototype the total number of minority class points at all proto-
with its own, elliptical metric, the resulting Voronoi cells are types. The prototypes are labeled according to the ma-
not necessarily convex or even connected.                 jority class at the prototype. Thus, for each prototype a
  An equivalent formulation is derived by using similarity
                                                          center (ck), a covariance matrix (W k), and a class label
(rather than distance) to prototype: a point is assigned to the are returned.
most similar prototype. We deﬁne the similarity to proto-
type as the probability of the point “belonging” to the pro- Observations: i) The algorithm has as sole adjustable pa-
totype and we associate a Gaussian pdf with each proto- rameter the impurity threshold g. The number of prototypes
type. The shape of the Gaussian varies from prototype to of either class is determined automatically. ii) The class la-
prototype, playing the role of the metric matrix Qk.The bels of the points are solely used in splitting decisions, and
similarity of point i to prototype k is, therefore: sik = are irrelevant to the Gaussian k-means algorithm. iii) Note
              T
exp −(xi − ck) Qk(xi  − ck) . Or, expressed in Gaussian the similarity to classiﬁcation and regression trees (CART).
pdf form:
                                                      The Gaussian clusters algorithm ﬁts K Gaussian clusters
                              T   −1                  to input data set. The Gaussian clusters algorithm is ba-
     s(ck, xi) = exp −(xi − ck) W   (xi − ck)   (3)
                                  k                   sically like k-means clustering except that each center also
                           −1
where the covariance W k = Qk . Therefore, under the 1- has a covariance matrix associated with it. So for every itera-
NN rule, point xi is assigned to the prototype whose Gaussian tion of the Gaussian clusters algorithm when the new centers
is the largest at xi.                                 are being estimated we also estimate the new covariance ma-
                                                      trices. This covariance matrix distorts the attraction of each
3  Finding prototypes for elliptical-metric           center along the different dimensions.
   1-NN classiﬁers
                            d
Each of the N points xi ∈  R  (the images) is labeled 4   Results: Artiﬁcial data
     1        2              1          2
class or class . We seek class- and class- prototypes We applied our prototype ﬁnding algorithm to several syn-
which correctly label the N points under the 1-NN rule using thetic data sets, illustrated in Figures 1-3. These synthetic
the elliptical-norm-based similarity measure in Equation (3). data sets were generated in two dimensions (two pixel im-
                                              c
Computing a prototype entails determining its location k as ages), so that the structure of the point clouds are clearly vis-
                    Q
well as its metric matrix k.                          ible.
  Our prototype ﬁnding algorithm is as follows:         In experiment 1 (Figure 1) there were 320 points of class 1
 1. Start with two prototypes, derived by applying Gaussian (blue) and 380 points of class 2 (red). The class 1 points were
    clusters (algorithm explained below) with two centers to arranged in a single vertical band and the class 2 points were
    the full data set. Go to step 2.                  shared by 1 vertical and 1 horizontal band. As expected threecenters have been assigned to the three distinct point clouds
based on the desired purity tolerance.


                                                      Figure 3: Left: Training set: class 1 points are blue (dots)
                                                      and class 2 points, red (circles). Right: The algorithm has
                                                      found two prototypes, whose centers are indicated by yellow
                                                      circles. The green lines indicate the axes of the Gaussians.
                                                      The cyan/magenta points (if present) are misclassiﬁed.
Figure 1: Left: Training set: class 1 points are blue (dots)
and class 2 points, red (circles). Right: The algorithm has by additive Gaussian pixel noise at one of four possible lo-
found three prototypes, whose centers are indicated by yellow cations. The location of the square is randomly chosen on
circles. The green lines indicate the axes of the Gaussians. each trial. Two of the possible locations are above the ﬁxa-
The cyan/magenta points (if present) are misclassiﬁed. tion point and two are below the ﬁxation point, with each lo-
                                                      cation being equidistant from the central ﬁxation point. Noise
  In experiment 2 (Figure 2) there were 340 points of class is added to each pixel in each of the four locations, with each
1 (blue) and 340 points of class 2 (red). The points were ar- location divided into a 4 × 4 grid of pixels. No noise is added
ranged into two non-overlapping, non-concentric circles. As to the regions in between the four square locations, and the
seen in the ﬁgure two prototypes were assigned, one to each ﬁxation point remains on the screen throughout the experi-
circle. Note that the prototype centers are at locations where ment. The observers task is to indicate whether the white
there were no training examples.                      square signal appeared above or below ﬁxation. The contrast
                                                      of the white square is manipulated across trials according to a
                                                      2-down 1-up adaptive staircase procedure to place it at a level
                                                      where performance is at approximately 71% correct. Accu-
                                                      racy feedback is given in the format of a high or low beep.
                                                        Before collecting human subject data two simulations were
                                                      performed using the above experimental setup. The two mod-
                                                      els simulated were the “exemplar” model and the “prototype”
                                                      model. In an “exemplar” model the observers are assumed
Figure 2: Left: Training set: class 1 points are blue (dots) to use multiple noisy “templates” to form a representation for
and class 2 points, red (circles). Right: The algorithm has each category. Each of these templates are compared to the
found two prototypes, whose centers are indicated by yellow input to reach a classiﬁcation decision. The templates used
circles. The green lines indicate the axes of the Gaussians. in the “exemplar” model simulation were the ideal templates
The cyan/magenta points (if present) are misclassiﬁed. (the four signals shown in Figure 4). In a “prototype” model
                                                      observers are assumed to use a single summary representa-
  In experiment 3 (Figure 3), there were 1849 points of class tion for each category. Thus the templates used in the pro-
1 (blue) and 1849 points of class 2 (red). Both the classes totype model simulation were combined versions of the two
were drawn from a gaussian distribution, with different means signals within each category. This resulted in a ’top’ proto-
and standard deviations. Notice the overlap of the two point type template composed of the two top squares and a ’bottom’
clouds. In the results obtained from the algorithm, we can see prototype template composed of the two bottom squares. For
that the points assigned to the class 2 prototype surround the each of these two models a simulation with 16000 trials was
class 1 cluster: this non-convexity is an effect of the elliptical performed.
norm in determining nearest-neighbors.                  Four human subjects were tested. For each subject, 4000
                                                      experimental trials were conducted. The staircase proce-
5  Results: Psychophysical experiment data            dure was used to keep the performance rate for each subject
The prototype ﬁnding algorithm was applied to simulated pegged at around 71% correct.
data and also to human image classiﬁcation data collected in Since each white square was 4 × 4 pixels, the classiﬁcation
a psychophysical experiment in which the subjects had to dis- images viewed by the subjects were 8 × 8 pixels (the cen-
criminate between two classes of visual patterns. The visual ter of the display was a constant gray-level). Therefore, the
pattern discrimination task is illustrated in Figure 4. In this algorithm learned prototypes in 64-dimensional space. The
task, the observer is shown a single white square corrupted simplifying assumption was made that there were no percep-                                                      lus is clearly visible.
                                                        The difference in the behavior of the mask across the “ex-
                                                      emplar” and “prototype” simulations is interesting. In the
                                                      case of the “prototype” simulation it seems that the classi-
                                                      ﬁcation into top (class 1) is made by the presence of darker
                                                      pixels in both the bottom quadrants and vice versa.
                                                        The algorithm yielded interesting results on the human
                                                      subjects. Three subjects (subjects 1,3 and 4) appeared to have
                                                      used four centers, one for each corner square, and thus two
                                                      per class, as can be seen in Figures 9, 11, 12. The masks
                                                      obtained for the subject data show that the pixels considered
                                                      most important do not seem to follow any particular pattern.
                                                      Also the difference in importance across pixels is very small.
Figure 4: Top: The four types of stimuli used in the experi- This seems to lead to the conclusion that the human subjects
ments, presented without noise. Top left and top right repre- based their decision on the entire image rather than on a par-
sent the class “above ﬁxation”, and the bottom left and right ticular quadrant.
represent the class “below ﬁxation”. Bottom: An actual test Interestingly, subject two appears to have used two cen-
image used during the experiments. The correct response is ters, one per class (Figure 10). The two centers correspond
‘bottom’, since the bottom right square is (slightly) brighter. to the two top and bottom corners taken together. Note that
Note the large noise level.                           in no actual stimulus both corner squares are “on” simulta-
                                                      neously. This would correspond, in the language of the psy-
                                                      chology of categorization, to a so-called “prototype model”,
tual interactions between the pixels, and therefore the covari- while the other three subjects operated using an “exemplar
ance matrices associated with the prototypes were restricted model”. The masks in this case are more distinct and like in
to being diagonal. A diagonal covariance matrix has one en- the “prototype” simulation show a stronger response for the
try per pixel, and can be interpreted as an image-sized mask pixels in which the stimulus is absent. This can intuitively be
that indicates which pixels the corresponding prototype pays explained by noting that for example in class ‘top’ no input
attention (responds) to.                              image actually contains a stimulus in both the ‘top left’ and
  The algorithm yielded the expected templates when ap- the ‘top right’ quadrant. However for class ‘top’ both the bot-
                                1
plied to the simulation data. Figure 5 shows the templates tom quadrants can be expected to have a lower contrast value,
obtained on running the algorithm on the “exemplar” model because the stimulus is absent in the lower two quadrants. A
simulation. As expected the centers represent the four dif- similar intuition can be applied to the ‘bottom’ class.
ferent stimuli. The masks shown alongside each center show

the relative importance of each pixel for that template. The # 1, class 2 mask    # 2, class 1 mask
masks are actually the inverses of the diagonal values of the
diagonal covariance matrices. A whiter pixel in the mask in-
dicates that the template is more sensitive to that particular
pixel. The masks are quite noisy but one can see that the pix-
els of the image that include the stimuli are considered more
important by the mask. To show the relative importance of
each of the four quadrants we also displayed the masks aver-
aged over each of the four quadrants (Figure 6). In this ﬁgure
the higher importance of the quadrant containing the stimulus # 3, class 2 mask   # 4, class 1 mask
is clearly visible.
  Figure 7 shows the templates obtained on running the algo-
rithm on the “prototype” model simulation. As expected the
two centers represent the combination of the stimuli that form
each class. The masks shown alongside each center show the
relative importance of each pixel for that template. The masks Figure 5: Templates obtained: The 4 “exemplar” centers and
are again quite noisy but one can see that the pixels of the corresponding masks obtained by running our algorithm on
image that do not include the stimuli are considered more im- the data generated by running an “exemplar” model simula-
portant by the mask. To show the relative importance of each tion.
of the four quadrants we also displayed the masks averaged
over each of the four quadrants (Figure 8). In this ﬁgure the
higher importance of the quadrants not containing the stimu- 6 Discussion
  1The results (Figures 5 - 12) are displayed in a more concise We introduced a prototype generating method for nearest-
format than the format (example Figure 4) used during experiments. neighbor classiﬁcation. Each prototype is endowed with its
In particular, the “ﬁxation point” is not shown and the four, 4 × 4 own elliptical metric, and our method is therefore related
pixel squares are shown adjacent to each other in the results. to adaptive metric methods such as [Hastie and Tibshirani,     # 1, class 2 mask# 1   # 2, class 1 mask# 2                 # 1, class 2            mask# 1


                                                                 # 2, class 1            mask# 2
     # 3, class 2 mask# 3   # 4, class 1 mask# 4


Figure 6: Templates obtained: The 4 “exemplar” centers and
corresponding masks obtained by running our algorithm on
                                                                                   2
the data generated by running an “exemplar” model simula- Figure 8: Templates obtained: The “prototype” centers and
tion. The masks are averaged over each of the four quadrants corresponding masks obtained by running our algorithm on
to give an idea of the overall importance of each quadrant in the data generated by running a “prototype” model simula-
the classiﬁcation.                                    tion. The masks are averaged over each of the four quadrants
                                                      to give an idea of the overall importance of each quadrant in
                                                      the classiﬁcation.
          # 1, class 2              mask

                                                           # 1, class 1 mask      # 2, class 2 mask


          # 2, class 1              mask


                                                           # 3, class 2 mask      # 4, class 1 mask


Figure 7: Templates obtained: The 2 “prototype” centers and Figure 9: Templates obtained: The 4 “exemplar” centers and
corresponding masks obtained by running our algorithm on corresponding masks obtained for subject 1 by running our
the data generated by running a “prototype” model simula- algorithm on the subjects classiﬁcation data.
tion.
                                                      Left) or feature B (Top Right) and class 2 by the presence of
1996] and especially [Xing et al., 2003]. The prototypes are feature C (Bottom Left) or feature D (Bottom Right). Any
not a subset of the data points, and therefore our method be- image contains only one of the four features, and, moreover,
longs in the prototype generation category. However, as op- each feature occupies a speciﬁc image region. The algorithm
posed to Chang’s method and its later reﬁnements ([Bezdek et correctly identiﬁed the regions of the image each prototype
al., 2001], [Mollineda et al., 2002]) we ﬁnd new prototypes “specializes” in.
by recursively splitting clusters, rather than by aggregating In this situation, there are two equally effective decision
them.                                                 strategies available to a nearest-neighbor classiﬁer: 1. store
  The main contribution of this paper lies in the application two prototypes per class, one for each of the features A, B,
of the prototype learning algorithm to understanding human C, D; or, 2. store one prototype per class, one for the com-
image classiﬁcation. If an image classiﬁcation experiment is posite feature (A or B) and one for the composite feature (C
designed such that correct classiﬁcation decisions require the or D). The ﬁrst strategy corresponds, in the terminology of
detection of one of several class-speciﬁc features in certain the psychology of categorization, to categorization by exem-
regions of the image, then nearest-neighbor is an appropri- plar, and the second, to categorization by prototype. Most
ate classiﬁcation model. In the experiment described in this interestingly, our algorithm revealed that one of the subjects
paper, class 1 was deﬁned by the presence of feature A (Top employed the second strategy, and the other three the ﬁrst. It