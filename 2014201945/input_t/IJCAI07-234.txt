  MB-DPOP: A New Memory-Bounded Algorithm for Distributed Optimization

                                    Adrian Petcu and Boi Faltings
         Ecole Polytechnique F´ed´erale de Lausanne (EPFL), CH-1015 Lausanne (Switzerland)
                               email: {adrian.petcu, boi.faltings}@epﬂ.ch


                    Abstract                          decentralized, and asynchronously. It requires polynomial
                                                      memory, but it may produce a very large number of small
    In   distributed combinatorial  optimization      messages, resulting in large communication overheads.
    problems,  dynamic  programming  algorithms         OptAPO   [Mailler and Lesser, 2005] is a centralized-
    like DPOP ([Petcu and Faltings, 2005]) require    distributed hybrid that uses mediator nodes to centralize
    only a linear number of messages, thus generating subproblems and solve them in dynamic and asynchronous
    low communication overheads. However, DPOP’s      mediation sessions. The authors show that its message
    memory  requirements are exponential in the       complexity is signiﬁcantly smaller than ADOPT’s. However,
    induced width of the constraint graph, which may  it is possible that several mediators solve overlapping
    be prohibitive for problems with large width.     problems, thus needlessly duplicating effort. This has been
    We present MB-DPOP, a new hybrid algorithm that   shown in [Petcu and Faltings, 2006] to cause scalability
    can operate with bounded memory. In areas of      problems for OptAPO, especially on dense problems.
    low width, MB-DPOP operates like standard DPOP      DPOP  [Petcu and Faltings, 2005] is a complete algorithm
    (linear number of messages). Areas of high width  based on dynamic programming which generates only a
    are explored with bounded propagations using the  linear number of messages. However, DPOP is time and
    idea of cycle-cuts [Dechter, 2003].               space exponential in the induced width of the problem.
    We introduce novel DFS-based mechanisms for       Therefore, for problems with high induced width, the
    determining the cycle-cutset, and for grouping    messages generated in high-width areas get large, therefore
    cycle-cut nodes into clusters. We use caching     requiring exponential communication and memory.
    ([Darwiche, 2001]) between clusters to reduce the   This paper introduces MB-DPOP, a new hybrid algorithm
    complexity to exponential in the largest number of that is controlled by a parameter k which characterizes the
    cycle cuts in a single cluster.                   amount of available memory. MB-DPOP is a tradeoff of the
    We compare MB-DPOP     with  ADOPT   [Modi        linear number of messages of DPOP for polynomial memory.
    et al., 2005], the current state of the art in      The rest of this paper is structured as follows: Section 2
    distributed search with bounded memory. MB-       introduces the distributed optimization problem. Section 3
    DPOP   consistently outperforms ADOPT on 3        presents the DPOP algorithm, which is extended to the MB-
    problem domains, with  respect to 3 metrics,      DPOP(k) hybrid in Section 4. Section 5 shows the efﬁciency
    providing speedups of up to 5 orders of magnitude. of this approach with experiments on distributed meeting
                                                      scheduling problems. Section 6 discusses related work, and
                                                      Section 7 concludes.
1  Introduction
Constraint satisfaction and optimization are powerful 2   Deﬁnitions and Notation
paradigms that can model a wide range of tasks like   Deﬁnition 1 (DCOP) A   discrete distributed constraint
scheduling, planning, optimal process  control, etc.  optimization problem (DCOP) is a tuple < X , D, R >:
Traditionally, such problems were gathered into a single
                                                        •X=    {X1, ..., Xn} is a set of variables
place, and a centralized algorithm was applied to ﬁnd
a solution. However, problems are sometimes naturally   •D=    {d1, ..., dn} is a set of ﬁnite variable domains
distributed, so Distributed Constraint Satisfaction (DisCSP) •R= {r1, ..., rm} is a set of relations, where a relation
was formalized in [Yokoo et al., 1992]. These problems are r                           (X  , ···,X )  r :
                                                           i is any function with the scope i1    ik , i
divided between a set of agents, which have to communicate d ×  .. × d →  R
                                                           i1       ik     , which denotes how much utility is
among themselves to solve them. Complete algorithms like  assigned to each possible combination of values of the
ADOPT, DPOP and OptAPO have been introduced.              involved variables. Negative utilities mean cost. 1
  ADOPT   [Modi et al., 2005] is a backtracking based
bound propagation mechanism.  It operates completely     1Hard constraints (that explicitly forbid/enforce certain value

                                                IJCAI-07
                                                  1452  DCOPs are multiagent instances of the valued CSP    each other as parent/child or pseudoparent/pseudochild, and
framework, where each variable and constraint is owned by edges are identiﬁed as tree/back edges. The DFS tree serves
an agent. The goal is to ﬁnd a complete instantiation X ∗ as a communication structure for the other 2 phases of the
for the variables Xi that maximizes the sum of utilities of algorithm: UTIL messages (phase 2) travel bottom-up, and
individual relations.                                 VALUE messages (phase 3) travel top down, only via tree-
  A simplifying assumption [Yokoo et al., 1992] is that each edges.
agent controls a virtual agent for each one of the variables Xi Phase 2 - UTIL propagation: the agents (starting from the
that it owns. To simplify the notation, we use Xi to denote leaves) send UTIL messages to their parents. The subtree of a
either the variable itself, or its (virtual) agent.We also assume node Xi can inﬂuence the rest of the problem only through
here only unary and binary relations 2                Xi’s separator, Sepi. Therefore, a message contains the
                                                      optimal utility obtained in the subtree for each instantiation
2.1  Depth-First Search Trees (DFS)                   of Sepi. Thus, messages are size-exponential in the separator
MB-DPOP works on a DFS traversal of the problem graph. size (which is in turn bounded by the induced width).
                                                        Phase 3 - VALUE propagation top-down, initiated by the
Deﬁnition 2 (DFS tree) A DFS arrangement of a graph G is root, when phase 2 has ﬁnished. Each node determines its
a rooted tree with the same nodes and edges as G and the optimal value based on the computation from phase 2 and
property that adjacent nodes from the original graph fall in
                           X      X                   the VALUE message it has received from its parent. Then, it
the same branch of the tree (e.g. 0 and 12 in Figure 1). sends this value to its children through VALUE messages.
  DFS trees have already been investigated as a means to It has been proved in [Petcu and Faltings, 2005] that DPOP
boost search [Freuder, 1985; Dechter, 2003]. Due to the produces a linear number of messages. Its complexity lies
relative independence of nodes lying in different branches of in the size of the UTIL messages: the largest one is space-
the DFS tree, it is possible to perform search in parallel on exponential in the width of the DFS ordering used.
independent branches, and then combine the results.
  Figure 1 shows an example DFS tree that we shall refer to 4 MB-DPOP(k) - bounded inference hybrid
in the rest of this paper. We distinguish between tree edges, We introduce the control parameter k which speciﬁes
                      X  − X
shown as solid lines (e.g. 1 2), and back edges,shown the maximal amount of inference   (maximal message
                 12 − 8 4 − 0
as dashed lines (e.g.  ,    ).                        dimensionality). This parameter is chosen s.t. the available
                                                                                        k
Deﬁnition 3 (DFS concepts) Given a node Xi, we deﬁne: memory at each node is greater than d , (d is the domain
                                                      size).
  • parent Pi /  children Ci: these are the obvious
                                                        The algorithm identiﬁes subgraphs of the problem that
    deﬁnitions (e.g. P4 = X2, C0 = {X1,X8}).
                                                      have width higher than k, where it is not possible to perform
  • pseudo-parents PPi   are Xi’s ancestors directly  full inference as in DPOP. Each of these areas (clusters) are
    connected to Xi through back-edges (PP5 = {X0}).  bounded at the top by the lowest node in the tree that has
                                                                    k
  • pseudo-children PCi are Xi’s descendants directly separator of size or less. We call these nodes cluster roots
    connected to Xi through back-edges (PC1 = {X4}).  (CR).
                                                        In such areas, cycle-cut nodes (CC) are identiﬁed such that
  • Sepi is the separator of Xi: ancestors of Xi which are                                              k
                        X                       X     once these are removed, the remaining problem has width
    directly connected with i or with descendants of i or less. Subsequently, in each area all combinations of values
    (e.g. Sep15 = {X9} and Sep11 = {X0,X8,X9,X10}).
                       Sep                            of the CC nodes are explored using k-bounded DPOP utility
    Removing the nodes in  i completely disconnects the                            [             ]
                  X                                   propagation. Results are cached ( Darwiche, 2001 )bythe
    subtree rooted at i from the rest of the problem. respective cluster roots and then integrated as messages into
                                                      the overall DPOP-type propagation.
3  DPOP: dynamic programming optimization               If k ≥ w (w is the induced width), full inference is done
                                                      throughout the problem; MB-DPOP is equivalent with DPOP.
The basic utility propagation scheme DPOP has been
                                                        If k =1, only linear messages are used, and a full cycle
introduced in [Petcu and Faltings, 2005]. DPOP is an
                                                      cutset is determined. MB-DPOP is similar to the AND/OR
instance of the general bucket elimination scheme from
                                                      cycle cutset scheme from [Mateescu and Dechter, 2005].
[Dechter, 2003], which is adapted for the distributed case,
                                                        If k<w,   MB  −  DPOP(k)   performs full inference in
and uses a DFS traversal of the problem graph as an ordering.
                                                      areas of width lower than k, and bounded inference in areas
  DPOP  has 3 phases:
                                                      of width higher than k.
  Phase 1 - a DFS traversal of the graph is done using
                                                        In the following we explain how to determine high-width
a distributed DFS algorithm, like in [Petcu et al., 2006],
                                                      areas and the respective cycle-cuts (Section 4.1) and what
which works for any graph requiring a linear number of
                                                      changes we make to the UTIL and VALUE phases (Section 4.2
messages. The outcome is that all nodes consistently label
                                                      and Section 4.3). The algorithm is described in Algorithm 1.
combinations) can be simulated with soft constraints by assigning
−∞  to disallowed tuples, and 0 to allowed tuples. Maximizing
utility thus avoids assigning such value combinations to variables. 4.1 MB-DPOP - Labeling Phase
  2However, all *-DPOP algorithms easily extend to non-binary This is an intermediate phase between the DFS and UTIL
constraints, as in [Petcu and Faltings, 2005; Petcu et al., 2006]. phases. It has the goal to delimit high-width areas, and

                                                IJCAI-07
                                                  1453Figure 1: A problem graph (a) and a DFS tree (b). In low-width areas the normal UTIL propagation is performed. In high width
                                                                                               k
areas (shaded clusters C1, C2 and C3 in (b)) bounded UTIL propagation is used. All messages are of size at most d . Cycle-cut
nodes are in bold (X0,X9,X13), and cluster roots are shaded (X2,X9,X14). In (c) we show a 2-bounded propagation.

identify CC nodes in these areas. We emphasize that this cuts, either by the children of Xi or by Xi itself. If |Sepi|≤
process is described as a separate phase only for the sake of k, the function simply returns an empty list.
clarity; these results can be derived with small modiﬁcations
from either of the original DFS or UTIL phases.
                                                      Mechanism 1: highest nodes as CC  The nodes in Ni are
  Labeling works bottom-up like the UTIL phase. Each
                       i                              sorted according to their tree-depth (known from the DFS
node Xi waits for LABEL messages from its children Xj,
                       j                              phase). Then, the highest |Ni|−k nodes are marked as CC.
                           Pi
computes its own label LABELi , and sends it to its parent For example, in Fig. 1, let k =2. Then, Sep12 =
Pi.                                                   {X0,X8,X11},  CClists12  =  ∅⇒N12      =  Sep12  ⇒
     LABELPi
  A         i  message is composed of 2 parts:  the   CC12  = {X0} (X0 is the highest among X0,X8,X11)
separator Sepi of the node, and a list CCi of CC nodes.
  Each node Xi can easily determine its separator Sepi as
                                                      Mechanism 2: lowest nodes as CC  This is the inverse of
the union of: (a) separators received from its children, and (b)            |N |−k
its parent and pseudoparents, minus itself (see Deﬁnition 3). Mechanism 1: the lowest i nodes are marked as CC.
                                                        For example, in Fig. 1, let k =2.  Then, Sep12 =
Formally, Sepi = ∪Xj ∈Ci Sepj ∪ Pi ∪ PPi \ Xi.
                                            CC        {X0,X8,X11},  CClists12  =  ∅⇒N12      =  Sep12  ⇒
  The second part of the LABEL message is the list i of CC  = {X  }  X                    X ,X  ,X
the cycle-cut nodes to send to the parent. Each node computes 12 11 ( 11 is the lowest among 0 8  11)
this list through a heuristic function based on the separator 4.2 MB-DPOP - UTIL Phase
of the node, and on the lists of cycle-cuts received from the
children (see next section).                          The labeling phase (Section 4.1) has determined the areas
                                                      where the width is higher than k, and the corresponding
Heuristic labeling of nodes as CC                     CC nodes. We describe in the following how to perform
   label(Sep ,CClists,k)
Let         i           be a heuristic function that takes bounded-memory exploration in these areas; anywhere else,
as input the separator of a node, the lists of cycle-cuts the original UTIL propagation from DPOP applies.
received from the children, and an integer k, and it returns
another list of cycle cutset nodes.                   Memory-Bounded UTIL Propagation
  It builds the set Ni = Sepi \{∪CClists}: these are nodes The labeling phase has identiﬁed the cluster root nodes
in Xi’s separator that are not marked as CC nodes by Xi’s for each high-width area, and furthermore, the roots have
children. If |Ni| >k(too many nodes not marked as CC), received the lists of cycle-cutset nodes, as designated by their
then it uses any mechanism to select from Ni asetCCnew of children.
|Ni|−k nodes, that will be labeled as CC nodes. The function Let Xi be the root of such a cluster. Just like in DPOP, Xi
                                                                   Pi
returns the set of nodes CCi = ∪CClists ∪ CCnew.      creates a UTILi table that stores the best utilities its subtree
  If the separator Sepi of Xi contains more than k nodes, can achieve for each combination of values of the variables in
then this ensures that enough of them will be labeled as cycle- Sepi. Xi’s children Xj that have separators smaller than k

                                                IJCAI-07
                                                  1454 Algorithm 1: MB-DPOP - memory bounded DPOP.           in case a better utility was found.
                                                                                            X
             X , D, R,k           Xi                     When all the instantiations are explored, i simply sends
   MB-DPOP(           ): each agent does:                                        P
                                                       to its parent the updated UTIL i table that now contains the
   Labeling protocol:                                                            i
                    i                                  best utilities of Xi’s subtree for all instantiations of variables
 1 wait for all LABELj msgs from children
                                                       in Sepi, exactly as in DPOP. Pi then continues propagation
 2 if |Sepi|≤k then                                                                        X
        ∪CClists = ∅                                  as in normal DPOP; all the complexity of i’s processing is
 3    if             then label self as CR             transparent to it.
 4    else label self as normal
                                                         Example  In  Figure 1, let k  =2;thenC2        =
 5    CCi ←∅
                                                       {X9,X10,X11,X12,X13}   is an area of width higher than 2.
 6 else                                                X9  is the root of C2, as the ﬁrst node (lowest in the tree)
 7    let N = Sepi \∪CClists                           that has Sepi ≤ k. Using the Mechanism 1 for selecting CC
 8    select a set CCnew of |N|−k nodes from N         nodes, we have X9,X0 as CC in C2. X9 cycles through all
 9    return CCi = CCnew ∪ CClists                     the instantiations X9,X0, and sends its child(ren) context
               Pi                                      messages of the form X9 = a, X0 = b. These messages
10 send LABELi   =[Sepi,CCi]  to Pi
                                                       travel to X10, X11, X12 and X13 (no other nodes in the cluster
   UTIL
        propagation protocol                           have sent non-empty CClists). Upon receiving the context
          UTILi                         X  ∈ C(i)
11 wait for     k messages from all children k         messages, X12 and X13 start 2-bounded UTIL propagation
     X  =
12 if i   normal node then do UTIL / VALUE as DPOP     (X12 with X11 and X8 as dimensions, and X13 with X11 and
13 else                                                X10 as dimensions).
                                      CClists
 14   do propagations for all instantiation of           It is easy to see that using this scheme, the memory
        X
 15   if  i is cluster root then                       requirements are still O(exp(k)) for the propagation, and
 16      update UTIL and CACHE for each propagation    O(exp(|Sep|)) for the cache tables. Since |Sep|≤k (see
 17      when propagations ﬁnish, send UTIL to parent  section 4.1), overall we observe the memory limit O(exp(k)).

                                   ∗                                     VALUE
   VALUE  propagation(Xi receives Sepi from Pi)        4.3  MB-DPOP -            Phase
 18 if Xi is cluster root then                         The labeling phase has determined the areas where bounded
                       ∗                   ∗
 19   ﬁnd in cache the CC corresponding to Sepi        inference must be applied due to excessive width. We will
 20   assign self according to cached value            describe in the following the processing to be done in these
              ∗
 21   send CC  to nodes in CC via VALUE messages       areas; outside of these, the original VALUE propagation from
 22 else                                               DPOP applies.
                                                ∗                                     X
 23   perform last UTIL with CC nodes assigned to CC     The VALUE message that the root i of a cluster receives
 24   assign self accordingly                          from its parent contains the optimal assignment of all the
                                                                               Sep     X
                     ∗                                 variables in the separator  i of  i (and its cluster).
 25           (Xi ← v )     C(i)    PC(i)
   Send VALUE        i  to all   and                   Xi  retrieves from its cache table the optimal assignment
                                                       corresponding to this particular instantiation of the separator.
                                                       This assignment contains its own value, and the values of
 |Sep |≤k       X        UTILi
 (   j     )send  i normal     j messages, as in DPOP; all the CC nodes in the cluster. Xi informs all the CC
 X
  i waits for these messages, and stores them.         nodes in the cluster what their optimal values are (via VALUE
   For the children Xj that have a larger separator (|Sepj| > messages).
 k), Xi creates a Cache table with one entry Cache(sepi) As the non-CC nodes in the cluster could not have cached
 that corresponds to each particular instantiation of the their optimal values for all instantiations of the CC nodes,
 separator, sepi ∈Sepi (size of the Cache table is thus it follows that a ﬁnal UTIL propagation is required in order
 O(exp(|Sepi|))).                                      to re-derive the utilities that correspond to the particular
   Xi then starts exploring through k-bounded propagation instantiation of the CC nodes that was determined to be
 all its subtrees that have sent non-empty CClists. It does optimal. However, this is not an expensive process, since it
 this by cycling through all instantiations of the CC variables is a single propagation, with dimensionality bounded by k
 in the cluster. Each one is sent down to its children via a (the CC nodes are instantiated now). Thus, it requires only a
 context message. Children propagate the context messages linear number of messages that are at most exp(k) in size.
 again to their children that have sent non-empty CClists. Subsequently, outside the clusters, the VALUE propagation
 This propagates only to nodes that have separators larger than proceeds as in DPOP.
 k, down to the lowest nodes in the cluster that have separators
 larger than k.                                        4.4  MB-DPOP(k) - Complexity
   The leaves of the cluster then start bounded propagation, In low-width areas of the problem, MB-DPOP behaves
 with the nodes speciﬁed in the context message instantiated exactly as DPOP: it generates a linear number of messages
                                                                        k
 to their current value. These propagation are guaranteed to that are at most d in size. Clusters are formed where
 involve k dimensions or less, and they proceed as in normal the width exceeds k.LetT be such a cluster, let |T | be
 DPOP, until they reach Xi. Xi then updates the best utility the number of nodes in the cluster, and let |CC(T )| be
 values found so far for each sepi ∈Sepi, and also updates the number of cycle cut nodes in that cluster. MB-DPOP
 the cache table with the current instantiation of the CC nodes executes d|CC(T )| k-bounded propagation in that cluster, each

                                                 IJCAI-07
                                                   1455      1e+06                                                  1e+06


      100000                                                100000


      10000                                                  10000


       1000                                                  1000
   Runtime  (ms)
                                                         #  of messages

                                     ADOPT                                                 ADOPT
        100                       MB-DPOP(1)                  100                       MB-DPOP(1)
                                  MB-DPOP(2)                                            MB-DPOP(2)
                                  MB-DPOP(3)                                            MB-DPOP(3)
                                  MB-DPOP(4)                                            MB-DPOP(4)
                              MB-DPOP(5)=DPOP                                       MB-DPOP(5)=DPOP
        10                                                     10
           20  40  60  80  100  120  140  160  180               20  40  60  80  100  120  140  160  180
                       Number of variables                                   Number of variables
                                                             1e+08
      Figure 2: MB-DPOP(k) vs ADOPT - runtime
                                                             1e+07

requiring |T |−1 messages. The size of these messages is     1e+06
bounded by dk.
  Therefore, it is easy to see that the overall time/message  100000
complexity is O(exp(|CC(Tmax)|)) where Tmax  is the
                                                             10000
cluster that has the maximal number of CC nodes.                                           ADOPT
                        O(exp(k))                                                       MB-DPOP(1)
  Memory requirements are         by design.                 1000                       MB-DPOP(2)
                                                                                        MB-DPOP(3)
                                                         Total  message size (sum of sizes in bytes) MB-DPOP(4)
                                                                                    MB-DPOP(5)=DPOP
                                                              100
5  Experimental evaluation                                       20  40  60  80  100  120  140  160  180
                                                                             Number of variables
We performed experiments on 3 different problem domains3:
distributed sensor networks (DSN), graph coloring (GC), and Figure 3: MB-DPOP(k) vs ADOPT - message exchange
meeting scheduling (MS).
  Meeting scheduling we generated a set of relatively large
distributed meeting scheduling problems. The model is as improved over ADOPT on some instances for 5 orders of
in [Maheswaran et al., 2004]. Brieﬂy, an optimal schedule magnitude.
has to be found for a set of meetings between a set of agents. Also, notice that even though MB−DPOP(k>1) sends
The problems were large: 10 to 100 agents, and 5 to 60 larger messages than ADOPT, overall, it exchanges much less
meetings, yielding large problems with 16 to 196 variables. information (Fig 3, low). We believe there are 2 reasons for
The larger problems were also denser, therefore even more this: ADOPT sends many more messages, and because of
difﬁcult (induced width from 2 to 5).                 its asynchrony, it has to attach the full context to all of them
  The experimental results are presented in Figure 3 (number (which produces extreme overheads).
of messages and total information exchanged - sum of    The DSN and GC problems are the same as the ones used
all message sizes, in bytes), and Figure 2 (runtime in in [Maheswaran et al., 2004]. For lack of space, we do not
milliseconds)4. Please notice the logarithmic scale! ADOPT present detailed results here, but they align well with the
did not scale on these problems, and we had to cut its meeting scheduling ones.
execution after a threshold of 2 hours or 5 million messages. DSN The DSN instances are very sparse, and the induced
The largest problems that ADOPT could solve had 20 agents width is 2, so MB − DPOP(k ≥ 2) always runs with a
(36 variables).                                       linear number of messages (from 100 to 200 messages) of
  We also executed MB-DPOP with increasing bounds k.  size at most 25. Runtime varies from 52 ms to 2700 ms.
As expected, the larger the bound k, the less nodes will be In contrast, ADOPT sends anywhere from 6000 to 40.000
designated as CC, and the less messages will be required5. messages, and requires from 6.5 sec to 108 sec to solve
However, message size and memory requirements increase. the problems. Overall, these problems were very easy for
  It is interesting to note that even MB− DPOP(1) (which MB-DPOP, and we have experienced around 2 orders of
uses linear-size messages, just like ADOPT) performs much magnitude improvements in terms of CPU time and number
better than ADOPT: it can solve larger problems, with a of messages.
smaller number of messages. For example, for the largest Graph Coloring The GC instances are also small (9 to 12
problems ADOPT could solve, MB − DPOP(1)   produced   variables), but they are more tightly connected, and are even
improvements of 3 orders of magnitude. MB − DPOP(2)   more challenging for ADOPT. ADOPT terminated on all of
                                                      them, but required up to 1 hour computation time, and 4.8
  3All experiments are run on a P4 machine with 1GB RAM million messages for a problem with 12 variables.
  4Each data point is an average over 10 instances      All  three  domains   showed   strong performance
  5Mechanism 1 for CC selection was used.             improvements of MB-DPOP over the previous state of

                                                IJCAI-07
                                                  1456