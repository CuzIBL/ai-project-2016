                          Planning with Goal Utility Dependencies

    Minh B. Do†    and  J. Benton ‡  and Menkes van den Briel    ‡  and Subbarao Kambhampati       ‡
            † Embedded Reasoning Area, Palo Alto Research Center, Palo Alto, CA 94304, USA, minh.do@parc.com
               ‡ CSE Department Arizona State Univ. Tempe, AZ 85287, USA, {j.benton,menkes,rao}@asu.edu


                    Abstract                          changes in utility on sets of goals, thereby increasing its ex-
                                                      pressive power.
    Work in partial satisfaction planning (PSP) has     Two concrete examples of utility dependency are mutual
    hitherto assumed that goals are independent thus  dependency and conditional dependency. For mutual depen-
    implying that they have additive utility values. In dency, the utility of a set of goals is different from the sum
    many real-world problems, we cannot make this     of the utility of each individual goal. For example, (1) while
    assumption. In this paper, we motivate the need   the utility of having either a left or right shoe alone is zero,
    for handling various types of goal utility depen- utility of having both of them is much higher (i.e. the goals
    dence in PSP. We provide a framework for rep-     “complement” each other); (2) utility of having two cars is
    resenting them using the General Additive In-     smaller than the sum of the individual utilities of having each
    dependence model and investigate two different    one of them (i.e. the goals “substitute” each other). Con-
    approaches to handle this problem: (1) compil-    ditional dependency is where the utility of a goal or set of
    ing PSP with utility dependencies to Integer Pro- goals depend on whether or not another goal or set of goals
    gramming; (2) extending forward heuristic search  is already achieved. For example, the utility of having a ho-
    planning to handle PSP goal dependencies. To      tel reservation in Hawaii depends on whether or not we have
    guide the forward planning search, we introduce   already purchased a ticket to Hawaii.
    a novel heuristic framework that combines cost-     The main technical challenges in handling utility depen-
    propagation and Integer Programming to select     dencies are in ﬁnding (1) a model where different types of
    beneﬁcial goals to ﬁnd an informative heuristic es- goal utility dependencies can be compactly expressed and (2)
    timate. The two implemented planners, iPUD and    an approach that effectively combines utility interactions with
    SPUDS, using the approaches discussed above,      cost interactions to ﬁnd a high quality plan. The primary con-
    are compared empirically on several benchmark     tribution of our paper is a systematic approach for handling
    domains. While  iPUD is more readily amend-       cost and utility dependencies together in PSP. In particular we
    able to handle goal utility dependencies and can  present:
    provide bounded optimality guarantees, SPUDS
    scales much better.                                  • An approach for representing utility dependencies be-
                                                           tween planning goals using the Generalized Additive In-
                                                           dependence (GAI) model [Bacchus and Grove, 1995],
1  Introduction                                            combining utility theory and deterministic planning.
                                                         • An extension of a state of the art Integer Programming
Classical planning aims at ﬁnding a plan that achieves a set of
                                                           (IP) planner [van den Briel et al., 2005] to solve this
conjunctive goals. Partial satisfaction planning (PSP) relaxes
                                                           extended PSP problem.
this all-or-nothing constraint, focusing on ﬁnding a plan that
achieves the “best” subset of goals (i.e. the plan that gives • A novel heuristic framework combining cost propaga-
the maximum trade-off between total achieved goal utilities tion and an IP encoding to capture mutual dependencies
and total incurred action cost). The process of ﬁnding goals of goal achievement cost and goal utility. This leads to
on which to focus is complicated by the fact that they in- informative heuristics used for guiding a variation of a
teract with one another. For instance, actions may share in forward state space search planner.
their achievement of goals (positive interaction) or conﬂict
(negative interaction). These types of interactions introduce The two approaches (IP encoding and forward heuristic
cost dependencies between goals because the cost of achiev- search) are implemented, resulting in two planners iPUD and
ing them separately may differ from the cost of achieving SPUDS, and tested on several planning benchmark domains.
them together. In the existing frameworks, goals only inter- While the IP approach is more readily amendable to handle
act through cost dependencies. In this paper we extend PSP goal utility dependencies and can provide bounded optimal-
to handle utility dependency which allows users to specify ity guarantees, we shall see that the heuristic search method
                                                      scale much better.

                                                 IJCAI07
                                                  18722  Problem Formulation                                actions) in each network such that, when merged, they con-
A classical planning problem is a 4-tuple F, I, G, A where: stitute a feasible plan. In the networks, nodes and arcs ap-
ﬂuents F are a set of predicate symbols; initial state I is pear in layers, where each layer represents a plan period. The
completely deﬁned by predicates in F ; goal state G is par- layers are used to solve the planning problem incrementally.
tially deﬁned by a set of predicates in F ; a set of actions That is, we start by performing reachability analysis to ﬁnd a
A with a  ∈  A are deﬁned by pre- and post-conditions lower bound on the number of layers necessary to solve the
Pre(a), Add (a), Delete(a) ⊆ F .AplanP is a sequence of problem. If no plan is found, all the networks are extended
actions that when executed from I achieves all goals g ∈ G. by one extra layer and the planning problem is solved again.
  In partial satisfaction planning (PSP) [Smith, 2004; This process is repeated until a plan is found (see [van den
van den Briel et al., 2004], goals g ∈ G have utility val- Briel et al., 2005] for a complete description of the G1SC
                                                      formulation).
ues ug ≥ 0, representing how much each goal is worth to
the user; each action a ∈ A has an associated execution cost In order to deal with utility dependencies we incorporate
                                                      the following extensions to the G1SC formulation:
ca ≥ 0, representing how costly it is to execute each action
                                                                 UD
(e.g. amount of time or resources consumed). Let GP ⊆ G  • In PSP   problems not all goals have to be achieved
be the set of goals achieved by a plan P . The objective is for a plan to be feasible. Therefore, we remove those
to ﬁnd a plan P that maximizes the difference between total constraints from the G1SC formulation which state that
achieved utility u(GP ) and total cost of all actions a ∈ P goals must be achieved.
(i.e., plan beneﬁt):
                                                        • For each goal utility dependency function Gk we add a
                       (   ) −                                        ∈{0  1}          =1
              MAX     u GP        ca            (1)        variable zGk   ,  ,wherezGk     if all goals in Gk
                P                                                            =0
                              a∈P                          are achieved, and zGk otherwise.
  Work on PSP has until now  assumed that goals have
                                                         • For each goal utility dependency function Gk we add
no utility dependencies and thus their utilities are additive:
                                                           constraints to ensure that Gk is satisﬁed if and only if
u(GP )=      ∈   ug. In order to represent the types of
            g GP                                           all goals g ∈ Gk are achieved, that is:
goal utility dependencies discussed in the previous section         
                                                                                 −|    | +1≤
(i.e., complement, substitute, conditional), we adopt the Gen-             yc,f,g,T Gk        zGk     (3)
eralized Additive Independence (GAI) model [Bacchus and         f,g∈Dc:g∈Gk
          ]                                                          
Grove, 1995 . We chose this model because it is expressive,       ≤              ∀  ∈    :  ∈
general and we can compile to it from other commonly used     zGk        yc,f,g,T  g  Dc   g  Gk      (4)
models such as UCP-Net [Boutilier et al., 2001]. We assume           f∈Dc
that the utility of the goal set G can be represented by k local where Dc is the domain of a state variable c,
               u
utility functions f (Gk) ∈ R over sets Gk ⊆ G.Forany              ∈{0   1}
                                                         yc,f,g,T    ,   are variables of the IP problem that
subset G ⊆ G the utility of Gis:                          represent value changes in the state variables, and T is
                             u
               u(G )=       f  (Gk)             (2)        the plan horizon.
                            
                       Gk⊆G                              • We create an objective function to maximize the net-
  This model allows users to specify changes in utility over beneﬁt (utility minus cost) of the plan.
sets of goals. For the rest of this paper, we name the new PSP
                                                              MAX         (   )   −                   (5)
problem with utility dependencies represented by the GAI                 u Gk zGk             caxa,t
         UD                              k                            Gk            a∈A,1≤t≤T
model PSP   .Ifthereare|G| local functions f (Gk) and
                                   UD                      where u(Gk) represents the utility of satisfying the goal
each Gk contains a single goal then PSP reduces to the
original PSP problem (no utility dependencies).            utility dependency function Gk,andca represents the
                                                           cost of executing action a ∈ A.
3  IP Encoding for   PSPUD
                                                        The extended G1SC formulation is bounded length opti-
Since classical planning can be solved by IP, and since IP mal (i.e., it generates optimal plans for a plan horizon T ).
provides a natural way to incorporate numeric constraints and
                               UD                     Global optimality cannot be guaranteed as there could still be
objective functions, it follows that PSP planning problems solutions with higher net beneﬁt at longer plan horizons.
can be solved by IP as well.
  We setup an IP formulation to handle PSPUD problems 4   Heuristics for Maximizing Plan Beneﬁt
by extending the generalized single state change (G1SC) for- While IP planners are optimal within a bounded horizon,
mulation [van den Briel et al., 2005]. Currently, the G1SC prior work suggests that heuristic search planners are more
formulation is the most effective IP formulation for solving efﬁcient and are able to ﬁnd better solutions in larger prob-
classical planning problems, and it outperforms the previ- lems [van den Briel et al., 2004].ForPSPUD problems, the
ously developed IP formulation used to solve PSP problems challenge in computing a heuristic for maximizing plan ben-
without utility dependencies [van den Briel et al., 2004]. eﬁt is that we need to simultaneously (1) pick the best set of
  The G1SC formulation represents the planning problem as goals and (2) ﬁnd the best plan for them. While the ﬁrst chal-
a set of loosely coupled network ﬂow problems, where each lenge is complicated by the utility dependencies, the second
network corresponds to one of the state variables in the plan- is complicated by the cost dependencies.
ning domain. The network nodes correspond to the state vari- Current heuristic approaches for solving PSP problems in-
able values and the network arcs correspond to the value tran- volve planning graph based heuristics that handle cost depen-
sitions. The planning problem is to ﬁnd a path (a sequence of dencies by providing an estimate of the cost for achieving

                                                 IJCAI07
                                                  1873each goal. The heuristics then use the goals’ deﬁned utility to achieve facts p and to execute actions a are1:
values to select goal subsets that offer the best net beneﬁt on
                                                         • Facts: ∀f : C(f)= MIN   (C(a)+ca)
the estimated cost. In this scenario goals have no dependen-               f∈Add (a)
                      UD
cies on one another. In PSP we must deal with the fact that • Either:
both cost dependencies between actions and utility dependen-
cies between goals exist.                                    1. Max-prop: ∀a ∈ A : C(a)= MAX   C(f);or
                                                                                       f∈Pre(a)
  In this section we deﬁne our search algorithm along with
                                                             2. Sum-prop: ∀a ∈ A : C(a)=  Σ    C(f)
three heuristics that combine planning graph methods with                              f∈Pre(a)
a declarative IP encoding. We generate an IP encoding over
                                                      The update rules are used while extending the (relaxed)
the relaxed plan heuristic rather than the entire problem as
                                                      planning graph structure [Blum and Furst, 1997].After
discussed in Section 3. By solving the IP encoding, we select
                                                      the propagation is done (i.e., no costs change), C( ) is an
a goal set along with an estimated cost for achieving it. Our                                     g
                                                      estimate on the cost to achieve for each goal ∈ .
main innovation is the combination of a relaxed plan that                       g            g   G
handles cost interactions between goals and a declarative IP
                                                      Deriving Heuristics from Propagated Costs: We will use
encoding that captures both mutual goal achievement cost          x
and goal utility dependencies.                        the notation hy to name our heuristics. Here x is the method
                                                      used to estimate the goal utilities and y is the method used to
                              UD               UD     estimate the goal costs. If utilities and costs are independent,
Best-First Heuristic Search for PSP : To handle PSP , both x and y can be “sum”. The dependencies between goal
we use the best-ﬁrst anytime heuristic search framework in utilities can be estimated using the GAI model while the de-
SapaPS  [van den Briel et al., 2004]. This forward metric
                                            ∗         pendencies between goal costs can be estimated using relaxed
temporal planner uses an anytime variation of the A algo- plans.2
rithm guided by a heuristic derived from the relaxed planning
             ∗                                          It is easy to observe that if we use max propagation (max-
graph. Like A , this algorithm starts with the initial state prop), then C(g) will underestimate the cost to achieve g
Sinit and continues to dequeue from the open-list the most
                           ( )=   ( )+   ( )          while there is no such guarantee for sum propagation (sum-
promising node S (i.e. highest f S g S  h S  value).  prop) [Bonet et al., 1997].UsingC(g) calculated by the cost
For each search node S, g(S) represents the beneﬁt achieved
                               ( )                    propagation process outlined in the previous section, we can
so far by visiting S from Sinit and h S represents the pro- estimate the achievable beneﬁt value as below:
jected maximum additional beneﬁt gained by expanding S,                          
                                                              hGAI =  MAX   [u(G ) − (MAX  C(g))]     (6)
with plan beneﬁt deﬁned in Section 2. Though calculating                ⊆             ∈ 
g(S) is trivial, having a good estimate of h(S) is hard and key       G  G            g G
to the success of best-ﬁrst search algorithms. During explo- Notice that, as part of our heuristic, we the calculate the
                                              ∗
ration of the search tree the algorithm, which is called APSP, local utility functions as deﬁned in Equation 2. As such,
keeps outputting better quality plans whenever a node S with our heuristic directly applies the GAI model. If we use
                                         ∗                                                   GAI
the best-so-far g(S) value is expanded. Like A , the algo- max-prop, then Equation 6 will give the hmax heuristic
                                                                                                     GAI
rithm terminates when a node S with h(S)=0is picked   and if we use sum-prop, it will give a corresponding hsum
                                                                       GAI
from the top of the open list.                        heuristic. While hmax overestimates the real achievable
           ∗                                          beneﬁt, there is no such guarantee for hGAI. Thus A∗
  Though  APSP  can keep all generated search nodes,                                     sum         PSP
              PS                                            GAI
in practice Sapa  prunes the search space by removing using hmax is guaranteed to output an optimal solution given
nodes that that appear unpromising (i.e., nodes where enough time.
the estimated beneﬁt is negative). Though this improves
                                                                                           GAI
efﬁciency, one potential drawback is that when the heuristic Relaxed Plan based Heuristic: Because hmax can signif-
h(S) underestimates the value of a search node S,thenS icantly over-estimate the real beneﬁt of achieving a set of
will be discarded (when compared to the beneﬁt of the best goals, it performs badly in some domains (as we shall see).
                                                           GAI
solution found so far g(SB)) even if it can be extended to The hsum heuristic, while more informative, relaxes the cost
reach a better solution. To mitigate this issue, we modiﬁed interaction and assumes that plans achieving different goals
the SapaPS search strategy to keep some search nodes that are independent and do not overlap. To improve on those two
appear unpromising when ﬁrst generated. During search we heuristics, we adapt the relaxed plan heuristic, ﬁrst introduced
set a value  as half the distance between the best node found in the FF planner [Hoffmann and Nebel, 2001], that solves
so far S and the worst-valued unpromising node. For each the planning problem ignoring the delete list. This heuristic
      B                                                             GAI
unpromising search node S that is within a threshold  of improves over hsum by taking into account actions contribut-
                                                      ing to the achievement of several goals. The challenge in ex-
the current best solution, we ﬁnd ρ, the complement of the          UD
percentage distance between it and the beneﬁt of SB (i.e. tending it to PSP is how to efﬁciently ﬁnd a high-beneﬁt
 (  )
g SB ). We then keep S with probability ρ.               1
                                                         ca, which is the execution cost of a, is different from C(a),
                                                      which is the cost to enable the execution of a (i.e., costs to achieve
Goal Achievement Cost Propagation: In all of our heuristic preconditions of a)
                         C( )
methods we estimate the cost g to achieve each goal [Do  2Given this notation, we can view the heuristic used in
                                  C(  )=0                 PS                            sum
and Kambhampati, 2004]. Starting with f    for facts  Sapa   [Do and Kambhampati, 2004] as hrelax because it sums
f in the initial state I and C(f)=C(a)=∞ for all other the individual goal utilities and extracts a relaxed plan to estimate
facts and all actions, the propagation rules to estimate costs cost.

                                                 IJCAI07
                                                  1874relaxed plan in the presence of both cost and utility depen- To capture the mutual dependencies between the goal
dencies.                                              achievement costs, we ﬁnd the set of actions shared between
        + ⊆
  Let GP     G be the set of goals achieved by the relaxed different partial plans achieving different goals. This proce-
plan +. The relaxed plan heuristic for PSPUD is:      dure utilizes the causal links in the relaxed plan +.
    P                                                                                        P
          ∗                                                           ∀    ∈     +    :      ( )=∅
           GAI  =          (  + ) −                     1. Initialize: a       P         GS a          ;
        h  relax  MAX    u GP           ca      (7)
                   P +                                     ∀ p   ∈   Add (a)    Prec(a):GS(p)=∅;
                                   a∈P +
                                                           ∀ g ∈ G : GS(g)={g}.
  Note that Equation 7 looks like Equation 1 except that the                                  +
optimal plan P in Equation 1 is replaced by the optimal re- 2. Backward sweep from goals achieved by P and update
laxed plan P + (i.e. achieving maximum beneﬁt) in Equa-    until ﬁx-point:                 
       ∗                                                      ( )=           ( )    ( )=            ( )
tion 7. h GAI overestimates the real achievable beneﬁt and GS  a          GS  p ; GS p           GS  a
         relax                       ∗                             p∈Add (a)              p∈Pre(a)
can be used as an admissible heuristic in APSP to ﬁnd the
optimal solution for PSP problems.                      Using the procedure above, for each action a, GS(a) con-
  While ﬁnding a satisfying relaxed plan P + for any given tains the set of goals g that a contributes to, where the goal-
                                      ∗
         + ⊆                           GAI            supporting sets  ( ) represents the achievement cost de-
goal set GP  G  is polynomial, extracting h relax requires          GS  a
ﬁnding an optimal relaxed plan (highest beneﬁt). This task is pendencies between goals.
NP-hard even when we already know the optimal goal set
 ∗                                                    Step 3: Estimate the Maximum Achievable Beneﬁt
   +                            [            ]
GP   and actions have uniform cost Bylander, 1994 .To                                            ( )
            ∗           UD                            In this step, we combine the goal supporting set GS a found
             GAI                                                                                     u
approximate h relax for PSP we use the following three in the previous step with the goal utility dependencies f to
                                       PS
steps. The ﬁrst step was introduced in Sapa while the ﬁnd the most beneﬁcial relaxed plan P  within P +.Onesim-
second and third steps are novel:                     ple approach to ﬁnd this plan P  ⊆ P + is to iterate over
                                                       |  + |        
                                             +        2 GP             ⊆     +                 +
                                                             subsets G    GP   of goals, with GP is the set
  1. Greedily extract a low cost relaxed plan P that                      +
    achieves the largest set of achievable goals.     of goals achieved by P , and compare the beneﬁt of plans
                                                      P  achieving G.However,when|G| is large this approach
  2. Capture the achievement cost dependencies between                  3
                                            +         becomes impractical. Therefore, we use a declarative ap-
    achievable goals using the causal structure of P . proach of setting up an IP encoding with solution represent-
  3. Pose the problem of extracting the optimal subplan ing the most beneﬁcial relaxed plan P  ⊆ P +. Note that
            +
    within P  that takes both cost and beneﬁt dependen- while IP is generally slow for solving a complete planning
                                              GAI
    cies into account as an IP encoding. A solution hrelax problem, the number of actions in the relaxed plan is much
                                      ∗ GAI
    of this IP encoding is used to estimate h relax.  smaller (by several orders) than the number of actions in the
                                                      (relaxed) planning graph. This allows us to ﬁnd an optimal
  Notice that if we compile the entire relaxed planning graph
                                                      solution in reasonable time. This is critical because we will
(rather than just the greedily extracted relaxed plan) we can
                       ∗                              build an IP encoding for each search node generated during
post the problem of ﬁnding h GAI as an IP problem. Despite
                         relax                        forward heuristic search. The IP formulation that we set up
its conceptual elegance, we chose not to follow this route as
                                                      is very similar to the one described in Section 3 but it only
the cost of heuristic computation increases signiﬁcantly (es-
                                                      allows actions that are in the relaxed plan and it does not
pecially for our progression planner which extracts a relaxed
                                                      create constraints for negative interactions. Moreover, addi-
plan at each node).
                                                      tional constraints representing the goal supporting set GS(a)
Step 1: Heuristically Extract a Low Cost Relaxed Plan found in the previous step are also included to enforce that if
Let G ⊆ G be the set of all achievable goals (C(g) < ∞), we a given goal g is selected, then any action that contributes to
use the planning graph and the propagated achievement costs the achievement of g should also be selected. Speciﬁcally:
in Section 4 to heuristically extract a low-cost relaxed plan to • Binary Variables:
        
support G as follows:                                                                    u
                                                             – ∀a ∈ P, ∀g ∈ G, ∀Gk ⊆ G, f (Gk) =0: create
                              =                  =
  1. Start with supported facts SF I, subgoal set SG           one binary integer variable Xa, Xg, XGk .
       \                    + = ∅
    G   I andtherelaxedplanP      .                      • Constraints:
  2. For each g   ∈   SG  select a supporting action           ∀  ∈   ∀  ∈    ( ):(1−     )+    ≥ 1
                                                             –  a  P, g   GS  a       Xg    Xa
    a : g ∈ Add (a) with lowest execution cost C(a) value.         (1 −   )+      ≥  1
             + ←   + ∪{  }    ←     ∪(    ( )\    )          –          Xg    XGk
    Update: P     P     a , SG   SG    Pre a   SF              g∈Gk
    and SF ←  SF  ∪ Add (a).                                   ∀  ∈    :(1−      )+     ≥ 1
                                                             –  g   Gk      XGk     Xg
  3. Repeat until SG = ∅.                                •               (    u(  ) ∗     − Σ   ∗   )
                                                           Objective: MAX    f  Gk   XGk     Xa   ca
  This backtrack-free process is guaranteed to ﬁnish in time Solving this IP encoding gives the beneﬁt value of the most
polynomial in the number of actions.                  beneﬁcial relaxed plan P  within P +. The beneﬁt of this P 
                                                                                              ∗
                                     +                                   GAI                       4
Step 2: Build Cost Dependencies within P              plan can be used as a hrelax heuristic to guide APSP.
Because certain actions contribute to the achievement of 3In the empirical section, we test with problems used in the plan-
multiple goals, there are dependencies between the costs to ning competition, which can have more than 40 goals.
achieve them. Those relations can be discovered by using the 4We use similar IP encoding to derive the heuristic estimates for
                                       +               GAI     GAI
causal structure of the extracted relaxed plan P .    hmax and hsum as described in the earlier part of this section.

                                                 IJCAI07
                                                  18755  Empirical Results                                  scientiﬁc data together gives redundant information and
                                                      therefore removes a large portion of utility gained by having
We have implemented the heuristic framework on top of the
    PS                                                them separately.
Sapa    planner along with the extension to the G1SC en-
coding discussed in Section 3. We call the new planners
                                                      Analysis: The empirical evaluation is designed to: (1) com-
SPUDS  and iPUD and compare (1) iPUD;(2)SPUDS  with
               GAI   GAI       GAI                    pare the effectiveness of the IP-based and heuristic search
three heuristics (hrelax, hmax,andhsum ); and (3) a version                  UD
      PS                                              approaches in solving PSP  problems; (2) determine the
of Sapa  whose heuristic ignores the goal utility dependen- characteristics of PSPUD planning problems which cause our
cies (but whose g-value does not)                     approaches to return plans of differing quality.
  iPUD  runs with CPLEX 10.0, a commercial LP solver,   Our results in Figure 1 show the plan quality achieved by
while we use lp solve version 5.5 (a free solver with a Java each planning method and the time to reach that quality. On
wrapper) to solve the IP encodings in SPUDS. We found problems where only the null plan was found, we indicate
that lp solve, while less powerful than CPLEX, has a shorter the extensive search for a better plan by setting the time to
setup time and is more suitable for SPUDS, which sets up 600 seconds. For every other instance, the time that the best
an IP encoding at every search node. All tests use a P4 plan was found is shown. As the ﬁgure shows, the tested
2.66GHz/1GB RAM computer with a 600 second time limit.
              PS                                      approaches varied in their relative plan quality on each do-
SPUDS  and Sapa   continuously ﬁnd better solutions until                     GAI
                                                      main but SPUDS using the hrelax heuristic always performed
a termination criterion is met.                       among the best.
                                               UD       First, we observe the planner behavior in Zenotravel and
Test Problems: We automatically generated the PSP     TPP. Both of these domains involve gathering objects, though
problems from a subset of the propositional planning bench- Zenotravel focuses on delivering these objects as well. Util-
marks used in IPC3 and IPC5: In Zenotravel, airplanes move ity dependencies play an important role in these domains, and
people between cities; in Satellite, satellites turn to objects we see that SapaPS does poorly, while the SPUDS heuristics
and take pictures; in Rovers, sets of rovers navigate to take and iPUD fared much better. Since the SapaPS heuristic is
samples and images; and in TPP, trucks visit markets to buy not informed about utility dependencies, this comes as no sur-
products.                                             prise. In easier problems, the hGAI heuristic tends to return
  For each domain, we implemented a Java program that                            sum
                                               UD     plans of similar or equal quality as compared with the other
parses the original problem ﬁles and generates the PSP                                               GAI
                                                      techniques used. However, as problem size increases, hsum
version with action cost and goal utilities randomly generated begins to return plans of better quality, but still does worse
within appropriate upper and lower bounds. The set of goal GAI
                                                      than hrelax in terms of the overall number of plans found with
dependencies along with their utility values are also randomly best quality. With iPUD, as the size of the problem encoding
generated. Thus, the number of dependencies, size of the de- increases it is unable to ﬁnd a good feasible solution.
pendencies, set of goals involved, utility values and action
                                                        For our version of the Satellite domain, some goal combi-
costs are all selected within varied lower and upper bounds
                                                      nations remove utility from the overall quality of plans. Also,
for each domain. All goals are soft, and therefore planners
                                                      the plans of higher quality tend to require many actions. This
can trivially solve each problem with the null plan.
                                                      can be seen in the quality of the plans that iPUD returns. Its
  We varied our bounds on action cost and goal set utility reachability analysis is unable to properly estimate the dis-
values such that each domain focuses on different aspects tance to goals and it therefore begins its solution searching
of utility dependency. In Zenotravel, ending a plan with                       GAI
                                                      at a small horizon. For the hrelax heuristic, it turns out that
people at various locations increases utility signiﬁcantly. But action selection helps guide search toward the goals.
ﬂying a person from one location to another has a cost that
                                                        For the Rovers domain, iPUD does well on several prob-
is only slightly less than the individual utilities of achieving
                                                      lems. However, like in the Satellite domain, it turns out that
each goal. Thus, it is vital to have sets of people at their
                                                      better quality plans require a larger horizon on some of the
desired location. In TPP, purchasing items has a cost about
                                                      problems than its initial horizon provides. This gives SPUDS
equivalent to the individual utility of having the item. How-  GAI
                                                      with the hrelax heuristic an edge over iPUD in 8 of the 20
ever, having items together can change the utility of a plan                 GAI      GAI
                                                      problems. The heuristics hsum and hmax have information
considerably. The idea is to simulate the beneﬁt of having                              GAI
                                                      regarding utility dependencies, though hsum often performs
several items together (e.g., to build a crate you need wood,    GAI
nails, a hammer and saw). The Satellite domain removes worse than hrelax (solving 5 of 20 problems with better qual-
                                                                   GAI
the emphasis on cost. Here actions have costs lower than ity plans) and hmax is only able to ﬁnd the null plan in every
the comparatively higher beneﬁt of having several images problem instance. Neither of these heuristics can detect the
together (e.g., to produce a mosaic image). The domain also individual dependencies between actions.
adds negative goal utility dependencies (i.e., substitution) by Also of interest is the time it takes to solve each problem
including negative utility for having certain sets of images between the heuristic search methods and the IP encoding
yet ending a plan by pointing to an inconvenient spot.5 The used in iPUD. Since the SPUDS heuristics solve an IP encod-
Rovers domain focuses on substitution as having certain ing at each search node, they take much longer to compute on
                                                      larger problems than the procedural SapaPS heuristic. Un-
                                                                    PS
  5In this case we group the goal of having certain images along fortunately, Sapa lacks the heuristic guidance necessary
with a ﬁnal ending position as a dependency with a randomly gen- to properly select goals with utility dependencies. Though we
                                                                                         GAI
erated negative utility.                              found that the per-node IP encoding of hrelax increased the

                                                 IJCAI07
                                                  1876