On the application of least-commitment and heuristic search in temporal planning 

                              Antonio Garrido and EvaOnaindia 
                           Dpto. Sistemas Informaticos y Computation 
                               Universidad Politecnica de Valencia 
                            Camino de Vera s/n, 46071 Valencia, Spain 
                                {agarridot,onaindia}@dsic.upv.es 

                   Abstract                      and optimality. However, backward search has some ineffi•
                                                 ciencies that impose important limitations in large temporal 
    Graphplan planning graphs are structures widely problems. In these problems, the search space is vastly in•
    used in modern planners. The exclusion relations creased and the performance of the algorithm degrades. We 
    calculated in the planning graph extension pro• suggest a new two-stage search process to overcome these 
    vide very useful information, especially in tempo• inefficiencies. First, a backward search generates an initial 
    ral planning where actions have different duration. relaxed plan. Next, this relaxed plan is used as an outline 
    However, Graphplan backward search has some  for generating a solution plan by means of a non-complete 
    inefficiencies that impose limitations when dealing heuristic process, where actions are only definitively allo•
    with large temporal problems. This paper presents cated in the plan when they are applicable and no mutex 
    a new search process for temporal planning to avoid (least-commitment). This allows to increase the scalability 
    these inefficiencies. This search uses the informa• of search, producing non-optimal, but good quality, plans. 
    tion of a planning graph and shows beneficial in 
    the scalability of the planner. Moreover, our ex• 2 A Review of TPSYS 
    periments show that a planner with this new search 
    is competitive with other state-of-the-art planners TPSYS is based on a three-stage process [Garrido et al, 
    w.r.t. the plan quality.                     2002], which combines the ideas of Graphplan and TGP. 
                                                 This means that TPSYS incrementally extends a temporal 
                                                 planning graph, performs a backward search through that 
1 Introduction                                   graph and extracts a plan. 
                                                   Unlike conservative actions, durative actions present more 
Many of the current challenges in AI planning focus on in• conditions to be guaranteed for the success of the action. 
creasing the functionalities of planners to deal with more real These conditions are SConda, EConda and Inva with the 
features, such as temporal capabilities, explicit management conditions of a to be guaranteed at the start, end and over all 
of resources, more expressive domain definition languages, the execution of a, respectively. Durative actions have two 
heuristic techniques and optimisation criteria, etc. [Fox and types of effects: SEffa and EEffa with the effects to be 
Long, 2001; Gerevini and Serina, 2002; Smith and Weld, asserted at the start and end of a, respectively. 
1999]. This paper deals with three of the previous func• The first stage of TPSYS calculates the action-action and 
tionalities: i) planning with temporal features (actions with proposition-action static mutex relationships. These mutex 
duration), ii) more expressive domain definition languages relationships are static because they only depend on the def•
(PDDL2.1 [Fox and Long, 2001]), and iii) plan optimisa• inition of the actions and they always hold. The second 
tion (makespan). Traditional temporal planners have adopted stage extends a temporal planning graph which alternates 
a conservative model of actions, where two actions cannot temporal levels of propositions (ify) and actions (A^). Un•
overlap in any way if they have conflicting preconditions or like Graphplan, levels in TPSYS represent instants of time 
effects. This model is adequate in some planning domains, t 6 R+ in which propositions are present and actions can 
but there exist others that require a richer model of actions. start/end. Action-action, proposition-action and proposition-
Level 3 of PDDL2.1 used in IPC-2002 provides a model of proposition mutex relationships are calculated during the ex•
durative actions which allows a more accurate exploitation of tension of the temporal planning graph. The third stage per•
action concurrency to obtain shorter makespan plans. forms the search in a Graphplan backward way, extracting 
  This paper describes our experiences with a Temporal an optimal plan through the planning graph. Since the third 
Planning SYStem (from now on TPSYS), based on Graph- stage starts as soon as all the propositions in the final situa•
plan [Blum and Furst, 1997] and TGP [Smith and Weld, tion are present, non pairwise mutex, and the plan extraction 
1999], to manage the model of durative actions proposed in is complete, TPSYS obtains the plan of optimal makespan. 
level 3 of PDDL2.1. TPSYS performs a Graphplan back• Backward search in TPSYS preserves the same proper•
ward search, which guarantees the properties of completeness ties of completeness and optimality of Graphplan, but it en-


942                                                                                   PLANNING                                                        The worst performance happens when the gcd of the dura•
                                                       tions is 1, forcing the algorithm to generate the maximum 
                                                       number of levels. In consequence, the previous inefficiencies 
                                                       and wasted search are repeated more frequently. 
                                                      3 Combining Least-Commitment and 
                                                          Heuristics to Improve the Search Process 
                                                       In this section we substitute the backward search by a two-
                                                       stage search to avoid the previous inefficiencies in a temporal 
Figure 1: Outline of the temporal planning graph for the planning approach. First, a backward chaining stage gener•
ferry problem. Shaded propositions represent the non- ates an initial relaxed plan from the information of the tem•
pairwise mutex problem goals at time 16. Mutex relations poral planning graph. Second, a forward chaining stage allo•
between propositions are represented by thick lines.  cates the execution time of the actions in the relaxed plan. 
                                                      3.1 Generation of an Initial Relaxed Plan 
tails the most time consuming stage. Furthermore, this search This stage generates an initial relaxed plan from the informa•
presents some inefficiencies (inherited from Graphplan) tion of the temporal planning graph (from now on TG) to be 
which impose important limitations in temporal problems. used as a skeleton of the final plan. We define a relaxed plan II 
Let us consider a simple problem from the ferry domain. as a partially ordered set of actions in which both the problem 
The domain consists of transporting a number of cars from goals and action conditions hold. It is called relaxed because 
one location to another using a ferry which can carry only one neither mutex relationships between actions nor commitment 
car at a time. To keep the problem simple enough we assume on their start time are considered. 
three cars cl, c2 and c3 to be transported from location 11 A relaxed plan always contains two fictitious actions with 
to 12 by ferry /l. The actions are board              no duration called IS and FS. IS achieves the propositions of 
sail and debark                                       the initial situation, whereas FS requires the problem goals. 
with durations 1, 5 and 2, respectively. The optimal plan II is generated similarly to the relaxed solution plan in the FF 
contains 11 actions (3xboard, 5xsail and 3\debark) and the planner [Hoffmann, 2000] with the exception that we handle 
makespan is 34. The mutex relations are binary, so the sec• durative actions (see Algorithm 1). 
ond stage ends at time 16 and the search starts from there 
(see Figure 1). Since every pair of actions is mutex, only one 1: goals problem goals {must hold in any plan for the problem 
action is planned in each level. If we assume that applica• 2: FT {obligatory actions 
ble actions are selected in each level from top to bottom in 3: while goals do 
the planning graph of Figure 1, action A2 is firstly planned 4: extract from goals 
                                                       5: if i is not supported in II then 
at time 14. Next, actions A7 and Al are planned at times 6: arg min(number of mutex which a* imposes in II) 
9 and 8, and so on. Because no feasible plan is found, the 
                                                                 Vaf which supports 
search backs to time 14 where all permutations of actions A2, 7: if a is the only action which supports is a condition 
A4, A6 are planned under the same schema with no success.    of an obligatory action then 
This is the first indication of inefficiency: a lot of effort is 8: mark a as obligatory in II 
wasted trying, unsuccessfully, to plan nearly identical actions 9: II commitment on start time oj a yet 
in problems with symmetry. As no plan is found from time 10: goals goals SConda 
16, the planning graph is extended to time 17 and the search is Algorithm 1: Generation of an initial relaxed plan II. 
re-started from scratch. This entails the second indication of 
inefficiency: no actions planned in previous stages of search Step 6 studies the actions which support Qi and selects the 
are reused as a part of the current plan, committing similar action which minimises the number of mutex in In prob•
failures in the new one-deeper-level search space. Although lems with multiple resources, this selection tends to use as 
memoization helps reduce the amount of failures committed many resources as available. For instance, in a ferry prob•
during search, the way in which it prunes one branch of search lem with two or more ferries .., step 6 distributes 
does not allow to solve the real conflict until exhausting the the use of the ferries in a homogeneous way. If action de-
whole level. This is the third indication of inefficiency: if one bark(cljl,l2) is used for debarking the car cl, action de-
proposition becomes unsupported, no new actions supporting bark(c2,f2,l2) is first selected when debarking the car c2 be•
it are studied but that branch is discarded and the algorithm cause debark(c2,flJ2) is mutex with debark(c 1 ,fl,12) and im•
performs a backtracking stage.                        poses more mutex in II. This selection provides the relaxed 
  These inefficiencies have a negative influence in Graph- plan more information about the structure of the problem, 
plan-based temporal approaches. While a classical Graph- thus increasing the quality (number of actions in parallel) of 
plan's planning graph for this problem has 11 levels, in tem• the final plan. Note that in step 6 we do not need to perform 
poral planning no plan is found until level 34 is extended and real search (or backtracking) because none of the mutexes are 
explored. Particularly, in TPSYS the number of levels gener• considered and, therefore, this strategy always leads to a so•
ated depends on the dispersion of the durations of the actions. lution. Moreover, we introduce the term of obligatory action 


PLANNING                                                                                              943 a as the only action which supports a goal which must hold supported the algorithm exits with success (step 5). Oth•
in any plan for the problem. This is helpful because it means erwise, actions from Relaxi which can start at the current 
that a must be always present in II (steps 7-8). Obviously, time.of-execution* are tried to be allocated (step 7). 
both IS and FS are obligatory.                         If one action a is mutex with actions in Alloci and non-
  One important property of II is that if there is no mutex obligatory, a is removed from H\ (step 10), delaying the ful•
between overlapping actions, all actions in II form a feasible, fillment of its goals to a future time of execution. The reason 
optimal plan. The proof of this is straightforward and relies to remove a non-obligatory action is that it could be a bad 
on the complete extension of the temporal graph. The level in choice for the plan. If a is obligatory it is not removed but 
which the temporal graph extension ends indicates the mini• its start time is postponed (step 12). If a is not mutex and ap•
mal time in which the goals can be achieved by non-pairwise plicable, a is allocated in time (step 15). This step entails the 
mutex actions. Thus, this level provides a minimal bound of first indication of loss of completeness. Although there exist 
the makespan for a feasible plan and, if no mutex between alternative actions to a, if a can be allocated those actions arc 
actions holds, the plan is not only feasible but also optimal. not considered in IIj. Step 17 is a branching point in which 
Unfortunately, this is not a very common situation and mutex new actions are inserted (generating new plans) to achieve 
relations break the plan relaxation. This entails to postpone unsupported conditions of a. For each action a, supporting 
the allocation of actions, and/or to plan new actions to solve each condition a new plan IIj is generated and inserted into 
the unsupported (sub)goals.                            set.of .plans with a,j marked as obligatory in IIj. It is im•
                                                       portant to note that a, is not allocated in time, but it is inserted 
3.2 Planning and Allocating of Actions                 with its earliest start time of execution extracted from the TG. 
This stage performs the allocation in time of actions in the re• This is part of the least-commitment technique performed in 
laxed plan. We use a structure called set_of .plans, with the allocation of actions when they are inserted into plans. 
the search space formed by all the generated plans . Ac• Step 18 moves to the next relevant time-of-execution* 
tions in each are divided into two disjunctive sets:   in which actions can start, extending the TG if necessary. 
and contains the actions which have been al•             The algorithm has two important points of selection: steps 
located in time and will never be removed from 11;. Relaxj 3 and 7. Step 3 selects the plan Ili with the lowest cost from 
contains the actions which have not been allocated yet, and set.of .plans, where the cost is estimated as follows: 
so they can be removed from Initially, is empty 
and contains all the actions in (the initial IIj is the 
relaxed plan computed in the previous section). This stage 
finishes once gets empty, obtaining inthe ac•
tions of the plan which support all the problem goals. 

 1: set.of .plans , generated in Algorithm 1 
 2: while set.of .plans 
 3: extract the lowest cost Ili from set.of .plans       The cost of a plan IIj consists of the sum of the cost due 
 4: if Alloa supports all the problem goals then       to Allod and is an estimation of 
 5: exit with success                                  the number of actions necessary to solve the unsupported 
 6: else I 
 7: arg max (allocation priority) ' conditions of from the current time.of-execution 
                                                       It is estimated through the TG, ignoring the delete effects 
 8: if a is mutex in Alloci then                       of actions (as in the heuristic used in FF), is 
 9: if a is not obligatory then                        the number of conditions of FS which supports, whereas 
10: remove from Relaxi                                 del\ FS) is the number of conditions of FS which deletes. 
11: else                                               PAjmutex\ FS) is the number of mutex between condi•
12: postpone start time of a in                        tions of FS and action This mutex information is extracted 
13: else                                               from the TG and indicates the impossibility to have simulta•
14: if is applicable then                              neously the conditions of FS and duration represents the 
15: allocate a in at time.of .execution!               duration of the plan/action to take into account the makespan 
16: else                                               of Note that a, 0 because they have a pos•
17: insert new plans into set.of .plans to make a ap•
           plicable                                    itive impact in the cost of the plan. In opposition, 
18: update t ime.of.execut io                         because it has a negative impact in the cost. 
                                                         In step 7, the action a with the maximal allocation priority 
     Algorithm 2: Planning and allocating of actions.  is selected to be studied at time.of -execution*. This 
                                                      priority is estimated as follows: 
  The idea is to move forward in time, simulating the real ex•
ecution of IIj, progressively taking care of the actions which 
can start their execution (see Algorithm 2). The current time 
of execution in Ili, time-of-execution*, is initialised to 
0. The algorithm always selects the plan Ftj of lowest cost The allocation priority of action a depends on several local 
from set.of-plans (step 3). If all the problem goals are factors, succ is the number of direct successor 


944                                                                                             PLANNING (dependent) actions of a in rneetsuccis proaches have difficulties to solve all the problems (see Fig•
the number of direct successor actions of which can start ures 2-c,d,e,f), the least-commitment search can solve more 
as soon as ends, i.e. which meet These two values in•  problems. On one hand, backward search difficulties rise as 
dicate the importance of an action for the successor actions a result of the redundancy in the complete, blind search pro•
in Intuitively, the more successor actions are directly cess. On the other hand, least-commitment search difficulties 
supported by the more important is in the plan. Similarly, rise as a result of: i) the heuristic, greedy approach, which can 
the meeting successor actions indicate the number of succes• lead to the wrong path in the search, and ii) the non-complete 
sor actions which can be immediately executed without mu- preserving search. The zenotravel and satellite do•
tex. unsup and duration are defined as above. Coefficients mains show the highest speedups. It is important to note that 
        because they imply to select an appropriate action the best improvement is produced in the satellite do•
to be allocated. However, because they indicate that   main, which is the only domain in the competition that ex•
action is not promising enough to be allocated yet.    ploits the end conditions of durative actions. 
  The previous evaluation functions can have many more   The third and fourth experiments are aimed at evaluating 
heuristic factors, but according to our experimental analysis the quality of the plans generated by the new approach. We 
they are general enough for most temporal planning prob• are mainly interested in the makespan of the plans, but we 
lems. We can also implement different heuristic methods by also consider the number of actions as an additional indica•
setting the values of the coefficients, which in our case are tion of the plan quality. The third experiment uses the plans 
the same for all the domains. Although the values of the co• generated in the experiment 1 (Figures 2-a,b) and compares 
efficients can influence the search, their precise value is not them with the plans generated by LPG3 [Gerevini and Serina, 
as relevant as in other heuristic approaches based on local 2002] and Mips4 [Edelkamp, 2002]. We have chosen these 
search as LPG [Gerevini and Serina, 2002]. For instance, two planners as they handle temporal features and showed 
the static cost of inserting an action in LPG is based on the distinguished performance in the last IPC. To date our inter•
number of unsupported conditions, what cannot represent the est has not focussed on code optimisation, so in this experi•
real complexity of solving each condition. On the contrary, ment we will not compare the execution time of the planners5 
the coefficient deals with that complexity because it  but only their plan quality. Table 1 shows the comparison be•
estimates the real cost to support it in the TG.       tween the three planners taking into account the makespan 
  It is important to note that plans are incrementally gener• and the number of actions of each plan. We have not in•
ated without discarding allocated actions and with no redun• cluded the results for the ferry domain because the three 
dancy due to symmetry. Although Algorithm 2 explores the planners generate the same fully sequential plans. However, 
complete space of actions to make actions applicable, the al• plans for the gripper domain can have actions in paral•
location priority imposes an order of execution and discards lel (the gripper is a resource with capacity for two balls) so 
the rest of feasible orderings (second indication of loss of that the planner can exploit a better concurrency. In order to 
completeness). For instance, in the ferry problem of sec• simplify the resulting plans the actions have been assigned 
tion 2, when studying the actions to debark            duration 1. Hence, the optimal makespan is 1 and the 
the algorithm allocates one action and postpones the others. number of actions in an optimal plan is 1, where is the 
This avoids the complete exploration of all the permutations number of balls in the problem. Surprisingly, both LPG or 
of A2, A4 and A6, preventing the planner from the generation Mips generate sequential plans as can be easily noticed from 
of symmetric plans.                                    the fact that the makespan comes directly from the number 
                                                       of actions in the plan. tpsys-LC is the only of the three 
4 Experimental Results                                 planners which generates optimal plans for all the problems, 
                                                       highly exploiting the action parallelism. 
We have implemented the previous search on top of TPSYS, 
                                                         In the fourth experiment, we have used the plans gen•
conducting several experiments1. The two first experiments 
compare the new search vs. the Graphplan backward search. erated in the last IPC to perform a comparison between 
In the first experiment, we studied the impact of the new tpsys-LC and some of the state-of-the-art planners which 
search in problems with a high degree of symmetry, such as participated in the simple-time track. We have analysed 
the ferry and gripper, focussing on the planner scala•
bility. Figures 2-a,b show the results for some problems of http://www.dur.ac.uk/d.p.long/IPC 
these domains. Although it is not surprising that the least- 3 LPG is based on a non-deterministic local search and, con•
                                                       sequently, it would not be fair to work with the plan from 
commitment search (tpsys-LC) is faster than Graphplan  only one execution. In our experiments with LPG, we have 
backward search (tpsys-GP), it is worthy to mention that run each problem ten times and extracted the average val•
tpsys-LC scales up much better than tpsys-GP, espe•    ues. Wc have used the LPG 1.0 version as provided in: 
cially in the gripper domain. Moreover, tpsys-LC found http://prometeo.ing.unibs.it/lpg 
optimal plans without backtracking for all the problems. 4We have used the Mips version as provided in: 
  The second experiment deals with some problems of the http://www.informatik.uni-freiburg.de/~mmips 
simple-time track of the last IPC-20022. Although both ap- 5LPG and Mips arc clearly faster than tpsys-LC. For instance, 
                                                       they get to solve some simple problems before tpsys - LC finishes 
   1 The experiments were run on a Pentium IV 2 GHz with 512 Mb. its 1st and 2nd stages. Currently, these stages represent an impor•
   2More information on the domains, problems and re•  tant bottleneck in our implementation and we think they could be 
sults of the international planning competition (IPC-2002) in: drastically reduced. 


PLANNING                                                                                               945  Figure 2: Comparison of the least-commitment search vs. the Graphplan backward search. Tests were censored after 300 s. 

     Problem    tpsys-LC     LPG       Mips           improved by SHOP2 and TLPIan. Further, we have no•
     gripper-4    7(11)      13(13)   15(15)          ticed that tpsys-LC generates plans with nearly the same 
     grippcr-8    15(23)    25 (25)   31(31)          (or even fewer) actions than the rest of the planners. These 
    | gripper-12  23 (35)   45 (45)   47 (47)         experimental results show that the new approach significantly 
     gripper-16   31(47)    53 (53)   63 (63)         improves the scalability of the Graphplan backward search. 
     grippcr-20   39 (59)   63 (63)   79 (79) 
     gripper-24   47(71)    77 (77)   95 (95)         5 Conclusions through Related Work 
     gripper-28   55 (83)   89 (89)  111 (111) 
     gripper-32   63 (95)   105(105) 127(127)         Least-commitment techniques have been widely used in plan•
     grippcr-36  71(107)    117(117) 143(143)         ning, relying on the consistency of temporal constraints 
     gripper-40  79(119)    127(127) 159(159)         (IxTeT and HSTS), postponing the assignment of values to 
                                                      variables or the order of execution of actions, etc. [Weld, 
Table 1: Comparison of the makespan (number of actions are 1994]. We use a least-commitment approach to overcome 
in brackets) of the plans for the gripper domain obtained the limitations of the Graphplan backward search detected 
by tpsys-LC, LPG and Mips planners.                   in previous works [Fox and Long, 1999; Zimmerman and 
                                                      Kambhampati, 1999]. Our approach basically postpones the 
                                                      allocation in time of actions until they become not mutex and 
the plans generated by the domain-independent (di) planners applicable. Thus, the algorithm generates a relaxed plan sim•
LPG, Mips and VHPOP, and the domain-dependent (dd)    ilarly to FF, to be used as a skeleton of the plan. Next, it 
planners SHOP2, TALPIanner and TLPIan. For LPG and    allocates actions in time according to their mutex relations 
Mips we have run the problems again and for the rest of the and to several local heuristic criteria in the line of LPG. Our 
planners we have used the results of the competition. Al• critical difference with LPG relies on several points. First, 
though Sapa, TP4 and IxTeT also participated in the com• the planning graph is temporal and moves chronologically in 
petition we have not found enough results for the simple-time time instead of planning steps. Second, the TG is not only 
track to be considered in our comparison. Figure 3 shows the used to extract heuristic information but also to generate a 
results of this comparison (for lack of space we only include relaxed plan. Third, this plan is repaired in a forward chain•
the domains with more problems solved). In the driver- ing direction, and unlike LPG the allocated actions are never 
log domain, the plans of tpsys-LC are generally longer removed. Fourth, the heuristics exploit better the structure of 
than the rest of planners with the exception of LPG and the plan and the real importance of each action in the plan. Fi•
SHOP2. In the satellite domain, tpsys-LC behaves      nally, tpsys-LC uses a more precise model of action mutex 
in average better than the rest of the planners, with the only which implies fewer constraints on the execution of actions 
exception of TLPIan. In the rovers domain, tpsys-LC   and a larger search space. 
generates again plans of very good quality, which are only This paper contributes in the way in which least-


946                                                                                            PLANNING 