                      Probabilistic Consistency Boosts MAC and SAC

                               Deepak Mehta∗    and M.R.C. van Dongen
                    Computer Science Department, University College Cork, Ireland


                    Abstract                          grained arc consistency algorithms such as AC-3 [Mackworth,
                                                      1977] and AC-2001 [Bessi`ere and R´egin, 2001] are competi-
    Constraint Satisfaction Problems (CSPs) are ubiq- tive. These algorithms repeatedly carry out revisions, which
    uitous in Artiﬁcial Intelligence. The backtrack al- require support checks for identifying and deleting all unsup-
    gorithms that maintain some local consistency dur- ported values from the domain of a variable. However, for
    ing search have become the de facto standard to   difﬁcult problems, in many revisions, some or all values suc-
    solve CSPs. Maintaining higher levels of consis-  cessfully ﬁnd some support, that is to say, ineffective con-
    tency, generally, reduces the search effort. How-
                                                      straint propagation occurs. For example, when RLFAP 11
    ever, due to ineffective constraint propagation, it of-
                                                      is solved using either MAC-3 or MAC-2001 equipped with
    ten penalises the search algorithm in terms of time. dom/deg as a variable ordering heuristic, 83% of the total re-
    If we can reduce ineffective constraint propagation, visions are ineffective. If we can avoid this ineffective propa-
    then the effectiveness of a search algorithm can be gation, then a considerable amount of work can be saved.
    enhanced signiﬁcantly. In order to do so, we use
                                                        Recently, singleton arc consistency (SAC) [Debruyne and
    a probabilistic approach to resolve when to propa-
                                                      Bessi`ere, 1997] has been getting much attention. It is a
    gate and when not to. The idea is to perform only
                                                      stronger consistency than AC. Therefore, it can avoid much
    the useful consistency checking by not seeking a
                                                      unfruitful exploration in the search-tree. However, as pointed
    support when there is a high probability that a sup-
                                                      out earlier, as the strength of local consistency increases, so
    port exists. The idea of probabilistic support in-
                                                      does the amount of ineffective propagation. Hence, applying
    ference is general and can be applied to any kind
                                                      it before search can be expensive in terms of checks and time,
    of local consistency algorithm. However, we shall
                                                      and maintaining it during search can be even more expensive.
    study its impact with respect to arc consistency and
                                                               CPAI 2005           [
    singleton arc consistency (SAC). Experimental re-   At the     ’     workshop, Mehta and van Dongen,
                                                           ]
    sults demonstrate that enforcing probabilistic SAC 2005a presented a probabilistic approach to reduce ineffec-
    almost always enforces SAC, but it requires signif- tive propagation and studied it with respect to arc consistency
    icantly less time than SAC. Likewise, maintaining on random problems. This probabilistic approach is to avoid
    probabilistic arc consistency and maintaining prob- the process of seeking a support, when the probability of its
    abilistic SAC require signiﬁcantly less time than existence is above some, carefully chosen, threshold.This
    maintaining arc consistency and maintaining SAC.  way a signiﬁcant amount of work in terms of support checks
                                                      and time can be saved.
1  Introduction                                         In this paper, we present a more extensive investigation.
                                                      We study the impact of using the probabilistic approach not
                            CSP
Constraint Satisfaction Problems ( s) are ubiquitous in Ar- only in AC but also in SAC and LSAC (limited version of SAC
tiﬁcial Intelligence. They involve ﬁnding values for problem proposed in this paper) on a variety of problems. We call the
variables subject to constraints. For simplicity, we restrict                                     1
                                                      resulting algorithms Probabilistic Arc Consistency (PAC),
                   CSP
our attention to binary s. Backtrack algorithms that main- Probabilistic Singleton Arc Consistency (PSAC), and Proba-
tain some local consistency during search have become the bilistic LSAC (PLSAC). Our four main contributions, then, are
de facto standard to solve CSPs. Maintaining a higher level as follows: First, we investigate the threshold at which Main-
of local consistency before and/or during search usually re- taining PAC (MPAC) performs the best on different classes of
duces the thrashing behaviour of a backtrack algorithm. How- random problems. Second, we carry out experiments to deter-
ever, the amount of ineffective constraint propagation also in- mine how well MPAC does on a variety of known problems in-
creases, which can penalise the algorithm in terms of time. cluding real-world problems. Our ﬁndings suggest that MPAC
                AC
  Arc consistency ( ) is the most widely used local consis- usually requires signiﬁcantly less time than MAC.Next,we
tency technique to reduce the search space of CSPs. Coarse-
  ∗The ﬁrst author is supported by the Boole Centre for Research 1Probabilistic Arc Consistency proposed in this paper has no re-
in Informatics.                                       lation with the one mentioned in [Horsch and Havens, 2000]

                                                IJCAI-07
                                                   143examine the performances of PSAC and PLSAC when used as 3 Probabilistic Support Inference
a preprocessor before search. Experimental results demon-
                                                      The traditional approach to infer the existence of a support
strate that enforcing probabilistic SAC and LSAC almost al-
                                                      for a value a ∈ D(x) in D(y) is to identify some b ∈ D(y)
ways enforces SAC and LSAC but usually require signiﬁcantly
                                                      that supports a. This usually results in a sequence of support
less time. Finally, we investigate the impact of maintaining
                                                      checks. Identifying the support is more than needed: know-
PSAC and PLSAC during search on various problems. Re-
                                                      ing that a support exists is enough. The notions of a support
sults show a signiﬁcant gain in terms of time on quasi-group
                                                      condition (SC)andarevision condition (RC) were introduced
problems. Overall, empirical results presented in this paper
                                                      in [Mehta and van Dongen, 2005b] to reduce the task of iden-
demonstrate that the original algorithms are outperformed by
                                                      tifying a support up to some extent for arc consistency algo-
their probabilistic counterparts.
                                                      rithms. If SC holds for (x, a) with respect to y, then it guar-
  The remainder of this paper is organised as follows: Sec-
                                                      antees that (x, a) has some support in D(y).IfRC holds for
tion 2 gives an introduction to constraint satisfaction and con- an arc, (x, y), then it guarantees that all values in D(x) have
sistency algorithms. Section 3 introduces the notions of a some support in D(y). In the following paragraphs, we de-
probabilistic support condition and probabilistic revision con-
                                                      scribe the special versions of SC and RC which facilitates the
dition. Experimental results are presented in section 4 fol- introduction of their probabilistic versions.
lowed by conclusions in section 5.
                                                        Let Cxy be the constraint between x and y,leta ∈ D(x),
                                                      and let R(y)=Dac(y)  \ D(y) be the values removed from
2  Preliminaries                                      the ﬁrst arc consistent domain of y.Thesupport count of
                                                      (x, a) with respect to y, denoted sc( x, y, a ), is the number
A Constraint Satisfaction Problem (V, D, C) is deﬁned as a      D   (y)         a          | R(y) |
   V   n                           D(x) ∈D            of values in ac  supporting . Note that     is an up-
set  of  variables, a non-empty domain      ,forall   per bound on the number of lost supports of (x, a) in y.If
x ∈Vand a set  C of e constraints among subsets of vari- (x, y, a) > | R(y) | (x, a)           y
       V                               2 e/(n2 − n)   sc                then      is supported by . This con-
ables of .Thedensity of a CSP is deﬁned as        .   dition is called a special version of a support condition. For
A binary constraint Cxy between variables x and y is a sub-
                                                      example, if |Dac(y)| =20, sc(x, y, a)=2,and| R(y) | =1,
set of the Cartesian product of D(x) and D(y) that speciﬁes 1                 D  (y)                (x, a)
                          x    y                      i.e. value is removed from ac ,thenSC holds and
the allowed pairs of values for and .Thetightness of the has a support in D(y) with a probability of 1. Hence, there is
constraint Cxy is deﬁned as 1 −|Cxy |/| D(x) × D(y) |.A                      a   D(y)
     b ∈ D(y)(              , (y,b))                  no need to seek support for in .
value          also denoted as     is called a support  For a given arc, (x, y),thesupport count of x with
for (x, a) if (a, b) ∈ Cxy. Similarly, (x, a) is called a support
                                                      respect to y, denoted sc(x, y),isdeﬁnedbysc(x, y)=
for (y,b) if (a, b) ∈ Cxy.Asupport check is a test to ﬁnd if
                                                      min ({sc(x, y, a):a ∈ D(x)}).Ifsc( x, y ) > | R(y) | ,then
two values support each other. The directed constraint graph each value in D(x) is supported by y. This condition is a spe-
of a CSP is a graph having an arc (x, y) for each combination
                                 x    y               cial version of what is called a revision condition in [Mehta
of two mutually constraining variables and . We will use                                   | D (y) | =20
G                                                     and van Dongen, 2005b]. For example, if ac        ,
  to denote the directed constraint graph of the input CSP. sc(x, y)=2and | R(y) | =1then each value a ∈ D(x)
  Avaluea  ∈ D(x) is arc consistent if ∀y ∈Vconstraining                        D(y)                   1
x         a                          D(y)             is supported by some value of  with a probability of .
  the value is supported by some value in .ACSP  is   Hence, there is no need to revise D(x) against D(y).
arc consistent if and only if ∀x ∈V, D(x) = ∅,and∀a ∈
                                                        In the examples discussed above, if |R(y)| =2,thenSC
D(x), (x, a) is arc consistent. We denote the CSP P obtained
                                                      and RC will fail. Despite of having a high probability of the
after enforcing arc consistency as ac(P). If there is a variable
                     ac(P)              ac(P)=⊥       support existence, the algorithm will be forced to search for
with an empty domain in   ,wedenoteitas           .   it in D(y). Avoiding the process of seeking a support with
Usually, an input CSP is transformed into its arc consistent a high probability can also be worthwhile. In order to do
equivalent, before starting search. We call the domain of x
                                                      so, the notions of a probabilistic support condition (PSC)and
in this initial arc consistent equivalent of the input CSP the
                                                      a probabilistic revision condition (PRC) were introduced in
ﬁrst arc consistent domain of x.WeuseDac(x) for the ﬁrst
                                                      [Mehta and van Dongen, 2005a].ThePSC  holds for (x, a)
arc consistent domain of x,andD(x) for the current domain          y
  x                       P                    a      with respect to , if the probability that a support exists for
of .TheCSP   obtained from   by assigning a value to  (x, a) in D(y) is above some, carefully chosen, threshold.
the variable x is denoted by P|x=a.Thevaluea ∈ D(x) is                      (x, y)
                               ac(P|   ) = ⊥         The PRC holds for an arc   , if the probability of having
singleton arc consistent if and only if x=a .ACSP     some support for each value a ∈ D(x) in D(y), is above
is singleton arc consistent if and only if each value of each some, carefully chosen, threshold.
variable is singleton arc consistent.
                                                        Let Ps(x,y,a) be the probability that there exists some sup-
  MAC  is a backtrack algorithm that maintains arc consis-
                                                      port for (x, a) in D(y). If we assume that each value in
tency after every variable assignment. Forward Checking
                                                      Dac(y) is equally likely to be removed during search, then
(FC) can be considered a degenerated form of MAC.Iten-
                                                      it follows that
sures that each value in the domain of each future variable is                                
FC consistent, i.e. supported by the value assigned to every                | R(y) |    | Dac(y) |
                                                            Ps(x,y,a) =1−            /             .
past and current variable by which it is constrained. MSAC                 sc(x, y, a)  sc(x, y, a)
is a backtrack algorithm that maintains singleton arc consis-
tency. Throughout this paper, familiarity with the arc consis- Let T , 0 ≤ T ≤ 1, be some desired threshold. If Ps(x,y,a) ≥
tency algorithm AC-3 [Mackworth, 1977] is assumed.    T then (x, a) has some support in D(y) with a probability

                                                IJCAI-07
                                                   144  T                                                   Function PAC-3( current var ):Boolean;
of  or more. This condition is called a Probabilistic Sup- begin
port Condition (PSC)in[Mehta and van Dongen, 2005a].If  Q := G
it holds, then the process of seeking a support for (x, a) in while Q not empty do begin
D(y)                         T =0.9  |D  (y)| =20         select any x from {x :(x, y) ∈ Q }
     is avoided. For example, if    ,  ac         ,       eﬀective revisions :=0
sc(x, y, a)=2, and this time | R(y) | =2,thenPSC holds    for each y such that (x, y) ∈ Q do
and (x, a) has a support in D(y) with a probability of 0.994. remove (x, y) from Q
                                            D   (x)         if y = current var then
  Let Ps(x,y) be the least probability of the values of ac   revise(x, y, changex)
that there exists some support in y.IfPs(x,y) ≥ T then,     else
                                                                  (x, y,     )
            D(x)               y                             revisep  changex
each value in    is supported by with a probability of      if D(x)=∅ then
T or more. This condition is called a Probabilistic Revision return False
Condition. If it holds then the revision of D(x) against D(y) else if changex then
                                                             eﬀective revisions := eﬀective revisions +1
                                                              
is skipped. The interested reader is referred to [Mehta and  y  := y;
                                                          if eﬀective revisions =1then
van Dongen, 2005a] for details.                                                 
                                                            Q := Q ∪{(y ,x) ∈ G : y = y , Ps(y ,x) <T}
                                                          else if eﬀective revisions > 1 then
3.1  PAC-3                                                           
                                                            Q := Q ∪{(y ,x) ∈ G : Ps(y ,x) <T}
PSC and PRC can be embodied in any coarse-grained AC al- return True;
                                                      end;
gorithm. Figure 1 depicts the pseudocode of PAC-3,theresult              Figure 1: PAC-3

of incorporating PSC and PRC into AC-3 [Mackworth, 1977]. Function revisep (x, y, var changex)
Depending on the threshold, sometimes it may achieve less begin
                                                        changex := False
than full arc consistency. If PSC holds then the process of for each a ∈ D(x) do
identifying a support is avoided. This is depicted in Figure 2. if Ps(x,y,a) ≥ T then
                                                            \∗      ∗\
If PRC holds then it is exploited before adding the arcs to the do nothing
                                                          else
queue, in which case the corresponding arc (x, y) is not added if b ∈ D(y) such that b supports a then
to the queue. This is depicted in Figure 1. Note that coarse- D(x) := D(x) \{a }
                                                                    =
                                     O(ed)                   changex : True
grained arc consistency algorithms require revisions  end;
in the worst-case to make the problem arc consistent. Nev-
ertheless, the maximum number of effective revisions (that is       Figure 2: Algorithm revisep
when at least a single value is deleted from a domain) cannot
exceed O(nd), irrespective of whether the algorithm used is examine the usefulness of PSAC and PLSAC when used as a
optimal or non-optimal. Thus, in the worst case, it can per- preprocessor and when maintained during search.
    O(ed  − nd)
form            ineffective revisions. In order to use PSC Problems Studied
and PRC, the support count for each arc-value pair must be We have used model B [Gent et al., 2001] random problems
computed prior to search. If T = 0 then PAC-3 makes the and several problems from the literature to evaluate the com-
problem FC consistent. If T = 1 then PAC-3 makes the prob- petence of probabilistic consistencies. In model B, a random
lem arc consistent. The support counters are represented in                      n, d, c, t 
 n
O(ed)                                                 CSP instance is represented as    where   is the num-
     , which exceeds the space-complexity of AC-3. Thus, ber of variables, d is the uniform domain size, c is the num-
the space-complexity of PAC-3 becomes O(ed).Theworst-                     t
                           O(ed3)                     ber of constraints, and is the number of forbidden pairs of
case time complexity of PAC-3 is  . The use of PSC and values. For each combination of parameter, 50 instances are
PRC in PAC-3 is presented in such a way that the idea is made generated and their mean performances is reported. The re-
as clear as possible. This should not be taken as the real im- maining problems, except odd even n 2 have all been used
            [                         ]
plementation. Mehta and van Dongen, 2005a describes how as benchmarks for the First International CSP Solver Com-
to implement PSC and PRC efﬁciently.                  petition and are described in [Boussemart et al., 2005].In-
                                                      formally, the odd-even n problem is an undirected constraint
4  Experimental Results                               graph with a cycle with n variables. The domain of each vari-
4.1  Introduction                                     able is {1, 2, 3, 4}. For each constraint Cxy,ifa(x, a) is odd
                                                      (even) then it is supported by even (odd) values of D(y).The
Overview
                                                      problem is unsatisﬁable if n is odd.
We present some empirical results demonstrating the practi- Throughout, it has been our intention to compare general-
cal use of PSC and PRC. We investigate several probabilis- purpose propagation algorithms, and not special-purpose al-
tic consistencies, particularly, Probabilistic Arc Consistency gorithms, which make use of the semantics of the con-
(PAC), Probabilistic Singleton Arc Consistency (PSAC), and straints. Some readers may argue that the probabilistic con-
a limited version of PSAC (PLSAC). First, we ﬁnd out the straint propagation algorithms should have been compared
threshold at which Maintaining PAC (MPAC) performs the with special-purpose propagation algorithms. For example, it
best by experimenting on model B random problems. Next, is well known that for anti-functional constraints, there is no
we carry out experiments to determine how well MPAC does need to look for a support unless there is only one value left.
when compared to MAC and FC. The results for FC are also
included to show that MPAC is not only better than MAC on 2The problem is mentioned in the invited talk ”Towards theo-
problems on which FC is better than MAC butaswellason retical frameworks for comparing constraint satisfaction models and
the problems on which MAC is better than FC. Finally, we algorithms” by Peter van Beek in CP’2001.

                                                IJCAI-07
                                                   145Table 1: Comparison between FC, MAC,andMPAC   (with   Table 2: Comparison between FC, MAC,andMPAC (with T =
T=0.9) on random problems.                            0.9) on a variety of known problems.
     n, d, c, t Algorithm  #chks   time     #vn         Problem  Algorithm   #chks time   #vn    #rev
                 FC       60,435,849 13.084 1,336,291              FC       74,944,982 11.564 1,508,169 13,406,750
   20, 30, 190, 271 MAC 223,034,030 18.203 281,954      frb40-19 MAC      177,424,742 11.488 158,816 25,493,093
                 MPAC     49,496,904 11.602 443,292                MPAC     47,423,325 8.407 268,115 14,899,791
                 FC      286,321,115 61.306 6,181,026              FC       972,804,340 196.002 17,843,238 172,256,029
   20, 40, 190, 515 MAC 1,052,973,654 86.216 1,287,709  frb45-21 MAC     1,501,335,748 215.092 1,861,016 333,222,409
                 MPAC    234,024,186 51.102 2,048,660              MPAC     599,255,164 145.864 3,532,973 195,139,744
                 FC      121,226,499 31.230 2,581,395              FC       20,492,062 1.791 384,458 1,515,356
   50, 10, 500, 20 MAC 276,708,237 35.178 334,566       scen5    MAC        879,425 0.061 498  21,934
                 MPAC     72,993,605 27.913 678,370                MPAC      7,713,406 0.466 59,048 585,416
                 FC      3,809,711,519 2754.135 346,075,062        FC        2,891,066 0.325 11,788 131,020
   150, 15, 400, 134 MAC 908,870,372 217.939 709,387    scen11   MAC       8,285,681 0.517 3,749 276,601
                 MPAC    706,309,188 193.746 1,149,995             MPAC     10,391,078 0.298 4,624 98,334
                 FC      555,592,958 119.888 17,268,137            FC      2,203,289,973 550.03 14,543,828 170,755,686
   100, 20, 290, 240 MAC 135,546,970 17.777 97,939      scen11 f7 MAC    8,028,568,317 777.38 3,471,542 408,551,247
                 MPAC     81,031,221 16.731 132,983                MPAC    1,518,283,911 360.86 6,935,594 157,729,437
                 FC       58,969,203 8.686 1,871,351               FC      5,372,894,595 1,295.79 36,611,678 421,021,114
   90, 20, 222, 272 MAC 18,255,078 1.086   7,719        scen11 f6 MAC   16,066,360,455 1,767.93 7,643,388 817,697,705
                 MPAC      8,019,466 1.081  10,734                 MPAC    4,233,509,071 954.79 19,056,709 413,380,973
                                                                   FC         206,389 0.054 11,588 77,051
                                                          bqwh15 106 MAC      231,871 0.036 1,594 91,721
Indeed, this should improve constraint propagation. How-           MPAC       81,520 0.027 1,893 50,785
                                                                   FC        9,368,452 3.093 500,794 3,615,749
ever, probabilistic algorithms can be improved similarly. bqwh18 141 MAC     5,516,466 1.224 23,229 2,283,944
                                                                   MPAC      1,402,175 0.788 27,232 1,101,786
Implementation Details                                             FC       12,213,843 2.487 149,151 2,040,421
 C                                                        geom     MAC      49,937,553 4.119 28,220 5,895,601
A  -3 is used to implement the arc consistency component of        MPAC      7,313,488 2.006 43,511 2,371,765
MAC and SAC. The reason why AC-3 is chosen is that it is eas-      FC       129,662,303 7.510 1,656,165 15,002,347
                                                          qa-5     MAC      52,300,903 3.999 94,531 11,736,269
ier to implement and is also efﬁcient. For example, the best       MPAC     3,2433,059 2.342 105,304 4,731,980
solvers in the binary and overall category of the First Inter-     FC      2,135,903,729 1,526.256 140,853,896 1,704,256,885
                                                          qa-6     MAC      911,855,065 129.094 672,252 164,556,262
national CSP Solver Competition were based on AC-3.Sim-            MPAC     960,010,551 104.517 1,462,548 99,707,970
ilarly, PAC-3 is used to implement the probabilistic arc con-      FC       287,382,172 37.730 96,173,136 96,873,380
                                                          odd even 27 MAC       948 0.000    4     162
sistency component of the probabilistic versions of MAC and        MPAC        1,218 0.000   4     162
SAC.SAC-1 is used to implement singleton arc consistency.          FC      4,190,654,127 211.518 33,918,459 40,155,040
                                                          K25⊕Q8   MAC    23,117,603,455 308.070 122,934 1,804,139
All algorithms were equipped with a dom/wdeg [Bousse-              MPAC    5,512,831,722 180.914 246,026 2,004,268
mart et al., 2004] conﬂict-directed variable ordering heuris-      FC      5,959,952,959 503.351 32,977,840 174,400,084
                                                          K25⊗Q8   MAC    23,472,721,326 335.107 122,549 12,963,828
tic. The performance of the algorithms is measured in terms        MPAC    5,550,542,521 198.914 260,750 4,182,518
of checks (#chks), time in seconds (time), the number of re-
visions (#rev), and the number of visited nodes (#vn). The constrained problems (ﬁrst 3 rows), on which FC is better than
experiments were carried out on a PC Pentium III having 256 MAC, and on hard sparse, tightly constrained problems (last 3
MB of RAM running at 2.266 GHz processor with linux. All rows) on which MAC is better than FC. Results demonstrate
algorithms were written in C.                         that MPAC (T = 0.9) is better than the best of FC and MAC on
                                                      both classes of random problems. Also, the number of nodes
4.2  Probabilistic Arc Consistency                    visited by MPAC (T = 0.9) is nearer to MAC than those visited
Maintaining probabilistic arc consistency in such a way that by FC. This is the ﬁrst time an algorithm has been presented
the amount of ineffective constraint propagation is minimised that outperforms MAC and FC on both classes of problems.
and simultaneously the least amount of effective propagation Seeing the good performance of MPAC for threshold values
is avoided depends heavily on the threshold value T .There- ranging between 0.8 and 0.9, we decided to choose T =0.9
fore, a natural question is for which values of T , MPAC re- for the remainder of the experiments.
solves the trade-off, in terms of time, between the effort re-
                                                      Problems from the Literature
quired to search and that required to detect inconsistent val-
ues. To ﬁnd this out, experiments were designed to exam- Table 2 shows the results obtained on some instances of va-
                                                      riety of known problems: (1) forced random binary prob-
ine the behaviour of MPAC with different thresholds ranging
from 0 to 1 in steps of 0.02 on random problems. Note that lems frb-40-19 and frb-45-21 (2) RLFAP instances scen5
                                                      and scen11, (3) modiﬁed RLFAP instances scen11 f7 and
at T =1, MPAC maintains full arc consistency and at T =0,
it becomes forward checking. It is well known that on hard scen11 f6, (4) average of 100 satisﬁable instances of bal-
                                                      anced Quasigroup with Holes problems bqwh15 106 and
dense, loosely constrained random CSPs, FC performs bet-
                                                      bqwh18 141 (5) average of 100 (92 satisﬁable, 8 satisﬁable)
ter than MAC and on hard sparse, tightly constrained random
                                                      instances of geometric problem geom (6) two instances of
CSPs, MAC performs better than FC [Chmeiss and Sa¨ıs, 2004].
                                                      attacking prime queen problem qa-5 and qa-6, (7) one in-
Therefore, we studied MPAC with these classes of problems.
                                                      stance of odd-even problem odd-even 27, (8) two instances
Random Problems                                       of queen-knights problem K25⊕Q8 and K25⊗Q8.
In our investigations, we found that inferring the existence One can observe in Table 2, that in terms of time, on some
of a support with a likelihood, roughly between 0.8 and 0.9, problems, FC is better than MAC, while on some, MAC is bet-
enables MPAC to outperform both MAC and FC on both classes ter than FC. It is surprising that FC is not much inferior than
of problems. Table 1 presents results on hard dense, loosely MAC as anticipated. This is partially because of the robust-

                                                IJCAI-07
                                                   146ness of the conﬂict directed variable ordering heuristic. For Table 3: Comparison between SAC, LSAC, PSAC and PLSAC.
easy problems, due to the expense entailed by computing the problem        SAC      LSAC    PSAC    PLSAC
                                                                 #chks   274,675   186,172  14,384  11,436
number of supports for each arc-value pair, MPAC may not be bqwh15 106 time 0.026   0.020   0.006   0.005
beneﬁcial. However, the time required to initialise the sup-     #rem       23        23      23      23
                                                                 #chks   409,344   299,821  44,534  36,973
port counters is not much. Furthermore, for all the harder bqwh18 114 time 0.040    0.030   0.010   0.008
instances, that require at least 1 second to solve, MPAC gen-    #rem       15        15      15      15
                                                                 #chks 872,208,323 895,600,777 17,484,337 17,484,337
erally pays off, by avoiding much ineffective propagation. In qa-7 time   50.885   52.390   1.929   1.979
summary, by visiting few extra nodes than MAC, MPAC is able      #rem       65        65      65      65
                                                                 #chks 3,499,340,592 3,533,080,066 51,821,816 51,821,816
to save much ineffective propagation and solves the problem qa-8 time    249.696   290.534  9.790   11.496
                    MAC     FC                                   #rem      160       160     160     160
more quickly than both  and   .                                  #chks 206,371,887 206,371,887 16,738,737 16,738,737
  Note that, if the domain size is small or if the values have K25⊕Q8 time 2.407    2.446   0.469   0.450
                                                                 #rem     3,111     3,111   3,111   3,111
only a few supports, then keeping the threshold high, fails      #chks 1,301,195,918 1,301,195,918 19,252,527 19,252,527
PSC and PRC quickly, since the likelihood of support exis- K25⊗Q8 time    13.473   13.469   0.613   0.635
                                                                 #rem     3,112     3,112   3,112   3,112
tence decreases rapidly with respect to the number of values     #chks  9,896,112 11,791,192 2,793,188 2,348,189
removed from the domain and the prospect of effective prop- scen5 time    0.700     0.858   0.126   0.120
                                                                 #rem     13,814   13,814   13,794  13,794
agation increases. This in turn permits MPAC to act like MAC.    #chks 622,229,041 622,229,041 16,376,619 16,376,619
For example, in case of odd even 27, the domain size of each scen11 time  21.809   21.809   3.005   3.005
                                                                 #rem        0        000
variable is 4 and each arc-value pair is supported by 2 values.  #chks 292,600,735 292,600,735 16,415,998 16,415,998
                                n+1
For this problem, FC visits exactly 2 − 4 nodes, while   scen11 f6 time   11.775   11.763   0.811   0.813
                                                                 #rem      3660     3660    3660     3660
MAC  visits only 4 nodes and for T =0.9 MPAC also vis-           #chks 600,508,958 600,508,958 14,100,504 14,100,504
                                                          js-1   time     15.549   15.411   0.446   0.415
its only 4 nodes. The probability of support existence for a     #rem        0        000
value (x, a) in D(y) becomes 0.66, as soon as 2 values are       #chks 985,446,461 985,446,461 18,291,441 18,291,441
            y                              0.9            js-2   time     24.963   25.393   0.601   0.631
removed from  , and since the threshold is set to , both         #rem        0        000
PSC and PRC fails, enabling MPAC to maintain full arc consis-    #chks  5,272,064 6,184,748 744,324 611,475
                                                        co-25-10-20 time  0.258     0.303   0.076   0.061
tency. This again shows that MPAC with the right threshold is    #rem      392       391     392     392
able to resolve when to propagate and when not to.               #chks  2,143,350  23,359  184,507 184,507
                                                        co-75-1-80 time   0.087     0.001   0.012   0.013
  We also experimented with MAC-2001 which uses an opti-         #rem       59        59      56      56
mal arc consistency algorithm AC-2001. However, for almost
all the problems, MAC-2001 was consuming more time than
MAC-3, since there is a huge overhead of maintaining auxil- The algorithms SAC, LSAC, PSAC (Probabilistic SAC), and
iary data structures [van Dongen, 2003].              PLSAC (Probabilistic LSAC) were applied to forced random
                                                      problems, RLFAP, modiﬁed RLFAP, quasi-group with holes,
4.3  Probabilistic Singleton Arc Consistency          queens-knights, attacking prime queen, job-shop instances,
Although there are stronger consistencies than arc consis- composed random problems. Table 3 presents results for only
tency, the standard is to make the problem full/partial arc con- a few instances of the above problems, due to space restric-
sistent before and/or during search. However, recently, there tion. Again, the value of threshold used for PSC and PRC is
has been a surge of interest in SAC [Bessi`ere and Debruyne, 0.9. In Table 3 #rem denotes the number of removed val-
2005; Lecoutre and Cardon, 2005] as a preprocessor of MAC. ues. The intention is not to test if the preprocessing by SAC
The advantage of SAC is that it improves the ﬁltering power has any effect in the global cost of solving the problem, but
of AC without changing the structure of the problem as op- to see if the same results can be achieved by doing consid-
posed to other stronger consistencies such as k-consistency erably less computation by using probabilistic support infer-
(k>2)  and so on. But, establishing SAC can be expensive, ence. When the input problem is already singleton arc con-
and can be a huge overhead, especially for loose problems sistent, PSAC and PLSAC avoid most of the unnecessary work.
                                                                                       1      2
[Lecoutre and Cardon, 2005]. We investigate the advantages For example, for job-shop instances js- and js- , both PSAC
                                                                            34
and disadvantages of applying PSC and PRC to SAC.     and PLSAC spend at least times less time than their coun-
  Enforcing SAC in SAC-1 [Debruyne and Bessi`ere, 1997] terparts. Even when the input problem is not singleton arc
style works by having an outer loop consisting of variable- consistent, probabilistic versions of the algorithms are as ef-
value pairs. For each (x, a) if ac(P|x=a)=⊥, then it deletes ﬁcient as the original versions. For most of the problems,
a from D(x). Then it enforces AC. Should this fail then the they remove exactly the same number of values as removed
problem is not SAC. The main problem with SAC-1 is that by SAC and LSAC, but consume signiﬁcantly less time. For
deleting a single value triggers the addition of all variable- example, in case of attacking queen problems, all the algo-
value pairs in the outer loop. The restricted SAC (RSAC)al- rithms remove the same number of values. However, PSAC
                                                                                            27
gorithm [Prosser et al., 2000] avoids this triggering by con- and PLSAC are quicker by an order of at least .
sidering each variable-value pair only once. We propose lim- Seeing the good performance of PSAC and PLSAC,theim-
ited SAC (LSAC) which lies between restricted SAC and SAC. mediate question arises: can we afford to maintain them dur-
The idea is that if a variable-value pair (x, a) is found arc- ing search? So far SAC has been used only as a preprocessor.
inconsistent then, only the pairs involving neighbours of x as Maintaining SAC can reduce the number of branches signiﬁ-
a variable are added in the outer-loop. Our experience is that cantly but at the cost of much constraint propagation, which
LSAC is more effective than RSAC.                     may consume a lot of time. Maintaining it even for depth 1

                                                IJCAI-07
                                                   147