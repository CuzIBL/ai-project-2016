Improving Anytime Point-Based Value Iteration Using Principled Point Selections

                    Michael R. James, Michael E. Samples, and Dmitri A. Dolgov
                                         AI and Robotics Group
                           Technical Research, Toyota Technical Center USA
                  {michael.james, michael.samples, dmitri.dolgov}@tema.toyota.com


                    Abstract                          our algorithms choose additional points that signiﬁcantly im-
                                                      prove the resulting approximation of the value function. Such
    Planning in partially-observable dynamical sys-   improvement is potentially beneﬁcial in two ways. First,
    tems (such as POMDPs and PSRs) is a com-          computation time can be reduced because there are many
    putationally challenging task. Popular approx-    fewer points for which computation must be performed.
    imation techniques that have proven successful    However, this beneﬁt is sometimes (but not always) offset by
    are point-based planning methods including point- the additional time required to select new points. Another po-
    based value iteration (PBVI), which works by ap-  tential beneﬁt is reduced memory storage for smaller sets of
    proximating the solution at a ﬁnite set of points. points. Currently, the solution of most systems do not require
    These point-based methods typically are anytime   large numbers of points, but a storage beneﬁt may become
    algorithms, whereby an initial solution is obtained more important as the size of problems increases such that
    using a small set of points, and the solution may more points are required.
    be incrementally improved by including additional
    points. We introduce a family of anytime PBVI al-
    gorithms that use the information present in the cur- 2 Background
    rent solution for identifying and adding new points The planning methods developed here are for partially-
    that have the potential to best improve the next so- observable, discrete-time, ﬁnite-space dynamical systems in
    lution. We motivate and present two different meth- which actions are chosen from a set A, observations from a
    ods for choosing points and evaluate their perfor- set O, and rewards from a set R. There is exactly one action,
    mance empirically, demonstrating that high-quality one observation, and one reward per time-step—planning al-
    solutions can be obtained with signiﬁcantly fewer gorithms attempt to ﬁnd a policy that maximizes the long-
    points than previous PBVI approaches.             term discounted reward with discount factor γ ∈ [0, 1).
                                                        These point-based planning methods are suitable for at
1  Introduction                                       least two classes of models that can represent such dynamical
Point-based planning algorithms [Pineau et al., 2003; Spaan systems, the well-known partially observable Markov deci-
and Vlassis, 2005] for partially-observable dynamical sys- sion processes (POMDP), and the newer predictive state rep-
                                                                     [               ]
tems have become popular due to their relatively good per- resentation (PSR) Singh et al., 2004 . For the sake of famil-
formance and because they can be implemented as anytime iarity, we use POMDPs here, but it should be noted that the
algorithms. It has been suggested (e.g., in [Pineau et al., methods presented here (as well as other planning methods
2005]), that anytime point-based planning algorithms could for such dynamical systems) can just as easily be applied to
                                                               [               ]
beneﬁt signiﬁcantly from the principled selection of points to PSRs (see James et al., 2004 for details).
add.
  We provide several methods for using information col- 2.1 POMDPs
lected during value iteration (speciﬁcally, characteristics of POMDPs are models of dynamical systems based on under-
the value function) to choose new additional points. We show lying latent variables called nominal states s ∈S.Atany
that properties of the value function allow the computation of time step, the agent is in one nominal state s. Upon taking
an upper bound on the potential improvement (gain) resulting an action a ∈Athe agent receives a reward r(s, a) that is
from the addition of a single point. We argue that the addition a function of the state and action, transitions to a new state
of points with maximal gain produces good approximations s according to a stochastic transition model pr(s|s, a), and
of the value function, and this argument is empirically ver- receives an observation o ∈Oaccording to a stochastic ob-
iﬁed. Further, we deﬁne an optimization problem that ﬁnds servation model pr(o|s, a). For compactness, we deﬁne the
                                                                               1
the point with the maximal gain for a given region.   vector ra as ra(s)=r(s, a).
  These new approaches are empirically compared to tradi-
tional anytime point-based planning. The results show that 1The notation v(e) for vector v refers the value of entry e in v.

                                                IJCAI-07
                                                   865                                                                        
                                                             b                      i   T i
  The agent does not directly observe the nominal state s, where ga = ra + γ o argmax{gao}i b gao. In PBVI, the
and so, must maintain some sort of memory to fully charac- backup is applied to each point in P , as follows.
terize its current state. In POMDPs, this is typically done
                                                      function   oneStepPBVIbackup(      ,     )
using the belief state: a probability distribution over nomi-                           P   Sold

nal states. The belief state b summarizes the entire history 1. Snew = ∅
by computing the probability of being in each nominal state
                                        o              2. For each   b ∈ P  compute   α  = backup(b) and
b(s). This computation of the new belief state ba reached af-              ∪
ter taking action a and getting observation o from belief state set Snew = Snew α
b is given in the following update:                    3. return   S
                                                                  new
                                
                 pr(o|s ,a) pr(s |s, a)b(s)
        bo =   s            s             .             For Perseus, in each iteration the current set of α vectors
         a             pr(o|a, b)                     is transformed to a new set of α vectors by randomly choos-
This equation is used as the agent interacts with the dynami- ing points from the current set P and applying the backup
cal system to maintain the agent’s current belief state. operator to them. This process is:
                                                      function   oneStepPerseusBackup(       ,     )
2.2  Point-based Value Iteration Algorithms                                                P    Sold
                                                                    ∅
Point-based planning algorithms, such as PBVI and Perseus, 1. Snew = ,  P  =   P , where   P  lists the
for partially observable dynamical systems perform planning non-improved  points
by constructing an approximation of the value function. By 2. Sample b uniformly  at random from    P ,
updating the value function for one point, the value-function compute α = backup(b)
approximation for nearby points is also improved. The ba-      T
                                                       3. If  b α  ≥ Vn(b) then add    α to  Snew, else
sic idea is to calculate the value function (and its gradient)                   T  
                                                          add                        to
only at a small number of points, and the value function for   α  =argmaxα   ∈Sold b α     Snew
the other points will be “carried along”. This point-based ap-
                                                       4. Compute   P =  {b ∈ P : Vn+1(b) − <Vn(b)}
proach uses only a fraction of the computational resources
to construct the approximate value function, as compared to 5. If P is empty return  Snew,  otherwise
exact methods.                                            go  to  step 2
  There are two main sets of vectors used: the set P of points,
                                                        Given this, the basic (non-anytime) algorithms are, for * ∈
each of which is a belief state vector; and the set S which
                                            n         [PBVI, Perseus]:
represents the approximate value function Vn at step n. The
value function is a piecewise linear convex function over be- function basic*()
lief states, deﬁned as the upper surface of the vectors α ∈ Sn.
The value for belief state b is                        1. P  =  pickInitialPoints(),      S0 =
                                                          minimalAlpha(),     n =0
                              T
                 Vn(b)=maxb    α.
                         α∈Sn                          2. Sn+1  =  oneStep*Backup(P    , Sn)
  The Bellman equation is used to deﬁne the update for the 3. increment n, goto  2
next value function:
                                                   where pickInitialPoints() typically uses a random walk with
                T             |        o
Vn+1(b)=max    b ra + γ   pr(o a, b)Vn(ba)            distance-based metrics to choose an initial set of points, and
           a
                      o                            the function minimalAlpha() returns the α vector with all en-
                                                                             −
  =maxbT     r  + γ   pr(o|a, b)max(bo)T αi           tries equal to minr∈R r/(1 γ). The algorithm will stop on
              a                 i     a
       a                       α ∈Sn                  either a condition on the value function or on the number of
                    o
                                                     iterations. This algorithm is easily expanded to be an any-
            T
  =maxb      ra +                                     time algorithm by modifying pickInitialPoints() to start with
       a                                          a small set of initial points and including a step that iteratively
                                              
      γ    max     pr(o|s ,a)   pr(s |s, a)b(s)αi(s )
            i                                         expands the set of current points P . Typically, having a cur-
           α ∈Sn
        o                   s                        rent set with more points will result in a better approximation
                s             
            T               T i                       of the value function, but will require more computation to
  =maxb      ra + γ    max b gao
       a              {gi }                           update. The anytime versions of the algorithms are:
                    o   ao
                                                      function   anytime*()
where           
         i             |       |    i               1. P  =  pickInitialPoints(),      S0 =
        gao(s)=    pr(o s ,a)pr(s s, a)α (s ),  (1)
                 s                                       minimalAlpha(),     n =0
    i                                                  2. if(readyToAddPoints())       then  P  =  P ∪
for α ∈ Sn. These g vectors are deﬁned as such because they
lead to computational savings. The computation of α vectors bestPointsToAdd(findCandidatePoints())
for Vn+1(b) uses the so-called backup operator.        3. Sn+1  =  oneStep*Backup(P    , Sn)
                                 T b
             backup(b) = argmax b ga,           (2)    4. increment    n, goto   2
                           b
                         {ga}a∈A

                                                IJCAI-07
                                                   866  There are three new functions introduced in this anytime on points that lead to these points (although the effect will
algorithm: readyToAddPoints() which determines when the be discounted), improving many parts of the value function.
algorithm adds new points to S; ﬁndCandidatePoints() which This gain is deﬁned as:
is the ﬁrst step in determining the points to add; and best-                                   
                                                                                       |       o  −
PointsToAdd() which takes the set of candidate points and gB(b)=maxr(b, a)+γ       pr(o b, a)V (ba) V (b)
                                                                   a
determines a set of points to add. In Section 4, we present                      o
variations of these functions, including our main contribu-   =  bT α − V (b),
tions, methods for determining the best points to add based
on examination of the value function.                 where α =   backup (b). Note that this measure includes
                                                      the immediate expected reward at b, a quantity that was not
3  Incremental PBVI and Perseus                       previously included in the computation of any α vector. This
                                                      measure can make use of cached ga vectors (Equation 1), and
In this section we present methods for ﬁnding the best points so it is inexpensive from the computational standpoint. In the
to add, given a set of candidate points. In some cases, the following section, we describe a different measure of gain
best points will be a subset of the candidates, and in other that has a stronger theoretical justiﬁcation, but also comes at
cases new points that are outside the set of original candidates the expensive of higher computational cost.
will be identiﬁed as best. In all cases, we will make use of
a scalar measure called the gain of a point, which is a way 3.2 Gain Based on Value-Function Bounds
to evaluate how useful that point will be. We show how the This second measure of gain that we introduce uses the fol-
current (approximate) value function can be used to compute lowing insight, which we ﬁrst illustrate on a system with two
useful measures of gain that can then be used in informed nominal states, then extend the intuition to a three-state sys-
methods of point selection.                           tem, and then describe the general calculation for any num-
  For a point b in the belief space, the gain g(b) estimates ber of states. The value function is a piecewise linear convex
how much the value function will improve. The problem, function consisting of (for two nominal states) the upper sur-
then, is to construct a measure of gain that identiﬁes the points face of a set of lines deﬁned by α vectors (see Figure 1a for a
that will most improve the approximation of the value func- running example). The vectors which deﬁne these lines corre-
tion. This is a complex problem, primarily because changing spond to points interior to the regions where the correspond-
the value function at one point can affect the value of many ing lines are maximal (points A, B, and C). Intuitively, the
(or all) other points, as can be seen by examining the backup value function is most relevant at these points, and becomes
operator (Equation 2). Changes may also propagate over an less relevant with increasing distance from the point. Here,
arbitrary number of time steps, as the changes to other points we assume that the value given by the α vector is correct at
propagate to yet other points. Therefore, exactly identifying the corresponding point. Now consider the inclusion of a new
the points with best gain is much too computationally expen- α vector for a new point (point X in Figure 1a). If the value
sive, and other measures of gain must be used.        function for point A is correct, then the new α vector cannot
  Here, we present two different measures of gain: one based change the value of A to be greater than its current value; the
on examining the backup operator, written gB, and the other same holds for B. Therefore, the new α vector for point X
is derived from ﬁnding an upper bound on the amount of gain is upper-bounded by the line between the value for A and the
that a point may have. We use linear programming to com- value for B. Thus, the gain for X is the difference between
pute this gain, written gLP .                         this upper bound and the current value of X.
  Given these deﬁnitions of gain, we present two differ- For the case with three nominal states, the analogous pla-
ent methods for identifying points to add. The simplest nar solution to the upper bound is not as simple to compute
method (detailed in Section 4) takes the candidate points, or- (see Figure 1b and 1c). To visualize the problem, consider
ders them according to their gains, and then selects the top a mobile plane being pushed upward from point X, which
few. A more sophisticated method leverages some informa- is constrained only to not move above any of the existing
tion present when computing gLP to identify points that have points that deﬁne the value-function surface (A, B, C, and
even higher gain than the candidate points, and so returns dif- D in Figure 1b). In the example depicted in Figure 1b, this
ferent points than the original candidates. We describe how plane will come to rest on the points deﬁned by the loca-
these selection methods can be implemented in Section 4, fol- tions of A, B, C in the belief space and their values. The
lowing a detailed discussion (Sections 3.1 and 3.2) of the two value of that plane at X then gives the tightest upper bound
measures of gain.                                     for its value if we were to add a new α vector at X. The
                                                      gain is then computed in the same manner as in the two
3.1  Gain Based on One-Step Backup                    state case above, but ﬁnding the above-described plane is not
The gain gB measures the difference between the current straightforward (and becomes even more difﬁcult in higher-
value of point b and its value according to an α vector com- dimensional spaces). The difﬁculty is that in higher dimen-
puted by a one-step backup of b via Equation 2. This mea- sional spaces — in contrast to the two state case where the
sure does not have strong theoretical support, but intuitively, minimal upper bound is always deﬁned by the points imme-
if the one-step difference for a point is large, then it will diately to the left and right of the new point — selecting the
also improve the approximations of nearby points signiﬁ- points that deﬁne that minimal upper-bounding surface is a
cantly. These improvements will then have positive effects non-trivial task. However, this problem can be formulated as

                                                IJCAI-07
                                                   867   Value

gLP (X)

       A     XB         C
            p(s1)

             (a)                              (b)                                    (c)

 Figure 1: (a): Value function for a dynamical system with two nominal states (note that p(s2)=1− p(s1), so an axis for p(s2)
 is unnecessary). The value function is deﬁned by the α vectors corresponding to points A, B, and C. The gain gLP (X) for point
 X is the difference between the upper bound deﬁned by the line V (A),V(B) and the current value of X. (b,c): Value function
 for a system with three nominal states. The value function is deﬁned by the α vectors corresponding to points A, B, C, and D,
 and the gain gLP (X) for point X is the difference between the tightest upper bound (deﬁned by plane V (A),V(B),V(C))
 and the current value for X. That tightest upper-bound plane is produced by the ﬁrst LP (FindGainAndRegionForPoint). X is
 the best point produced by the second LP (FindBestPointForRegion) for the bounding region {A, B, C}.

 a linear program (LP). We describe this LP in Table 1 and As before, the variables in this augmented LP are the scalar
 refer to it as FindGainAndRegionForPoint(b0).         weights w1...wm that deﬁne which points from {P ∪U} form
   Given a candidate belief point b0 its current scalar value v0, the bounding region Γ(b0)
 the current points {b1...b }, the current scalar values v1...v
                     m                            m    3.3  Finding the Best Point in a Bounding Region
 of these points, and the value vectors α1...αn, this minimiza-
 tion LP ﬁnds the tightest upper bound Vu(b0)= i wivi, Given the gains gLP for the candidate points, it is possible
 which can then be used to compute the gain gLP (b0)=  to choose points to add based on this criteria, but one draw-
 Vu(b0) − V (b0). In words, this minimization LP works by back to this is that we might add multiple points from the
 ﬁnding a set of points (these are the set of points with non- same bounding region Γ, and thus waste resources by ap-
 zero weights wi) such that: i) b0 can be expressed a convex proximating the value function for multiple points when just
 linear combination of these points, and ii) the value func- one would work almost as well. Further, it may be that none
 tion deﬁned by the plane that rests on their value-function of these points is the point in the region with the highest
 points is the minimal surface above v0. We call the set gain. To address these issues, we introduce another LP called
 of such points with non-zero weights the bounding region FindBestPointForRegion(Γ) (Table 1) that takes a bounding
 Γ(b0)={bi|wi  >  0} for point b0; it has the property that region and ﬁnds the point interior to that region with maximal
 the point b0 must be interior to it, and these bounding regions gLP . Note that this region may contain unit basis points, al-
 will play an important role in the next section.      lowing the new point to be exterior to the current set of points.
                                                         This LP takes as input a bounding region Γ(b0)=
   There is one subtle issue regarding the above LP, which is { }
 that not all points of potential interest are interior to the set of b1...bl , scalar values v1...vl of these points, and the value
 current points for which α vectors are deﬁned (in fact early vectors α1...αn. The optimization variables are: scalar
 in the process when there are few points, most of the useful weights w1...wl, vector bnew , which is the point to be found,
 points will be outside the convex hull of current points). This and the scalar value vnew, which is the value of bnew. The
 is problematic because we want to consider these points (they process of ﬁnding the best points to add will call this LP on all
 often correspond to relatively poorly approximated areas of unique regions found by running the ﬁrst LP (FindGainAn-
 the value function), but they are never interior to any subset dRegionForPoint) on all candidate points.
 of the current points.
   To resolve this issue, we introduce the set U of unit basis 4 Using Gains in PBVI and Perseus
 points: the points with all components but one equal to 0, and We now deﬁne two incremental algorithms, PBVI-I and
 the remaining entry equal to 1 (the standard orthonormal basis Perseus-I, using the gains gB and gLP , and the linear
 in the belief space). We then augment the set of current belief programs above. Referencing the anytime*() algorithm,
 points in our LP to include the unit basis points: {b1...bm} = we explored various possibilities for readyToAddPoints(),
 {P ∪ U}. The values vj of the points in U \ P are computed bestPointsToAdd(C), and ﬁndCandidatePoints(). While
 as vj = backup (bj) ∀bj ∈ U \ P , since these points were many variations exist, this paper presents only a few that seem
 not updated in oneStep*Backup() as were the points in P . most promising.

                                                 IJCAI-07
                                                    868Table 1: The linear programs used to i) compute the gain and region Γ(b0) for point b0 given a value function, and ii) ﬁnd the
best point within a given region Γ given the value function.

 FindGainAndRegionForPoint(b0):                       FindBestPointForRegion(Γ)
                                                                            
   Minimize:         wivi                              Maximize:           wivi − vnew
                   i                                                     i
       Given:     b0,v0,b1...bm,v1...vm,α1...αn            Given:     b1...bl,v1...vl,α1...αn
   Variables:     w1...wm                             Variables:    w1...wl,vnew,bnew
                                        ≥
  Constraints:    b0 =    wibi;     wivi  v0           Constraints:   bnew =    wibi;  wi ≥ 0 ∀i ∈ [1..l]
                      i          i                                          i
                                 ≥   ∀  ∈
                     wi =1;   wi   0  i   [1..m]                         wi =1;   vnew ≥ αjbnew  ∀j ∈ [1..l]
                   i                                                   i
  Two computationally cheap possibilities for readyToAdd- of three types. The ﬁrst type (performance vs. number of
Points() are to add points: i) after a ﬁxed number of iterations, points) is a measure of the effectiveness of point selection.
and ii) when the update process has approximately converged, The second type (performance vs. number iterations) and the
i.e., the maximal one-step difference in value over all points is third type (performance vs. cpu time) both measure how well
below some threshold (maxb∈P (Vn+1(b) − Vn(b)) ≤ ). We the use of principled point selection affects the overall per-
have also explored two methods for ﬁndCandidatePoints(). formance, but the third type shows the impact of additional
The ﬁrst is to keep a list of points that are one-step successors time incurred by the point-selection process. These graphs
                     { o| ∈   }
to the points in P , the set ba b P . The second method is show performance on the x-axis, and the amount of resource
to do a random walk and use a distance threshold to choose (points, iterations, or time) used to achieve that performance
points, just as in pickInitialPoints().               on the y-axis. When comparing two algorithms with respect
  The gains discussed in the previous section can then be to a given resource, the better algorithm will be lower.
used for bestPointsToAdd(C). Gain gB orders the candi-  Examination of the ﬁrst-type graphs shows that the LP-
date points C and the top k are chosen. For gain gLP , based Perseus-I did a good job of identifying the best points to
the candidate points deﬁne a set of unique bounding regions add. The resulting policies produced better performance with
{Γ(b)|b ∈ C}. For each region, the LP FindBestPointFor- fewer points than either of the other two methods. Further-
                                   
Region() returns the best candidate point b . These candidate more, on three of the problems, the one-step backup Perseus-
                        
points are ordered by gLP (b ) and the top k are chosen. To I also did signiﬁcantly better than the baseline for choosing
compare our methods against a baseline anytime algorithm, points. Thus, for this metric, our goal of ﬁnding useful points
we used the standard random walk method, choosing the ﬁrst has been achieved. Most promisingly, on the largest problem
k points that exceeded a distance threshold.          (Hallway) our algorithms used signiﬁcantly fewer points to
                                                      achieve good performance. However, the other graphs show
5  Experiments                                        that choosing good points does not always translate into a
                                                      faster algorithm. On one problem (Network) both versions
To evaluate our principled point selection algorithms, we con- of Perseus-I were faster than the baseline, but on the other
ducted testing on a set of standard POMDP domains. Three of problems, the performance was either closely competitive or
the problems are small-to-mid sized, and the fourth (Hallway) slightly worse due to the overhead incurred by identifying
is larger. Domain deﬁnitions may be obtained at [Cassan- good points. While this result was not optimal, the fact that
dra, 1999]. We tested three algorithms: i) a baseline, anytime there were signiﬁcant speedups on one problem combined
Perseus using the distance-based metric; ii) one-step backup with the point selection results leads us to draw the conclusion
Perseus-I using gB; and iii) LP-based Perseus-I using gLP that this method is promising and needs further investigation
and the two LPs for ﬁnding the best points.           and development.
  All three algorithms used the convergence condition with
 =1E − 3 for readyToAddPoints(). The algorithms for Net-
work, Shuttle, and 4x3 added up to 3 points at a time, while References
Hallway added up to 30 points at a time. However, choos-
                                                      [Cassandra, 1999] A. Cassandra. Tony’s  pomdp  page.
ing points using LPs often did not add all 30 because fewer http://www.cs.brown.edu/research/ai/ pomdp/index.html, 1999.
unique regions were found. In the one-step backup Perseus-
I, we used the successor metric for ﬁndCandidatePoints() as [Izadi et al., 2005] Masoumeh T. Izadi, Ajit V. Rajwade, and Doina
it was easily integrated with little overhead, while in the LP- Precup. Using core beliefs for point-based value iteration. In 19th
based Perseus-I we used a random walk with a distance met- International Joint Conference on Artiﬁcial Intelligence, 2005.
ric as it introduced the least overhead in this case. The results [James et al., 2004] Michael R. James, Satinder Singh, and
were averaged over 30 runs, and the performance metric is Michael L. Littman. Planning with predictive state representa-
the average discounted reward, for a given initial belief state. tions. In The 2004 International Conference on Machine Learn-
The results are presented in the graphs in Figure 2, which are ing and Applications, 2004.

                                                IJCAI-07
                                                   869