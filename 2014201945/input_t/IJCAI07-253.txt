                     Phonetic Models for Generating Spelling Variants 

                                   Rahul Bhagat and Eduard Hovy 
                                     Information Sciences Institute 
                                   University Of Southern California 
                        4676 Admiralty Way, Marina Del Rey, CA 90292-6695 
                                         {rahul, hovy}@isi.edu 

                    Abstract                          source language to English [Knight and Graehl, 1997]. Such 
                                                      a transliterator is quite likely to generate a spelling that is 
    Proper names, whether English or non-English,     not the most commonly used spelling of a name. In such a 
    have several different spellings when transliterated case, we could use the spelling variant model to match up 
    from a non-English source language into English.  this spelling to its more commonly accepted variant(s). 
    Knowing the different variations can significantly   Of course generating all the possible spelling variants of a 
    improve the results of name-searches on various   name is a next to impossible task, given that this would re-
    source texts, especially when recall is important. In quire one to simulate all the possible corruptions that a se-
    this paper we propose two novel phonetic models   quence of characters could undergo to produce a reasonable 
    to generate numerous candidate variant spellings of spelling. But one could approximate this by using different 
    a name. Our methods show threefold improvement    models. 
    over the baseline and generate four times as many   In this paper we propose two previously unexplored 
    good name variants compared to a human while      methods to generate the spelling variants of a person name. 
    maintaining a respectable precision of 0.68.      Our first method is a unique phoneme-based approach using 
                                                      the CMU pronouncing dictionary1. Here we first employ the 
1 Introduction                                        EM algorithm [Baum, 1972; Dempster et al., 1977] to learn 
In this paper, we present a novel approach for generating the mappings between letters and the corresponding pho-
variant spellings of a person’s name.                 nemes in both directions. We then use a noisy channel 
  Proper names in general are very important in text. Since model based translator to first generate n-best phoneme se-
news stories especially revolve around people, places, or quences for a name and then use a reverse translator to gen-
organizations, proper names play a major role in helping erate the n-best name variants for the phoneme sequences. 
one distinguish between a general event (like a war) and a   Our second method is a completely unsupervised method 
specific event (like the Iraq war) [Raghavan and Allan, in which we collect a list of over 7 million names (words) 
2005].                                                using a named entity extraction system applied to a large 
  Proper names in English are spelled in various ways. De- text corpus (about 10 GB plain text) collected from the web, 
spite the existence of one or more standard forms for some- and then use a popular sound based algorithm called Soun-
one’s name, it is common to find variations in translitera- dex [Knuth, 1973] to group together the variants in order to 
tions of that name in different source texts, such as Osama make them searchable. 
vs Usama. The problem is more pronounced when dealing   As the baseline, we use a system based on the names list 
                                                                                2
with non-English names or when dealing with spellings by obtained from the US Census . This list consists of about 
non-native speakers.                                  89,000 last names and 5500 first names (male and female) 
                                                                                    3
  Missing some spelling variations of a name may result in collected by the US census bureau . Given a name, we use 
omission of some useful information in a search about a levenshtein distance or edit distance [Hall and Dowling, 
person. For example, imagine a defense analyst or reporter 1980] to find the names that are possible variants of a given 
searching English transcripts of Arabic TV news or news- name. 
paper articles for information about some person. Transcrib-   To the best of our knowledge, no one has ever used a bi-
ers or different news sources, may spell the name of the directional phoneme-based approach the way we have to 
person differently and some relevant information about this generate spelling variants. Raghavan and Allan [2004] have 
person may never be found.  An automated spelling variant used Soundex codes to normalize names in a corpus for the 
generator would help locate all potential mentions of the purpose of story link detection task and Zobel and Dart 
person in question.                                                                                   
  Another useful application for a variant spelling generator 1 http://www.speech.cs.cmu.edu/cgi-bin/cmudict 
is transliteration. Imagine a transliterator that uses a pho- 2 http://www.census.gov/genealogy/names/names_files.html 
neme-based model to transliterate from a non-English     3 http://www.census.gov 


                                                IJCAI-07
                                                  1570[1996] have used Soundex as one of the phonetic string 3. 1  Pronunciation Learning Method 
matching algorithms for name retrieval.               In this method, we use the CMU pronouncing dictionary1, a 
  The rest of the paper is organized as follows.  Section 2 
                                                      pronunciation dictionary for North American English, as the 
discusses some related work, section 3 describes our meth-
                                                      data for training our models. The CMU dictionary consists 
ods in detail, section 4 describes our experiments, section 5 of over 125,000 English words along with their pronuncia-
presents the results and section 6 discusses our conclusion 
                                                      tions in a fixed set of 39 phonemes. 
and future work. 
                                                      3.1.1 Noisy Channel Model 
2 Related Work                                        We use the noisy channel model, which is commonly used 
                                                      in machine translation and speech recognition, as our basic 
The problem of spelling variants is a well studied problem model. In this framework for machine translation, the target 
in the information retrieval community, especially in the language sentence E has supposedly been corrupted into the 
context of query expansion and word conflation. For this source language sentence F due to a noisy channel [Brown 
purpose, various methods including stemming and more  et al., 1993]. 
complex morphological analysis have been proposed and 
                                                        argmax P(E | F) = argmax P(E)*P(F | E)      (3.1) 
widely used [Hull, 1996; Krovetz, 1993; Tzoukermann et 
                                                             E         E 
al., 1997].  These methods work very well with normal Eng-
                                                      where –  
lish words. However they cannot be effectively applied to 
                                                        P(E): represents the probability of the target language 
proper names given the difference in the nature of proper 
                                                      sentence E (language model)  
names and other English words 
                                                        P(F | E): represents the probability of generating the 
  In the past, people have worked with proper names. 
                                                      source language sentence F given the target language sen-
Knight and Graehl [1997] proposed a cascaded finite state 
                                                      tence E (translation model) 
transducer (FST) based approach for name transliteration 
                                                        P(E | F): represents the probability of generating the tar-
from Japanese to English. Virga and Khudanpur [2003] pro-
                                                      get language sentence E given the source language sentence 
posed a similar name transliteration approach for Chinese to 
                                                      F, estimated using the noisy channel model 
English to use in cross language information retrieval. Both 
these approaches use sounds or pronunciations as their   Similarly, in our case we assume a variant spelling of a 
bridge to go from one language to the other. They however name to be the result of a two translation processes:  
are targeted for transliteration between different languages 1. The characters in the original name are translated 
(say Japanese to English) and hence are not applicable for    into n-best sequences of phonemes 
generating variants in the same language. Raghavan and    2.  Phoneme sequences are translated back into n-best 
Allan [2005] studied the problem of proper name spelling      character sequences, thus generating the variants. 
variants in automatic speech recognition (ASR). They pro- We therefore have two noisy channels, one representing the 
posed a number of methods to match inconsistently spelled translation from a character sequence (C) to a phoneme se-
names in ASR. Their methods however are tailored for  quence (Ph) (text to speech) and other representing the 
speech recognition errors and require a parallel corpus of translation form a phoneme sequence back to a character 
speech and the corresponding transcriptions. Zobel and Dart sequence (speech to text).
[1996] used various phonetic string matching algorithms Text to speech: 
including Soundex for name retrieval. Their approach how-   argmax P(Ph | C) = argmax P(Ph)*P(C | Ph)    (3.2) 
ever deals only with matching phonetically similar names as      Ph          Ph 
against generating them.                              Speech to text: 
  None of these methods is suitable for our task since we   argmax P(C | Ph) = argmax P(C)*P(Ph | C)    (3.3) 
want to be able to model reasonable transformations a name        C           C 
spelling could undergo to actually generate variant spellings 3.1.2 Training 
for a name.                                           We apply the EM algorithm [Baum, 1972; Dempster et al., 
                                                      1977] in two directions to the CMU dictionary to obtain the 
3  Generating Spelling Variants                       IBM Model-3 [Brown et al, 1993] alignments between the 
                                                      characters and phonemes in both the directions. This gives 
In this section, we present two distinct and complementary 
                                                      us the two translation models - P(Ph | C) and P(C | Ph). 
approaches to generating the different spellings of a name. 
                                                        To obtain the phoneme language model P(Ph) we use the 
In the first method, we use a supervised learning approach 
                                                      125,000+ phoneme sequences from the CMU dictionary. 
to overgenerate a large number of variant spellings by varia-
                                                      Using this as training data, we build a phoneme trigram lan-
tions in pronunciation. We call this the Pronunciation 
                                                      guage model. 
learning method. 
                                                        To obtain the character language model P(C), we use the 
  In the second method we use a novel approach to first 
                                                      list of 7.3 million names that we extracted from text. Using 
obtain a large list of names, group the similar sounding 
                                                      this as training data, we build a character trigram language 
names using Soundex [Knuth, 1973], and then use Soundex 
                                                      model. 
to find the different spellings for a name. We call this the 
List Soundex method. 


                                                IJCAI-07
                                                  15713.1.3 Implementation                                  3.2.2 Soundex  Algorithm 
We use the GIZA++ package [Och and Ney, 2003] to train Levenshtein distance or edit distance [Hall and Dowling, 
our translation models. We obtain the alignments between 1980] is a measure of similarity between two strings, meas-
letters and phonemes in both the directions using GIZA++ uring the number of insertions, deletions, and substitutions 
and then based on the alignments, we build translation mod- required to transform a string into the other.  
els for both “text to speech” and “speech to text”.     Traditionally, edit distance has been used for spelling 
  We use the CMU-Cambridge statistical language model- error detection and correction [Kukich, 1992]. We can use 
ing toolkit4 to build the language models. We use trigram the same edit distance as a measure for finding names that 
based language models for both the letters and phonemes.  are close to a given name by doing a lookup in a name list. 
  Following Knight and Graehl [1997], we represent each But calculating edit distance between two strings is O(n2) in 
of our language models as a weighted finite state automaton the length of the strings. It is impossible in practice to use 
(WFSA) and each of our translation models as a weighted this measure when comparing against a large list. We need 
finite state transducer (WFST). We then use the USC/ISI to do better. We should at least initially prune our candi-
finite state transducer toolkit Carmel5 to perform the com- dates down and then use edit distance on this pruned list of 
position between the corresponding WFST and WFSA to   candidates. 
obtain two noisy channel based WFST decoders – one going   The Soundex algorithm [Knuth, 1973], first patented in 
from letters to phonemes (text to speech) and the other go- 1918 by Margaret O’Dell and Robert C. Russel, is an ap-
ing from phonemes to letters (speech to text).        proximate string matching algorithm. It produces a coarse-
  To obtain variant spellings for a given name, we place the grained representation for a string using six phonetic classes 
two noisy channel based WFST decoders in a cascade. The of human speech sounds (bilabial, labiodental, dental, alveo-
first generates an n-best list of pronunciations for a given lar, velar, and glottal). The representation consists of the 
input name. The second then produces an n-best list of spell- first letter of the word followed by three digits that together 
ings for each of the pronunciations. We then combine the n- represent the phonetic class of that word. 
best spellings generated by each of the pronunciations and   We use Soundex to divide our huge list of names into 
rank the combined output by sorting it based on (a) increas- bins of similar sounding names and then index our list on 
ing order of edit distance from the original name, (b) de- the Soundex four-character code. Now, whenever we get a 
creasing order of the weight a name variant gets from the name whose variants have to be found, we can look only at 
decoder and (c) decreasing order of the number of times a the appropriate Soundex-bin instead of the whole list, thus 
variant is generated by the different pronunciations. Ties, if making the search for variants possible in practice. 
any, are broken randomly. 
                                                      3.2.3 Implementation 
3.2  List Soundex Method                              We use the named-entity extraction system BBN Identi-
                                                      finder to identify named entities in our corpus. We then col-
In this method, we use a huge database of names combined lect all the “person” names from the tagged corpus and find 
with a phonetic sound matching algorithm called Soundex all the unique names along with their corpus frequencies. 
to find variant spellings.                            Then we run Soundex on the list of names and divide then 
3.2.1 Creating a List of Names                        into bins of similar sounding names. We obtain about 7000 
The web contains many proper names. One could search  bins, with on average 1000 names in each bin. 
and create databases of names by manually collecting vari-   To obtain the variants of a name, we first find the Soun-
ous name lists like the lists for baby names, census lists etc.  dex code for that name. Then in the corresponding Soundex-
  We have found that trying to create name lists manually bin, we find the n-best variants by sorting them based on (a) 
is not only a tedious task but also results in very sparsely increasing order of edit distance from the original name and 
populated lists. Even the best resource of names that we (b) decreasing order of frequency in the corpus. Ties, if any, 
know of, the US census name list, contains fewer than are broken randomly. 
100,000 names, and those are US names only. Apart from 
this, hand-created lists that are meticulously prepared by 4 Experiments 
experts are mostly well spelled names. We are interested in 
finding the common misspellings of names.             4.1 Experimental Setup 
  To overcome these limitations we decided to create a list 
of names automatically. Using a corpus containing about It is not immediately clear how one can evaluate a name 
10GB of English text gathered from the web in a previous spelling generator.  We therefore perform experiments to 
project [Ravichandran et al., 2005], we applied the BBN measure the performance of the different methods on the 
IdentiFinder, a state of the art named-entity extraction sys- spelling variants generation task.  
tem [Bikel et al., 1999], to it. We extracted all the entities   First, we randomly select 30 US names from a list of 
that the named-entity extractor tagged as “person names”. baby names. We run each of the systems (including the 
This gave us a list of about 7.3 million unique names. baseline) on these names and generate the top 25 variants 
                                                      for each of these names. We then ask a human to look at the 
                                                      names generated by each system and mark then as good or  
   4 http://svr-www.eng.cam.ac.uk/~prc14/toolkit.html 
   5 http://www.isi.edu/licensed-sw/carmel 


                                                IJCAI-07
                                                  1572 # of top out-     Pronunciation learning             List Soundex                    Baseline 
    puts 

              Precision Recall      F-score Precision Recall       F-score Precision Recall F-score 
     5          0.97 0.28 0.39 0.80 0.24 0.32 0.43 0.18 0.21 
     10         0.89 0.45 0.54 0.76 0.36 0.46 0.32 0.23 0.22 
     15         0.78 0.47 0.54 0.74 0.50 0.55 0.26 0.27 0.21 
     20         0.71 0.50 0.53 0.73 0.53 0.56 0.21 0.27 0.20 
     25         0.68 0.52 0.54 0.68 0.58 0.58 0.19 0.27 0.19 

                                             Table 1: Results 

bad variants. We use this human judgment as the measure 
for precision (Section 5.1). To measure recall (Section 5.1), The F-score (F) is the harmonic mean of the precision and 
                                                      recall. It is calculated as- 
we ask a human to generate possible variants for each of the 
                                                                     2* P *R 
30 names and then compare the output of each of the sys-         F =                  (5.3) 
tems with the name variant list generated by the human.               P + R
4.2 Baseline                                          5.2  Result Scores and Graphs 
The US Census list, one of the largest publicly available list Table 1 shows the comparison of precision, recall, and F-
of US names, contains about 89,000 last names and about scores of the pronunciation generation, list Soundex, and 
5,000 first names (male and female). Apart from the names baseline systems for different numbers of outputs. The out-
itself, the list provides information about the frequency of puts are varied from top 5 to top 25 and their effect on the 
each name. We use this list as the resource for building our macro-averaged precision, macro-averaged recall, and 
baseline system.                                      macro-averaged F-score is shown. 
  For each of the 30 test names, we obtain variants by find-
ing the top 25 names that are closest in levenshtein edit dis-
tance to the given name and sort them based on (a) increas- 1
ing order of edit distance, (b) decreasing order of frequency. 0.9
                                                        0.8

                                                        0.7

5. Results                                              0.6                               Pronunciation learning

                                                        0.5                               List Soundex
                                                                                          Baseline
                                                        0.4
5.1 Evaluation Metrics                                  Precision
                                                        0.3

We use the standard Natural Language Processing measures 0.2

of precision, recall, and F-score to measure the performance 0.1

of each of the systems.                                  0
                                                         5      10152025
  To obtain precision, we ask a human to look at all the            # of top outputs
outputs generated by each of the systems and mark then as 
correct or incorrect variants. Then the precision (P) for each Figure 1: Precision graph 
system can be obtained as- 
        # of correct system outputs
   P  =                              (5.1)
           # of system outputs                          0.6

  Given that we do not have a comprehensive gold standard 0.5
list of variants of a name, finding true recall is quite hard. 
But we can obtain recall of each system relative to a human. 0.4
                                                                                          Pronunciation learning

To do this, we ask a human to look at each of the 30 test 0.3                             List Soundex

names and generate a set of possible variants for each name. Recall                       Baseline
We then compare the output of each system to that of the 0.2
human generated list. Then the recall (R) for each system 
can be obtained as-                                     0.1

      # of systemoutputsin the human list               0
  R =                                   (5.2)            5      10152025
         # of outputsin the human list                              # of top outputs
                                                               Figure 2: Recall graph 


                                                IJCAI-07
                                                  1573                                                      system uses a large meticulously prepared list of names (US 
                                                      census list). We however feel now that the very fact that the 
 0.6                                                  US census list was meticulously prepared went against the 
                                                      baseline given the nature of the task, where it is as important 
 0.5                                                  to have misspellings as to have correct spellings. 

 0.4
                                    Pronunciation learning 6. Conclusion 
 0.3                                List Soundex
                                    Baseline
 F-score                                              The results here clearly show the success of using the pho-
 0.2                                                  netic models for the purpose of generating spelling variants. 
                                                      We attribute this success to the fact that spelling variants 
 0.1
                                                      more often than not have to do with the ambiguous mapping 
  0                                                   between pronunciations and their corresponding rendering 
   5      10152025
              # of top outputs                        into letter sequences (spellings). Our models derive their 
                                                      power from the very fact that different people on one hand 
        Figure 3: F-score graph                       tend to pronounce the same letter sequences differently and 
    Figures 1, 2 and 3 graph the precision, recall, and F- on the other tend to write different spellings for the same 
scores respectively of the three systems corresponding to the pronunciation. 
number of outputs of the system varying from top 5 to top   One other striking observation is the four-fold increase in 
25.                                                   the number of good name variations compared to the vari-
  We find that for the top 25 name variants, the perform- ants generated by a human. This clearly reinforces the need 
ances of the pronunciation learning and the list Soundex of a variant generator for the name query expansion task. 
methods are very close to each other. The pronunciation   Another interesting conclusion is the clear superiority of 
learning method has an F-score of 0.54 while the list soun- the automatic acquisition of large name lists compared to 
dex method has an F-score of 0.58. Both the systems show the slow manual preparation for the purpose of generating 
roughly three-fold improvement over the baseline, which variants even in the low recall ranges (top 5 outputs), as is 
has an F-score of 0.19. The result is validated by the two- demonstrated by the high performance of the list Soundex 
tailed paired Student’s t-test [Manning and Schütze, 1999]. method compared to the baseline. 
The t-test shows a statistically significant difference at   In the future, we would like to build a hybrid system that 
p<0.0005 between the baseline and both the systems. How- can combine the outputs of both the algorithms and rank the 
ever, it shows no statistically significant difference between combined output in a meaningful way. We would also like 
the performances of the pronunciation learning and list to test our algorithms with non-English names. Our initial 
Soundex systems themselves.                           experiments with non-English names look very promising 
  The graphs for the three systems show an intuitive trend. though we presently do not have a baseline to compare 
We find that as we increase the number of outputs that each against for these names. We would further like to apply our 
system generates from 5 to 25, the precision of each system algorithms to other entities, such as technical terms, that are 
goes down slowly while the recall goes up.            likely to be misspelled for the same reason as person names. 
                                                      Also, in the future we plan to modify the algorithms to tailor 
5.3 Discussion                                        the variants for the kind of mistakes that are more likely to 
It is clear from the results above that the pronunciation occur while spelling names from different languages and by 
based methods for generating name variants reap good re- native speakers of different languages owing to the different 
sults. Further it is clear that by using these methods, signifi- sounds present in those languages. 
cant improvement over the baseline can be achieved.
  What is also encouraging is the relative recall compared Acknowledgments 
to humans. We find that for the 30 test names, a human was 
able to generate on an average four variant spellings. How- The authors would like to thank Mr. Andrew Philpot for 
ever both the pronunciation generation and list soundex providing the list of baby names with their variants and Dr. 
methods generated 25 variants with a precision of 0.68, i.e., Patrick Pantel for his expert advice on evaluation.
about 17 correct variants, which is four times what a human 
could generate.  This of course goes in line with the general References 
observation that humans are good at telling a good thing [Baum, 1972] L.E. Baum. An Inequality and Associated 
from a bad but are not so good at generating a set of possi- Maximization Technique in Statistical Estimation of a 
ble good things.                                         Markov Process. Inequalities 3:1–8, 1972. 
  What is also interesting is that the precision, recall, and F-
scores of the pronunciation generation and list Soundex [Bikel et al., 1999] Daniel M. Bikel, Richard L. Schwartz 
methods are significantly better than the baseline at all the and Ralph M. Weischedel. An algorithm that learns 
output sizes. This came as a bit of a surprise initially, be- what's in a name. Machine Learning, vol. 34, no. 1-3, 
cause we expected the baseline to perform well at least  pages. 211–231, 1999. 
when the number of outputs is small, given that the baseline 


                                                IJCAI-07
                                                  1574