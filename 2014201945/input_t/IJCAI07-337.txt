        Dealing with Perception Errors in Multi-Robot System Coordination

Alessandro Farinelli   and  Daniele Nardi        Paul Scerri                    Alberto Ingenito
    Dip. di Informatica e Sistemistica,       Robotics Institute,               Dataspazio S.p.A.,
   University of Rome, “La Sapienza”,    Carnegie Mellon University,     Alberto.Ingenito@dataspazio.it
        lastname@dis.uniroma1.it             pscerri@cs.cmu.edu


                    Abstract                          action [Pynadath and Tambe, 2002]. Several approaches use
                                                      cooperative perception to deal with perception limitation of
    A prerequisite to efﬁcient behavior by a multi-robot the single robot [Rosencratz et al., 2003; Dietl et al., 2001;
    team is the ability to accurately perceive the en- Stroupe et al., 2001]. The general idea of these approaches is
    vironment. In this paper, we present an approach  to exchange sensor readings and aggregate them using differ-
    to deal with sensing uncertainty at the coordina- ent ﬁltering techniques (e.g. Kalman ﬁlters [Dietl et al., 2001;
    tion level. Speciﬁcally, robots attach information Stroupe et al., 2001] or particle ﬁlters [Rosencratz et al.,
    regarding features that caused the initiation of a 2003]).
    course of action, to any coordination message for
                                                        Coordination in Multi-Robot Systems has been success-
    that activity. Further information regarding such
                                                      fully addressed using task assignment approaches [Parker,
    features, acquired by the team, are then combined
                                                      1998; Werger and Mataric, 2000; Zlot et al., 2002]. While
    and the expected utility of the started action is
                                                      task assignment has been deeply investigated in several sce-
    re-evaluated accordingly. Experiments show that
                                                      narios and many different techniques have been proposed, lit-
    the approach allows to coordinate a large group of
                                                      tle attention has been devoted to the impact that limited and
    robots, addressing sensing uncertainty in a tractable
                                                      noisy perception capabilities have on the task allocation pro-
    way.
                                                      cess. In many applications, tasks to be allocated are created
                                                      by the robots when particular features are extracted from the
1  Introduction                                       environment. Such feature extraction process is subject to
                                                      errors, which can greatly impact the overall task assignment
Emerging, large multi-robot teams hold great promise for rev- process. Cooperative perception techniques can be used to
olutionizing the way some important, complex and danger-
                              1                   2   address this problem, however previous approaches to coop-
ous tasks, such as disaster response and space exploration erative perception often require to exchange too many data
are performed. Such teams, consist of multiple, heteroge- among robots. A key reason for this is that, typically, each
neous robots with imperfect sensors, which must act efﬁ- robot attempts to maintain an accurate model of the complete
ciently in the face of considerable uncertainty and time pres- state when, in practice, only a small part of the overall state
sure. Speciﬁcally, in many complex environments, robots might be relevant to its activities.
have systematic sensor noise that leads individual robots to
incorrect perception of the objects in the environment. This This paper presents an approach to deal with perception
paper presents an approach that leverages multi-robot coop- errors by exchanging information about observed features in
eration to overcome individual sensing limitations.   a task assignment coordination framework. This approach
  Dealing with sensing uncertainty is a key area of robot comprises two key ideas, ﬁrst, when a robot senses an event
and agent research. A variety of techniques attempt to ei- in the environment that might lead it to initiate a team ac-
ther reduce the uncertainty before deciding how to act, e.g., tivity, it immediately computes expected utility of action and
Bayesian ﬁlters [Fox et al., 1999], or explicitly deal with the inaction, given its conﬁdence in its sensors. If the expected
uncertainty when choosing a course of action, e.g., POMDPs utility of acting is greater than that of not acting, it initiates
[Theocharous et al., 2001]. Such approaches, require that the team activity. For example, if a team of robots is search-
each robot deals with its sensor noise on its own, thus fail- ing a sparsely occupied burning ofﬁce building, any sensors
ing to leverage any assistance the rest of the team might suggesting the presence of a trapped civilian should imme-
be able to supply. Other work explicitly uses input from diately trigger a team response. Over time, new information
other members of the team to allow a more accurate pic- acquired by the team can impact the conﬁdence in the occur-
ture of the environment to be created. For example, DEC- rence of the event. At any point in time, if robots’ conﬁdence
POMDPs have been used to devise a coordinated course of in the event drops sufﬁciently low, the team activity can be
                                                      suspended. The idea of the approach is to balance the need
  1see http://www.ai.sri.com/project/Centibots        for a rapid response in a time critical domain and the high
  2see http://www.cs.cmu.edu/∼ﬁre/                    costs of acting on incorrect sensor information.

                                                IJCAI-07
                                                  2091  Once a team activity has been initiated, messages are typ- When events occur, the robot team should take actions in
ically passed around the team to coordinate the activity. The response. The function Ae(t) →{0, 1} returns 1 if the team
second key idea to the proposed approach is to require that is acting in response to event e at time t and returns 0 oth-
these communication messages include the event that led to erwise. Informally, the team receives reward (α), for acting
the team activity being initiated. Such information is consid- when an event is real, and costs for either not acting when the
ered as a justiﬁcation for the team activity to be carried out. event is real (β2), or acting when it is not (β1). Formally, the
Robots receiving such messages check whether they have any problem for the team is to maximize:
information that can impact conﬁdence in the occurrence of
                                                                              tf
the event. If so, the information are communicated to the                       e
                                                                         e∈E α  s Ae(t)+
                                                                               te
robot initiating the action. This technique focuses the in-                  f
                                                                              te
                                                                     e∈E −β2   s (1 − Ae(t))+         (1)
formation gathering process on events that are important for                 te              
                                                                          ts         ∞
team activities and, thus, prevents communication about ir-                 e
                                                                 e∈E −β1       Ae(t)+   f Ae(t)
relevant aspects of the state. Notice that, in order to refute             −∞          te
justiﬁcations, robots need to maintain a history of the areas To maximize expected utility, the team should act on ei
they have observed so that they can report not seeing some- only when:
thing at a particular location. In this way, uncertainty in robot
perception is addressed at coordination level, focusing only        t              t            t
                                                             αBel(ei) − β1(1 − Bel(ei)) >β2Bel(ei).   (2)
on information which are relevant to robot mission and thus
dramatically reducing the required communication overhead. 2.1 Example
  To evaluate the effectiveness of the proposed approach,
experiments were performed both in an abstract simula-
tion environment and in a simulation framework based on
Player/Stage3. The proposed approach was shown to perform
almost as good as an approach that broadcasts every detected
features to every other robots, while using orders of mag-
nitude less communication bandwidth. Unsurprisingly, the
proposed approach did not perform as well when the envi-
ronment was very sparse, because fewer robots had helpful
information, or when the environment was very dynamic be-
cause information from other robots were soon out-of-date.

2Problem
This section formally describes the problem addressed by this
paper. Mobile robots R = {r1,...,rm}, with imperfect sen- Figure 1: Example of scenario where cooperative perception
                                         t      t
sors, act in an environment with events E = {e1,...,en}. can enhance system performance
                                               t
The events are spread spatially across the environment. ei =
true iff event i is observable at time t. The robots make ob-
          [+|−]        +                                Figure 1 shows an example of the type of situation that co-
servations Oe ,whereOe   corresponds to a positive read-
                 −                                    operative teams of robots should avoid at low cost. Unﬁlled
ing for event e and Oe corresponds to a negative reading. The hexagons show mobile robots performing search and rescue
                                  P (O+|¬e)
probability of a false positive reading is e . Notice in an ofﬁce-like environment. Dotted lines indicate the paths
that, false positive (or false negative) should be intended not the robots have taken through the environment. The ﬁlled
as direct sensor readings, but as errors in the feature extrac- hexagon is a robot that believes it sees an injured victim, in-
tion process. The proposed binary model for robot observa- dicated by the emoticon. It should consider initiating a joint
tions is therefore well suited and general enough to represent activity to rescue the victim. However, there is not actually a
such issues. Moreover, such model can consider both errors victim at that location. Since six other robots have recently
due to systematic issues with sensors, and random errors of passed that same location without sensing a victim the team
the feature extraction process.                       should be able to quickly establish that the ﬁlled hexagon
                        t                     t
  The prior probability of ei = true is written P (ei) → robot is experiencing a perception error and avoid the costs
[0, 1]. This is the probability an event occurs before robots of the joint activity.
                                         t
acquire any observation. Robot r estimate of ei = true,
                                 t
given acquired observation, is Belr(ei) → [0, 1].The
                                        t+1  t        3   Approach
world changes dynamically according to P (ei |ei) and
P (¬et+1|¬et)                        ts      t        The key idea to this approach is to use input from team mates
     i    i .Thestart time of an event ei to be such
   ¬et−1 ∧ et                         tf     t        to update conﬁdence in reasons for acting, while starting ac-
that  i     i and the end time of the event ei to be such
    t     t+1                                         tions on initial observations. The technical elements of the
that ei ∧¬ei .                                        approach are: i) attach to coordination messages assumptions
                                                      that justify a coordinated action; ii) add observations to coor-
  3see playerstage.sourceforge.net/                   dination messages when relevant; iii) revise decisions to act

                                                IJCAI-07
                                                  2092based on observations attached from teammates to coordina-
tion messages.
  When a robot detects a new event, it performs an expected
utility calculation to decide whether to act in response to that
event (see Equation 2). If it decides to start a coordinated
action, it attaches the justiﬁcation for that coordinated action
to the coordination messages. When a robot receives a
coordination message, it evaluates whether it has relevant
observations about that event. If it is the case, it will attach
to the coordination message the relevant observations and
it will send a cooperative perception message back to the
robot that initiated the action. Finally, when the robot that
instantiated a coordinated action receives a cooperative
perception message, it integrates all observations attached
to the message and re-considers the expected utility, while Figure 2: Supporting and refuting observations
continuing to perform the coordinated action. In particular, if
robot r receives a cooperative perception message at time t
                 t                             t
related to the event ei (where t <t), it will update Belr(ei) Notice that, to relate observations to detected features (or
using the observations attached to the message. With the events), the data association problem has to be solved (i.e.
            t
update Belr(ei) robot r will then re-evaluate the expected which feature is related to which observation). Data associ-
utility of continuing the activity.                   ation is a well known problem for robotic and tracking ap-
                                                      plications (see for example [Hall and Llinas, 2001]). Several
  World representation                                approaches have been used to address this problem, however,
  To support or refute observations performed by other team since our method is based on a feature-level representation,
members, robots have to store their previous observations. In and the data association issue is not the main focus of our
particular, their representation should include not only ob- work, a distance threshold is adopted. Other approaches to
served relevant features, but also in which parts of the en- address the data association problem can be used; in fact, the
vironment they did not observe any relevant features. Thus decision process we described is general with respect to the
each robot maintains three main elements: i) a Set of Interest- chosen data association method.
ing Points (IPS); ii) a representation of the Observable Space Figure 2 provides a graphical representation of supporting
(OS) iii) a set of positive observations (PO). An interesting and refuting observations, showing a robot with the current
point is a portion of space where an event was detected at a laser readings and the ﬁeld of view of the camera. The OS, in
given time step. Each entry of the (IPS) comprises: i) in- this case, is the intersection between the laser reading and the
formation characterizing the location to which the event is camera ﬁeld of view. The point labeled as none in the ﬁgure
related (e.g., x and y for a bi-dimensional representation); ii) is a point for which the robot cannot provide any information,
a numerical value (belief) representing the robot’s estimates because it can not observe that part of the environment.
that the observation is correct.                        Bayesian update of robot knowledge
  The OS is dependent on the robot’s sensors, but in general In this work, the belief update of each robot is done using
it is a representation of the portion of the environment that a Bayes ﬁlter. Speciﬁcally, a Bayes ﬁlter is instantiated for
was observed by the robot’s sensors at a given time step. The each relevant detected event in the environment (Equations 3
PO is the set of relevant features that were detected at each and 4).
                      e                   r      r
time step. Given an event i detected by a robot , robot                  
will perform the following operations to support or refute the Bel(et)=η    Pr(Oj  |et)Bel(et)
                                                                    i            et i      i         (3)
event.                                                                    j       i
                                                                       
  For each entry of the OS history:                               t           t t−1      t−1
                                                             Bel (ei)=     Pr(ei|ei )Bel(ei  )        (4)
  • If the portion of space related to ei is inside the current
                                                                       et−1
    OS and the corresponding PO set contains an observa-                i
    tion for that feature, attach the observation to the coop-        Oj
                                                        Since readings et obtained from team mates may be
    erative perception message (supporting the event detec-             i
    tion).                                            older than present time t <t, they cannot be directly in-
  •                              e                    tegrated using the ﬁlter equation, because, referring to a time
    If the portion of space related to i is inside the cur- step in the past, they should have inﬂuenced the robot’s be-
    rent OS but the current PO set does not contain any ob- lief up to the present time. When a reading referring to a
    servation for that feature, create a negative observation past time t is obtained the ﬁlter is reinitialized with a state
    and attach the observation to the cooperative perception ¯
                                                      Bel(et) where t¯ = Max{t | et ∈ IPS ∧ t<t¯ }.Ifthe
    message (refuting the event detection).                i                     i
                                                      event location is not inside the IPS a new interesting point is
  • If the portion of space related to ei is not inside the cur- added to the IPS. Observations for the locations are generated
    rent OS do nothing.                               using the PO and the OS. Maintaining the history for OS, PO

                                                IJCAI-07
                                                  2093and IPS for all the process has a cost in terms of memory that in the environment, robots need to share a common refer-
grows with time. To limit such cost, a valid time window T ence framework. To simplify the experimental setting, we
is used that goes from the current time tc back to tc − T .An do not explicitly consider localization errors. As a matter of
appropriate time window can be chosen by considering the fact, standard localization techniques [Fox et al., 1999] can
evolution model of the environment.                   be used for our experimental scenario, and localization errors
                                                      can be taken into account in the error model of the feature
4  Experiments and Results                            extraction process. Each graph reports values averaged over
                                                      10 trials of the same experiment.
To evaluate the approach, we have tested our method both in
an abstract simulation environment and in a simulation frame-
work based on Player/Stage. The former simulator has been 4.1 Abstract Simulator Results
used to test our method with a very large team of robots (100 The abstract simulator captures key features of the environ-
team members). Moreover, the behavior of our method has ment, while being sufﬁciently abstract to test a wide range
been tested under varying environmental conditions such as of parameters and conﬁgurations efﬁciently. The simulated
the world dynamism and the world size. The latter simu- robots have limited knowledge of the overall team state and
lation environment allowed us to consider important issues can communicate only with a subset of the overall team. In
such as sensor occlusion or message delay among team mem- each experiment there were 100 simulated robots, each with
bers. Overall, the ﬁrst experimental setting allows to test the the same perception model.
general behavior of the method, while the second set of exper- Figure 3 shows that Share All does perform better and the
iments provides more accurate indications on speciﬁc robotic advantage increases as the world becomes more dynamic.
issues. Two metrics were used to measure performance: the However, for less dynamic environments ShareRelInfo per-
percentage of stopped actions out of the total number of ac- forms almost as well. For this team size (100 robots) the com-
tions incorrectly instantiated (percentage found, pFound on munication gain of ShareRelInfo is approximately two orders
graphs) and the percentage of correctly stopped actions out of magnitude.
of all the actions that were stopped (percentage good, pGood
on graphs). In both cases, higher is better. Notice that, the
                                                                  120
                                                                                 pGood Share All
percentage good measure is related to the correctness of the                    pFound Share All
approach while the percentage found measure is related to         110          pGood ShareRelInfo
                                                                              pFound ShareRelInfo
the completeness. These metrics are the key values under-         100
lying Equation 1 and hence, with knowledge of the relative
costs of action and inaction, allow for the computation of the    90
team performance. In the experiments presented below, each


                                                               pGood/pFound  80
robot initiates a coordinated action according to Equation 2.
  The communication overhead is evaluated using two mea-          70
sures: i) number of messages exchanged at each time step by       60
each robot; ii) size of the messages (in bytes) exchanged at        0  0.002  0.004  0.006  0.008  0.01  0.012  0.014
                                                                            World Change Rate
each time step by each robot. We assume that the overhead of
a broadcast message is higher than the overhead of a point to
point message. In particular, we count a broadcast message as Figure 3: Comparison between Share All and ShareRelInfo,
point to point message times the number of robots. While for varying world dynamics
a more precise analysis of the overhead one should consider
the speciﬁc network used, this provides a general cost model Figure 4 shows performance as the size of the environment
for communication which is suitable for our level of analysis. is varied, while keeping the number of robots and the sen-
  In our experiments we used a task assignment algorithm sor range constant. The performance decreases as the robot
based on token passing [Scerri et al., 2005]. Tokens,repre- density becomes lower. This is because, when the density
senting tasks to be accomplished, get propagated through the of robots decreases there will be less opportunity for mutual
team until a robot accepts the task. The algorithm has been observations of same features, therefore less information for
chosen, because it requires a very low communication over- supporting or refuting observations can be provided.
head and is thus well suited for our interest domain.
  The proposed approach (referred as ShareRelInfo4 in the 4.2 Player/Stage results
following) was compared to a benchmark strategy, called
Share All, where each robot shares all its observations with In the Player/Stage experimental framework each robot is
all other robots at each time step. Clearly, this type of ap- equipped with a laser range ﬁnder and a color camera. Robot
proach is infeasible for large teams, but it provides an upper controllers are run as distributed processes over a network of
bound on the performance that can be achieved by the coop- PCs and messages are exchanged using the UDP protocol. In
erative perception process.                           this conﬁguration, we can validate the coordination method
  Experiments have been performed in a 2D ofﬁce-like en- with possible message loss and delay. Objects of various col-
vironment. To exchange information about features present ors are distributed over the map. The goal of the team is to
                                                      detect objects and locate them in the map (Figure 5 represents
  4Because it shares only information relevant to the tasks. the reference experimental scenario).

                                                IJCAI-07
                                                  2094           120                                                    120
                           pGood Share All                                       pGood ShareAll
                          pFound Share All                                      pFound ShareAll
           110          pGood ShareRelInfo                        110         pGood ShareRelInfo
                        pFound ShareRelInfo                                   pFound ShareRelInfo
           100                                                    100

            90                                                    90


         pGood/pFound  80                                         80


            70                                                 Perc.  Good / Found  70

            60                                                    60
              10  20   30  40   50  60   70                          Sit. 1     Sit. 2      Sit. 3
                        World Size                                             Situations

Figure 4: Comparison among Share All and ShareRelInfo, Figure 6: Performance comparison among Share All and
varying world size                                    ShareRelInfo in the tree different conﬁgurations

                                                      reached a robot, the chances to stop an invalid action remain
                                                      almost constant.
                                                        ShareRelInfo achieves results which are very close to the
                                                      Share All strategy. As for completeness, the proposed method
                                                      attains lower values and is more sensitive to the differences
                                                      among conﬁgurations. This is due to the smaller amount of
                                                      information that this method uses. In fact, when fewer obser-
                                                      vations are shared among robots, there is a lower chance that
                                                      coordination messages reach robots that can provide relevant
                                                      information to refute or support coordinated actions. How-
                                                      ever, the performance decrease is minimal while the gain in
                                                      communication is very high (see below).
                                                        As for correctness, ShareRelInfo attains slightly better re-
                                                      sults than the Share All strategy. This can be explained by
                                                      considering how actions are created and stopped in the two
       Figure 5: Reference experimental scenario      policies. In the ShareRelInfo a coordinated action can be
                                                      stopped only when a message containing observations of a
                                                      subset of the teammates is received and the computation of
  The approach was tested in three different conﬁgurations, Equation 2 indicates that the action should be stopped. In the
where the object and robot positions are different. Specif- Share All strategy the policy to stop actions is different: each
ically, the ﬁrst conﬁguration comprises one group of eight robot monitors, at each time step, the belief associated with
robots which observe the same group of objects. In this con- features that originated corresponding actions, and actions are
ﬁguration the number of shared observations is very high. stopped according to Equation 2. In this way, if at some time
However, due to occlusions in the visual ﬁeld the observa- step a subset of the robots experiences an error in the percep-
tions for each robot are not exactly the same. The second tion process for the same feature, the corresponding action
conﬁguration includes two groups of robots. The ﬁrst one is will be stopped immediately. Since the proposed approach
composed of eight robots which observe the same group of integrates measures over time before stopping a coordinated
objects, the second group is composed of two robots which action, it is less sensitive to this problem.
observe a group of other two objects. In this conﬁguration Figure 7 and 8 show that the proposed approach not only
the two groups of robots do not share any observations. Fi- requires a lower number of messages, but ensures also a
nally, the third conﬁguration (shown in Figure 5) shows three smaller communication overhead in terms of message size.
groups of robots, in this case the number of shared observa- Since the communication overhead does not change signif-
tions among groups is very limited.                   icantly across the different conﬁgurations, we report results
  Figure 6 reports results obtained for the two methods in the referred to one particular conﬁguration (conﬁguration 2).
three described conﬁgurations. Figure 6 shows that the lower The graphs show the number of messages and communi-
number of shared observation has a negative impact for both cation load for different world change rate. For this team size
strategies and both measures. The completeness (pFound in (10 robots) the communication gain is approximatively one
graph) is more disadvantaged by the lower availability of order of magnitude. When the world change rate is lower,
shared observations than the correctness (pGood in graph). less coordinated actions will be instantiated. In such a situa-
This can be explained by considering that, when there are tion, ShareRelInfo requires a lower communication overhead,
fewer shared observations, there will be a lower chance that while the communication overhead for the Share All strategy
a robot will obtain enough information to stop an invalid ac- remains almost constant.
tion. On the other hand, once the relevant information has Notice that, having a smaller communication overhead can

                                                IJCAI-07
                                                  2095