        Expectation Failure as a Basis for Agent-Based Model Diagnosis and
       Mixed Initiative Model Adaptation during Anomalous Plan Execution*

                Alice Mulvehill, Brett Benyo, Michael Cox, and Renu Bostwick 
                                      BBN Technologies 
                          Intelligent Distributed Computing Department 
                           10 Moulton Street, Cambridge, MA 02138 
               amm@bbn.com, bbenyo@bbn.com, mcox@bbn.com, renu@bbn.com 

                  Abstract                      proves with experience. The research presented here shows 
                                                how small discrepancies between what is expected in a plan 
   Plans provide an explicit expectation of future ob- and what actually happens during plan execution can deter-
   served behavior based upon the domain knowledge mine an effective refinement to the models upon which 
   and a set of action models available to a planner. 
                                                plans are based and hence improve plan performance.  
   Incorrect or missing models lead to faulty plans Plans themselves provide an expectation about what 
   usually characterized by catastrophic goal failure. should happen when the plans execute. An expectation fail-
   Non-critical anomalies occur, however, when ac-
                                                ure occurs when the expected performance diverges from 
   tual behavior during plan execution differs only what the models of the domain predict, and such failure 
   slightly from expectations, and plans still achieve provides the basis for learning [Birnbaum et al., 1990; Ram 
   the given goal conjunct. Such anomalies provide 
                                                et al., 1995]. Diagnosis is a symptom to fault mapping that 
   the basis for model adjustments that represent links the expectation failures detected during execution to 
   small adaptations to the planner’s background the model changes necessary to prevent such failures from 
   knowledge. In a multi-agent environment where 
                                                recurring in the future. However this blame assignment 
   1000 or more individual plans can be executing at problem is nontrivial, because many factors can contribute 
   any one time, automation is required to support to a single error, multiple errors can co-occur, and the diag-
   model anomaly detection, evaluation and revision. 
                                                nostic mapping between symptom and fault can be very 
   We provide an agent-based algorithm that gener- indirect. Indeed catastrophic plan failure may result from so 
   ates hypotheses about the cause of plan anomalies. many factors that diagnosis is not practical. But plans can 
   This algorithm leverages historical plan data and a 
                                                also fail in nondisruptive ways that result in suboptimal per-
   hierarchy of models in a novel integration of hy- formance while still achieving the goal set. It is this type of 
   pothesis generation and verification. Because many expectation failure we term an anomaly.
   hypotheses can be generated by the software 
                                                 The dynamic and continuous nature of our planning do-
   agents, we provide a mechanism where only the main and the complexity of the models of this domain has 
   most important hypotheses are presented to a user led us to develop an agent-based model diagnosis tool that 
   as suggestions for model repair. 
                                                handles multiple types of plan anomalies (e.g., consumable, 
                                                spatial, and temporal). The agents use a model hierarchy 
1 Introduction                                  with spreading-activation likelihood functions to control 
Planning in most domains requires a description of relevant hypotheses generation. The agents reference historical plan 
entities and processes. These are typically described by a set data to recognize past anomaly patterns. When an anomaly 
of models. Feedback collected during or after plan execution has occurred in the past and all planned activities have com-
can be used to refine models so that the planner perform- pleted, the agents decrease the likelihood that a model repair 
ance becomes more adaptable to the environment and im- is required. In addition, the agents use a temporal link 
                                                analysis to localize failure symptoms within model proc-
                                                           
  *                                             esses. The diagnosis system includes a mixed-initiative 
    This research is sponsored by the United States’ Defense Ad- component that provides model error and repair suggestions 
vanced Research Projects Agency (DARPA) under contract (resulting from the most likely hypotheses) to a user who 
FA8750-04-C-0002. The views and conclusions contained herein can accept, ignore, or reject them. Others have examined 
are those of the authors and should not be interpreted as necessar- agent-based [e.g., Roos and Witteveen, 2005] and model-
ily representing the official policies or endorsements, either ex- based [e.g., Williams and Nayak, 1999] diagnosis for plan-
pressed or implied, of the sponsoring institutions, the U. S. Gov- ning as well as mixed-initiative approaches [e.g., Mulvehill 
ernment or any other entity. 


                                           IJCAI-07
                                             489 and Cox, 1999]. Here we present a novel combination of the During takeoff and climb (the first two points), the values 
 three.                                          are equal, but as the mission continues the values begin to 
  In this paper, we describe our technical problem and pro- diverge at successive navigation points. The difference be-
 vide detail on our approach. We also provide the results of a tween planned (square) values and simulated (triangle) val-
 study that compares a hand-coded approach (as described in ues at point three, however, is not great enough to generate 
 this paper) with our agent-based approach.      an anomaly by the monitor. At point four and all subsequent 
                                                 locations the difference exceeds a threshold, and the monitor 
 2  Model-Based Mission Planning and Execu-      sends anomaly messages to the model adaptor component. 
                                                 Yet during the midpoints of the mission and at the very end, 
    tion Monitoring                              the difference between actual and expected fuel levels re-
 Our planning domain is focused on military air operations mains constant, thus indicating that no problem exists in 
 and our tool suite for this domain includes a generative those segments of the mission, despite anomaly messages 
 planner, a plan monitor and a model adaptor component. from the monitor. In actuality, the fuel level discrepancy 
 The planner creates a hierarchical task network that allo- was introduced by problems in previous mission segments. 
 cates resources for specific tasks that achieve a set of input 
 objectives. The monitor tracks the behavior of a simulator 3  Agent-Based Diagnosis and Adaptation 
 that executes the activities in the plan. The model adaptor 
provides and refines models to account for changes in the The problem for the model adaptation component is to map 
world state and to improve plan performance.     failure symptoms from the monitor such as fuel consumable 
  The domain is defined by two sets of hierarchical models. anomalies to causal faults such as incorrect model parame-
The entity models describe objects in the domain, and the ters like high fuel burn rates on navigate activities for A-
process models define the actions that entities perform. Enti- 10s. The reported anomalies can be simple or severe and can 
ties include hundreds of configurations of munitions and be caused by many sources, including the models. As 
fuel tanks that may be loaded on an aircraft for specific mis- anomalies are detected, they are classified and provided to 
sions. Processes encode the different mission variations for the model adaptor component. Here users, who are familiar 
which the aircraft may be deployed, e.g., the sequence of with the models, use the model adaptor software to deter-
 activities the aircraft perform varies depending on the mis- mine if a model is responsible for an anomaly, and if so, 
 sion being performed and the aircraft’s configuration load at repair and republish it to the other planning components. 
 the time. In addition the entity hierarchy defines specific Because this particular planning application has the poten-
 types of aircraft using default parameters valid for whole tial to scale to over 1000 concurrently executing missions, 
 families of aircraft types when applicable and uses specific an agent-based diagnosis system was developed to support 
 overridden individual parameters when necessary. Finding anomaly management, interpretation and model repair sug-
 and fixing model problems in such a large and complex gestion generation.  
 model is difficult. 

  As an example, consider a plan servicing 300 objectives,                       Query:
                                                           Diagnosis Manager     Similar
                                                                                     Historical Plans
                                                                                Executed
 ranging from targets that need to be destroyed to surveil-                           Case Base
                                                            Past                 Plans
 lance tracks that must be flown. During execution of this  Diagnoses
                                                      Diagnosis                        Store: Plan History
                                                                   Generate
 plan, the plan monitor can detect hundreds of anomalies. Case Base      Diagnosis 
                                                                  Hypotheses          Monitor 
                                                                          Data  Input:
 Figure 1 shows a data set of expected and actual fuel values Test & Select (symptoms) Anomalies Executing Plans
                                                     Diagnosis Hypothesis
 during various activities of a close air support mission flown Results
                                                                                      Generate
 by A-10 aircraft.                                    Chosen       Potential          Plans
                                                      Hypothesis    Faults
                                                                                       Publish:  Models
                                                       (fault)                  Query:
                                                                                 Check
                     Actual Expected                                            Existing Models
                                                                                Models Case Base
                                                          Provide: 
                                                        Suggestions 
     8000                                                 for Model 
                                                          Revision     Model Adaptation
                                                                                       Propagate: 
     6000                                                           Reject or Ignore   Model 
                                                                     Suggestion        Changes
     4000                                               Retain: 
                                                       Decisions              Revise
     2000                                                        User Accept  Models
                                                                      Suggestion

      0
       0    1000  2000  3000  4000 5000  6000    Figure 2. Agent-based diagnosis and mixed-initiative model adap-
    Fuel  Level(lbs) 
     -2000                                       tation processes 

     -4000

     -6000                                       The diagnosis system is composed of a set of agents. Each 

     -8000                                       agent is a java class and is associated with a hypothesis 
                      Duration (min)             about a model failure.  The Diagnosis Manager (detailed in 
 Figure 1. Data set 1                            Figure 2) is the component responsible for hypothesis gen-
                                                 eration, along with the creation and execution management 


                                            IJCAI-07
                                              490of these agents. Each agent executes a set of tasks, gathering parameter or a specific constraint of a process model. Sec-
and performing computations on data from past and current ond, the Diagnosis Manager can specify an interaction be-
runs in order to determine whether its hypothesis is likely or tween models, such as an error for the A-10 model on a 
not. When an agent attains a high degree of confidence in its navigate activity flying a CAS mission.  
hypothesis, it will further generalize or refine the hypothesis Parameter refinement is accomplished by data mining the 
in a mixed-initiative process with the user. Figure 2 shows model case base to generate a list of parameters that have 
both the agent-based manager and the mixed-initiative com- adaptable values associated with the model in question. For 
ponent. Specialized agents combine and evaluate hypotheses each such parameter we reference a predefined knowledge 
derived from single agents. These specialized agents output base to determine if that parameter can cause the anomalies 
model revision suggestions, if warranted.       the agent has seen. If so, a new diagnosis agent with a re-
                                                fined hypothesis is generated. The new agents compare the 
3.1 Hypothesis Generation                       current anomalies with historical data and with expected 
Currently the Diagnosis Manager uses four methods to gen- data for each such parameter type. These newly specified 
erate new hypotheses and associated agents. First, a set of hypotheses are then further refined by looking for interac-
general hypotheses that should always be investigated is tions between models. For this domain, parameters can have 
provided at initialization time. Examples of such general different values for sets of aircraft, activities, and missions.  
hypotheses are that the planner is using an old model ver- For example, consider consumable fuel anomalies for an 
sion, or that there is a non-model related error, such as a A-10 aircraft. When the “A-10 Aircraft model error” agent 
faulty sensor or a bug in the world simulator. The second reaches a high likelihood, the hypothesis is refined. An ex-
type of hypothesis generation is initiated by the arrival of a amination of the A-10 model data reveals a list of adaptable 
plan anomaly message. The Diagnosis Manager analyzes parameters, and the causal model narrows this list to the 
the anomaly within the context of the plan activity in which maxFuel parameter, and the fuelBurnRate parameter. For 
the anomaly occurred and within the context of a network of fuelBurnRate, there are multiple values in the models based 
related activities and entities; it generates a list of the model on the aircraft, activity, and mission. Thus, we can further 
classes and parameters that were used to model the activity. refine these hypotheses for the A-10 Aircraft by tracking the 
Each of these classes and parameters within the model is highest likelihood activity and mission. In our example, the 
suspected as a potential source for the error, and an appro- consumable anomalies occur on Navigate activities for any 
priate hypothesis is generated. Consider one example plan mission type, so the Navigate model error agent has a high 
anomaly referencing an altitude discrepancy on a navigate likelihood, whereas no mission model error agent is very 
activity for an A-10 flight group. Related models involved high. Therefore, we refine the hypothesis to suspect an “Er-
in the generation of this planned activity include the A-10 ror with fuelBurnRate on A-10 aircraft performing Navigate 
entity model,  the navigate activity model, the CAS (close activities on any mission type.” Similar refined hypotheses 
air support) mission process model,  a set of entity models for the other parameter choices are also generated.  
for objects carried on the A-10 (missiles, bombs, and fuel We call the refined hypotheses with the highest likelihood 
tanks), and a set of geometric object models defining the a suggestion, because they can be presented to the user to 
space through which the aircraft flies. For each of these support model repair. The operator can accept, reject, or 
models, a hypothesis that there is an error in that model is ignore a suggestion and in doing so, provides feedback to 
generated by the Diagnosis Manager.             the suggestion agent. At this time, the feedback is in the 
 The third type of hypothesis generation is triggered when form of a selection from a list of pre-defined options. Ex-
the planner is unable to satisfy a particular goal. This prob- amples are: “suggestion is too general/specific”, “suggestion 
lem can point to an inconsistency between the capabilities makes no sense”, and “source of error is not in the models.” 
modeled for the actor entity, the process models used by the 
planner to support reasoning, and a potential change in the 3.3 Likelihood Calculation 
world state.   In this case, model error hypotheses will be When a new hypothesis and associated agent are generated, 
generated for each available actor model and any related the agent is loaded with a predefined set of tasks. The goal 
models referenced in the unsatisfied goal. The fourth type of of a task is to calculate the belief that the agent’s hypothesis 
hypothesis generation is hypothesis generalization and re- is true, false, or uncertain by performing a certain calcula-
finement. Specifically, when an agent’s belief that its hy- tion or examining a specific data source. We are experi-
pothesis is true (called the agent’s likelihood) reaches a cer- menting with various forms of evidence combination to 
tain value, rules can fire that generate more general hy- merge the belief calculations from various tasks into one 
potheses by traversing up the model hierarchy.  single value for the agent, including an application of the 
                                                Dempster-Schafer evidence combination theory [Dempster, 
3.2 Hypothesis Refinement                       1968; Shafer, 1976] and an operator modifiable set of likeli-
In addition to generalizing hypotheses by utilizing the hood functions.  
model hierarchy, agents can generate new hypotheses by Examples of tasks executed by most agents include: (1) 
refining their current hypothesis. This refinement can take querying the model case base to determine what model 
two forms. First, the Diagnosis Manager can specify what changes have been made in the past, (2) querying the his-
part of the model might be in error, either giving a specific torical plan case base to determine if similar anomalies ad-


                                           IJCAI-07
                                             491versely affected previously executed missions, (3) examin- hood, because the anomalies additionally occur on many 
ing currently executing missions and activities to see if other types of activities, such as Climb, Descend, and Orbit. 
activities involving this model are completing without error, However, examining the temporal link structure of the proc-
and (4) performing a statistical analysis of the current ess model (task 5) shows that the gap between expected and 
anomalies with the involved models. Agents with hypothe- actual fuel values increases mostly on the Navigate legs. 
ses about activity models can execute an additional task (5) Because both the “A-10 fuelBurnRate error” and “Navigate 
that examines the temporal successor links in the plan to error” agents now have a high likelihood, a refined hypothe-
determine if anomalies can be blamed on the previous activ- sis from combining the two will be generated.  
ity in the mission. Refined hypothesis suggestion agents can As a result of the agent processing, the user is finally pre-
execute a task (6) that compares the set of current anomalies sented with a set of suggestions. The highest confidence 
and their actual data values with a theoretical set of anomaly suggestion, from the highest likelihood agent is to check the 
data that we would expect to receive if the model error in value for fuelBurnRate for A-10 aircraft on Navigate activi-
question were present. This theoretical anomaly data can ties for all mission types. Less likely suggestions presented 
come from information about previous model errors or from to the user include “Check the fuelBurnRate parameter for 
a human-defined knowledge base.                 A-10 aircraft for all FlightActivities”, and “Check the max-
 For example, for a fuel burn rate error, the expected re- Fuel parameter for A-10 aircraft.”  
sults (defined in the knowledge base and case base of past 
fuel burn rate errors) are a decreasing slope for actual values 4 Evaluation 
as the mission progresses, with an increasing value for the 
delta between actual and expected values. If the fuel burn As discussed earlier, anomalies occur in the form of expec-
rate is in error, we expect the difference between actual and tation failures when the expected value of some parameter 
expected fuel levels to get progressively worse as the mis- as specified in a plan differs from an actual value as deter-
sion executes. Alternatively, if the maximum fuel level is in mined during monitoring of plan execution. Because most 
error, we expect the difference between expected and actual of our data is proprietary, we created an artificial data set 
fuel levels to remain constant,” and we expect the actual that is representative of the real data for use in this paper. As 
fuel level value to decrease.                   shown by Figures 1, 3 and 4, we created three data sets for 
                                                aircraft fuel levels with which to evaluate the effectiveness 
                                                of our approach. Data set 1 (Figure 1) represents a typical 
3.4 Example Scenario                            case where a mismatch occurs, because the fuel burn rate in 
For example, consider an A-10 model error agent. Assume the model for the A-10 aircraft is mistakenly set too high. 
that a case base query (task 2) reveals a handful of success- Thus the plan predicts the fuel at increasingly lower levels 
ful A-10 missions using an older version of the A-10 aircraft than what actually occurs. Data set 2 (Figure 3) represents 
model. This discovery would result in a small belief value the case where false anomalies are reported by the plan 
that the current A-10 model might be in error and a large monitor. In this case, a faulty sensor reports all fuel values 
belief that we are uncertain. The supporting evidence is that to be zero. Data set 3 (Figure 4) reflects the case where a 
previous successful missions were found and the A-10 fuel leak causes an A-10 to crash. In the latter two sets the 
model was recently updated. Next, assume that of the mis- generated plan is correct, but in the first it is not. Note also 
sions in the currently executing plan, the ones without A-10 that superficially the third set is similar to a combination of 
aircraft are experiencing few anomalies (task 3) and most of features from the other two.  
the ones with A-10 aircraft are generating fuel value anoma- The results from our study compare a naïve method 
lies (task 4). Both of these tasks would result in a significant whereby a simple set of hand-coded rules is compared to the 
belief value that the A-10 model has an error. Combining diagnosis process described earlier. The rules can be sum-
these beliefs using the Dempster rule of combination marized as follows: 
[Dempster, 1968] would result in a high likelihood for this  
A-10 agent.                                     If Expected(current-activity)  
 Refining this hypothesis gives rise to two new agents hy-  < Actual(current-activity) then  
pothesizing that either the maxFuel parameter or the fuel- Is-Faulty  parameter(current-activity) 
BurnRate parameter of the A-10 is in error. Examination of  
the anomaly value data (task 6) shows that the delta between If Was-Faulty = parameter(last-activity) 
the expected and actual fuel values continued to grow as the  and ThisDelta = LastDelta then 
mission progressed. Historical case base data shows that this Is-Faulty  null 
is consistent with previous fuelBurnRate parameter errors;  
however the knowledge base data for maxFuel errors show Where  
that this delta between expected and actual fuel values ThisDelta = Actual(current-activity) 
should stay constant. Thus the “A-10 fuelBurnRate error”            -Expected(current-activity) 
agent ends up with a higher likelihood than the “A-10 max- LastDelta = Actual(last-activity) 
Fuel error” agent.                                         -Expected(last-activity) 
 Next, consider the Navigate model error agent. Similar 
tasks (tasks 2, 3, and 4) would result in a moderate likeli-


                                           IJCAI-07
                                             492 4.1 Data Set 1                                  pothesis agents, the “faulty sensor or simulator bug” agent, 
                                                 is inversely proportional to the maximum likelihood of the 
 The results between the naïve method and the agent-based 
 diagnosis method are comparable on the first data set of other suggestion agents. Because no other agent has a high 
 eleven anomalies. With both techniques, the fault is identi- likelihood, the suggestion that there is a faulty sensor or a 
                                                 simulator error is presented to the user. 
 fied as a fuel burn rate parameter for the navigate activity on 
 the A-10 model. The crucial aspect of the anomaly pattern is 4.3 Data Set 3 
 that the difference between expected and actual values 
 changes for those activities related more directly to the fault. The third data set cannot be easily analyzed by the agents 
 The delta remains the same for an activity that is not faulty. alone, nor can the rules diagnose the fault. Indeed the fault 
 This distinction is evident within Figure 1 from the relative is outside the system and a proper diagnosis relies upon in-
 slopes of various segments of the two curves. When the sight provided by a user. In this case, not only does the ex-
 slopes are the same and the curves parallel, the differences pectation failure progressively increase, but at a certain 
 between expected and actual do not change, and any anom- point in the input stream, the fuel ends at zero. At this point 
 aly can be considered a false positive. The slopes are differ- a series of spatial anomalies enter the input stream.  
 ent in the two segments that correspond to navigation activi- The expectation in the plan specified that the altitude 
ties (points 3-6 and 9-12). That is, the plan predicts a steeper would be a given height, but instead the altitude is zero. 
decline in fuel than actually occurs.            Using the simple rules results in spatial anomalies being 
  The temporal link analysis discussed earlier (task 5 in most suspect, but with our system, although the agents are 
Section 3.3) forms the basis to determine the slopes and able to focus correctly upon the fuel anomalies as opposed 
hence identify the correct activity that represents the diag- to the spatial anomalies, the complete diagnosis depends 
nosed fault given the anomaly symptoms.          upon the human ignoring the spatial anomaly suggestions 
                                                 from the suggestion manager. This is done using the feed-
 4.2 Data Set 2                                  back received through the mixed-initiative adaptation proc-
 Not all anomalies detected by the plan monitor will follow ess described in Figure 2. 
 the pattern of data set 1. Data set 2 represents the case of 

 false symptoms (in this example, where the plan simulator             Expected Actual
 or fuel sensor is bad) and hence provides incorrect data for 
 comparison to the expected values (which are good). This 8000

 data set cannot be handled correctly by the naïve rules, be- 6000
 cause for each anomaly input into the system, an expecta-
 tion failure exists and the deltas progressively vary.  4000
                                                    2000

                                                      0
                     Expected Actual
                                                       0    1000   2000  3000   4000  5000  6000
                                                   Fuel  Level  (lbs)
                                                    -2000
     8000

                                                    -4000
     6000

                                                    -6000
     4000

                                                    -8000
     2000
                                                                       Duration (min)

      0
       0    1000  2000  3000  4000  5000 6000    Figure 4. Data set 3 
   Fuel  Level  (lbs)
    -2000

    -4000

    -6000                                        5 Conclusion 

    -8000                                        Our evaluation results indicate that while our agent-based 
                      Duration (min)             approach is superior to the simple hand-generated method 
 Figure 3. Data set 2                            we presented, our approach is unable to handle all classes of 
                                                 faulty anomaly reporting unless there is a human in the loop. 
                                                 However, even with the mixed-initiative approach, we still 
  What is needed is recognition that zero fuel values repre- are faced with the problem of focus. In other words, a user 
 sent unrealistic data and thus the input is faulty. Our diagno- might reject or ignore a suggestion because there is a more 
 sis system can check for such conditions using a knowl- important problem being reported by the anomalies or be-
 edge-based sanity check (task 6 in Section 3.3). Data Set 2 cause visual cues from other tools show a particular state 
 has a constant actual fuel level, and a decreasing value for that is inconsistent with anomaly reporting. For instance, in 
 the delta between actual and expected fuel values. Because the example where the aircraft runs out of fuel and crashes, 
 this does not match the expected results for fuel burn rate or if the reported anomalies do not result in timely adjustment 
 maximum fuel level errors, neither hypothesis ends up with of the activities to include an aerial refuel, then the plan will 
 a high likelihood. The likelihood of one of the default hy- fail. The crash will be indicated in a spatial anomaly with a 


                                            IJCAI-07
                                              493