        Approximating       Pseudo-Boolean       Functions    on  Non-Uniform       Domains∗

                        R. F. Lax1, Guoli Ding1,  Peter P. Chen2,  and  J. Chen2
                      1 Department  of Mathematics, LSU,  Baton  Rouge,  LA  70803
          2 Department  of Computer  Science, 298  Coates Hall, LSU,  Baton Rouge,  LA  70803
         lax@math.lsu.edu,  ding@math.lsu.edu,   chen@bit.csc.lsu.edu, jianhua@bit.csc.lsu.edu,


                    Abstract                          where N =   1, . . . , n and the aT are real numbers. By the
                                                      degree of a pseudo-Boolean{ } function, we mean the degree of
    In Machine Learning (ML) and Evolutionary Com-    its multilinear polynomial representation.
    putation (EC), it is often beneﬁcial to approximate
                                                        Several authors have considered the problem of ﬁnding the
    a complicated function by a simpler one, such as
                                                      best pseudo-Boolean function of degree approximating a
    a linear or quadratic function, for computational                                     k
                                                      given pseudo-Boolean function , where≤“best” means a least
    efﬁciency or feasibility reasons (cf. [Jin, 2005]).                         f
                                                      squares criterion. Hammer and Holzman [Hammer and Holz-
    A complicated function (the target function in ML
                                                      man, 1992] derived a system of equations for ﬁnding such a
    or the ﬁtness function in EC) may require an ex-
                                                      best degree    approximation, and gave explicit solutions
    ponential amount of computation to learn/evaluate,             k
                                                      when      ≤  and       . They proved that such an ap-
    and thus approximations by simpler functions are       k  =  1    k  =  2
                                                      proximation is characterized as the unique function of degree
    needed. We consider the problem of approximat-
                                                          that agrees with in all average -th order derivatives
    ing pseudo-Boolean functions by simpler (e.g., lin- k               f             m
                                                      ≤for             , in analogy with the Taylor polynomials
    ear) functions when the instance space is associ-    m  = 0, 1, . . . , k
                                                      from calculus. Grabisch, Marichal, and Roubens [Grabisch et
    ated with a probability distribution. We consider
                                                      al., 2000] solve the system of equations derived by Hammer
     0, 1 n as a sample space with a (possibly non-
                                                      and Holzman, and give explicit formulas for the coefﬁcients
    {uniform)} probability measure on it, thus making
                                                      of the best degree function. Zhang and Rowe [Zhang and
    pseudo-Boolean functions into random variables.                    k
                                                      Rowe, 2004] use linear≤ algebra to ﬁnd the best approximation
    This is also in the spirit of the PAC learning frame-
                                                      that lies in a linear subspace of the space of pseudo-Boolean
    work of Valiant [Valiant, 1984] where the instance
                                                      functions; for example, these methods can be used to ﬁnd the
    space has a probability distribution on it. The best
                                                      best approximation of degree k.
    approximation to a target function f is then deﬁned                        ≤
    as the function g (from all possible approximating  Here, instead of simply viewing the domain of a pseudo-
    functions of the simpler form) that minimizes the Boolean function as the set 0, 1 n, we consider 0, 1 n as
                                                                              {   }             {   }
    expected distance to f. In an example, we use     a discrete sample space and introduce a probability measure
    methods from linear algebra to ﬁnd, in this more  on this space. Thus, a pseudo-Boolean function will be a ran-
    general setting, the best approximation to a given dom variable on this sample space. (Viewing 0, 1 simply as
                                                                                           {   }
    pseudo-Boolean function by a linear function.     a set corresponds to viewing all of its points as equally likely
                                                      outcomes.) Given a pseudo-Boolean random variable f, we
                                                      then use methods from linear algebra to ﬁnd the best approx-
1  Introduction                                       imation to f that lies in a linear subspace, taking into account
                                                      the weighting of the elements of 0, 1 n. Such a best approx-
A pseudo-Boolean function of variables is a function from
                          n                           imation will then be close to f at{ the}“most likely” n-tuples,
 0, 1 n to the real numbers. Such functions are used in 0-1
                                                      and may not be so close to f at the “least likely” n-tuples.
optimization{ } problems, cooperative game theory, multicrite-
ria decision making, and as ﬁtness functions. It is not hard to
see that such a function f(x1, . . . , xn) has a unique expres-
sion as a multilinear polynomial                      2   Best Approximation    on a Non-Uniform
                                                          Domain

             1
          f(x , . . . , xn) = aT    xi  ,                                                n
                         T ⊆N "  i∈T  #               We  will identify the integers 0, 1, . . . , 2 1 with the el-
                         X       Y                    ements in Bn  via binary representation.− Let p(i), i =
                                                               n                                n
  ∗Research partially supported by NSF grant ITR-0326387 and 0, 1, . . . , 2 1, be a probability measure on B . Let
AFOSR grants F49620-03-1-0238,F49620-03-1-0239, and F49620- denote the space− of all pseudo-Boolean functions in n vari-F
03-1-0241                                             ables. Then has the structure of a real vector space. Deﬁne
                                                                Fan inner product , p on  by                           in agreement with Example 4.1 of [Zhang and Rowe, 2004].
              h   i    F
                      2n−1                            Here,  f   g p   2.88.
                                                        Nowk we−takke a≈different probability measure on B3. Sup-
              f, g p =    f(i)g(i)p(i).
             h   i                                    posing that a “1” is twice as likely as a “0” we deﬁne a proba-
                      i=0
                      X                               bility measure p˜on B3 by p˜(0) = 1/27, p˜(1) = 2/27, p˜(2) =
We note that f, g p is the expected value of the random vari-
           h   i                                      2/27, p˜(3) = 4/27, p˜(4) = 2/27, p˜(5) = 4/27, p˜(6) =
able fg. Put f p=    f, f p.                          4/27, p˜(7) = 8/27. An orthonormal basis for with respect
          k   k     h   i                                                                    L
  Now let  be a vector subspace of of dimension m. For to the inner product , p˜ is then
example, Lmight be pthe space of allFpseudo-Boolean func-              h   i
        L                                                            3x1  2       3x2  2       3x3  2
tions of degree at most k, for some ﬁxed k. We recall how to u˜1 = 1, u˜2 = − , u˜3 = −  , u˜4 =  −   .
use an orthonormal basis of to ﬁnd the best approximation              √2           √2           √2
to a given element of (cf. L[Hoffman and Kunze, 1971]).
                  F                                   Then  the  best linear approximation to  f  is now
  Let v1, . . . , vm be a basis for . We can ﬁnd an orthonor-         4
                           L                          g˜(x1, x2, x3) = j=1 f, u˜j p˜u˜j =
mal basis u1, . . . , um for by applying the Gram-Schmidt                h    i
                      L
algorithm. This orthonormal basis satisﬁes the property         368P     91√2      46√2      85√2
 u , u  =  δ  for r, s = 1, . . . , m, where δ equals 0 if   =       1 +      u˜2 +     u˜3 +     u˜4
  r  s p    rs                         rs                        27        27        27        27
hr = s andi equals 1 if r = s. The orthonormal basis can be ob-     ·
 6                                                           =  (1/27)( 76 + 273x1 + 138x2 + 255x3).
tained as follows: Take u1 = (1/ v1 p)v1. If u1, . . . , ur−1          −
                            k   k    r−1
                                                      Here,         ˜      . For comparison, the distance now
have been obtained, then put wr = vr j=1 vr, uj puj,         f   g˜ p  2.55
                                 −      h     i       betweenk the− lineark ≈function g we found above and the func-
and take ur = (1/ wr p)wr.
                k   k              P                  tion f is f  g  p˜ 2.79.
  Given f    , the “best approximation” to f by functions     k  −   k ≈
in  is that ∈functionF g that minimizes
  L               ∈ L                                 4   Conclusion
                      2n−1
                                                                           n        n
                                     2                Instead of considering B = 0, 1 simply as a set, we al-
          f   g p =       (f(i)  g(i)) p(i).                                   {   }
        k  −   k    v          −                      low it to be viewed as a sample space wth a probability mea-
                    u  i=0
                    u X                               sure p. Then pseudo-Boolean functions are random variables
Notice that if we take tthe uniform distribution on Bn, so on this sample space. Given a complicated pseudo-Boolean
that p(i) = (1/2)n for all i, then the best approxima- function, it is natural to want to approximate it by a simpler
tion to f in is the function g    that also minimizes
   n                                                  function, for example a linear or quadratic function. As an
  2 −1     L     2           ∈ L
  i=0 (f(i)  g(i)) . This is the usual “least squares” con- example, we found the best linear approximation to a given
dition used in−[Hammer and Holzman, 1992], [Grabisch et pseudo-Boolean function in three variables with respect to
P      ] [                   ]                        two different probability measures on 3. Further research
al., 2000 , Zhang and Rowe, 2004 , and in this casenone may                            B
simply use the usual Euclidean inner product in R2 . In our is needed to ﬁnd an effective method of computing the best
more general setting, it follows from section 8.2 of [Hoffman approximation on a non-uniform domain when the number of
and Kunze, 1971] that the best approximation to f by func- variables is large.
                                 m
tions in is the unique function g = j=1 f, uj puj .
      L                             h    i            References
                               P
3  Example                                            [Grabisch et al., 2000] Michel Grabisch, Jean-Luc Marichal,
To illustrate these ideas, we look at an example considered by and Marc Roubens. Equivalent representations of set func-
[Zhang and Rowe, 2004]. Take n = 3 and f(x1, x2, x3) =   tions. Mathematics of Operations Research, 25(2):157–
5x1 + 13x3 + 9x1x2 4x1x3   4x2x3 + 4x1x2x3. We wish      178, May 2000.
to approximate f by −the best linear− function, so we let be
                                              L       [Hammer  and Holzman, 1992] P. L. Hammer and R. Holz-
the space spanned by the functions v1 = 1, v2 = x1, v3 =
                                              3          man. Approximations of pseudo-boolean functions; ap-
x2, v4 = x3. If we take the uniform distribution on B , so plications to game theory. ZOR–Methods and Models of
that p(i) = 1/8 for i = 0, 1, . . . , 7, then by applying the Operations Research, 36:3–21, 1992.
Gram-Schmidt algorithm we get the following orthonormal
                                                      [Hoffman and Kunze, 1971] Kenneth Hoffman  and Ray
basis for with respect to the inner product , p:
       L                             h   i               Kunze. Linear Algebra, 2nd edition. Prentice-Hall, En-
   u1 = 1, u2 = 2x1 1, u3 = 2x2  1, u4 = 2x3 1.
                  −            −           −             glewood Cliffs, New Jersey, 1971.
(More generally, one can show that, for any n, an orthonormal [Jin, 2005] Yaochu Jin. A comprehensive survey of ﬁtness
basis for the space of pseudo-Boolean functions of degree at approximation in evolutionary computation. Soft Comput-
most 1 with respect to the uniform distribution is 1, 2x1
                                                 −       ing, 9(1):3–12, 2005.
1, . . . , 2xn 1.) Then the best linear approximation to f is
         −      4                                     [Valiant, 1984] L. G. Valiant. A theory of the learnable.
g(x1, x2, x3) =    f, uj puj =
                j=1h   i                                 Communications of the ACM, 27(11):1134–1142, 1984.
       39     17            7
   =       1 +P  (2x1  1) +  (2x2   1) + 5(2x3  1)    [Zhang and Rowe, 2004] Hang Zhang  and  Jonathan E.
       4  ·    4     −      4     −          −           Rowe. Best approximations of ﬁtness functions of binary
        5   17      7                                    strings. Natural Computing, 3(1):113–124, 2004.
   =      +    x1 +  x2 + 10x3,
      −4     2      2