  A Learning-Based Jam Session System that Imitates a Player's Personality Model 


        Masatoshi Hamanaka12, Masataka Goto3) 2), Hideki Asoh2), and Nobuyuki Otsu2) 4) 
                  1) Research Fellow of the Japan Society for the Promotion of Science, 
              2) National Institute of Advanced Industrial Science and Technology (AIST), 
             3) "Information and Human Activity," PRESTO, JST, 4) University of Tokyo 
                      Mbox 0604, 1-1-1 Umezono, Tsukuba, Ibaraki 305-8568, Japan 
                                         m.hamanaka@aist.go.jp 

                     Abstract                          et al., 1994] has a set of rules that determine the system's 
                                                       reactions and VirJa Session [Goto et al., 1996] has pa•
    This paper describes a jam session system that 
                                                       rameters for altering how it reacts, these systems cannot 
    enables a human player to interplay with virtual 
                                                       develop player personality models of an actual human 
    players which can imitate the player personality 
                                                       player. 
    models of various human players. Previous sys•
                                                         To realistically imitate a human player, a system must 
    tems have parameters that allow some alteration 
                                                       be able to acquire player personality models of that player. 
    in the way virtual players react, but these systems 
                                                       The imitating virtual player can then improvise according 
    cannot imitate human personalities. Our system 
                                                       to the models. The Neuro-Musician [Nishijima and Kijima, 
    can obtain three kinds of player personality 
                                                       1989; Nishijima and Watanabe, 1992] can learn the rela•
    models from a MIDI recording of a session in 
                                                       tionship between 30 sets of an 8-bar-length input pattern 
    which that player participated - a reaction model, 
                                                       and an output pattern by using neural networks. However, 
    a phrase model, and a groove model. The reaction 
                                                       it is only capable of dealing with the limited style of a jam 
    model is the characteristic way that a player reacts 
                                                       session where a solo part must be changed in 8-bar rotation. 
    to other players, and it can be statistically learned 
                                                       In other words, a virtual player and a human player cannot 
    from the relationship between the MIDI data of 
                                                       both play a solo part in the same time. Moreover, the 
    music the player listens to and the MIDI data of 
                                                       Neuro-Musician must prepare a training set of 
    music improvised by that player. The phrase 
                                                       8-bar-length input-output data to enable neural network 
    model is a set of player's characteristic phrases; it 
                                                       learning. In an actual jam session, a player does not always 
    can be acquired through musical segmentation of 
                                                       play an 8-bar solo to the 8-bar solo of the other players. 
    a MIDI session recording by using Voronoi dia•
                                                       Therefore, we cannot acquire the player models from a 
    grams on a piano-roll. The groove model is a 
                                                       MIDI session recording by using the Neuro-Musician 
    model that generates onset time deviation; it can 
                                                       method. 
    be acquired by using a hidden Markov model. 
                                                         On the other hand, the Band-OUT-of-a-Box (BoB), 
    Experimental results show that the personality 
                                                       which deals with a problem similar to ours [Thorn, 2001a; 
    models of any player participating in a guitar trio 
                                                       Thorn, 2001b], indicates that machine learning techniques 
    session can be derived from a MIDI recording of 
                                                       provide a useful approach to acquire a player's models. 
    that session. 
                                                       However, BoB can only react to a human performance of 
                                                       an immediately previous four bars. It has a fixed rela•
1 Introduction                                         tionship in which the human player is the leader and the 
Our goal is to create a jam session system in which virtual virtual player is the follower. 
players react as if they were actual human players. We   Our jam system allows us to acquire player personality 
want to make it possible for a human player to interact, models of a target human player from the MIDI recording 
whenever they like, with a virtual player that can imitate of a session in which that player participated. The main 
whoever the human player wishes to perform, for example, advantage of our approach is that we do not have to di•
with a familiar, professional, or deceased player, or even rectly evaluate the target player: all we need to build the 
with themselves. What is most important in imitating   models is session recording data. 
players is to acquire the player's personality models of a 
target human player.                                   2 A Guitar Trio Session System 
  Previous session systems have not been able to imitate a 
                                                       Our system deals with constant-tempo 12-bar blues per•
human player's personality. Some systems [Aono et al., 
                                                       formed by a guitar trio. Figure 1 shows a jam session 
1995] have been designed to follow the performance of a 
human soloist, but without considering the individual 
character of the virtual player. Although JASPER [Wake      MIDI stands for Musical Instrument Digital Interface. 


ART AND CREATIVITY                                                                                      51                                                               the reaction model is to learn the relationship between the 
                                                              input and the output of the target player in MIDI re•
                                                              cordings. This can be formulated as a problem of obtaining 
                                                              a mapping from the input to the target player's output. 
                                                              However the direct MIDI-level learning of this mapping is 
model in which either a human or the computer can be          too difficult because the same MIDI-level sequence rarely 
selected to perform the part of each player. We can           occurs more than once and the mapping itself is too sparse. 
imagine sessions in which all players will be human           We therefore have introduced two intermediate subjective 
players just as we can imagine sessions in which all          spaces: an impression space and an intention space (Figure 
players are computer players. The three players take the      4). 
solo part one after another without a fixed leader-follower   3.1 Impression space 
relationship. 
                                                              The impression space represents the subjective impression 
 We obtain three kinds of player personality model from a     derived from the MIDI input. By applying principal 
MIDI session recording - a reaction model, a phrase           components analysis (PCA) to the results of subjective 
model, and a groove model.                                    evaluations of various MIDI performances, we determined 
  The system has two modes, a learning mode and a ses•        three coordinate axes for the impression space. PCA is a 
sion mode. In the learning mode (discussed in Sections 3,4,   statistical method for reducing the number of dimensions 
and 5), the system acquires player personality models in      while capturing the major variances within a large data set. 
non-real time. These models are stored in a database and      While listening to a performance, a subject subjectively 
different personality models can be assigned to the two       evaluated it by using ten impression words to rank the 
virtual players before session play (Figure 2). In the ses•   performance's impression on a scale of one to seven. The 
sion mode (discussed in Section 6), a human player can        three selected axes of the impression space represent 
interact with the virtual players in real time.               qualities that can be described as appealing, energetic, and 
                                                              heavy. To obtain a vector in this space, an impression 
                                                              vector corresponding to the MIDI input, we use canonical 
                                                              correlation analysis (CCA). This analysis maximizes the 
                                                              correlation between various low-level features of the 
                                                              MIDI input (such as pitch, note counts, tensions, and pitch 
                                                              bend) and the corresponding subjective evaluation. Since 
                                                              an impression vector is obtained from an individual 
                                                              player's performance, we have at every moment three 
                                                              impression vectors (Figure 4). 
                                                                The impression space is necessary for learning the re•
3 Learning a reaction model                                   lationship between various input performances and the 
                                                              corresponding output performances. If we represent the 
A reaction model is the characteristic way that a player      input performances as short MIDI segments without using 
reacts to other players. Acquiring an actual player's indi•   the impression space, the same MIDI segments will not be 
vidual reaction model is necessary to create a virtual        repeated in different sessions. The impression space en•
player that reacts as that actual human player does. As       ables the abstracting of subjective impressions from input 
shown in Figure 3, each virtual player listens to the per•    MIDI data and those impressions can be repeated. Even if 
formances of all the players (including its own) and uses     two segments of the input MIDI data differ, they can be 
the reaction model to determine what its next reaction        represented as a similar vector in the impression space as 
(output performance) will be. The main issue in deriving      long as they give the same impression. 


52                                                                                               ART AND CREATIVITY                                                                we determined the three dimensions of this space. Be•
                                                               cause the number of the short phrases is limited, those 
                                                               phrases are sparsely placed in the intention space. When 
                                                               generating the output, the system selects the output phrase 
                                                               close to the determined intention vector: an appropriate 
                                                               phrase can be selected even if the phrase database does not 
                                                               have a phrase that is exactly placed on the intention vector. 

                                                               3.3 Acquiring a reaction model 
                                                               We can regard the mapping from the impression space to 
                                                               the intention space as the reaction model. To derive this 
                                                               mapping function statistically, we obtain various training 
                                                               sets from the target session recordings. These sets are pairs 
                                                               of impression vectors obtained from the three players 
                                                               during a sequence of the past twelve bars and the corre•
                                                               sponding next intention vector. For this learning we use 
                                                               Gaussian radial basis function (RBF) networks [Chen et 
                                                               al., 1991]. The RBF networks have one hidden layer with 
                 Figure 4: Player architecture.                nonlinear inputs, and each node in the hidden layer com•
   Figure 5 shows the transition of the rated values for the   putes the distance between the input vector and the center 
 impression word "appealing" The black line represents         of the corresponding radial basis function. 
 the value calculated by the system and the gray line 
 represents the value as evaluated by a human listener. For 
 92 percent of the performance, the calculated and subjec•
 tively evaluated values do not differ by more than 1. 


 3.2 Intention space 
 The intention space represents the intention of the player 
 improvising the output. A vector in this space, an intention 
 vector, determines the feeling of the next output. It is used 
 to select short MIDI phrases from a phrase database, and 
 connecting the selected phrases generates the output MIDI 
 performance. 
   Without the intention space, learning the relationship 
 between impression vectors and output MIDI data is dif•
 ficult because in actual MIDI recordings various outputs 
 can occur when the input data gives the same impression. 
 The intention space makes it easier to learn the player's 
 reaction model. 
   The intention space is constructed by using 
 multidimensional scaling (MDS) [Kruskal and Wish, 
 1978] such that intention vectors are distributed with 
proximities proportional to subjective similarities of 
 short phrases corresponding to those vectors. Based on 
 MDS results, we determined the three dimensions of this 


ART AND CREATIVITY                                                                                                     53  The RBF networks have good generalization ability and         compare the results of grouping by our method with the 
 can learn whichever nonlinear mapping function we are         results of grouping by a human according to the GTTM. 
dealing with. 
                                                               4.1 Generative Theory of Tonal Music 
4 Learning a phrase model                                      The generative theory of tonal music is composed of four 
                                                               modules, each of which is assigned to a separate part of 
A phrase model is a set of player's characteristic phrases. 
                                                               the structural description of a listener's understanding of 
To create a virtual player that performs using phrases as an 
                                                               music. The four GTTM modules are the grouping 
actual human player does, acquiring the actual player's 
                                                              structure, the metrical structure, the time-span reduction, 
individual phrase model is necessary. This can be done 
                                                               and the prolongational reduction. 
through musical segmentation of a MIDI session recording 
(Figure 6).                                                      The grouping structure is intended to formalize the 
                                                               intuition that tonal music is organized into groups, which 
                                                              are in turn composed of subgroups. There are two kinds 
                                                              of rules for GTTM grouping: grouping well-formedness 
                                                              rules and grouping preference rules. Grouping 
                                                              well-formedness rules are necessary conditions for the 
                                                              assignment of a grouping structure and restrictions on the 
                                                              generated structures. When more than one structure may 
                                                              satisfy the grouping well-formedness rules, grouping 
                                                              preference rules only suggest the superiority of one 
                                                              structure over another; they do not represent a determi•
                                                              nistic procedure. This can lead to the problem of ambi•
  Two kinds of grouping appear in polyphony, one in the       guity mentioned above. 
direction of pitch interval and the other in the direction of 
time. Grouping in the pitch interval direction divides po•    4.2 Use of Voronoi diagrams for grouping 
lyphony into multiple homophony (Figure 7a). In the time      To overcome the ambiguity problem, we propose a 
direction, notes are grouped from time gap to time gap        method of grouping based on the use of Voronoi dia•
(Figure 7b).                                                  grams. The GTTM result is a binary tree that indicates the 
  To segment a MIDI session recording into phrases, we        hierarchical structure of a piece of music. In our method, 
need to automatically divide the polyphony notes into         Voronoi diagrams on a piano-roll represent the hierar•
groups. The generative theory of tonal music (GTTM)           chical structure of a piece of music. 
[Lerdahl and Jackendoff, 1983] includes a grouping con•
cept, and thus can be used to derive a set of rules for the 
division of notes into groups. We think that GTTM is the 
most promising theory of music in terms of computer 
implementation; however, no strict order exists for ap•
plying the rules of GTTM. This may lead to ambiguities in 
terms of analysis results. The implementation of GTTM as 
a computer system has been attempted [Ida et al., 2001], 
but the resulting system was only capable of dealing with a 
limited polyphony made up of two monophonies. 
  In this paper, we propose a method of grouping based on 
applying the Voronoi diagram. We have developed a 
method of grouping rather than naively implementing 
GTTM so that a result obtained using our method is equi-
final to one obtained with the GTTM approach. We 

      a: Grouping in pilch interval direction. 


      b: Grouping in time direction.                          We can form the Voronoi diagram for a given set of 
                                                              points in a plane as a connected set of segments of 
                                                              half-plane boundaries, where each of the half-planes is 
                                                              formed by partitioning the plane into two half-planes, one 
                                                              on either side of the bisector of the line between each 
             Figure 7: Examples of grouping.                  adjacent pair/?, and Pj,. 


54                                                                                                ART AND CREATIVITY Voronoi diagram for two notes                                    a. Result obtained using our method. 
Our method uses the piano-roll format as a score, and thus 
notes are expressed as horizontal line segments on a pi•
ano-roll. To construct a Voronoi diagram on the score, we 
need to consider the Voronoi diagram for multiple hori•
zontal line segments, which will be constructed of linear 
segments and quadratic segments. 
   When two notes sound at the same time or no note 
sounds, the corresponding part of the Voronoi diagram is a 
linear segment (Figures. 9a and 9c). When a single note 
sounds, the Voronoi diagram becomes a quadratic segment 
(Figure 9b). 
                                                                 b. Result obtained using GTTM. 


Voronoi diagram for more than two notes 
To construct a Voronoi diagram for more than two notes, 
we construct the Voronoi diagrams for all note pairs and          Figure 11: Results obtained using our method and GTTM. 
delete the irrelevant segments. For example, to construct a 
Voronoi diagram for notes a, b, and c, we construct three 
Voronoi diagrams (Figure 10). The boundaries in the three      5 Learning a groove model 
diagrams then intersect at a point that is equidistant from 
each note. The Voronoi diagram for notes a and b is di•        A groove model is a model generating the deviation of on 
vided into two half-lines at the intersection. We then delete  set times. Acquiring an actual player's individual groove 
the half-line that is closer to c than to a or b.              model is necessary to create a virtual player that performs 
                                                               with musical expression as that human player does. A 
                                                               human player, even when repeating a given phrase on a 
                                                               MIDl-equipped instrument, rarely produces exactly the 
                                                               same sequence of onset notes because the onset times 
                                                               deviate according to performer's actions and expressions. 
                                                               We can model the process generating that deviation by 
                                                               using a probabilistic model. 

                                                               5.1 Formulation of the hidden Markov models 
                                                               Let a sequence of intended (normalized) onset times be 0 
                                                               and a sequence of performed onset times (with deviation) 
                                                               be y. Then, a model for generating the deviation of onset 
4.3 Making groups                                              times can be expressed by a conditional probability 
Hierarchical groups of notes were constructed by con•          P (y \0) (Figure 12). Using this conditional probability and 
verging adjacent notes iteratively. Here, we introduce the    the prior probability P (0) can be formulated as a hidden 
following principle for making groups; the smallest Vo•       Markov model (HMM), which is a probabilistic model that 
ronoi cell is first merged to an adjacent group.              generates a transition sequence of hidden states as a 
  We have implemented our grouping method (Figure             Markov chain. Each hidden state in the state transition 
1 la) and have compared the results with correct data ob•     sequence then generates an observation value according to 
tained by a human (Figure 11b). We evaluated grouping         an observation probability. 
performance in terms of a correctness rate defined as 
                    The number of notes grouped correctly      Modeling of performance 
   Correctness rate = -— — (5)                                 Target in modeling 
                           The number of notes                We modeled the onset time of a musical note (i.e. the start 
When wc ran the program, we calculated that the cor•          time of the note) and introduced a new model of distribu•
rectness rate was 78.5 percent. The tune used as MIDI data    tion of onset times. While the duration- time-based model 
in this experiment was the Turkish March. 


ART AND CREATIVITY                                                                                                    55 