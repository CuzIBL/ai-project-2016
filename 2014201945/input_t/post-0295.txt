          Image Retrieval and Disambiguation for Encyclopedic Web Search

                                 Atsushi Fujii and Tetsuya Ishikawa
                      Graduate School of Library, Information and Media Studies
                                         University of Tsukuba
                                 1-2 Kasuga, Tsukuba, 305-8550, Japan


                    Abstract                          content-based image retrieval. Given a text query, an image
                                                      ﬁle, such as GIF and JPEG ﬁles, linked from an HTML ﬁle
    To produce multimedia encyclopedic content, we    including one or more query terms is selected as a candidate
    propose a method to search the Web for images as- image. In other words, text content in an HTML ﬁle is used
    sociated with a speciﬁc word sense. We use text in as a “pseudo-caption” for a target image.
    an HTML ﬁle which links to an image as a pseudo-
                                                        However, the text-based image retrieval cannot distinguish
    caption for the image and perform text-based in-
                                                      images depicting different entities, if a query term is polyse-
    dexing and retrieval. We use term descriptions in a
                                                      mous. For example, images of network devices and images
    Web search site called “CYCLONE” as queries and
                                                      of axles can potentially be retrieved together in response to
    correspond images and texts based on word senses.
                                                      the query “hub”.
                                                        To resolve this problem, we use a text description for a
1  Introduction                                       speciﬁc word sense. Term descriptions in CYCLONE, which
The World Wide Web, which contains an enormous volume are organized on the basis of word senses, provide informa-
of up-to-date information, is a promising source to obtain tive contexts for word sense disambiguation. For example,
encyclopedic knowledge. It has become common to con-  if an HTML ﬁle includes words “LAN” and “cable”, an im-
sult the Web for speciﬁc keywords, instead of using con- age linked from this HTML ﬁle is likely to depict a network
ventional dictionaries and encyclopedias. However, existing device more than an axle.
Web search engines often retrieve extraneous pages contain- We need to crawl the Web and cache a large number of im-
ing low-quality, unreliable, and misleading information. ages and HTML ﬁles linking to those images. We shall call
  Fujii and Ishikawa [2001] proposed an automatic method these HTML ﬁles “hyper HTML ﬁles”. However, this process
to extract term descriptions from the Web and classify mul- is computationally expensive. We experimentally use Yahoo!
tiple descriptions into domains and word senses. Using this Japan3 to obtain pairs of an image and its hyper HTML ﬁle,
method, Fujii and Ishikawa have built a Web search site called by submitting a target term (e.g., “hub”) as a query. We dis-
“CYCLONE”1, in which a user can efﬁciently obtain an en- card all HTML tags in the hyper HTML ﬁles and extract the
cyclopedic term description in a speciﬁc word sense. Over text content, from which we produce a text index.
700,000 Japanese terms are currently indexed as headwords. For indexing and retrieval purposes, any best-match text
  However, to explain certain headwords, speciﬁcally those retrieval method, such as the vector space model and prob-
related to an entity, such as devices and animals, it is effective abilistic model, can be used. We experimentally use Okapi
to present a picture depicting the entity, in addition to text BM25. We use content words, such as nouns, extracted from
descriptions.                                         text as index terms, and perform word-based indexing. We
  In this paper, we propose a method to integrate images on use the ChaSen morphological analyzer4 to extract content
the Web and text descriptions in CYCLONE. We resolve the words, because Japanese sentences lack lexical segmentation.
ambiguity of the meaning of an image by text analysis, so that The same method is used to extract terms from queries.
images for a polysemous word, such as “hub (network de- However, unlike a text-based image retrieval which uses
vice and center of wheel)”, are classiﬁed on the basis of word well-organized captions [Smeaton and Quigley, 1996], not all
senses. Our research is a step toward the automatic compila- words in an HTML ﬁle are related to an image. We use differ-
tion of multimedia encyclopedias, such as Encarta2.   ent term weights depending on the region in an HTML ﬁle.
                                                      In principle, a decreasing function which assigns a value to
2  Description-based Image Disambiguation             each word depending on the proximity between the word and
                                                      an anchor (i.e., <IMG> and <A> in HTML) to a target image
Existing search engines, such as Google and Yahoo!, use texts                                          M
in HTML ﬁles for retrieval purposes, instead of performing can be used. In practice, we multiply the weight of a word
  1http://cyclone.slis.tsukuba.ac.jp/                    3http://www.yahoo.co.jp/
  2http://encarta.msn.com/                               4http://chasen.aist-nara.ac.jp/                                                         100

                                                          90

                                                          80

                                                          70

                                                          60


                                                        Accuracy  (%) 50

                                                          40

                                                          30
                                                                                             PBTW
                                                                                              DBD
                                                                                            Baseline
                                                          20
                                                            1 2 3 4  5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
                                                                                Rank

Figure 1: Example text descriptions and images for “habu”. Figure 2: Rank-accuracy graphs for different methods.

times, if the number of characters between the word and the
anchor to the image is less than N. We shall call this method queries and performs the proximity-based term weight-
“proximity-based term weighting (PBTW)”. The values of M  ing method (“PBTW”).
and N are determined empirically in Section 3.        For the baseline method, which did not perform image dis-
  Figure 1 depicts a successful example result for the ambiguation, the same list of candidate images was associ-
Japanese term “habu”, which is associated with multiple ated with the different senses for each test term. Through a
word senses, such as a network device, snake in Okinawa, preliminary experiment, we set M =7and N = 400 for
airport, and center. In Figure 1, the ﬁrst two paragraphs de- PBTW.
scribe device and snake, respectively. The top three image Figure 2 shows the accuracy for each method in different
candidates are associated with each paragraph.        ranks. The accuracy for rank r is the number of queries for
                                                      which a correct image was found in the top r candidates and
3  Experimentation                                    the total number of queries. DBD and PBTW signiﬁcantly
                                                      improved on the accuracy of the baseline method, irrespective
To evaluate the accuracy of our method, we produced a test of the rank. PBTW improved on the accuracy of DBD. As
collection. First, we collected polysemous words used as test predicted, the words in close proximity to an anchor for a
terms. For each test term, at least two word senses must be target image were important to disambiguate the meaning of
able to be depicted by image, because our purpose is to dis- the image. PBTW retrieved at least one correct image in the
ambiguate the meaning of images. We collected 22 test terms. top ten candidates for 93.6% of the queries.
  Second, for each test term, we used Yahoo! Japan to search
the Web for the top one hundred images and their hyper 4  Conclusion
HTML ﬁles. Third, each image was manually annotated with
                                                      To compile multimedia encyclopedic content on the Web, we
a word sense, disregarding as to whether or not the sense is
                                                      proposed a method to associate text descriptions in CYCLONE
included in CYCLONE. The annotator was able to read the
                                                      and image ﬁles based on word senses, and showed its effec-
content of a hyper HTML ﬁle for the decision, if necessary.
                                                      tiveness by means of experiments.
The images not associated with any word sense are annotated
with “irrelevant”. Fourth, for each test term, a query is pro-
duced from each description in CYCLONE. We used the top References
descriptions classiﬁed into each domain. The descriptions not [Fujii and Ishikawa, 2001] Atsushi Fujii and Tetsuya
associated with any word sense annotated to the images were Ishikawa. Organizing encyclopedic knowledge based on
discarded. The total number of queries was 155.          the Web and its application to question answering. In
  We compared the following three methods:               Proceedings of the 39th Annual Meeting of the Association
  • a baseline method, which sorts candidate images for  for Computational Linguistics, pages 196–203, 2001.
    each query according to the ranking in Yahoo! Japan [Smeaton and Quigley, 1996] Alan F. Smeaton and Ian
    (“Baseline”),                                        Quigley. Experiments on using semantic distances be-
                                                         tween words in image caption retrieval. In Proceedings
  • our method  (the description-based disambiguation
                                                         of the 19th Annual International ACM SIGIR Conference
    method), which uses descriptions in CYCLONE  as
                                                         on Research and Development in Information Retrieval,
    queries (“DBD”),
                                                         pages 174–180, 1996.
  • our method, which uses descriptions in CYCLONE as