         Feature Generation for Text Categorization Using World Knowledge

                             Evgeniy Gabrilovich    and  Shaul Markovitch
                             {gabr,shaulm}@cs.technion.ac.il
                     Computer Science Department, Technion, 32000 Haifa, Israel

                    Abstract                          venture is mining copper; instead, this fairly long document
    We enhance machine learning algorithms for text   mainly talks about the mutual share holdings of the compa-
    categorization with generated features based on   nies involved (Teck Corporation, Cominco, and Lornex Min-
    domain-speciﬁc and common-sense knowledge.        ing), as well as discusses other mining activities of the con-
    This knowledge is represented using publicly avail- sortium. Consequently, three very different text classiﬁers we
    able ontologies that contain hundreds of thousands used (SVM, KNN and C4.5) failed to classify the document
    of concepts, such as the Open Directory; these on- correctly. This comes as no surprise—“copper” is a fairly
    tologies are further enriched by several orders of small category, and neither of these companies, nor the loca-
    magnitude through controlled Web crawling. Prior  tion of the venture (Highland Valley in British Columbia) are
    to text categorization, a feature generator analyzes ever mentioned in the training set for this category. The fail-
    the documents and maps them onto appropriate on-  ure of the bag of words approach is therefore unavoidable, as
    tology concepts, which in turn induce a set of gen- it cannot reason about the important components of the story.
    erated features that augment the standard bag of    We argue that this needs not be the case. When a Reuters
    words. Feature generation is accomplished through editor originally handled this document, she most likely knew
    contextual analysis of document text, implicitly  quite a lot about the business of these companies, and easily
    performing word sense disambiguation. Coupled     assigned the document to the category “copper”. It is this
    with the ability to generalize concepts using the on- kind of knowledge that we would like machine learning algo-
    tology, this approach addresses the two main prob- rithms to have access to.
    lems of natural language processing—synonymy        To date, quite a few attempts have been made to deviate
    and polysemy. Categorizing documents with the     from the orthodox bag of words paradigm, usually with lim-
    aid of knowledge-based features leverages infor-  ited success. In particular, representations based on phrases
    mation that cannot be deduced from the documents  [Dumais et al., 1998; Fuernkranz et al., 2000], named enti-
    alone. Experimental results conﬁrm improved per-  ties [Kumaran and Allan, 2004], and term clustering [Lewis
    formance, breaking through the plateau previously and Croft, 1990; Bekkerman, 2003] have been explored. In
    reached in the ﬁeld.                              the above example, however, none of these techniques could
1  Introduction                                       overcome the underlying problem—lack of world knowledge.
The state of the art systems for text categorization use in- In order to solve this problem and break through the ex-
duction algorithms in conjunction with word-based features isting performance barrier, a fundamentally new approach is
(“bag of words”). After a decade of improvements, the per- apparently necessary. One possible solution is to completely
formance of the best document categorization systems be- depart from the paradigm of induction algorithms in an at-
came more or less similar, and it appears as though a plateau tempt to perform deep understanding of the document text.
has been reached, as neither system is considerably superior Yet, considering the current state of natural language process-
to others, and improvements are becoming evolutionary [Se- ing systems, this does not seem to be a viable option (at least
bastiani, 2002].                                      for the time being).
  The bag of words (BOW) approach is inherently limited, as We propose an alternative solution that capitalizes on the
it can only use pieces of information that are explicitly men- power of existing induction techniques while enriching the
tioned in the documents, and even that provided the same vo- language of representation, namely, exploring new feature
cabulary is consistently used. Speciﬁcally, this approach has spaces. Prior to text categorization, we employ a feature gen-
no access to the wealth of world knowledge possessed by hu- erator that uses common-sense and domain-speciﬁc knowl-
mans, and is easily puzzled by facts and terms not mentioned edge to enrich the bag of words with new, more informative
in the training set.                                  features. Feature generation is performed completely auto-
  To illustrate the limitations of the BOW approach, consider matically, using machine-readable hierarchical repositories of
document #15264 in Reuters-21578, which is one of the most knowledge such as the Open Directory Project (ODP), Ya-
frequently used datasets in text categorization research. This hoo! Web Directory, and the Wikipedia encyclopedia.
document discusses a joint mining venture by a consortium In this paper we use the ODP as a source of background
of companies, and belongs to the category “copper”. How- knowledge. Thus, in the above example the feature genera-
ever, the document only brieﬂy mentions that the aim of this tor “knows” that the companies mentioned are in the miningbusiness, and that Highland Valley happens to host a copper 2. There is a collection of texts associated with each con-
mine. This information is available in Web pages that discuss cept. The feature generator uses these texts to learn the
the companies and their operations, and are cataloged in cor- deﬁnition and scope of the concept, in order to be able
responding ODP categories such as Mining and Drilling and to assign it to relevant documents.
Metals. Similarly, Web pages about Highland Valley are cat-
aloged under British Columbia. To amass this information, We currently use the ODP as our knowledge base, however,
we crawl the URLs cataloged in the ODP, thus effectively our methodology is general enough to facilitate other sources
multiplying the amount of knowledge available many times of common-sense and domain-speciﬁc knowledge that sat-
over. Armed with this knowledge, the feature generator con- isfy the above assumptions. The Open Directory comprises
structs new features that denote these ODP categories, and a hierarchy of approximately 600,000 categories that catalog
adds them to the bag of words. The augmented feature space over 4,000,000 Web sites, each represented by a URL, a ti-
provides text classiﬁers with a cornucopia of additional infor- tle, and a brief summary of its contents. The project consti-
mation. Indeed, our implementation of the proposed method- tutes an ongoing effort promoted by over 65,000 volunteer
ology classiﬁes this document correctly.              editors around the globe, and is arguably the largest publicly
  Feature generation (FG) techniques were found useful in available Web directory. Being the result of pro bono work,
a variety of machine learning tasks [Markovitch and Rosen- the Open Directory has its share of drawbacks, such as non-
stein, 2002; Fawcett, 1993; Matheus, 1991]. These tech- uniform coverage, duplicate subtrees in different branches of
niques search for new features that describe the target con- the hierarchy, and sometimes biased coverage due to peculiar
cept better than the ones supplied with the training instances. views of the editors in charge. Nonetheless, ODP embeds a
A number of feature generation algorithms were proposed colossal amount of human knowledge in a wide variety of ar-
[Pagallo and Haussler, 1990; Matheus and Rendell, 1989; eas, covering even most speciﬁc scientiﬁc and technical con-
Hu and Kibler, 1996; Murphy and Pazzani, 1991], which led cepts. In what follows, we refer to the ODP category nodes
to signiﬁcant improvements in performance over a range of as concepts, to avoid possible confusion with the term cat-
classiﬁcation tasks. However, even though feature generation egories, which is usually reserved for the labels assigned to
is an established research area in machine learning, only a few documents in text categorization.
works applied it to text processing [Kudenko and Hirsh, 1998; 2.1 Building a Feature Generator
Mikheev, 1999; Cohen, 2000]. With the exception of a
few studies using WordNet [Scott, 1998; Urena-Lopez et al., We start with a preprocessing step, performed once for all fu-
2001], none of them attempted to leverage repositories of ture text categorization tasks. We induce a hierarchical text
world knowledge.                                      classiﬁer that maps pieces of text onto relevant ODP con-
  The contributions of this paper are threefold. First, we pro- cepts, which later serve as generated features. The resulting
pose a framework and a collection of algorithms that perform classiﬁer is called a feature generator according to its true
feature generation based on very large-scale repositories of purpose in our scheme, as opposed to the text categorizer (or
human knowledge. Second, we propose a novel kind of con- classiﬁer) that we build ultimately. The feature generator rep-
textual analysis performed during feature generation, which resents ODP concepts as vectors of their most characteristic
views the document text as a sequence of local contexts, and words, which we call attributes (reserving the term features
performs implicit word sense disambiguation. Finally, we de- to denote the properties of documents in text categorization).
scribe a way to further enhance existing knowledge bases by We now explain how the attribute vectors are built.
several orders of magnitude by crawling the World Wide Web. We use the textual descriptions of ODP nodes and their
As we show in Section 3, our approach allows to break the URLs as training examples for learning the feature genera-
performance barrier currently reached by the best text cate- tor. Although these descriptions alone constitute a sizeable
gorization systems.                                   amount of information, we devised a way to increase the vol-
                                                      ume of training data by several orders of magnitude. We do so
2  Feature Generation Methodology                     by crawling the Web sites pointed at by all cataloged URLs,
The proposed methodology allows principled and uniform in- and obtain a small representative sample of each site. Pooling
tegration of external knowledge to construct new features. In together the samples of all sites associated with an ODP node
the preprocessing step we use knowledge repositories to build gives us a wealth of additional information about it.
a feature generator. Applying the feature generator to the doc- Texts harvested from the WWW are often plagued with
uments produces a set of generated features. These features noise, and without adequate noise reduction crawled data may
undergo feature selection, and the most discriminative ones do more harm than good. To remedy the situation, we per-
are added to the bag of words. Finally, we use traditional form attribute selection for each ODP node; this can be done
text categorization techniques to learn a text categorizer in using any standard feature selection technique such as infor-
the augmented feature space.                          mation gain. For example, consider the top 10 attributes se-
  Suitable knowledge repositories satisfy the following re- lected for the ODP concepts Science—science, research, sci-
quirements:                                           entiﬁc, biology, laboratory, analysis, university, theory, study,
 1. The repository contains a collection of concepts orga- scientist, and Artiﬁcial Intelligence—neural, artiﬁcial, algo-
    nized in a hierarchical tree structure, where edges repre- rithm, intelligence, AAAI, Bayesian, probability, IEEE, cog-
    sent the “is-a” relationship. Using a hierarchical ontol- nitive, inference. Additional noise reduction is achieved by
    ogy allows us to perform powerful generalizations. pruning nodes having too few URLs or situated too deep in                                                      sentences or paragraphs. The optimal resolution for docu-
                                                      ment segmentation can be determined automatically using a
              Business/Mining_and_Drilling            validation set. We propose a more principled multi-resolution
              Attributes selected for this 
              concept : …, Teck, Cominco, …           approach that simultaneously partitions the document at sev-
                                                      eral levels of linguistic abstraction (windows of words, sen-
          … 
                      Web sites catalogued under      tences, paragraphs, up to taking the entire document as one
   www.teckcominco.com Business/Mining_and_Drilling   big chunk), and performs feature generation at each of these
                                                      levels. We rely on the subsequent feature selection step to
    “ … Cominco and Generated features:  
    Teck's 22 pct-owned …, Metallurgy,                eliminate extraneous features, preserving only those that gen-
    Lornex agreed in Metallic_Deposits 
                                  Feature   Text 
    January 1986 to form Mining_and_Drilling, …       uinely characterize the document.
                                  vector  classifier 
    the joint venture, 
    merging their Highland                              In fact, the proposed approach tackles the two most impor-
    Valley operations …”  Bag of Words  
                                                      tant problems in natural language processing, namely, syn-
         Figure 1: Feature generation example         onymy and polysemy. Classifying individual contexts implic-
the tree (and thus representing overly speciﬁc concepts), as- itly performs word sense disambiguation, and thus resolves
signing their textual content to their parents.       word polysemy to some degree. A context that contains one
  In our current implementation, the feature generator works or more polysemous words is mapped to the concepts that
as a nearest neighbor classiﬁer—it compares its input text correspond to the sense shared by the context words. Thus,
to (the attribute vectors of) all ODP nodes, and returns the the correct sense of each word is determined with the help of
desired number of best-matching ones. The generator also its neighbors. At the same time, enriching document repre-
performs generalization of concepts, and constructs features sentation with high-level concepts and their generalizations
based on the classiﬁed concepts per se as well as their ances- addresses the problem of synonymy, as the enhanced repre-
tors in the hierarchy.                                sentation can easily recognize that two (or more) documents
  Let us revisit the example from Section 1. While building actually talk about related issues, even though they do so us-
the feature generator, our system crawls the Web sites ing different vocabularies.
cataloged under mining-related ODP concepts such as Busi- Let us again revisit our running example. During feature
ness/Mining and Drilling, Science/Technology/Mining and generation, document #15264 is segmented into a sequence
Business/Industrial Goods and Services/Materials/Metals. of contexts, which are then mapped to mining-related ODP
These include www.teckcominco.com and www.mining-     concepts (e.g., Business/Mining and Drilling). These con-
surplus.com   that belong to the (now merged) Teck    cepts, as well as their ancestors in the hierarchy, give rise to a
Cominco company. Due to the company’s prominence, it  set of generated features that augment the bag of words (see
is mentioned frequently in the Web sites we have crawled, Figure 1). Observe that the training documents for the cat-
and consequently the words “Teck” and “Cominco” are   egory “copper” underwent a similar processing when a text
included in the set of attributes selected to represent the classiﬁer was induced. Consequently, features based on these
above concepts. Figure 1 illustrates the process of feature concepts were selected during feature selection thanks to their
generation for this example.                          high predictive capacity. It is due to these features that the
                                                      document is now categorized correctly, while without feature
2.2  Contextual Feature Generation                    generation it consistently caused BOW classiﬁers to err.
Traditionally, feature generation uses the basic features sup-
plied with the training instances to construct more sophisti- 2.3 Feature Selection
cated features. In the case of text processing, however, ap- Using support vector machines in conjunction with bag of
plying this approach to the bag of words leads to losing the words, Joachims [1998] found that SVMs are very robust
important information about word ordering. Therefore, we even in the presence of numerous features, and further ob-
argue that feature generation becomes much more powerful served that the multitude of features are indeed useful for text
when it operates on the raw document text. But should the categorization. These ﬁndings were corroborated in more
generator always analyze the whole document as a single unit, recent studies [Brank et al., 2002; Bekkerman, 2003] that
similarly to regular text classiﬁers?                 observed either no improvement or even small degradation
  We believe that considering the entire document may of- of SVM performance after feature selection.1 Consequently,
ten be misleading, as its text can be too diverse to be readily many later works using SVMs did not apply feature selection
mapped to the right set of concepts, while notions mentioned at all [Leopold and Kindermann, 2002; Lewis et al., 2004].
only brieﬂy may be overlooked. Instead, we propose to parti- This situation changes drastically as we augment the bag of
tion the document into a series of non-overlapping segments words with generated features. First, nearly any technique for
(called contexts), and then generate features at this ﬁner level. automatic feature generation can easily generate huge num-
Each context is classiﬁed into a number of concepts in the bers of features, which will likely aggravate the “curse of di-
knowledge base, and pooling these concepts together results mensionality”. Furthermore, it is feature selection that allows
in multi-faceted classiﬁcation for the document. This way, the feature generator not to be a perfect classiﬁer. When at
the resulting set of concepts represents the various aspects or
sub-topics covered by the document.                      1Gabrilovich and Markovitch [2004] described a class of prob-
  Potential candidates for such contexts are simple sequences lems where feature selection from the bag of words actually im-
of words, or more linguistically motivated chunks such as proves SVM performance.least some of the concepts assigned to the document are cor- 4. Movie Reviews (Movies) [Pang et al., 2002] deﬁnes a sen-
rect, feature selection can identify them and seamlessly elim- timent classiﬁcation task, where reviews express either pos-
inate the spurious ones.                              itive or negative opinion about the movies. The dataset has
                                                      1400 documents in two categories (positive/negative).
3  Empirical Evaluation                                 We used support vector machines3 as our learning algo-
We implemented the proposed methodology using an ODP  rithm to build text categorizers, since prior studies found
snapshot as of April 2004.                            SVMs to have the best performance for text categorization
                                                      [                                    ]
3.1  Implementation Details                            Dumais et al., 1998; Yang and Liu, 1999 . Following es-
                                                      tablished practice, we use the precision-recall Break-Even
After pruning the Top/World branch that contains non- Point (BEP) to measure text categorization performance. For
English material, we  obtained a hierarchy of  over   the two Reuters datasets we report both micro- and macro-
400,000 concepts and 2,800,000 URLs. Applying our metho- averaged BEP, since their categories differ in size signiﬁ-
dology to a knowledge base of this scale required an enor- cantly. Micro-averaged BEP operates at the document level
mous engineering effort. Textual descriptions of the concepts and is primarily affected by categorization performance on
and URLs amounted to 436 Mb of text. In order to increase larger categories. On the other hand, macro-averaged BEP
the amount of information for training the feature generator, averages results for individual categories, and thus small cat-
we further populated the ODP hierarchy by crawling all of its egories with few training examples have large impact on the
URLs, and taking the ﬁrst 10 pages (in the BFS order) en- overall performance. For both Reuters datasets we used a
countered at each site. This operation yielded 425 Gb worth ﬁxed data split, and consequently used macro sign test (S-
of HTML ﬁles. After eliminating all the markup and truncat- test) [Yang and Liu, 1999] to assess the statistical signiﬁ-
ing overly long ﬁles at 50 Kb, we ended up with 70 Gb of ad- cance of differences in classiﬁer performance. For 20NG
ditional textual data. Compared to the original 436 Mb of text and Movies we performed 4-fold cross-validation, and used
supplied with the hierarchy, we obtained over a 150-fold in- paired t-test to assess the signiﬁcance.
crease in the amount of data. After removing stop words and
rare words (occurring in less than 5 documents) and stem- 3.3 The Effect of Feature Generation
ming the remaining ones, we obtained 20,700,000 distinct We ﬁrst demonstrate that the performance of basic text cate-
terms that were used to represent ODP nodes as attribute vec- gorization in our implementation (column “Baseline” in Ta-
tors. Up to 1000 most informative attributes were selected ble 1) is consistent with other published studies (all using
for each ODP node using the Document Frequency criterion SVM). On Reuters-21578, Dumais et al. [1998] achieved
(other commonly used feature selection techniques, such as micro-BEP of 0.920 for 10 categories and 0.870 for all cate-
Information Gain, χ2 and Odds Ratio, yielded slightly infe- gories. On 20NG, Bekkerman [2003] obtained BEP of 0.856.
rior results). We used the multi-resolution approach for fea- Pang et al. [2002] obtained accuracy of 0.829 on Movies. The
ture generation, classifying document contexts at the level minor variations in performance are due to differences in data
of words, sentences, paragraphs, and ﬁnally the entire doc- preprocessing used in different systems; for example, for the
ument.Features were generated from the 10 best-matching Movies dataset we worked with raw HTML ﬁles rather than
ODP concepts for each context.                        with the ofﬁcial tokenized version, in order to recover sen-
3.2  Experimental Methodology                         tence and paragraph structure for contextual analysis. For
                                                      RCV1, direct comparison with published results is more dif-
The following test collections were used:             ﬁcult, as we limited the category sets and the date span of
1. Reuters-21578 [Reuters, 1997]. Following common prac- documents to speedup experimentation.
tice, we used the ModApte split (9603 training, 3299 testing Table 1 shows the results of using feature generation with
documents) and two category sets, 10 largest categories and signiﬁcant improvements (p < 0.05) shown in bold. For both
90 categories with at least one training and testing example. Reuters datasets, we consistently observed larger improve-
2. Reuters Corpus Volume I (RCV1) [Lewis et al., 2004] ments in macro-averaged BEP, which is dominated by cate-
has over 800,000 documents, and presents a new challenge gorization effectiveness on small categories. This goes in line
for text categorization. To speedup experimentation, we used with our expectations that the contribution of external knowl-
a subset of the corpus with 17808 training documents (dated edge should be especially prominent for categories with few
20–27/08/96) and 5341 testing ones (28–31/08/96). Follow- training examples. As can be readily seen, categorization
ing Brank et al. [2002], we used 16 Topic and 16 Industry performance was improved for all datasets, with notable im-
categories that constitute a representative sample of the full provements of up to 25.4% for Reuters RCV1 and 3.6% for
groups of 103 and 354 categories, respectively. We also ran- Movies. Given the performance plateau currently reached by
domly sampled the Topic and Industry categories into several the best text categorizers, these results clearly demonstrate
sets of 10 categories each (Table 1 shows 3 category sets in the advantage of knowledge-based feature generation.
each group with the highest improvement in categorization
performance).2                                        3.4  Actual Examples Under a Magnifying Glass
3. 20 Newsgroups (20NG) [Lang, 1995] is a well-balanced Thanks to feature generation our system correctly classiﬁes
dataset of 20 categories containing 1000 documents each. the running example document #15264. Let us consider ad-
                                                      ditional testing examples from Reuters-21578 that are incor-
  2Full deﬁnition of the category sets we used is available at
                                                             light
http://www.cs.technion.ac.il/˜gabr/ijcai2005-appendix.html . 3SVM implementation [Joachims, 1998].   0.845                              0.86                                0.7
    0.84                              0.84                               0.65
                     Baseline
   0.835             FG/multi         0.82                                0.6
                     FG/words
    0.83              FG/doc           0.8                               0.55
   0.825                              0.78                                0.5
    0.82                              0.76                               0.45
                                                           BOW


  Precision-recall  BEP              Precision-recall  BEP                                    BOW
   0.815                              0.74             BOW+GEN          Precision-recall  BEP  0.4 BOW+GEN
                                                           GEN                                GEN
    0.81                              0.72                               0.35
       1 2 3 5 10 30 50 70 100 200 1000 0.005 0.01 0.05 0.1 0.2 0.5 0.75 1.0 0.005 0.01 0.05 0.1 0.2 0.5 0.75 1.0
           Context window length (words)   Fraction of generated features selected Fraction of generated features selected
 Figure 2: Varying context length (Movies) Figure 3: Feature selection (Movies) Figure 4: Feature selection (RCV1/Topic-16)
 Dataset       Baseline    Feature   Improvement      feature generator to the context of that size. With these word-
                         generation   vs. baseline    level contexts, maximum performance is achieved when us-
              micro macro micro macro micro macro     ing pairs of words (x=2). The FG/doc line shows the result
              BEP  BEP   BEP   BEP   BEP    BEP
                                                      of using the entire document as a single context. In this case,
 Reuters-21578                                        the results are somewhat better than without feature genera-
  10 categories 0.925 0.874 0.930 0.884 +0.5% +1.1%   tion (Baseline), but are still inferior to the more ﬁne-grained
  90 categories 0.877 0.602 0.880 0.614 +0.3% +2.0%
 RCV1                                                 word-level contexts (FG/words). However, the best perfor-
  Industry-16 0.642 0.595 0.648 0.613 +0.9% +3.0%     mance by far is achieved when using the multi-resolution ap-
  Industry-10A 0.421 0.335 0.457 0.420 +8.6% +25.4%   proach (FG/multi), in which we use a series of linguistically
  Industry-10B 0.489 0.528 0.530 0.560 +8.4% +6.1%    motivated chunks of text, starting with individual words, and
  Industry-10C 0.443 0.414 0.468 0.463 +5.6% +11.8%   then generating features from sentences, paragraphs, and ﬁ-
  Topic-16    0.836 0.591 0.840 0.660 +0.5% +11.7%    nally the entire document.
  Topic-10A   0.796 0.587 0.806 0.695 +1.3% +18.4%
  Topic-10B   0.716 0.618 0.731 0.651 +2.1% +5.3%     3.6  The Utility of Feature Selection
  Topic-10C   0.719 0.616 0.727 0.646 +1.1% +4.9%     Under the experimental settings deﬁned in Section 3.1, fea-
 20NG         0.854      0.858      +0.5%             ture generation constructs approximately 4–5 times as many
 Movies       0.813      0.842      +3.6%
                                                      features as are in the bag of words. We conducted two ex-
 Table 1: Text categorization with and without feature generation periments to understand the effect of feature selection in con-
rectly categorized by the BOW classiﬁer. Document #16143 junction with feature generation.
belongs to the category “money-fx” (money/foreign ex-   Since earlier studies found that most BOW features are in-
change) and discusses the devaluation of the Kenyan shilling. deed useful for SVM text categorization (Section 2.3), in our
Even though “money-fx” is one of the 10 largest cate- ﬁrst experiment we only apply feature selection to the gener-
gories, the word “shilling” does not occur in its training ated features, and use the selected ones to augment the (en-
documents even once. However, the feature generator eas- tire) bag of words. In Figures 3 and 4, the BOW line de-
ily recognizes it as a kind of currency, and produces fea- picts the baseline performance without generated features,
tures such as Recreation/Collecting/Paper Money and Recre- while the BOW+GEN curve shows the performance of the
ation/Collecting/Coins/World Coins. These high-level fea- bag of words augmented with progressively larger fractions
tures were also constructed for many training examples, and of generated features (sorted by information gain). For both
consequently the document is now classiﬁed correctly. datasets, the performance peaks when only a small fraction
  Similarly, document #18748 discusses Italy’s balance of of the generated features are used, while retaining more gen-
payments and belongs to the category “trade”, while the word erated features has a noticeable detrimental effect. Similar
“trade” itself does not occur in this short document. How- phenomena have been observed for other datasets; we omit
ever, when the feature generator considers document contexts the results owing to lack of space.
discussing Italian deﬁcit as reported by the Bank of Italy, Our second experiment was set up to examine the perfor-
it correctly maps them to concepts such as Society/Govern- mance of the generated features alone, without the bag of
ment/Finance, Society/Issues/Economic/International/Trade, words (GEN curve in Figures 3 and 4). For Movies, dis-
Business/International Business and Trade. Due to these carding the BOW features hurts the performance somewhat,
features, which were also generated for training documents but the decrease is far less signiﬁcant than what could be
in this category, the document is now categorized correctly. expected—using only the generated features we lose less than
                                                      3% in BEP compared with the BOW baseline. For 20NG, a
3.5  The Effect of Contextual Analysis                similar experiment sacriﬁces about 10% off the BOW per-
We now explore the various possibilities to deﬁne document formance, as this dataset is known to have a very diversi-
contexts for feature generation. Figure 2 shows how text ﬁed vocabulary, for which many studies found feature selec-
categorization performance on the Movies dataset changes tion to be particularly harmful. However, the situation is re-
for various contexts. The x-axis measures context length in versed for both Reuters datasets. For Reuters-21578, the gen-
words, and the FG/words curve corresponds to applying the erated features alone yield a 0.3% improvement in micro- and