                                 Sparse-Memory Graph Search 

                                    Rong Zhou and Eric A. Hansen 
                            Department of Computer Science and Engineering 
                        Mississippi State University, Mississippi State, MS 39762 
                                  {rzhou,hansen}@cse.msstate.edu 


                     Abstract                          a "boundary" in the search graph that prevents previously 
                                                       closed nodes from being revisited. This is the strategy 
    We describe a framework for reducing the space 
                                                       adopted by a pair of recent search algorithms [Korf, 1999; 
    complexity of graph search algorithms such as A* 
                                                       Korif and Zhang, 2000], which are related to earlier work 
    that use Open and Closed lists to keep track of the 
                                                       on reducing the memory requirements of dynamic program•
    frontier and interior nodes of the search space. We 
                                                       ming algorithms for sequence comparison [Hirschberg, 1975; 
    propose a sparse representation of the Closed list 
                                                       Myers and Miller, 1988]. If not all expanded nodes are stored 
    in which only a fraction of already expanded nodes 
                                                       in a Closed list, an alternative method of solution extraction 
    need to be stored to perform the two functions of 
                                                       is needed - since closed nodes along an optimal solution path 
    the Closed List - preventing duplicate search effort 
                                                       may no longer be in memory when the search ends. So, these 
    and allowing solution extraction. Our proposal is 
                                                       algorithms preserve information about nodes that are in the 
    related to earlier work on search algorithms that do 
                                                       middle of a solution path. After the search ends, they use this 
    not use a Closed list at all [Korf and Zhang, 2000]. 
                                                       information to divide the original problem into sub-problems 
    However, the approach we describe has several ad•
                                                       - employing a divide-and-conquer strategy to recursively re•
    vantages that make it effective for a wider variety 
                                                       construct an optimal solution path. This approach to reduc•
    of problems. 
                                                       ing memory requirements results in an algorithm with two 
                                                       distinct phases; the first phase searches from the start to the 
1 Introduction                                         goal node, and the second phase uses a divide-and-conquer 
                                                       method to reconstruct an optimal solution path. 
Graph search algorithms such as Dijkstra's algorithm and A* 
                                                         In this paper, we describe some improvements of this 
use an Open list to store nodes on the search frontier, and 
                                                       search strategy. Earlier search algorithms that use this strat•
a Closed list to keep track of already expanded nodes. The 
                                                       egy do not store a Closed list at all [Korf, 1999; Korf and 
Closed list performs two important fiinctions. 
                                                       Zhang, 2000]. Instead they include extra information in open 
  1. It allows the optimal solution path to be reconstructed nodes, and even insert additional nodes into the Open list, 
    after completion of the search by tracing pointers back• to ensure that it forms a "boundary" that prevents "leaks" 
    wards from the goal node to the start node.        back into the closed region. Instead of adding information 
  2. In graph search problems, it allows nodes that have al• to the Open list, our algorithm preserves some already ex•
    ready been reached along one path to be recognized if panded nodes in a Closed list - but only enough to create a 
    they are reached along another path, in order to prevent boundary and allow efficient solution reconstruction. Much 
    duplicate search effort.                           of the closed region of the search can be removed from mem•
                                                       ory. Thus, we call this a sparse representation of the Closed 
Although both functions are important, storing all expanded 
                                                       list, and a sparse-memory approach to graph search. We show 
nodes in a Closed list can quickly use all available memory. 
                                                       that it results in a more flexible approach to reducing memory 
  If one is willing to give up the ability to recognize when 
                                                       requirements that offers several advantages. 
the same node is reached along different paths, IDA* and 
RBFS can solve search problems in linear space [Korf, 1985; 
1993]. Related search algorithms provide a limited abil• 2 Background 
ity to prevent duplicate search effort by storing a limited The most closely related algorithms to the search algorithm 
number of expanded nodes [Reinefeld and Marsland, 1994; we introduce in this paper are Divide-and-Conquer Bidirec•
Miura and Ishida, 1998]. In complex graph search problems tional Search (DCBS) [Korf, 1999] and Divide-and-Conquer 
with many duplicate paths, however, an inability to prevent Frontier Search (DCFS) [Korf and Zhang, 2000]. Although 
all duplicate search effort often leads to poor performance. both are general graph-search algorithms, they were devel•
  Fortunately, it is not necessary to store all expanded nodes oped as an approach to performing multiple sequence align•
in a Closed list in order to eliminate all duplicate search ef• ment, and the memory-saving technique they use was first 
fort. It is only necessary to store enough nodes to form used by related dynamic programming algorithms for se-


SEARCH                                                                                                1259  quence comparison [Hirschberg, 1975; Myers and Miller,        expansion, only operators that are not among the forbidden 
 1988]. To provide some perspective, we begin with a brief     operators are used to generate its successor nodes. This pre•
 description of the multiple sequence alignment problem. For   vents the search from re-generating nodes that may have been 
 a detailed description of this problem, we refer to our refer• already closed and removed from memory. However, a com•
 ences.                                                        plication arises in the case of directed graphs - in particu•
                                                               lar, directed graphs in which a node can have predecessors 
 2.1 Multiple sequence alignment                               that are not also potential successors. If a node is expanded 
 Alignment of multiple DNA or protein sequences is an im•      and removed from memory before all of its predecessors have 
 portant problem in computational biology. It provides a way   been generated and inserted into the Open list, it can be re•
 to measure the similarity between sequences and detect re•    generated if one of these predecessor nodes is later expanded. 
 lated segments. Alignment involves inserting gaps into se•    To prevent this, DCFS modifies the Open list in a second way. 
 quences in order to maximize the number of matching "char•    When a node is expanded, it generates not only its successor 
 acters." It is well-known that this problem can be formal•    nodes, but all of its predecessor nodes - even if the search has 
 ized as a shortest-path problem in a n-dimensional lattice,   not yet found a path to these predecessor nodes. If there is not 
where n is the number of sequences to be aligned. The          yet a legal path to these predecessor nodes, they are assigned 

number of nodes in the lattice is ln, where / is the aver•     an infinite /-cost to prevent them from being expanded until 
age length of sequences, and thus grows polynomially with      a legal path is found. 
the length of sequences, and exponentially with the num•         To make it possible to reconstruct the solution path at the 
ber of sequences. Although dynamic programming is the          end of the search, DCFS modifies nodes in a further way. In 
traditional method for solving this problem, A* has been       each node past the midpoint of the search, it stores all in•
shown to outperform it by using an admissible heuristic to     formation about a node on its path that is about halfway be•
limit the number of nodes in the lattice that need to be ex•   tween the start and goal node. Then, when the search is com•
amined to find an optimal alignment [Ikeda and Imai, 1999;     pleted, DCFS knows a middle node on the optimal solution 
Lermen and Reinert, 2000]. But given the large number of       path, and can reconstruct the solution path by a divide-and-
nodes that usually must be examined, memory is a bottleneck,   conquer approach. Using the same search algorithm, it recur•
and techniques for solving this problem in reduced memory      sively solves the subproblems of finding an optimal path from 
can be very helpful.                                           the start node to the middle node, and then from the middle 
                                                               node to the goal node. This recursive method of solution re•
2.2 Divide-and-conquer frontier search                         construction is essentially the divide-and-conqucr idea first 
Both Divide-and-Conquer Bidirectional Search proposed by Hirschberg [1975]. 
(DCBS) [Korf, 1999] and Divide-and-Conquer Frontier 
Search (DCFS) [Korf and Zhang, 2000] use the same              2.3 Limitations 
strategy for reducing memory requirements. The difference      Korf and Zhang [2000] show that DCFS can be very effec•
is that DCBS uses bidirectional search and DCFS uses           tive in "problem spaces that grow polynomially with prob•
unidirectional search. Korf and Zhang [2000] find that         lem size, but contain large numbers of short cycles," includ•
unidirectional search results in better performance, and so    ing path-planning in two-dimensional grids and multiple se•
we refer to DCFS in the rest of this paper.                    quence alignment, assuming a small number of sequences. 
   DCFS reduces memory requirements by storing only the        They acknowledge that their search algorithm is not as ef•
frontier nodes of the search, not the interior nodes - that is, fective in an "exponential problem space with a branching 
by using an Open list but not a Closed list. Because it does not factor of two or more." In that case, they explain, the Open 
use a Closed list, DCFS must use some other method to avoid    list is much larger than the Closed list and "not storing the 
duplicate node expansions and to extract an optimal solution   Closed list doesn't save much." In fact, the multiple sequence 
path at the end of the search. The problem of avoiding dupli•  alignment problem is an exponential problem space (and NP-
cate node expansions is particularly important in the case of  complete [Just, 2001]), when the number of sequences to be 

multiple sequence alignment because there are combinatori-     aligned is not bounded. Its branching factor is 2n — 1 (where n. 
ally many paths from the start node to any other node. For     is the number of sequences), and the size of the Open list can 
this reason, linear-space search algorithms that do not test for dwarf the size of the Closed list when aligning as few as five 
duplicates, such as IDA*, have "pitiful results" (in the words or six sequences. This problem is well-known and has moti•
of Korf [1999]), when used for multiple sequence alignment.    vated development of techniques for reducing the size of the 
Even bounded-memory search algorithms that detect some         Open list when using A* to align multiple sequences. These 
but not all duplicates have been reported to perform poorly    include use of an upper bound to prune open nodes that can•
on this problem [Yoshizumi et ai, 2000].                       not lead to an optimal solution [Ikeda and Imai, 1999], and 
  To avoid duplicate node expansions, DCFS uses the fol•       use of partial node expansions [Yoshizumi et al., 2000]. 
lowing techniques to prevent the search from "leaking" back      As it turns out, it is difficult to combine DCFS with tech•
into the closed region, that is, to prevent closed nodes from  niques for reducing the size of the Open list without creating 
being re-generated. First, it stores in each node a list of for• inefficiencies, or even "leaks" back into the closed region. It 
bidden operators. This list includes one operator for each     is possible to combine DCFS with Partial Expansion A*, a 
neighbor (predecessor or successor) of this node that has al•  technique for reducing the size of the Open list by allowing 
ready been generated. When the node is later selected for     partially expanded nodes [Yoshizumi et al., 2000]. This can 


1260                                                                                                            SEARCH be beneficial in some cases. But allowing nodes to be partially 
expanded has the effect of reducing the number of nodes that 
are closed. In turn, this reduces the memory-saving effect 
of DCFS by reducing the number of nodes eligible to be re•
moved from memory, as our experimental results will show. 
   Another approach to reducing the size of the Open list is 
to prune open nodes when their /-cost is greater than an up•
per bound on the optimal /-cost, as in Enhanced A* [Ikeda 
and Imai, 1999]. Because this technique does not reduce the 
number of closed nodes, the idea of combining it with DCFS 
appears more promising. However, it introduces other dif•
ficulties. Recall that DCFS generates all predecessors of a 
node when it is expanded, even if it has not yet found a path  Figure 1: An illustration of the relationships among the kernel 
to these predecessors. If nodes are pruned from the Open       and the boundary of the search interior, the search frontier, 
list, no path may ever be found to these extra nodes, and the  and the entire state space. 
Open list may become cluttered with useless nodes that can 
never be removed. In directed graphs with the special prop•
erty that the set of successors of each node is disjoint from the A key difference from DCFS is that our algorithm does 
set of predecessors, such as the search graph of the multiple  not entirely eliminate the Closed list. Instead, we propose 
sequence alignment problem, this inefficiency is the only neg• a sparse representation of the Closed list that allows many 
ative effect of pruning the Open list. But in directed graphs  (but not all) closed nodes to be removed from memory. To 
that do not share this property, and in all undirected graphs, explain our approach, we note that the search interior (the set 
pruning nodes from the Open list can also result in "leaks"    of closed nodes) can be partitioned into two disjoint subsets 
back into the closed region, as follows. The first time a node that we call the set of boundary nodes and the kernel of the 
is generated, there is no guarantee that the best path to it has search interior. 
been found. So, if it is pruned using an upper bound, it may   Definition 1 Let I be the set of search interior nodes, i.e., 
later be re-generated if a better path to it is found. But since nodes whose lowest-cost paths have been found. The kernel 
the forbidden operators associated with the node when it was   of I, denoted K (I), is defined as follows: 
first generated were lost when it was pruned, a node that was 
previously closed could be re-generated. 
   The difficulty of combining DCFS with techniques for re•    where Pred(k) denotes the set of predecessor nodes ofk, that 
ducing the size of the Open list is a significant limitation.  is, the set of nodes that can make a transition into node k in 
Another potential limitation worth mentioning is the over•     the underlying graph, which may be directed or undirected. 
head for storing a list of forbidden operators in each node. 
                                                               Basically, the kernel is the set of nodes whose predecessor 
For problems with a small branching-factor, this overhead is 
                                                               nodes are all interior (i.e., closed) nodes. 
slight. But for the multiple sequence alignment problem, this 
overhead grows as the number of sequences grows. Recall        Definition 2 The set of boundary nodes of search interior I, 
that the number of operators (i.e., the branching factor) of   denoted B(I), is defined as the non-kernel nodes of l, that is: 
multiple sequence alignment is and DCFS stores in•
coming as well as outgoing edges in the list of forbidden op•
erators. Thus, the total number of edges incident to a node is Another way of describing a boundary node is to say that at 
                           Although Korf and Zhang [2000]      least one of its predecessor nodes is not an interior node, or 
claim that the space complexity of DCFS for multiple se•       mathematically, 
quence alignment is compared to the space 
complexity of A*, this claim rests on the assumption that a 
node takes constant storage. As n increases, the storage re•   Figure 1 illustrates the relationship between the kernel and 
quired for the list of forbidden operators increases exponen•  boundary of the search interior. Note that nodes in the bound•
tially. In fact, the space complexity of DCFS for mulitple     ary can enter the kernel, but once a node is in the kernel it 
sequence alignment is and its advantage over the               remains there. The nodes in the kernel are eligible for re•
      space complexity of A* disappears when                   moval from memory because they are not needed to prevent 
                                                               duplicate search effort. 
3 Sparse-Memory Search Algorithm                                 The intuitive meaning of "boundary" can be explained as 
                                                               follows. Because every closed node is reachable from the 
The algorithm we describe in the rest of this paper adopts     start node, the set of closed nodes can be considered a "vol•
a strategy for reduced-memory search that is similar to the    ume" in the underlying graph that encompasses the starting 
strategy used by DCFS. However, it implements this strategy    node. Nodes outside this volume cannot reach nodes inside 
in a simpler way that is more compatible with techniques for   the volume without passing through some node in the bound•
reducing the size of the Open list, and does not require storing ary. Thus, storing only the boundary nodes in the Closed list 
lists of forbidden operators in nodes.                         is as effective as storing the entire "volume," with respect to 


SEARCH                                                                                                              1261 preventing the search from "leaking" back into the closed re•
gion. (From this perspective, one could say that DCFS adds 
nodes to the Open list - i.e., the search frontier - in order 
to ensure that the frontier forms a boundary, and it treats the 
Closed list as the kernel that can be removed from memory.) 
   In addition to keeping boundary nodes in the Closed 
list, our sparse-memory approach keeps some other, non-
boundary nodes that allow solution reconstruction. The 
method of solution reconstruction is different from the one 
used by DCFS. Recall that DCFS stores in each node all infor•
mation about a "middle" node on the path through this node 
to the goal. In our approach, each node in the search graph 
maintains a pointer to its predecessor node along the best path 
to this node, or to some earlier, ancestral node along this 
path} In the latter case, we have a sparse solution path. 


If a node in a sparse solution path has a pointer to an an•
cestral node instead of a pointer to its predecessor, we call 
the ancestral node a relay node to indicate that it skips over 
some nodes in an original, "dense" solution path. We also 
consider the start node (which has no backward pointer) a re•
lay node. How relay nodes are created and used in solution 
reconstruction is explained below. Here, we simply note that 
relay nodes are never removed from the Closed list because 
they are needed for solution reconstruction. Thus, a sparse 
representation of the Closed list includes all boundary nodes 
and all relay nodes. Nodes that do not fall in either category 
may be removed from memory. 
   It is well-known that A* can be viewed as Dijkstra's al•
gorithm applied to a transformed graph with the same set 
of nodes and edges, but modified edge costs given by the 
equation where  
            is the cost of edge in the untransformed 
(or transformed) graph and is the cost esti•
mate of the lowest-cost path from node u (or v) to the goal 
node. Therefore, we present our sparse-memory algorithm as 
a modification of Dijkstra's algorithm, and note that our de•
scription applies to A* also. Our sparse-memory approach 
requires two assumptions. First, the transformed (or untrans•
formed) graph cannot contain any negative-cost edges. This 
means the heuristic used by A* must be consistent. With•
out this assumption, it is impossible for our algorithm (or any 
heuristic search algorithm) to accurately identify the interior 
of the search, and DCFS makes the same assumption. Sec•
ond, we assume that our algorithm knows the in-degree (in 
the underlying graph) of every node it visits. For comparison, 
DCFS assumes that it knows every predecessor (in the under•
lying graph) of a node it visits. Thus, our second assumption Figure 2: Pseudocode for SMGS (Sparse-Memory Graph 
is weaker than that made by DCFS.                             Search), in which procedure ExpandNode assumes a directed 
                                                              graph. See Figure 3 for the pseudocode of ExpandNode in 
    Because pointers require less memory than state information undirected graphs. 
about a midpoint node, the memory required to store all pointers 
plus relay nodes could be less than the memory required to copy state 
information about the same midpoint node into many other nodes. 


1262                                                                                                           SEARCH 3.1 Pruning the Closed list 
Our search algorithm must be able to efficiently distinguish 
between the kernel and boundary of the search interior, in 
order to prune nodes from the kernel. Recall that a node is 
in the kernel if all of its predecessors are closed. To identify 
such nodes, we introduce a technique for keeping track of the 
number of unexpanded predecessors for each generated-and-
stored node. We call this number the value of a node. It is 
initially set to the number of predecessors (the in-degree) of 
the node in the underlying graph minus one to account for the 
predecessor that generated it. The is updated during 
node expansion. As each successor of a node is considered 
(some of which may already be in the Open or Closed lists), 
its p- value is decremented. (See lines 3, 8 and 10 of procedure 
ExpandNode in Figure 2.) This requires negligible time and 
space overhead, and, given kernel-membership for a 
node can be determined in constant time by checking whether    Figure 3: Pseudocode for ExpandNode in undirected graphs. 
it is a closed node with a of zero. 
   An advantage of the sparse-memory approach is that it       new start and goal nodes, in order to get a dense solution path 
does not immediately remove closed nodes from memory, un•      between the two which is added to the tail of DSP (line 17). 
like DCFS. A sparse-memory version of Dijkstra's algorithm       Another difference from DCFS that is worth noting is that 
(or A*) acts exactly like Dijkstra's algorithm (or A*) until   DCFS divides a problem into two subproblems at each level 
it senses that memory is about to be exhausted. Only then      of the recursion. The sparse-memory approach can divide a 
does it invoke procedure PruneClosedList in Figure 2 to re•    problem into two or more subproblems. The extra flexibility 
cover memory. This procedure prunes nodes from the Closed      is possible because the sparse-memory approach uses relay 
list in two steps. First it updates the ancestral pointer of any nodes with ancestral pointers, whereas DCFS stores all infor•
boundary node whose predecessor is about to be pruned (lines   mation about a middle node in each node. When a problem 
 1-8). This is necessary to allow solution reconstruction and  is divided into more than two subproblems, the subproblems 
requires finding the relay node that is the closest boundary   are smaller and easier to solve and solution reconstruction can 
node along its solution path (lines 3-5), and updating its an• be faster. In fact, relay nodes can be spaced at half intervals, 
cestral pointer accordingly (line 7). This makes this boundary one-third intervals, or any other interval, and allow a tradeoff 
node a relay node, and to prevent it from being pruned in the  between the sparseness of the search interior and the speed of 
future, its is set to(line 8). After this step, kernel         solution reconstruction. 
nodes are pruned unless they are a start node or relay node 
created in a previous pruning step (lines 9-12). Updating the  3.3 Pruning the Open list 
ancestral pointers of nodes (followed by pruning) creates a 
sparse solution path, from which a complete or "dense" solu•   We now consider how easily the sparse-memory approach to 
tion path can be reconstructed after the search terminates.    pruning the Closed list can be combined with techniques for 
                                                               pruning the Open list. Pruning nodes on the Open list that 
                                                               have an /-cost greater than an upper bound on the optimal 
3.2 Solution Path Reconstruction 
                                                               /-cost creates difficulties for DCFS, as discussed earlier. An 
The fact that the Closed list is not pruned unless memory is   advantage of the sparse-memory approach is that it does not 
close to being exhausted means that the overhead of solution   create difficulties, at least in solving problems for which the 
reconstruction can be avoided if memory resources are ade•     set of predecessors of a node is disjoint from the set of succes•
quate. In that case, the sparse-memory algorithm acts exactly  sors, such as the multiple sequence alignment problem. This 
like Dijkstra's algorithm (or A*) and an optimal solution path advantage will be illustrated in our experimental results. 
is extracted in the conventional way.                            For other directed graphs, that is, for directed graphs in 
   If the Closed list has been pruned, an optimal solution     which the same node can be both predecessor and succes•
path is reconstructed by invoking the Sparse-Memory Graph      sor of another node, DCFS allows leaks back into the closed 
Search algorithm (SMGS) in Figure 2 recursively. First the     region when the Open list is pruned. The sparse-memory ap•
sparse solution path (SSP) is extracted (line 11) in the con•  proach does not, and this is another advantage. Unfortunately, 
ventional way by tracing pointers backward from the goal.      the sparse-memory approach has a problem in such graphs. 
Then the corresponding dense solution path (DSP) is re•        If the best path to a node has not been found when it is first 
constructed as follows. For each pair of consecutive nodes     generated, it could be pruned and re-generated later, when a 
                        in the SSP (starting from the start    better path is found. Since are erased when the node 
node), the algorithm checks to see if is a pre•                is pruned, the of such nodes will not be decremented 
decessor of (line 14). If so, nodeis added to                  to zero. As a result, the sparse-memory algorithm may not 
the tail of the DSP (line 15); otherwise, the search algorithm recover as much memory from the Closed list. However, our 
calls itself recursively with and as the                       experimental results suggest that this inefficiency is minor. 


SEARCH                                                                                                              1263 