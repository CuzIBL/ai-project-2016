                       Item Selection Strategies for Collaborative Filtering 

                                           Rachael Rafter, Barry Smyth 
                           Smart Media Institutce, University College Dublin, Ireland 
                                        {rachae 1.rafter, barry.smyth } @ucd.ie 


 1 Introduction                                                However, naive item selection strategies are likely to result 
                                                               in significant reductions in recommendation accuracy and so 
Automated collaborative filtering (ACF) methods leverage 
                                                               more intelligent strategies, based on an understanding of the 
the ratings-based profiles of users that are similar to some 
                                                               relative value of different items, are proposed. 
target user in order to proactively select relevant items, or 
predictively rate specific items, for the target user. Many of 
the advantages of ACF methods are derived from its content-    2 Item Selection Strategies 
 free approach to recommendation; it is not necessary to rely  Let us assume that for reasons of efficiency it is necessary to 
on content-based descriptions of the recommendable items,      select a subset of k shared items for consideration during ACF 
only their ratings distribution across the population of raters. prediction using Resnick's algorithm. Which subset should 
 Furthermore, ACF methods have an element of serendipity       be chosen? One could select the k items at random. Alter•
associated with them, as users can find items for which they   natively one to look to identify those items that are likely to 
would never have explicitly searched but nonetheless find in•  contribute more information to the prediction task. 
teresting. The raters, items and ratings form an sparse ma•
trix, R and the classical ACF prediction task is to predict    2.1 Inverse Popularity 
the rating that user t will give to item i given that Rltl is 
currently empty. For example, Resnick's well-known algo•       One approach to selecting useful items during ACF predic•
                                                               tion is to look at how popular an item is among the rater 
rithm [Resnick et al, 1994] predicts Rt,i based on t's average 
rating, and the rating each rater r gives to i, relative       population. The motivation here lies in the belief that rela•
                                                               tively poorly distributed items among the population should 
to r's average rating, and weighted by the correlation 
                                                               be better predictors of a users preferences [Rafter and Smyth, 
between the shared ratings of t and r. 
                                                               2001b]; if a user has looked at an unusual item this should 
                                                               tell us more about her preferences than an item that everyone 
                                                               is familiar with. For example in a movie recommendcr, most 
                                                               people will have seen movies like "The Lord of the Rings" 
   It is well known that the success of ACF depends broadly    or "Fight Clubhand therefore most profiles will contain these 
                                                               movies, but all this really tells us is that these are popular 
speaking, on the quality of the user profiles and on the cov•
                                                               movies. However if a user profile contains more unusual 
erage of the ratings space that they provide [Smyth et al, 
                                                               movies such as "Run Lola Run" or "Buffalo 66", that most 
2002; Rafter and Smyth, 2001a; Rafter et al, 2000a; 2000b; 
                                                               other profiles don't contain, then we can tell more about that 
Herlocker et al, 1999; Breese et al, 1998; Konstan et al, 
                                                               user's individual taste for movies. Accordingly, our inverse 
 1997]. At the same time efficiency depends on the number 
                                                               popularity strategy weights the items in a profile according to 
of users that are taken into account during rating and the size 
                                                               the number of users in the population that have that item in 
of their individual profiles. For example, Resnick's algorithm 
                                                               their profile and selects those k items, shared between rater 
is 0(r.i) where r is the number of raters and i the average 
                                                               and target user, that have the highest inverse popularity score 
number of items that they have rated. 
                                                               (Equation 2). 
   In this paper we are interested in looking for ways to im•
prove the efficiency of ACF without compromising the qual•
ity of recommendations. Our basic proposal is to find ways                                                            (2) 
of reducing the number of items that need to be considered 
during recommendation. For example, Resnick's algorithm 
                                                               2.2 Deviation of Ratings 
above compares each rater profile to the target user by com•
puting the correlation between all item ratings that these pro• The deviation of ratings strategy is based on the principle that 
files share, which can often be a large number of ratings.     the more users tend to disagree about an item the more infor•
By selecting a subset of shared ratings we can significantly   mative that item is about any given user's particular prefer•
improve the efficiency of this fundamental prediction step.    ences. For example, in a movie recommender most users will 


POSTER PAPERS                                                                                                       1437  give a movie like "The Shawshank Redemption" a high rat•
 ing and so there is little to be gained by comparing users along 
 this dimension. However, by the same token, there may tend 
 to be a lot of disagreement about "Vanilla Sky", and knowing 
 whether a user likes or dislikes this movie is likely to tell us a 
 lot about this user. 
   One way to take account of the above idea is to weight 
 items according to the standard deviation of their ratings 
 across the user population. Items that have a high standard 
 deviation in their ratings (ri) (a lot of disagreement) get a 
 high weight, and items with a lot of agreement (low standard 
 deviation) get a low weight (Equation 3). Once again, using 
 this strategy, we can prioritise the selection of the k shared 
 items. 


                                                                         Figure 1: Average prediction error v. .v. k 
3 Experimental Evaluation 

 An experimental evaluation has been carried out to evaluate     It is interesting to note that for k = 100 the prediction 
how our inverse popularity and deviation of ratings selection  accuracy of the various techniques is seen to converge, indi•
strategies impact prediction quality. To do this we have im•   cating that there is little difference in the selection benefits 
plemented a version of Resnick's ACF algorithm and modi-       for item subsets of this size. However, the average overlap of 
fled it to select different sized subsets of shared items as the the population is 116.75 meaning that at the k = 100 mark 
basis for prediction. Four different item selection strategies almost all overlapping items are being considered by any of 
are reported:                                                  the four strategies and therefore it is appropriate that the ac•
   • All selects all shared items as per the standard Resnick  curacy converges. In point of fact it is appropriate that item 
     approach.                                                 selection strategies work well at low values of k for two rea•
                                                               sons. First, it maximises the potential efficiency advantages. 
   • Random selects a random subset of A: shared items. 
                                                               Secondly, most profiles tend to have relatively small numbers 
   • Popularity selects a subset of k shared items according   of ratings and so the shared ratings between two profiles is 
     to the inverse popularity metric.                         likely to be small; in EachMovie more than 90% of profiles 
   • Deviation selects a subset of k shared items according to have less than 100 ratings. 
     the deviation of ratings metric. 
   In turn we evaluated the above methods using a subset of    4 Conclusions and Future Work 
the largest 2050 profiles (2000 as the user population, and 50 We have described two item selection strategies for ACF (De•
as the target users) from the EachMovie dataset, [McJones,     viation and Popularity) that reduce the set of items used when 
 1997]. From each target user profile we selected 10 items at  making predictions. We have discussed how these strategies 
random (500 in total) for which to predict scores measuring    improve the efficiency of ACF and our evaluation has shown 
the quality of the prediction as the average prediction error  that these improvements incur little compromise in the qual•
by computing the difference between the predicted rating and   ity of prediction, when compared with the standard Resnick 
the actual rating in the standard way. In addition, we vary the algorithm. The results also show that our strategies outper•
value of k from 5 to 100 to investigate the impact of different form the naive Random strategy and therefore are selecting 
profile subset sizes.                                          a more intelligent subset of items. Efficiency in ACF is a 
   The results are presented in Figure 1 as graphs of average  well documented problem and we believe that item selection 
prediction error versus k for each of the 4 selection strategies strategies such as those proposed in this paper are one of the 
(All, Random, Popularity, Deviation). The results for All are  keys to solving efficiency problems. In the future we look to 
obviously a straight line as this strategy in unaffected by k by investigating other similar item selection strategies (such as 
design. The error for this strategy serves as an optimal bench• combining the Popularity and Deviation methods), based on 
mark against which to judge the other 3 techniques. In each    a further understanding of the relative values of items. 
case we find that the Popularity and Deviation techniques sig•   The development of item selection strategies such as those 
nificantly outperform the naive Random selection approach.     we have described forms part of a larger research goal con•
For example, at A: = 25 the Random method presents with a      cerning the value of items in ACF. In any ACF prediction or 
prediction error of about 0.207 compared to errors of 0.185    recommendation task we can imagine three distinct beneficia•
and 0.186 for the Popularity and Deviation methods, and a     ries. The first and most obvious beneficiary is the target user, 
minimum error of 0.183 for the All benchmark. A similar       the person for whom the prediction is being made. The sec•
pattern is found for k < 50.                                  ond is the party making the recommendation - for example, 


1438                                                                                                   POSTER PAPERS an online store whose desire it is to make recommendations       Techniques for Web Personalization (ITWP2001), Seattle, 
to the target user and encourage them to purchase something.     Washington, U.S.A., August 2001. 
Finally the ACF system itself is also a potential beneficiary in 
                                                              [Rafter and Smyth, 2001b] R. Rafter and B. Smyth. Towards 
the sense that with each prediction or recommendation made 
                                                                 a domain analysis methodology for collaborative filtering. 
the system learns a new piece of information about the user.     In Proceedings of 23rd European Colloquium on Informa•
In such a situation where three distinct parties can potentially tion Retrieval Research (ECIROI), Darmstadt, Germany, 
benefit from the outcome of the recommendation, there are        April 2001. 
clear trade-offs. For example, the online store may prefer to 
recommend expensive items over cheaper alternatives to cus•   [Rafters al, 2000a] R. Rafter, K. Bradley, and B. Smyth. 
tomers and even weight items for recommendation not only         Automated collaborative filtering applications for online 
according to their relevancy to the customer but also accord•    recruitment services. In Proceedings of the International 
ing to their price. Conversely, the user is unlikely to opt for  Conference on Adaptive Hypermedia and Adaptive Web-
such a recommendation strategy. The trade-off we are most        based Systems, Trento, Italy, August 2000. 
interested in investigating is that of optimising recommenda• [Rafter et al., 2000b] R. Rafter, K. Bradley, and B. Smyth. 
tions for short-term benefit against optimising them for long-   Personalised retrieval for online recruitment services. In 
term benefit. The straightforward recommendation strategy is     Proceedings of the 22nd Annual Colloquium on Informa•
to select the item with the highest relevancy for the target user tion Retrieval (IRSG2000), Cambridge, UK, April 2000. 
(i.e. the one she is most likely to like) for recommendation. 
                                                              [Resnick et al, 1994] P. Resnick, N. Iacovou, M. Suchak, 
This optimises recommendations on a short-term basis - the 
                                                                 P. Bergstrom, and J. Reidl. GroupLens: An open architec•
best option is selected for the current recommendation. How•
                                                                 ture for collaborative filtering of netnews. In Proceedings 
ever, if we were to weight recommendations not only based 
                                                                 of ACM Conference on Computer-Supported Cooperative 
on the probability of the user liking them, but also based on 
                                                                 Work (CSCW94), Chapel Hill, North Carolina, USA, Au•
the amount of knowledge the system is likely to gain with 
                                                                 gust 1994. 
each recommendation we could potentially make better rec•
ommendations in the future.                                   [Smythetal, 2002] B. Smyth, K. Bradley, and R. Rafter. 
  Our research so far has shown that different items have dif•   Personalization techniques for online recruitment services. 
ferent levels of knowledge gain. Relatively unpopular items,     Communications of the ACM, 45(5):39^0,2002. 
or those that tend to have a high deviation of ratings tell us 
more about the user and her preferences than an item that ev•
eryone has seen and liked. In the future we plan to look at 
the potential benefit of weighting items not only according to 
their relevance to the user, but also according to their associ•
ated knowledge gain, and investigating how such a strategy 
affects the quality of future predictions. 

References 
[Breese et ai, 1998] J. Breesc, D. Heckerman, and C. Kadie. 
  Empirical analysis of predictive algorithms for collabora•
  tive filtering. In Proceedings of 14th Conference on Uncer•
  tainty in Artificial Intelligence, Madison, Wisconsin, USA, 
  July 1998. 
[Herlocker et al., 1999] J. Herlocker, J. Konstan, 
  A. Borchers, and J. Reidl. An algorithmic framework 
  for performing collaborative filtering. In Proceedings of 
  the 22nd Annual International ACM SIGIR Conference 
  on Research and Development in Information Retrieval, 
  Berkeley, California, USA, August 1999. 
[Konstan et al, 1997] J. Konstan, B. Miller, D. Maltz, 
  J. Herlocker, L. Gordon, and J. Reidl. Grouplens: Apply•
  ing collaborative filtering to Usenet news. Communications 
  of ACM, 40(3):77-87, March 1997. 
[McJones, 1997] P. McJones. Eachmovie col•
  laborative filtering data set. Available from 
  http://research.compaq.com/SRC/eachmovie/, 1997. 
[Rafter and Smyth, 2001a] R. Rafter and B. Smyth. Passive 
  profiling from server logs in an online recruitment envi•
  ronment. In Proceedings oflJCAI Workshop on Intelligent 


POSTER PAPERS                                                                                                      1439 