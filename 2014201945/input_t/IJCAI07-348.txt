       Inferring Long-term User Properties based on Users’ Location History
                      Yutaka Matsuo     and  Naoaki Okazaki    and  Kiyoshi Izumi
              and  Yoshiyuki Nakamura     and  Takuichi Nishimura     and  Koitiˆ Hasida
                   National Institute of Advanced Industrial Science and Technology
             y.matsuo@aist.go.jp, {kiyoshi, nmura, taku}@ni.aist.go.jp, hasida.k@aist.go.jp

                                         Hideyuki Nakashima
                                      Future University, Hakodate
                                        h.nakashima@fun.ac.jp
                    Abstract                          in a laboratory might imply working behavior for laboratory
                                                      members. While for different types of users such as guests
    Recent development of location technologies en-   for a campus tour, being in a laboratory implies sightseeing
    ables us to obtain the location history of users. This behavior. Therefore, user modeling and behavior detection
    paper proposes a new method to infer users’ long- are mutually complementary: if we have a more precise user
    term properties from their respective location histo- model, we can guess more precisely the user behavior, and
    ries. Counting the instances of sensor detection for vice versa. Automatically obtaining a user model will boot-
    every user, we can obtain a sensor-user matrix.Af- strap activity recognition in a ubiquitous environment to en-
    ter generating features from the matrix, a machine able context-aware information services.
    learning approach is taken to automatically classify
                                                        Toward user modeling for ubiquitous computing, several
    users into different categories for each user prop-
                                                      studies have been done in recent years. Heckmann pro-
    erty. Inspired by information retrieval research, the
                                                      poses the concept of ubiquitous user modeling [Heckmann,
    problem to infer user properties is reduced to a text
                                                      2005]. He proposes a general user model and context ontol-
    categorization problem. We compare weightings
                                                      ogy GUMO  and a user model and context markup language
    of several features and also propose sensor weight-
                                                      UserML that lay the foundation for inter-operability using Se-
    ing. Our algorithms are evaluated using experimen-
                                                      mantic Web technology. Carmichael et al. proposes a user-
    tal location data in an ofﬁce environment.
                                                      modeling representation to model people, places, and things
                                                      for ubiquitous computing, which supports different spatial
1  Introduction                                       and temporal granularity [Camichael et al., 2005].
Context-aware computing are gaining increasing interest in This paper describes an algorithm to infer a user’s long-
the AI and ubiquitous computing communities. To date, nu- term properties such as gender, age, profession, and interests
merous approaches have been taken to recognize and model from location information. The system automatically learns
a user’s external context, for example one’s location, physi- patterns between users’ locations and user properties. Conse-
cal environment, and social environment, to provide context- quently, the system can infer properties: it can automatically
dependent information. Though “context” is a slippery no- produce a user model of a new user coming to the environ-
tion [Dourish, 2004], it is promising if we can recognize and ment. We show that some properties are likely to be inferred
adapt to aspects of users such as their activities, general in- and others are difﬁcult to infer. The algorithm is useful in
terests, and current information needs [Jameson and Kruger, various ubiquitous computing environments to provide user
2005]. Such user models are useful for personalized informa- modeling for personalized information services.
tion services in ubiquitous computing.                  We address users’ long-term properties, especially among
  Recently, location information has become widely avail- many user-modeling dimensions. Kobsa lists frequently
able both in commercial systems and research systems. De- found services of user-modeling, some of which utilize users’
vices such as Wi-Fi, Bluetooth, low-cost radio-frequency tags long-term characteristics such as knowledge, preference, and
and associated RFID readers, and ultrasound devices all pro- abilities [Kobsa, 2001]. Jameson discusses how different
vide location-based information support in various situations types of information about a user, ranging from current con-
and environments. One early and famous project was Ac- text information to the user’s long-term properties, can con-
tive Badge [Want et al., 1992]. Since that work, numer- tribute simultaneously to user adaptive mechanisms [Jame-
ous studies of users’ activity recognition and location-aware son, 2001]. In the ontology GUMO, long-term user model di-
applications have been developed using location and other mensions are categorized as demographics such as age group
sensory information in the context of ubiquitous and mobile and gender, personality and characteristics, profession and
systems [Wilson, 2003; Hightower et al., 2005; Ashbrook proﬁciency, or interests such as music or sports. Some are
and Starner, 2003; Liao et al., 2005; Lester et al., 2005; basic and therefore domain independent, whereas others are
Wilson and Philipose, 2005]. In these studies, user mod- domain dependent.
els are sometimes implicitly assumed. For example, being Our algorithm is so simple that it is applicable to many

                                                IJCAI-07
                                                  2159            Figure 1: ID-CoBIT and sensors
                                                                    Figure 2: ID-CoBIT system.
types of location data. Inspired by research on information
retrieval, we regard the problem of inferring users’ proper-
ties as text categorization problems. Support vector machine
(SVM) is applied to the problem with various feature weight-
ing methods compared in the paper. Our study is evaluated on
empirical data obtained through one-week experiments at our
research institute. We collected location data of more than
200 users (staffs and guests). The ID-CoBIT system consist-
ing of namecard-type infrared transmitters and sensors is in-
stalled in the environment to recognize users’ location. Figure 3: Sensor allocation map for a part of the fourth ﬂoor.
  The paper is organized as follows. The next section intro-
duces the ID-CoBIT system and describes location data. The 2.2 Experiments
proposed algorithm for user modeling from location informa-
tion is explained in Section 3. Analyses of the results are The ID-CoBIT system is installed in an ofﬁce environment of
made in Section 4. We also propose measurements of sensor our research institute. Location data were collected at AIST
importance in Section 5. Related works and discussion are Tokyo Waterfront Research Center, from February 16, 2004
described in Section 6. Finally, we conclude the paper. (Mon) through February 20 (Fri). In all, 94 sensors are in-
                                                      stalled at the ﬁrst ﬂoor and the fourth ﬂoor. On the ﬁrst ﬂoor,
                                                      we have entrances, reception areas, lobbies, and lounges. The
2  Location information                               fourth ﬂoor is our main ofﬁce, consisting of a research area
In our research, location information is obtained using the and an administrative area. The sensor allocation map on the
CoBIT system. This section brieﬂy overviews the ID-CoBIT fourth ﬂoor is shown partly in Fig. 3, which is about 1000
system and describes experiments to collect location data. square meters, or about a third of the entire covered area. Ev-
                                                      ery working staff member on these ﬂoors was delivered an
2.1  ID-CoBIT                                         ID-CoBIT, which they continued to wear during the period.
The Compact Battery-less Information Terminal (CoBIT ) is We also delivered ID-CoBITs to and obtained location in-
a compact information terminal that can operate without bat- formation of 170 guests who visited the institute temporarily
teries because it utilizes energy from the information carrier during the period.
[Nishimura et al., 2004]. The ID-CoBIT is a terminal inte- After the experiments, we analyzed the location data. The
grating CoBIT with an infrared (IR) ID tag and a liquid crys- detection instances of all sensors were 24317 times: 20273
tal (LC) shutter. Figure 1(a) depicts an ID-CoBIT, which is times of staff, 4044 times of guests. The number was almost
useful as a namecard holder. The ID detector for ID-CoBIT constant each day. On average, a staff member was detected
is a single detector type IR sensor, as shown in Fig. 1(b). The 431.3 times; a guest was detected 23.8 times. Because the
sending cycle of a tag is about 3 s. The effective distance is location information and user properties of staffs are quanti-
3–5 m. Detailed speciﬁcations are available in [Nakamura et tatively and qualitatively better than those of guests, we use
al., 2003].                                           the staff information in this paper.
  The ID-CoBIT system provides location-based informa-  For obtaining users’ long-term properties, we manually
tion support in the environment such as exhibitions, mu- surveyed user attributes for all staff such as age, work fre-
seums, and academic conferences [Nishimura et al., 2004] quency, room, and whether they smoke or not. The user
Users can download information depending on their location properties used in our study are shown in Table 1. We
and orientation, mainly via voice information. The entire ar- chose demographic properties such as AGE and POSITION,
chitecture is shown in Fig. 2. Although the ID-CoBIT system domain-dependent properties such as TEAM and WORK-
has multiple communication channels, in this study we use FREQUENCY, and user-speciﬁc properties such as COF-
only the IR LED on an ID-CoBIT and IR sensors in the envi- FEE and SMOKING.
ronment. We speciﬁcally address obtaining locations of users We elaborate these properties considering usefulness in our
without disturbing usual daily behavior.              domain and also versatility in other domains: First, AGE and

                                                IJCAI-07
                                                  2160               Table 1: User properties.
 user property  range
 AGE            under24, 24-29, 30-34, 35-39,
                over40
 POSITION       sc∗, full-time researcher,
                part-time researcher :
                technical-staff, temporary-staff
 TEAM           research-group-A, -B, -C,     -D,
                secretaries, administrators
 WORK-          high, middle, low
 FREQUENCY∗∗
 COFFEE∗∗∗      high, middle, low
 SMOKING        yes, no
 ROOM+          A,  B, C,  D, E, F
 COMMUTING++    station-A, station-B
∗ SC stands for steering committee. ∗∗ Because of the free time
system of this work environment, working time and commuting fre-
quency depend on the person. ∗∗∗ How often one drinks coffee. +
Working room at one’s desk. ++ Two train stations on two lines are
accessible from this Institute.
                                                      Figure 4: Illustration of sensor detection and the sensor-user
POSITION  are important properties especially in Japan; in matrix.
the Japanese culture, age and position make large differences
                                                      FEE                            {      }   {   }
in communication such as using respect language and behav- property) can be represented as yes, no or 1,0 .As-
ior. As it is often inappropriate and impolite to ask a user suming that three users have the values yes, no,andyes for
about the age and position directly, it is useful for the system the property, we have the following table as a training set.
to infer such properties. TEAM and WORK-FREQUENCY                    s1  s2  s3  s4  COFFEE
can be seen as users’ interests in the research domain. Be-      u1   1224               1
cause team organization is ﬂexible in our institute, they re-    u2   1020               0
ﬂect well the reseracher’s interest. COFFEE and SMOK-            u3   3200               1
ING are useful for guests. If the system can recognize that
a guest likes coffee or smoking, it can suggest appropriate Then, when a new user u4 comes and the detection fre-
                                                      quencies are observed, a prediction problem arises. Is the
restaurants or cafes in break time. Because we are often COFFEE
asked “do you like coffee or tea?” or “do you smoke or not?”   property of the user 1 or 0?
(in Japan), it indicates the usefulness of the properties in our     s1  s2  s3  s4  COFFEE
daily lives. Lastly, ROOM and COMMUTING are for navi-            u4   2200               ?
gation. Knowing the properties, the system can infer in which From the training set, classiﬁcation can be learned using
room a researcher might be (even if he does not wear the Co- machine-learning techniques. If we take nearest neighbor
BIT), or recognize whether he/she goes home or not.
                                                      method, the most similar one to u4 seems to be u3 (though
                                                      it depends on the similarity measure). Therefore, the method
3  Inference of User Properties                       outputs 1.
In this section, we propose our algorithm to infer user prop- This approach is justiﬁed using the following example: Let
erties based on their respective location histories. We ﬁrst us consider a situation in which sensor s2 is installed in front
describe how to reduce the prediction problem of user prop- of a coffee server. Then, frequent detection by s2 means that
erties into a text categorization problem. Then, the feature the user comes frequently to the coffee server, which might
design for machine learning is explained.             imply that the user likes coffee. We cannot know in advance
                                                      which sensors are important for classiﬁcation; they might be
3.1  Reduction to a Text Categorization Problem       those in front of a coffee server, the ones in front of a vending
When a sensor detects a user, the SensorID and UserID are machine, or those that are completely unexpected. In any
obtained each time a sensor detects a user. Counting the num- case, classiﬁcation is learned through sensor detection data
ber of detections, we can build a matrix that represents how and the performance is evaluated by k-cross validation or the
many times each sensor detects each user. We call it a sensor- leave-one-out method, where each part of the training data is
user matrix. Denoting the number of users as n and the num- used repeatedly as both initial training data and test data.
berofsensorsasm, the sensor-user matrix is an n×m matrix The obtained problem closely resembles a text categoriza-
W . We denote Wij as the element of W , i.e., the number of tion problem. A document is often represented by a word vec-
detections of user uj by sensor si. The illustration of sensor tor (or a bag of words) in which each word in the document
detection to a sensor-user matrix is shown in Fig. 4. is weighted by some word weighting; all structure and linear
  Next, we consider user properties. For example, a user ordering of words in the document are ignored. The term-
property of whether the user drinks coffee or not (the COF- document matrix (or a document-by-word matrix [Manning

                                                IJCAI-07
                                                  2161and Sch¨utze, 2002]) resembles our sensor-user matrix W in
that we have n documents and m words in which each user Table 2: Classiﬁcation performance depending on various
corresponds to a document and each sensor corresponds to a feature weighting
word. In a text categorization task, categories are annotated        F-value(%) Recall(%)  Precision(%)
to each document, which can be considered as user properties FREQ      44.45      73.56       37.75
in our problem. The classiﬁcation is learned and used to infer BINARY  43.92      65.83       41.62
the category based on the word vectors. Therefore, the user- TFIDF     44.28      71.62       37.38
modeling problem from location information is reduced to a  IDF        44.37      68.45       45.33
(multi-label) text categorization problem under the proper as- N-FREQ  54.46      68.83       49.23
sumptions and simpliﬁcations.                            N-BINARY      40.73      63.80       40.97
  Text categorization is typically attained using several clas- N-IDF  41.23      61.02       41.46
siﬁcation techniques. We employ support vector machine    N-TFIDF      53.00      65.50       47.88
(SVM) as a learner, which creates a hyperplane that separates             ×
the data into two classes with the maximum-margin [Vapnik, Therefore, we have 4 2 feature weighting methods, which
1995]. The SVMs offer two important advantages for text are compared in the next section. We call those: FREQ,
categorization: term selection is often unnecessary because BINARY,IDF,TFIDF,N-FREQ,N-BINARY,N-IDF,andN-
SVMs tend to be fairly robust to overﬁtting. In addition, there TFIDF. Although normalized tf-idf (N-TFIDF) is known to
is a theoretically motivated, “default” choice of parameter set- perform well for text categorization, different results are re-
ting [Joachims, 1998]. These beneﬁts are also provided by vealed in our user-modeling problem.
our user-modeling problem.
                                                      4   Evaluation
3.2  Feature Design
In the context of text categorization, tf-idf is frequently used For each user property shown in Table 1, a categorization
as feature weighting, which encodes the intuition that (i) the problem is generated. More exactly, because SVM is fun-
more often a word occurs in a document, the more it is rep- damentally applicable to the two-classes problem, a problem
                                                      is generated for each value of the property. For example, the
resentative of its content, and (ii) the more documents in the AGE
word occurs in, the less discriminating it is. In our studies, it property can take ﬁve values: ﬁve classiﬁcation prob-
is rephrased as follows: (i) the more often a sensor detects a lems are generated. We make positive and negative classes
user, the more it is representative of the user’s characteristics, for each value, say under24, i.e., those who are under 24
and (ii) the more users a sensor detects, the less discriminat- and those who are not. Thus the obtained classiﬁer will clas-
ing it is.                                            sify people into those who are under 24 and those who are
  The tf-idf weighting function tailored to our case is deﬁned not. The SVM is used to learn the categorization and the per-
                                                      formance is evaluated by leave-one-out. We employ a radius
as tfidf(si,uj)=freq(si,uj)×idf(si) where freq(si,uj)
                                                      basis function (RBF) kernel, which performs well in our pre-
is the number of detections of users uj by sensor si.The
                                                      liminary experiments. 1
idf(sj) is deﬁned as idf(si) = log(n/uf(si)) where uf(si)
                                                        Average performances on all categorization problems are
is the number of users that sensor si detects (corresponding
to document frequency). A sensor that detects many users shown in Table 2. For example, if we use FREQ as a feature
                                                      weighting, the recall is 73.56%, meaning that we can detect
has high uf(si) value, and therefore a low idf(si) value. In
an extreme case, a sensor detecting all n users has a zero idf 73.56% of persons with a property having a certain value. As
value as log(n/n)=0.                                  a baseline, we investigate the performance of the straightfor-
  Aside from tf-idf weighting, several ways of feature ward classiﬁer that always outputs positive; F-value is 38.2%
weighting are possible. We compare typical weighting meth- and precision is 23.93%. Thus our method is much better than
ods that are often used and compared in information retrieval. the baseline. As for feature weighting, N-FREQ has the high-
The following is a list of feature weighting methods that we est F-value, and N-TFIDF is the second best. Normalization
use:                                                  seems to function effectively for either feature weighting: it
                                                      might alleviate the difference of detection frequency among
  • Frequency (number of detections): wij = freq(si,uj)
                                                     users that was caused by the difference on the working time
                    1  if freq(si,uj) >fthre          or individual device/usage characteristics. Depending on fea-
  • Binary: wij =                            where
                    0  otherwise                      ture weighting, the performance varies as much as 10 points,
    fthre is a threshold. In this paper, we determine fthre = thereby emphasizing the importance of feature weighting for
    1 through preliminary experiments.                user modeling.
                                                       In text categorization, normalized tf-idf works well and
                 idf(si) if freq(si,uj) >fthre
  • IDF: wij =                                        normalized frequency does not compete [Joachims, 1998].In
                   0     otherwise
                                                      our case, N-TFIDF performs well, but N-FREQ performs the
  • TFIDF: wij = tfidf(si,uj)                         best. Thus the result is not completely identical to those in the
  For the weights to fall in the [0,1] interval and for the text categorization literature. The reason can be considered as
vectors to be of equal length, the weight can be normal- follows: compared to documents that have many functional
                                      normalized
ized by cosine normalization, given as wij     =       1Other kernels, such as linear and polynomial kernels, produce
        m      2
wij /   i=1(wij ) .                                   similar results overall; the results worsen by a few points.

                                                IJCAI-07
                                                  2162words and popular words with less information, location data  60
suffers less from such a problem. Therefore, a naive approach

using a normalized frequency might work well.             50
  Generally, recall is about 70% and precision is less than
50%. However, we have much better results for a particular
set of user properties. For SMOKING, ROOM and COM-        40
MUTING, the F-values are as high as 64.13%, 67.00%, and
61.86% respectively with about 60-90% recall and 50-80%   30
                                                       F  value
precision. The under24 and over40 values of AGE,most
        TEAM                   COFFEE
values of     ,andhigh  value of        are all more      20
than 10 points greater than the baseline. Some of them has
                                                                                               W-TotalFreq
                                                                                                 TfidfSum
more than F-values of 80% with 70-100% recall and 50-80%                                        TotalFreq
                                                          10                                    TotalUser
precision.                                                                                      N-TfidfSum
                                                                                               N-TotalFreq
  In summary, some user properties, such as TEAM and                                           N-TotalUser
                                                                                                  Random
ROOM, can be predicted effectively using solely loca-      0
                                                           0       5      10      15      20     25      30
tion information. To some degree, AGE, COFFEE,and                             Number of enabled sensors
SMOKING   are also predictable. POSITION and WORK-
FREQUENCY    are difﬁcult to predict.                    Figure 5: Number of enabled sensors versus F-value.
  We investigated feature weights from the learned models
                                                        We compare several importance measures for a sensor de-
and found that some sensors are unexpectedly important; if
                                                      rived from text categorization studies. The importance of
we take COFFEE  property for example, the ones around a
                                                      sensor si is deﬁned as follows: (i) Overall frequency (TO-
coffee server are of the ﬁfth and ninth importance among                 n
                                                      TALFREQ):  w(si)=       freq(si,uj) (ii) Total detected
all sensors. The most important one was that in front of a                 j=1
                                                      users (TOTALUSER): w(si)=uf(si)  (iii) Total Tf-idf sum
small table where people gather for break. Some corridors are             n
also recognized as important. Surprisingly a sensor exactly in (TFIDFSUM): w(si)= j=1 tfidf(si,uj) These functions
front of the coffee server was slightly negatively weighted; it can be normalized and taking a summation over every user,
may be because around the sensor there is a copy machine and denoted as N-TOTALFREQ,N-TOTALUSER,N-TFIDFSUM.
a door, thus the detection has little information for the prop- In addition, we use another importance measure, called
erty. These results show the limitation of our presumption for weighted frequency (W-TOTALFREQ), following the intu-
user behaviors and effectiveness of our approach.     ition that a sensor that detects users who are detected by
                                                      fewer sensors might be more important, as (iv) Weighted fre-
                                                                                         n             ×
5  Sensor Weighting                                   quency (W-TOTALFREQ):   w(si)=     j=1 freq(si,uj)
In actual use-cases, it is not always possible to prepare train- log(m/sf(uj)), where sf(uj) represents the number of sen-
ing data consisting of users’ location histories and user prop- sors that detect uj. This can be regarded as a tf-idf measure
erties. Then, the question arises: is there a way to ﬁnd out on the transposed sensor-user matrix. In summary, we have
whether a sensor is useful for future user modeling in ad- seven sensor importance measures.
vance without training data? In the real world situation, we 5.2 Comparison and Results
often change sensor locations depending on actual user be-
haviors. Therefore it is useful if we can know the importance Assume that we tentatively disable all sensors and enable
of sensors for future user modeling so that we can properly them one by one in decreasing order of sensor importance.
choose sensors to ﬁx locations. This section describes an ap- Eventually all sensors are enabled and the results will coin-
proach to measure the usefulness of sensors using only loca- cide in any case. However, if a sensor weighting method is
tion histories. It is similar to keyword extraction for indexing superior to the others, the performance will improve faster.
documents for future retrieval.                       If sensor weighting is poor, the performance grows no faster
                                                      than random selection of sensors does. This approach to eval-
5.1  Importance of Sensors                            uate feature selection is found in text categorization research
A sensor that does not detect users at all is almost useless, at [Joachims, 1998; Mladenic et al., 2004].
least for user modeling purposes. Therefore, one deﬁnition to Figure 5 shows how the categorization performance
measure the usefulness, or the importance, of a sensor is sim- changes over the number of enabled sensors. We used N-
ply the total number of detections: its frequency of detection. FREQ for feature frequency, and we used user properties
Alternatively, sensors that detect many different users might that are shown to be predictable as shown in Section 4. In
be important.                                         the ﬁgure, the undermost line (RANDOM) is plotted by se-
  The importance of a sensor is understood as follows: The lecting sensors randomly: it is shown as a baseline. The
user-modeling performance becomes better than the other best performance is obtained by W-TOTALFREQ and TOTAL-
sets of sensors if we have a set of more ”important” sensors. FREQ. Other methods such as TOTALUSER,TFIDFSUM,and
In the context of information retrieval, several studies have normalized series (N-TOTALFREQ,N-TOTALUSER,andN-
examined ﬁnding good indexing terms for document catego- TFIDFSUM) are better than RANDOM, but not as much as the
rization. Better indexing terms improve categorization per- best two.
formance [Mladenic et al., 2004].                       Sensor weighting is beneﬁcial in several situations: we can

                                                IJCAI-07
                                                  2163