               using ontologies web learn lexical semantics                           aarti gupta                                   tim oates                       amazoncom                  university maryland baltimore county                     th avenue south                          hilltop circle                      seattle wa                            baltimore md                      aartigamazoncom                             oatescsumbcedu                        abstract                          components signiﬁcantly impact performance                                                        task statisticsbased extension symbolic knowledge      variety text processing tasks require bene language processing tasks      ﬁt semantic resources ontologies                                                          lexical acquisition methods use different sources data      lexicons creating resources manually te                                                        learning historically static corpus used      dious time consuming prone error                                                        training purposes widdows  dorow  recently      present new algorithm using web                                                        web popular alternative compare al      termine correct concept existing ontology                                                        gorithm cilibrasi vitanyi cilibrasi  vitanyi      lexicalize previously unknown words                                                         uses web extract meaning words      discovered processing texts                                                        phrases      tailed empirical comparison algorithm                                                          work related work learning ontologies lin      existing algorithms cilibrasi  vitanyi                                                         lin  constructs ontology scratch identify      maedche et al  described leading                                                        ing similar words parsed corpus agirre et al agirre et      sights sources algorithms’ strengths                                                        al  use web enrich existing concepts ontolo      weaknesses                                                        gies each concept wordnet fellbaum  associ                                                        ated topic signature lists topically related words    introduction                                       identify sense new word build binary hi  semantic resources ontologies lexicons erarchical clustering possible senses compare new  widely used natural language processing nlp auto word’s context topic signatures each branch  mated text processing understanding word sense dis similar decision tree choose highest ranking branch  ambiguation information extraction speech recognition each step maedche et al maedche et al  deter  machine translation require lexical resources ontologies class new word employing treedescending  used information retrieval automatic query expan treeascending classiﬁcation algorithms algorithm  sion word sense disambiguation task determines concept existing ontology best  easier domainspeciﬁc ontologies reﬂect distribu candidate meaning new word tree descending  tion word senses particular domain outside realm compared algorithm maedche et al  nlp ontologies widely used semantic web  allow programs “understand” web content     methods    acquiring knowledge hand extremely costly time  consuming construction ontologies word net section describes proposed approach learning lex  fellbaum  cyc lenat  edr yokoi  ical semantics summarizes existing methods  required enormous investments time money used comparison  addition handcrafted lexical resources prone human  errors biases inconsistencies judgment        proposed approach    propose novel method learning lexical semantics ontosem ontology consists concepts taxonomic  ontological concept best captures lexical seman relations concepts enrich existing concepts  tics new word determined using statistical analysis ontology new words need ﬁnd hierarchy  web pages containing word experiments reported concepts concept best approximates meaning  paper use ontosem ontology nirenburg  raskin new word accomplished using notion word   large ontology knowledge representation similarity use latent semantic analysis lsa  language understanding tasks developed institute deerwester et al   language information technologies ilit decide appropriate concept new word  form detailed comparison proposed method belong need determine similarity  existing methods process identify individual new word words lexicalized ontology                                                    ijcai                                                    obtain training set words ontol probability px number web pages returned  ogy each word wherew new word google containing search term search  document wtxt created tokenising list deﬁnitions term divided overall number web pages returned  retrieved querying google “deﬁnew ” result google conditional probability pxy deﬁned  ing document collection passed input lsa px ypy  algorithm using world wide web dynamically build attempt use google method extend  document collection relevant given set words allows tosem ontology use tree descending al  ad hoc word learning                                 gorithm assign new word concept each child    words stopped using smart’s stop list stemmed ontology node currently randomly pick  ing porter’s stemming algorithm ﬁltered based representative set words compute distance  logarithm term frequencies word term fre tween new word word extracted  quency freqi included termdocument matrix logical subtrees submitting queries google java  logfreqi ≥ represent raw term frequen url interface scraping page counts web  cies remaining content words termdocument pages returned decision path follow  matrix use tfidf                                 tree choosing child concept subsumes    treat ontosem ontology similar decision tree word closest new word distance mea  starting root attempt descend ontology tree sure  reach leaf concept tree node decision  path follow choosing child concept  category based tree descending algorithm  similar new word compute similarity maedche et al maedche et al  use categorybased  each child ontology node currently method determine child concept similar  randomly pick representative set words belong new word ontology node currently  subtree rooted child                          gather hyponyms  levels    obtain deﬁnitions words representa build generalized class vector each child concept  tive sets word trying learn word adding vector representations hyponyms gath  create new document contains list deﬁnitions ered belong subtree rooted child normal  word end document collection ize resulting vector unit length similarity  contains document word extracted unit vector new word class vectors measured  various ontological subtrees document means three different similarity metrics jaccard’s coef  new word invoke lsa algorithm gives ﬁcient distance skew divergence child concept  word document vectors reduced space com class vector similar new word’s vector  pute cosine similarity scores word vectors finally chosen node path ontology tree  nearest neighbor classiﬁer assigns new word child utility using categorybased method  concept subsumes word similar sides reducing computational cost summarizes charac  new word process repeated search reaches teristics each class combining multiple prevalent fea  leaf node                                            tures features simultaneously    automatic meaning discovery using google         present single vector                                                          use maedche method extend ontosem ontol  subsection describes method proposed cilibrasi                                                        ogy each ontology node gather hyponyms  vitanyi cilibrasi  vitanyi  automatically learn                                                        three levels build termdocument matrix rel  meaning words phrases intuitively approach                                                        evant document collection obtained google deﬁne ob  follows words semantically similar cooccur                                                        tain normalized class vectors use similarity  words semantically unrelated conditional                                                        metric choose child concept closest new  probabilities used measure cooccurrence                                                        word  terms pxy gives probability term accompany  ing term pyx gives probability term ac  companying term probabilities asymmetric  experiments  semantic distance terms obtained section describes experiments performed pro  taking negative logarithm conditional probabilities cess identifying components work best                px py selecting maximum statisticsbased reﬁnement taxonomic relations  normalizing maximum log px log py describes experiments conducted evaluate perfor                                                        maxlog pxy  log pyx         mance proposed lsabased tree descending method                                                    dx                                   google method categorybased tree                    max  log px  log py            scending method  web probabilities term cooccurrence ex document wtxt created obtaining context  pressed google page counts probability term word  similarity words  given number web pages returned google measured computing similarity documents  presented search term divided overall num wtxt wtxt experiments compute simi  ber web pages possibly returned google joint larity document vectors word vectors                                                    ijcai                                                    cause empirically using document vectors gave  marginally better results word vectors    experiments performed leaveoneout cross  validation word held test word  remaining words constituted training set  formance measured terms number words cor  rectly classiﬁed word correctly classiﬁed assigned  correct child concept ontology node    value threshold ﬁltering low  frequency words ﬁxed words occurred  fewer times corpus ﬁltered      impact corpus learning task  wanted gauge impact corpus lsa  based tree descending algorithm randomly figure  performance lsabased method using  picked ﬁfty words each subtrees rooted wsj corpus google deﬁne corpus   child concepts socialrole node  tosem ontology giving total  words removing      node       words classiﬁed correctly  polysemous words                                          socialrole                  used wall street journal corpus obtain contexts  each word  document wtxt created extract      mammal                   ing window width seven words centered each      animate                ﬁrst  occurences corpus replaced        object                  wsj document collection google deﬁne docu  ment collection keeping table  results obtained categorybased method  each word  document wtxt created submitting ing metric  google query “deﬁnew ”    results using google deﬁne corpus vs wsj  corpus shown figure  accuracies corpora show gives better results jaccard’s coefﬁcient  calculated number words correctly classiﬁed skew divergence  total number words possibly classiﬁed carried experiments nodes ontology  correctly wsj corpus google tree each node created relevant document col  deﬁne corpus discrepancy lection picking words three levels  number words originally extracted ontology node googling words’ deﬁnitions measured  fact words occur wsj corpus similarity normalized categorybased vector rep  deﬁnitions web occur fewer resentations obtained summing individual document vec  times threshold frequency                   tors table  shows results obtained each cell table    seen figure  values shows number words classiﬁed correctly total  number singular values retained running lsa number words possibly classiﬁed correctly  performs signiﬁcantly better fed analysis results shows cases  google deﬁne corpus fed wsj cor new word similar child concept  pus google deﬁne corpus best accuracy  comparison child concepts subsumed fewest  wsj corpus best accuracy number words example socialrole node                                       vast majority words similar    google deﬁne corpus dramatically improves celebrity concept just word  performance contains fewer extra mammal node words simi  neous irrelevant words potentially distract lar concept freshwatermammal just  lsa algorithm                                        word observation corroborates ﬁndings                                                        maedche et al observed words    impact similarity metric                      assigned concepts subsumed words                                                          given words length vectors ythe  maedche et al make use three different similarity met distance given  rics jaccard’s coefﬁcient distance skew divergence                                                                                  n  categorybased tree descending algorithm show                           −     performance categorybased tree descending          distx     xi  yi  algorithm signiﬁcantly improved using cosine                       similarity metric                                    deﬁnition distance    initially implemented categorybased method using small difference xi yi small  similarity metric maedche et al empirically thismeansthatifx document vector                                                    ijcai                                                               node       words classiﬁed correctly            node        baseline  lsa     google  category        socialrole                                                                  mammal                                     object                              animate                                   physobj                              object                                   animate                                                                               animal                       table  results obtained categorybased method vertebrate                ing cosine similarity metric                                                           mammal                                                                                primate                     new word generalized class document vector                                                            human                   distance small conditions  satisﬁed documents contained socialrole                  words second documents  contained words child concepts subsume table  average accuracy  lsabased tree  words ontology tree represented documents scending method google method categorybased  means fewer words tree descending method  concepts default second condition satisﬁed    replaced metric cosine similarity met google method  ric keeping carried ex lsabased tree descending method  periments ontology nodes table  shows node path randomly picked  words  results using cosine similarity metric each subtrees rooted child concepts node  seen cosine similarity metric does signiﬁcantly better each node different set words  metric nodes                 measured performance google method                                                        experiments carried  times each node each time    evaluation three methods                  different set words  section describes experiments carried evaluate categorybased tree descending method  performance lsabased tree descending algorithm                                                        carried experiments categorybased tree  google method categorybased tree descending                                                        descending method proposed maedche et al  algorithm                                                        replaced metrics used cosine similar    picked path ontology root   ity metric node path gathered words  leaf node carried experiments node three levels each subtrees rooted  path carried experiments child concepts node random  object physicalobject animate ani           element involved carried experiments just  mal vertebrate mammal primate human              each node  socialrole nodes goal evaluate  formance three methods based number words results  classiﬁed correctly each node path word benchmark performance three meth  classiﬁed correctly assigned correct child ods baseline calculated number  cept                                                 words classiﬁed correctly new word randomly                                                        assigned child concept probability getting  lsabased tree descending method                      word correct chance depends number child  ontology node path randomly picked cepts given node baseline varies number   words each subtrees rooted child child concepts node  concepts node node table  shows results three methods each cell  words picked object event property      shows percentage accuracy given method given  subtrees object node words picked node lsabased google methods value  physicalobject intangibleobject          average accuracies obtained each  runs  mentalobject socialobject temporal            experiment given node google’s estimates  object subtrees each node path differ page counts vary quite bit given search term  ent set words experiments carried results google method page counts  each set words used crossvalidation testing returned time performing experiments  termine number words classiﬁed correctly table nodes category    generalize results random element involved based method outperforms lsabased google meth  picking words each node carried experi ods lsabased method does better google  ments  times each time picking different set words method nodes primate node  performing crossvalidation testing used values node performed ttest accuracy distri  running lsa empirically good          butions lsabased google methods using pub                                                    ijcai                                                                                                      maximize maximizing possible                                                  small minimize numerator                                                  case needs maximized                                                          clear google method say                                                        similar three conditions satisﬁed  table  contingency table cooccurrence                                                        occur certain number web pages cell  second                                                        number web pages occurred  licly available simple interactive statistical analysis sisa minimal cells   ﬁnally  package ttest results show difference perfor inﬁnitely web pages occurred  mance lsabased google methods statistically cell   signiﬁcant nodes primate web virtue unrestricted size satisﬁes  nodes                                                condition time size web    similarly zscores categorybased method show problem sheer mass web pages  difference performance lsabased conceivable topic likely word  categorybased methods statistically signiﬁcant nodes web used sense means  animate animal nodes           words semantically related                                                        likely signiﬁcant number web pages    analysis                                           used sense related viceversa  experimental results show categorybased tree pairs words second condition  descending method outperforms methods satisﬁed example words monk pope  lsabased tree descending method outperforms goo religiousroles human plays  gle method section attempt identify reasons words semantically related cooccur signiﬁcant  superior performance categorybased method number pages google query words “monk  ﬂaws google method                pope” retrieves  web pages query                                                        “monk pope” retrieves  web pages    analysis google method                    query “pope monk” retrieves  pages  subsection argue google method performs  poorly ngd measure does capture true  analysis categorybased method  semantic distance polysemous terms           surprisingly categorybased method com    given words normalized google distance putes word similarities original vector space performs  ngd given                       better sophisticated lsabased method                                                    identify reasons categorybased method perform                     max  log pxy  log pyx         ing better lsabased method carried set        ngdx                                              maxlog px  log py          controlled experiments                                                          carried experiments lsabased method  words perceived semantically similar categorybased method physicalobject  distance small numerator animate animal mammal  socialrole   small denominator large nodes categorybased method modiﬁed slightly  minimizing numerator means maximizing pxy                                                       given node  words randomly picked  py maximizing denominator means mini each subtrees rooted child concepts  mizing px py                           modiﬁcation use lsa    table  shows contingency table cooccurrence ﬁrst method categorybased vector representations  terms table                        second method methods identical                        px ∩                      spects               pxy                                   py                        experiments each node control groups                                                        used ﬁrst “control group” method com                        px ∩                  pyx                                 putes word similarity using document vector representations                         px                      original vector space uses lsa  order maximize pxy pyx respectively categorybased vector representations second “con  minimized table            trol group” method computes word similarity using                                                   categorybased vector representations reduced vector                  px                                 space uses lsa categorybased vector                                             representations                                              py                                   each node evaluated performance                                             methods  times each using different set words each  maximize denominator minimize px evaluation  py minimize px need maximize dhow tables  through  show results obtained each node  maximizing possible needs mini each table ﬁrst cell shows average percentage  mized minimize numerator minimize py need accuracy method uses lsa category                                                    ijcai                                                    
