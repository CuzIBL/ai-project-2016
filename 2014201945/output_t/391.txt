              acquiring robust case base robot soccer domain                                        raquel ros josep llu´ıs arcos                               iiia  artiﬁcial intelligence research institute                               csic  spanish council scientiﬁc research                                  campus uab  barcelona spain      ∗                                          rosarcosiiiacsices                        abstract                                                                                  paper presents mechanism acquiring                                        case base cbr deal      limited perception environment      construction case bases domains      complex requires mechanisms au      tonomously adjusting scope existing      cases acquiring new cases work pre      sented paper addresses goals                                                        figure  snapshot fourlegged league image ex      ﬁnd “right” scope existing cases                                                        tracted ofﬁcial robocup rule book      introduce new cases appropriate solution      tested mechanism     acquiring case adaptation knowledge combining rulebased      robot soccer domain performing experiments  methods user guidance leake et al inthe      simulation real robots            aqua ram  presents approach incre                                                        mental learning based revision existing cases    introduction                                       incorporation new ones solution                                                        main challenges novel situations ii misindexed  working robots interact environment cases iii incorrect incomplete cases ap  complex task degree uncertainty robot’s proach attempt cover iii domain  perception world achieve accu paper continuation previous work ros et  rate perception mechanism consequence al  designed casebased reasoning sys  low degree uncertainty consider tem action selection robot soccer domain  environment fully controllable unpredictable situa introducing problem address brieﬂy  tions occur reasons reasoning domain relevant features  introduce mechanism hand allows focus work fourlegged league  adapt priori knowledge given expert real robocup soccer competition league teams consist  perception robot hand automatically sony aibo robots robots operate fully au  incorporates new knowledge unexpected situation tonomously external control hu  occurs                                               mans computers ﬁeld  long  wide    researchers address case base acquisition different goals cyan yellow colored mark  ways based domains textual casebased rea ers robots use localize ﬁeld  soning ﬁeld cases extracted textual sources teams game red team blue team figure   example emails manuals scientiﬁc papers minor shows snapshot ﬁeld details ofﬁcial rules  biermann  medical records abidi manickam refer ofﬁcial robocup rule book   robotics log ﬁles created during execution  tasks used inputs case generation gabel description               veloso   interactive approaches studied goal cbr determine actions  complete missing knowledge user robots execute given state game snapshot  through concept mapping leake wilson                                                         game time instead considering single actions    ∗partial funding spanish ministry education sci each state deﬁne sequences actions  ence projects qualnavex dpic mid game plays examples near ball shoot  cbr tinc raquel ros holds scholarship ball grab turn shoot case  generalitat catalunya government         sists description environment problem descrip                                                    ijcai                                                    tion game play robots performed state parameters high values modelling large  solution description problem description features regions low values modelling small regions  robots positions ball position opponents positions defend interested creating case bases “essen  ing goal time game score difference solution tial” cases meaning expect include cases  description deﬁned ordered list actions  general cover basic situations include    henceforward paper focus simpliﬁed cases represent speciﬁc situations ﬁrst ones  version consider robot ball represented larger scopes second ones  defending goal description problem al smaller scopes having types cases allows  ideas presented extendable features reduce number cases relevant ones  described solution description remains desirable property realtime response domain                 case ga                      improve robot’s perception                                                        hardware limitations need real time response  θ   cyan yellowand ﬁnding hand right parameters reasoning  aa  θ corresponds robot’s angle module hard propose ﬁrst include  respect axis ﬁeld                   reasoning model mechanism automatically compute    order retrieve similar case model scope existing cases based actual perception  similarity function based ball position robot second introduce additional mechanism  gaussian function consider points cartesian combination include new cases sys  plane similar distance given threshold tem case retrieved ensure  using gaussian allows model maximum distances regions cases cover adapted robots believes  axis consider values similar world respond according  different degrees similarities based propor perception robot ability  tional distances points deﬁned follows “creative” act new behavior                                                        does return possible solution                                                                 − x  y                brieﬂy approach focused creating initial case                              τ   τ              gx ye                           base partial information com                                                        plete modifying scope cases order  x y distances points                                                        cover problem space minimum number cases  axis respectively τxτy maximum distances                                                        introducing new cases needed processes  each axis parameters represent scope                                                        guided human trainer  case region points considered similar  represented ellipse plane each case  different region sizes each case store  learning scope existing cases  additional information knowledge initial case base manually created    new problem presented ﬁrst represents priori expert’s knowledge idea pro  ﬁlter cases based defending goal problem vide set cases adapted  case defending goal robot’s actual perception expert knows generic  considered similar compute situations prototypical cases corresponding solu  similarity position balls simi tions predict real scope cases  larity exceeds given threshold consider case robot’s point view propose create initial  potential solution problem select case case base composed prototypical cases default scopes                                                                higher similarity degree reusing step        τx τy  let robot learn end    problem address paper ensure expert tell robot case retrieved each time  robustness given high uncertainty correct refer process training step  robot’s perception cbr correctness mentioned previous section refer case’s  case base main issues determines scope region ﬁeld case  accuracy performance represents trieved regions modelled ellipses corre  knowledge given new problem solution obtained spond gaussians’ projections plane  comparing description new problem cases refer directly ellipse order learn scope  case base approach position ball cases propose modify size ellipses                                     τ      τ  ﬁeld perception parameters used varying gaussian parameters τx τy end  similarity function knowledge crucial correct deﬁne policy determine  performance retrieval step wrong cases parameters adjusted  returned case situations  ball correctly positioned  adjust values    complete account features goal increasing decreasing size ellipse  compute similarity cases robot position reach “ideal” region case cover cen  cluded retrieval step details ter ellipse represents exact position ball  relevant work present                ﬁeld speciﬁed case boundary                                                    ijcai                                                                          τy                                                                                                                                                                                 τy                        γy                                          τy                                    τ                                                                                                                            γx                                       τx                      τx                                                                        t−                    figure  example security region gray region       τy                    τy  risk region white region deﬁned γx  γy                                                                                  t−                   ellipse uncertainty points belong              τx                  τx  scope case increases set points  center ellipse security region  near boundary ellipse risk regionwedeﬁneγx                                                              figure  case scope evolution γx  γy   γy relative size security region respect  size ellipse each value corresponds radius increasing policies show equations axis  percentage figure  shows example regions equations used axis    proposes solution new problem •  use expert’s feedback tuning parameters ﬁxed increasing ﬁxed value                                                            deﬁne step function  retrieved case proposed solution succeeded scope               case increased decreased                        ˆ                                                                               δx  x ≥ γxτx                                                                       δx     ﬁrst focus increasing process prob                     lem located inside security region position  ball region introduce new knowl • linear compute increasing value based lin  edge case current information robust ear function  determine problem corresponds scope                                                                                    x−γxτx  ˆ                                                                          τ −γ τ  · δx  x ≥ γxτx  case contrary problem risk region  δx       conﬁrm current scope case increas                          ing size ellipse expanding ellipse results                                                          •  expanding security region                    polynomial compute increasing value based    problems incorrectly solved using case scope polynomial function                                                                        overestimation reduce size el                                                                                             x−γxτx  ˆ                                                                                  · δx  x ≥ γxτx  lipse ball inside security region δx    τx−γxτx  crease parameters corresponds robust region                         problem region feedback neg  ative assume error caused computing increasing values update τx τy  wrong localization wrong knowledge adding computed δx δy respectively  illustration imagine following sit motivation decreasing parameters reduce  uation robot localized consequence ellipse size new problem solved considered  perceives position ball incorrectly hap inside region anymore end equal τx τy  pen retrieves right case given perception values problem higher  external observer perception case used radius security region                                                                           solve problem right feed                      ≥ γ  τ                                                                    τ             given robot negative reduces         τ t−  ellipse radically reduce scope case                  overestimated high impre update τy way  cision problem inside risk region updating values separately prob  does reduce scope case scope lem risk region prevents radically reducing  overestimation cause negative feedback scope case simple example    summary enlarges reduces scope illustrate approach  case modiﬁes knowledge problem pre  sented correctly incorrectly solved  example  case’s risk region                                   figure  depicts steps training process gray    adjust values                         region represents security region dashed ellipse                                                        corresponds “ideal” scope case deﬁned  ﬁrst problem determine increasing values human trainer attempt reach problem located  each parameter τxτy ideal area produces positive feedback ex  increase size ellipse respect each axis pert black dot represents new solved problem ball                                       ˆ     ˆ  deﬁne δx δy increasing value δx δy position respect case figure  shows ini  maximum increasing value each axis propose three tial stage time  scope case minimum                                                    ijcai                                                                                                        appear white regions represent                                                        gions robot acquire new information                                                        increase knowledge                                                          new case created using description envi                                                        ronment problem description generated game play                                                        solution new case create game play pro                                                      vide set possible actions robot   figure  “ideal” case base based expert knowledge form combination actions correspond poten  τ τ                                                tial game plays given new problem solve does    new solved problem risk retrieve case imprecision problems  gion feedback positive proceed enlarge cause problem actually gap generates  size ellipse using policies deﬁned                                                                        random game play  robot executes suggested ac    time  figure  observe ellipse tion expert evaluates correctness solution  increased reached expected size proposed succeeds new case created  continue enlarge scope solving new problems new case inserted cre  long expert feedback positive                   t−                                  ated minimum scope small ellipse mo    figure  time  depicts situation ellipse ment evolution new case depends  generated bigger expected size robot reuses enlarging reducing scope using  feedback positive negative new problem mechanism presented previously idea  risk region feedback positive ginning new case good solution  proceed increase ellipse feedback concrete situation actual effectiveness  negative decreasing process used reduce evaluated robot reuses time passes  ellipse ﬁgure shows example situation scope case does increase instead reduced  new problem located risk regionbut deduce case useful robot’s  ideal scope current scope reduced                τ         γ  τ                        formance contrary scope increases  updating                       remains stable consider case contributes    figure  shows updated scope problem system’s knowledge  remains outside scope case problems  solved scope case converge ideal scope    conclusion distinguish phases training  experimentation  process growing scope case converging section describes experiments performed order  ideal scope during ﬁrst phase feedback test approach introduced paper divide ex  positive scope expanded second perimentation stages simulation real robots  phase occurs expected scope exceeded  feedback positive negative goal  simulation  positive feedback enlarge scope goal goal ﬁrst phase examine behavior  negative feedback converge ideal scope human policies using different values parameters presented  trainer expects                                      section  test different combinations                                                        values simulation fastest way obtain orientative    introducing new cases                results relevant selected experimenta  finding possible situations robot encounter dur tion real robots  ing performance unfeasible domain based experiments single case observe  high uncertainty domain working different values variables affect evolution                                                        scope resulting size ellipse case  domain real time game                                       τ      afford robot stop during game just does initial case deﬁned small scope                                                        τy   expected outcome τx    “know” situation robot τ    execute action time step game  randomly created  problems time    training step knowledge case retrieved used different policies mod  present “gaps” scope cases cover ify scope case experiment repeated com  ﬁeld course depends number bining following values  cases used during training mentioned • security region size expressed percentage  hand expert deﬁne possible cases γx        hand focus approach initially deﬁning • maximum increasing value expressed mm  set generic situations allowing robot create new ˆ                                                            δx             ones based experience    figure  shows example hand coded case base paper number available actions low   cases simplicity show quarter ﬁeld considered generating random game plays feasible  positivepositive quadrant each ellipse represents pre believe complex situations mechanisms  deﬁned case given knowledge gaps used random generation scalable                                                    ijcai                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              radius                          radius                           radius                                                                                                                                                                                                                                                                                                maximum increment                 maximum increment                  maximum increment                                                                                            figure  resulting τx using policies fixed policy linear policy polynomial policy                                  ˆ  values used γy δy              policy use second consists    each combination values ran  experiments evaluating convergence cases given case base  figure  shows average obtained results finally goal observe           ˆ      ˆ  hand δx δy deﬁne ellipse able acquire new knowledge solution  crease each time higher values bigger  resulting scope case hand γx γy testing parameters policies mentioned  determine size security region risk region divide training process steps growing  low values represent small security regions large risk scope case converging ideal scope  gions risk region determines scope case interested rapidly enlarging size ellipse  modiﬁed region increases reaching ideal opt conservative  chances modifying scope three behavior adjust switch strategy  policies curves tend increase left right size ellipse decreased    respect policies ﬁxed policy obtains achieve strategy combining poli  highest τx τy values polynomial obtains cies modifying values parameters through  lowest ones function aggressive process regarding policies included addi  havior radically increasing size ellipse tional strategies ﬁxed linear policy growing step  function conservative behavior computing ﬁrst polynomial convergence step respect  small increments increasing reach bound parameters ﬁrst step deﬁne large risk regions  ary ellipse consequence ﬁxed policy sig high increasing values opposite second  niﬁcantly varies different parameters step  behavior polynomial policy remains stable al experimentation similar simulation stage  values parameters change regarding experiments based single case ex  linear policy intermediate behavior respect pected scope case τx   τy   tending ﬁxed policy      generated  new problems manually positioning ball    experimentation conﬁrm ﬁeld each experiment combined ﬁve policies  servative policy low increasing values small risk regions                                ˆ                                                        three different sets parameters γx  δx   ii  appropriate combination obtain desired γ  δˆ     γ    δˆ      γ    scope cases conclusion obvious        iii                                                                        δˆ   establishing ideal conditions order gradually increase growing process lat                                                        ter convergence process values used  scope cases problems arise extend    ˆ  ing experiments real world time uncertainty γy δy each parameter varies separately depending  number iterations needed reach expected τ altered modifying τx does imply modifying τy  result unfeasible working real robots sec performed  trials set  ond noisefree environment available simu comparing results respect expected scope  lation observed different behaviors verify ﬁxed linear policies generate  graphics obtained gradually modifying parameters highest τx values exceeding ii polynomial policy does  differences obvious real environment reach ideal scope low increas  cause issues modify expected result ing speed iii ﬁxedpolynomial linearpolynomial  stage experiment real world strategies obtain closest scopes expected ones  relevant parameters understanding relevant ones combine advantages policies  show contrasting behaviors determine effective regarding values parameters conﬁrmed  ness approach presented                       conclusions drawn simulation combining low increas                                                        ing values small risk regions ensures reaching ex    real robots                                      pected result problem number steps  three types experiments performed real robots achieving goal combining values  ﬁrst aims ﬁnd appropriate parameters parameters –ﬁrst high increasing values large risk regions                                                    ijcai                                                    
