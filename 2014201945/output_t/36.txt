                              multiprototype support vector machine                                 fabio aiolli                                  alessandro sperduti                      dept science                    dept pure applied mathematics                        university pisa italy                         university padova italy                            aiollidiunipiit                              sperdutimathunipdit                               abstract                                preliminaries notation                                                                                                 set training exam•       extend multiclass svm multiple prototypes                                                                  plesa singlelabel        class framework compact                                                                  multiclass classifier functionthat maps in•       constrained quadratic problem suggest                                                                  stances labels focus class        efficient algorithm optimization guaran•                                                                 winnemakeall linear classifiers form        tees local minimum objective function        annealed process proposed helps es•                                                                     cape local minima finally report experi•         ments performance obtained using linear         mr rth prototype vector set proto•       models comparable obtained           type indexes cr function returning class associ•         stateofart kernelbased methods signif•      ated prototype indexed given classifier hmx        icant reduction orders response        training example say misclassi       time                                                     fies                                                                    following denote constant equal                                                                     ifotherwise given example    introduction                                                 denote set positive                                                                  prototypes indexes    automatic multiclass classification process auto•                                                                 set negative prototypes indexes finally real value   matically assign exactly prefixed set labels                                                                               • referred similarity score simply   stream input instances central task real world                                                                  score rth prototype instance   problems like speech recognition ocr text categorization   supervised learning methods studied         singleprototype multiclass svm   help tasks recently kernelbased methods like   svm studied especially binary settings    effective multiclass extension svm   yielded stateofart performance different    proposed crammer singer  resulting   tasks svm searches high margin linear discriminant      classifier form  each class   model high dimensional space feature space   associated exactly prototype   examples implicitly mapped function           solution obtained through minimization   kernelbased algorithms need dot products feature   convex quadratic constrained problem section   space possible resort called kernel trick present simpler derivation equivalent formulation   dot products computed efficiently kernel   extended section multiprototype   function kx  • number exam•                 framework   ples support vectors large approaches tend   efficient wrt time spent classifying new vectors multiclass setting order correct classi•  require work implicit characterization  fication instance prototype correct class   discriminant model                                     score greater maximum     effective svm extension able deal         scores prototypes associated incorrect classes   general multiclass problems recently provided    formally write constraints correct classifica•  crammer singer  shown good re•      tion example margin greater equal    sults paper extend multiclass svm      requiring   multiprototype setting each class   prototype vector allowed     expressive decision functions using simple models   yi  index prototype vector associated   necessarily requiring use kernels                      correct class example allow margin       learning                                                                                                               violations each example introduce soft margin slack   multiprototype multiclass svm   variables                                                                 section sprotsvm model previously defined                                                                 extended case multiple prototypes class                                                                 basic idea given multiple prototype vectors   denotes hinge loss equal            correct classification iff prototypes associ•   notice value upper bound       ated correct class score higher maximum      loss example xi consequently aver• scores prototypes associated incorrect classes   age value training set upper bound   case write constraints correct classifi•  empirical error                                              cation example xi margin greater equal       motivated structural risk minimization srm prin•  requiring   ciple vapnik  want search set pro•  totype vectors  mi mc small norm   minimize empirical error training set   formulate problem svmstyle requiring         allow margin violations each example xi   set prototypes minimal norm fulfill soft con• introduce soft margin slack variables  each   straints given classification requirements  positive prototype st   singleprototype multiclass svm sprotsvm result                                                                     given pattern xi arrange soft margin slack variables                                                              vector let introduce each                                                                   example xi new vector  components                                                                 zero component  following   notice desired optimal solution refer assignment pattern xt notice   maximum value negative scores instance      dot product upper bound —                                                                 loss example independently assignment   xi problem convex solved stan•  dard way resorting optimization wolfe dual      ready formulate multiprototype prob•  problem case lagrangian                     lem requiring set prototypes small norm                                                                 best assignment examples able fulfill soft con•                                                                straints given classification requirements                                                                    mprotsvm formulation result                                                                                                                                                                                            subject constraints  differentiating           unfortunately mixed integer problem   lagrangian respect primal variables impos•    convex difficult problem general   ing optimality conditions obtain set constraints following prone efficient optimization   kkt conditions variables fulfill order procedure approximates global optimum   optimal solution                                          point worth noticing effective formulation                                                                 heuristic approximation structural risk                                                                 minimization principle good solution opti•                                                                mal good results claim                                                                 confirmed results obtained experimental work                                                                   let suppose assignments kept fixed     using fact substituting condi•                   case reduced problem convex solved   tions   omitting constants change resorting optimization wolfe dual   solution problem restated                     problem case lagrangian                                                                   section includes efficient optimization pro•  cedure general multiprototype setting in•  subject constraints  differen•  cludes singleprototype case particular instance    tiating lagrangian reduced problem imposing                                                                                                                 learning  optimality conditions obtain        notice second condition requires dual variables    associated positive prototypes assigned as•   sociated pattern  denoting yi unique    index  using conditions      omitting constants change obtained    solution reduced problem restated                                                                                                                                     values ap aft updated turn      trivially shown formulation consistent feasible constraints arp   aft      formulation sprotsvms given              select value fulfill violated constraint                                                                  bounds limit    optimization static assignments                         show analytically solve associated                                                                  problem respect update involving pair vari•   patterns statically assigned prototypes                                                                  ables       ri    constant vectors convexity associated                                                                                                       case update zero sum   mprotsvm problem implies optimal solution   primal problem  through maximization    lagrangian       assuming equal number prototypes class   dual involves variables lead large   scale problem independence constraints   different patterns allows separation   variables disjoint sets variables      algorithm propose optimization prob•   lem  inspired ones presented cram•   mer singer  aiolli sperduti con•  sists iteratively selecting patterns training set                                                                  similarly previous case values   optimizing respect variables associated pat•                                                                   updated turn feasible   tern convexity each iteration leads increase   rp                                                                 constraints select value   lagrangian improvement possible                                                                  fulfill violated constraint bounds limit   optimal solution lagrangian                                                                    iterating multiple times basic step described      selecting pattern  enforce constraint                                                                pairs variables chosen associated given                                    elements set     pattern guaranteed optimality condition   variables optimized pair                         pattern exploited aiolli sper  keeping solution inside feasible region par• duti devise incremental algorithm uses   ticular let wi selected variables restrict method reduced problem single example   updates form iterates different examples optimization proce•  optimal choices iterating application basic dure considered incremental sense so•  step different pairs doing different lution previously given pattern forms initial   patterns guarantee reach optimum overall   condition pattern selected optimiza•  problem                                                       tion version basic step optimization      let compute optimal value   reduced problem require optimization   observe update affect squared norm                                         pairs variables   prototype vector mr                               constrained  associated selected pattern                                                                  complexity optimization reduced problem                                                                                    number iterations      show analytically solve associated         perform step giving algorithm   problem respect update involving single variable  each iteration complexity om ob•              variable does influence          serve variables associated pattern       learning                                                                                                                xp optimal feasible analytic solution     each pair       particular case order able    apply step required following    conditions verified                                                                second case          notice facts checked linear time    easy show solution obtained certain step    improved iff facts verified suggests    efficient procedure shown figure ltop tries    greedily fulfill previous condition optimality     optimization general mprotsvm    section present efficient procedure guaran•   tees reach local minimum objective function    problem  associated mprotsvm procedure    try optimize respect assignments      let suppose start given assignment    patterns case seen associated    problem convex efficiently solved using    algorithm given section  optimal value    primal reached observe so•   lution improved updating assignments    way assign each pattern positive prototype    minimal slack value setting vector     unique  corresponding best perform•   ing positive prototype new assignment    variables fulfill second kkt con•   dition eq  anymore case simply means    current solution optimal new assign•   ment lagrangian optimization satisfying    constraints dictated kkt conditions new assign•   ment guaranteed obtain new better optimal    primal value  optimization algorithm suc•   ceed kkt conditions restored    order return feasible solution finally    resuming lagrangian optimization new assign•   ment restore kkt conditions setting    exists      performing procedure different assignments    each obtained previous procedure   just mentioned implies convergence algorithm    local solution primal problem improvements    possible kkt conditions fulfilled    current solution fact step induces    improvement primal value      problem procedure results oner•   ous dealing prototypes per•   form lagrangian optimizations observe      figure  algorithm optimization variables    procedure work each step sufficient associated given pattern xp tolerance    stop optimization lagrangian value  algorithm optimization mprotsvm                                                                                                                  learning primal better going code training classification works directly   happen sure solution op• explicit compact version model   timal requires periodic check primal value   primarily interested evaluation   optimizing lagrangian                                mprotsvm wrt sprotsvm each dataset performed      second stringent problem proce•    validation parameter sprotsvm model   dure lead local minimum far    reused obtained value training mprotsvm   best possible suggest update assign•  generated dataset approach any•  ments basis stochastic annealed function instead   way pessimistic estimate performance mprotsvm   hard decision function described                   annealing process required mprotsvm      specifically let view value primal energy implemented decreasing temperature   function                                                       exponential law       let suppose pattern xi having slack variables              external parameters          suppose probability assignment  used   following experiments   state th component set  follows   law                                             temperature        variation energy pattern xi   assigned sth prototype multiplying term         normalization term exp               considering probabilities alternative   states sum  obtain                       table  comparison generalization performances be•                                                                 tween lvq mprotsvm increasing number code                                                                 booksprototypes nist dataset     partition function      assigning pattern xi each positive proto•  type selected probability pis notice   temperature low probability   pattern assigned prototype different   having minimal slack value tends  obtain   behavior similar annealed version algorithm   simulated annealing typically implemented decreas•  ing temperature number iterations increases   monotonic decreasing function  ttt    algo•                                                                table  test error mprotsvm usps dataset   rithm depicted figure                                                                                                          increasing                                                                  number prototypes test error mprotsvm    experimental results                                         letter dataset   tested model three datasets briefly de• increasing number prototypes   scribe following    nst consists class task  digits randomly   set experiments performed compare        taken nist dataset training set con•      generalization performance linear model versus lvq        sists  randomly chosen digits remain•   kohonen et al  compa•       ing  digits used test set                 rable model reported best results    usps consists class ocr task digits   obtained lvq nist dataset specifi•       input pixels scaled digit image cally obtained lvq version         training examples  test examples        algorithm sona sperduti  possi•                                                                 ble table  mprotsvm performs significantly better    letter consists class task alphabetic letters    prototypes class used difference        az inputs measures printed font glyph  gets lower number prototypes class increases         examples used training   effective control margin         testing                                         svm wrt lvq models dataset tangent     kernel function principle used distance based tvq algorithm aiolli sperduti   following preliminary experiments used linear kernel   obtained best result remarkable  test error   kx     allowed write optimized   polynomial svms obtained  test error       learning                                                                                                              
