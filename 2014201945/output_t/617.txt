         feature generation text categorization using world knowledge                                 evgeniy gabrilovich     shaul markovitch                               gabrshaulmcstechnionacil                       science department technion  haifa israel                        abstract                          venture mining copper instead fairly long document      enhance machine learning algorithms text   mainly talks mutual share holdings compa      categorization generated features based   nies involved teck corporation cominco lornex min      domainspeciﬁc commonsense knowledge        ing discusses mining activities      knowledge represented using publicly avail sortium consequently three different text classiﬁers      able ontologies contain hundreds thousands used svm knn failed classify document      concepts open directory correctly comes surprise—“copper” fairly      tologies enriched orders small category companies loca      magnitude through controlled web crawling prior  tion venture highland valley british columbia      text categorization feature generator analyzes mentioned training set category fail      documents maps appropriate  ure bag words approach unavoidable      tology concepts turn induce set gen reason important components story      erated features augment standard bag    argue needs case reuters      words feature generation accomplished through editor originally handled document likely knew      contextual analysis document text implicitly  quite lot business companies easily      performing word sense disambiguation coupled     assigned document category “copper”      ability generalize concepts using kind knowledge like machine learning algo      tology approach addresses main prob rithms access      lems natural language processing—synonymy        date quite attempts deviate      polysemy categorizing documents     orthodox bag words paradigm usually lim      aid knowledgebased features leverages infor  ited success particular representations based phrases      mation deduced documents  dumais et al  fuernkranz et al  named enti      experimental results conﬁrm improved  ties kumaran allan  term clustering lewis      formance breaking through plateau previously croft  bekkerman  explored      reached ﬁeld                              example techniques    introduction                                       overcome underlying problem—lack world knowledge  state art systems text categorization use order solve problem break through ex  duction algorithms conjunction wordbased features isting performance barrier fundamentally new approach  “bag words” decade improvements apparently necessary possible solution completely  formance best document categorization systems depart paradigm induction algorithms  came similar appears plateau tempt perform deep understanding document text  reached considerably superior considering current state natural language process  improvements evolutionary se ing systems does viable option  bastiani                                       time    bag words bow approach inherently limited propose alternative solution capitalizes  use pieces information explicitly men power existing induction techniques enriching  tioned documents provided vo language representation exploring new feature  cabulary consistently used speciﬁcally approach spaces prior text categorization employ feature gen  access wealth world knowledge possessed hu erator uses commonsense domainspeciﬁc knowl  mans easily puzzled facts terms mentioned edge enrich bag words new informative  training set                                  features feature generation performed completely auto    illustrate limitations bow approach consider matically using machinereadable hierarchical repositories  document  reuters knowledge open directory project odp ya  frequently used datasets text categorization research hoo web directory wikipedia encyclopedia  document discusses joint mining venture consortium paper use odp source background  companies belongs category “copper” knowledge example feature genera  document brieﬂy mentions aim tor “knows” companies mentioned miningbusiness highland valley happens host copper  collection texts associated each  information available web pages discuss cept feature generator uses texts learn  companies operations cataloged cor deﬁnition scope concept order able  responding odp categories mining drilling assign relevant documents  metals similarly web pages highland valley cat  aloged british columbia amass information currently use odp knowledge base  crawl urls cataloged odp effectively methodology general facilitate sources  multiplying knowledge available times commonsense domainspeciﬁc knowledge sat  armed knowledge feature generator isfy assumptions open directory comprises  structs new features denote odp categories hierarchy approximately  categories catalog  adds bag words augmented feature space  web sites each represented url ti  provides text classiﬁers cornucopia additional infor tle brief summary contents project consti  mation implementation proposed method tutes ongoing effort promoted  volunteer  ology classiﬁes document correctly              editors globe arguably largest publicly    feature generation fg techniques useful available web directory result pro bono work  variety machine learning tasks markovitch rosen open directory share drawbacks non  stein  fawcett  matheus  tech uniform coverage duplicate subtrees different branches  niques search new features target hierarchy biased coverage peculiar  cept better ones supplied training instances views editors charge nonetheless odp embeds  number feature generation algorithms proposed colossal human knowledge wide variety ar  pagallo haussler  matheus rendell  eas covering speciﬁc scientiﬁc technical  hu kibler  murphy pazzani  led cepts follows refer odp category nodes  signiﬁcant improvements performance range concepts avoid possible confusion term cat  classiﬁcation tasks feature generation egories usually reserved labels assigned  established research area machine learning documents text categorization  works applied text processing kudenko hirsh   building feature generator  mikheev  cohen  exception  studies using wordnet scott  urenalopez et al start preprocessing step performed fu   attempted leverage repositories ture text categorization tasks induce hierarchical text  world knowledge                                      classiﬁer maps pieces text relevant odp    contributions paper threefold pro cepts later serve generated features resulting  pose framework collection algorithms perform classiﬁer called feature generator according true  feature generation based largescale repositories purpose scheme opposed text categorizer  human knowledge second propose novel kind classiﬁer build ultimately feature generator rep  textual analysis performed during feature generation resents odp concepts vectors characteristic  views document text sequence local contexts words attributes reserving term features  performs implicit word sense disambiguation finally denote properties documents text categorization  scribe way enhance existing knowledge bases explain attribute vectors built  orders magnitude crawling world wide web use textual descriptions odp nodes  show section  approach allows break urls training examples learning feature genera  performance barrier currently reached best text cate tor descriptions constitute sizeable  gorization systems                                   information devised way increase vol                                                        ume training data orders magnitude    feature generation methodology                     crawling web sites pointed cataloged urls  proposed methodology allows principled uniform obtain small representative sample each site pooling  tegration external knowledge construct new features samples sites associated odp node  preprocessing step use knowledge repositories build gives wealth additional information  feature generator applying feature generator doc texts harvested www plagued  uments produces set generated features features noise adequate noise reduction crawled data  undergo feature selection discriminative ones harm good remedy situation  added bag words finally use traditional form attribute selection each odp node  text categorization techniques learn text categorizer using standard feature selection technique infor  augmented feature space                          mation gain example consider  attributes se    suitable knowledge repositories satisfy following lected odp concepts science—science research sci  quirements                                           entiﬁc biology laboratory analysis university theory study    repository contains collection concepts orga scientist artiﬁcial intelligence—neural artiﬁcial algo      nized hierarchical tree structure edges repre rithm intelligence aaai bayesian probability ieee cog      sent “isa” relationship using hierarchical ontol nitive inference additional noise reduction achieved      ogy allows perform powerful generalizations pruning nodes having urls situated deep                                                      sentences paragraphs optimal resolution docu                                                        ment segmentation determined automatically using                businessmininganddrilling            validation set propose principled multiresolution                attributes selected                 concept  … teck cominco …           approach simultaneously partitions document sev                                                        eral levels linguistic abstraction windows words sen            …                         web sites catalogued      tences paragraphs taking entire document     wwwteckcomincocom businessmininganddrilling   big chunk performs feature generation each                                                        levels rely subsequent feature selection step      “ … cominco generated features        tecks  pctowned … metallurgy                eliminate extraneous features preserving gen      lornex agreed metallicdeposits                                     feature   text       january  form mininganddrilling …       uinely characterize document                                    vector  classifier       joint venture       merging highland                              fact proposed approach tackles impor      valley operations …”  bag words                                                          tant problems natural language processing syn           figure  feature generation example         onymy polysemy classifying individual contexts implic  tree representing overly speciﬁc concepts itly performs word sense disambiguation resolves  signing textual content parents       word polysemy degree context contains    current implementation feature generator works polysemous words mapped concepts  nearest neighbor classiﬁer—it compares input text correspond sense shared context words  attribute vectors odp nodes returns correct sense each word determined help  desired number bestmatching ones generator neighbors time enriching document repre  performs generalization concepts constructs features sentation highlevel concepts generalizations  based classiﬁed concepts se ances addresses problem synonymy enhanced repre  tors hierarchy                                sentation easily recognize documents    let revisit example section  building actually talk related issues  feature generator crawls web sites ing different vocabularies  cataloged miningrelated odp concepts busi let revisit running example during feature  nessmining drilling sciencetechnologymining generation document  segmented sequence  businessindustrial goods servicesmaterialsmetals contexts mapped miningrelated odp  include wwwteckcomincocom wwwmining     concepts businessmining drilling  surpluscom   belong merged teck    cepts ancestors hierarchy rise  cominco company company’s prominence  set generated features augment bag words  mentioned frequently web sites crawled figure  observe training documents cat  consequently words “teck” “cominco”   egory “copper” underwent similar processing text  included set attributes selected represent classiﬁer induced consequently features based  concepts figure  illustrates process feature concepts selected during feature selection thanks  generation example                          high predictive capacity features                                                        document categorized correctly feature    contextual feature generation                    generation consistently caused bow classiﬁers err  traditionally feature generation uses basic features sup  plied training instances construct sophisti  feature selection  cated features case text processing ap using support vector machines conjunction bag  plying approach bag words leads losing words joachims  svms robust  important information word ordering presence numerous features ob  argue feature generation powerful served multitude features useful text  operates raw document text categorization ﬁndings corroborated  generator analyze document single unit recent studies brank et al  bekkerman   similarly regular text classiﬁers                 observed improvement small degradation    believe considering entire document svm performance feature selection consequently  misleading text diverse readily later works using svms did apply feature selection  mapped right set concepts notions mentioned leopold kindermann  lewis et al   brieﬂy overlooked instead propose parti situation changes drastically augment bag  tion document series nonoverlapping segments words generated features nearly technique  called contexts generate features ﬁner level automatic feature generation easily generate huge num  each context classiﬁed number concepts bers features likely aggravate “curse di  knowledge base pooling concepts results mensionality” furthermore feature selection allows  multifaceted classiﬁcation document way feature generator perfect classiﬁer  resulting set concepts represents various aspects  subtopics covered document                      gabrilovich markovitch  described class prob    potential candidates contexts simple sequences lems feature selection bag words actually im  words linguistically motivated chunks proves svm performanceleast concepts assigned document cor  movie reviews movies pang et al  deﬁnes sen  rect feature selection identify seamlessly elim timent classiﬁcation task reviews express pos  inate spurious ones                              itive negative opinion movies dataset                                                         documents categories positivenegative    empirical evaluation                                 used support vector machines learning algo  implemented proposed methodology using odp  rithm build text categorizers prior studies  snapshot april                             svms best performance text categorization                                                                                                implementation details                            dumais et al  yang liu   following es                                                        tablished practice use precisionrecall breakeven  pruning topworld branch contains non point bep measure text categorization performance  english material  obtained hierarchy    reuters datasets report micro macro   concepts  urls applying metho averaged bep categories differ size signiﬁ  dology knowledge base scale required enor cantly microaveraged bep operates document level  mous engineering effort textual descriptions concepts primarily affected categorization performance  urls amounted  mb text order increase larger categories hand macroaveraged bep  information training feature generator averages results individual categories small cat  populated odp hierarchy crawling egories training examples large impact  urls taking ﬁrst  pages bfs order en overall performance reuters datasets used  countered each site operation yielded  gb worth ﬁxed data split consequently used macro sign test  html ﬁles eliminating markup truncat test yang liu  assess statistical signiﬁ  ing overly long ﬁles  kb ended  gb ad cance differences classiﬁer performance ng  ditional textual data compared original  mb text movies performed fold crossvalidation used  supplied hierarchy obtained fold paired ttest assess signiﬁcance  crease data removing stop words  rare words occurring  documents stem  effect feature generation  ming remaining ones obtained  distinct ﬁrst demonstrate performance basic text cate  terms used represent odp nodes attribute vec gorization implementation column “baseline” ta  tors  informative attributes selected ble  consistent published studies using  each odp node using document frequency criterion svm reuters dumais et al  achieved  commonly used feature selection techniques microbep   categories  cate  information gain χ odds ratio yielded slightly infe gories ng bekkerman  obtained bep   rior results used multiresolution approach fea pang et al  obtained accuracy  movies  ture generation classifying document contexts level minor variations performance differences data  words sentences paragraphs ﬁnally entire doc preprocessing used different systems example  umentfeatures generated  bestmatching movies dataset worked raw html ﬁles  odp concepts each context                        ofﬁcial tokenized version order recover sen    experimental methodology                         tence paragraph structure contextual analysis                                                        rcv direct comparison published results dif  following test collections used             ﬁcult limited category sets date span   reuters reuters  following common prac documents speedup experimentation  tice used modapte split  training  testing table  shows results using feature generation  documents category sets  largest categories signiﬁcant improvements   shown bold   categories training testing example reuters datasets consistently observed larger improve   reuters corpus volume rcv lewis et al  ments macroaveraged bep dominated cate   documents presents new challenge gorization effectiveness small categories goes line  text categorization speedup experimentation used expectations contribution external knowl  subset corpus  training documents dated edge especially prominent categories  –  testing ones – follow training examples readily seen categorization  ing brank et al  used  topic  industry performance improved datasets notable im  categories constitute representative sample provements  reuters rcv   groups   categories respectively ran movies given performance plateau currently reached  domly sampled topic industry categories best text categorizers results clearly demonstrate  sets  categories each table  shows  category sets advantage knowledgebased feature generation  each group highest improvement categorization  performance                                          actual examples magnifying glass    newsgroups ng lang  wellbalanced thanks feature generation correctly classiﬁes  dataset  categories containing  documents each running example document  let consider ad                                                        ditional testing examples reuters incor    deﬁnition category sets used available                                                               light  httpwwwcstechnionacil˜gabrijcaiappendixhtml  svm implementation joachims                                                                                                                                                            baseline                  fgmulti                                                                fgwords                    fgdoc                                                                                                                                                                                                                                             bow        precisionrecall  bep              precisionrecall  bep                                    bow                                                bowgen          precisionrecall  bep   bowgen                                                             gen                                gen                                                                                                                   context window length words   fraction generated features selected fraction generated features selected   figure  varying context length movies figure  feature selection movies figure  feature selection rcvtopic   dataset       baseline    feature   improvement      feature generator context size word                           generation   vs baseline    level contexts maximum performance achieved                micro macro micro macro micro macro     ing pairs words fgdoc line shows result                bep  bep   bep   bep   bep    bep                                                        using entire document single context case   reuters                                        results somewhat better feature genera     categories         tion baseline inferior ﬁnegrained     categories         rcv                                                 wordlevel contexts fgwords best perfor    industry           mance far achieved using multiresolution ap    industrya         proach fgmulti use series linguistically    industryb          motivated chunks text starting individual words    industryc         generating features sentences paragraphs ﬁ    topic             nally entire document    topica            topicb               utility feature selection    topicc             experimental settings deﬁned section  fea   ng                                  ture generation constructs approximately – times   movies                                                                           features bag words conducted ex   table  text categorization feature generation periments understand effect feature selection  rectly categorized bow classiﬁer document  junction feature generation  belongs category “moneyfx” moneyforeign ex   earlier studies bow features  change discusses devaluation kenyan shilling deed useful svm text categorization section   “moneyfx”  largest cate ﬁrst experiment apply feature selection gener  gories word “shilling” does occur training ated features use selected ones augment en  documents feature generator eas tire bag words figures   bow line  ily recognizes kind currency produces fea picts baseline performance generated features  tures recreationcollectingpaper money recre bowgen curve shows performance  ationcollectingcoinsworld coins highlevel fea bag words augmented progressively larger fractions  tures constructed training examples generated features sorted information gain  consequently document classiﬁed correctly datasets performance peaks small fraction    similarly document  discusses italy’s balance generated features used retaining gen  payments belongs category “trade” word erated features noticeable detrimental effect similar  “trade” does occur short document phenomena observed datasets omit  feature generator considers document contexts results owing lack space  discussing italian deﬁcit reported bank italy second experiment set examine perfor  correctly maps concepts societygovern mance generated features bag  mentfinance societyissueseconomicinternationaltrade words gen curve figures   movies dis  businessinternational business trade carding bow features hurts performance somewhat  features generated training documents decrease far signiﬁcant  category document categorized correctly expected—using generated features lose                                                         bep compared bow baseline ng    effect contextual analysis                similar experiment sacriﬁces  bow  explore various possibilities deﬁne document formance dataset known diversi  contexts feature generation figure  shows text ﬁed vocabulary studies feature selec  categorization performance movies dataset changes tion particularly harmful situation  various contexts xaxis measures context length versed reuters datasets reuters gen  words fgwords curve corresponds applying erated features yield  improvement micro
