      locationbased activity recognition using relational markov networks                                 lin liao    dieter fox   henry kautz                              department science  engineering                                         university washington                                             seattle wa                            abstract                          extracted geographic databases including information                                                        kinds businesses various locations  sequen      paper deﬁne general framework ac tial information activity follows activ      tivity recognition building extending ity  global constraints number different      relational markov networks using example     homes workplaces additionally uses data collected      activity recognition location data show users improve classiﬁcation speciﬁc      model represent variety features user’s activities constraints soft example      including temporal information time day days person unusual      spatial information extracted geographic data movie middle workday furthermore norm      bases global constraints number  individuals different general com      homes workplaces person develop    monsense prior example people work jobs      efﬁcient inference learning technique based shuttle different homes necessary use      mcmc using gps location data collected     rich ﬂexible language robustly integrate wide      multiple people show technique ac variety local global probabilistic constraints      curately label person’s activity locations builds previous work extracting      show possible learn good mod places traces users’ movements gathered gps      els data using priors extracted localization technologies ashbrook starner       people’s data                              hariharan toyama  liao et al  work                                                        goes theirs recognizes    introduction                                       activities associated places previous  activity recognition contextaware computing gain approaches modeling personal movements place  ing increasing ai ubiquitous computing patterns require large training data each  communities existing systems focused user generalized new places new users  relatively low level activities small environments contrast relational approach requires individual  during short periods time paper training data leveraging data collected  recognize high level activities work summary contributions paper  ing shopping dining weeks  general framework sensorbased activity  uses data wearable gps location sensor able recognition based relational markov networks  identify user’s signiﬁcant places learn discriminate rmns taskar et al  highly  activities performed locations — includ expressive wellsuited discriminative learning  ing novel locations activity information used  extension rmns incorporate complex global  applications example used automat features using aggregations labelspeciﬁc cliques  ically instruct user’s cell phone ring dining  efﬁcient markovchain montecarlo mcmc algo  restaurant support home rehabilitation people rithms inference learning extended rmns                                                     suffering traumatic brain injuries salazar et al  particular mcmc algorithm simultaneously  providing automatic activity monitoring estimat evaluate likelihood function gradient  ing highlevel activity categories expanded  incorporate additional sensor information recog  positive experimental results real data multiple  nizing ﬁnegrained indoor household tasks subjects including evidence improve accu  scribed philipose et al                       racy extracting priors others’ data    behavior patterns highly variable reliable paper organized follows introduce  discrimination activities sources relational activity model section  inference learning  evidence account considers  tempo discussed section  followed experimental eval  ral information time day  spatial information uations conclusions future work given section   relational activity model                      plate share weights wc  resulting cliques                                                        factorize conditional distribution  section ﬁrst discuss rmns extensions  show use modeling activities                                                                                    py                   φ                                                                                     zx                relational markov networks                                             c∈c vc ∈c                                                                                         rmns extensions conditional random fields crfs                            expw   · fc vc                                                                           zx                 undirected graphical models developed                   c∈c vc ∈c  labeling sequence data lafferty et al  crfs                                                                                         expwt ·                discriminative models shown outperform              zx  generative approaches hmms markov random  ﬁelds areas natural language processing lafferty normalizing partition function zx                                                                           et al  vision kumar hebert           φc    follows moving                                                            c∈c   vc ∈c      rmns extend crfs providing relational language products exponent combining summations  describing clique structures enforcing parameter sharing  template level rmns extremely ﬂex  ible concise framework deﬁning features  relational activity models  used activity recognition context             relational activity models    rmn consists three parts schema illustrate concepts using example  main set relational clique templates correspond locationbased activity recognition model ﬂexible  ing potentials Φ schema speciﬁes set classes applied variety activity recognition tasks  entity types attributes each class attribute schema activity recognition based temporal  content attribute label attribute reference spatial patterns shown fig includes three classes  attribute speciﬁes reference relation classes activity place transition  instantiation schema speciﬁes set entities activity activity central class domain  each class values attributes each entity tribute label hidden variable set possible  context instantiation consists sequence labels experiments ’athome’ ’atwork’ ’shop  signiﬁcant locations visited user temporal ping’ ’diningout’ ’visiting’ ’others’ attribute id serves  spatial attributes                               primary key class contains temporal infor    relational clique template ∈ similar relational mation associated activity timeofday day  database query sql selects tuples ofweek duration values discretized  stantiation query result denoted ci extend necessary finally place reference attribute points  deﬁnition templates ways allow place entity activity performed  template select aggregations tuples example place class place includes boolean attributes near  group tuples deﬁne potentials counts restaurant nearstore indicate  statistics groups second introduce labelspeciﬁc restaurants stores nearby  cliques structures depend values labels transition transition captures temporal succession relation  example model construct clique activities ship activities reference attributes  labeled “athome” labels hidden during refer pair consecutive activities  ference cliques potentially involve labels label based schema deﬁne following relational  speciﬁc cliques speciﬁed allowing label attributes clique templates each takes account number  used “where” clause sql query     discriminative features    each clique template associated potential func  tion φc vc  maps tuple values variables aggre  temporal patterns different activities differ  gations nonnegative real number using loglinear ent temporal patterns duration time  combination feature functions following repre day local patterns modeled clique templates                                                          connect each attribute activity label  sentation φc vc   expwc ·fc vc  fc  deﬁnes                                                         geographic evidence information types  feature vector wc transpose corre  sponding weight vector instance feature businesses close location extremely useful  number different homes deﬁned using aggregations      determine user’s activity information    speciﬁc instantiation rmn deﬁnes condi   extracted geographic databases microsoft  tional distribution pyx labels given observed mappoint hariharan et al  used experi  attributes compute conditional distribution ments location information databases  rmn generates unrolled markov network    accurate consider information  nodes correspond content attributes label checking example restaurant  tributes cliques unrolled network built ap certain range location  plying each clique template ∈ instantiation  transition relations ﬁrstorder transitions  result cliques template fig activities informative example stay  example cliques originate tem ing home followed work common                  activity                                                        timeofdaydayofweekduration                       id                                                           nearrestaurantnearstore                       label                                                        label    place              timeofday   transition       id              dayofweek            nearrestaurant    duration                                                                nearstore                       place                                                                         figure  schema relational activity model dashed lines indicate reference relations classes example  unrolled markov network activity locations solid straight lines indicate cliques generated templates temporal geographic  transition features bold solid curves represent spatial constraints activity   associated place    dashed curves stand global features generate labelspeciﬁc cliques activity   labeled ’athome’      dining immediately followed din using mcmc inference gilks et al  nut      ing rare sql query clique template shell label object changed during sam                                                    pling determine cliques affected      select alabel alabel                         change recompute potentials      activity activity transition         ﬁrst implemented mcmc using basic gibbs sampling      tfromaid ttoaid                 unfortunately technique performs poorly model                                                        strong dependencies labels make    spatial constraints activities place                                                        mcmc mix faster ﬁrst make additional spatial      similar words number different types                                                        straint activities occurring place      activities place limited express                                                        label relaxation constraint ad      constraint using aggregation function count                                                        dressed future work hard constraint allows      select countdistinct label                      activities occurring place socalled      activity                                     block develop mixture transition kernels      group place                                    converges correct posterior    global features features model global soft ﬁrst kernel block gibbs sampler each step      straints activities person number differ update labels block simultaneously sampling      ent home locations example global constraints conditional distribution      constraint modeled clique template                                selects places labeled home returns yk  y−k ∝ expw · fx y−k ∪ yk       different                                                        index block yk label block      select countdistinct place                      y−k labels blocks second kernel      activity                                     metropolishasting mh sampler update label      label’athome’                              block mh sampler randomly picks block      note label variable appears “where” proposes exchange label yk yj acceptance rate      clause example labelspeciﬁc clique proposal follows      different activity recognition context global features                                                                                 expwt  · fx y      model information “the number     ay    min                              times person lunch day”                                           expwt · fx                                                                         ﬁrst three templates feature functions fc  labels exchange  just indicator functions return binary values respectively  return numbers templates numbers different homes workplaces stored                                                        chains global variables allows compute    inference learning                             global features locally kernels gibbs kernel                                                        increase decrease numbers depending labels    labeling activities                              given block mh kernel numbers remain                                                        intact each time step choose gibbs sampler  application task inference estimate la                                                        probability γ mh sampler probability  − γ  bels activities given sequence locations visited  person rmn converts location sequence  supervised learning  unrolled markov networks illustrated fig infer  ence relational activity model complicated fact show learn generic activity models labeled                                                        activity sequences different users learning cus  structure unrolled markov network change tomized model individual user special case  during inference labelspeciﬁc cliques using   parameters learned feature weights  standard belief propagation networks require deﬁne clique potentials  avoid overﬁtting  construction cliques labels obviously perform maximum posterior map parameter estima  inefﬁcient taskar et al  overcome problem tion impose independent gaussian prior constantvariance each component pw ∝ exp−w − input  weights provided optimizer  µt · − µσ µ mean σ vari output lw ∇lw  ance  deﬁne map objective function negative                ∇lw  loglikelihood training data subjects plus prior evaluate gradient                                                          foreach subject                                                           run mcmc samples                                                                                     lw  ≡      − log yj  xj  − log pw                                                             feature count difference ∆fj  ≤ ≤                                                       end                                                        compute gradient ∇lw using eq                                     w−µt· w−µ      −wt· fx    log zx                                               σ              evaluate objective value lw                                                      time calling function  ranges different users activity lw˜   lw   w˜                                                               ˜i     labels each user  convex global minimum ∆fj  ∆fj  ≤ ≤ ≤ ≤   using standard optimization algorithms taskar  et al  apply quasinewton technique ﬁnd  compute lw using eq    optimal weights sha pereira  each iteration lw  lw˜                                                                 lw˜   lw w˜    technique requires value gradient  computed                                                                ∆˜f  ∆f  ≤ ≤  ≤ ≤  weights returned previous iteration                                                                                                 end  evaluating objective function                       end  intractable compute exact objective values  algorithm  mcmcbased algorithm simultaneously  simplest cases fact evaluating objective function gradient  speciﬁc necessary evaluate partition func  tion zx  requires summation possible la                                                                       bel conﬁgurations approximate objective value using ∆fj  fxj yj  − fxj yj difference  montecarlo methods geyer thompson  sup  tween sampled empirical feature counts  pose know value lw˜  weight vector  w˜  each subject use mcmc inference algorithm  random samples y˜i ≤ ≤ distri compare   require difference                                                      sampled empirical feature counts  bution   w˜  lw approximated                                                      samples  based weights w˜                                                      based best weight                                            lw ≈ lw˜    log      expw − w˜ · ∆˜f                                                     estimate w˜  reuse sampled feature counts                                                gradient estimation making objective value evalua         − µt · − µ − w˜ − µt · w˜ − µ      tion efﬁcient                                                                          σ                              algorithm simultaneously estimates each iteration                                                        value gradient negative loglikelihood           ˜i         ∆fj    fxj y˜j  − fxj yj difference given weights estimates used quasi  tween sampled feature counts using w˜ empirical fea newton approach compute new weights esti  ture counts labeled data                      mation repeated shown alg  lw˜  lw    eq  used estimate values lw relative initialized  objective values evalu  lw˜  fortunately relative values sufﬁcient ated relative objective value initial weights later  purpose optimization shown best ap iterations ﬁnd better weight estimate makes  proximation  obtained w˜ close optimal lw lw˜  update w˜ new  during optimization algorithm updates w˜                                                                         new lw˜  ∆˜f  ≤ ≤  ≤ ≤  better weight estimates possible                                                                                     doing evaluate objective values efﬁ  evaluating gradient                               ciently able accurate approximations  gradient objective function ∇lw equals w˜ approaches closer optimal weights  difference sampled feature counts em  pirical feature counts plus prior term generate  experiments  sampled feature counts run mcmc evaluate locationbased activity recognition technique  ference suppose obtained random samples                                                    collected sets location data using wearable gps  yj  ≤ ≤ distribution  xj units ﬁrst data set called “single” contains location  compute gradient                          traces single person time period months                                                          − µ      fig  includes  visits  different places   ∇lw          ewfxj − fxj yj          second data set called “multiple” collected ﬁve                                               σ                                                    different people week each each person’s data                                                    include   visits   different places ex                          − µ            ≈            ∆f                       tracted places  visits gps logs detecting loca                                σ                                                tions person spends  minutes hariharan toyama  each instance corresponds ac  tivity clustered nearby activity locations places  training evaluation let subjects manually label  types activities trained models tested  accuracy accuracy determined activities  likely labeling correct  applying learned models people  practice great value learn generic activity  model immediately applied new users      athome       atwork       shopping  additional training experiment used “mul      diningout    visiting      tiple” data set performed leaveonesubjectout cross figure  locations contained “single” data set  validation trained using data subjects collected period months xaxis  miles long  tested remaining average error rates indi  cated white bars fig using features improved learning through priors extracted  generic models achieved average error rate  estimating weights rmns prior imposed  seen global features spatial constraints signif order avoid overﬁtting additional information  icantly improve classiﬁcation gage impact different zero mean gaussian typically used prior taskar  habits results performed evaluation et al  peng mccallum  demonstrated  using “single” data set case used onemonth better accuracy achieved featuredependent vari  data training threemonth data test ances used experiment shows performance  repeated validation process each month improved estimating prior means weights  sults shown gray bars fig case µ eq  using data collected people  models achieved error rate  using fea experiment compared models spe  tures experiment shows possible learn good ciﬁc person trained using zeromean prior models  activity models groups people demonstrates trained using estimated prior case ﬁrst  models learned “similar” people achieve learned feature weights people used  higher accuracy indicates models improved mean gaussian prior evaluated perfor  grouping people based activity patterns  mance different amounts training data available    table  shows confusion matrix experiment test person results shown fig  generic models rightmost white bar fig error rates counted novel places places  seen approach able perfectly label homes work visited training data  places technique performs surprisingly irregular using data generate  activities given extremely difﬁcult distinguish prior boosts accuracy signiﬁcantly especially  based location information confusion matrix small amounts training data available  shows simply labeling places frequent bayesian prior allows model smoothly shift  activity home result error rate  generic customized end data                                                        given subject available approach returns                          inferred labels               generic prior model end labeled data    truth  home    work   shop   dining  visit    available model adjusts                                                        speciﬁc patterns user   home                                         work                                         additional experiments    shop                                          comparison built basic hmms hid   dining                                         den states labels observations inde    visit                                         pendent given states parameter estimation hmms                                           labeled data frequency counting  table  confusion matrix crossvalidation generic models likely labels using viterbi algorithm  features                                    onemonthtraining crossvalidation “single” data set                                                        hmm produced average error rate  using    evaluate impact number people available temporal geographic transition features   model learning trained model using data dif advantages discriminative learning using  ferent numbers subjects tested remaining features rmns performed better hmms  features used average error rates cross duced relative error rate   validation shown fig trained using separate set experiments tested performance  subject does perform error rate mcmc sampler visualizing standard gelman   mainly patterns speciﬁc person rubin statistics gilks et al  generated parallel  applied subjects used  training patterns learned generic spatial constraints global features satisfy ﬁrst  models achieve signiﬁcantly higher accuracy          order markov assumption difﬁcult model hmms
