              compiling bayesian networks using variable elimination                     ∗                                    mark chavira      adnan darwiche                                       science department                                   university california los angeles                                       los angeles ca                                       chaviradarwichecsuclaedu                        abstract                          run efﬁciently using structured                                                        representation like adds ri bahar et al  afﬁne      compiling bayesian networks proven ef     adds  sanner mcallester  representations com      fective approach inference utilize posed confactors poole zhang  sparse repre      global local network structure pa   sentations larkin dechter  collection      deﬁne new method compiling based     representation makes use local structure      variable elimination ve algebraic deci  skip certain arithmetic operations represent factors      sion diagrams adds approach impor      compactly effectiveness ap      tant following reasons exploits lo proaches limited practice      cal structure effectively previous overhead incur outweigh gains      techniques based ve second approach al                                                          work answer multiple queries si      lows ve variants compute                                                        multaneously using ve jointree algorithm      swers multiple queries simultaneously                                                        jensen et al  lauritzen spiegelhalter      approach makes large body research                                                        cozman  exception theoretical results      structured representations factors relevant                                                        darwiche  demonstrate keeping trace      circumstances pre                                                        use ve basis compilation algorithm      viously finally experimental results demonstrate                                                        refer tabular compilation compile      ve exploit local structure effectively                                                        bayesian network ofﬂine arithmetic circuit ac      state–of–the–art algorithms based condition                                                        tabular compilation runs time space exponential      ing networks considered                                                        treewidth resulting ac size exponential treewidth      lead faster compilation times                                                        ofﬂine compilation complete ac used                                                        online answer queries simultaneously time lin    introduction                                       ear size applicability approach                                                        limited tabular compilation provides practical                                                     variable elimination zhang poole  dechter  advantage jointree  ve well–known algorithm answering probabilistic  queries respect bayesian network algorithm important observation compiling using  runs time space exponential treewidth net ve need use tables instead use  work advantages ve include generality simplicity structured representations factors observation  paper consider aspects ve ﬁrst seemingly innocent critical implications  effectively utilize local structure form determin usual cost incurred using structured repre  ism jensen andersen  context–speciﬁc inde sentations gets pushed ofﬂine phase  pendence boutilier et al  perform inference afforded second usual advantage realized using  efﬁciently second consideration answer mul structured representations means size  tiple queries simultaneously example given particular sulting ac necessarily exponential treewidth  evidence like able simultaneously com smaller ac translates directly efﬁcient online  pute probability evidence posterior marginal each inference efﬁciency matters pro  network variable like able repeat posed approach important key reasons  process different evidence sets             exploits local structure effectively previous    proposals extended utilize local struc techniques based ve second approach allows  ture context ve standard version ve variants compute answers multiple queries  algorithm uses tables represent factors algorithm simultaneously approach makes large body                                                        research structured representations factors rele    ∗this work partially supported air force grant vant circumstances previously  fap jplnasa grant  finally experimental results demonstrate consid                                                    ijcai                                                    ered networks ve exploit local structure effectively                xy      zf  state–of–the–art algorithms based conditioning applied                                                                                        logical encoding networks lead                            faster compilation times                                                                                                                                                demonstrate ideas propose new method                                                                                                                              compiling based ve algebraic decision diagrams                                  adds refer method compiling add                            compilation known adds represent                                 initial conditional probability distributions factors                      bayesian network compactly tables                     clear adds retain advantage pro  ducing intermediate factors during elimination process figure  add variables corre  especially process compilation involves sponding table represents dotted edges point low–  evidence note evidence smaller children solid edges point high–children  adds intermediate factors    experimental results demonstrate important  points respect add compilation ﬁrst point deals  elimination using adds  ac sizes add elimination compilation  perform tabular elimination compilation add graph representation function maps                                                                                                    massive amounts local structure dramatically stantiations boolean variables real–numbers ri bahar                                                                   derperform tabular elimination add et al   figure  depicts add corresponding  compilation produces acs smaller table function represents worst case add  produced tabular compilation cases space complexity table representing  lesser amounts local structure second function factor operations multiplication  smaller ac size online inference time capable summing–out implemented adds polynomial  outperforming jointree orders magnitude finally add time points important respect  compilation faster cases state–of– adds multiplication summing–out  the–art compilation technique reduces problem available adds use adds during ve instead  logical inference darwiche                    tables second adds leverage local structure                                                        add smaller corresponding table    paper organized follows begin section                                                         reason applied adds fac  reviewing ve elimination using adds compilation                                                        tor operations multiplication summing–out result  acs section  shows trace kept dur                                                        far fewer arithmetic operations numbers  ing elimination employing adds compile network                                                        factor operations acting tables finally constants  ac discuss section  implications com                                                        volved using adds larger involved  piling using structured representations factors present                                                        using tables elimination using adds  experimental results section  conclude section                                                         longer elimination using tables                                                        add performs fewer arithmetic operations num    background                                         bers run memory  section brieﬂy review ve elimination using using adds cases tabular elimination does  adds compilation acs                       discuss later deal many–valued                                                        variables add    variable elimination                                                          compiling acs  variable elimination standard algorithm computing  probability evidence respect given bayesian notion using arithmetic circuits acs perform                                                                                              network zhang poole  dechter  space probabilistic inference introduced darwiche                                                               reasons mention points regard al   each bayesian network associate cor  gorithm algorithm acts set factors each responding multilinear function mlf computes                                                        probability evidence example network fig  factor involves set variables maps instantiations                                    variables real–numbers initial set factors ure —in variables boolean  network’s conditional probability distributions usu three values—induces following mlf  ally tables elimination driven ordering vari λ λ λ θ θ θ    λ  λ  λ  θ θ  θ                                                                  cab cab  ables called elimination order during algorithm   factor operations performed times factors mul λ λ θ  θ θ        λ  λ  λ  θ θ  θ                                                          λa   tiplied variable summed factor factor                                   operations reduce performing multiplication ad terms mlf onetoone correspondence  dition operations real–numbers tables rows network’s joint distribution assume  common representation factors representation indicator variables λx value  parameter  supports multiplication summing–out used variables θxu value prxu each term                                                    ijcai                                                                                                                     multiplyα   symadd α     symadd                                                    algorithm                                                                                            returns symadd              compile                                                                                swap α α posα posα                                                                                        cacheαα  null                                                       return cacheαα                                                    α α leaf nodes                                                       α ← new add leaf node                                                                                    acα ← new ac ∗ node children acα acα                                                          posαposα                                                           α ←        cab                                    new internal node                              cab                                                       varα ← varα  c c                                             cab                                           loα ← multiplyloαloα                                                          hiα ← multiplyhiαhiα    figure  bayesian network corresponding ac                                                           α ← new internal node                                                          varα ←  varα                                                          loα ← multiplyloαα  product probabilities evaluates probability  hiα ← multiplyhiαα  corresponding row joint mlf add  end                                      probabilities joint sum  compute  cacheαα ← α  probability pre evidence need way exclude  return α  certain terms sum removal terms accom  plished carefully setting certain indicators  instead      according evidence                         stant each variable network construct    fact network’s mlf computes probability indicator add acts placeholder evidence  evidence interesting network mlf exponential entered during online inference phase assuming  size factor mlf small                                                                       pre      variable binary values   indicator  ﬁt memory compute    add  consist internal node labeled  time linear size factorization factor variable having sink children child corre  ization form ac rooted dag                                                        sponding xx sink labeled pointer  directed acyclic graph internal node represents                                     λ   λ                                                         single–node ac labeled indicator   sum product children leaf represents figure shows simple bayesian network figure  stant variable context variables indi shows corresponding symbolic adds  cator parameter variables example ac depicted  figure  refer process producing ac working symbolic adds requires modiﬁcation  network compiling network                     standard add operations minimal way ﬁrst    ac network compute pre point add operations typically implemented  assigning appropriate values leaves comput cursively reducing operation adds opera  ing value each internal node bottomup fashion tions smaller adds reach boundary conditions  value root answer query adds correspond sinks boundary condi  compute posterior marginal each variable tions need modiﬁed order produce symbolic  network performing second downward pass darwiche add operations example algorithm  speciﬁes   queries computed simultaneously multiply symbolic adds applied internal                                                                             pos  lo     hi  time linear size ac main point add node functions  return position  process repeated evidence sets variable labeling node add variable order                                                                                    false  desired recompiling                      low–child corresponding   high–child                                                        corresponding true respectively applied                                                        add sink functions posand ac return ∞ pointer    add compilation                                    ac labels sink respectively finally cache  seen adds used place tables during standard computed table used add operations  ve compilation produces ac network main observation algorithm identical  section combine methods compile ac multiplying normal adds ri bahar et al  ex  using ve algorithm employs adds represent factors cept line  multiplying normal adds line    core technique approach work label newly created sink constant  adds sinks point acs roots instead point product constants labeling α α multi  ing constants refer adds symbolic plying symbolic adds instead label new sink  adds  given bayesian network convert each condi pointer ac represents analogous multiplication  tional probability table cpt symbolic add called ac consist new multiply node having children  cpt add ﬁrst convert cpt acs pointed α α algorithm  mal add replace each constant sink summing–out variable symbolic add constructed  pointer ac consisting single node labeled algorithm summing–out variable normal                                                    ijcai                                                                                                                                                             xypryx                                                                                                                         prx                                                                                                                                                                                             x x    y y                                                         cpt add     cpt add     indicator  indicator                                                                  add  add                                                                                       figure  simple bayesian network symbolic adds representing network    algorithm  compilen  bayesian network returns ac dundant ac nodes each entry ac node                                                        constructed indexed node’s label children    Ψ ← set indicator cpt adds       construct new ac node ﬁrst consult unique    π ← ordering variables πi ith variable order table similar node constructed     number variables         case simply point existing node instead     ←α  ∈ Ψα  mentions variable πi           constructing duplicate node standard practice       Ψ ← Ψ −  ∪Σ        α                     πi α∈p                         use unique table add nodes    end for     β ←       α                                          multi–valued variables network variable         α∈Ψ    return acβ                                      values deﬁne add variables follows                                                                                                                                                        each value xi  create add variable xi                                                        translate instantiations straightforward way                                                                                          true                                                              example translate         xi  add analogous way modifying code labels false                                                                                                  construct add xi  newly created sinks case instead labeling                                constant representing sum instead label pointer enforces constraint exactly xi true                                                        multiply add cpt indicator add  new addition node                                             compilation process algorithm  mentions  finally eliminating summing–out                                                        multi–valued variable sum corresponding add  line  begins representing bayesian network using       symbolic adds described previously gener variables xi simultaneously  ate ordering variables using minﬁll heuristic converting cpt add straightforward  line  lines – perform variable elimination stan way construct add cpt construct add  dard way using multiply sum–out operations sym each row cpt add resulting adds  bolic adds afterward left trivial symbolic method extremely inefﬁcient large cpts  add sink labeled pointer ac ac thousand parameters instead construct tree–structured  factorization network mlf compilation add terminals correspond cpt rows  given network each internal node ac labeled use standard reduce operation adds produce dag  multiplication addition operation each leaf labeled structure  constant indicator variable ac represents simpliﬁcations certain cases simpliﬁcations pos  history trace arithmetic operations performed during sible example multiplying add nodes  elimination process                              nodes α sink labeled pointer ac node    procedure scale produce results labeled constant  simply  report later augmented number key return α doing work similar simpliﬁcations  techniques                     exist constant  summing–out operation    add variable order adds require ﬁxed variable order figure  depicts elimination process applied  independent elimination order dis symbolic adds figure using elimination order  cussed use reverse order used elimina yx ﬁrst step multiply set symbolic adds  tion process ensures variable eliminated involving  consists ’s cpt add ’s indi  add appears add sum– cator add figure shows result observe each  operation adds known efﬁcient add sink points ac represents multiplication  summed variable appears   acs pointed sink ’s cpt add    unique table maintain cache called unique table pointed sink ’s indicator add ob  add literature ensure generate serve acs involved multiplication                                                    ijcai                                                    sink labeled   resulting ac simpliﬁed          tabular     add  figure shows result summing–out network  time ms time ms improvement  symbolic add figure each add node labeled   alarm                                                                                     barley                        children replaced sink bm                       points addition node simpliﬁcation occurred diabetes                 figure shows result multiplying symbolic adds  hailﬁnder                        involving variable steps ﬁrst figure x’s link                        indicator add result x’s cpt add finally mm                      figure shows result summing–out fig    mildew                        ure point remaining sym munin                   bolic add compilation                        munin                                                                                   munin                                                                                   munin                          implications                                            pathﬁnder                      research using alternatives tabu pigs                          lar representations factors ve motivation st                       research tabular elimination makes use global tccf                                                                                    water                          network structure topology miss oppor  tunities afforded local structure make inference ef table  time perform ve compilation using tables  ﬁcient structured representations factors typically exploit using adds  local structure lessen space requirements required  inference skip arithmetic operations numbers mul  tiplications additions required inference overhead incurred during ofﬂine phase each arithmetic  cases structured representations factors success operation saved makes size resulting ac smaller  ful performing inference tabular elimination runs yielding efﬁcient online inference observations  memory cases structured representations al make research structured representations factors ap  low faster inference tabular elimination plicable circumstances pre  time space overhead involved using struc viously major advantage adding compilation  tured representations factors outweigh elimination compute online answers  beneﬁts particularly true exces queries simultaneously quickly  sive amounts local structure present network ta jointree algorithm darwiche  details  ble  demonstrates performance elimination com  pilation using tables adds applied set net  works considering later paper add op  experimental results  erations performed using publicly available cudd section present experimental results applying  add package httpvlsicoloradoedu∼fabiocudd add compilation compare add compilation tabu  cases does add elimination outperform lar compilation ace compilation jointree add  tabular elimination networks involved bm operations performed using cudd add package   mm contain massive amounts determinism httpvlsicoloradoedu∼fabiocudd modiﬁed work  remaining cases add elimination actually slower symbolic adds ace httpreasoningcsuclaeduace  tabular elimination order magnitude state–of–the–art compiler encodes bayesian net  large number examples structured repre works logical knowledge bases applies condi  sentations factors slower tabular elimination tioning result ace shown extremely  limited applicability                          effective networks having large amounts local structure    main observation paper chavira et al   able compile net  elimination using structured representation factors works treewidths excess one–hundred ace  slower tabular elimination structured representations shown chavira darwiche  perform  powerful context compilation compi line inference orders magnitude efﬁciently join  lation ofﬂine process extra time afforded tree applied networks having treewidth small  fact combination structured representations jointree work having lesser amounts local struc  compilation ideal purpose compilation ture networks ace online inference efﬁ  spend time ofﬂine effort identify opportunities cient compile times excess thousand  savings used repeatedly during online inference seconds networks experimented su  context compilation disadvantages perset networks chavira darwiche   using structured representations severe virtu experiments ran ghz core duo processor gb  ally disappearing advantages retained memory using networks table  make                                                        experiments fair possible each network ﬁrst    note use structured representations factors  usually asymptotically worse use tabular represen ace available test platform ace compi  tations particularly true adds         lation carried ghz pentium gb memory                                                    ijcai                                                    
