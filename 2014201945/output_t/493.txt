                                  self adaptive particle filter                                                  alvaro soto                                  pontiﬁcia universidad catolica chile                                      department science                              vicuna mackenna   santiago  chile                                              asotoingpuccl                        abstract                          section  presents method adaptively estimate num                                                        ber particles section  presents method adaptively      particle ﬁlter emerged useful tool improve propagation function section  shows      problems requiring dynamic state estimation  sults applying self adaptive ﬁlter visual tracking      efﬁciency accuracy ﬁlter depend task finally section  presents main conclusions      number particles used estimation work      propagation function used reallocate      particles each iteration features  particle filter      speciﬁed kept ﬁxed reg      ular implementation ﬁlter practice bayesian terms posterior distribution state      highly inappropriate ignores errors expressed      models varying dynamics pro                                                                   px   β py  px       cesses work presents self adaptive version                          t−                 particle ﬁlter uses statistical methods β normalization factor xt represents state      adapt number particles propagation time yt represents information      function each iteration furthermore method collected time equation  assumes xt totally      presents similar computational load stan explains current observation yt      dard particle ﬁlter show advantages  particle ﬁlter provides estimation poste      self adaptive ﬁlter applying synthetic ex rior equation   main steps sampling weighting      ample visual tracking targets real resampling sampling step consists taking sam      video sequence                                   ples particles socalled dynamic prior distribution                                                        pxtyt− weighting step resulting parti                                                        cles weighted likelihood term pytxt finally    introduction                                       resampling step usually applied avoid degeneracy  particle ﬁlter useful tool perform dynamic state es particle set key point explains efﬁciency  timation bayesian inference provides great efﬁciency ﬁlter comes using markovian assumption  extreme ﬂexibility approximate functional non expressing dynamic prior  linearity key idea use samples called particles     represent posterior distribution state given se pxtyt−  pxtxt− pxt−yt−dxt−   quence sensor measurements new information arrives  particles constantly reallocated update esti expression provides recursive implementation  mation state                    ﬁlter allows use estimation pxt−yt−                                                                               efﬁciency accuracy particle ﬁlter depend select particles xt− iteration par  mainly key factors number particles used ticles propagated dynamics process                                                               estimate posterior distribution propagation func pxtxt− complete sampling step  tion used reallocate particles each iteration each iteration operation particle ﬁlter  standard implementation ﬁlter speciﬁes factors seen importance sampling process tanner  im  forehand keeps ﬁxed during entire operation portance sampling provides efﬁcient way obtain sam  ﬁlter paper present self adaptive particle ﬁl ples density px cases function  ter uses statistical methods select appropriate num evaluated affordable possible sample  ber particles suitable propagation function each directly basic idea importance sampling use  iteration                                            proposal distribution qx called importance function    paper organized follows section  provides obtain samples xi weigh each sample using  background information standard particle ﬁlter compensatory term given pxiqxi possible toshow tanner  mild assumptions set true posterior distribution empirical distribution  weightedsamples resembles target distribution px known nonparametric maximum likelihood    sampling weighting steps particle ﬁlter cor estimate kldsampling based assumption  respond basic steps importance sampling pro true posterior represented discrete piecewise  cess case given true posterior pxtyt stant distribution consisting set multidimensional bins  known samples drawn importance func assumption allows use χ asymptotic conver  tion corresponds dynamic prior pxtyt− using gence likelihood ratio statistic ﬁnd bound  importance function compensatory terms exactly number particles  non normalized weights used weighting step                                                                                   particle ﬁlter methods presented paper use                 χk−−δ                 sults theory importance sampling provide                    ²  self adaptive version particle ﬁlter          ² upper bound error given kl                                                        divergence  − δ quantile χ distribution    adaptive selection number                −  degrees freedom given number                                                        bins support     particles                                            problem kldsampling derivation  selection number particles key factor bound using empirical distribution implicit  efﬁciency accuracy particle ﬁlter computa assumption samples comes true distribution  tional load convergence ﬁlter depend case particle ﬁlters samples come  number applications select ﬁxed number parti importance function furthermore quality  cles advance using ad hoc criteria statistical methods match function true distribution  monte carlo simulations standard statistical main elements determines accuracy ﬁlter  bound boers  unfortunately use ﬁxed num suitable number particles bound given  ber particles inefﬁcient dynamics kldsampling uses information complexity  processes usually produces great variability complex true posterior ignores mismatch  ity posterior distribution consequence initial true proposal distribution  estimation number particles larger ﬁx problem kldsampling need way  real number particles needed perform good esti quantify degradation estimation using samples  mation posterior distribution worse point importance function goal ﬁnd equivalent  selected number particles small causing number samples importance true densities  ﬁlter diverge                                     capture information    effect number particles accuracy context monte carlo mc integration geweke  ﬁlter determined factors complexity  introduced concept relative numerical efﬁciency  true density closely proposal density mimics rne provides index quantify inﬂuence  true density factors intuitive estimation sampling importance function idea rne  complex pdf requires greater number sam compare relative accuracy solving integral  ples correctly represent predictable shape ing samples coming true proposal den  function greater mismatch proposal sity accuracy measured according variance  true densities produces wasted samples located estimator integral  irrelevant parts true distribution previous works use mc integration estimate mean value  adaptively determine adequate number particles state emc variance estimator given  failed consider factors fox et al  doucet et al    koeller fratkina  fox                                                                      aren   ar xn             propose methods based theory                    mc            statistics used adaptively estimate num number samples coming true dis  ber particles represent target posterior distribution tribution px subscript expresses variance  adding signiﬁcant load normal operation involved computed using target distribution  ﬁlter each cycle particle ﬁlter techniques samples come importance function qx  estimate number particles certain level variance estimator corresponds variance  conﬁdence limits maximum error approximation importance sampling given geweke                                                            kldsampling revised                                                                                                                             areisx  eqx−epx  wx nis  σisnis  kldsampling algorithm fox  method                                                   adaptively estimate number samples needed bound wx corresponds pxqx weights  error particle ﬁlter error measured                                                        nis  number samples coming importance  kullbackleibler divergence kldivergence function    complexity understood terms infor rest section concentrate iteration  mation needed code distribution               ﬁlter drop subscript  achieve similar levels accuracy variance  testing bounds  estimators equal allow ﬁnd relation figure  shows distributions used test bounds  quantiﬁes equivalence samples true true distribution corresponds px       proposal density                                importance function qx                         ar                             trials desired error                                                                                                 set  conﬁdence level                           σis    replacing   allows correct bound given                                                                                     samples px  kldsampling samples come                                  samples qx                                                                                                                                                           true distribution importance function                                     true distribution px                                                                                 − − −proposal qx                       σis                    nis             χk−−δ                                              arpx ²                                                                                                                                     prx    using mc integration arpx σis estimated                                                                                               pn                                                                     wi                                                             arpx  epx  − epx ≈   pn       − epx                                                                                                                                −                                                                                                                                                                                      figure  inefﬁcient allocation samples mismatch  σis ≈          −                                                                     tween px qx            wi          wi            wi                                                                  pn         pn    epx   xi wi  wi equation  shows  figure shows number particles predicted  using appropriate accumulators possible calculate different bounds predicted number particles highly  bound incrementally keeping complexity consistent revised versions kldsampling  ﬁlter                                                sistently require larger number particles original                                                        algorithm expected clear mismatch    asymptotic normal approximation                  proposal true densities  usually particle ﬁlter keeps track posterior density figure shows resulting kldivergence each  goal estimating mean higher order moments case interesting note practical results match  state suggests alternative error metric deter closely theoretical ones using original version  number particles instead checking accu kldsampling error estimation signiﬁcantly  racy estimation posterior possible check greater speciﬁed  accuracy particle ﬁlter estimation moment predicted number particles sampled true dis  density                                      tribution solidline resulting error matches closely    weak assumptions using strong law large speciﬁed shows clearly constraining sam  numbers possible show each iteration esti pling right assumption original bound predicted  mation mean given particle ﬁlter asymptoti kldsampling correct case revised ver  cally unbiased degroot  furthermore variance sions kldsampling resulting error using equation   estimator ﬁnite central limit theorem justiﬁes matches closely speciﬁed way error  asymptotic normal approximation degroot  provided bound equation  matches closely  given                                    level speciﬁed                                              ep ∼ epx σisnis          µ σ denotes normal distribution mean µ  adaptive propagation particles  standard deviation σ                             regular implementation particle ﬁlter propagates    using approximation possible build sided particles using dynamic prior pxtyt− strat  conﬁdence interval number particles limits egy limitation propagating samples  error estimation mean                  considering recently available observation yt im              ep − epx                          portance sampling suggests use alternative prop                          ≤ ² ≥  − α                       epx                                agation functions provide better allocation                                                        samples example suitable functional  unfor   ·  denotes absolute value epx true mean                                       value state ² corresponds desired error  − tunately use arbitrary importance function signif  α corresponds conﬁdence level                icantly increases computational load particle ﬁlter    following usual derivation conﬁdence intervals case opposed standard particle ﬁlter esti  equation  produces following bound number mation each weight requires evaluation dynamic  particles                                         prior section shows method build importance                                                      function takes account recent observation                         z−α σis                                                        yt increasing computational complexity ﬁl                   nis ≥                                                 ² epxt                      ter                                                                                                                             ↓ kld−sampling revised using eq                                                                                                                                      ← original kld−sampling                                                                                                                                                                                                                                                                          ↓ using asymptotic normal approximation kl−divergence  kld−sampling using samples true distribution                    number  particles                     −o−o− kld−sampling revised using eq                                                         −−− using asymptotic normal approximation                                                                                                           ↓ original kld−sampling                                                                                                                                                                                                                                            independent runs                      independent runs                         figure  number particles given each bound resulting kldivergence                                                                                               previous work                                    drawn mixture components pxtxt− associated  literature particle ﬁlters importance sam areas high probability likelihood function  pling possible ﬁnd techniques help importance sampling approach possible                                                        generate new set coefﬁcients β∗ takes account  allocate samples areas high likelihood tar                                                                                                                                 px     distribution basic technique rejection sam sampling importance function t−                                                                            xi                    px    pling tanner  idea rejection sampling way set samples dynamic prior t−  accept samples importance weight generated sampling mixture                                                                          xn  suitable value drawback efﬁciency high                  ∗        rejection rate cases proposal density does                βk pxtxt−               match closely target distribution west  west                                                                                                  presents kernelbased approximation build suitable im adding each particle xt compensatory weight  portance function computational complexity given  method unaffordable context mobile robot                                                                  pxk    localization thrun et al thrun et al  propose sam  t− t−                                                                             wt              xt ∼ pxtxt−     ple directly likelihood function appli    pxt−yt  cations feasible prohibitive                                                                                                    resulting set weighted samples xt wti comes    pitt shephard propose auxiliary particle ﬁlter pitt dynamic prior computational complexity  shephard  augment state representation resulting ﬁlter extra complexity  auxiliary variable sample resulting joint operation comes need evaluate draw sam  density generic scheme computational                                                                                    ples importance function pxt−yt fortunately  complexity disadvantage additional com calculation function obtained directly  plexity ﬁnding convenient importance function pitt operation regular particle ﬁlter clearly  sheppard provide just general intuitions form consider following  function paper improve point pre  senting method ﬁnd suitable importance function pxt xt−yt ∝ pytxt xt− yt− pxt xt−yt−                                                                       ∝  pytxt pxtxt− yt−pxt−yt−      adaptive propagation samples                             ∝  pytxtpxtxt−pxt−yt−   sampling dynamic prior equation  equiva equation  shows regular steps  lent sample following mixture distribution particle ﬁlter generate approximation joint density                                                        px    resampling px  prop                         xn                                 t−                          t−  t−                                                      agating samples pxtxt− calculating             pxtyt− ≈   βk pxtxt−                                                                                                              weights pytxt set resulting sample pairs xt xt−                                                                                                                                      correcting weights pytxt forms valid set sam  mixture coefﬁcients βk proportional  ples joint density pxt xt−yt considering  pxt−yt− key observation scheme pxt−yt just marginal joint distribution set                                                                            selection each propagation density depends mix weightedsamples xt− valid samples  ture coefﬁcients βk’s incorporate previous description provides adaptive algorithm  cent observation yt mc perspective possible allows particle ﬁlter use yt allocation  achieve efﬁcient allocation samples includ samples particles used generate im  ing yt generation coefﬁcients intuition portance function pxt−yt starting im  incorporation yt increases number samples portance function particles used generatethe desired posterior pxtyt relevant compensatory figure  shows results tracking targets using  weights calculated according equation  self adaptive particle ﬁlter bounding boxes correspond  likelihood term ytxt resulting ﬁlter computa probable hypotheses sample set used  tional complexity                           estimate posterior distributions states esti    previous algorithm overlapping reg mation number particles just consider  ular iteration regular particle ﬁlter process coordinates center bounding boxes assuming  generating importance function provides convenient independence facilitate use equation  set  way perform online evaluation beneﬁts desired error  conﬁdence level   dating dynamic prior information ob minimum number  samples used ensure  servation cases poor match dy convergence achieved adaptation  namic prior posterior distribution updating propagation function set threshold entropy  dynamic prior beneﬁcial cases distri weights   butions agree updating does offer real advantage figure left shows number particles needed esti  extra processing avoided current mate posterior distribution ball each frame  knowledge issue addressed  adapting propagation function figure right shows    basic idea quantify each iteration par number particles case adapting importance  ticle ﬁlter tradeoff continuing drawing samples function tracking engine decides adapt importance  known potentially inefﬁcient importance function function frames ball travels child  pxt−yt− versus incurring cost building new frames   importance function pxt−yt provides better alloca case tracking child result shows  tion samples likelihood function impor major difference self adaptive particle  tant observation regular particle ﬁlter reaches ﬁlter regular ﬁlter self adaptive ﬁlter needs  adequate estimate used estimate pos roughly constant number particles during entire se  terior distribution pxtyt updated importance func quence needing adapt importance function  tion pxt−yt                                     expected child small slow    step algorithm ﬁnd metric pro motion center position during entire sequence  vides way quantify efﬁciency allocation stationary gaussian motion model highly ac  samples considering efﬁciency allocation curate real advantage adapting num  samples depends dynamic prior resem ber particles propagation function  bles posterior distribution estimation distance case ball situation different during  distributions suitable index quan period ball travels child  tify effectiveness propagation step frames   large fast motion  convenient way estimate kullbackleibler divergence gaussian motion model poor approximation real  kldivergence distributions general motion consequence large mismatch  target distribution px importance function dynamic prior posterior distribution pro  qx                                                 duces inefﬁcient allocation samples estimate           klpx qx ≈ logn − hw ˆi       adapting importance function needs larger set    equation  states large number particles samples populate relevant parts posterior  kldivergence dynamic prior poste trast adapting importance function during frames  rior distribution estimated calculating far   possible observe signiﬁcant reduction                                                        number samples better allocation  entropy distribution weights hw ˆi  entropy uniform distribution logn intu  itive result ideal case importance sampling  conclusions  px  qx weights equal consequence  entropy weights suitable value quantify paper present self adaptive version parti  efﬁciency allocation samples           cle ﬁlter uses statistical techniques estimate suitable                                                        number particles improve propagation function                                                        terms estimation number particles vali     application                                       dation bounds using synthetic example shows  illustrate advantages self adaptive particle ﬁlter empirical results match closely theoretical predictions  use set frames video sequence consisting particular results indicate considering com  children playing ball goal track plexity true density closely proposal den  positions ball left side child each hypothesis sity mimics true density new bounds show clear im  position target given bounding box provement previous techniques kldsampling  ﬁned height width coordinates center mechanisms used self adaptive ﬁlter adapt  motion model used implementation parti importance function identify adaptation  cle ﬁlter corresponds gaussian function zero mean importance function beneﬁcial proved  diagonal covariance matrix standard deviations  highly relevant using mechanisms track targets  center each hypothesis  width height real video sequence self adaptive ﬁlter able ef
