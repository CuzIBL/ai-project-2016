            distributed clustering based sampling local density estimates                 matthias klusch stefano lodi gianluca moro     deduction multiagent systems department electronics department electronics           german research centre science systems science systems           artificial intelligence university bologna university bologna            stuhlsatzenhausweg  viale risorgimento  rasi spinelli         saarbruecken germany  bologna bo italy  cesena fc italy             kluschdfkide slodideisuniboit gmorodeisuniboit                             abstract                               tributed data data warehouse apply                                                                  usual data mining techniques data warehousing popular        huge amounts data stored autonomous                                                                  technology integrates data multiple data sources        geographically distributed sources discov•                                                                 single repository order efficiently execute complex        ery previously unknown implicit valuable                                                                  analysis queries moro sartori  despite        knowledge key aspect exploitation                                                                  commercial success approach impractical        sources recent years approaches                                                                  impossible business settings instance        knowledge discovery data mining        particular clustering developed          • huge amounts data frequently produced        designed distributed data           different sites cost centralization        sources propose novel distributed clustering             scale terms communication storage computa•       algorithm based nonparametric kernel density               tion        estimation takes account issues          • data owners want release        privacy communication costs arise dis•           information instance protect privacy        tributed environment                                          disclosing information result competitive                                                                       advantage considerable commercial added value    introduction                                                   studied data mining techniques central•                                                                 ized environments data clustering goal tech•  knowledge discovery process aiming extraction                                                                  nique decompose partition data set groups   previously unknown implicit knowledge large                                                                  intragroup similarity intergroup dissimilarity   databases potentially added value                                                                  maximized despite success data clustering cen•  given application fayyad et al                                                                   tralized environments approaches problem      data mining devoted automated extrac•                                                                 distributed environment available date   tion unknown patterns given data central element                                                                    work present kdec novel approach dis•  steps overall knowledge discovery process                                                                  tributed data clustering based sampling density estimates   steps include preparation data analyzed                                                                  kdec each data source transmits estimate prob•  evaluation visualization discovered knowledge                                                                  ability density function local data helper site   large variety data mining techniques                                                                  executes density based clustering algorithm   developed past decade include methods pattern                                                                 driven overall density estimate built   based similarity search cluster analysis decisiontree based                                                                  helper samples local densities   classification generalization taking data cube attribute                                                                   paper organized follows section  de•  oriented induction approach mining association rules                                                                  scribe related work highlight differences respect   chen et al                                                                    approach section   present kdec scheme      increasing demand scale massive data sets                                                                  distributed data clustering finally section  concludes   inherently distributed networks limited                                                                  paper outlines ongoing future research work   bandwidth computational resources led methods   parallel distributed knowledge discovery kargupta   et al  related pattern extraction problem dis•   related work   tributed knowledge discovery referred distributed data johnson kargupta  tree clustering approach   mining distributed data mining expected perform par•    taken build global dendrogram individual dendro•  tial analysis data individual sites send grams computed local data sites subject given   outcome partial result sites set requirements contrast approach presented   aggregated global result                               paper distributed data sets assumed hetero•     common approaches business applica•      geneous site access subset   tions perform distributed data mining centralize dis• features object proposed solution implements       learning                                                                                                               distributed version singlelink clustering algorithm density estimation based clustering    generates clusters substantially different    ones generated densitybased methods particular    density estimation based clustering    suffers socalled chaining effect   density estimation based clustering search    separated internally homogeneous groups    densely populated regions accomplished estimating    objects connected dense sequence objects re• socalled probability density function given    garded single cluster kargupta et al  proposes data set assumed arisen techniques    technique distributed principal component analysis col•  debased clustering available vast kdd liter•   lective pca shown technique satisfies efficiency ature ankerst et al  ester et al  schikuta    data security requirements integrated ex•  hinneburg keim  statistics silverman    isting clustering methods order cluster distributed high areas proposed clustering methods require   dimensional heterogeneous data dimensionality       computation nonparametric estimation density   data reduced prior clustering applying pca    function data important family non  approach orthogonal related research   parametric estimates known kernel estimators idea   direction deals incremental clustering algorithms    estimate density function defining density   birch izhang et  related bubble method           data object proportional weighted sum   ganti et al  compute accurate clustering     objects data set weights defined   given memory available minimizing     appropriately chosen kernel function following   number io operations uses dynamic index struc•       introduce kernelbased density estimation parzen    ture nodes store synthetic constanttime maintainable silverman  approach density estimation   summaries sets data objects method sufficiently  based clustering   scalable requiring nogn time linear io        let assume set data   uses centroid incrementally aggregate objects points objects kernel estimators originate in•  method exhibits strong bias globular clusters   tuition higher number neighbouring data ob•  incrementaldbscan lester et  dynamic clus•      jects given object  higher density   tering method supporting insertions deletions  object ways cap•  shown equivalent wellknown static dbscan      turing weighting influence data objects   algorithm turn dbscan shown equiv•      given distance data object jc   alent method based density estimation kernel  argument influence jf quantified us•  function square pulse clusters densitybased ing called kernel function kernel function   incrementaldbscan general methods based        realvalued nonnegative function finite   kernel density estimates time complexity nogn     integral computing kernelbased density es•                                                                 timation data set  element jf regarded    data clustering                                              exert influence elements                                                                  farther element accordingly    cluster analysis problem                               kernel functions nonincreasing  promi•  cluster analysis descriptive data mining task     nent examples kernel functions square pulse func•  aims decomposing partitioning usually multivariate     tion gaussian function   data set groups data objects group   similar each different possible                                                                    kernelbased density estimate   groups clustering algorithm                                                                  defined modulo normalization factor sum   mapping data set objects clustering                                                                  data objects  distances scaled    collection pairwise disjoint subsets  clus•                                                                           factor called window width weighted kernel   tering techniques inherently hinge notion distance                                                                  function   data objects grouped need know   set interobject distances values   data object variables techniques data cluster•                                                          ing available matched developer   objectives considered clustering task grabmeier      influence data objects smoothness   rudolph  partitionbased clustering example    estimate controlled window width   task partition given data set multiple disjoint shape kernel controls smoothness estimate   sets data objects objects each set determines decay influence data   homogeneous possible homogeneity captured       object according distance number data   appropriate cluster scoring function option     objects large practice necessary compute   based intuition homogeneity expected   distances calculating kernel density estimate   high densely populated regions given data set con•  given object fact value commonly used kernel   sequently searching clusters reduced searching  functions negligible distances larger units   dense regions data space likely   populated data objects leads approach                                                                                                                  learning zero kernel bounded support   case example square pulse using kernel  based density estimation straightforward decompose   clustering problem three phases follows      choose window width kernel function      compute kernelbased density estimate        given data set      detect regions data space value        estimate high group data objects space re•       gions corresponding clusters      literature different definitions cluster   proposed formalizing clusters referred step    densitybased cluster ester el al  collects   data objects included region density exceeds   threshold centerdefined clusters hinneburg kcim     based idea local maximum   corresponds cluster including data objects   connected maximum continuous uphill path   graph finally arbitraryshape cluster lhinneb  urg keim  union centerdefined clusters   having maxima connected continuous path   density exceeds threshold      algorithm  decluster implements computation   centerdefined clusters climbing procedure driven   density estimate main procedure decluster taking   inputs instance class data objects kernel   function window width returning clustering   represented stores mapping each       equipping class spatial access method like                                                                  kd mvp mtree time complexity   unique integer label ofxifs cluster assumed   instance class provides following meth•   declusler nqn qn cost near•  ods geti access object given index nqkx     est neighbour query access method note   radius retrieve given indexes maxi•                practical cases qn close log tv   mum distance nearest neighbours uphill computes   steepest direction graph estimated density  distributed data clustering   versor gradient computed function degradient    body work applications data clustering dis•  cf hinneburg keim  uphill moves    tributed environments problem called distributed   direction fractions   distance sradius      data clustering ddc comparatively small sec•  th nearest neighbour finally returns index tion adopt kernel density estimation based clustering   nearest neighbour reached position nested   approach presented distributed case assuming   fixedpoint marks current object visited  homogeneous data means data object   calls uphill index data object xj   split sites   object visited proximity local   maximum reached taken new cluster la•      ddc problem   bel inductively assumed lie                                                                  define problem homogeneous distributed data clus•  end path leading proximity local maximum                                                                  tering clustering algorithm follows let   labeled accordingly marked   clustered recursive ensures assumption holds                    data set objects let      complexity decluster algorithm call•  finite set sites each site stores data   ing — scount times fixedpoint beginning    set dj assumed  ddc   iteration decluster sets clustered visited ob•  problem site clustering cj residing data   jects equal fixedpoint called clustered   space   object argument visits unclustered objects      correctness requirement   number visited data objects                                                                  ii time communications costs minimized effi•  fixedpoint bounded number                                                                       ciency requirement   visited data objects calls each   visited object single knearest neighbour query suffices iii end computation size subset   compute gradient uphill object methods        transferred data space                             efficiently implemented         site minimized privacy requirement       learning                                                                                                                traditional solution homogeneous distributed data  immediate  addivity holds sampled    clustering problem simply collect distributed data forms    sets dj centralized repository union    computed clustering union com•                                                                  puted transmitted sites approach    does satisfy problems requirements terms    privacy efficiency propose different ap•  receiving sampled forms    proach yielding kernel density estimation based clustering  density estimates helper site compute     scheme called kdec                                          sampled form overall estimate transmit                                                                  sites lj sites lj cluster local data respect     kdec scheme ddc                                   overall density estimate using gradient sampling    key idea kdec scheme based follow•       series    ing observation density estimate computed    each local data set gives information distribution    objects data set conceals objects                                                          local density estimate coded provide    compact representation data set purpose   transmission sequel tacitly assume sites   lj agree using global kernel function global    window width omit   notation write  density estimates                        needed hillclimbing function    form equation  additive global den•  briefly discuss extent series                                                                   used represent known   sity estimate decomposed info sum                                                                  mild conditions sampling function invertible   site density estimates estimate data set dj                                                                  transformation coordinate                                                                 frequency fourier transform differs                                                                  zero interval  samples   local density estimates transmitted    computed period greater   summed distinguished helper site yielding global   cf higgins  assumptions value   estimate returned sites each site lj  sampling series computed equals gx unfortunately   apply local data space hillclimbing technique popular kernel functions summations kernel   algorithm  deciuster assign clusters local data functions satisfy hypotheses support   objects weakness plan  fourier transform unbounded consequently sam•  definition density estimate explicitly refers data pling density estimates yields information loss   objects knowing manipulate estimate     shown fourier transform kernel density   entails knowing data objects contradicts pri•   estimate negligible greater   vacy requirement intensional algebraic      global density estimate re•  definition estimate includes knowledge data ob•  constructed samples  introducing small   jects multidimensional sampling theory provides basis     error   alternative extensional representation estimate    worth noting infinite series  need ap•  makes explicit reference data objects         proximated finitely nonzero terms      theoretical idea sampling represent function case holds used kernel function bounded support    sampling series summation suitable ex•   density estimate bounded support   pansion functions weighted values  discrete    kernel function unbounded support like   subset domain higgins  following let gaussian kernel density estimate approxi•  th coordinate denoted let diag                   mated regarding value zero       denote th diagonal matrix                               inside appropriately chosen bounded region   having diagonal defined according approach propose following al•  diag let vector                                     gorithmic kdec scheme computing kernel density es•  sampling periods sampled form intervals          timation based clusters local data spaces distributed     sequencedefined                                    data sites lj algorithm  local site runs pro•                                                                 cedure sitedecluster helper site runs helper                                                                                                                             sitedecluster passed reference helper   • inner product vectors       local data set returns clustering class instance   sequence values real           helper passed list references local sites   dimensional vectors th coordinates spaced     procedure sitenegotiate carries negotiation   multiple th sampling period ti  sam•  local sites through helpernegotiate helper   pled forms local density estimates defined sim• site determine sampling periods bounding cor•  ilar way                                          ners sampling rectangle  kernel                                                                                                                  learning                                                                vances fraction  gradient direction gradi•                                                                 ents norm exceeds threshold                                                                  object returmed uphill contains clustered data                                                                  object current cluster label id set objects la•                                                                 bel checking uphill returned                                                                  space object signals fixedpoint proximity                                                                  local maximum reached maximum marked                                                                  adding current space object dummy object                                                                  local data set ensures subsequent paths converging                                                                  local maximum use cluster label                                                                  current path method dadd returns identifier                                                                  added object used current cluster label                                                                  case holds label id obtained recursive                                                                  finally objects small neighbourhood current                                                                  object labeled id note adding dummy objects                                                                  eflect range queries does modify                                                                  density estimate                                                                     complexity kdec scheme                                                                  terms complexity computation communica•                                                                 tion crucial point kdec scheme sam•                                                                 ples computed transferred sites                                                                  cases obtain good density estimates                                                                  small multiple smallest object distance                                                                    ti  number samples rarely exceed                                                                  number objects space regions density                                                                  estimate negligible sampled size                                                                  sample usually smaller size data ob•                                                                 ject overall communication costs ddc approach                                                                  cases significantly lower centralized                                                                  approach course precise number samples depends                                                                  bounding region sampled site                                                                    algorithm  site lj determines autonomosly rectangle                                                                  contains computed samples                                                                    computational costs kdec scheme terms                                                                  used cpu cycles io exceed cen•                                                                 tralized approach clustering performed data col•                                                                 lected single repository computational complexity                                                                  linear number samples precise cost compu•                                                                 tation kdecbased ddc algorithm instance                                                                  proposed scheme largely depends used kernel   window width negotiation procedures contain ap•     function local clustering algorithm decluster algo•  propriate handshaking primitives ensure sites par• rithm developed kdec scheme section    ticipate exit negotiations agreement   complexity nqn qn cost nearest   reached each local site computes sampled form      neighbour query practical cases close logjv   estimate calling function sample sends     algorithm  implements slightly different approach   helper function computes density estimate     hillclimbing function algorithm  function   omitted brevity helper receives sampled es•   does use data objects direct uphill path how•  timates sums sampling indexes global sam•      preliminary results experiments conducted pro•  ple returns sites procedures send receive  totype implementation show good scalability approach   implement appropriate blocking handshaking ensure       terms number executed range queries   transmission takes place each local site uses global   sample functions fixedpoint uphill compute        conclusion   values gradient global density estimate func•  tion seriesgradient easily derived  local      explosion number autonomous data   sites perform decluster algorithm compute corre•     sources growing need effective approaches   sponding local data clusters details hillclimbing distributed knowledge discovery data mining pa•  strategy different algorithm     presented kdec novel scheme distributed   sites allowed access local data objects uphill ad• data clustering computes density estimation      learning                                                                                                              
