                  planning algorithm predictive state representations                                          masoumeh izadi doina precup                                                school science                                                     mcgill university                                                      montreal canada                               abstract                               tions aak prediction test given prior history                                                                   denoted probability seeing sequence        address problem optimally controlling                                                                  observations seeing history taking se•       stochastic environments partially observ•                                                                 quence actions specified set tests        able standard method tackling prob•                                                                 prediction vector        lems define solve partially observable        markov decision process pomdp        known exactly solving pomdps                                                                  set tests psr prediction vector forms suffi•       costly computationally recently littman                                                                  cient statistic dynamical tests        sutton singh  proposed alter•                                                                 predicted based pqh particular case        native representation partially observable en•                                                                 linear psrs exists projection vector mq        vironments called predictive state representations       test        psrs psrs grounded sequence ac•       tions observations agent re•       late state representation directly agents       littman et al define outcome function map•       experience paper present policy iter•      ping tests ndimensional vectors defined recursively        ation algorithm finding policies using psrs                  uaoq  repre•       preliminary experiments algorithm produced                                                                  sents null test cn  vector each        good solutions                                           component indicates probability test                                                                    sequence actions applied state st set    predictive state representation                              tests   called linearly independent                                                                  outcome vectors tests arc   assume given consisting dis•                                                                 linearly independent using definition set   crete finite set states  discrete finite set actions                                                                  simple search algorithm polynomial time   discrete finite set observations interaction                                                                  given pomdp model environment littman sut•  takes place discrete time intervals                                                                  ton singh  showed outcome vectors   initial state drawn initial probabil•                                                                 tests linearly combined produce outcome   ity distribution states time step action                                                                  vector test   chosen according policy underlying   state changes observation gener•          policy evaluation using psrs   ated markovian sense   action transition state generated according assume given policy   probability distribution described transition initial start state drawn according   matrix similarly given observation action      staring probability distribution consider given   observation generated according diag• horizon finite number tests length possible   onal observation matrix probability            starting let set possible tests   observation action selected state reached  value memoryless policy respect given   interested optimal control predic• start state distribution expected return possi•  tion assume exists set reward vectors ble tests occur starting state drawn form       each action reward taking action   behavior generated according policy    underlying state      psrs based notion tests test ordered   sequence actionobservation pairs    prediction test probability sequence ob• expected return test given   servations generated given sequence ac•          initial state drawn  policy followed                                                                                                          poster papers    let matrix formed concatenating   outcome vectors tests pseu  doinverse columns define probability each   test applied each underlying state conse•  quently iu represents probability tests   starting       each actionobservation combination ao define   projection matrix        projection vector                                                                    figure  policy quality vs number iterations      considering probability distribution tests    grid world    generates expected return test given                                                                      consists  linearly independent tests                                                                                                                                                 tried problem finite horizon case discount                                                                  factor   figure  indicates performance                                                                  algorithm problem    evaluation method requires large precom   putation useful small horizon suffices  conclusion future work    good policy                                                key difficulty planning algorithm num•                                                                 ber possible tests grows exponentially horizon     policy iteration psrs                                   length algorithm used large prob•   similar pomdps psrs define actionvalue func•    lems infinite horizon case    tions level tests actionvalue function tak• worse existing exact solution methods solving    ing action test computed                 pomdps hope good approximations opti•                                                                 mal solution efficiently                                                                    references      policy agent improved choosing   cassandra et al   cassandra kaelbling    action greedily respect actionvalue function  littman acting optimally partially observ•                                                                   able stochastic domains proceedings twelfth                                                                    national conference artificial intelligence       agent words select best pol•        littman   littman algorithms sequential de•   icy tree rooted each decision point each time            cision making phd thesis brown university providence    step total running time algorithm       rl march                      complexity algorithm    singleexponential horizon time                       littman et al   littman sutton                                                                     singh predictive representations state advances     experimental results                                          neural information processing systems  proceedings                                                                      conference mit press    experimented standard gridworld navigation task                                                                  parr russell  parr russell approximat•   used pomdp literature cassandra  parr rus•                                                                    ing optimal policies partially observable stochastic    sell  environment   grid agent                                                                     domains proceedings fourteenth international    actions change location                                                                    joint conference artificial intelligence ijca    deterministically neighboring states    goal state lower right corner generates    distinct observation reward  states    perceptually aliased generate reward initial    probability distribution uniform states    goal taking action goal state moves agent uni•   formly randomly states      problem  possible combinations    actionobservation ao pairs  nnothingwnothing   enothingsnothingegoalsgoal set core tests        poster papers                                                                                                       
