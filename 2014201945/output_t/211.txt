    automatically selecting answer templates respond customer emails                      rahul malik venkata subramaniam saroj kaushik                                dept science engineering                                    indian institute technology delhi                                       hauz khas new delhi india                                           ibm india research lab                                   block indian institute technology                                             new delhi india                      abstract                                                         provide current status rebate      contact center agents typically respond email   reimbursement phone purchases      queries customers selecting predeﬁned      swer templates relate questions present understand concern regarding mailin rebate      customer query paper present  mailin rebate reimbursement allow       technique automatically select answer tem  weeks receive      plates corresponding customer query email    understand concern regarding mailin rebate      given set queryresponse email pairs ﬁnd   mailin rebate reimbursement allow replace      associations actual questions  weeks months replace receive      answers use information         map future questions answer templates      evaluate small subset      figure  example query responsetemplate pair      publicly available pineinfo discussion list email technique tries automatically handle email queries      archive actual contact center data com needs use natural language processing handle      prising customer queries agent responses tem  today’s contact centers handle wide variety domains      plates                                           sales support mobile phones ap                                                        parel each domains typical answer templates    introduction                                       deﬁned provided agents aid composing                                                        responses contact centers lots email data  contact center general term help desks information corresponding each domains handle cus  lines customer service centers companies today tomer queries corresponding agent responses  operate contact centers handle customer queries stored available abundance  customers provided email support professional paper presented techniques automatically  agent contact centers central focus answer customer emails  companies allow direct contact                                                           extracting relevant portions customer queries  customers solve product services related issues                                                            require response  grievance redress typical contact center agent  handles emails day typically agents  automatically matching customer queries predeﬁned  provided templates cover different topics templates compose response  customer emails agent gets customer query evaluate performance technique show  selects answer templates relevant composes achieves good accuracy real life data sets  response mailed customer figure  shows  example query responsetemplate pair                background related work    work ﬂow processing emails contact centers  follows customer sends query email human  key phrase extraction  manually triages forwards right agent extracting sentences phrases contain important  agent number predeﬁned response templates formation document called key phrase extraction  selects appropriate ones composes key phrase extraction based learning tagged cor  response email customer query combining pus widely explored hirao et al frank et  templates inserting additional text fragments incoming al  problem extracting key phrases emails  mails free text format little structured content using parts speech tagging studied tedmori  usually structured content email ﬁelds like et al  mention body work context  date subject line sender id help paper given email important identify  triaging email query answering portions correspond questions answers                                                    ijcai                                                      text similarity                                  questions corresponding answers response  text similarity used information retrieval deter emails identiﬁed given corpus way  documents similar query typically similarity multiple questions query email identiﬁed ad  tween text segments measured based number dressed technique shows good accuracy  similar lexical units occur text segments salton  lisk  similarity measures used ﬁnd  problem deﬁnition  similar documents sentences metzler et al                                                        repository matching query response emails  lexical matching methods fail account                                                        exchanged customers center  semantic similarity words remained silent                                                        agents responses composed set  quiet matched overcome sev                                                        templates provided agents single  eral techniques based measuring word similarity                                                        query comprise questions requiring multiple  proposed work wu palmer wu palmer                                                        templates used answering problem   measure similarity words based depth                                                        matching individual questions queries  concepts relative each wordnet                                                        corresponding templates  mihalcea et al  corpus knowledgebased                                                          given repository queryresponse pairs tem  measures evaluated measuring similarity based                                                        plates ﬁrst problem learn associations  semantics words context paper                                                        questions templates let qqm query  need identify similar questions need match                                                        emails rrm corresponding responses  question answer                                                        query qi comprises questions qlqm    question answering                               matched templates tltm used compose                                                        response ri problem deﬁned follows  question answering qa attracted lot research                                                        given query email qi need ﬁnd set questions  annual text retrieval conference trec qa track qs match corresponding templates  text retrieval systems evaluated common real                                                        ts used compose response ri  world text collections aim trec qa associations established tackle problem  task return answers documents automatically composing responses new queries                                          containing answers response question voorhees new query comes need identify questions             dang   essence attempting compose response using mappings  paper answer customer queries looking ways previously established  similar questions answered past    contact center email processing                     email triaging  lot work hasebeenedone automatic triaging emails contact center typically customer query emails man  contact centers nenkova bagga busemann et ually triaged triaging step emails forwarded  al  classiﬁer learnt based existing concerned agent handling particular class queries  cases using features words mail parts cases single agent handles classes queries  speech type sentence new queries come emails actually classiﬁed clas  automatically routed correct agent siﬁcation information available replace step  work automatically answering email automatic triaging obtaining labelled data  queries customers possible learn classiﬁer new process hard use clustering ﬁrst identify  map questions set answer templates scheffer  different classes learn classiﬁer based  work automatically learning classes classiﬁed emails larger pool  questiontoanswer mappings training instances bickel equal number query response clusters using text clus  scheffer  work paper describes meth tering repeated bisection using cosine similarity match  ods automatically answer customer queries selecting ing query response clusters contain different num  sponse templates                                     bers emails subsequently matched based                                                        maximal matching criteria cluster having maximum    contributions paper                      match fraction separated remaining clusters  paper present techniques automatically locate rematched way onetoone mapping query  relevant questions customer query email map response clusters obtained nonmatching emails  each predeﬁned answer templates putting each map removed create clean clusters having exact  templates response email message com correspondence queryresponse emails svm classiﬁer  posed given query email automate process trained classes created clustering  composing response aware work classiﬁer used triage emails  response generated putting existing tem  plates technique novel questions  extraction questionanswer pairs  query email ﬁrst identiﬁed associations                                                        given query email like extract key ques    httpwordnetprincetonedu                      tions like map questions                                                    ijcai                                                    answers response email determine tem queryemail  number questions query  plates used                           email  number answers responseemail                                                          each answer mapped template    identiﬁcation questions answers           simply matching answer sentences templates  identify questions based presence key agent typically makes little changes template  phrases follow approach frank et composing answer result steps  al  identify key phrases length  words obtain question template pairs  use set training documents key phrases multiple questions match template  known generate naive bayes model model different customers ask question differ  used ﬁnd key phrases new document            ent ways example account    actual fact tagged training documents avail balance know balance account  able ﬁrst extracted frequent unigrams bi merged sentence need know carry forward  grams trigrams selected list ex month easily linked earlier sen  tracted phrases length  words marked tences mapping method gave question  emails key phrases tagged set used totemplate mappings need merge similar sentences  generate naive bayes model key phrases  minimal set questions associated tem    query email questions identiﬁed sen plate prune set questions removing questions  tences contain key phrases similarly high similarity score  sponse email replies identiﬁed sentences new question comes need compare  contain key phrases                          minimal set    mapping questions answers                        answering new questions  questions responses identiﬁed                                                        new query ﬁrst identify questions  need map each question corresponding response                                                        following method outlined section  each  given query email contain multiple questions                                                        questions needs answered compose  fore response contain multiple answers accom                                                        response email answers each questions  plish mapping ﬁrst partition each extracted sentence                                                         list tokens stop words removed  maining words transcription passed through  mapping new questions existing questions  stemmer using porter’s stemming algorithm  root  form word called similarity new question comes need determine sim  each question answer calculated ﬁnd ilarity question seen earlier  correct map order calculate overlap know template previous discussion know  sentences used word overlap measure different questions map answer  score adjusted account inverse doc template able determine new question  ument frequency metzler et al  measure given similar existing question new                                                    question mapped template existing question                                                        similar                      ∩                                similarity concepts given wu                                           sim             log ndfw              palmer                          w∈q∩r                                                                                                                              ∩                                  ∗       depth lcs   total number words  collection          sim                     common words stopword removal stem                     depth   depth  ming df  document frequency belongs denote source target words  common word set                        compared depths shortest distance root node    gives score similarity question node taxonomy synset lies lcs  answer addition used heuristic question denotes common subsubmer using  asked beginning chances response wordnet  beginning biased need compute similarity  high weight compared lying end cepts present sentences want match  penalized low weight               sentences ﬁrst tokenized stop words removed    expression score               porter stemmed parts speech labels assigned                                                    kens nouns verbs adjectives adverbs selected                    ∗  − pos −  pos      score  sim                        addition cardinals numbers play                                                    important role understanding text form   simq  similarity score obtained matrices each ﬁve classes rows  posq  position question set questions matrix tokens sentence columns                                                        tokens second sentence each entry matrix    httpwwwtartarusorg martinporterstemmer      sims denotes similarity obtained                                                    ijcai                                                    pair word does exist dictio working creating rpm university  nary use edit distance similarity need pineconf usrlocaletcpineconf  words                                                 instead etcpineconf wondering    results combined follow extra parameters pass build time redirect pine  ing manner obtain overall similarity score usrlocaletcpineconf isn’t parameter pass does  sentences                                          know patch like    similarity sentences determined fol yes recommend look build script  lows mihalcea et al                           port redhat includes altdocpaths                                                         defines extra variables particular look                                                         dsystem pinercetcpineconf                                                          s∈qi sim       s∈qj sim      idea  scoreqiqj                              qi  qj                                                          figure  typical query response pair pineinfo  simms qj word qj belongs  class noun verb highest semantic signed wireless web   months ago  similarity word qi                        charged  each time     using similarity compare new question problem  questions seen earlier match  select response template matched question sorry inconvenience caused  template new question                         adjusted account  reflected                                                                                                                 sorry inconvenience caused    evaluation                                          adjusted account replace insert                                                         minutes  replace  section present results real life data sets reflected replace month replace                                                            contact center data  chose sets data work pineinfo discus figure  typical query responsetemplate pair  sion list web archive contains emails users reporting prob  lems responses users offering solutions  measures  advice questions users ask problems  face using pine users offer solutions advice measure accuracy comparing  problems pineinfo dataset arranged form email response generated human agent gen  threads users ask questions replies erated use criteria comparison  forms thread discussion topic ﬁrst case say correct  choose ﬁrst email thread query email generates exact answer agent second case  tains questions asked second email response allow partial correctness query contains  contains responses email contain questions response matched agent  swers questions asked answered sponse  correct  subsequent mails thread randomly picked total query   queryresponse pairs pineinfo question sen  experiments  tences answer sentences marked  mappings average query email section show results techniques  tains  questions ﬁrst response email contains  pine dataset contact center emails pine  answers  questionanswer pairs show templates effect testing  query response pair pineinfo figure  able map manually extracted questions  actual question answer marked hand swers correctly used  annotated pairs query  shown bold example shown questions response emails measure mentioned  sentences marked query email looking answer ﬁrst response query  answer marked response email               questions query addressed    second data set used obtained actual possible mappings table   tact center process relating mobile phone services ob show numbers obtained total  questions  tained  query response emails relating mobile  mapped answers manual annota  phone support process obtained  answer tem tion process using method presented section   plates agents provided aid answering able ﬁnd  maps correctly  customer queries average each response contains contact center emails tested method   templates implying key questions accurately generate responses queries  customer query figure  query shown built using   queryresponse pairs  actual response template used composing emails available tested using remaining  response                                              pairs emails ran sets experiments                                                        emails ﬁrst case didnt use class information gen    httpwwwwashingtonedupinepineinfo           erate response emails second case triaged                                                    ijcai                                                    table  results pineinfo dataset questionanswer table  results clustering contact center dataset  mapping                                                  actual    descriptive total    total    templates      total  total total actual correct   correct          class     cluto         templates         mails  qns   ans   maps    maps     maps                         label    emails   class   email                                           rebate      rebate                                                                             cancelling    cancel                                                                              charges      charge                    emails ﬁrst aid generation templates  account     payment                      table  show results generating response payment  email using class information general    phone                     case questiontotemplate maps established using queries   training email pairs each template questions overall                          sociated using techniques section   new questions testing set response au  tomatically generated discussed section  gener  cases considering partial correctness  ated exact response human generated  accuracy goes  results shown  cases considering partial correctness accuracy table                                               seen marked jump                                                          accuracy numbers complete match emails                                                        triaged notice large jump case  table  results contact center dataset triaging partial correctness reasons twofold    total  training testing  total                    firstly step triaging emails limits search space    email    set      set   correct correct  partial    questions need matched secondly    pairs                    resp   resp  correct     query lands wrong cluster misclassiﬁcation                                    stands chance partially correct                                                        particular class template    case triaging emails ﬁrst clustered   query response sets separately used cluto  package  doing text clustering experimented table  results contact center dataset triaging  available clustering functions cluto cluto  total  classiﬁcation              clustering algorithm consistently outperformed class     accuracy     correct   partial  difference various algorithms label   emails                responses correct  based available goodness metrics used rebate                        default repeated bisection technique cosine function cancel                       similarity metric clustering results using cluto charge                          shown table  chose cluster  clusters payment                     cause values total number clusters resulted phone                    lower purity numbers cluto generated overall                         descriptive feature each cluster using cluto  close actual label class mentioned ques  assigned human average number tions customers reply agent does use  templates varied quite lot classes tem existing templates actually composes  plates used classes reply  used libsvm  train svm classiﬁer clusters  obtained used rbf kernel γ    conclusions  ρ   − classiﬁer used triaging  emails resulting overall accuracy classiﬁcation paper introduced automatic email response   case questiontotemplate maps generation technique given corpus queryresponse  established using training email pairs each class email pairs answer templates determine typical  separately each template questions associated questions given answer templates new query  using techniques section  new email presented identify questions ﬁnd  questions testing set email ﬁrst triaged using nearest questions identiﬁed  classiﬁer learnt response automati answer templates answer templates relating  cally generated discussed section  questions questions composed response  email matched questions class accuracies obtained using methods presented  generate exact response human generated paper point fact practically                                                        possible useful contact center agent compos    httpglarosdtcumnedugkhomeviewscluto       ing response customer query agent select    httpwwwcsientuedutwcjlinlibsvm˜           templates presented                                                    ijcai                                                    
