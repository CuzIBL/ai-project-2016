          improving revolutionary search optimal multiagent behaviors                   liviu panait                        paul wiegand                            sean luke      department science                  krasnow institute            department science          george mason university                george mason university                george mason university              fairfax va                       fairfax va                       fairfax va              lpanaitcsgmuedu                      paultesseractorg                     seancsgmuedu                               abstract                                 ec fits nicely multiagent systems                                                                  populationoriented searches set multiple agents        evolutionary computation useful technique        individuals ec population broken        learning behaviors multiagent systems           distinct subpopulations each yielding agents        types evolutionary computation        tested multiagent environment each sub       natural popular method coevolve multi          population evolving parallel notion separately        agent behaviors multiple cooperating popula•          evolving interacting populations agents known       tions recenl research suggested revo•           evolution coevolution proven useful technique        lutionary systems favor stability         multiagent problems quality agent typically        performance domains order im•              assessed context competing cooperating peers        prove existing methods paper examines            coevolution panacea recent research shown        idea modifying traditional coevolution bias•      coevolutionary does necessarily search        ing search maximal rewards introduce        better teams agents instead search agent        theoretical justification improved method        populations represent stable equilibria coopera•       present experiments three problem domains         tive search space ficici pollack  wiegand et        conclude biasing help coevolution        paper explore problem introduce        better results multiagent problem domains        method biasing coevolution search stabil•                                                                 ity coincides optimization improvement                                                                    continue paper brief description coevo•   introduction                                                 lution present experimental theoretical frame•                                                                 work suggest method biasing coevolu•  multiagent learning area intense research                                                                  tionary process theoretical investigation   challenging problem dynamics com•                                                                 biasing modifies search space discuss experimental   plex fraught local optima difficulties                                                                  results three problem domains paper ends set   evolutionary computation ec attractive approach                                                                  conclusions directions future work   learning multiagent behaviors example flba    luke et  wu et  bull et    bassett jong  bull  work led   evolutionary computation coevolution   interesting research questions applying ec multiagent  evolutionary computation family techniques known   setting including communication representation generaliza•  evolutionary algorithms widely used learning agent   tion teamwork collaboration strategies                  behaviors ec abstract darwinian models evolution     general relatively knowledgepoor evo•  applied refine populations agents known indi•  lutionary computation particularly useful problems  viduals representing candidate solutions given problem   high dimensionality nonmarkovian yield    evolutionary algorithm begins initial population   heuristic clues search space    randomlygenerated agents each member popu•  make reinforcement learning various supervised learning     lation evaluated assigned fitness quality as•  methods good choices believe multiagent learning      sessment ea uses fitnessoriented procedure   problem domains exhibit features problem     select agents breeds mutates produce child   domains complex correct actions      agents added population replacing   known given situation rela•     older agents evaluation selection breeding cycle   tively simple problems require large numbers external   known generation successive generations continue   challenging internal state variables    refine population time exhausted sufficiently   problems exhibit changing environments         fit agent discovered   ones adapt make problem harder learner       coevolutionary algorithms ceas represent natural ap•  presence colearning opponents                proach applying evolutionary computation refine mul      multiagent systems                                                                                                      tiagent behaviors cea fitness individual                                                              based interaction individuals popula•                                                            tion fitness assessment contextsensitive sub•  jective competitive systems agents benefit expense                                                                                                                              agents cooperative systems agents succeed    fail collaboration focus paper    cooperative coevolutionary algorithms interesting cea is•                                                                sues include communication bull et al  teamwork    collaboration bull                                represent new population distributions      standard approach ipotter  applying coopera•     generation assumed individ•   tive coevolutionary algorithms cceas optimiza•     uals fitness assessed through pairwise collaborations    tion problem starts identifying static decomposition  member cooperating population    problem representation subcomponents each repre•    idea complete mixing equations   sented separate population individuals example  step process vectors derived    task requires agents collaboration op• represent fitness assessments strategies genera•  timized choose use populations      tions respectively note infinite population    agent task fitness individual popula•  model considers fitness assessment strategy    tion determined testing individual collabo• particular instance strategy individual   ration individuals popula•     selection performed computing proportion fit•  tion aside collaborative assessment each popula•   ness specific strategy sum fitness entire   tion follows independent evolution process parallel population   populations                                                                   optimization versus balance    formalizing ccea                                       ccea researchers apply algorithms hoping optimize   appealing abstract mathematical model       collaborations populations isnt clear   comes biology literature evolutionary game the•      meant fact seeks   ory egt maynardsmith  hofbauer sigmund          form balance strategies corre•    egt provides formalism based traditional game     spond external viewers   theory dynamical systems techniques analyze lim•    consider optimal context payoff matrix op•  iting behaviors interacting populations longterm     timal position pair strategies yield highest   evolution specifics applying egt analysis payoff cooperating agents position stable   multipopulation cooperative coevolutionary algorithms    attracting fixed point case   wiegand et                                       suboptimal points attract                                                                  trajectories wiegand et al possible      paper consider twopopulation models                                                                  trajectories pulled suboptimal   model common way expressing rewards                                                                  spots points correspond nash equilibria subopti•  individual interactions through pair payoff matrices                                                                  mal combinations strategies strategy   assume symmetric model individuals                                                                  changed net reward agents decrease   population interact individuals   second payoff matrix used individuals      result individuals ccea necessarily re•  second population receive rewards defined trans•    fined optimal subcomponent optimal com•                                                                 ponent instead refined jacksofalltrades   pose matrix theoretical exploration   egt paper use infinite population    dovetail nicely current individuals   population thought set individuals    population does mean practitioners wanting   finitelength vector proportions   coevolve optimal good cooperative   each element vector proportion given indi•  strategies using coevolutionary algorithm means   vidual configuration popularly known genotype     ceas necessarily optimizers sense   term strategy population pro•    intuitively expect   portions valid vector sum legal vectors  modify existing algorithms expectations   make commonly known unit simplex de•        algorithms really   noted number distinct strategies   possible                                                       biasing optimal cooperation      formally model effects evaluation pro•    reason cceas tend balance individ•  portional selection time using pair difference equa• uals fitness commonly assessed based per•  tions each population proportion vectors forms immediate individuals population   populations respectively neglecting is•   optimal cooperation search process need   sue mutation breeding concentrating     optimistic assessing fitness based   effects selection define dynamical  highestreward interactions individual   twopopulation cooperative coevolutionary algorithm        various members population previous investi•                                                                 gation direction reported wiegand et al                                                                                                     multiagent systems table  joint reward matrixes climb left   penalty right domains     assessing individuals fitness based maximum perfor•  mance agents collaborative domain shown    figure  probability converging optimum   yield better results using mean minimum    bias parameter  varied     performance idea presented paper relatively   simple base individuals fitness combination                                                                  rative fitness individual approximation   immediate reward interacting individuals                                                                  large strong effect overall fitness   population estimate reward                                                                  appears early evolutionary run   received interacted ideal collaborators                                                                  deform search space drive search trajectories sub  fraction reward immediate opposed                                                                  optimal parts space escape   ideal interaction changes during course run                                                                  hand approximation affects fitness mea•     note notion bias maximum possible   surement weakly late run   reward used reinforcement learning litera• help gravitate   ture subtly different ways use example balance   maximum reward used loaus boutilier          better tradeoff alter equations    modify exploration strategy agent llauer     time adding bias weight parameter    riedmiller  modify update rule ta•                                                                   iymaxi andvt  atxmdart   ble extent hall fame method introduced      varying    control degree   rosin belew  competitive coevolution      model makes use bias consider climb payoff   related biased cooperative coevolution                matrix left side table  select  initial points      justify use bias ccea follows                                                                  dynamical uniformly random   recall individuals fitness based immediate iterate converges convergence   interaction individuals population   virtually guaranteed traditional twomatrix egt games    ay — atx described equations       lhofbauer sigmund  necessarily guar•  let consider function maxa returns column vector   anteed modified experimental results   corresponding maximum value each row matrix       obtained convergence cases   individuals fitness based maximum     degree machine precision figure  shows probability   possible performance conjunction individual   various levels  dynamical converging   population modify equations       optimum penalty set       maxat  maxr                                 notice penalty worsens transition      modified tendency optimize perfor•   optimal suboptimal convergence   mance clear each iteration model fitness severe suggests problems benefits   each strategy best possible fitness provided type bias quite sensitive   unique maximum result highest fitness  degree bias   proportion corresponding strategy increase   step global maxima unique    experiments   resulting fixed point mixed strategy weights split   maxima                                          theoretical discussion helps justify intuition      reason straightforward problem lost including performance bias fitness evaluation   dimensionality added nature interactions immediately applicable real problems real•  agents problem reduces     istic setting simplifying model assumptions infinite   simple evolutionary algorithm regardless content    populations lack variational operators complete mixing   opposing population fitness measure given strat• priori knowledge maximum payoff pos•  egy shown vose  infinite popu•   sible convert theory practice adopted   lation model reduced evolutionary algorithm con•  approximation performance bias based his•  verge unique global maximum                              torical information gathered during evolutionary run      difficult imagine real ccea algorithm    decreased bias through course run ad•  know maximum possible reward given indi•       vantage fact initial partners likely weak   vidual priori approach use historical information later partners stronger   during run approximate maximum possible collabo      performed experiments compare simple      multiagent systems                                                                                                                                                                             table  proportion runs converged global optimum                                                                            average best individual fitness climbing domain                                                                                                                   penalty      figure  joint reward continuous peaks domain     evolution sc biased coevolution bc three prob•   lem domains detailed later sc bc base fitness   immediate performance individual context             table  proportion runs converged global optimum   individuals cooperating population bc ad•                average best individual fitness penalty domain   ditionally includes bias factor fitness based   approximation individuals fitness                                                                            ular strategy possible partner strategies exper•  cooperate ideal partners                                                                            iments paper chose approximate maxreward      compared techniques combination                                                                            setting maximum reward seen far run   approaches representing individual pure                                                                            given strategy   strategy representation psr individual represented                                                                               experiments fit individual survived auto•  single strategy psr individuals stored single integer repre•                                                                           matically generation select in•  senting strategy question psr individual bred chil•                                                                           dividual breeding chose individuals random   dren through mutation coin repeatedly tossed                                                                            replacement population selected fitter   individuals integer increased decreased direction                                                                            each experiment repeated  times   chosen random coin came heads                                                                            experiments used ecj software package luke    mixed strategy representation msr individual   represented single strategy probability distribu•             problem domains   tion possible strategies evaluating msr                                                                            experimented three different singlestage game do•  individual partner agent  independent trials                                                                            mains simpler ones climb penalty introduced   performed each time each agents strategy chosen                                                                            claus boutilier  complex artificial   random agents probability distribution msr                                                                            problem peaks evolutionary runs climb   individuals used onepoint crossover followed adding ran•                                                                           penalty problem domain lasted  generations used    dom gaussian noise ju —    each distribu•                                                                           individuals population runs peaks domain   tion values followed renormalization distribution                                                                            lasted  generations used populations  individu•  observe using msr creates potentially difficult                                                                            als each   problem domain using psr reasons search space   size stochasticity fitness result                               joint reward matrices climb penalty                                                                            domains presented table  domains difficult      chose common approach cooperative coevolution                                                                            penalties associated miscoordinated ac•  fitness assessment individual assessed twice deter•                                                                           tions presence suboptimal collaborations avoid   fitness partner chosen random                                                                            penalties figure  presents continuous version   partnered individual population                                                                            peaks coordination game axes represent   received highest fitness previous generation in•                                                                           continuous range actions agents axis   dividuals fitness set maximum assess•                                                                           shows joint reward reward surface peaks   ments during fitness assessment individual receives                                                                            lower spread large surface   number rewards trying certain strategies                                                                            higher covering small area agents strategy   context partners psr individual assessment                                                                            space continuous  discretized increas•  simply single reward received trying strategy                                                                            ingly difficult sets      strategies   partners msr individual tried fifty strategies as•                                                                           discretizations result slightly different optimal values   sessment mean fifty rewards received      sc bc differ bc adds reward bias                results   term reward —    • reward   • maxreward    decreasing bias rate starts  lin•            tables  present proportion  runs con•  early decreases reaches   maximal run           verged global optimum plus mean fitness   length passed ideally maxreward bias factor              best individuals runs msr individuals consid•  highest possible reward received trying partic          ered optimal optimal strategy held                                                                                                                     multiagent systems table  proportion runs converged global optimum   average best individual fitness peaks domain                                                                                                                                                                                              generations                                                                    figure  distance bestofgeneration individuals op•                                                                 timal strategy  actions peaks domain using sc                                                                  bc                                                                    successful applications biasing method tied suc•                                                                 cessfully determining appropriate degree bias apply                                                                  msrs increased difficulty challeng•                                                                 ing appropriate balance bias figure  sug•                                                                 gests exactly notice early run                                                                   strong algorithm tends optimal   figure  distance bestofgeneration individuals op•  solution bias reduced over•  timal strategy  actions peaks domain using sc     whelmed trajectories eventually drawn   bc                                         suboptimal local attractor problem                                                                  larger figure  shown failure                                                                  occurs earlier run suggests careful attention   percent distribution fact optimal msr indi•                                                                 needed set parameters adjust bias rate   viduals  percent                                                                  using msr versus psr running longer allow•    biased coevolution consistently global optima                                                                  ing interactions during evaluation able   standard coevolution                                                                  obtain convergence global optimum using msr   times standard coevolution held                                                                  shown   climbing penalty domains psr individuals   optimum  time harder   peaks domain msr individuals op•        conclusions future work   timum problems individuals op•       cooperative coevolution successfully ap•  timum  time compared dif•        plied task learning multiagent behaviors re•  ferences mean best fitness run using twofactor     search algorithms advances increas•  anova repetitions factored method used      ingly clear algorithms favor stability opti  problem domain                                            mality problem domains paper develop     anova results allow state  confi•          simple idea improve coevolution through use   dence biased coevolution better simple coevolu•   maximum reward bias introduce theoretical justifi•  tion msr used climbing domain        cation idea present experimental evidence   peaks domain psr used tests      confirms biasing coevolution yield significantly bet•   confidence stating bcmsr better  ter results standard coevolution searching op•  scmsr penalty domain                                 timal collaborations work reveals domain     order better understand happens using       features greatly influence levels biasing necessary   msr peaks domains plotted average eu      convergence optima problems performance   clidian distance best individual generation changes slowly level bias modified   known global optima figures   graphs present     domains rapid degradation results    confidence interval mean fitnesses in• suggests adding kind maximum reward   vestigations showed sc converged suboptimal interac•  bias helpful work under•  tions lower wider peak figure  cases standing best apply bias different problem do•  hand trajectories search process radically mains   different using bc lets closer look      initial experimental results paper suggest                                               effective use history approximation true     learned discussion surrounding figure      maximal collaborative reward given strategy future       multiagent systems                                                                                                    
