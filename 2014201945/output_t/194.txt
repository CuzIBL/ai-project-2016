data clustering principal components hopfield selfaggregation networks                                                        chris hq ding                              nersc division lawrence berkeley national laboratory                           university california berkeley ca  chqdinglblgov                               abstract                               wellmotivated clustering objective functions point                                                                  recognition spectral graph clustering embedded        present coherent framework data cluster•                                                                 scaled pca leading selfaggregation networks        ing starting hopfield network show                                                                    paper combines three threads develop        solutions wellmotivated cluster•                                                                 coherent framework clustering begin twoway        ing objective functions principal components         clustering generalize multiway clustering §        minmaxcut objectives motivated ensuring        cluster balance solutions nonlinearly         twoway clustering        scaled principal components using scaled pc        generalize multiway clustering construct•         start formulate twoway clustering hopfield net•       ing selfaggregation network connection          work derive pca cluster indicator vectors        weights different clusters automati•           hopfield network pca        cally suppressed connection weights        clusters automatically enhanced                 given data points properly defined similarity associ•                                                                 ation  points form network                                                                  weighted graph connection    introduction                                                                  nodes wish partition clusters cjc   principal component analysis pca widely adopted     result clustering represented indicator   effective unsupervised dimension reduction method pca      vector   extended different directions hastie stuetzle    kramer  lee seung  scholkopf et al                                                                  collins et       main justification pca uses singular value de•  consider clustering objective   composition svd best low rank approxima•    tion norm original data eckartyoung theo•  rem results inadequate explain   effectiveness pca provide new derivation   pca based optimizing suitable clustering objective func•                                                                 ity analogously sc   tions show principal components actually cluster    propose minmax clustering principle data   indicator vectors clustering                                                                  points grouped clusters overlap sc      hopfield networklhopfield  provide convenient       different clusters minimized withincluster   framework study particular selfaggregation    similarities maximized   network proposed work uses hebb rule encode pat•                                                               tern vectors feature hopfield associativememory   networks adopted solve hard combinato•    conditions simultaneously satisfied maximiz•  rial problemshaykin  nd ed                            ing energy objective function using hopfield model     thread work spectral graph partition• hopfield  solution obtained update rule   ing fiedler  pothen et al  hagen kahng    shi malik  ding et al   ng et al  meila shi  uses laplacian   matrix graph arises naturally balancing clus• vector form relaxes qi   ters approach differs mainly           discrete indicators continuous values                                                                   solution given       work supported department energy office science   through lbnl ldrd contract deacsf                                                                        learning                                                                                                               matrix entries nonnegative prin• solutions equation singular value decom•  cipal eigenvector qi positive negative entries position svd left singular vectors   desired solution                               right singular vectors svd £    hopfield network bipartite graph                                                                                                                            extend hopfield networks clustering bipar•  tite graph example bipartite graph term  document association matrix  each row rep•             matrix entries nonnegative     resents word each column represents document btj    principal components entries sign   counts cooccurrence row rt column desired solutions  note   show solution clustering indicators precisely svd employed lsi summarize results   latent semantic indexingdeerwester el al           theorem  principal components solutions clus•     wish partition rtype nodes parts  tering indicators clustering undirect graphs bipartite     simultaneously partition otype nodes graphs appropriate hopfield network models   parts based clustering principle mini•  mizing betweencluster association maximizing      principal component clustering   cluster association use indicator vector determine   objective explicitly enforce balance   split    depending                   clusters eql need minimize                     use determine split   consider clustering objective                       depending      presentation purpose index nodes                                                             nodes cluster indexed contiguously   clustering algorithms presented independent as•                                                                parameter — adjust   sumption bold face lower case letters vectors matri•                                                                control levele balance principal   ces denoted upper case letters write                                                                 eigenvector desired indicator                                                                 vector                                                                    reasonable choice natural choice                                                                   set average wij                                                                 choice modified weight matrix satisfies sumtozero                                                                                                                           condition     convenient convert bipartite graph undi•                                                          rected graph follow standard procedure combine   types nodes setting                                                                    condition refined centering each col•                                                             umn each rows                                                                                                                          induces undirected graph adjacency matrix   symmetric weight matrix     consider following objective function                                                                                                                                                                                                                                                                   column row sums                                                                 standard notations statistics desired    sum association                                cluster indicator vector principal eigenvector     src sum association   sric srci mini•                                                                  fully centered useful property eigen•  mized sr  sum association cluster                                                                  vectors nonzero eigenvalues sumtozero   figl src sum association cluster                                                                 property        sr  sr maximized condi•                                                                eigenvector  eigenvectors   tions simultaneously satisfied maximizing     write hopfield network update rule   orthogonal qo   relaxes qi discrete indicators continuous val• sumtozero condition   does necessar•  ues solution satisfies eq utilizing explicit ily imply sizes cluster   structures                                equal fact cluster indicator vector refined                                                                                                                                                                                                                                       learning paper vectors implicitly normalized  using overcome problem seek prevent      norm correspondingly clustering objective   scc scc small optimizelding                                                                  et                                                                                                                                                                                      clearly terms represent average  clustcr similarities maximized rd term   represent average betwcencluster similarities min•  imized factor encourages cluster balance                                                                                                   reached          summarize results   theorem  solution clustering objective given   qi solution clustering objective      clustering schemes objective functions             principal component clustering methods                                                                                                                           use principal components      discussions apply bipartite graphs exam•  written   ple                                                                                                                                                                                                                                                   desired solutions eigenvector associated                                                                  second largest eigenvalue note comparing                                                                  eq eq net effect cluster balance di•  sizes row clusters  — total                      agonal scaling diagonal scaling leads   row size sizes column clusters  important feature selfaggregation §               column size terms represent                                                                   cluster balance bipartite graphs   average withincluster similarities maximized   terms represent average betweencluster sim•  balanced clustering bipartite graphs object function   ilarities minimized                                 eq      note partially motived classic scal•  ing called principal coordinate analysis statistics   iborg gronen  suppose given pairwise   distances dataset define pairwise similarity     using representation eq similar deriva•                follow through centering procedures    tion ding  zha et al  solution optimiza•    solve eigenvectors classic scaling the•  tion given eq let dr  diagbe   orem proves dtj euclidean distances                    eigenvectors recover original coordinates   theorem justifies use principal eigenvec•  tors coordinates multidimensional scaling   clustering approach does emphasize recovery   original coordinates objective function  motivated clustering                                                                  maximized oc•  curs cluster larger            vice versa                                        clustering balancing using minmaxcut objective eq                                                                  simple objective eq scaling associ•     exprr monotonic max maxexp    minexp  approx•                                   ation matrix eq scaling   imately eq                                                 selfaggregation property emerges  away clustering   mainly focus way clustering gen•  eralize away clustering   generalization   based key observation solution cluster in•  dicator vectors § § scaled principal com• eigenvectors eigenvalue lin•  ponents discuss                                  ear combination step functions piecewise constant                                                                 function clearly data objects cluster    scaled principal components                               identical elements coordinate object                                                                dim spca space objects   associations data objects quantified                                                                 cluster located selfaggregate   similarity metric scaled principal component approach                                                                 point spac space   starts nonlinear nonuniform scaling noting                                                                    scaled principal components unique    dd        wd    apply spectral                                                      orthogonal matrix   decomposition scaled matrix                                                                                                                              note eq identical eq eq scaled   principal components cluster indicator vectors min    clusters overlap   maxcut §                                              consider case overlaps different clusters                                                                 exist overlaps treated perturbation theorem    selfaggregation network                                   order scaled principal components   hopfield networks pattern encoded net•   eigenvalues form   work hebb rule multiple patterns encoded   additively problem pattern cluster partitioning   indicator vector define selfaggregation network   connection weights                         highlights important   properties wsa provides example applica•  tions selfaggregation studied ding et al            interesting selfaggregation property enforced   withincluster association connectivity prove ap•  ply perturbation analysis writing    similarity matrix clusters        features spca obtained theorem    separated zerooverlap accounts overlap         corollary  sa network block di•  clusters treated perturbationlding et al   agonal form eq accuracy theorem    perturbation approach standard quantum     assures objects cluster self  physicsmathews walker                             aggregate theorem                                                                  corollary  scaled principal component qi                                                                                                                     qi                                                                 exact solutions original eq                                                                 corollary    second principal compo•                                                                nent                                                                                                                                                                                                                                                                                                                                                                   learning note precisely eq clustering objective   started clustering framework consistent   example  dataset  clusters substantial ran•  dom overlap clusters edge weights    similarity matrix results shown figl   nonzero matrix elements shown dots exact   approximate theorem  close       wsa sharper original weight matrix   clearly selfaggregation connections differ•  ent clusters substantially suppressed connections   clusters substantially enhanced       figure  left similarity matrix diagonal blocks repre•  sent weights inside clusters offdiagonal blocks represent   overlaps clusters right computed wsa    application  dna microarray gene expression pro•                                                                figure  gene expression profiles cancerous normal lym•  filing responses thousands genes tumor tissues    phoma tissues samples alizadeh et al original euclidean   simultaneously measured apply spca framework          space scaled fca space scaled pca space   gene expression profiles lymphoma cancer sampleslal    iteration eq  panels objects original space   izadeh ex al  three cancer three normal subtypes   shown dview spanned pca components   shown fig difficult case large cluster structures clearer selfaggregation in•  variations cluster sizes number samples each sub• sert shows eigenvalues st nd sa network   type shown parentheses figb selfaggregation   evident figure computed clusters corre•     noise reduction   spond quite normal cancer subtypes identified                                                                   sa net noises example wsfii nega•  human experts                                                                 tive weights wsaij expect nonnega                                                                tive corollaries    diagonal    dynamic aggregation                                                                                 sa                                                                block structure elements block identical   selfaggregation process repeated obtain        eq overlaps exit property allows   sharper clusters lowdimensional projection   interpret probability objects   contains essential cluster structure combining struc• belong cluster   ture original similarity matrix obtain new sim•  ilarity matrix containing sharpened cluster information                                                                 reduce noise dynamic aggregation set                                                                                                                                                                                   weight matrix fth                              chose  noise reduction   iteration setting crucial enforcing cluster       integral sa net experiments final re•  structure                                                    sults insensitive dynamic aggregation     applying sa net leads aggregation     repeats selfaggregation process forces data objects   figure eigenvalues st nd sa net     attractors desired clusters   shown insert figure iteration proceeds clear principal eigenvalues approach  insert figc usu•  gap developed indicating clusters sep• ally iterations cluster structure   arated                                                       evident       learning                                                                                                             
