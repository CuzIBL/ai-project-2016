                            learning     forward     models    robots                                      anthony  dearden   yiannis  demiris                            department  electrical electronic engineering                                          imperial college london                                    exhibition road  london  sw  bt                           email  anthonydearden ydemirisimperialacuk                        abstract      forward models enable robot predict ef      fects actions motor      environment vital aspect intelligent      haviour robot use predictions decide      best set actions achieve goal ability      learn forward models enables robots      adaptable autonomous paper describes      learnt represented      bayesian network robot’s motor      controlled explored using ‘motor babbling’      feedback motor comes com      puter vision techniques requiring prior informa             figure  forward model      tion perform tracking learnt forward model      used robot imitate human      ment                                                        forward models forward models dynamic                                                        certain environments learnt topic    introduction                                       investigated paper forward mod                                                        els used different context similarities  purpose robot interact environment work calibrating actionsensor models robotics  separation effects robot roy thrun  robot learning  produce environment mechanisms produc environment position active  ing motor commands overcome inverse trying learn situation draws inter  forward models used jordan rumelhart  esting parallels learning human infants mech  robotics forward models enable robot predict anisms babbling issuing random motor commands  sequences actions given current state robot used infants learn control motor sys  predict set motor commands inﬂuence tem meltzoff moore   state robot environment observa  tions perceived robot’s sensors shown presented enables robot au  ﬁgure  conversely inverse models used output tonomously learn forward model prior knowledge  necessary motor commands achieve maintain desired motor external environment informa  goal internal models hypothethised tion effects robot’s actions captured  used human motor control wolpert et al  vision clusters lowlevel image features au  ability predict consequence actions tomatically ﬁnd track moving objects scene  uses robotics allowing mental rehearsal possi robot sends random motor commands motor  ble actions imitating actions humans robots receives information vision  demiris                                       set evidence used learn structure parameters    practically environment robot works change bayesian network represents forward model  properties modelled model used enable robot predict  environment assumed completely pre effects actions observing gestures human  dictable endowing robot knowledge vision robot imitate human  abilities desires programmer truly au gesture using forward model learnt motor  tonomous robot needs able learn adapt  representing   forward  models   bayesian     variables hidden nodes robot’s knowledge     networks                                           comes noisy observations state ot  bayesian networks pearl  ideal method rep  resenting forward models learnt offer way  robot learn use forward  representing causal nature robot’s control models  rigorous probabilistic framework structure forward model described section   aimed learning representing causal associations quire aspects learnt firstly representation  tween robot’s motor commands robot’s state state robot environment needed rich  observations robot’s state received vi est source information comes robot’s  sion motor commands state robot vision challenging  represented random variables bayesian network source information comes lowlevel format pixels  causal relationships shown arcs furthermore robot seeking learn forward mod  bayesian network represents learnt probability distribu els prior information track  tion previous motor commands mn t−d environment unknown extract information  current states sp observations state scene method needed automatically initialising  op variable represents delay mo tracking objects presented works  tor command issued robot’s state changing real clustering tracked lowlevel features image accord  robotic systems assumed effect mo ing position dynamics allows position  tor command occur just timestep objects scene tracked knowledge  parameter modelled learnt figure  shows objects having supplied  structure      figure  ‘template’ bayesian network forward  model question marks represent struc  ture needs learnt causal association  motor commands state robot ob  servations associated each object scene rect  angular nodes correspond observed nodes      motor random variables represent speciﬁc lowlevel figure  vision ﬁnds moving objects scene  motor commands robot discrete clustering optical ﬂow points  ‘open’ ‘close’ robot’s gripper continuous set  height gripper robot issuing lowlevel point features used tracked using  commands uncertainty value lucaskanade optical ﬂow algorithm lucas kanade  modelled observed nodes alternatively  tracked points clustered using kmeans  robot observing actions robot human algorithm according position velocity draw  whilst using forward model hidden nodes method clustering number clus  bayesian network receive direct evidence ters known overcome ﬁrst ex  value                                       cluding stationary points extracting increasing numbers    observations statespace ot represented clusters error particular number clusters  square nodes descended st ﬁgure  taken average squared distance optical  model treats ot noisy observations actual state ﬂow points centre cluster  space noise vision uncer cluster number used curvature  tainty modelled evidence actual state error respect number clusters minimised  robot enters state space hoppner et al  positions velocities sizes  st robot represented depends infor each clusters used observations  mation received vision state ot objects forward model learning                                                      known data used learn structure                                                        parameters network methods learning struc                                                        ture data based performing search through                                                        space possible structures goal ﬁnding                                                        maximises loglikelihood model given data                                                        friedman  neapolitan  higher log likeli                                                        hood accurate particular network predicting                                                        data subject constraint complexity                                                        model structure highest likelihood                                                        connections node paper                                                        network structure learnt experiment                                                        performing search through set possible structures                                                        choosing maximises loglikelihood  figure  robot learn environment search performed online training evaluating simul  stages  involved experiment outlined text taneously set candidate models search space                                                        set models different delays motor commands  actual state motor st taken hidden different observation nodes each possible object  discrete node each object scene vision second issue particular motor commands  connected continuous observa values chosen learn ac  tion                                                 curate forward model unlike machine learning situa    possible nodes bayesian network spec tions forward model robot active  iﬁed ﬁnal task learn motor commands bayesian network structure attempting learn sit  teract state train parameters bayesian uation referred active learning received relatively  network predictions accurate possible little attention bayesian networks literature active learn  train bayesian network set evidence required data ing bayesian networks discussed unknown  set containing actual observed values observed nodes parameters unknown structure tong koller   network set motor commands executed  method choosing motor commands ex  each time step mn − observations periment paper inspired idea babbling  state op size position velocity object infant motor skill learning meltzoff moore   problem use data learn struc motor commands chosen random walk through  ture parameters bayesian network inspiration markov model  solving problem learn bayesian net  work taken developmental psychology gopnik  experiments   learn forward  model  meltzoff compare mechanism infant uses learn  scientist scientists form theories make observa experiment carried show forward models  tions perform experiments make generalisations revise autonomously learnt used robot used  existing theories gopnik meltzoff  notion activmedia peoplebot shown ﬁgure  task  forming theories world dealt learn forward model movement robot’s  forward model seen theory robot’s grippers robot needed learn predict effects  world process robot uses obtain data infer motor commands prior information appear  forward model experiment outline ance grippers nature motor commands  robot’s experiment involves follows highlighted speciﬁed robot perform experiment  ﬁgure                                            babbled motor commands observed happened                                                        learnt relationship motor command    particular motor command mt chosen      observation using bayesian network process    value motor command sent robot’s repeated accurate model learnt      motor                                       motor command  case limited just    vision returns set observations degree freedom robot’s grippers ei                                                      ther opened closed halted motor commands      scene op td example moving forward ms decided random using random walk through markov      direction                                   model shown ﬁgure  motor commands sent accord    training set data mt op td used ing current state markov model state      train bayesian network develop forward model change each timestep according transition prob                                                        abilities shown ﬁgure parameters markov    process repeated different                                                        model chosen motor stays bab      value current motor command different mo                                                        bling state just long information train      tor command altogether                                                        forward model moving state  open issues relate stages firstly motor commands sent grippers moved  structure bayesian network completely vision correctly calculated tracked posi          figure  activmedia peoplebot                                                          figure  tracking working grippers           open gripper         close gripper           correctly identiﬁed moving objects                                                        identiﬁed grouped primitives shown colour                                                  stop gripper      figure  markov model gripper babbling values  arcs represent transition probabilities going  state self transitions shown                                                                  template bayesian network gripper  tions moving grippers scene ﬁgure  shows figure   grippers located tracked tracking sys ward model vision supplied information  tem worked situation black objects automat objects interacted grippers                                                        robot learn delay  action ef  ically tracked black background                          robot’s base                                         fect observations change state each                                                        object represents translation change velocity    vision provided random variables                                                        parameters specify bayesian network  states st observations ot bayesian network  forward model situation objects  grippers automatically added bayesian network use forward model velocity posi  each gripper represented discrete node state tion size task structure learning algorithm  set continuous nodes observation maximise loglikelihood data given  represented gaussian distribution set model case log   possible observations ot velocity velt set motor commands experiment set  position post size sizet tracked objects corresponding observations directed acyclic  basic template structure forward models graph representing structure model  learnt shown bayesian network ﬁgure    parameters model value calculated    forward model robot’s gripper parameter learning process particular model  relatively simple example highlighted trained data  robot needed learn parameters important each model parameters bayesian network  properties structure needed learnt firstly learnt using expectation maximisation em algo  known long delay motor com rithm inference stage performed  mand issued gripper changing state junctiontree algorithm pearl  experiment  shown ﬁgure  multiple possible motor commands search space small robot consider  connected each state previous commands each possible candidate structure simultaneously pre  shown diagram simple secondly vious  motor commands considered  possible  known observation vision best combinations observation variables velt post                                                                                                                                                                                                     left gripper observation                                                                                                                                                                                                         predicted left observation                                                                                                                                                                                        −                 predicted right observation                                                              −                                                          actual  gripper velocities                                                            −                                                              −                                                                              right gripper observation                                                            −                                                                                                                                                                              time                                                          figure  evaluating predictive abilities learnt                                                        ward model predicted gripper movements dashed                                                        close actual ones solid differences princi  figure  loglikelihoods bayesian networks pally variation gripper velocities each  using velt observation node evolve course three motor commands modelled noise  typical experiment maximum loglikelihood ward model  bayesian network motor delay  time steps   ms    sizet each gripper search space contains  pos  sible models figure  shows loglikelihoods  bayesian networks varying motor delays veloc  ity observation change time ﬁgure shows  motor delay maximise loglikelihood   timesteps  ms following search figure  using learnt bayesian network inverse  learnt forward model grippers shown ﬁgure  model evidence supplied observations state  motor command learnt mt best task infer probability distribution motor  observation learnt velocity grippers commands  correct motor commands control grip  pers’ velocities                                                        means observations velt velt                                                        ference algorithm used calculate marginal distribution                                                        junctiontree algorithm pearl  evaluate                        mt                                                        quality learnt forward model grippers babbled                                                        similar way using different markov model                                                        figure  shows likely predicted observation                    st     st                     compares actual observation xcoordinate                                                        predictions plotted grippers’ movements                                                        predominantly plane prediction shown                                                        accurate                   velt   velt                      learnt bayesian network used                                                        verse model calculating likely motor command     figure  learnt forward model grippers given current velocity observation each timestep                                                        shown ﬁgure  use inverse model imi                                                        tation replacing robot’s observations                                                        ment observations human’s hand movements     using bayesian network forward model                                                       inverse model robot able reproduce motor  bayesian network ﬁgure  learnt commands likely recreate human  used forward model prediction movement gripper principle  consequences motor command forward mod used demiris switch imitation recognition al  els grippers predicted output velocity beit multiple paired inverse forward model  grippers calculated conditional probability distri demiris  figure  shows results imitation  bution pveltmtm observations experiment robot able imitate simple hand wav  modelled gaussians likely values ing motion human’s hand movements tracked
