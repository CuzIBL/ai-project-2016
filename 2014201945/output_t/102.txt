   tfidf weighting text categorization vector space model                      pascal soucy                                  guy mineau                       coveo                                      université laval                   quebec canada                                 québec canada                 psoucycoveocom                             guymineauiftulavalca                          abstract                      liu  brank et al  dumais et al                                                     weighting method appropriate ir       knn svm machine learning         clear best choice tc problems       approaches text categorization tc based actually weighting method does leverage       vector space model model borrowed information implicitly contained categorization task       information retrieval documents    represent documents       represented vector each component   illustrate let suppose text collection       associated particular word   categorization tasks tfidf weighting       vocabulary traditionally each component value representation each document represented                                                    vector importance       assigned using information retrieval tfidf       measure weighting method word document seen independent       appropriate ir clear best categorization task believe       choice tc problems actually weighting case situations suppose task       method does leverage information     consists classifying categories documents       implicitly contained categorization task pertain computers documents don’t       represent documents paper introduce intuitively words intel keyboard       new weighting method based statistical    relevant task words       estimation importance word reason words       specific categorization problem method higher weight ones suppose       benefit make feature selection implicit consists classifying different categories       useless features categorization documents written english documents written       problem considered small weight  languages arguable particular task       extensive experiments reported paper shows words english stop word les french stop       new weighting method improves      word relevant tfidf       significantly classification accuracy small weight idf inverse document       measured categorization tasks       frequency low fact                                                    weight assigned task example                                                    somewhat extreme case believe weighting       introduction                                approach benefit knowledge                                                    categorization task hand     knn svm machine learning approaches    paper introduce new weighting method based    text categorization tc based vector space model statistical estimation word importance    salton et al  model borrowed information particular categorization problem weighting   retrieval ir approaches known benefit makes feature selection implicit   accurate text categorizers joachims yang useless features categorization problem considered   liu  vector space model documents small weight   represented vector each component associated    section  presents tfidf weighting function   particular word text collection vocabulary  new weighting method introduced paper section      generally each vector component assigned value  describes evaluation test bed section  report   related estimated importance weight results show significant improvements terms   word document traditionally weight classification accuracy     assigned using tfidf measure joachims yang               weighting approaches text categorization approach presented han  study                                                              vector components weighted using iterative approach                 tfidf weighting                           involving classifier each step each iteration              tfidf common weighting method used weights slightly modified categorization              documents vector space model particularly accuracy measured using evaluation set split              ir problems regarding text categorization training set convergence weights provide              weighting function particularly related optimal set weights appealing probably              important machine learning methods knn svm near optimal solution training data              tfidf function weights each vector component each information available classifier method              relating word vocabulary each document generally slow used particularly broad              following basis incorporates word problems involving large vocabulary              frequency document word appears    weighting methods based confidence              document tf term frequency high              estimated significant document addition weighting method named confweight rest              idf measures infrequent word collection text introduced paper based statistical              value estimated using training text confidence intervals let xt number documents              collection hand accordingly word frequent containing word text collection size              text collection considered particularly text collection estimate proportion              representative document occurs documents containing term               documents instance stop words contrast                                                                                                                   word infrequent text collection believed   xt  zα                                                                                                                   relevant document tfidf commonly used          nz              ir compare query vector document vector using             α              similarity distance function cosine similarity wilson proportion estimate wilson               function variants tfidf following                                                              α value Φzα  α Φ             common variant used experiments                                                             tdistribution student’s law function               yang liu                                                                                                                                 normal distribution ≥  ≥                                           ⎧                                                                                             logtf log  tf                                                           ⎪    td≥td                                                                                weighttd  ⎨       xt                                                                ⎪                          ⎩                                                                                     confidence interval                tf  frequency word document                                                td                                                            −                                                                            ±                                  number documents text collection xt                            number documents word occurs normalization               unit length generally applied resulting vectors categorization tasks formulated way use              unnecessary knn cosine similarity function  binary classifiers classifier decides                                                              document belongs specific category                supervised weighting                       task categories binary classifiers              debole sebastiani  tested compared   given category let  equation                                                                                                          supervised weighting approaches leverages applied positive documents labeled             training data approaches variants tfidf related category training set             weighting idf modified using common                                       −                                                             negative class use label minpos             functions used conduct feature selection paper                                                              lower range confidence interval              best finding variant information gain                                                                                        label maxneg higher range  according             gain ratio respective category ci gain ratio                         p−            term tk                                   measured respective training set let                                   igt                   minposrelfreq                      grt       ki                         ki                                                              − ∑  pclog pc                               cc∈c                                                                                                 ii                                                  minpos                                                                    minposrelfreq                                                                                                        minpos maxneg             joachims slight variant used tf used                                                              logarithm function yang liu  reports    occurs categories positive             significant difference classification accuracy log instances tdistribution used instead normal law             applied                              equations modified accordingly define strength term category   frequently relative number documents                                                   positive category negative                                                   weighting method favors features proportionally         ⎧log ⋅minposrelfreq minpos  maxneg    strt  ⎨                                 frequent positive class weight decreases                 ⎩                                         maxneg increases eq  scales weight values linearly                                                    range resulting weight    weight ≠  iff word appears proportionally term occurs relative frequency classes   frequently  category – category proportionally frequently negative set finally   worst measured confidence interval eq  makes decrease faster reflect rate   estimation error scenario categories features lose “energy” evenly   weight ≠  categorization task divided distributed positives negatives   binary classifiers maximum strength consequence predictive features high weight                                                   regardless absolute frequency proportion                                                                                   differences matter               maxstrts  max  trtc                              c∈categories                 interested weighting training testing                                                   documents components vector space model   maxstrt global policy technique debole use  individual documents taking document   sebastiani  value best term frequency account define confweight   classifier used binary classifiers document    using global policy allows use document    representation binary classifiers local confweight  logtf maxstrt     policies intuitively appealing global policies   td     td  categorization task divided binary                                             problems debole sebastiani  shown global eq  quite similar tfidf equation    policies good local policies note weights term according importance   value  maxstrt akin feature selection document second weights term globally   deciding reject feature                 unlike tfidf confweight uses categorization     figure  presents example highlight behavior problem determine weight particular term    eq   figure minpos set     means hypothetic term occurs recall   value lower range relative document frequency    methodology   confidence interval half documents positive    corpora   set curves labeled    graph   consists resulting weights different values paper three data sets previously studied   maxneg eq  gives weight terms occur literature selected datasets reuters                                                   ohsumed new reuters corpus vol  let                                                   briefly datasets                                                     reuters lewis  categories related                                                business news report written using limited                                                vocabulary succinct manner used modapte                                                   lewis  split  categories having                                                                                            training testing document categories                                                                                                   highly unbalanced each document categorized                                             category                                                         ohsumed comes large text collection                                                medline bibliographical index rarely used                                                available categories documents chosen split                                                text collection lewis et al                                                    result task comprising  closely related categories                                                  using technical vocabulary similarly reuters                                     document classified categories                       maxneg                         finally reuters corpus vol  rcv rose et al                                                    newer text collection released reuters corp          figure  weight  vary ing axneg wit consists year new stories                   fixed minpos                 documents  categories documents                                                   assigned collection large making  challenging task learning models svm number documents labeled    knn polynomial complexity particularly classifier category     able use svm large training set   category classifier precision defined    svm does scale large text collections aac recall aab combine    using knn implementation limited measures single value fmeasure used    training set  documents testing fmeasure reflects relative importance recall versus    set  documents average  precision importance granted precision   categories assigned each testing document recall fmeasure    total assignments                                                                                          precision  recall                                                                                     classifiers feature selection settings                ⋅ precision⋅ recall   weighting method presented paper intended    weight documents vector space model  fmeasure estimation breakeven point    used classifiers using model precision recall meets classifier parameters    reason evaluated method using knn tuned balance precision recall    svm compared results obtained tfidf evaluated each category different values     gainratio debole sebastiani  weighting        used svmlight package joachims   compare methods needed combine   knn classifier described yang liu  values order approaches   experiments svm divided each     used macrof average microf average   categorization task binary classification problems macrof average simple average values   usual contrast knn able classify document each category gets weigh average   categories using multicategory classifier counterpart microf average weighs large categories   decide document classified smaller ones microf    particular category thresholds learned each global values instead category                                                   based ones instance microf total   category yang liu  tfidf experiments   weighted using eq  normalized unit length number classifications classifiers                                                    good predictions microf widely used text    gainratio experiments weighted debole                                                    categorization lewis et al  yang liu    sebastiani                                                      joachims table  includes microf results      reach optimal classification accuracy feature selection                                                    svm table  includes knn each   required included feature selection   tests information gain measure used experiment best score tfidf gainratio   rank features thresholds used confweight bolded                                                       results show low information gain   filter features confweight addition use   information gain select features maxstr thresholds confweight clearly outperforms tfidf    eq   feature rejected stop words gainratio drastic term selection conducted    removed words stemmed         overall scores tend decrease three term weighting                                                    methods interesting note large                                                    difference confweight tfidf using knn       results discussion                      difference particularly significant collection    assess classifier accuracy confusion matrix created size rcv     each category                                figure    show curves resulting use                        classifier   classifier     increasing number features decreasing information                             positive label negative label gain thresholds each weighting method using knn      true positive label                       clearly confweight weighting doesn’t      true negative label                       suffer decrease accuracy lowscored features                                                    added tfidf results stable confweight    table  confusion matrix used evaluate classifier accuracy gainratio observation leads claim tfidf                                                    sensitive choice feature selection settings     instance true positives number   gainratio sensitive presence    documents labeled classifier category terms relevant tfidf confweight    correct predictions similarly false negatives need term selection arguably inherent term                                                    selection mechanism believe confweight                                                     used feature selection produce good     time experiments conducted lyrl results    split released                            igain                      reuters                    weighting                    ohsumed                                    threshold                                                                                                                                 tfidf                                                                                                                               gainratio                                                                                                                                                                                                              confweight                                                                                                                                                                                                                                           tfidf                                                                                                                                     mi                gainratio                                                                                                                            confweight                                                                                                                     tfidf                                                                                                                           gainratio                                                                                                                       number features                   confweight                                        tfidf                                                                         tfidf                gainratio                                                                      gainratio                   confweight                                                                      confweight                     tfidf                                                                                                                                                   gainratio                                         figure  knn microfs reuters number                    confweight                                                               feature increases                      tfidf                                      gainratio                                                                     confweight                                                                                                              table  svm microfs text collection weighting method                                                                                                                                                                                                                                                                                                                                                                                                                                                                    igain                       reuters                                            mi                  weighting                 ohsumed rcv                                 threshold                                         tfidf                                                                      gainratio                                                                confweight                                                                                                               number features                   tfidf                  gainratio                                                                      tfidf                 confweight                                                                     gainratio                                                                                                            confweight                   tfidf                  gainratio                                     figure  knn microfs ohsumed number feature                  confweight                                                                 increases                    tfidf                                                                                         gainratio                       confweight                                                                  tfidf                                                                                                        gainratio                                                                                                                                                                                                                        confweight                                                                                                                                                                                                                                     tfidf                                                                                                                                                                                                                       mi               gainratio                                          confweight                                                                                                                                          table  knn microfs text collection weighting method                                                                                                     number features   interesting remark best overall scores                                           tfidf   each corpora using knn svm obtained                                                   gainratio   confweight reuters  svm                                                   confweight   knn ohsumed  svm  knn rcv                                                                               figure  knn microfs rcv number feature     knn                                                                                                          increases 
