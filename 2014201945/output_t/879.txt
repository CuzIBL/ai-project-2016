                      parametric kernels sequence data analysis                                      youngin shin donald fussell                                     university texas austin                                     department sciences                               codegurufussellcsutexasedu                          abstract                          ated point parameter space similarity metrics                                                        deﬁned independently elements parame      key challenge applying kernelbased methods  ters parameter space decomposed possibly      discriminative learning identify suitable lapping ranges overall similarity sequences      kernel given problem domain methods   computed taking summation kernel ele      stead transform input data set vectors ments associated parameters each range      feature space classify transformed data intuition use parameters encode informa      using generic kernel ﬁnding effec tion ordering input data kernel ﬂexi      tive transformation scheme sequence time ble way information frequently lost featurespace      series data difﬁcult task paper based approaches choose apply wide range      troduce scheme directly designing kernels orderpreserving transformations distances      classiﬁcation sequence data elements parameterizations obtain additional      handwritten character recognition object recog trol similarity metrics deﬁne note      nition sensor readings ordering information use term “parametric” does imply      represented values parameter associated assume sort priori parametric model data      each input data element similarity met   example case generative approaches jaakkola      ric based parametric distance corre haussler  note sequences ﬁxed      sponding elements combined problem dimensional feature vectors used instead input data      speciﬁc similarity metric produce mercer ker elements method needed assume      nel suitable use methods support   elements ﬁxeddimensional      vector machine svm scheme directly em      consider input represented sequence ele      beds extraction features sequences vary                                                        ments xi ∈ xie ··· xn choose      ing cardinalities kernel needing                                                        associate each element xi parameter τ xi parameter      transform input data common feature space follows      space classiﬁcation apply method      object handwritten character recognition tasks                                                                                     i      compare current approaches                         xk − xk−                                                               τxi                                      sults show obtain comparable                                        accuracy state art problemspeciﬁc meth      ods using systematic approach kernel design   associated parameters form nondecreasing sequence      contribution introduction general nonnegative real numbers starting zero      technique designing svm kernels tailored  sequences parametric kernel each iteration picks      classiﬁcation sequence data               element each sequences computes                                                        similarities elements associated param                                                        eters separately multiplied return overall sim    introduction                                       ilarity elements product similarities  common technique mechanical classiﬁcation regres elements parameters implies similar  sion deﬁne feature space domain elements contribute signiﬁcantly overall sequence  transform input data vectors space similarity associated parameters similar  apply appropriate classiﬁcation regression technique step repeated pairs elements  feature space data naturally rep sequences results summed return  resented irregular form feature vectors overall sequence similarity    paper propose new approach based direct na¨ıve application approach potential  matching using parametric kernels inputs vari swamped computational expense performing  able length sequences elements each element associ comparisons elements widely divergent param                                                    ijcai                                                                                                                  transformed set uniform size feature vectors                                                                                      similarity input data assessed evaluating                                                                                       generic kernel functions feature vectors handle                                                                                                 sequence data traditional kernel framework features                                                      based distance metrics extracted mean                                                    coordinates second order statistics median variance                                                  ···          ···          minimum maximum distances area                                                    features generalize impose                                                restrictions input patterns equal lengths                                                                        sampled equal rates alternatively histograms                                                 structed locations speed size aspect ratio                                                      tograms effective scheme map varying length se                                                                                                                      ΔΔΔ                                 quences uniform dimensional feature vectors porikli                                                        grauman darrell  unfortunately structural       figure  mapping sequence parameter space    information elements input patterns inevitably                                                        lost histogramming                                                          methods based direct matching suffer  eters contribute little ﬁnal result drawbacks retain structural information  tuitively handle limiting comparisons map input sequences sequences equal dimensional lo  subsets elements close parameter space cal features compared using known  closeness parameter space easily speciﬁed direct sequence matching techniques instance number  decomposition parameter space ranges close methods based dynamic time warping dtw  elements deﬁned parameters fall recently proposed classifying sequence data                                                                                         range instance decompose speech handwritten characters bahlmann et al                                                                                nonoverlapping intervals equal length Δ elements shimodaira et al   extensive survey  sequences close associated parame shown dtw methods effective tech                                                                                          ters fall interval figure  elements niques classifying sequence data lei govindaraju                                                                                                          grouped three ranges based afore  keogh kasetty  bahlmann et al                                                          normalized coordinates tangent slope angle com  mentioned decomposition scheme instance                                                        puted each points stroke sequence form  compared  sequence data types fall category handwritten feature vector dtw computes optimal distance  characters laser sensor readings digital signals sequences viterbi path used                                                        exponent radial basis function rbf tapia    ideally wish ﬁnd method meets fol                                                                    lowing requirements  computationally efﬁcient handle rojas   ﬁxed size feature vector computed  large inputs need assume probabilistic models strokes svm classiﬁer used achieved high                                                        accuracy  allowed ﬁxed feature  kernels positive semideﬁnite requirement ﬁxed  form inputs ability ﬂexibly embed structural vectors each stroke method’s application quite lim                                                                                                 formation input previous approaches fail ited lei govindaraju   extended squared                                                        er proposed similarity measure sequences  satisfy requirements sat  isﬁed approach appropriate decomposition uses coordinates points directly features  scheme parametric kernels computed time linear operate ﬁxedlength windows points  number elements inputs parametric kernels posi dtw methods deﬁne kernels shown                                                                                                         tive semideﬁnite admissible kernel methods symmetric satisfy cauchyschwartz inequality shi  svms require mercer kernels optimal solu modaira et al  svm classiﬁers employ ker  tion                                                 nels classify sequential data kernels based    applied method handwritten character dtw   metrics triangle inequality violated  recognition object recognition sensor readings cases resulting kernel matrices positive  results compare favorably best previously reported semideﬁnite admissible kernel  schemes using simple similarity metrics    methods svm guarantee exis                                                        tence corresponding feature space notion opti                                                        mality respect space contrast paramet    related work                                       ric kernels positive semideﬁnite  great deal work application suited use kernelbased classiﬁers  kernelbased methods data represented vectors fea  ture space shawetaylor christianini  sch¨olkopf  approach  smola  discriminative models ﬁnd complex  ﬂexible decision boundaries performance kernelbased discriminative learning algorithms ﬁnd  superior alternative methods rely complex nonlinear decision boundaries mapping input  heuristic preprocessing step input data examples feature space inner product                                                    ijcai                                                    evaluated kernel function κ  × → exam pair elements sets compared pa  ples input space linear decision function rameters fall range compare  corresponds nonlinear function xthis ···  similarity  “kernel trick” lets ﬁnd decision boundary ex given pair elements obtained taking product  plicit evaluation feature mapping function φ  → similarity κτ  × → elements’                                                                                          taking inner product computationally parameters similarity κx  × → deﬁned di  expensive intractable guarantee rectly elements each mercer  unique optimal solution kernel functions satisfy kernel function feature extraction function φ  mercer’s condition gram matrix obtained parametric kernel deﬁned  kernel functions positive semideﬁnite      parameters                                                 φxφxφx ···φn−x         underlying intuition work associate param  eter each elements enforcing parametric  similarity equivalent similarity structure el                                                                 φ          κ  ·κ τ  τ ·  ements input patterns work assumes input                 xi    τ               patterns varying length sequences elements        xi∈itx  common input feature space example handwritten                                                        wxi nonnegative weighting factor given se  characters sequences points images     ···      ···   grids ﬁxed dimensional color values structure quences                   para  sequence manifold vectors image metric kernel function normalization deﬁned  manifold vectors assuming colors repre sum similarity ranges   sented rgb instance parameter element  point manifold corresponds element                    n−  parameters elements close κx zφx · φz    φtx · φtz   structurally close parametric association                       deﬁned making choice kernel func                                                         tions                                                                  φtx · φtz                           parametric kernel                                                                                                                      κ κ τ  τ   input pattern sequence elements each           xi zj    τ                                                                            ∈i         xi                        ··· xx              element  dimensional vector                         ∈i                                                                   xi ∈  number elements vary se  quences associate each element parameter pa note product κx κτ taken   rameter space function τ  rd →  consider score high signiﬁcance  note  decomposition nonoverlapping ranges      comparison elements                                                        common range instead compare                          n−                          elements input input                                                  face number undesirable consequences instance                                                                                    ···                                                     figure  compare                                                                zz result higher similarity value    instance recall earlier sequence example helpful certain cases time  set nonnegative real numbers τ deﬁned likely confused inputs   decomposed shown figure            far elements case swamped                                                        bad comparisons course need dramatically                                                          ttt                             time compute  number kernel evaluations               Δ     ΔΔΔΔ                           signiﬁcantly increased                                                         parameter space decomposition solves problems                                                        decomposition scheme introduce quanti  figure   parameter space decomposed  non                                                        zation errors overcome problem allow ranges  overlapping ranges length Δ                                                        overlap instance ranges figure  overlap                                                        Δ shown figure  suppress overcontribution    derivation parameter kernel functions elements fall intersections ranges intro  ﬁrst deﬁne decomposed element set tt itx    duce weighting factors   xiτxi ∈ tt set elements simplest weighting scheme average  associated parameters tt previous example similarity overlapped regions scheme    shown figure  instance ixxx    fault value wxi txi wheretxi  ttτxi ∈ tt    izzzzz compute similarity ranges overlap txi     each range taking weighted sum similarities fore wxi  overlapped ranges yield                                                    ijcai                                                                                                 irregular decomposition parameter ranges varying                                                        lengths implementation complicated decom                                                                                             posed element sets longer compute freely              Δ   Δ      Δ  Δ    Δ            decompose parameter space better ﬁt data               figure  ranges overlap Δ                                                        multiscale decomposition parameter ranges form hier                                                        archical structure different resolutions instance    wxi    instance decomposition scheme consider decomposition ranges form pyramid    figure  intersection Δ Δ set wxi  shown figure  elements nonadjacent ranges    txi   note scheme result compared coarser resolutions    txi  wxi →∞  evaluated proper weighting scheme improve performance  itx  ∅ifitx∅thenφtx ≡   term implementation complex kernel evaluation  just ignored discussion different decomposition longer  schemes given     finally avoid favoring large inputs normalize                                                                                                            dividing product norms                                                                                                                                                                                                                                                                                                                                        κx                                                               κx z                                                                                       κx xκz                             ΔΔΔ             ΔΔ    equivalent computing cosine angle  tween feature vectors vector space model       figure  pyramidal parameter space decomposition    parameter space decomposition scheme  section decomposition scheme discussed gen  eral terms pros cons respect additional cost  mercer condition  computation changes classiﬁcation performance according mercer’s theorem kernel function corre  range overlapping similarity weighting num sponds inner product feature space  ber different decomposition schemes presented positive semideﬁnite unique optimal solution    mentioned decomposition lets avoid swamp guaranteed kernel methods kernels posi  ing bad comparisons dramatically reduces compu tive semideﬁnite proposed method pro  tational cost kernel evaluation introduces quantization duces positive semideﬁnite kernels ﬁrst note   error alleviated allowing range overlapping positive semideﬁnite haussler suchker  similarity weighting overlapping al nels called summation kernels proven positive  lowed care increasing size range overlaps semideﬁnite difﬁcult  just sum  quire additional computation likely involve summation kernels synthesize new mercer  kernel evaluations elements each inter kernel adding mercer kernels  mercer kernel  section gain decreasing quantization error pro  vide little improvement classiﬁcation performance  efﬁciency  swamped bad comparisons tradeoff  quantization error classiﬁcation performance time complexity compute parametric kernels depends    issue left time compute decomposed ele greatly particular decomposition scheme used  ment sets complicated decomposition scheme provide brief analysis regular decomposition  gets difﬁcult implementation schemes  time takes run fortunately experimen assume constant time needed evaluate κx  tation revealed classiﬁcation performance rel κτ using regular decomposition scheme  atively insensitive minor changes decomposition figure   time complexity evaluat  scheme favor simpler decomposi ing  sequences composed el  tion schemes ease implementation efﬁcient kernel ements respectively average oxzΔlwhere  evaluation expectation minimal losses maxτxx τ zz worst case  formance                                             composition Δl complexity oxzingen    present number example parameter space eral expect decomposition produce Δ    composition schemes                                  like reasonably small subset elements                                                        each range  regular decomposition  parameter ranges com storage complexity sum  mon length Δ figure   implementation simple kernel evaluations memory time complexity  shows good classiﬁcation performance general compose sequences respective element sets  limited freedom ﬁt data               ox  constant time taken each element                                                    ijcai                                                      results                                               class   svs    error   class   svs    error                                                            ’’              ’’            handwritten character object recognition experi ’’           ’’            ments implementation based matlab svm toolbox   ’’              ’’                       gunn   used handwritten character recogni  ’’              ’’            tion limited scope testing recognition ’’        ’’            isolated characters built training test sets  similar unipen data                                                               figure  handwritten number recognition    handwritten character recognition  handwritten characters represented sequences  bahlmann et al  unlike ap  coordinates pixels points screen ob proaches achieved sophisticated feature  jective learn training set function correctly extraction restrictions input structures  classiﬁes unseen handwritten character normalize  scaling inputs ﬁt × pixel bounding box align  object recognition sensor data  ing center input data points each sequence analyzed sensor data captured  second intervals  chosen elements training set composed hokuyo urglx laser range ﬁnder mounted   labeled examples created writers each side segway rmp segway rmp navigates  wrote numeric characters ’’ ’’ times test environment control attached tablet pc  data composed  labeled examples created communicating usb commands tablet pc  authors  each character figure  shows training program reads sensor data detects nearby objects  examples characters ’’ ’’ number points obstacles during navigation speciﬁc objective  each shown                          locate subregion sensor data corresponds                                                        soccer ball each frame input data represented                                                                                                                                       ◦                                                                array  regular directional samples range −                                                                                                             ◦                                              each distance nearest object                                                                                                                                                                                                                                                  millimeters ranging   maximum                                                                                     − −                error figure  snapshot     points     points      points    points                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           points     points     points    points                                                                                                                                                                                       figure  sample raw inputs handwritten numbers    raw input    segmented     detected      trained oneversusall multiclass support vector nov figure  raw sensor input shown curves  elty detectors svnds parametric kernel blobs segmentation round  shawetaylor christianini  sch¨olkopf smola blob angle ◦ distance  detected   introduction svnd parameter space soccer ball  regularly decomposed overlapping allowed shown  figure  window hop sizes set   normalizing sensor data dividing  spectively chose rbf κx κτ σ  maximum distance segmented subregions  ν whereν  lower bound ratio support called blobs blob subregion frame dis  vectors time upper bound ratio tance values θ  consecutive values  outliers snvd predicts novel test sample terms δ apart experiment used θ   novelty each test examples classiﬁed class δ  blobs normalized scaling trans  minimum novelty value result com lating min max distance values each blob  pared label result shown figure     classiﬁcation error measured percentage mis blobs sequences scalar values ball blobs resemble  classiﬁed examples test set obtained error rate semicircles distorted small sensor noise   cases                           laser range ﬁnder scans side ball    represents classiﬁcation accuracy compara case round objects  ble recognizer tapia rojas  superior human legs beacons confuse classiﬁer  lei govindaraju  keogh kasetty                                                           httpwwwhokuyoautjp    httpunipennicikunnl                            httpwwwsegwaycomproductsrmp                                                    ijcai                                                    
