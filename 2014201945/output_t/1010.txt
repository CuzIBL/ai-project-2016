                    realtime heuristic search priority queue            chris rayner katherine davison vadim bulitko kenneth anderson jieshan lu                                            university alberta                                     department computing science                                   edmonton alberta canada tg              raynerkdavisonbulitkoandersonjieshanualbertaca                        abstract                          updates neighboring state prioritizing heuris                                                        tic updates efﬁcient learning motivated obser      learning realtime search interleaves plan vations asynchronous dynamic programming barto et      ning acting allows agents learn mul al  states updated time new      tiple trials respond quickly algorithms state values depend order updates oc      require prior knowledge environment     cur judicious update ordering make individual updates      deployed preprocessing    effective second signiﬁcant update state      introduce prioritizedlrta plrta learn   affects neighbors giving priority neighbors      ing realtime search algorithm based prioritized focus computation worthwhile updates      sweeping plrta focuses learning important     rest paper organized follows ﬁrst      areas search space importance mally problem examine identify      state determined magnitude shortcomings related algorithms motivate ap      dates neighboring states empirical tests proach provide comprehensive description      pathplanning commercial game maps show     novel algorithm general properties justify      substantial learning speedup stateoftheart performance metrics conduct empirical evaluation      realtime search algorithms                      conclude considering possible extensions plrta      introduction                                          problem formulation  introduce prioritized learning realtime plrta focus  problems   deﬁned      tuple  plrta prioritizes learning achieve signiﬁcant speedups ssgh ﬁnite set states  competing realtime search algorithms           set deterministic actions cause state transitions    realtime search algorithms interleave planning acting cs cost performing action ∈ state ∈  generate actions userbounded time algorithms executing action state returns agent state  agentcentered koenig  require action said blocked blocked actions  priori knowledge map learn transition model discovered agent’s visibility radius  interacting environment improve distance agent sense environment  solutions reﬁning heuristic function multiple trials update transition model  algorithms three properties used path agent begins particular start state ∈ aims  planning games virtual reality trainers dini et reach goal state sg reaching goal state  al  robotics koenig simmons  each agent teleported start state commences  domains agents plan act potentially unknown new trial learning agent converged completes  environments identical tasks solved succes trial updating heuristic value state  sion agent opportunity improve performance action executed agent incurs cost associ  learning examples include commutetype tasks ated action general realvalued costs lower  resource collection patrolling                   bounded positive constant used assume    focus learning process learning takes state space safely explorable insomuch goal state  place online onsite critical minimize learning reachable state  time converging rapidly highquality solutions   agent deals initial uncertainty    build existing research present learning real action blocked particular state assuming  time search algorithm makes learning experience actions states unblocked belief known  efﬁcient prioritizing updates moore atkeson  freespace assumption koenig et al   states deemed important updated agent explores learn remember actions  states importance determined magnitude possible states plan accordingly                                                    ijcai                                                      related work                                         prioritizedlrtas    realtime agent situated given time single state   known current state current state changed                                                                 stateupdates  taking actions incurring execution cost agent repeat  reach goal current state ways  queuepop  agent plan sequence actions leading goal   act agent plan incompletely execute                                                                    stateupdatep  partial plan repeat reaches goal end  review search algorithms techniques             states updated queue  ∅    agent using local repair lra silver     ⇐ neighbor s’ lowest fs scs shs  plans complete path current state goal end  executes plan path optimal given agent’s  current knowledge agent discover planned  path blocked point stop replan figure  plrta agent updates current state  updated world knowledge each plan generated states taken queue  search hart et al  time needed ﬁrst input parameter deﬁned user agent takes single  replanning log num greedy repeats process reaching                                                        goal state   ber states algorithms dynamic stentz        lite koenig likhachev  efﬁciently  correct current plan reproduce                                                          koenig’s lrta koenig  updates heuristic val  reduce computation needed ﬁrst                                                        ues lss states each accelerate conver  each trial executed large ﬁrstmove delay nega                                                        gence process dijkstrastyle relaxation procedure  tively affects agent’s responsiveness interactive environ                                                        uses produces highly informed heuristics process ex  ments games highspeed robotics                                                        pensive limits size lss used real    simplest form korf’s learning realtime  time domains koenig likhachev   lrta  updates current state respect attempt reduce convergence execution cost pr  immediate neighbors refer version lrta lrts bulitko et al  builds hierarchy levels  lrtad initial heuristic nonoverestimating abstraction runs search algorithms each level                                         lrta converges optimally korf   search higher levels abstraction constrains lower  travel each trial during learning oscillate unpre level searches promising sections map reducing ex  dictably causing seemingly irrational behavior heuristic ploration lower levels result convergence travel  weighting learning separate upper bound reduces ﬁrst delay improved cost complex imple                      path length instability shimbo ishida  bulitko mentation additional computation required main            lee   result suboptimal solutions   tain abstraction hierarchy during exploration    deﬁne local search space lss states different line research considers sophisticated  neighbors generated planning   date schemes realtime dynamic programming algorithms  lrtad looks current state’s immediate barto bradtke singh note “the subset states  neighbors deeper lookahead gives agent costs backed changes stage stage  formation decide action korf  choice subsets determines precise nature  stance lrts bulitko lee  considers algorithm”  prioritized sweeping reinforce  states radius current state alternatively ment learning algorithm performs updates order pri  koenig uses lss deﬁned partial search ority moore atkeson  state high priority  current state goal                 large potential change value function    updating state value each planning states potential update greater ∈  stage result efﬁcient learning example added queue prioritized sweeping shown  physical backtracking helps state experience efﬁcient qlearning dynapi moore  updates close physical proximity agent sla atkeson  core inﬂuence algorithm  slat  shue zamani shue  et al   γtrap bulitko  lrts bulitko lee   physically return previously visited states po  novel algorithm  tentially reducing number trials needed conver prioritizedlrta plrta combines ranked updates  gence possibility increasing travel cost al prioritized sweeping lrta’s realtime search  ternatively lrtak hernandez´ meseguer sumptions deterministic environment nontrivial  uses mental backups decrease number initial heuristic section plrta’s algo  vergence trials techniques difﬁcult com rithmic details comment nature execution  bine recent study demonstrates fragile highly plrta agent planning phase acting phase  contextspeciﬁc effects combining physical mental interleaved agent reaches goal fig  backups sigmundarson bjornsson¨           ure  during planning phase agent gains knowl                                                    ijcai                                                                                                                                                             stateupdates                                      hs  current estimated cost traveling                                                        closest goal state figure     ﬁnd neighbor s lowest fs scs shs    Δ ⇐  fs s − hs                                   algorithm properties    Δ                                         section make general observations key fea          ⇐             hs   fs                                    tures make plrta different learning real      neighbors                       time search algorithms discuss plrta’s conver        addtoqueuen   Δ                              gence space time complexity      end    end                                              key features design                                                        unlike prioritized sweeping’s  parameter restricts  figure  value state set lowest available potentially small updates entering queue plrta  cs shs cs s cost traveling s speciﬁes maximum queue size guarantees strict limit  hs estimates distance s goal value memory computational time used enabling  changes neighbors enqueued                algorithm process arbitrarily small updates                                                          plrta speciﬁes current state                                                                                                          addtoqueues   Δs                                 updated plrta degenerates korf’s lrtad korf                                                         size queue     s∈ queue                                     plrta agent disallows duplicate entries queue      queuef ull                              retains contents queue acting phases        ﬁnd state ∈ queue smallest Δr            design key difference plrta real                                                                                                     Δr  Δs                                 time search algorithms lrtak hernandez´          queueremover                                meseguer koenig’s lrta  koenig                                                                      queueinserts Δs                             plrta agent’s local search space nec        end                                          essarily contiguous dependent agent’s current state                                                   property beneﬁcial change single state’s        queueinserts Δs                              heuristic value affect heuristic values      end                                            potentially remote states empirically limiting far    end                                              dates propagate unexplored regions state space                                                        does signiﬁcantly impact plrta’s performance                                                          plrta algorithm present speciﬁes pri  figure  state inserted queue room oritized learning process greedy action selection  queue priority greater previ                                                      plrta modiﬁed select actions way  ously enqueued state  state enqueued incorporates techniques algorithms  inserted second time queue                                                        creased lookahead speciﬁed radius bulitko                                                        lee  heuristic weighting shimbo ishida   edge navigate world updating dis bulitko lee  preferentially taking actions  tance heuristics select states during acting phase agent through recently updated states koenig   agent simply uses greedy actionselection choose  phases         theoretical evaluation    beginning planning phase agent updates similar korf’s lrta korf  plrta  current state considering immediate neighbors viewed special case barto et al’s trialbased real  figure  current state’s value time dynamic programming rtdp following  changes stored variable Δ each cur orems outline theoretical guarantees trial  rent state’s neighbors slated entry queue based rtdp hold plrta explain plrta’s  priority Δ queue entry lowest prior time space complexity  ity removed figure  plrta requires initial world theorem  plrta converges optimal solution  model updates spread unseen states use freespace                                                        start state ∈ goal state sg ∈ initial  assumption                                           heuristic nonoverestimating    current state’s heuristic updated series pri  oritized updates begins states spec algorithm meets criteria set convergence  iﬁed user taken queue barto et al barto et al  shown trial  dated using procedure figure  states based rtdp extension plrta converges op  queue updates remain queue timal policy undiscounted shortest path problems  used planning phase                   start state set goal states sg exists    having completed planning phase agent moves policy takes agent goal probability   acting phase agent takes single action moving theorem  plrta’s permove time complexity  neighboring state s minimumvalued fs s om · logq maximum number updates  cs shs cs s cost traveling s time step size queue                                                    ijcai                                                      primary source plrta’s permove time complex puter game use particular testbed enabled com  ity comes updates algorithm performs parison existing published data number states  speciﬁed each updates potentially each map       sults queue insertions branching factor generated  problems each map resulting total  current state each insertions requires  unique path planning problems solved each  check state queued using hash  competing parameterizations learning realtime  table high priority search algorithms table   queued ologq using ordered balanced tree      agent incurs unit costs for√ moving states  theorem  plrta’s memory requirements space  cardinal direction costs  moving diagonally  complexity os size state space algorithms experimented use octile distance bu                                                                             plrta requires memory environmental  litko lee  initial heuristic  model states queue learning model state precise execution cost  priori unknown environment necessitates keeping track curred agent obstacles  constant number connections states goal sg maps initially unknown each  duplicate states disallowed maximum agents uncertainty map handled using  number states queue exceed  aforementioned freespace assumption visibility ra                                                        dius each algorithm set  limits each agent    performance metrics                                knows world begins planning                                                            compare plrta   ﬁve  algorithms lra  realtime search algorithms used lrtad lrtsdγt prlrts lra  sponse time user experience important base level lrtsdγt ﬁrst ab  measure performance search algorithms using fol stract level lrts parameters handtuned  lowing metrics                                       low convergence execution cost size koenig’s    firstmove lag time agent make ﬁrst adeﬁned strict search space similar parameter  measure algorithm’s ﬁrstmove lag terms lrta’s queue size compare koenig’s lrta  number states touched ﬁrst trial using local search spaces size      agent converged solution                                                                line previous research realtime search enables                                           compare new results old results                                     suboptimality ﬁnal solution percentagewise          length ﬁnal path longer                                                                                               length optimal path                                                                                                       planning time unit distance traveled indicates      planning step realtime multiagent applica  tions measure upper bounded application    straints producing action each time step video                                                             game algorithm’s planning time measured terms  number states touched unit distance traveled      memory consumed number heuristic values                 stored heuristic table measure does include   memory used store observed map algorithms   run use map representation    learning heuristic search algorithms typically learn  multiple trials use convergence execution cost measure                                                                                                                          total distance physically traveled agent during                         learning process measure terms distance                          traveled agent path converges distance  measured terms cost traveling state figure  convergence execution cost semilog averaged                                                         problems plotted optimal solution length                                           lrtad large convergence execution cost    note measures platform independent lrtaqueuesizeupdates convergence execu  report planning time number states touched tion cost comparable lra  algorithm state considered touched heuristic  value accessed algorithm linear correla each algorithm’s performance tabulated compari  tion number states touched wall time son table  lra lrtad demonstrate ex  taken implementation                         tremes lra smallest convergence execution cost                                                        stores heuristic values ﬁrstmove lag    experimental results                               greatest algorithms plans way  ran search algorithms pathplanning problems ﬁve goal lrtad largest convergence execution cost  different maps taken bestselling commercial com result simplistic update procedure ﬁrst                                                    ijcai                                                                   algorithm             execution  planning     lag      heuristic memory suboptimality                   lra                  ±   ±   ±                                    lrtad             ±   ±   ±     ±                     lrtsd γ      ±   ±   ±   ±      ±           prlrtsdγ      ±   ±   ±     ±         ±            koenig’s lrtalss      ±   ±   ±   ±                    koenig’s lrtalss      ±   ±   ±   ±                    koenig’s lrtalss      ±   ±   ±   ±                    koenig’s lrtalss      ±   ±   ±   ±                plrtaqueuesize updates  ±   ±   ±   ±                plrtaqueuesize updates  ±   ±   ±    ±                plrtaqueuesize updates  ±   ±   ±    ±                plrtaqueuesize updates  ±   ±   ±    ±              table  results  problems visibility radius  results lra lrta lrts prlrts taken  bulitko et al     lag planning costs extremely low each queue size ﬁxed maximum number updates fig  parameterization plrta ﬁrstmove lag comparable ure  demonstrates plrta’s parameters provide  lrtad convergence execution cost effective ways changing algorithm meet speciﬁc  lower algorithms use sophisticated abstraction rou time andor space requirements  tines prlrts    figure  shows average convergence execution cost  future work  algorithms  problems various lengths  lrta’s convergence execution cost similar lra’s prioritized lrta simple effective algorithm invites  indicates heuristic learning plrta efﬁcient analysis experimentation randomized  expense learning heuristic function startlocations problems explore provide ad  scales similarly expense learning priori ditional insight like extend plrta  known map                                     include dynamic parameterization settings                                                        beneﬁcial use extra memory available                                                        lrta provides convenient way advantage free                                                        memory queue size dynamically adjusted                                                          plrta beneﬁt sophisticated action                                                        selection scheme purely greedy decisionmaking                                                        process present plrta’s simplicity makes easy                                                   experiment number recent realtime search tech                                                        niques improve convergence time                                                      state abstraction successfully applied realtime                                                        heuristic search bulitko et al  hybrid approach                                                    combines prioritized updates state abstraction likely                                                        produce search routine powerful ei                                                    ther method interesting direction extend                                                        plrta handle dynamic environments including fo                                                   cused exploration allowing heuristic values decrease     convergence  execution cost                                                                                conclusions                                                                                                         incremental search algorithms realtime search algo                                        queue size  rithms meet different requirements incremental search al        maximum number updates                       gorithms lra converge quickly suffer                                                        arbitrarily long delays responding realtime search  figure  impact queue size maximum number works strict permove computational limit  updates convergence execution cost                long online interactive learning process reduces applica    using set  problems used generate bility good solutions needed start  table  explore plrta’s parameter space exper plrta response time par fastest known  iment reveals queue size maximum number realtime search algorithms learning process  updates exhibit independence converges time scales mere map discov  affect performance increase maximum ery lra plrta agent learn twice fast  number updates ﬁxed queue size convergence actual map stateoftheart prlrts agent learns  execution cost decreases happens increase smaller abstract map                                                    ijcai                                                    
