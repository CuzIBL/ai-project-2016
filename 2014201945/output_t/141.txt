                adaptive contextbased algorithm term weighting                              application singleword question answering         marco ernandes giovanni angelini marco gori leonardo rigutini franco scarselli                               dipartimento di ingegneria dell’informazione                                      universita di siena siena  italy                           ernandesangelinimarcorigutinifrancodiiunisiit                        abstract                          problems debole sebastiani   best      term weighting systems crucial importance  knowledge attempt compute tfidf      information extraction information     like term weights make use relationships terms      trieval applications common approaches term   latent semantic indexing lsi deerwester et al       weighting based statistical nat statistical approach does suffer word      ural language analysis paper present independence assumption lsi tries measure principal      new algorithm capitalizes advantages associative patterns sets words concepts using      strategies adopting machine learn singular value decomposition technique taking      ing approach proposed method weights account word order unfortunately lsi em      computed parametric function called ployed practical problems case qa      text function models semantic inﬂuence  lsi projects document words nonlinguistic      exercised terms context  space qa requires answers natural language      context function learned examples      side techniques deeply inspired      allowing use statistical linguistic infor natural language theories applications voorhees      mation time novel algorithm   morphological syntax analysis naturally ex      successfully tested crossword clues rep ploit information provided word contexts      resent case singleword question answering  design difﬁcult require large human effort                                                          paper present novel algorithm term weight    introduction                                       ing aims combine advantages statistical  term weighting important task areas infor linguistic strategies adopting machine learning ap  mation retrieval ir including question answering qa proach method exploits relationships order  information extraction text categorization distance words document order  goal term weighting assign each term evaluate semantic relevance given question  collection text documents speciﬁc score sw mea intuition proposed model relevance  sures importance respect certain goal term computed recursively combination  information represented word instance passage intrinsic relevance relevance terms ap  retrieval systems weigh words document order pear context inﬂuence exercised  discover important portions text discard irrelevant word computed using parametric func  ones case applications qa snippet extrac tion called context function function trained  tion keyword extraction automatic summarization    examples suited using statistical    common approaches term weighting roughly di term frequency linguistic information morpholog  vided groups statistical linguistic techniques ical syntactical lexical requiring predesigned rules  methods group based statistical main idea underlining proposed approach tightly  analysis extracts document collection features related textrank algorithm mihalcea tarau   word frequencies informationtheoretical measures succesfully applied keyword extraction  tfidf salton mcgill  popular statistically text summarization precisely contextbased algo  inspired method currently used ir systems mea rithm extends textrank allowing general mod  sure importance words major assumption elling word relationships providing learning  approach words document consid algorithm deﬁne strength relationships  ered unordered independent elements assump contextbased algorithm evaluated spe  tion shared measures information gain ciﬁc problem singleword question answering  gain ratio bestmatch bm chisquare func goal ﬁnd single correct word answers given  tion manning schtze  literature question singleword qa particularly suited evaluate  presents interesting adaptations tfidf speciﬁc term weighting algorithm directly exploits rank                                                    ijcai                                                    produced weights proposed method ap context function set examples eval  plied improve performances particular answering uate performances issues  webcrow ernandes et al  designed ad considered following sub–sections  dress crossword clues results show approach  context functions  viable singleword qa problem suggest  extended ﬁelds text processing  document set contains multiple instances words each    section  describes contextbased term weighting al instance wordoccurrence affected different  gorithm section  presents experimental environment text distinguish words shall                                                                      used evaluate proposed method section  report represent  word occurrences represented                                                            wˆ                     experimental results obtained single hat  assume wu computed                                                                                                      word qa problem section  provides conclusions  sum contributions the occurrences                                                                  cwu                  cpˆw uˆ        contextbased term weighting                                        wˆ∈occw uˆ∈ictˆwu  proposed method exploits contexts words word  context primarily consists text surrounding given occw set instances word wandictˆw  word include features document ti set occurrences ofu belong context  tles hyperlinked documents idea wˆie ictˆw uoccu ctxtˆwwherectxtˆw  order measure relevance word respect context wˆ given set parameters  certain goal query document category features cpˆw uˆ parametric context function establishes  context term appears important strength inﬂuence instances wˆ  features word roughly speaking word word evaluation uˆ context word work  important just statistically strong function learned examples  words belong context important context word occurrence wˆ deﬁned    recursive deﬁnition recalls social net set words contained document  works seeley  status person depends surround wˆ dimensions kl  kr left mar                                                                                  “ uˆ   uˆ   uˆ wˆ uˆ  status persons related gin right margin −kl− −kl −                                                          uˆ uˆ    assume text document represented kr kr   text passage document                                                        ctxtˆwuˆ    uˆ  uˆ   uˆ   cial network importance words com      −kl     −      kr holds formula  puted basis neighbors precisely weight tion introduce strong assumption direct semantic  sw word computed                     relations words registered                                                       surrounds assumption plausible widely adopted          sw−   λdw  λ       sucwu        snippets search engines hand ap                              u∈rw                    proach easily extended cases context  dw default score rw set words cludes features document title section title  belong context cwu real number mea text anchors pointing document  suring inﬂuence exercised wandλ ∈   delicate point deﬁnition                                                                   ˆw uˆ  damping factor score word result function  establishes word couples                                                        inﬂuence basis features extracted  the combination default score dw context score                                                        words relationships words    u∈rw sucwu                                                        theoretically inﬂuence function exploit sort    real numbers dw cwu calculated using                                                        information related wˆ uˆ informationtheoretical  formation occurrences context words                                                        text categorization information gain gain ratio morpho  frequency linguistic role word distance                                                        logical partofspeech classes syntactical  words functions used com                                                        syntax role lexical wordnet dis  pute values predeﬁned learned exam                                                        tance features used  ples machine learning fashion work assume                                                        preliminary experiments exclusively statistical  dw given initial scoring tfidf                                                        tab  interestingly reduced list basic fea  learn parametric function calculating cwu                                                        tures displays notable performances  goal improve initial values                                                          merge information    dw provided external informative                                                        single output general approach consists imple  sources algorithm suited exploit weights  ˆw uˆ  produced algorithms order improve menting modeling tool universal                                                        approximation property allows realize function  formances worth notice dw cwu  computed exploiting statistical linguistic features desired degree precision tools include neu  point view method represents mechanism ral networks polynomials rationales plan  tegrate kinds information                       novelty approach respect textrank mihal    order implement proposed approach follow cea tarau  consists introduction context func  ing problems addressed deﬁne context tion learning algorithm fact textrank uses equation  function computes cwu values compute similar  deﬁne word scores inﬂuence factors cwu  term weights sw using eq automatically learn predeﬁned values computed using word cooccurrences                                                    ijcai                                                                                                                                 δep  use neural networks future introductory scope  compute gradient δp error function  paper preferred exploit simpler approach spect parameters  implementation cpˆw uˆ learning algo                                                           adapt parameters resilient method riedmiller  rithm simpliﬁcation allows evaluate proposed                                                            braun   method term weighting problem avoiding  sults altered complexity    resilient parameter adaptation technique allows    deﬁned inﬂuence function                  update parameters using signs partial deriva                         in                           tives error function experimentally proved                                                        resilient efﬁcient common gradient              cpˆw uˆ   σαixi  βi                                                             descent strategies riedmiller braun   xi  value associated ith fea    gradient approximated simple brute force al                                                                                             δep  ture αiβi   model parameters                                                            gorithm each component gradient δpi given  ααnββnandσ logistic sigmoid func                     −x                                 corresponding incremental ratio requires calcu  tion σx     notice logistic sigmoid late error function times each training epoch  monotone increasing function approaches worth mention proposed learning algorithm  →−∞ approaches   whenx   →∞ each      simpliﬁed version described gori et al  term σαixi  βi eq  sort soft switch related  procedure used efﬁciently  ith feature controlled parameters αi βi models having large number parameters fact  αi    switch “on” close  xi important guarantees implementation                                                large positive “off” close  context function cpˆw uˆ efﬁciently replaced  large negative precisely parameter αi controls complex general models neural networks  steepness direction soft switch βi implementation decided learn  controls point switch assumes medium value set parameters damping factor λ eq    finally function cpˆw uˆ described intuitively establishes level conﬁdence attributed  simple boolean operation “on” information extracted context  switches “on”                                incorporation couple improvements ex    computing learning context weights           pected firstly experiments required                                                        establish best λ avoided secondly new weights  correct deﬁnition weights                                                         guaranteed outperformed default scor  unique solution stacking variables eq                                                         ing value fact context function turns  written                 −   λd  λcs                 deleterious term ranking λ set                                                         weighting replicates ranking performances   wn set words dictionary                                                       during experiments case observed  sw  swn vector weights                  wn        wu  square matrix contain  evaluating term weighting performances                            ing word inﬂuence factors wu                    criterion evaluate term weighting depends                                   λc       easily proved provided   holds  speciﬁc task addressed application  matrix norm · eq  unique solution                                                      qalike problems proposed paper  computed iterating st −λdλcs                                                      performance depends position   limt→∞   initial  practice correct answer assumes candidate answer list  computation stopped difference positional cumulative measures used qa  scores iteration iteration speciﬁed                                                  evaluation mean reciprocal rank correct answers  small value  −   method called ja mrr standard evaluation measure qa  cobi algorithm golub loan  solution community success rate sr  linear systems worth mention technique annotate probability ﬁnding correct answer  extremely efﬁcient applied sparse matri ﬁrst candidates formally given set questions  ces containing billions variables page et al   quest  questq  questn denoted    learning procedure implemented op posaq position correct answer aq question  timization algorithm minimizes error function ep questq                                                                wehave         qn  ppn denotes set parameters                                                                                                context function cpˆw uˆ function ep measures      mrr              posaq               performance weighting given dataset                     discussed details following section              qn                                                                            Θn  − posaq   method training algorithm repeats following steps sr                                      predeﬁned number times                                                                            st −λ   t− λkckdλtcts                       Θ                           Θx     ≥      fact                        holds simple  heaviside function deﬁned         algebra power series convergence theorems λc   Θxotherwise                                     −  fulﬁlled limt→∞ − λi − λc performance measures used  solution eq  identity matrix  evaluating weighting implementing                                                    ijcai                                                    learning procedure drawback using positional mea       feature set  sures discrete functions non differ fsa idfw idfu distˆw uˆ  entiable fact values mrr sr change abruptly fsb    idfw idfu distˆw uˆ distˆu  positions words exchanged possi fsb      idfw idfu distˆw uˆ distˆu swlist  ble approach adopt learning scheme robust                                                        table  set features inserted context functions used  discrete environments simulated annealing genetic al                                                        experiments distˆw uˆ number separating words  gorithms major problem algorithms                                                        occurrence wˆ uˆ distˆu number separating  stochastic nature makes convergence slow                                                        words uˆ closest occurrences words query    order adopt differentiable error function deﬁned                                                        swlist indicates stopword list used order avoid  differentiable function soft pos replaces concept                                                        presence stopwords context window  position pos                              soft posa          σ γsw − sa     useful documents using search engine currently google                     w∈w wa                          extracts candidate answers words                                                        ranked using statistical morphological information  set words considered weighting al experiments extended webcrow addi  gorithm word position value calcu tion contextbased algorithm results show  lated γ predeﬁned parameter σ sig ranking correct answers improved  moid function monotone increasing differentiable func dataset consisted  italian crossword clues ran  tionsuchthatlimx→∞ σxand   limx→−∞  σx       domly extracted archive ernandes et al     each term contained sum eq  compares dataset divided subsets side  score word score word wifγsw nequestions  examples answers exclusively  larger γsa term assumes value close factoid named entities ≺reallife comic played   converse case γsw smaller ﬁlm dustin hoffman lennybruce side  γsa term approaches  large γ each nonnequestions  examples answers non  terms approaches heaviside function soft posa ap named entities common nouns adjectives verbs  proximates posa                                    ≺twenty hours ago yesterday    based eq   deﬁned differentiable evalu  ation function approximates mrr                  weighting techniques comparison                     qq    iw                       order assess effectiveness contextbased al                              soft                 σ γsw  − sw     gorithm compared ranking performances three        mrr                                                                             different weighting techniques ﬁrst tfidfwhich                                                     gives statistical evaluation importance word  trained using soft function evalu document techniques webcrows  ations using standard mrr sr    webcrowsm represent ranking methods adopted                                                        webcrow webcrows exploits statistical information    experimental setup                                 words documents queries weighting    singleword qa problem                       scheme modiﬁed version presented kwok                                                        et al  webcrowsm additionally uses morpholog  problem proposed approach applied ical analysis documents joined morphological  special case question answering singleword answer type classiﬁcation clues details  qa each question answered single correct webcrow ernandes et al   word given number documents related question  target answer unique correct word perfor  experimental results  mance evaluations unlike standard qa require  human refereeing best knowledge standard train set test set subsets ne nonne  dataset available task singleword qa questions randomly divided train set test  popular challenging example provided crosswords set containing   examples respectively  crossword clues intrinsically ambiguous open experiments repeated  times each conﬁgura                                                        tion each example data set contained ques  domain represent challenging reference point                        worth mentioning singleword qa used tionanswer couple ii set documents retrieved  testbed particularly suited evaluate term weight google documents selected google’s order iii                                                        vector ranked terms candidate answer list ex  ing actually answers qa directly                                     pendent ranking produced term weights      tracted documents experiments    aim experiments show context tains words length  based algorithm improves ranking quality candidate features context functions trained each  answers provided webcrow ernandes et al web different set features table  presents list  crow webbased qa designed tackle cross feature combinations adopted experiments fairly  word clues crossword cracking core  web search module given clue retrieves dataset available httpwebcrowdiiunisiit                                                    ijcai                                                                      learning curves mrr                                   success rate                                                                                                                                                                                                                                                                                                                         tf−idf         mrr                                                                           webcrow−s  context  train−set                              tf−idfcontext                          webcrow−s  context  test−set       success  rate           webcrow−s                                                                                      baseline webcrow−s  train−set                             webcrow−s  context                          baseline webcrow−s  test−set                              webcrow−sm  context                                                                                                                                                                                                               max lookdown position                          epochs   figure  learning curve context function ne figure  success rate nequestions test set   question problem softmrr fsb feature conﬁgu curves depict probability xaxis ﬁnding correct   ration webcrows outperformed  epochs  swer question ﬁrst candidate answers yaxis   epochs sensible improvement observed        clarity curve webcrowsm reported     default tw             feature set ne     nonne      fault scores provided webcrows produced    tfidf                                      crement mrr   row    tfidf  context        fsa                      insightful resume performance improvements   webcrows                                      provided success rate curve fig  shows   webcrows  context    fsb                    probability ﬁnding correct answer ﬁrst   webcrows  context    fsb                    words each weighting scheme compar   webcrowsm                                 ison appears consistently curve context   webcrowsm  context   fsb               based reweighting particular  ob                                                        served success rate tfidf  tfidfcontext  table  mrr performancethe results three baseline algo  webcrows  webcrowscontext   rithms given bold column default tw denotes algorithm webcrowsm  webcrowsmcontext   used default term weights dw feature set speciﬁes fea  ture set context function columns contain exp  answering nonnequestions nonne  mrr values obtained subsets testset questions represent difﬁcult task context func  “context” indicates context weighting algorithm used tions trained tested higher number doc                                                        uments  improvement tab  rank  compare contextbased weighting tech ing quality provided contextbased algorithm  niques features restricted effectively used evident ne subset clear phe  each algorithm comparison example reweight nomenon depends different nature questions  tfidf scores adopted feature set called fsa tab  make improbable strong increment mrr using  ﬁrst row exploits information question exclusively statistical features revealed poor perfor  work morphological information integrated mance tfidf measure ﬁrst row reweighting  context functions able improve term scores provided webcrowsm lead   webcrowsm’s performances adopts morpho  increment mrr   row    logical analysis simplicity chose  ﬁx dimen                                                                                                         sion context window kl kr    exp  varying number web documents                                                           interesting feature evaluate ability context  initialization stop policy parameters function work number documents differs  text functions initialized small random weights used learning phase reason tested  exception λ initialized  each ranking quality context functions trained  training session stopped  epochs stop policy ne subset dw given webcrowsm rows  suggested prior observation variation curves table  varying contextbased algorithm proved  learning set test set fig  robust changes constantly outperforming  resilient learning scheme guaranteed fast convergence webcrowsm fig   addition  quiring  epochs reach good local minima context increased mrr     exp  answering  nequestions nequestions  example  example help better illustrate  problem context functions trained tested using promising results webcrowsm answered question  number documents used extracting ≺la paura nella folla panico  ≺fear crowd  word candidates results presented table  panic correct answer th position  shows performances terms mrr ranking addition contextbased weighting panic jumped   formances compared methods given bold row nd position related words appeared ﬁrst   tfidf  webcrows  webcrowsm           candidates collective multitude emergency    contextbased algorithm outperformed compared irrational passage extracted docu  weighting methods particular reweighting ments explain context information result ef                                                    ijcai                                                    
