                        dynamics temporal difference learning                                             andreas wendemuth                        ottovonguerickeuniversity  magdeburg germany                                         cognitive systems group                             andreaswendemuthetechnikunimagdeburgde      abstract                                              smart  adopt following notation course                                                        paper following dayan abbott   behavioural sciences problem sequence stim                                                          •  uli followed sequence rewards rt considered stimulus ut  subject learn sequence rewards • future reward rt  stimuli prediction modelled suttonbarto • sum future rewards rt  rule sequence trials prediction rule learned •  eratively temporal difference learning present closed weights wk  formula prediction rewards trial time trial • predicted reward vt  formula show directly →∞the want compute trials duration andfor  predictions converge real rewards approach time trial predicted reward vnt ex  new quality correlation type toeplitz matrices proven tended stimulus ut given times tumin tumax  learning rates optimally speed learning extended reward rt presented times trmin trmax  process                                              stimulus reward overlap trmin tumax                                                          subject learn total remaining reward time                                                                t−t    temporal difference learning                       rt       rt  τ stimulus onset  consider mathematical treatment problem     τ                                                          brackets  refer general stochastic values  behavioural biology problem described                                                        rt exactly rewards given each trial  dayan abbott  learning predict reward                                                        ﬂuctuations  pavlovian sense classical conditioning adressed                                                          previous stimuli ut weighted linear pre  reward immediate series stimuli                                                        diction model sutton barto   latency time followed series rewards                                                                              t  ing simple linear rule show subject able                                                                                        −                 predict remaining rewards rule repeating         vt     wτut  τ                                                                              τ  stimulireward pattern series trials review  learning theory related problems update rule suttonbartoformula easily                                                        rived mean square error dayan abbott   sutton barto                                                                                                                                                       t−t         t                  recent experimental biological correlates            mathematical model activity primate rt − vt      rt  τ −   wτut−τ  dopamine cells during appetitive conditioning tasks            τ          τ  psychological pharmacological rationale                                                studying cells review given schultz  using partial derivative respect weight wα                                                                             connection temporal difference learning ∂rt − vt  montague et al                                                                   ∂wα    paper focus mathematical issues                                                                                                   −t           provide direct constructive proof convergence giving                                                                                   −              −            −        −  explicit dependence prediction error trials   rt  τ     wτut  τ  ut  α  minimize learning time giving formula optimal         τ          τ  setting learning rate paper contributes updates discrete steps direction neg  temporal difference learning purely mathematical ative gradient providing following rule  issue valuable reference Δwτεδtut   − τ                                                                                                          havioural biology reinforcement learning          t−t  understood dynamic programming sense watkins    δt         rt  τ  − vtrt−vt   later work gordon  szepesvari          τ                                                    ijcai                                                                obviously total future reward rt known written matrix notation follows              subject time use rtrtrt inthis unit matrix              formulation rt known subject      ⎛              ⎞                                                                                tumax              approximate value prediction vt    ⎜              ⎟                                                                           ⎜    tumax  ⎟              provide socalled                                        ⎜                 ⎟                temporal difference rule time                        ⎜                 ⎟   − εga  ×                                                                           ⎝                 ⎠                                     −      ∀                     Δ   τεδt      τ    τ                                                                   −                                trmax                        δtrtvt         vt                     ⎛                ⎞       ⎛           ⎞                                                                                                                     updates sequentially each time step     tumax                                                                             ⎜              ⎟       ⎜          ⎟              parallel sampling weight updates times ⎜  tumax  ⎟       ⎜          ⎟                                                                             ⎜               ⎟       ⎜           ⎟              given trial updating end trial × ⎜            ⎟   εg ⎜  rtrmin ⎟                                                                             ⎝               ⎠       ⎜           ⎟              alternatives substantially differ ﬁnal result                       ⎝          ⎠                                                                                                                     trials computational reasons use parallel       trmax              version update rule learning schedules                                rtrmax              adopted use eq  widely accepted shall use total time  trmax−tumax              community following dayan abbott let              denote trial number superscripts                      tumax−y                                                                          gy         uk uy   ∀                  dynamics temporal difference learning                        ktumin                parallel temporal difference rule eq  obtained real values uk utumax  andt ×               using approximation gradient descent matrices              vergence guaranteed shall proven course                                                                                 ⎛            ···           ⎞              paper compact notation introduced                    gk                                                                                 ⎜                          ⎟              proceed follows                                             ⎜                 ···     ⎟                                                                                 ⎜               gk ⎟                • incorporate rule prediction formula yielding     ⎜                      ⎟                                                                            ⎜                      ⎟                   recursive formula predictions trial      ⎜                      ⎟                                                                                 ⎝ gk     ···       ⎠                • make closed formula vnt                                                                                                        •                    →                                                 gk ···                       show convergence  rt large                      ⎛                      ⎞                                                                                       −                • choose optimal learning rate ε maximally fast                                                                                                  ⎜         −            ⎟                  convergence                                                   ⎜                    ⎟                                                                             ⎜                    ⎟              obtain predictions trial fol       ⎜                  ⎟                                                                                            ⎝                      ⎠              lowing recursive formula summation limits explicitely state                         −              situations stimuli reward phases overlap                                          restrict nonoverlapping cases later                                 minttumax               ””ing  refers remaining upper                 − t≥tumin        Δw   − kuk                     ε                                ε             lower triangle respectively entries                                       ktumin                     diagonals  write compact                 minttumax mintrmax−tktumax                                                                  notation vectors component index                          uk                   δ  − kux                                                                                                                 ktumin          xtumin                                      −  εga    εgr                 mintrmax−ttumax−tumin                                                                             δ  gt                                yt   −mintt                         umin     umax                                                 n                                                                          vn         −  ga   gr              δntrtvnt  −  vnt                                ε       ε                                                                                                                  minminttumaxtumax−y                                 −                                                                                             εεga   − − εga       gr                 gt                      ukuy                                                                                                                                   −        −                                      kmaxtumintumin−y                                 −    − εga                        interested subject make proper −ga hurwitz stability matrix eigenval              predictions stimuli given restrict ues negative real suitable ε chosen              analysis times ttumaxthengt                                                                                  − εga       vanish large similar              independent tgiving                                                                    approach relying hurwitz matrices followed                               mintumaxtumax−y                sutton  hurwitz property               gygt                     ukuy     shown immediately matrix structure eq                                 kmaxtumintumin−y                aim provide explicit proof establish                                                                ijcai                                                                interesting result right general property xtgx written  toeplitz matrices correlation entries               n k            n  k k−j                                                                                                                                 −       ut xi             ut ut  xi xij    show hurwitz property later          values ε convergence assured                                         optimal continuing large nbehaviour obtain       n→∞                                              rearranging inner sums  vn  −→   a−  holds matter stimulus                                                                          k k−j  k k−t               ⎛                  ⎞                                                                                                                     ⎜                  ⎟                                                      ⎜     ⎟               −   ⎜               ⎟                 ⎜             ⎟                using vectors dimension components                    ⎝                 ⎠                                                      ut  ut leads                                                                     n  k            n                                                                                         ˜  obtain                                                  gx  −        ut xi                                 −t                                                                                              ∞                   rt  τrt                                  ˜                      τ                               matrices × band matrices                                                                   ˜  desired result proves convergence entries xmmn  xixin ≥  generality need show −ga hurwitz ma symmetrizing matrix products write                                                                                                      trix eigenvalues matrix negative real n       n               n                                                                                      want values ε provide   x˜        x˜          x˜     maximum speed convergence                                                                                                                                                                 proof convergence                               matrix elements second term −k ≤ ≤                                                                       previous approaches literature temporal difference n             n           n                                                                ˜  td learning extended tdλ learning pa                 xjxj−n      xixin    rameter λ refers exponential weighting recency      mmn              learning convergence issues considered  dayan  dayan sejnowski inthetdλ summation limits result taken  framework consider tdlearning convenience larger necessary covering cases  contrast mentioned literature concentrate di summand nonzero note nonposi  rect proof convergence establishing general property tive extra terms zero zero padding  toeplitz matrices correlation entries        vention xi result matrix elements    proof proceeds follows show ﬁrst ﬁrst second term eq  identical format  positive deﬁnite show eigenvalues nonnegative nonpositive respectively  ga positive real estab making use eq  eq  incorporating                                                        ﬁrst sum eq  leads  lished hurwitz property required convergence                                      order positive deﬁnite consider                    n                                                                                   nonzero real vector show gx positive         gx        xˆ               ﬁrst extract diagonal matrix gd upper                       triangular matrix gthenwehave                                                        matrices xˆ band matrices entries      xtgx       xtg     xtg     xtgtx              ˆ                                                 xmmn    xixin positive negative                                                       gdx     gx                   write sum matrices eq  dif                                                                                                                              ferent way denote vectors x˜ dimension                 gdx    gx                                                                                         components x˜m  xim                 n            n    k                                                       understood xj jn                    xi     xi   gj xij   vectors nonzero components  −kn                                              notice following covariance matrices generated  order summation limits easy understood vectors                                                                               xi in”zero padding”                                                                                    x˜ x˜         xim xin          toeplitz bands number stimuli shifting                 mn  time index eq  tumin  gj arises  stimuli uk  utrealas                    kn  −mk−                                                                                       k−j                                             n                    nm                                                                  x˜i x˜i     gj      ut ut   ∀                                  xi xin−m                                                             i−k           mn  i−km                                                    ijcai                                                                                                        let eigenvector ga λ corre                                                                               ga                 n                        nm                   sponding eigenvalue    real λ ei                                              ther real complex complex case           x˜ x˜                    xi xin                              ∗                                                        exists eigenvector corresponding eigenvalue       i−k                     i−km                      mmn                           λ∗where∗ denotes complex conjugated transposed                                                                        ay  establishes                                  let denote      write                                                                   z∗gz    y∗a∗gay       y∗a∗y                                                                                  λ                                                                                                              ∗                    x˜i x˜i  xˆ               real symmetric                                                                ∗       ∗    ∗    ∗ ∗               i−k                                              gz  gz    λ ay                                                                  summation eqns   gives  rewrite eq  using eq                         ∗       ∗  ∗        ∗                                                                     gz   λ   λa                                                                                                real symmetric positive deﬁnite     xtgx         utx˜i x˜i   utx˜i                      ∗                                                complex gz real positive used             i−k                 i−k                  follows                                                          case  λ real  sum certainly nonnegative show                 zero                                   real  eq  immediately                                                                           ∗                                                                              rez gzλy                  proof contradiction suppose sum zero                                                                                                                         individual terms zero start ﬁrst signreλ  signλsigny       term deﬁnition                                                          case  λ complex                       k                               let write  viw λ  ih eq              utx˜−k                                                                    ujx−kj  ukx           real  obtain                                                                                     ∗                                                                       rez gzg                                                                                                                                                                                                              zero uk  eq             −     −                                                                                              proceed second term                                    ∗                                                                      imz      gzh                                                                                                                                  k                                                                             −k                                                                −    x˜           ujx−kj  uk−x  ukx  ukx                                                    combining eqns  and  gives                                                                                                                                                         gg                  previous result used                                                                zero uk eq   continuing follows with signre λ  signg                                                                                              vein steps end product     signreλ  sign                                  k                                                                                          −kn         x˜           ujx−knj                      results cases eqns   allow                                                    following sufﬁcient condition                                                        let  real symmetric positive deﬁnite matrix          uxn−k   uk−xn−   ukxn   ukxn                                                                                                        real square matrix matrix   previous results used xn  positive deﬁnite real parts eigenvalues  total means   contradiction ga positive  nonzero vector    result established xtgx    let turn attention speciﬁc matrix given  established                            eq  have⎛                     ⎞    symmetric toeplitz matrices structure                   −                                                                       ⎜  −         −            ⎟  eq  correlation entries gj eq  positive    ⎜                      ⎟  deﬁnite                                                           ⎜                      ⎟                                                                 ⎜                   ⎟                                                                       ⎝                         ⎠                                                                                         −      −    turn attention showing eigenvalues                           −  ga  positive real look real                                real symmetric positive deﬁnite  require stronger condition structure shown matrix   positive def  eq  say entries gj inite using previous result paper matrices    premises proof ﬁrst sufﬁcient structure positive deﬁnite noting  condition sign real eigenvalues structure using eq  im  ga show sign positive mediately gives desired result completes proof  hand                                    −ga  hurwitz matrix                                                    ijcai                                                    learningrateε       fast convergence             curves mεk ensuring condition chosen  convergence behaviour temporal difference rule satisﬁes maxk mεk                                                          ε allmεk     decreasing εthe  known eq  large number trials convergence                                         ∗                                          −  ga       slope given −gk   start choosing  speed dominated eigenvalue  ε            ∗                                                         argmink   gk ensures condition  largest modulus convergence speed                                     ∗  slowest eigenvalues ev            maxk  mεk satisﬁed choice  current                                                        position εc  apply following procedure   eve − εga−     ε evga−     ε  ih      start                                                                           ∗  notation eigenvalues gaas continuing curve  reach minimum                                                                           ∗       gk∗  previous section λ   ih used                                 εk∗                           ﬁrst task compute eigenvalues                 gk∗  hk∗  ga      dependent given stimuli uk current position εc pro                           ga                                         ∗  total time  note deﬁnes special struc posed position εk∗ maximum condition maxk mεk  ture unsymmetric toeplitz matrix bands satisﬁed k∗ order check compute inter  known closed solution eigenvalues sections curve inspection k∗ curves  toeplitz matrices exists three bands  given symmetric asymmetric cases eq  intersections given values εk  beam warming      according  closed solution given sec                                                                                               − εk gk  εk hk − εk gk∗   εk hk∗   numerical values obtained special methods  solution asymptotic structure eigenvalues                                                                                 gk − gk∗  large aregiveninbeam warming                                                                                          ε      −       −                square modulus eigenvalues given                     gk   gk∗  hk  hk∗                                                      inspect intersection closest    mε   eve − εga   −   εg   ε                                                            current position εcieforwhichkˆ argmink εk  ﬁrst choice ε convergence εk εc                                                                  ∗        ∗  assured serves good rough value εkˆ εk∗ thenεk∗ eq  solution  setting ε computational effort      free minimum stop                                                                                                   ∗    note ﬁrst mε eigenvalues fur     intersection prior reaching εk∗ ifthe  ther − ga hurwitz eigenvalues curve intersecting rising εkˆ means  small ε mε    eigenvalues actually reached condition  eq  lastly large ε mε increase eq  solution  bounds eigenvalues mε ∝ ε large ε                                                                                                                               gk − gk∗  eigenvalues                                    ˆ                                                        εkmink    εk     −       −    εk εc    sketch general behaviour mεitis                   gk  gk∗  hk   hk∗  clear each eigenvalue εk                                          mεk   mεk rising εk computing bounded minimum stop                                                                                                     ˆ  values eq  eigenvalues λk  gk  ihk curve intersecting falling εkwe  gives                                                 continue new curve satisﬁes max                              gk                       imum condition eq  end set εc  εkˆ                    εk                          ∗   ˆ                           gk  hk                        continue change falling curves maximum                                                        modulus start  mε    εmink εk good choice  ε˜ convergent behaviour mean value fig  illustrates behaviour free minimum ﬁg   bounds                                               bounded minimum ﬁgures change falling                              gk                        curves maximum modulus                   ε˜ mink                         algorithm terminates ﬁnitely steps                            gk  hk                                                        minimum curve k∗ intersection  note hk   additional              −                                         falling rising curve clear  eigenvalue gk  ihk minimum eq  possibilities exist curves eventually rise large ε  identical needs computed                                       ∗    turn ﬁnding optimal value ε fastest  stimulus  vergence given               ∗                                        look special case stimulus              ε  argminε  maxk mεk             present  eq  takes particularly                                                                          −  optimization problem closed solution simple form   unit shift matrix                                                                             simple line search algorithm given ﬁnd solu       t                                                                                                               n−j             tion ﬁnitely steps              av     −           − εu     εu  −      general idea start ε increase ε             til reach ε∗ process select                                                                                            ijcai                                                    
