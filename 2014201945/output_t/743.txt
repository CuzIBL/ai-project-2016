                        language learning multiagent systems                martin allen                 claudia goldman                 shlomo zilberstein     science department        caesarea rothschild institute    science department      university massachusetts            university haifa          university massachusetts       amherst ma  usa        mount carmel haifa  israel     amherst ma  usa         mwallencsumassedu                clagcrihaifaacil            shlomocsumassedu                        abstract                          sharing information agents utilize different                                                        sets messages fully understand      present problem learning communi    messagepassing agents need      cate decentralized stochastic environments learn respond messages passed      analyzing formally decisiontheoretic context them—in sense learning messages mean      illustrating concept experimentally ap                                                        deﬁnition  translation let Σ Σ sets mes      proach allows agents converge coordinated                                             communication action time               sages translation τ Σ Σ probabil                                                        ity function messagepairs messages σ σ                                                        τσ σ probability σ σ mean                                                                                                         introduction                                       ing τΣΣ set translations Σ Σ   learning communicate multiagent systems emerg agents need consider multiple possible translations  ing challenge ai research autonomous systems developed messages agents possess beliefs  separately interact contexts like dis translation correct given present situation  tributed computing information gathering internet                                                        deﬁnition  beliefstate let agents α  α use sets  widespread networks machines using distinct proto                                                                                           messages Σ Σ  beliefstate αi probability  cols result foresee need autonomous systems                                                                            function βi translationset τ  translation  learn communicate order                       ΣiΣj                                                        τ ∈ τ    β τ probability τ correct  achieve cooperative goals make ﬁrst steps ΣiΣj   solving attendant problems                         updating beliefs translations important    coordination agents acting environ overall process learning communicate  ment sharing resources studied extensively agents act based local observations messages received  particularly multiagent systems community current beliefs translate messages  coordination involve communication typically actions lead new observations causing  deliberation value communication date beliefs translations procedure governing  resulting systems communication ones allow updates comprises agent’s languagemodel function  ing free communication wellunderstood messages actions messages observations distributions  contrast study decentralized systems require agents translations models highly complex difﬁcult  adapt communication language new situations compute especially languages complicated  arise miscoordination occurs                environment partially observable                                                        centrate special—but interesting—cases gen    decentralized learning framework               erating probabilities straightforward  study problem context decentralized markov  decision processes bernstein et al  communi  formal properties problem  cation decmdpcom process multiagent ex main formal results isolate conditions dec  tension common mdp each agent αi observes mdpcoms reduce simpler problems present proto  local portion statespace attempt col learning communicate reduced problems  communicate using set messages Σi  decentralization makes decmdps communication reduction mmdps  signiﬁcantly harder solve regular mdps boutilier  deﬁnes multiagent mdps mmdps  complexity properties goldman zilberstein  sisting set agents operating fully commonly    agents share language optimal lin observed environment transitions states envi  guistic action matter deciding com ronment arise joint actions agents common  municate given cost relative projected beneﬁt reward shared                reward earned                  claim  given inﬁnite timehorizon agents acting ac                    language learned                cording elementary action protocol suitable dec                                                      mdpcom eventually converge joint policy                                                        optimal states encounter                                                                     empirical results conclusions       pct  learning progress                          explore viability approach implemented                                                      languagelearning protocol reasonably complex                                                        suitable decmdpcom involving agents joint                                       trol set pumps ﬂowvalves factory setting                     time−steps learning process                                                          results show elementary protocol converging                                                        optimal policies wide range probleminstances fig     figure  reward accumulated language learned ure  gives example probleminstance featuring                                                         vocabularyitems each agent showing percentage  calculate optimal joint policy process ofﬂine total accumulated reward total shared vocabulary each  thing implementing unless agents timestep process learning acting  coordinate actions guarantee jointly seen learning process dotted line proceeds quite  optimal policy communication allowed steadily rewardaccumulation hand grows  reliable boutilier deﬁnes coordination problems time ﬁnally stabilizing initially language learn  arise agents each individual action ing outpaces reward gain given knowledge agents  potentially optimal combine suboptimal fash ﬁnd other’s actions observations hard  ion show certain putatively complex dec termine time goes rate accumulated reward nar  mdpcoms fact reduce mmdps prob rows gap considerably agents know  lems arise notable decmdps generally need communicate spend time accumu  intractable mmdps solved efﬁciently    lating reward familiar circumstances necessarily                                                        learning new language  deﬁnition  fullydescribable decmdpcom fully experimental results conform intuition show  describable each agent αi possesses language ing small language learning does little  Σi sufﬁcient communicate observation help agents choosing actions capable  makes action takes                nearly optimal action presence  deﬁnition  freelydescribable decmdpcom    standing perfect opens door  freelydescribable agent αi mes study approximation contexts  sage σ ∈ Σi cost communicating message  continue investigate compare approaches  claim  decmdpcom equivalent mmdp problem including analysis differences possi  coordination problems fully freely ble optimal ofﬂine techniques online learning methods  describable agents share common language                                                        acknowledgments  suitability convergence                                                        work supported national science  freely fullydescribable decmdpcom agents foundation grant iis air force  calculate optimal joint policy working ﬁce scientiﬁc research grant  sumption agents share common language  relevant information shared agents references  fact learn communicate implementation  policies requires cooperation environment bernstein et al  bernstein givan immer  agents update translations appropriately time man zilberstein complexity decentralized  deﬁnition suitable decmdpcom   control markov decision processes mathematics op  cluded simply note problems prob erations research –   ability each agent assigns actual prior observations boutilier  boutilier sequential optimality  actions following statetransition strictly ordination multiagent systems procs ijcai  greater observations actions considered pages – stockholm sweden   likely transition unless entries goldman zilberstein  goldman zil  actually correct suitable decmdpcoms provide  berstein decentralized control cooperative systems  information ensure others’ actual actions observa categorization complexity analysis journal ar  tions likely mistaken ones                tiﬁcial intelligence research –     extend work goldman et al  agents                                                                           communicate states actions elementary goldman et al  goldman allen zil  action protocol using protocol action belief berstein decentralized language learning through acting  update agents optimality based ob procs aamas pages – new york city  served consequences action suitable problemdomain ny 
