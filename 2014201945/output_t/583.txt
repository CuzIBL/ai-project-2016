                       shallow semantics coreference resolution                                                  vincent ng                              human language technology research institute                                        university texas dallas                                           richardson tx                                            vincehltutdallasedu                        abstract                          president george bush background informa                                                        tion provided explicitly associated document      paper focuses linguistic aspect noun goal paper improve performance      phrase coreference investigating knowledge   learningbased coreference introducing features      sources potentially improve learning  encode semantic knowledge knowledge      based coreference resolution unlike       potentially useful identifying nonanaphoric nps      traditional knowledgelean coreference resolvers nps antecedent need      rely exclusively morphosyntactic resolved evaluate utility new linguistic      cues show induce features encode  features augment baseline feature set comprises      semantic knowledge labeled unlabeled     knowledge sources commonly employed existing corefer      corpora experiments ace data sets indicate ence engines new features evaluation      addition new semantic features ace datasets coreference using augmented      coreference employing fairly standard  feature set yields statistically signiﬁcant improvement      feature set signiﬁcantly improves performance  fmeasure baseline                                                          contribution work lies use corpus    introduction                                       based methods inducing features coreference resolu  recent years seen intensifying noun phrase tion attempts inducing                                                                                           np coreference — problem determining nps gender ge et al   path coreference bergsma lin                                                                                                refer realworld entity document owing   np anaphoricity bean riloff   selec                                                                                                           automatic content extraction ace evaluations tional preferences dagan itai  yang et al   initiated nist surge structured coreference resolution existing coreference  prediction machine learning community result resolvers rely heuristic methods feature computation  various new models approaches np coreference  developed instance coreference recast  new features coreference resolution  problem ﬁnding best path root leaf section new linguistic features  bell tree luo et al  tackled relational learningbased coreference resolution  learning task mccallum wellner andasa  supervised clustering task li roth     inducing semantic agreement feature    equally important development new coreference feature commonly employed coreference resolvers  models investigation new linguistic features determining nps coreferent semantic  problem recently research anaphora class sc agreement feature value true  coreference resolution largely adopted knowledge scs nps match false accuracy  lean approach resolvers operate relying sc agreement feature depends  set morphosyntactic cues knowledgelean sc values nps computed correctly  approaches reasonably successful mitkov et named entity ne sc typically determined using  al  kehler et al  speculate deeper linguis ne recognizer hand determining sc  tic knowledge needs available resolution sys common noun proves difﬁcult  tems order reach level performance fact words polysemous nontrivial determine  surprising certain coreference relations sense corresponds intended meaning noun  identiﬁed using stringmatching facilities determine sc common noun existing  syntactic knowledge instance semantic knowl coreference systems use wordnet soon et al   edge needed determine coreference relation simply assigning noun ﬁrst frequent  lexically dissimilar common nouns talks nego wordnet sense sc easy measure ac  tiations world knowledge required resolve curacy heuristic fact sc agreement                                                    ijcai                                                      person organization time day money percent      person        human    measure abstraction psychological feature phe     organization  corporation agency government    nomenon state group object unknown                facility      manmade structure building                                                          gsp           geopolitical region country city  table  list possible semantic class values com location geographical area landmass body  mon noun returned ﬁrstsense heuristic method                 water geological formation    feature used soon et al’s decision tree corefer      table  ace semantic classes  ence classiﬁer suggest sc values nps  computed accurately “ﬁrstsense” heuristic organization social group    motivated related work semantic lexicon construc facility    establishment construction building facil  tion hearst  phillips riloff         ity workplace  velop following method learning sc com gsp          country province government town city  mon noun goal improving accuracy              administration society island community  sc agreement feature given large unannotated corpus location    dry land region landmass body water                                                                        geographical area geological formation  use  inhouse ne recognizer achieves  measure  muc test set label each ne table  list keywords used wordnet search deter                                        semantic class  lin’s minipar mining ace semantic class common noun  pendency parser extract appositive relations ex  ample extraction eastern airlines carrier  ﬁrst entry proper noun labeled deﬁned able improve performance  seven mucstyle ne types sec ace data develop semantic class agreement  ond entry common noun proper noun labeled feature ace guidelines mind speciﬁcally  infer sc common noun ace coreference task concerned resolving references  proper noun minipar nps belonging ﬁve ace semantic classes  ne recognizer perfect use robust method ascs person organization facility gsp  inferring sc common noun  compute geographicalsocialpolitical region location  probability common noun cooccurs each table  brief description ascs particular ref  ne types based extracted appositive relations erences nps belonging scs marked   likely ne type cooccurrence prob desire ace sem class feature  ability certain threshold set threshold  siders nps semantically compatible  label common noun likely ne type nps common asc rest subsection    examination induced sc values indicates scribes determine asc np  method ﬁxes errors commonly ﬁrst allow np possess asc cases  sense heuristic instance common nouns carrier method determining asc np based  manufacturer typically used refer organizations sc value computed sem class fea  news articles labeled person heuristic ture particular method hinges observation    method potential weakness com  sem class’s organization class roughly corre  mon nouns belong seven ne seman sponds ascs facility organizationand  tic classes remain unlabeled address problem sem class’s location class roughly corresponds  set sc unlabeled common noun value ascs gsp location given observation  turned ﬁrstsense heuristic implementation determine asc np follows  ﬁrstsense heuristic determine  scs • sem class value person organization  listed table  common noun belongs based ﬁrst location asc  wordnet sense expect method • sem class person asc person  able label common nouns ace                                                          • sem class location deter  primarily interested nouns referring person orga                                                            asc location gsp according  nization location subsection observation speciﬁcally ﬁrst use word    inducing acespeciﬁc semantic feature             net determine head noun np                                                            hypernym gsp keywords listed table   sem class feature described previous subsection repeat wordnet lookup procedure using  developed use generalpurpose coreference sys                                                            location  keywords lookups successful  tem way ace coreference task                                                            asc np gsp locationother    used  bllip corpus words consists wise asc classes  wall street journal articles    reuters • sem class organization  corpus gb data  reuters articles                                                            determine asc organization fa    person organization location date time money percent    indicates proper noun muc ne       keywords obtained experimentation word    simplicity viewed ne type net ascs nps training data                                                    ijcai                                                        cility similarly use procedure outlined extract coreferent np pairs speciﬁcally design pattern      previous bullet determine asc learner induces each cs given annotated corpus      ganization facility                    three extraction patterns each represents different                                                        degree generalization cs work    inducing semantic similarity feature           consider segments antecedent anaphor  reference resolvers use wordnet compute se fewer three sentences apart  mantic similarity common nouns poesio table  shows three patterns learner induce  et al  daum´e marcu  example cs ﬁrst pattern row  cre  approach determining semantic similarity ro ated  representing antecedent anaphor  bust success depends large extent ability set attribute values indicating gender number semantic                                                                                         determine correct wordnet sense given nouns class grammatical role np type   representing each    motivated research lexical semantics instead remaining nps cs token np  repre  adopt distributional approach computing semantic senting each nonverbal nonadverbial token  similarity common nouns capture se enclosed np partofspeech tag  repre  mantics noun counting frequent cooccurs senting each verbal token reason retaining  words determining pair common nouns se verbal tokens motivated intuition verbs  mantically similar cooccurrence patterns similar play important role identifying coreferent    instead acquiring semantic similarity information np pairs hand adverbs represented  scratch use semantic similarity values provided cause generally contain useful information far  lin’s dependencybased thesaurus identifying coreferent np pairs concerned  structed using distributional approach combined second pattern shown row  table  created  informationtheoretic deﬁnition similarity each word procedure ﬁrst pattern each  thesaurus associated list words simi verbal token replaced partofspeech tag  lar semantic similarity values pattern row  table  created proce    given thesaurus construct semantic similarity dure preceding patterns nps  feature sem sim coreference resolution use retained three patterns represent three different  binary value denote nps npx npyare levels generalizations cs ﬁrst  semantically similar speciﬁcally feature value speciﬁc general  true npx nearest neighbors note induced patterns extract  npy according thesaurus vice versa         coreferent noncoreferent np pairs having low                                                        extraction accuracy reason pattern learner    inducing patternbased feature                 does capture evidence outside cs segment                                                        cases crucial inducing highprecision rules  induce pattern based feature using informa need estimate accuracy each pattern  tion provided algorithm learns patterns extract coreference decide dis  ing coreferent np pairs each involves pronoun card np pairs extracted patterns low accuracy  antecedent bean riloff  learn extraction  patterns coreference resolution unlike method estimating pattern accuracy acquire list  method unsupervised domainspeciﬁc      extraction patterns redundant patterns removed    showing compute pattern based fea estimate accuracy each pattern anno  ture let pattern learner operates fol tated corpus simply counting number coreferent np  lows  patterns acquired corpus annotated pairs extracts divided total number np pairs ex  coreference information  accuracy each learned tracts described collect cs’s  pattern estimated elaborate steps noncoreference segments ncs’s annotated                                                        corpus used induce patterns ncs  acquiring patterns recall pattern used ex deﬁned text segment beginning np npxand  tract coreferent np pairs good pattern cap ends pronoun npy npx coreferent  ture features nps involved context npy consider cs’s ncs’s  occur illustrate induce pattern let enclosing nps separated fewer three sen  consider following coreference segment cs tences each csncs use pattern learner  deﬁne text segment starts np npxand induce three patterns way time  ends pronoun corefers npx “john study additionally label each pattern ’’ induced  ing hard exam he” cs induce ncs ’’ insert  pattern simply comprises tokens segment labeled patterns list redundant patterns  sequence tokens test text apply tained finally compute accuracy pattern ∈  pattern determine john likely corefer number times appears label ’’ divided    pattern useful total number times appears  unlikely exactly text segment  unseen text desire pattern learner possible np types pronoun proper nounand  generalize cs retain sufﬁcient information common noun                                                    ijcai                                                             genderm numbersing semclassperson gramrolesubj nptypepn  studying np   gen            derm numbersing semclassperson gramrolesubj nptypepro            genderm numbersing semclassperson gramrolesubj nptypepn  vbz vbg np   gen            derm numbersing semclassperson gramrolesubj nptypepro            genderm numbersing semclassperson gramrolesubj nptypepn  np  genderm num            bersing semclassperson gramrolesubj nptypepro             table  three patterns induced coreference segment “john studying hard exam he”      using list extraction patterns sorted decreasing feature useful coreference resolution empiri  order accuracy create pattern based feature cal question evaluate utility section   follows given pair nps march pattern  list check patterns extract nps  baseline feature set  feature value accuracy ﬁrst pattern  extracts nps feature value  previous section introduced new features corefer                                                        ence resolution mentioned introduction fea    inducing anaphoricity feature                 tures used combination set baseline fea                                                        tures section describes baseline feature set  anaphoricity determination refers problem deter                                                        comprises  selected features employed highperforming  mining np antecedent knowledge                                                        coreference systems soon et al ngand  anaphoricity potentially used identify ﬁlter                                                        cardie  ponzetto strube   nonanaphoric nps prior coreference resolution  improving precision coreference lexical features use features allow different                                                        types string matching operations performed  attempts identifying nonanaphoric phrases                            pleonastic lappin leass  non given pair nps npx npy  including  exact string  anaphoric deﬁnite descriptions bean riloff  match pronouns proper nouns nonpronominal nps                                                        determiners removed  substring    unlike previous work goal build                                                        match proper nouns nonpronominal nps   ﬂedged identifying ﬁltering nonanaphoric                                                        head noun match addition nationality matching feature  nps want examine shallow anaphoric                                                        used match instance british britainfurther  ity information encoded feature beneﬁt                                                        feature tests words  learningbased coreference speciﬁcally employ                                                        appear np appear np  simple method inducing anaphoricity information given  corpus labeled coreference information compute grammatical features  features test grammatical                                                        properties nps include fea  anaphoricity value np npx probability                                                        tures test each nps pronoun def  npx antecedent corpus npx occurs  annotated corpus assign default anaphoric inite np indeﬁnite np nested np clausal subject  ity value  unlike previous work represent similar set ﬁve features used test nps  anaphoricity real value binary value pronouns deﬁnite nps nested nps proper nouns    encode anaphoricity information feature clausal subjects addition ﬁve features determine  learningbased coreference follows given nps compatible respect gender number                                                        animacy grammatical role furthermore features  coreference instance involving npx npy create fea                                                        test nps apposition participate  ture value simply npy’s anaphoricity value    conceivably data sparseness render anaphoric predicate nominal construction isa relation fi                                                        nally motivated soon et al  feature  ity feature useful desire glimpse  anaphoricity values computed feature shows determines npy demonstrative np  capture potentially useful information semantic features semantic features  stance feature encodes moderate proba employed soon et al’s coreference  bility anaphoric np contrary taken ﬁrst feature tests nps  phrase contrary anaphoric        semantic class semantic class proper noun                                                        common noun computed using ne ﬁnder wordnet    inducing coreferentiality feature              choosing ﬁrst sense respectively second feature  adapt method generating anaphoric tests np alias acronym  ity feature create coreferentiality feature positional features positional feature  encodes probability nps coreferent measures distance nps sentences  coreferentiality probabilities estimated  corpus annotated coreference information cases  evaluation  given nps appear cor section evaluate effectiveness newly pro  pus set coreferentiality value np pair  posed features improving baseline coreference    method inducing coreferentiality feature                                                             suffer data sparseness assume npx precedes npy associated text                                                    ijcai                                                      experimental setup                               addition replace heuristicbased sc agreement fea  use ace version  coreference corpus eval ture baseline feature set sem class feature  uation purposes corpus composed three data sets section  employ methods training  taken three different news sources broadcast news instance creation antecedent selection baseline  br newspaper pa newswire wi each data set  recall pattern based anaphoricityand  comprises set training texts acquiring coreference coreferentiality features computed using data  classiﬁers set test sets evaluating output set annotated coreference information need  coreference report performance terms reserve portion training texts purpose  recall precision fmeasure using different scoring computing features speciﬁcally partition avail  programs commonlyused muc scorer vilain et al able training texts sets roughly size   recentlydeveloped ceaf scorer luo  training subset development subset development  according luo ceaf designed address potential subset used computing features require  problem muc scorer partitions nps annotated corpus training subset used  overclustered tend underpenalized ex train coreference classiﬁer using expanded feature set  periments conducted paper use nps automatically results using expanded feature set shown row   extracted inhouse np chunker ne recognizer tables comparison baseline results row                                                         fmeasure increases   muc    baseline coreference                    ceaf gains mod  baseline uses decision tree learning al erate performance difference measured scor  gorithm quinlan  conjunction  baseline ers fact highly statistically signiﬁcant  features described section  acquire coreference clas muc ceaf  siﬁer training texts determining nps  coreferent create training instances pair each np  feature analysis  training text each preceding nps labeling  instance positive nps coreference better understand features important coref  chain associated text negative  erence resolution examine decision tree learned    training decision tree classiﬁer used select ing expanded feature set shown space  antecedent each np test text following soon et limitations tree lexical fea  al  select antecedent each np npjthe tures test exact string match proper nouns                                                        nonpronominal nps surprising  closest preceding np classiﬁed coreferent npj                                                        string matching features generally strong indicators  np exists antecedent selected npj     row  table  table  shows results coreference looking tree  baseline obtained muc scorer ceaf sem class anaphoricityandcoreferentiality  fea  scorer respectively each row tables corresponds tures appearing fourth levels tree  experiment evaluated different test sets en indicates three features play signiﬁcant role  tire ace test set comprising br pa wi test determining nps coreferent  texts each br pa wi test sets investigate contribution each new  sets results obtained applying corefer features overall performance remove each new feature  ence classiﬁer trained entire ace training cor time expanded feature set retrain  pus comprising training texts pa wi br coreference classiﬁer using remaining features results  owing space limitations mainly discuss results shown rows – tables   asterisk  obtained entire test set baseline  used indicate corresponding fmeasure  achieves fmeasure  muc  ceaf  signiﬁcantly different row     better sense strong baseline results results make observations removing  repeat experiment replace anaphoricity coreferentiality ace sem class   features  features employed soon et precipitates signiﬁcant drop fmeasure whichever scor  al’s  coreference resolver results soon et al ing program used interestingly faced  shown row  tables indicates data sparseness computing anaphoricity  baseline features yield signiﬁcantly better results soon et coreferentiality features turn useful  al’s fmeasure increases  muc  ceaf second removing sem class does result                                                        signiﬁcant drop performance does imply    coreference using expanded feature set       sem  class useful fact mentioned  train coreference resolver using baseline fea ginning subsection sem class appears near  ture set augmented ﬁve new features described tree inspection relevant decision tree reveals                                                                               ace sem class     sem class  sections – ace semclass sem sim pat learner substitutes                                                                 feature absent explains  tern based  anaphoricityandcoreferentiality                                                        large drop fmeasure    like muc organizers use noreen’s  approximate claim sem class important presence  randomization method signiﬁcance testing set  ace sem class feature correlated                                                    ijcai                                                    
