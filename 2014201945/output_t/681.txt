interactive    clustering text collections according userspeciﬁed criterion       ron bekkerman              hema raghavan                james allan                koji eguchi       university              university              university            national institute       massachusetts              massachusetts              massachusetts              informatics    amherst ma usa            amherst ma usa            amherst ma usa               tokyo japan    ronbcsumassedu         hemacsumassedu           allancsumassedu          eguchiniiacjp                        abstract                          numerous nontopical criteria considered—                                                        clustering sentiment turney  style genre au      document clustering traditionally tackled thor’s mood criteria esoteric      perspective grouping documents applicationspeciﬁc clustering author’s age      ically similar criteria  age documents credibility expressiveness      clustering documents considered exam readability unlikely simple bow representa      ple documents’ genre author’s mood    tion sufﬁcient purposes meaning      propose interactive scheme clustering doc require speciﬁc document representations intu      ument collections based criterion  itively representations based primarily      user’s preference user holds active posi syntax likely semantic nature      tion clustering process ﬁrst chooses                                                          study proposes uniﬁed framework clustering      types features suitable underlying                                                        document collections according nearly criterion      task leading taskspeciﬁc document represen                                                        users choice restrict hard clustering—ie      tation provide examples features—                                                        partitioning—of document collection user ﬁrst      examples emerging cluster                                                        asked choose types features suitable clustering      ing author’s sentiment words like ‘perfect’                                                        desired criterion example genres represented      ‘mediocre’ ‘awful’ intuitively good features                                                        sequences partofspeech pos tags particular fo      algorithm proceeds iteratively user                                                        cus punctuation stopwords general words      ﬁx errors clustering end                                                        captured standard bow representation user      each iteration interactive clustering                                                        asked provide examples features seed fea      method demonstrates excellent results clustering                                                        tures chosen types examples intuitive      sentiment substantially outperforming svm                                                        obtained effort—eg clustering      trained large labeled data                                                        authors mood words like ‘angry’ ‘happy’ ‘upset’      features provided                                                        easily suggested      tuitively obvious user—eg      good features clustering genre using   clustering represents documents based      ofspeech trigrams—our multimodal clustering    users choice applies multimodal clustering method      method performs signiﬁcantly better kmeans  bekkerman sahami  seed features pro      latent dirichlet allocation lda            vided iteratively clusters documents represented                                                        chosen features enriches feature sets                                                        useful features user choose intervene    introduction                                       each iteration order ﬁx possible mistakes  problem data clustering generally underspeciﬁed feature level document label  unless criteria clustering explicitly provided ex ing required  ample given set objects various colors shapes illustrate effectiveness approach  unclear clustering performed according mains clustering genre clustering author’s senti  objects color shape absence labeled ment genre type domain providing examples  instances clustering criterion expressed terms features nontrivial intuitive noun  data representation shapes objects phrases effective verbs sentiment classiﬁca  known doubt clustering criterion tion words like ‘brilliant’ easily    talk clustering text documents usually recognizable useful using bow features  assume clustering topic typically work interactive topical clustering  approach using bagofwords bow representation user corrects clustering errors document ba  ignores word order willett  rea sis basu et al  effort time consuming  son text documents clustered way feedback features raghavan et al otherre                                                    ijcai                                                     cent work user select important keywords su ily constructed nontrivial come good  pervised categorization leveraging user’s prior feature examples clustering genre—see section   knowledge dayanik et al  raghavan et al — user skip step   approaches like framework ragha  default clustering feature types chosen  van et al  support direction ﬁnding seed features provided user documents rep  users identify useful features reasonable accu resented distributions each entire  racy compared oracle liu et al  experiment feature sets corresponding type multimodal  labeling words instead documents text classiﬁca distributional clustering bekkerman sahami   tion providing user list candidate words applied  select potentially good seed words based  interactive clustering cases user  training set constructed set unlabeled documents provided seed features feature types  classiﬁer constructed given training set liu et propose new model multimodal clustering com  al’s document representation standard bow bines regular clustering nonseeded variables  strong topical ﬂavor used clus cremental bootstrapping procedure seeded variables  tering criterion example preliminary exper  represent documents distributions sets  iments show bow appropriate clustering seed features ignore documents zero probability  author’s mood addition liu et al’s method involves given seed features cluster remaining docu  user initial step selecting seed words limiting ments using distributional clustering method  user’s control classiﬁcation process    summary propose new interactive learning frame  stop documents clustered sec  work clustering userdetermined criteria section  tion  details  multimodal clustering method based combinatorial  represent features clustered documents dis  mrfs section  neatly incorporates multiple feature types tributions document clusters ignore features  user prior knowledge clustering presented zero probability given clustered documents  combinatorial optimization problem demonstrate  cluster remaining features using distributional  effectiveness testing genre clustering clustering method  section  multiclass clustering author’s sentiment  select feature clusters contain original seed  seed features provided section  knowl words let user revise selected clusters noisy  edge study ﬁrst clustering opposed features deleted misplaced features relo  classiﬁcation genre discussed ﬁrst cated new features added revised clusters  form multiclass clustering documents sentiment features new sets seed features   show interactive clustering outperforms stateofthe  art methods svm lda realworld data collections  combinatorial mrfs clustering                                                        combinatorial markov random ﬁeld comraf bekkerman    interactive  clustering scenario                   sahami  new framework multimodal learn  provide stepbystep recipe clustering documents ing general multimodal clustering particular  particular criterion user mind     multimodal hard clustering problem simultaneously     specify number clusters learning natural constructing partitionings data modalities  number clusters remains open problem documents words authors titles clustering  attempt solve paper instead user asked modalities simultaneously overcome statisti  specify desired number clusters               cal sparseness data representation leading dense     specify feature types list various feature types smoothed joint distribution modalities result  provided user examples types bag hypothetically accurate clusterings ones  words word ngrams pos tags pos tag ngrams obtained each modality clustered separately bekker  punctuation parse subtrees types syntactic man et al  empirically justify hypothesis  semantic patterns extracted text list comraf model multimodal clustering undi                                                                                                       ≤  hypothetically include large variety feature types rected graphical model each data modality                                                         ≤   respond everyone’s needs list user corresponds discrete random variable rv  asked choose types best serve particu rv deﬁned possible clusterings xiwhich  lar clustering criterion                             implies support rv exponentially large                                                                                                        examples features each feature type size rv combinatorial rv let                                                                                            chosen user attempt construct small sets rv empirical distribution docu  seed features correspond each category documents ments dataset let x˜ij rv deﬁned clusters                                                                                     task easy clustering criterion jth clustering xiletx˜i combinatorial rv  authors’ sentiments words ‘excellent’ ‘bril ﬁned possible clusterings xi edges eii  liant’ correspond category positive docu comraf graph correspond interactions modali  ments ‘terrible’ ‘awful’ correspond ties graph necessarily fully connected examples  negative category sets eas comraf graphs shown figure                                                     ijcai                                                                                                                                                objective construct clusterings modalities                              words ﬁnd values combinatorial rv’s                                                                                              sum pairwise mutual information cluster                                   ings interacting modalities maximized                                                                                                  c∗            x˜                 x˜ij x˜ij                 argmaxc                                             x˜j                          eii ∈e                       figure  comraf graphs way document clustering                                                        pos unigrams observed rv shaded node                                              objective function naturally factorizes sothat way clustering documents pos bigrams  efﬁcient inference algorithm iterative conditional pos grams grams way clustering bow  mode—icm   besag  directly applied way clustering pos bigrams bow  icm algorithm iterates each node gwhichis opti  mized respect current values neighbors    comraf case optimization each node categories dataset section  decide                                        xc  resourceconsuming process each clustering ˜ij rep feature types best match task clustering                             resented point   jni  idimensional genre documents labeled genres basis  hypercube hi possible clusterings ni external criteria intended audience purpose  number elements ith modality meaning ele activity type lee  notion genre  ment  belongs cluster cjelement belongs cluster scribed terms syntaxsemantics duality text doc  cj apply simplest combinatorial optimization uments different genres use different syntactic construc  algorithm—hill climbing procedure starts tions andor different vocabulary obvious  point hi greedily searches nearby point sat syntactic semantic features play major role clustering  isﬁes equation  problem nonconvex random documents genre propose advantage  restarts areusedtoovercomelocal optima               represent documents sets features words    paper propose interactive learning approach correspond documents’ vocabularies partofspeech  user assists clustering algorithm avoid lo pos ngrams correspond syntactic structure  cal optima selecting seed features user speciﬁes text pos ngrams extracted sentences incre  potentially good starting point hypercube hi sec mental manner ﬁrst ngram starts pos tag  ond correcting constructed clustering each itera ﬁrst word sentence second starts tag  tion user causes controlled jump region hi second word  potentially better clusterings located intuitively come particular features                                                        best capture documents’ genres hard say    evaluation methodology                             word ‘clouds’ used ﬁction po  paper use clustering accuracy quality mea etry weather reports contrary document distrib  sure document clustering let set ground truth utions entire set features different                                                        documents different genres appro  categories each cluster d˜letγt d˜ maximal num                  d˜                                    priate representation documents clustering genre  berofelementsof   belong category apply multimodal clustering method described          prec d˜   d˜               precision         respect isdeﬁnedas    section  interactive learning component  precd˜ γt d˜d˜ microaveraged precision given document collection let random variable                                             ˜                                          γt                                           d˜c  prec  d˜ct     d˜             documents random variable words  entire clustering             d˜                                          d˜            random variable pos ngrams  portion documents appearing dominant cate words apply multimodal comraf model section   gories experiments ﬁx number clus constructing clustering d˜ documents clustering w˜  ters equal number categories case words andor clustering s˜ pos ngrams maximiz  precd˜  equals clustering accuracy              ing objective equation  paper consider    experiment clustering sentiment com comraf models clustering genre  pare comraf clustering results svm classiﬁcation  pos unigrams number pos tags  sults bekkerman sahami  show clustering tagging relatively small makes sense clus  accuracy directly compared standard classi ter pos unigrams apply way model  ﬁcation accuracy constructed clustering wellbalanced clustering documents using comraf graph shown fig  meaning each category prevails exactly cluster ure objective function equation   appears clusterings obtained using comraf simple case form id˜  model wellbalanced                                 pos ngrams    number unique                                                        pos  ngrams order higher  exponential nso    clustering genre                                clustering necessary perform way  according scenario proposed section  let set clustering comraf graph figure  experiment clustering documents genre af objective id˜ s˜  ter ﬁxing number clusters equal number  bagofwords number unique words                                                    ijcai                                                      doc representation kmeans   lda        comraf             comraf accuracy pos ngrams comraf accuracy bow                              ±   ±                                 bagofwords                                                                                            ±   ±    pos bigrams                                                                                                        ±                                                                                      accuracy   bow  pos bigr     na       na                       accuracy                                                                                                                                                                                                 table  clustering genre clustering accuracy          ngram size           threshold low frequent words  bnc corpus averaged independent runs standard  error mean shown ± sign comraf results figure  clustering genre comraf clustering accuracy  pos tuples bigrams figure left function left size pos ngram grams grams  bowpos hybrid setup applicable comrafs grams grams right threshold low frequency                                                        words—a point axis means experiment                                                        words appear documents removed  dataset comparable number pos trigrams  analogy previous model perform way clus  tering comraf graph figure objective  d˜ w˜                                               fective unigrams effective trigrams                                                    fourgrams efﬁcient     bowpos hybrid    combine contextual infor  mation bow stylistic information pos ngrams  way clustering model simultaneously   clustering sentiment  cluster documents words bigrams pos tags clustering authors’ sentiment data categories corre  comraf graph figure maximize sum  spond different levels authors’ attitude dis  id˜ s˜id˜ w˜                                  cussed topic likeddisliked satisﬁedunsatisﬁed                                                        categories ﬁner grained strongly liked     dataset                                          liked etc—as long possible distinguish                                                        tween adjacent categories  evaluate models british national corpus   following procedure described section                       bnc  burnard   employ david lee’s ontology choosing number clusters particular feature types                         bnc genres lee   genres covering user asked select seed features each cate  pects modern literature ﬁction prose biography gory clustering sentiment close tasks  technical report news script perform fair eval clustering authors’ mood familiarity topic  uation using clustering accuracy section  choose  relevant feature types words word ngrams  largest categories each uniformly random semantic features quite similar tasks  choose  documents resulting dataset consists  clustering authors’ age semantics  documents bnc texts represented sgml  syntax matter children instance use certain words  remove markup lowercase text delete stopwords adults children tend use primi  low frequency words words bnc corpus tive erroneous syntactic constructions “me  semimanually tagged using  pos tags going byebye” paper simplicity experi  fer punctuation resulting dataset  unique ment word features  words  pos bigrams overall number task selecting seed words issues  unique pos trigrams fourgrams prohibitively large easier come words correspond extreme  apply aggressive term ﬁltering consider trigrams sentimental categories ‘spectacular’ ‘horrible’ dif  appear  documents  trigrams overall ﬁcult choose seed words intermediate mild categories  fourgrams appear   documents section  users usually suc   fourgrams                                  ceed accomplishing task second early exper                                                        iments users consistently tended choose words    results                                          vocabulary given dataset inspired liu et  compare results clustering model al  decided provide users word list  sults kmeans weka implementation latent narrow search dataset vocabulary unlike liu  dirichlet allocation lda—a popular generative model et al  task topical clustering auto  unsupervised learning use xuerui wang’s lda imple matically predict words relevant instead  mentation mccallum et al  performs gibbs sam employ zipf’s law provide user list words  pling  sampling iterations table  summarizes interior frequency spectrum anticipate  results appear surprisingly good unsuper list contain relevant seed words  vised method given result random assignment perform iterative process clustering al  documents  clusters  accuracy lows user’s involvement clustering iterations  shown way comraf model signiﬁcantly outperforms apply way comraf model figure ﬁrst clus  way models figure  shows results stability tests ter documents contain selected seed words  way comraf models left pos ngram setup right cluster words documents step  bow setup shown left ﬁgure pos bigrams seed word groups enriched new words  setup preferable pos tuples ef clustered original seed words user                                                    ijcai                                                     asked edit new seed word groups order cor doc repres kmeans lda   comraf      svm  rect possible mistakes word removal bow            ±   ±    ±   relocation addition allowed clustering iter sentim list   ±   ±   ±   ation completed iteration executed interactive clustering oracle  ±  na                                                                                               ±     seed word groups enlarged ex simulated classiﬁcation oracle  pect set documents contain seed words  larger clustering process cover table  clustering sentiment clustering accuracy                                                        vs classiﬁcation accuracy standard error mean  documents iteration iteration           ±  process stops documents added pool shown sign  documents covered ones  tain seed words largest seed word groups idea interactive clustering provided brief  considered clustered incorrectly alternative ap scription dataset given list  words  proach guarantee algorithm’s convergence appeared  ≤ documents dataset  require enlargement seed word groups users proceeded described section   document added clustering each iteration struct oracle follows each category select   algorithm stop entire dataset covered frequent words belong given list sentimental  choose approach want words distribution categories peak  additional constraints user com unlike human users oracle does provide feedback  raf clustering model each realworld dataset clustering iterations extent oracle’s  documents sentimental ﬂavor hard identify – performance considered upper bound results  beneﬁcial force documents obtained practice human user involved  sentimental clusters                               perform  simulated classiﬁcation sc experiment                                                        analogous liu et al  description    experimental setup                               section  seed words provided oracle  evaluate interactive clustering dataset replace adhoc knnlike clustering liu et al’s im  movie reviews dataset consists  reviews writ plementation effective comraf clustering naive  “harry potter goblet ” bayes classiﬁer svm                     imdbcom                downloaded             data     results  preprocessed exactly bnc corpus ignore  reviews rating scores assigned user table  summarizes observations surprisingly  imdb’s scoring  worst  bow features comraf clustering method performs  best based extensive experience imdbcom svm trained large data row   translate scores categories follows good performance unsupervised method bow  scores   translated category strongly disliked indicates constructed topical clustering sheds   documents scores   translated somewhat light reviewers’ sentiments occur  disliked  documents scores   somewhat liked viewers consensus certain aspects movie   documents score  translated category liked actors disliked plot  strongly liked  documents introduce neu feature selection according list sentimental  tral category neutral reviews words comraf achieves signiﬁcant boost accuracy  imdbcom                                             surpassing svm row  using oracle interac    task clustering sentiment compare tive clustering setup row  improves performance  method’s performance svm classiﬁer trained sc result row  slightly sig   movie reviews training data svm niﬁcantly inferior results close  sisted reviews  popular hollywood movies released training set sc identical clustering constructed   genre harry potter reviews ﬁrst iteration comraf algorithm size appears  genre labels movies obtained imdbcomagain  entire dataset room  ignore reviews userassigned rating       actual diversity performance methods    evaluated ﬁve users familiar figure  left shows accuracy microaveraged  task document clustering users explained classes each user each iteration three                                                        ﬁve users selection initial seed words sufﬁcient                                                        obtain signiﬁcantly higher accuracy best result    bo pang pang lee  maintains popular dataset  movie reviews unfortunately does fully correspond svm user  signiﬁcantly lower accuracy base  task want differentiate problem clustering line begin correction steps able  sentiment topical clustering—for reason dataset provide necessary feedback obtain improve  contains reviews written movie topic ment accuracy equalling baseline user  reviews potentially movie ratings bo pang’s  fairly conservative assessment terms  dataset extracted reviews’ text errorprone  procedure dataset ratings assigned list  sentimental words obtained described  reviewers using html form leaves room errors eguchi lavrenko                                                     ijcai                                                     
