                learning classiﬁers training data iid                       murat dundar balaji krishnapuram jinbo bi bharat rao                 aided diagnosis  therapy group siemens medical solutions                             valley stream parkway malvern pa usa    muratdundar balajikrishnapuram jinbobi bharatraosiemenscom                          abstract                          appreciate beneﬁts modeling corre                                                        lations ease accomplished      methods classiﬁer design assume algorithmically motivation consider aided di      training samples drawn independently iden agnosis cad applications goal detect struc      tically unknown data generating distribu tures physicians medical images iden      tion assumption violated tify potentially malignant tumors ct scans xray images      real life problems relaxing iid assumption universal paradigm cad algorithms      consider algorithms statistics litera problem addressed  stage identiﬁcation      ture realistic situation batches potentially unhealthy candidate regions roi      subgroups training samples inter medical image computation descriptive features      nal correlations samples dif  each candidate classiﬁcation each candidate      ferent batches considered uncorre   normal diseased based features candi      lated propose simpler efﬁcient   date roi point underlying anatomical structure      variants scale large datasets theoretical slightly different spatial locations      results literature provided support paradigm correlations clearly exist      validity experimental results reallife features labels candidates refer      aided diagnosis cad problems indi     underlying structure image patient imaging doc      cate relaxing iid assumption leads sta tornurse hospital clearly candidate roi acquired      tistically signiﬁcant improvements accuracy set patient images assumed iid      learned classiﬁer surprisingly simpler multiple levels hierarchical correlations commonly ob      algorithm proposed experimentally served real world datasets figure       accurate original version                                                          relationship previous work    introduction                                       largely ignored machine learning data mining lit  classiﬁerlearning algorithms assume training erature statistics epidemiology communities  data independently identically distributed ex veloped rich literature account effect correlated  ample support vector machine svm backpropagation samples known relevant mod                                                                                                           neural networks common algorithms im els purposes random effects model rem                                                                                                             plicitly make assumption derivation nev generalized linear mixed effects models glmm    ertheless assumption commonly violated real models mainly studied point  life problems subgroups samples exhibit high view explanatory data analysis effect  gree correlation features labels smoking risk lung cancer point    paper experimentally demonstrate ac view predictive modeling accurate classiﬁcation  counting correlations realworld training data leads seen test samples algorithms tend com  statistically signiﬁcant improvements accuracy pro putationally impractical large scale datasets com  pose simpler algorithms computationally faster monly encountered commercial data mining applications  previous statistical methods provide links theoreti paper propose simple modiﬁcation existing al  cal analysis establish validity algorithm gorithms computationally cheap experiments                                                        indicate approach effective glmms terms    motivating example cad                          improving classiﬁcation accuracy  overlooked dominance algorithms  learn iid data sample correlations ubiqui  intuition impact sample correlations  tous real world machine learning community fre simpliﬁed thought experiment consider estimation  quently ignores noniid nature data simply odds heads biased coin based set ob                                                    ijcai                                                                             figure  mixed effects model showing random ﬁxed effects    servations observation independent ﬂip dates spatially close image  coin corresponds iid assumption data didates refer underlying physiological region  based assumption easily build estimators lung nodule types  binomial data work ﬁne long obser structures nonwall attached nodules associated  vations reported statistician really true candidates fundamen  lying coin ﬂips provided underlying data generating tal properties biases candidate generation cg al  mechanism truly binomial dis gorithm occurrence frequency  statistical prop  tribution generates “outliers” binomial model erties underlying structural causes disease    suppose experimenter performing ex systematically altered naively treated data  periment reports statistician cer produced iid data sources result systematic  tain coin ﬂips experimenter reports result coin bias introduced statistical classiﬁer estimation al  ﬂip observation occurred times gorithm learns diagnose diseases bias remains  observed “heads” occasions observations large amounts training data  reports occurrences exactly simple bi does violation iid assumptions matter  nomial estimator designed using iid assumption clearly correlations samples weak  appropriate hand occurrence effectively ignore treating data iid   iid sample repeated number times correlations weak  essentially immune effect exam care outlier immunity each subtype sub  ple simplistic bear mind logistic population occurs similar identical frequency  regression gaussian processes classiﬁers es able ignore effects  sentially rely binomial distribution derive  likelihood maximize training step      random  mixed effects models    implications classiﬁer learning implicit consider problem shown figure  given                                                                                                      sumption machine learning community training dataset  xijk yijkwherexijk ∈  iid assumptions violated algorithms feature vector ith candidate jth patient                                                         th  work practice case hospital yijk ∈−  class labels let    ﬁrst intuition outliers mislabeled sam assume loss generality indexing variable  ples systematically bias estimation clas follow  jj pkk  siﬁer during training provided truly iid drawn generalized linear models glm  logistic  fairly symmetric distribution outliers introduce probit regression uses nonlinear link function—eg  larger variance estimation process logistic sigmoid function σr  exp−r—to ex  largely overcome simply increasing sample sizes press posterior probability class membership  training set hand outliers samples        α   σ αx     α     systematically correlated introduce systemic bias     ijk   ijk        ijk          estimation process effect remains mathematically expresses conditional inde  large training data                 pendence classiﬁcation samples ignores    explaining second intuition let ﬁrst consider correlations samples patient  practical situation occurring cad problems hospital limitation overcome  way candidate generation cg algorithms identify generalized linear mixed effects model glmm  postu  ing roi designed diseased structures wall lating existence pair random variables explain  tached nodules lung identiﬁed candi patient speciﬁc effect δjk hospital speciﬁc effect                                                    ijcai                                                     δk during training estimates ﬁxed effect deﬁne convenient notation use  parameters classiﬁer α distribution bold font distinguish rest paper let  random effects pδkδjkd class prediction denote vector combining α α random effect                                                        variables    yijk xijkα                                                                                                                                         α αδδδk δδpk          σ αx     α    δ    δ  δ δ   dδ dδ              ijk      jk  jk  jk     let deﬁne augmented vector combining fea                                                        ture vector unit scalar  vector  zeros—    bayesian terms classiﬁcation new test sample length corresponds number random effect  previously trained glm involves marginalization variables—as x   observe  posterior classiﬁer’s ﬁxed effect parameters requires hard classiﬁcation svm literature                                                       sign• function used link finally note                             ep   σα  αpα αddαdα     classiﬁcation decision  expressed                                                        ep   signwxpwddw  extension ﬁnd classiﬁcation decision test sam lemma  sample hard classiﬁcation decision                                                                           w        w x  ple glmm quite straightforward              point classiﬁer pc  sign      identical                                                        bayesian voting classiﬁcation                                                                                                    ep yijk xijk                                                                  xq                wx  dw                                                               bvc   sign     sign                       σα xijk  α  δk  δjkpα αδkδjkd                                                        qwqww  symmetric distribution respect                                  dαdαdδkdδjk                                                          w  qww qw w wherew ≡  w −  notice classiﬁcation predictions sets samples symmetric reﬂection w                                             patient   hospital proof domain integral w  longer independent during testing phase wants domain integral w w − wwesee                                                                            classify samples new patient new hospital wx  w w three cases considered  seen during training appropriate random effects             wx       −     w x     wx  available use glm approach rely case  sign   sign                                                                     w x                                w  marginalized version posterior distributions learnt  total contribution  glmm                                             integral                                                                                                                                                       signw xqww signw xqw w                                      σ  α  α α αδkδjkd                                                                                                                                                  case  signwxsignw  xsincewxw                                                                                                                         dαdαdδkdδjk         w follows signw xsignwx                                                                 w x  note explanation useful explain  sign                                     δ      δ                                                             equation integral  jk            wx ww        w x w w  marginalizing random effects sign sign    sign                                                                                                                 order obtain pα αd relying  clearly                               signw  training glmm amounts estimation posterior                                                                                                   distribution pα αδkδjkd                     case    w    w                                                                                                                                                         wx  w w    avoiding bayesian integrals                                                                                                                                           wx ww        w x w w  exact posterior determined analytic  sign sign       sign                                                                                                                 form calculation integral classifying ev                            signw  ery test sample prove computationally difﬁcult prac  tice use markov chain monte carlo mcmc meth  unless w case classiﬁer undeﬁned  ods tend slow data mining applica case   occur times proved   tions use approximate strategies computing assumptions  limitations approach lemma  bayesian posteriors laplace approximation vari suggests simply use point classiﬁers avoid  ational methods expectation propagation ep bayesian integration linear hyperplane classiﬁers  using following lemma adapted differ true objective obtain  ent context  posterior approximated sym classiﬁcation used link function obtain  metric distributioneg gaussian interested softclassiﬁcation lemma extended  strict classiﬁcation decision posterior purposes exactly approximate result  class membership probability remarkable result holds secondly lemma holds symmetric posterior  glmm   classiﬁcation involving bayesian integration distributions pα αδkδjkd practice  replaced point classiﬁer                 approximate bayesian methods use gaussian                                                    ijcai                                                     approximation case huge limitation fi class scattering second term penalizes  nally symmetric distribution approxi models α aprioriunlikely                                                                                              mated point classiﬁer mean estimation setting lξcξξ  lαcαα  assuming  mean required computing laplace ap zero mean gaussian density model unit variance  proximation posterior simply chooses approxi pξcξ pαcξ using augmented feature vectors  mate mean mode posterior distribution obtain following optimization problem fisher’s dis  mode obtained simply maximizing posterior criminant augmented feature vectors fdafv  during maximum posteriori map estimation com                      −                                                                            min     c¯ξ ξ  ¯cξ− ξ  ¯cα α ¯cδ δ  putationally expedient  works reasonably practice α αξδγ                                                                                                                                                       st       ξijk  yijk  α xijk  δ x˜ijk  α    proposed algorithm                                                       eξc c∈±    augmenting feature vectors afv                 ﬁrst set constraints runs   previous section showed bayesian inte  pk each  jk each pair                                                          gration required suitably chosen point classiﬁer ξ vector ξijk corresponding class δ  achieve identical classiﬁcation decision sec vector model parameters auxiliary features  tion make practical recommendations ob  tain equivalent point classiﬁers little effort  parameter estimation  using existing algorithms original way depending sensitivity candidate generation    propose following strategy building linear clas mechanism representative training dataset  siﬁers way uses known postulated correla order thousand candidates  tions samples training samples positive making training data large unbalanced  construct augmented feature vectors additional features classes account unbalanced nature  corresponding indicator functions patient  hos data used different tuning parameters c¯ξ  c¯ξ−  pital identity words original feature vector positive negative classes estimate c¯α c¯δ  asamplex append vector composed zero ﬁrst coarsely tune each parameter independently  locations location patientid termine range values parameter each  corresponding location hospitalid augment parameter consider discrete set three values use  feature vector auxiliary features x¯ x x˜ fold cross validation training set performance    use augmented feature vector train classi measure ﬁnd optimum set parameters  ﬁer using standard training algorithm fisher’s  discriminant svms classiﬁer classify samples  experimental studies  based features based id experiments section compare three tech  hospital patient viewed differently classiﬁer niques naive fisher’s discriminant fd fdafv  augmented feature space attempts explain glmm implemented using approximate expectation propa  original features predict class membership gation inference compare fdafv glmm  simultaneously assigns patient hospital speciﬁc fd algorithms yield statistically signiﬁcant im  “randomeffect” explanation decorrelate training data provements accuracy classiﬁer study    during test phase new patientshospitals ran computationally expensive fdafv compa  dom effects simply ignored implicitly rable glmm terms classiﬁer sensitivity  used lemma previous section paper cad problems important num  implement proposed approach fisher’s discriminant ber false positives volume reasonable level    fisher’s discriminant                            each candidate marked positive classiﬁer                                                        visually inspected physician projects  section adopt convex programming formulation described focus attention region  fisher’s discriminantfd presented         receiver operating characteristics roc curve fewer                                                         false positives volume roughly corresponds           min   lξcξlαcα          α αξ                                                        speciﬁcity datasets           st   ξi  yi    α xi  α                               eξc  c∈±                        experiment  colon cancer                                                        problem description colorectal cancer  lz ≡−log   pz negative log likelihood common cancer men women estimated  associated probability density constraint                                                        nearly  cases colon rectal cancer  ξi  yi  α xi  α ∀i    total diagnosed  people  number labeled samples pulls output each sample die colon cancer  wide consensus  class label constraints eξc c∈± screening patients effective decreasing advanced disease  ensure average output each class label  eligible population undergoes colorectal  loss generality class scattering ﬁxed cancer screening factors key  ﬁrst term objective function minimizes patient comfort bowel preparation cost                                                    ijcai                                                       noninvasive virtual colonoscopy derived                                                               tomographic ct images colon holds great promise                                      fd−afv  screening method colorectal cancer particularly                               fd                                                                                                glmm  cad tools developed facilitate efﬁciency radiol                                                               ogists’ efforts detecting lesions  cases  colon cancer progressed rapidly local polyp adeno     mas advanced stages colorectal cancer   poor survival rates identifying removing le  sions polyp local stage disease     high survival rates  early diagnosis critical     challenging learning problem requires  use random effects model reasons     sizes polyps positive examples vary  mm    way  mm size polyp gets larger                                                                number candidates identifying increases                     didates highly correlated second data collected   patients seven different sites factors  patient anatomypreparation physician practice scan figure  comparing fd fdafv colon testing data                                                         fd               fd            glmm  ner type vary different patients hospitals—the data pfd−af  pglmm  pfd−af   patienthospital correlated    dataset database highresolution ct images used  study obtained nyu medical center cleve  land clinic foundation ﬁve eu sites vienna belgium table  comparison training times seconds fd fd  notre dame muenster rome  patients  afv glmm pe colon training data  randomly partitioned training patients     algorithm time colon time pe  polyps  candidates test patients        fd                          polyps  candidates groups test        fdafv                     group sequestered used evaluate perfor     glmm                    mance ﬁnal combined total  features  extracted each candidate    experimental results roc curves obtained helping detect characterize emboli accurate  three techniques test data shown figure  efﬁcient reproducible way    better visualize differences curves en embolus forms complex shape characteristics  larged views corresponding regions clinical signiﬁcance lung making automated detection challenging  plotted performed pairwise analysis three candidate generation cg algorithm searches inten  curves difference each pair area sity minima each embolus usually broken sev  roccurve statistically signiﬁcant values com eral smaller units cg picks points  puted using technique described  statistical anal close neighborhood embolus features  ysis indicates fdafv accurate fd extracted multiple candidates generated  pvalue  glmm accurate fd characterizing embolus cg algorithm  pvalue  fdafv accurate addition usual patient hospital level random ef  glmm pvalue  run times each algo fects observe concrete example random  rithm shown table                            effects cad samples close neighborhood                                                        embolus patient strongly correlated    experiment  pulmonary embolism                 far embolus constitutes special case                                                        patientlevel random effects samples pointing  data sources domain description                                                        pe labeled positive ground truth  pulmonary embolism pe potentially lifethreatening signed pe id collected  cases   dition result underlying venous thromboembolic dis pes marked expert chest radiologists different  ease early accurate diagnosis key survival stitutions randomly divided sets training  computed tomography angiography cta merged  cases  clots generating total  candidates  accurate diagnostic tool pe hundreds testing  cases  clots generating total   ct slices each cta study manual reading laborious candidates test group sequestered used  time consuming complicated various pe lookalikes evaluate performance ﬁnal combined  false positives including respiratory motion artifact ﬂow total  features extracted each candidate  related artifact streak artifact partial volume artifact stair  step artifact lymph nodes vascular bifurcation experimental design results    computeraided detectioncad roc curves obtained three techniques test  systems developed assist radiologists process data shown figure  statistical analysis indicate                                                    ijcai                                                     
