                                   rgrams relational grams                                     niels landwehr     luc raedt                         machine learning lab department science                                    albertludwigsuniversity freiburg                            georgesk¨ohlerallee   freiburg germany                              landwehrderaedtinformatikunifreiburgde                        abstract                          tuples atoms indicated example                                                         lational markov model rmm approach anderson et al      introduce relational grams rgrams  extends traditional markov models domain      grade ngrams modeling relational sequences logical hidden markov models lohmms kerst      atoms ngrams rgrams based smoothed  ing et al  upgrade traditional hmms relational      nth order markov chains smoothed distributions  sequences allow logical variables uniﬁca      obtained decreasing order    tion motivated models success simplic      markov chain relational generaliza ity ngram models introduce relational grams      tion rgram avoid sampling object iden upgrade traditional ngrams relational sequences      tiﬁers sequences rgrams generative models distinguished features rgrams      level variablized sequences local ob lohmms rmms allow work general      ject identity constraints sequences deﬁne  ized abstract atoms sequences instance      equivalence classes ground sequences bioinformatics example atom helixrightalphashort      elements identical local identiﬁer renam generalized helixxalphay alpha      ing proposed technique evaluated helix orientation length secondly use      domains including mobile phone communication     variables uniﬁcation allows make abstraction      logs unix shell user modeling protein fold  object identiﬁers share information events      prediction based secondary protein structure  example abstract subsequence outcallxfail                                                        outtxtx describes user failing reach    introduction                                       son writes text message thesameperson stating  probabilistic sequence models occupy important position identity person especially important  ﬁeld machine learning generalizing patterns phones users ob  theoretically appealing proven provide ef jects referred typically different precise  fective learning algorithms application areas identiﬁers matter relationships events  ranging natural language processing bioinformatics occur  robotics traditional sequence models sequences paper structured follows section  intro                                                        duce relational sequences deﬁne notion genera  strings  wk ﬁnite alphabet Σ typically  goal estimate joint distribution ps pos tive model takes account nature identiﬁers  sible strings given ps tasks solved includ object identity section  start ngrams  ing sequence classiﬁcation sampling predicting derive rgrams section  report experiments  event sequence given history preceding events ﬁnally section  conclude touch related    recent technological advances progress artiﬁcial work  intelligence led generation structured data se  quences example smart phone   relational sequences  communication events phone users logged atom pttn relation arity fol  during extended periods time raento et al lowed terms ti work three kinds terms  ones concerned logging activities locations constants slanted font identiﬁers italicandvari  persons liao et al  visits websites ander ables starting upper case character furthermore  son et al  finally bioinformatics sequences relations typed each argument position  contain structural information durbin et al  relation constants identi  developments statistical ﬁers variables appear position shall  relational learning raedt kersting  distinguish constantvariables identiﬁervariables  overview motivated development probabilis instantiated constants identi  tic models relational sequences sequences ﬁers written italic slanted font respec                                                    ijcai                                                     example  following sequences atoms examples relational sequences different domains    outcall fail outcall fail incall succ outtxt  intxt     mkdirrgrams lsrgrams emacsrgrams tex latexrgrams tex    strandsaplusshort helixrightalphamedium strandblbplusshort helixrightftoshort    ﬁrst domain describes incoming outgoing calls text messages mobile phone user second domain unix  shell commands executed user described terms command arguments domain helices  strands protein secondary structure elements deﬁned terms orientation type length    tively instance relation outcall identiﬁers given  ﬁrst position constants second                                                          • relational alphabet Σ  outcall fail typeconform types constants  identiﬁers variables relations specify alpha • asets ground sequences Σ  bet Σ set typeconform atoms Σ¯ ⊆ Σ set                                                          • ∈  atoms contain identiﬁers relational sequence                              ∗                           •         Λ                                Σ  string  wwm Σ  expression ground family generative models order   does contain variable example sequences model λ ∈ Λ maximizes  typically ground cf example                                                 notice constants typically serve attributes describ       λ    λ  ing properties relations identiﬁers identify particu              s∈s  lar objects domain identiﬁers special meaning  used sharing object identity denotes equivalence class regard  events ﬁxed vocabulary identiﬁers congruence simple instance family generative  known priori new identiﬁers ap models introduced section  pearing applying model unseen data  desirable distinguish ground sequences iden  rgram models relational sequences  tiﬁer renaming motivates following deﬁnition                                                        markov chains simplest success  deﬁnition  sequence congruence relational se                                                        ful approaches sequence modeling ngrams based  quences                  ncongruent            pm   qm                            higherorder markov chains employ certain smoothing   ∈        −    subsequences         −                              pi pi     techniques avoid overﬁtting sample distribution         − identical identiﬁer renaming se  ri ri                                            section brieﬂy review ngrams propose  quences    identical identiﬁer renaming                                                   simple extension ngrams relational sequences  exist onetoone mapping ϕ identiﬁers  equals replacing identiﬁers ac  ngrams smoothed markov chains  cording ϕ                                                        ngrams deﬁne distribution sequences ww  example   sequences    rxpayrypbx                                                                                                      length order −  markov assumption  rzpawrwpbu congruent congruent                                                                             m    mcongruent sequences identical identiﬁer                                                               ww       − −  naming nm deﬁnition takes account                                                                                                                 limited history sequences congruent object                  identity patterns locally identical finally note wi−n shorthand wmaxi−n  congruence deﬁnes equivalence relation reﬂexive basic case conditional probabilities estimated  symmetric transitive                             set training sequences terms ”gram” counts    let deﬁne generative model relational se                                                                                                    quences sample actual identiﬁer values                         wi−n wi                                                           pnwi  wi−n wi−                       equivalence classes congruent sequences                           cwi−n wi−  yields following deﬁnition                                                        cwwk number times wwk appeared  deﬁnition  generative model let Σ relational al                    ∈             Σ                                        subsequence note  phabet let  set ground sequences length estimate maximizing likelihood  Σ let snΣ set equivalence classes             Σ                                          gram order deﬁnes tradeoff reliability  induced   ncongruence generative model probability estimates discriminatory power model  order Σ deﬁnes distribution Σ                                                      selecting ﬁxed order performance    generative model learned set creased combining models different order  ground sequences alphabet Σ simplest form discriminative estimated reliably manning  learning problem stated maximum likelihood sch¨utze  popular approaches  estimation                                           backoff interpolation estimates paper                                                    ijcai                                                                                                                           ∀          ∈ Σ¯ ∗              focus approach deﬁnes conditional distri  lln−ln               butions linear combinations models different order  ∀i  li contains constantvariables                                     n                                                                                                            ∀i  li annotated probability values              wi  wi−n wi−  αkpkwi   wi−k wi−                                                                                                                                                                                                      pr ln  lln− pr ln lln−                                                                    ∀                                                                                             lln−ln lln−ln heads              α  αn suitable weights  αk                                                                    mutually exclusive              lowerorder distributions pk wi wi−k wi−                                                           estimated according maximum likelihood equation  example  following example order rela              advanced smoothing techniques pro tional gram mobile phone domain⎫ example                                                                              outtxtx     ⎪              posed cf manning sch¨utze                         ⎪              scope paper                                            outtxty     ⎬                                                                               outcallx fail ← outcallx fail                                                                                                ⎪                rgrams smoothed relational markov chains                                ⎭⎪              consider ground  relational sequences  form              intxty                       ∈  Σ              gm       key idea rgrams    states reaching person user likely              markov assumption                                     write text message person somebody                                  m                                                                      need show rgram model deﬁnes dis                                       −     −                            gm       gi gi  gi             tribution relational sequences ﬁrst discuss basic                                                                                                     model analogy unsmoothed ngram extend              deﬁning conditional probabilities level ing smoothed analogy equation               ground grams does make sense presence object              identiﬁers ground grams replaced general abasicmodel              ized ones generality deﬁned notion subsumption basic rgram model ground sequence ggn−                                                                                               ∨   ∨ ←                                                                    exactly gram ln   ln   lln−              deﬁnition  subsumption relational sequence llk                                                                    lln− θ ggn− body lln− speciﬁc              subsumes sequence kkn substitution θ         ¯ ∗                                                                    sequence Σ subsuming ggn− according equa              notation llk θ kkn ≤                                                                    tion  start deﬁning probability prg  ggn−              ∀i  ≤ ≤   liθ  ki substitution set                                                                    ground atom given sequence ggn− ground              vtvt  different variables                                                              literals let ground literal consider gram              ti terms identiﬁer identiﬁer variable                          ∈                                                                        subsuming ggn−ifthereisani                  occurs twice  tl                                                                                                     lln−l θ ggn−g unique deﬁne                restriction allowed substitutions implements                                                                                                                      object identity subsumption semeraro et al pr ggn− pr ggn−  pr ln  lln−              notion sequence subsumption lee raedt prg  ggn−fromprg  ggn−               tested linear time               probability value prggm derived according              example  let yzuv identiﬁer variables        equation  note distribution ground                      pa      pa               sequences length model does distinguish                                θ                    tween ncongruent sequences instead following holds                      pa       pa                                   θ                    lemma    let  order rgram Σ                                                                s ∈ sΣ relational sequences sncongruent                                                                                                         rx pa rz   rw pa ru      thenpr     pr                                                                        let deﬁne                 θ  xw yu θ  xw yu zv                                                                                                               ∈ snqfurthermore   ∈s Σ prs                 reﬁne equation  account general                                                                                         fore              ized sequences realized deﬁning                                                                                                   Σ                                   m                               theorem  order rgram generative model                                                                    Σ                       ggm   li  li−nli−                                                                example  consider rgram model grams                                                                                 pa    ∨ pb  ←                li−nli θ gi−ngi generalization ab                                     stracts identiﬁer values time yields                     rx  ← pb               smoothed probability estimates degree charac            rx  ∨ ry  ← pa               teristic smoothing depending particular choice                                                                                            rx  ←               li−nli formalized following deﬁnition              deﬁnition  rgram model rgram model order uniform distributions head literals               alphabet Σ set relational grams       artiﬁcial start symbol matches begin                                                                                                                                                                                      ning sequence ground sequence gg                             ∨  ∨ ← lln−                                                                rupaurvpbvrv probability prgg·                                                               ·  ·  ·                                                                 ijcai                                                                 smoothing rgrams                                       building rgrams data                                            ∈  basic model exactly gram sub learn rgram given set training sequences  suming ground subsequence ggn− need  choose set relational grams  es  speciﬁc ngrams problem approach timate corresponding conditional probabilities   large number grams                                                        deﬁne weights αr ∈ specifying  training data needed reliably estimate fre algorithm need deﬁne counts relational setting  quencies prohibitive unless small ngrams  grams generalized shortening bodies cl lkis sm ∈ lk θ si sik  smoothing kgram estimates knequation                                                 basic idea smoothing rgrams generalize algorithm learn rgrams speciﬁed  grams logically mix resulting distributions                                                       rgramsinput sequences alphabet Σ parameters γn                           αr       gg −       gg −                             ¯ ∗                                                   lk− ∈ Σ cl lk−   ≤                          ˆ α                       r∈r                                each lk− ∈                                                                       pr   ggn− probability deﬁned       let lk lk contain maximally speciﬁc                     ˆ                                                     ∈ Σ¯                     explained subset grams sub            literals lk lk−lk                                                                           ∨···∨  ←  suming ggn−andα normalization constant addr        lk      lk   lk−                                                                                                      ˆ                                                                        llk−lk  α     r∈r αr general smooth             prl lk−                                                                                        llk−  probability estimate pr ggn− actual                               −                                                                      ggn−g∈sr pr gn   gree characteristic smoothing deﬁned set   sr  matching rgrams relative weights α               γ                                                                          analogy ngrams additional smoothing         αr     obtained considering relational grams ∈  return  shorter bodies llk− kn sub line  algorithm computes rgrams  tle problem approach relational grams order occur data notice identiﬁers occur                                      Σ                         ¯ ∗  kndeﬁne probability distribution rgrams cf Σ  realized using fre  Σ      sequences partitioned smaller num quent relational sequence miner mineseqlog lee  ber equivalence classes taken care raedt  using ontheﬂy approach  straightforward normalization distributes                                                        case relational gram body llk  probability mass assigned equivalence class modulo built added needed evaluate  equally subclasses modulo                                                       prg  ggn− llk  ggk unseen data                                                                                  example  consider rgram model grams rq line  possible literals lk sought occur  given                                              data maximally speciﬁc means                   rx  ∨ ry  ← rx              contain constantvariables cf condition  deﬁni                                                        tion  line  computes maximum likelihood esti                         rx  ←                                                        mates lines – weight α  sr denotes set                                                                                 uniform distribution head literals αr αq   ground subsequences gg −g appearing data                                                                    expect pr    pr          subsumed likelihood lr deﬁned  directly mixing distributions                    line  measure distribution deﬁned  prru  rv  αrprry   rx αqpqrx    matches sample distribution αr line                                                         deﬁned terms sr parameter γwhich  prrv  rv  αrprrx   rx αqpqrx                                                           controls tradeoff smoothness discrimination  rgram does distinguish sequences                                                        highly discriminative speciﬁc rules higher likelihood  rxrx rxry instead mix                                                       general ones able ﬁt sample dis    rx  ry  α rx   rx   α rx  tribution better receive weight γ                                 γ   γ   number subclasses modulo           experiments  congruence class rx                                                        section reports empirical evaluation pro    ultimate level smoothing obtained rela posed method realworld domains speciﬁ                        ∨  ∨  ←           tional gram form ln  ln ln fully cally seek answer following questions  variablized nonidentiﬁer arguments gram                                a                      rgrams competitive stateoftheart ap                                                 proaches relational sequence classiﬁcation        pr  ggn−   pr ln    xj    xj                                                    relational abstraction especially identiﬁers use                                                          ful   xa nonidentiﬁer arguments ln   xa instantiations case corresponds experiments carried realworld sequence clas  outofvocabulary event observing event siﬁcation problems three domains unix shell  training vocabulary ngrams         domain  greenberg  jacobs blockeel                                                     ijcai                                                      domain       rgrams   lohmm      lohmm  fk          domain       rgrams    ngrams   ngrams wo ids   protein                                   protein                            domain       rgrams     knn                     unix      ±             ±    unix      ±                         unix    ±             ±    unix    ±                         phone      ±             ±                                                          phone ii     ±            ±   table  comparison classiﬁcation accuracy rgrams  logical hidden markov models fisher kernels pro table  accuracy comparison rgrams ngrams  tein fold domain knearest neighbor ngrams wo ids proteinunix domains settings  unix shell domain protein fold prediction single split phone domain  subsets size   training test set used unix shell domain  sampled data fold crossvalidation  subsets  examples each randomly sampled ac performed each set results averaged phone  curacy determined fold crossvalidation averaged ii results based fold crossvalidation results                                                        ngrams based sample      thetaskistoclassifyusersasnovice programmers                                                                                                              rgrams  nonprogrammers based logs  shell sessions                                   ngrams wo ids  taining  commands constants arguments  identiﬁers reproduce setting used jacobs    blockeel  sampled  subsets  instances  each data measured classiﬁcation accuracy  using fold crossvalidation averaged results    protein fold classiﬁcation domain task classify                                                          accuracy  proteins belonging ﬁve folds scop hi    erarchy hubbard et al  strand names treated  identiﬁers ground terms constants problem  used benchmark kersting et al     kersting g¨artner  reproduce experi  mental setting used earlier work  ex                                                               amples fold used training remaining ex                             amples test set context phone domain data                    number examples  user communication behavior gathered using  software running nokia smartphones automatically figure  accuracy different training set sizes ranging  logs communication context data study   examples phone domain each  use information incoming outgoing calls text size  sets sampled fold crossvalidation  messages phone numbers identiﬁers ground terms formed result averaged  constants task phone discriminate  real sequences events ”corrupted” ones input support vector machine kersting g¨artner  tain sequence elements random order  unix shell log classiﬁcation problem orig  ∈      subsets size sampled                                                       inally tackled using knearest neighbor method based  randomly fold crossvalidation performed averaged customized sequence similarity jacobs blockeel   each kinphone ii task classify communication paper authors present results  logs belonging three users based cision tree learner using bagofwords representation  communication patterns referring actual phone cases rgrams yield competitive classiﬁcation accuracy  numbers event sequence                        positive answer question qfurthermorewe    domains sequence classiﬁcation performed note using na¨ıve implementation rgrams com  building rgram model rc each class la  putationally efﬁcient times building rgram model  beling unseen sequences class maximizes                                                                                                ranged    seconds presented experiments   pc   used bigram models phone ii domain second set experiments effect using rela  trigram models domains smoothing tional abstraction examined pre  parameter γ set  experiments learning cisely rgrams compared ngrams implement  gram model ontheﬂy explained section  nonrelational smoothing outlined section  treating    table  compares classiﬁcation accuracy rgrams atoms Σ ﬂat symbols experiments  accuracy results literature protein fold tried keeping identiﬁers events ngramsorremoving  unix shell domains protein fold domain hand                                                     data ngrams wo ids accuracy results  crafted logical hidden markov model achieves  accu   protein fold unix shell context phone domains  racy kersting et al  improved   ﬁsher kernel approach gradient like experiments run standard pc hardware  lihood function logical hidden markov model used ghz processor gb main memory                                                    ijcai                                                     
