                 fast incremental square root information smoothing∗                          michael kaess ananth ranganathan frank dellaert                    center robotics intelligent machines college computing                            georgia institute technology atlanta ga                                    kaessananthdellaertccgatechedu                        abstract      propose novel approach problem      simultaneous localization mapping slam      based incremental smoothing suitable      realtime applications largescale environments      main advantages ﬁlterbased algorithms      solve slam problem      need approximations      suffer linearization errors achieve      efﬁciency updating squareroot information      matrix factored version naturally sparse      smoothing information matrix efﬁciently      recover exact trajectory map given      time backsubstitution furthermore ap      proach allows access exact covariances      does suffer underestimation uncertain figure  updating upper triangular factor right hand      ties problem inherent ﬁlters side rhs new measurement rows left column shows      present simulationbased results linear ﬁrst three updates right column shows update  steps                                                        update operation symbolically denoted ⊕ entries      case showing constant time updates exploration remain unchanged shown light blue      tasks evaluate behavior pres      ence loops discuss approach ex      tends nonlinear case finally evalu    current realtime approaches slam typically based      ate overall nonlinear algorithm standard ﬁltering ﬁlters work linear problems      victoria park data set                                                        suitable realworld problems                                                        herently nonlinear julier uhlmann  reason    introduction                                       known marginalization previous poses                                                        bakes linearization errors way  problem  simultaneous localization mapping undone leading unbounded errors largescale  slam received considerable attention mobile  applications repeated marginalization complicates  robotics way enable robot explore nav problem making naturally sparse dependencies  igate previously unknown environments wide range tween poses landmarks summarized  applications commercial robotics searchandrescue information matrix dense sparse extended information ﬁl  reconnaissance solution incremental ters thrun et al  andthinjunctiontreeﬁlterspaskin  realtime order useful problem consists  present approximations deal complexity  components discrete correspondence continuous es                                                          smoothing approaches slam  recover complete  timation problem paper focus continuous                                                        robot trajectory map avoiding problems inher  keeping mind components                                                        ent ﬁlters particular information matrix sparse  completely independent information estimation                                                        remains sparse time need ap  simplify correspondence problem                                                        proximations number variables increases    ∗this work supported national science foun continuously smoothing realworld scenarios  dation award iis   “career markov chain monte carlo especially involving exploration information ma  methods large scale correspondence problems vi trix contains far entries ﬁlter based methods  sion robotics”                                   dellaert  repeatedly observing small number                                                    ijcai                                                    landmarks ﬁlters advantage  ignoring linearization issues correct way  dealing situation switch localization  map sufﬁcient quality obtained    paper present fast incremental smoothing ap  proach slam problem revisit underlying  probabilistic formulation smoothing problem  equivalent nonlinear optimization formulation section   basis work factorization smoothing  formation matrix directly suitable performing op figure  bayesian belief network representation slam prob                                                        lem state robot landmark locations  timization steps recalculating factorization      each step measurement equations incremen control input measurements  tally update factorized new measure  ments available described section  fully prior initial state xixi−ui  exploits natural sparsity slam problem resulting motion model parametrized control input uiand                                                          constant time updates exploration tasks apply vari  ik jk  landmark measurement model assuming  able reordering similar dellaert  order known correspondences ikjk each measurement zk  factored information matrix sparse closing multi standard slam literature assume gaus  ple loops linearization choices corrected sian process measurement models process model  time variables marginalized fac xi  fixi−uiwi describes robot behavior  tored representation apply backsubstitution sponse control input wi normally distributed  time obtain complete map trajectory linear time zeromean process noise covariance matrix Λithe                                                                                            evaluate incremental algorithm based standard gaussian measurement equation  ik jk  mod  victoria park dataset section                    els robot’s sensors vk normally distributed zero    approach incremental suitable realtime mean measurement noise covariance Σk  applications contrast smoothing approaches  like graphslam thrun et al  perform batch process  slam squares problem  ing solving complete problem each step section discuss obtain optimal estimate  explicitly exploiting structure slam problem set unknowns given measurements available  yield quite efﬁcient batch algorithms dellaert perform smoothing ﬁltering  largescale applications incremental solution needed interested maximum posterior map estimate  examples systems incrementally add new mea entire trajectory  xi map landmarks  surements graphical slam folkesson christensen  lj given measurements  zk control   multilevel relaxation frese et al inputs  ui let collect unknowns  similar solutions efﬁcient way ob vector Θx map estimate Θ∗ ob  taining marginal covariances needed data association tained minimizing negative log joint probability  section  approach allows access equation   exact marginal covariances matrix inver        ∗                                                                    Θ  argmin−   log         sion obtain efﬁcient conservative estimate              Θ    slam    smoothing                              combined process measurement models                                                        leads following nonlinear leastsquares problem  section review formulation slam                        problem smoothing framework following notation                    m                                                               ∗                                    dellaert  contrast ﬁltering methods   Θ    argmin         fixi−ui − xiΛ                                                                          Θ                         marginalization performed pose variables                                                                                                                     tained underlying probabilistic model              k  slam problem show inference model                           −                                                                                    ik jk   Σk      leads leastsquares problem                                                                                                                                 −    probabilistic model slam                   whereweusethenotationeΣ   Σ   squared  formulate slam problem terms belief net mahalanobis distance given covariance matrix Σ  work model shown figure  denote robot state practice considers linearized version      th  time step xi ∈  landmark lj problem process models fi measurement equa  ∈  measurement zk ∈  tions hk nonlinear good linearization point  joint probability given                     available nonlinear optimization methods solve succession                     m              k                 linear approximations equation order approach                                     i−       ik jk    minimum linearize leastsquares prob                                                lem assuming good linearization point avail                                                     able working iteration nonlinear                                                    ijcai                                                    figure  using givens rotation transform matrix upper  triangular form entry marked ’x’ eliminated changing  entries marked red dark depending sparseness    optimization method dellaert  derivation                                         m      ∗                    i−                       figure  complexity simulated linear exploration task show   δΘ    argmin         fi δxi−  giδxi − aiΛ                 δΘ                                   ing step averages each step squareroot factor updated                                                   adding new measurement rows givens rotations av                   k                                   erage number rotations red remains constant                      hik δx   jk δl −         average number entries matrix row execution time                            ik      jk   Σ                                                      step dashed green slightly increases implementation                                                                          tree representations underlying data structures          ik  jk  hk  jk jacobians hk respect                                i−                                                                    Δ                           change ik jk respectively jacobian deﬁned  btheﬁrsttermrθ −        gi                                                                       ∗   i−and    symmetry odometry vanishes leastsquares solution θ  leaving second  observation measurement prediction errors respectively term residual leastsquares problem    combine summands leastsquares problem squareroot factor allows efﬁciently recover  dropping covariance matrices Λi Σk pulling complete robot trajectory map given  matrix square roots inside mahalanobis norms time simply achieved backsubstitution using                          t                         current factor right hand side rhs obtain  et  −e      −te      −te     −te     Σ     Σ      Σ          Σ          Σ            date model variables θ based                                                                                                                                rθ                        scalar matrices simply means dividing each term                      measurement standard deviation collect ja note efﬁcient operation sparse  cobian matrices single matrix vectors ai ck assumption nearly constant average number en  right hand side vector variables vector tries row observed reasonable  θ obtain following standard leastsquares problem assumption loopy environments each variable                  ∗                                                                                      θ argminaθ   −               obtained constant time yielding   time complex                          θ                             ity number variables make map                                                        trajectory restrict calculation subset    updating factored representation                 variables stopping backsubstitution process  present incremental solution slam problem variables obtained constant time opera  based updating matrix factorization measurement tion typically sufﬁcient unless loops closed  jacobian  simplicity initially consider  case linear process measurement models  givens rotations  linear case measurement jacobian independent standard way obtain qr factorization mea  current estimate θ obtain squares surement jacobian using givens rotations golub  solution θ∗  directly standard qr matrix factor loan  clean entries diagonal  ization golub loan  jacobian ∈ rm×n time later approach readily extends                                                                                      factorization updates needed incorporate new                                                measurements process starts leftmost                                                                                      nonzero entry proceeds column rowwise  ∈ rm×m   orthogonal ∈ rn×n upper applying givens rotation                                          Δ                                              triangular note information matrix                   cos φ  sin φ                                                                                                       expressed terms factor                   − sin φ cos φ  squareroot information matrix  rewrite leastsquares problem noting multi rows ik parameter φ chosen  plying orthogonal matrix qt does change entry  shown figure                                                         entries diagonal zeroed  norm                                                                                           upper triangular entries contain factor note                                                   θ −          θ −               sparse measurement jacobian result sparse                                                                                               factor orthogonal rotation matrix typically                                                                      rθ −        dense matrix explicitly stored                                                    ijcai                                                    formed practice instead sufﬁcient update  rhs rotations applied    new measurement arrives cheaper update  current factorization factorize complete mea  surement jacobian adding new measurement row wt  rhs γ current factor rhs yields new  correct factorized form                                                 qt                                          simulated double loop interesting stages loop closing                            new rhs                                             γ            simplicity quarter poses landmarks shown  note obtained applying  givens rotations eliminate entries diagonal  new row givens rotations  determined zero new row yielding updated  factor r way factorization  simultaneously update right hand side rota  tions obtain d general maximum number givens  rotations needed add new measurement nhoweveras  new measurement rows sparse constant  number givens rotations needed furthermore new  measurements typically refer recently added variables cholesky factor cholesky factor  right new measurement                        variable reordering  row sparsely populated example locality  update process shown figure     easy add new landmark pose variables  qr factorization just expand factor  appropriate number zero columns rows updat  ing new measurement rows similarly rhs  augmented number zero entries    exploration task linear case number  rotations needed incorporate set new landmark  odometry measurements independent size tra  jectory map simulation results figure  show  algorithm time complexity explo  ration tasks recovering variables each step requires  time efﬁcient  steps   seconds step recent  variables change signiﬁcantly warrant recalcula  tion providing good approximation constant time    loops variable reordering  loops dealt periodic reordering variables  loop cycle trajectory brings robot  previously visited location introduces correlations  current poses previously observed landmarks execution time step different updating strategies                                                        shown linear log scale  connected earlier parts trajec  tory results based simulated environment multiple figure  simulated environment consisting loop  loops shown figure  information traversed twice upper triangular factor shows signiﬁ  matrix remains sparse process incremental updat ﬁllin yielding bad performance continuous red  ing factor leads ﬁllin ﬁllin local does ﬁllin occurs ﬁrst loop closed note  affect exploration evident example negative consequences subsequent exploration sec  ﬁllin avoided variable reordering ond loop loop closure occurs ﬁllin  described dellaert  factor af signiﬁcant complete loop traversed                                                        second time peak visiting center point  ter reordering shows signs ﬁllin reordering loop time variable reordering factor  variables subsequent factorization new mea matrix completely sparse reordering each step  surement jacobian expensive performed dashed green expensive case multiple loops  each step propose fast incremental updates considerable increase efﬁciency achieved using fast incre  interleaved occasional reordering yielding fast algo mental updates interleaved periodic reordering dotted blue  rithm supported dotted blue curve figure  steps                                                    ijcai                                                      robot continuously observes land  marks example remaining small room ap  proach eventually fail information matrix  completely dense case ﬁlters  fail underestimation uncertainties  ﬁnally converge  correct solution deal  scenario eventually switch localization    nonlinear systems  factored representation allows changing linearization  point variable time updating linearization  point based new variable estimate changes measure  ment jacobian way obtain new factorization  refactor matrix results presented  combine periodic reordering variables  ﬁllin reduction discussed earlier    situations necessary perform  relinearization steedly et al  measurements typ  ically fairly accurate local scale relinearization  needed step measurements local  affect small number variables directly  effects rapidly declining propagating through  straint graph exception situation loop clos  ing affect variables case  sufﬁcient perform selective relinearization vari                                                        figure  optimized map victoria park sequence solving  ables estimate changed thresh complete problem step takes  minutes  old case affected measurement rows ﬁrst laptop known correspondences trajectory landmarks  moved current factor qrdowndating golub shown yellow light manually overlayed aerial image  loan  followed adding relinearized measure reference differential gps used obtaining results  ment rows qrupdating described earlier        shown blue dark available note places                                                        gps available    results                                                           covariances data association  applied approach sydney victoria park  dataset available httpwwwacfrusydeduau    algorithm helpful performing data association  homepagesacademicenebotdatasethtm popu       generally difﬁcult problem noisy data  lar test dataset slam community trajectory resulting uncertainties map trajectory estimates  sists  frames trajectory  kilometer length allows undo data association decisions  recorded time frame  minutes  frames exploited second allows recovering  left removing measurements robot sta underlying uncertainties reducing search space  tionary extracted  measurements  land order reduce ambiguities matching newly ob  marks laser data simple tree detector  served features existing landmarks advanta                                                        geous know projection Ξ combined pose    ﬁnal optimized trajectory map shown figure                  known correspondences incremental recon landmark uncertainty Σ measurement space                                                                                     struction including solving variables each new         ΞhΣ         Γ                frame added took   minutes calculate pen                                                          tium  ghz laptop signiﬁcantly  jacobian projection process Γ mea  minutes took record data average calculation surement noise requires knowledge marginal                                                        variances                          time ﬁnal  steps step includes                                                                                                     Σjj  Σij  factorization including variable reordering took        Σij                             shows traversing long trajec                    Σij   Σii  tory signiﬁcant number loops algorithm current pose mi visible landmark xj  performs faster step needed realtime Σij corresponding blocks covariance  better selective reordering based matrix Σi− calculating covariance matrix order  threshold running average number recover entries option  givens rotations backsubstitution  steps completely populated entries  resulting execution time note representation allows retrieve exact values  provides good map trajectory estimates each having calculate complete dense  step measurements fairly accurate locally variance matrix efﬁciently obtain conservative                                                    ijcai                                                    
