                    stepwise nearest neighbor discriminant analysis∗                                           xipeng qiu lide wu                                 media computing  web intelligence lab                             department science engineering                                     fudan university shanghai china                                         xpqiuldwufudaneducn                        abstract                            major drawback lda suffers                                                        small sample size problem dealing high dimen      linear discriminant analysis lda popu                                                        sional data training samples sw      lar feature extraction technique statistical pat singular difﬁcult compute lda      tern recognition suffers  vectors example  ×  image face recog      small sample size problem dealing   nition  dimensions requires      high dimensional data lda                                                         training data ensure sw nonsingular      guaranteed ﬁnd best directions each approachesliu et al  belhumeur et al       class gaussian density common    chen et al  yu yang  proposed      variance matrix fail class densities address problem common problem      general paper new nonpara   proposed variant lda approaches lose      metric feature extraction method stepwise nearest discriminative information high dimensional space      neighbor discriminant analysissnnda pro                                                          disadvantage lda assumes each class      posed point view nearest neigh                                                        gaussian density common covariance matrix      bor classiﬁcation snnda ﬁnds important                                                        lda guaranteed ﬁnd best directions distri      discriminant directions assuming class                                                        butions unimodal separated scatter class      densities belong particular parametric fam                                                        means class distributions multimodal      ily does depend nonsingularity                                                        share mean fails ﬁnd discriminant      withinclass scatter matrix experimental                                                        directionfukunaga  rank −       results demonstrate snnda outperforms                                                                                                     number classes number extracted      existing variant lda methods state                                                        features −  unless posteriori prob      ofart face recognition approaches three datasets                                                        ability function selected −  features suboptimal      att feret face databases                                                        bayes sense optimal regard fisher                                                        criterion fukunaga     introduction                                         paper new feature extraction method step  curse highdimensionality major cause wise nearest neighbor discriminant analysissnnda pro  practical limitations pattern recognition technolo posed snnda linear feature extraction method  gies text classiﬁcation object recognition der optimize nearest neighbor classiﬁcation nn near  past decades dimensionality reduction tech est neighbor classiﬁcation duda et al  efﬁcient  niques proposed linear discriminant analysis method performing nonparametric classiﬁcation  lda fukunaga  popular super used pattern classiﬁcation ﬁeld especially ob  vised methods linear dimensionality reduction ject recognition nn classiﬁer close  applications lda proven powerful relation bayes classiﬁer nearest    purpose lda maximize betweenclass scat neighbor classiﬁcation carried highdimensional  ter simultaneously minimizing withinclass scatter feature space nearest neighbors point  formulated fisher criterion             far away causing bias degrading performance                                                        rule hastie et al  hastie tibshirani hastie                                                          sbw                      tibshirani  proposed discriminant adaptive nearest                  jf                                                   sww                      neighbor dann metric stretch neighborhood                                                        directions class probabilities don’t change  linear transformation matrix sb method suffers small sample size prob  class scatter matrix sw withinclass scatter matrix lem    ∗the support nsf china   snnda regarded extension nonparametric  acknowledged                                         discriminant analysisfukunaga mantock  itdoesn’t depend nonsingularity withinclass scat obviously suboptimal discarding discrimina  ter matrix snnda ﬁnds important discrimi tive information  nant directions assuming class densities belong liu et al liu et al  modiﬁed fisher’s criterion  particular parametric family                     using total scatter matrix st  sb  sw denom    rest paper organized follows section  inator instead sw proven modiﬁed  gives review analysis current existing variant criterion exactly equivalent fisher criterion  lda methods stepwise nearest neighbor sw singular modiﬁed criterion reaches max  discriminant analysis section  experimental evaluations imum value  transformation null  method existing variant lda methods space sw transformation guarantee                                                                                    stateofart face recognition approaches presented sec maximum class separability sbw  maximized  tion  finally conclusions section  sides method needs calculate inverse matrix                                                        time consuming chen et al chen et al     review analysis variant lda                 suggested null space spanned eigenvectors                                                        sw zero eigenvalues contains discriminative     methods                                            formation lda method called nldain null space  purpose lda maximize betweenclass scatter sw proposed chooses projection vectors maximiz  simultaneously minimizing withinclass scatter ing sb constraint sw zero approach    betweenclass scatter matrix sb withinclass discards discriminative information outside null space  scatter matrix sw deﬁned                       sw figure shows null space sw probably                                                        contains discriminant information obviously                    xc                                                      suboptimal maximizes betweenclass scatter            sb        pimi − mmi −                                                                 null space sw instead original input space                                                                         sides performance nlda drops signiﬁcantly                                                       − close dimension number                                                                                            samples number classes reason                                                    dimensionality null space small situ  number classes mi pi mean ation information lost li et al  yu  vector priori probability class respectively  et al yu yang proposed direct lda dlda  pc    pimi total mean vector si covariance ma algorithm ﬁrst removes null space sb  trix class                                      sume discriminative information exists space    lda method tries ﬁnd set projection vectors ∈ unfortunately shown assumption incorrect   d×d      maximizing ratio determinant sb sw figb demonstrates optimal discriminant vectors                                                        necessarily lie subspace spanned class                                                            sbw                   centers                 arg max                                               sww                                                                                                                                                          nlda              lda   dimensionalities data                              dlda                                                                                    transformation respectively                                                         class                                                                                                                                                                                                                                                           class  class      eq transformation matrix consti                                                  −                                                 lda                                                             −                 −     class    tuted eigenvectors sw sb corresponding ﬁrst                              largest eigenvalues fukunaga                    −                  −                                                              −                 −    small sample size problem occurs sw                                                            −                  −                      −                                     − − − − −       − − −      singular sw does exist                               class distributions multimodal share mean  example samples bc figure  figure  shows discriminant vector dashed line  fail ﬁnd discriminant directionfukunaga  nlda contains discriminant information shows  methods proposed solving problems discriminant vector dashed line dlda  following subsections detailed review strained pass through class centers  analysis methods                            according fisher criteria optimal discriminant                                                        projection solid line    methods aimed singularity sw  recent years researchers noticed problem  singularity sw tried overcome computa  tional difﬁculty lda                              methods aimed limitations  sb    avoid singularity sw twostage pcalda ap class conditional densities multimodal class  proach used belhumeur et al  pca ﬁrst used separability represented sb poor especially case  project high dimensional face data low dimen each class shares mean fails ﬁnd dis  sional feature space lda performed reduced criminant direction scatter class  pca subspace sw nonsingular method meansfukunaga   notice rank sb −  number extracted wn sample weight deﬁned  features −  unless posteriori prob                                                                                 ∆i α  ability function selected −  features suboptimal                                                                                        wn      α      α             bayes sense optimal regard fisher              ∆n  ∆n   criterion fukunaga                            α control parameter zero inﬁnity    fact classiﬁcation ultimate goal need sample weight introduced deemphasize samples  estimate class density near decision class center emphases samples near  boundaryhastie et al                         class sample larger ratio    fukunaga mantock fukunaga mantock    nonparametric extraclass intraclass differences given  presented nonparametric discriminant analysis nda undesirable inﬂuence scatter matrix sample  attempt overcome limitations presented lda weights eq values close  near classiﬁca  nonparametric discriminant analysis betweenclass scat tion boundaries drop zero class center  ter sb nonparametric nature scatter matrix gen control parameter α adjusts fast happens  erally rank loosening bound extracted fea paper set α                                                                                                  ture dimensionality nonparametric structure eq  ∆n  represents  matrix inherently leads extracted features preserve distance sample xn nearest neighbor                                                                                  relevant structures classiﬁcation bressan et al bressan different classes ∆n represents distance  vitria  explored nexus nonparametric tween sample xn nearest neighbor  discriminant analysis nda nearest neighbors nn class given training sample xn accuracy nearest  classiﬁer gave slight modiﬁcation nda ex neighbor classiﬁcation directly computed examin  tends twoclass nda multiclass version     ing difference    nonparametric methods overcomes lim                                                                                                 Θn  ∆   − ∆             itations sb depend singularity swor                                                                                            sˆw rank sˆw −     ∆   ∆  nonparametric extraclass intra                                                        class differences deﬁned eq     stepwise nearest neighbor discriminant               difference Θn zero xn correctly     analysis                                           classiﬁed xn classiﬁed false class                                                        larger difference Θn accurately sam  section propose new feature extraction method                                                        ple xn classiﬁed  stepwise nearest neighbor discriminant analysissnnda assuming extract features × linear pro  snnda uses nonparametric betweenclass jection matrix constraint identity  class scatter matrix does depend singularity matrix projected sample xnew  projected  withinclass scatter matrix improves performance nonparametric extraclass intraclass differences  nn classiﬁer                                         written δe  ∆e δi  ∆i  expect                                                                                                       nearest neighbor discriminant analysis           ﬁnd optimal make difference δn  − δn       criterion                                        projected subspace large possible  assuming multiclass problem classes ωii                          xn                                                                                                deﬁne extraclass nearest neighbor  arg max    wnδn  − δn                                                                             sample ∈ ωi                                                                                                                optimization problem interpreted ﬁnd         ∈ ωi − ≤ − ∀z∈  ωi                                                         linear transform maximizes distance classes    fashion set intraclass nearest neighbors minimizing expected distance samples  deﬁned                                         single class                             ∈ ωi − ≤ − ∀z ∈ ωi  considering    nonparametric extraclass intraclass differences xn                                                                             deﬁned                                                  wnδn  − δn                                                                                 ∆e      − xe                                                                             xn                      xn                                                                                                      ∆       −                           wnw  ∆n   ∆n  −    wnw  ∆n   ∆n                                                                                                                                                xn    nonparametric betweenclass withinclass scatter                  matrix deﬁned                                       tr  wnw   ∆n ∆n                                                                                       xn               ˆ                                            xn              sb         wn∆n ∆n                                                                                                  −tr   wnw  ∆nw   ∆n                                                                                                                                                                               xn              ˆ                                                                   sw         wn∆n∆n                    trw    wn∆n  ∆n                                                                                                                                               intraclass differences current dimensionality                                                                                    consistency nonparametric extraclass                                                 intraclass differences process dimensionality reduc                                                                                   tion                                 −                           −                           figure  gives algorithm stepwise nearest neighbor                      class  −   −                                        class   discriminant analysis                    class                     class                     lda    −                lda   −            nnda                       nnda                           −     −                     −    − − − − −       − − − −                                                        • dimensional samples · · ·  xn  expect                                                          ﬁnd dimensional discriminant subspace                                                                                           • suppose ﬁnd projection matrix wc                                                                                        steps reduce dimensionality samples dt                                                            step meet conditions                                                                                            t−                                   −                                 dt    −                    class  −                    class                     class                     lda    −                  class      •   · · ·    −              nnda                       lda                           −                  nnda             calculate nonparametric betweenclass sˆt   −                     −                                                                            − − −          − − −                                                                                        ˆt                                                                 withinclass scatter matrix sw current dt−                                                                 dimensionality  figure  projected directions nnda solid                                                                calculate projection matrix wc  wc ×d  lda dashed projections artiﬁcial datasets                                         t−                                                                  matrix                                                                project samples projection matrix wct               xn                                                    ct                                                          wt  ×       −trw     wn∆   ∆                                                                                         qt                                                         • ﬁnal transformation matrix  wt                            trw  sˆbw  − trw sˆww             ˆ   ˆ      trw  sb − sww                           figure  stepwise nearest neighbor discriminant analysis    tr· trace matrix sˆb sˆw non  parametric betweenclass withinclass scatter matrix  deﬁned eq                               discussions    eq equivalent                         snnda advantage need calculate                                                        inverse matrix efﬁcient stable method                                        wc  arg max trw sˆb − sˆww        snnda optimizes nn classiﬁcation                                                      easy extend case knn    eq nearest neighbor discriminant analysis drawback snnda computational  criterionnnda                                      efﬁciency ﬁnding neighbors original data    projection matrix wc constituted space high dimensionality improved method pca  eigenvectors sˆb − sˆw corresponding ﬁrst largest ﬁrst used reduce dimension data − rank  eigenvalues                                          total scatter matrix through removing null space    figure  gives comparisons nnda lda    total scatter matrix snnda performed  class density unimodal nnda approxi transformed space yang et al yang yang  shows  mately equivalent lda cases class den discriminant information lost transformed  sity multimodal classes share mean space  bc nnda outperforms lda greatly                                                           experiments    stepwise dimensionality reduction                                                        section apply method face recognition  analysis nearest neighbor discriminant analysis compare existing variant lda methods  criterion notice calculate nonparametric extraclass stateofart face recognition approaches                                 intraclass differences ∆ ∆  original high di pca turk pentland  pcalda belhumeur et  mensional space project low dimensional al  nlda chen et al  nda bressan                         space δ   ∆   δ    ∆   does ex vitria  bayesian moghaddam et al  ap  actly agree nonparametric extraclass intraclass proaches experiments repeated  times indepen  differences projection subspace orthonor dently average results calculated  mal transformation case warranty distance  preservation solution problem ﬁnd projec  datasets  tion matrix wc stepwise dimensionality reduction method evaluate robustness snnda perform ex  each step recalculate nonparametric extraclass periments three datasets popular att facedatabase samaria harter  feret  face   recognition rate snnda reached   database phillips et al  descriptions three feret dataset surprisedly dimensionality sam  datasets                                   ples  methods poor perfor  att dataset dataset att face database mances dimensionality snnda does      merly ‘the orl   database faces’  suffer overﬁtting snnda pca      tains  images  ×   persons  im rank recognition rates methods descent      ages person images taken differ  dimensionality increases continuously      ent times varying lighting slightly facial expres fig  shows cumulative recognition rates three dif      sions openclosed eyes smilingnonsmiling fa ferent datasets cumula      cial details glassesnoglasses each image linearly tive recognition rates reach  snnda      stretched range pixel values  dataset contains changes lighting condition      fig shows face examples database feret dataset  snnda obviously bet      set  images each person randomly parti ter performance      tioned training subset  images test set different att dataset feret dataset        training set used learn basis class labels involved training testing      components test set evaluate        ferer dataset  overlap training                                                        set galleyprobe set according feret proto                                                        col phillips et al  ability generalization                                                        known subjects training set unknown subjects                                                        galleryprobe set needed each method result                                                        feret dataset  convincing evaluate robust                                                        each method snnda gives best                                                        performance methods feret dataset          figure  face examples att database        major character displayed experimental results                                                        snnda stable high recognition rates                                                        three different datasets methods  feret dataset  dataset subset feret unstable performances      database  subjects each subject       images taken controlled lighting condi  conclusion      tion neutral expression taken      lighting condition different fa paper proposed new feature extraction method      cial expressions smiling taken stepwise nearest neighbor discriminant analysissnnda      der different lighting condition neutral ﬁnds important discriminant directions      expression images preprocessed using zero suming class densities belong particular paramet      meanunitvariance operation manually registered ric family does depend nonsingularity      using eye positions images normal withinclass scatter matrix experimental results      ized eye locations cropped size three datasets att feret face databases       ×  mask template used remove demonstrate snnda outperforms existing variant      ground hair histogram equalization applied lda methods stateofart face recognition ap      face images photometric normalization proaches greatly snnda efﬁcient accu      images each person randomly selected training rate robust works extend snnda      rest used test                nonlinear discriminant analysis kernel method                                                        attempt extend snnda knn case  feret dataset  dataset different subset      feret database  people feret      fafb data set used experiment references      face images each person dataset belhumeur et al  pn belhumeur hespanda      overlap training set galleyprobe set kiregeman eigenfaces vs fisherfaces recognition      according feret protocol phillips et al  using class speciﬁc linear projection ieee transactions       people randomly selected training pattern analysis machine intelligence –      remaining  people used testing each test        ing people face image gallery                                                                                  probe images preprocessed using bressan vitria  bressan vitria      method feret dataset                       nonparametric discriminant analysis   nearest                                                           neighbor classiﬁcation pattern recognition letters    experimental results                                  fig  shows rank recognition rates different chen et al  chen liao ko lin  number features three different datasets shown yu new ldabased face recognition  snnda outperforms methods recogni   solve small sample size problem pattern recog  tion rate snnda reach  att dataset nition – 
