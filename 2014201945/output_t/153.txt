             necessity syntactic parsing semantic role labeling                             vasin punyakanok         dan roth        wentau yih                                      department science                                 university illinois urbanachampaign                                          urbana il  usa                                  punyakandanryihuiucedu                        abstract                          possible use shallow syntactic information                                                        build outstanding srl      provide experimental study role     propbank built adding semantic annota      syntactic parsing semantic role labeling  tion constituents syntactic parse trees penn tree      conclusions demonstrate syntactic parse infor bank clear important syntactic parsing      mation clearly relevant ﬁrst  building srl best knowledge      stage – pruning stage addition quality problem ﬁrst addressed gildea palmer       pruning stage determined solely  attempt using limited syntactic information      based recall precision instead depends parser shallow – clauses available      characteristics output candidates chunks used pruning stage gildea      make downstream problems easier harder mo    palmer  strict chunks      tivated observation suggest effective sidered argument candidates meaning       simple approach combining different seman arguments treated candidates result      tic role labeling systems through joint inference overall recall approach low      signiﬁcantly improves performance      demonstrate later high recall pruning stage fact                                                        essential quality srl                                                          using shallow parse information srl    introduction                                       largely ignored recent conll shared  semantic parsing sentences believed important task competition carreras marquez  com  task natural language understanding imme petition participants restricted shallow parse  diate applications tasks information extraction information srl systems result  question answering study semantic role labeling srl clear performance best shallow parse based sys  each verb sentence goal identify tem hacioglu et al   best  constituents ﬁll semantic role determine uses parse information pradhan et al   roles agent patient instrument adjuncts addition true quantitative compari  locative temporal manner                 son shallow parsing conll shared task    propbank project kingsbury palmer   used subset data training furthermore  provides large humanannotated corpus seman evaluation treats continued referential tags differently  tic verbargument relations enabled researchers apply makes performance metric stricter results  machine learning techniques improve srl systems gildea worse second srl usually complicated  palmer  chen rambow  gildea   consists stages unknown  hockenmaier  pradhan et al  surdeanu et al precisely syntactic information helps   pradhan et al  xue palmer  goal study twofold make fair  systems rely heavily syntactic parse trees comparison srl systems use parse trees  overall performance largely exclusively using shallow syntactic information  determined quality automatic syntactic parsers brings forward better analysis necessity  state art collins  charniak  parsing srl task second relieve dependency  far perfect                               srl quality automatic parsers im    alternatively shallow syntactic parsers chunkers prove semantic role labeling signiﬁcantly combining sev  clausers providing information eral srl systems based different stateofart parsers  syntactic parser shown robust make conclusions applicable general srl sys  speciﬁc task li roth  raises tems adhere widely used step architec  natural interesting question quantifying necessity ture ﬁrst step trained identify argu  parse information semantic parsing ment candidates given verb predicate second stepthe classiﬁes argument candidate types pearls ra left   addition common use simple procedure          daughterinlaw fake  prune obvious noncandidates ﬁrst step use distribution argument labels fairly unbal  postprocessing inference ﬁx inconsistent predictions anced ofﬁcial release propbank core arguments  second step employ additional steps a–a aa occupy  largest parts    comparison systems using shallow   rest portion  syntactic information interesting adjunct arguments  continued carg  sult each step using shallow referential rarg arguments relatively fewer occupying  formation exhibits good performance overall   respectively deﬁnitions prop  formance signiﬁcantly inferior uses bank semantic role labeling task readers refer  information necessity parse information es kingsbury palmer  carreras marquez  pecially noticeable pruning stage addition pro   duce stateoftheart srl combining different  srl systems based potentially noisy automatic  srl architecture  parsers collins  charniak     rest paper organized follows section  srl consists stages pruning argument  gives brief description semantic role labeling task identiﬁcation argument classiﬁcation inference par  propbank corpus section  introduces general ticular goal pruning argument identiﬁcation  architecture srl including features used identify argument candidates given verb predicate  different stages detailed experimental comparison classiﬁes argument candidate types  tween using parsing shallow parsing provided stage argument classiﬁcation linguistic struc  section  try explain tural constraints incorporated inference stage  parse information contributes srl inspired result solve inconsistent global predictions section describes  suggests approach combines different srl sys build stages including features used  tems based joint inference section  finally section  training classiﬁers  concludes paper                                                          pruning                                                        parse tree sentence available    semantic role labeling srl task                  constituents parse tree considered argument  goal semanticrole labeling task discover didates addition exploits heuristic rules  verbargument structure given input sentence exam introduced xue palmer  ﬁlter simple  ple given sentence “ left pearls daughterinlaw stituents unlikely arguments heuristic  will” goal identify different arguments recursive process starting verb argu  verb left yields output                    ments identiﬁed ﬁrst returns siblings verb                                                        candidates moves parent verb col    left  pearls daughterinlaw lects siblings process goes reaches                   amloc                 root addition constituent pp propositional  represents leaver represents thing left phrase children collected  represents benefactor amloc adjunct indicat  ing location action determines verb  argument identiﬁcation  addition each argument mapped constituent argument identiﬁcation stage utilizes binary classiﬁca  corresponding syntactic parse tree              tion identify candidate argument    following deﬁnition propbank conll  parsing available train apply binary   shared task different types arguments classiﬁers constituents supplied pruning stage  labeled aa aa labels different seman shallow parsing available does  tics each verb speciﬁed propbank frame ﬁles pruning stage does constituents  addition  types adjuncts labeled begin conceptually  adj adj speciﬁes adjunct type cases sider possible subsequences consecutive words  argument span different parts sentence la sentence potential argument candidates avoid  bel carg used specify continuity arguments using learning scheme ﬁrst training classiﬁers  shown example                        predict beginnings possible arguments                                                        ends predictions combined form argument     pearls  said  ca left candidates violate following constraints                    daughterinlaw                                                           arguments cover predicate  cases argument relative pro  noun fact refers actual agent outside clause  arguments overlap clauses  case actual agent labeled appropriate argu embedded  ment type arg relative pronoun instead labeled  predicate outside clause arguments  rarg example                                    embedded clause  features used parsing shallow parsing • phrase type uses simple heuristics identify vp  settings described follows                        pp np  features parsing available                 • head word pos tag head word    features used standard features rightmost word np leftmost word vp  include                                             pp                                                          • shallowpath records traversal path pseudo    • predicate pos tag predicate features indicate  parse tree constructed clause structure      lemma predicate verb pos tag      chunks    • voice feature indicates passiveactive voice predi • shallowsubcategorization feature describes chunk      cate                                                 clause structure predicate’s parent    • phrase type feature provides phrase type pseudoparse tree      stituent                                           • syntactic frame features discarded    • head word pos tag head word feature pro      vides head word pos tag constituent  argument classiﬁcation      use rules introduced collins  extract stage assigns ﬁnal argument labels argument      feature                                          candidates supplied previous stage multiclass    • position feature describes constituent classiﬁer trained classify types arguments sup      predicate relative position sentence plied argument identiﬁcation stage addition    • path records traversal path parse tree duce excessive candidates mistakenly output pre      predicate constituent                     vious stage classiﬁer classify argument    • subcategorization feature describes phrase struc null meaning “not argument” discard argument      ture predicate’s parent records imme features used used      diate structure parse tree expands parent argument identiﬁcation stage parsing                                                        available additional feature introduced xue    use following additional features      palmer  used    • verb class feature class active predicate • syntactic frame describes sequential pattern      scribed propbank frames                           noun phrases predicate sentence    • lengths target constituent numbers      words chunks separately                        inference    • chunk  tells target argument embeds overlaps purpose stage incorporate prior lin      embedded chunk type          guistic structural knowledge “arguments    • chunk pattern encodes sequence chunks overlap” “each verb takes argument each      current words predicate               type” knowledge used resolve inconsistencies    • chunk pattern length feature counts number argument classiﬁcation order generate ﬁnal legiti      chunks argument                           mate predictions use inference process introduced                                                        punyakanok et al  process formulated    • clause relative position feature position integer linear programming ilp problem takes      target word relative predicate pseudoparse inputs conﬁdences each type arguments sup      tree constructed clause constituent plied argument classiﬁer output optimal      conﬁgurations—target constituent predicate lution maximizes linear sum conﬁdence scores      share parent target constituent parent conditional probabilities estimated argument      cestor predicate predicate parent ancestor tar classiﬁer subject constraints encode domain      word                           knowledge    • clause coverage describes local clause      predicate covered target argument  necessity syntactic parsing    • neg  feature active target verb chunk      n’t                                           study necessity syntactic parsing experimentally                                                        observing effects using parsing shallow pars    • mod  feature active modal verb                                                        ing each stage srl section  ﬁrst      verb chunk rules neg mod features                                                        prepare data basic      used baseline srl developed erik                                                        including features learning algorithm compar      tjong kim sang carreras marquez                                                         ison parsing shallow parsing three stages  features shallow parsing available       excluding inference stage presented reversed  features used similar used order sections     parsing need parse trees generate  types features try mimic features  experimental setting  heuristics rules discard details use propbank sections  through  training data  features follows                        section  testing order apply standard conll evaluation script conforms input clauses unclear mimic syn  output format deﬁned shared task          tactic frame feature relies internal structure    conll evaluation metric slightly parse tree does corresponding  stricted argument prediction considered cor feature shallow parsing case  rect continued arguments carg correct table  reports experimental results argument clas  referential arguments rarg included – require siﬁcation argument boundaries known  ments absent previous srl systems given parsing features help using gold stan  occupy small percentage data pro dard data difference    vide fair comparison report performance conll argm evaluation respectively  discarding continued referential arguments following automatic shallow parsers used gap  notation used xue palmer  evaluation smaller  metric referred “argm” considers core ar  guments adjunct arguments note             parsing shallow parsing  formance reported excludes label usually improves      gold                     overall performance included                           auto                       goal experiments section gold argm                 stand effective contribution parsing versus shal auto argm              low parsing using partofspeech tags chunks  clauses addition compare performance table  accuracy argument classiﬁcation argu  ing correct gold standard versus using automatic parse ment boundaries known  data automatic parse trees derived using char  niak’s parser charniak  version  automatic  shallow parsing information generated state lesson argument boundaries known  oftheart pos tagger evenzohar roth  chun formance paring systems  ker punyakanok roth  clauser carreras shallow parsing  marquez     learning algorithm used variation winnow  argument identiﬁcation  update rule incorporated snow roth  roth  yih  multiclass classiﬁer tailored large argument identiﬁcation important stage effectively  scale learning tasks snow learns sparse network linear reduces number argument candidates pruning  functions targets argument border predictions given argument candidate argument identiﬁer  argument type predictions case represented binary classiﬁer decides candidate  linear functions common feature space improves considered argument evaluate inﬂu  basic winnow multiplicative update rule ways ence parsing stage candidate list used  example regularization term added ef pruning results gold standard parse trees  fect trying separate data large margin separa similar argument classiﬁcation stage differ  tor grove roth  hang et al  voted av ence fullparse shallowparse use path  eraged weight vector used freund schapire  subcategorization features replace    experimental evidences shown snow activa shallowpath shallowsubcategorization binary  tions correlate conﬁdence prediction classiﬁer trained using shallow parsing information  provide estimate probability used argu table  reports performance argument identiﬁer  ment identiﬁcation inference use softmax func test set using direct predictions trained binary  tion bishop  convert raw activation conditional classiﬁer recall precision parsing  probabilities speciﬁcally classes raw   percents higher shallow parsing  activation class acti posterior estimation class gold standard data result score                                                    higher performance automatic parse data                                eacti                   unsurprisingly lower difference parsing             scorei  pi                                               eactj               shallow parsing relatively terms ﬁlter                              ≤j≤n                     ing efﬁciency  examples predicted    argument classiﬁcation                           positive words argument identiﬁers ﬁlter  evaluate performance gap parsing  argument candidates pruning  shallow parsing argument classiﬁcation assume  argument boundaries known train classiﬁers           parsing        shallow parsing  classify labels arguments stage  prec   rec         prec   rec      difference parsing shallow parsing gold            construction three parsing features path sub auto            categorization syntactic frame described sec  tion  path subcategorization approximated table  performance argument identiﬁcation  shallowpath shallowsubcategorization using chunks pruning based gold standard parse trees            parsing         shallow parsing      argument classiﬁer predict end          prec    rec        prec    rec          argument product probabilities pair   gold                   predictions larger predeﬁned threshold pair   auto                   considered argument candidate pruning compar                                                        ison using classiﬁers heuristics shown table   table  performance argument identiﬁcation  pruning based gold standard parse trees     parsing       classiﬁer th  threshold                                                                 prec   rec         prec   rec                                                              gold                  recall argument identiﬁcation sets upper auto            bound recall argument classiﬁcation practice  threshold predicts examples positive usually low    table  performance pruning  ered allow positive predictions candidate  predicted positive probability estimation larger amazingly classiﬁer pruning strategy better  threshold table  shows performance ar heuristics recall classiﬁers  gument identiﬁers threshold           achieve higher precision really compare sys    argument identiﬁcation just intermediate step tems using parsing shallow parsing need  complete realistic evaluation method overall performance build semantic role sys  each ﬁnal performs table  table  tems based parsing shallow parsing pars  port ﬁnal results recall precision conll ing follows pruning argument identiﬁcation ar  argm metrics difference  using gument classiﬁcation inference stages described ear  gold standard data automatic parsers lier shallow parsing pruning replaced  used shallowparse fact slightly better wordbased pruning classiﬁers rest stages  fact shallow parsers accurate chunk signed use shallow parsing information described  clause predictions compared regular parser li previous sections table  table  show overall  roth                                           performance evaluation methods              parsing        shallow parsing                                                                     parsing        shallow parsing          prec    rec         prec    rec                                                                  prec   rec          prec   rec       gold                                                                                                                           gold                auto                                                                        auto               table  conll evaluation overall                                                        table  conll evaluation overall  formance pruning using gold standard parse                                                        formance  trees available                                                                     parsing        shallow parsing              parsing        shallow parsing                                                                 prec   rec         prec   rec              prec    rec        prec   rec             gold                gold                     auto                auto                                                                          table  argm performance overall  table  argm performance overall  pruning using gold standard parse trees available                                                          indicated tables gap                                                        parsing shallow parsing systems enlarges  lesson  parsing helps argument identiﬁcation  gold standard data ﬁrst glance result  automatic shallow parser accurate contradict conclusion section   parser using parsing information pruning stage shallow parsing srl  advantages shallow parsing                 forms equally better overall performance gap                                                        small    pruning                                            carefully examine output wordbased  shown previous subsections performance classiﬁer pruning realize fact ﬁlters “easy”  difference parsing shallow parsing large candidates leaves examples difﬁcult later  pruning information given conclude stages speciﬁc argument candidates  main contribution parse pruning stage lap differ words  shallow parsing does hand pruning heuristics based parsing  formation pruning heuristics train word based puts overlapping candidates following argument iden  classiﬁers replace pruning stage classiﬁer tiﬁcation stage thought good discriminating  trained predict given word start different types candidates
