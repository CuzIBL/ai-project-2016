                collapsed variational dirichlet process mixture models∗             kenichi kurihara                    max welling                      yee whye teh       dept science         dept science        dept science  tokyo institute technology japan        uc irvine usa            national university singapore       kuriharamicstitechacjp          wellingicsuciedu            tehywcompnusedusg                          abstract                          orders magnitude faster sampling especially                                                        special data structures kd trees used cache cer      nonparametric bayesian mixture models partic tain sufﬁcient statistics moore  verbeek et al       ular dirichlet process dp mixture models  kurihara et al       shown great promise density estimation      blei jordan  recently applied framework      data clustering given size today’s datasets variational bayesian vb inference dirichlet process dp      computational efﬁciency essential  mixture models demonstrated signiﬁcant computational      gredient applicability techniques gains model formulated entirely truncated      real world data study experimentally com stickbreaking representation choice representa      pare number variational bayesian vb ap    tion advantages disadvantages instance      proximations dp mixture model partic  easy generalize dp prior use      ular consider standard vb approximation    ﬂexible priors representation ﬂip      parameters assumed independent    side model formulated space explicit non      cluster assignment variables novel col exchangeable cluster labels instead partitions      lapsed vb approximation mixture weights     words randomly permuting labels changes probabil      marginalized vb approximations  ity data requires samplers mix cluster      consider different ways approximate labels avoid bias porteous et al       dp truncating stickbreaking construction                                                          paper propose study alternative approaches      using ﬁnite mixture model sym                                                        vb inference dp mixture models proposed      metric dirichlet prior                                                        blei jordan  three distinct contri                                                        butions paper proposing improved vb algo    introduction                                       rithm based integrating mixture weights comparing                                                        stickbreaking representation ﬁnite symmet  mixture modeling remains useful tools ric dirichlet approximation dp maintain  statistics machine learning data mining applications ing optimal ordering cluster labels stickbreaking  involving density estimation clustering vb algorithms lead total different algo  prominent recent developments ﬁeld application rithms including proposed blei jordan   nonparametric bayesian techniques mixture modeling experimentally evaluate algorithms compare  allow automatic determination appropriate gibbs sampling  number mixture components current inference algorithms section  explore truncated stickbreaking  models based gibbs sampling approximation ﬁnite symmetric dirichlet prior ﬁ  suffer number drawbacks importantly gibbs nite dimensional approximations dp opposed  sampling efﬁcient scale large scale truncated stickbreaking approximation ﬁnite symmetric  problems face modernday data mining secondly sam dirichlet model exchangeable cluster labels theoret  pling requires careful monitoring convergence ically important consequences example gibbs  markov chain decide number samples sampler required mix cluster labels  ignored burnin decide samples computing averages quantities invariant cluster label  needed reduce variance estimates permutations typically case  siderations lead researchers develop deterministic al                                                          section  explore idea integrating  ternatives trade variance bias easily                                                        mixture weights π collapsing model lower di  monitored terms convergence                                                        mensional space idea shown work    ∗this material based work supported lda models teh et al  strong dependencies ex  national science foundation grant number dhs ist model parameters assignment variables  ywt thanks lee kuan yew endowment fund funding dependencies exist mixture weights assignment                                                    ijcai                                                    variables mixture model context collaps terms  ing important intuition reﬂected                                                             ∼b    α                    −  observation variational bound log evidence                               guaranteed improve                                  vt                                                                                                               section  derive vb update equations corre    πi  vi   − vj                  sponding approximations section          ji  sider optimally reordering cluster labels stickbreaking                                                             πi                                     vb algorithms mentioned ordering cluster la  bels important models formulated stickbreaking α                                                                                      beta density variable para  representation paper blei jordan  issue                                                                                   meters  α verify πi  ignored study effect cluster reorder corporating joint probability data items   ing relevant performance measures predictive                                                        xnn  cluster assignments  znn  log evidence                                                          stickbreaking weights  vii     considerations lead vb inference meth cluster parameters η  ηii  ﬁnd  ods evaluate section  methods                                                           η  truncated stickbreaking representation standard vb                                      tsb  truncated stickbreaking representation n                      t                                                               η   π        η   α  collapsed vb ctsb  ﬁnite symmetric dirichlet rep      zn                  resentation standard vb fsd  ﬁnite symmetric                      dirichlet presentation collapsed vb cfsd                                                         πv mixture weights deﬁned    tsb ctsb optimal reordering otsb                                                        representation cluster labels interchangeable  octsb respectively                                                        changing labels change probability value  note                                                        →∞the approximation exact                                                          second approach approximate dp assuming    approximations dp                      ﬁnite large number clusters using sym                                                        metric dirichlet prior π ishwaran zarepour                                                                          π ∼dπ    α   α  approximations dp section                                       approximations obtained combination results joint model  truncated stickbreakingﬁnite symmetric dirichlet approxi  mations mixture weights marginalized π η                                                                                       based approximations n                   k  vb inference algorithms section             η  π       η   π  α   α                                                                 zn                       natural representation dps using chi                  nese restaurant process formulated space                                                        essential difference stickbreaking representa  partitions partitions groupings data independent                                                        tion cluster labels remain interchangeable  cluster labels each datapoint assigned exactly                                                        representation changing cluster labels does   group space partitions turns problem                                                        change probability porteous et al  limit  atic vb inference wish use fully factorized                                                         →∞is somewhat tricky transition →  variational distributions assignment variables qz                                                       ∞  switch space partitions states     qzn assignments rep                                                      result cluster relabelings mapped par  resent partition                                                           tition example             intricate dependencies assignment vari                                                                                           mapped partition  ables does make sense use factorization                                                                circumvent using ﬁnite dimensional    approximations dp formulated space ﬁgure  show prior average cluster sizes                                                        truncated stickbreaking tsb representation left  cluster labels partitions known  closely approximate dp prior number explic ﬁnite symmetric dirichlet fsd prior middle  itly maintained clusters grows ishwaran james  values truncation level number clusters                                                        spectively ﬁgure apparent cluster  ishwaran zarepour  ﬁnite approximations  discuss                        labels tsb prior interchangeable proba                                                        bilities ordered decreasing size inter                                                        changeable fsd prior increase    tsb fsd approximations                       priors approximate dp prior increasing accuracy                                                          note live different spaces                                                        dp naturally deﬁned space parti  ﬁrst approximation use stickbreaking represen tions tsb fsd deﬁned space  tation dp ishwaran james  truncate cluster labels tsb fsd live different                                                    ijcai                                                            truncated stick−breaking representation finite symmetric dirichlet prior truncated stick−breaking representation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        expected  cluster size   expected  cluster size          expected  cluster size                                                                                                                                                                                                                                                                                                                                                                                                                           cluster label                      cluster label                     cluster label    figure  average cluster size three ﬁnite approximations dp prior left truncated stickbreaking prior tsb given   middle finite symmetric dirichlet prior fsd right stickbreaking representation corresponding fsd prior each ﬁgure  show results truncation levels tk left bars tk right bars    spaces precisely transform sample  fsd prior stickbreaking representation    n                    n  forming sizebiased permutation mixture weights π                                                π                                                          sample   sample ordering                            according π replacement turns ﬁ  nite does exactly recover left hand ﬁgure n≥i  ni  ni fsd ﬁnd instead   samples prior closely related                                                                                                α           α  shown right pane ﬁgure  prior given            Γ    Γ                                                                      fsd                α            stickbreaking construction eqn sticklengths              Γn   αΓ   sampled                             α      iα                     variational bayesian inference               vi ∼bvi     α−                                                                   variational bayesian inference algorithm attias   conversely obtain samples fsd prior ghahramani beal  lower bounds log marginal  applying random uniformly distributed permutation likelihood assuming parameters hidden variables  cluster weights obtained eqn independent lower bound given                                                                              stickbreaking constructions slightly different large                            θ  similar expect ≥           θ                                                                                            log  θ    difference terms performance                       dθ                      marginalizing mixture weights            θ η η π η various dp  variational bayesian approximations discussed approximations discussed previous section approxi  section assume factorized form posterior dis mate inference achieved alternating optimization  tribution means assume parameters bound qz qθ following  dependent assignment variables clearly bad spell details vb inference proposed  assumption changes π considerable methods tsb prior use                                                                                               impact  ideally integrate parame               n        t  ters computationally expensive η           η                                           π                   tsb                         middle ground marginalize                             methods computational penalty make  approximation discussed section  qv used tsb model marginalized  tsb fsd representations joint collapsed model fsd prior use  η given                                                                                                                                       n         k                                    ∞                                                          qfsdz η π    qzn      qηk  qπ         η       η         η                      zn                                                                                                                                            π  different distributions cluster labels pz   left collapsed version  cases tsb representation                                                         bounds evidence                        Γ  niΓα  ni           ptsbz                                 given variational posteriors construct bounds                                α   n≥i                      Γ                        log marginal likelihood inserting eqn af                                                    ijcai                                                                ter algebra ﬁnd following general form   conditional pznz¬n different fsd                                                                    tsb priors tsb prior use  giving condi                         n                                                                        tional                                 zn ηz    xnηz                                       log                                      ¬n             ¬n                                 dηzn                                                              α  ni                         zn                                          iz                                                                                      ¬n            ¬n              ¬n                                           n                                        α    n≥i     α    n≥i                                   pηi                                                          jk                          qηilog     −       qznlogqzn                         η         qηi                                  ¬n   −     ¬n     −                                    zn                                                                                                                                                       extra term                                   corresponding counts removed contrast                                                                    fsd prior              “extra term” depends particular method                         ¬n   α                                                                                                                 tsb prior                                                kz                                                                                                 ¬n  ¬n   α                                                                                                                                       n  t           zn                termtsb          qzn       qvi log pznv       gaussian approximation                                        dv                          zn                              expectation required compute update                             t                                     intractable exponentially large space assign                                           pvi                                                              qvilog                     ments  fact computed polynomial time                                           vi                             dvi                              using convolutions solution tended                                                                    slow practical efﬁcient approximate              hand fsd prior ﬁnd                                                                    solution observe random variables ni ni                                                                    k                                 sums bernoulli variables ni  izn                                                                                                termfsd             qznqπlogpznπ                   using central limit theorem                                dπ                            sums expected closely approximated gaussian                                                                         π                       distributions means variances given                                  π                                            log π                                 n                                dπ                                                                                      eni     qzn                                   collapsed versions expressions replaced                                                                                              n                                        n                     termctsbcfsd         qzn log pz             vni     qzn  − qzn                                                                                                                                                                      n                  vb update equations                                                                           eni         qzn                              given bounds hard derive update equa          ji              tions various methods space constraints                                                                                    n                           refer papers blei jordan  ghahramani                                    beal  penny  yu et al  details                                                                                                                        update equations uncollapsed methods fo              ji         k≤i              cus novel collapsed update equations          apply approximation computation average                provide general form update  use following second order taylor expansion              equations assume par                                   η                                                                          ticular form prior  equations par     efm ≈ fem    emvm                   ticularly simple choose prior conju                                        gate exponential family explicit update equations qηi approximation observed work extremely              papers ghahramani beal  practice small values              blei jordan  penny  yu et al                 qηi ﬁnd update methods    optimal cluster label reordering                                                                                                                            discussed section  stickbreaking prior assumes                 qηi ∝ pηiexp    qzn  ilogpxnηi       certain ordering clusters precisely sizebiased                                                                  ordering permutation cluster labels changes                                                                    probability data choose optimal                                    ﬁnd update                      mutation resulting highest probability data                             ⎛                         ⎞                                                                  optimal relabelling clusters given                             ⎝                         ⎠            ders cluster sizes decreasing order true                  qzn ∝ exp         qzmlogpznz¬n                                                                    average prior cluster sizes ordered ex                               z¬n mn                                                                   periments assess effect reordering introducing                                                                    algorithms otsb octsb maintain                         ×            η      η                           exp          zn log  zn        optimal labelling clusters note optimal ordering                                  η                                  zn                              maintained blei jordan                                                                 ijcai                                                                figure  average log probability datapoint test data figure  average log probability datapoint test data  function                                        function tsb methods fsd methods      figure  relative average log probability datapoint test figure  relative average log probability datapoint test  data function                              data function tsb methods fsd methods      experiments                                        coefﬁcient  studied accuracy each algorithm                                                        function number data cases truncation  following experiments compared algorithms                                                        level approximation ﬁgures   show  discussed main text terms logprobability                                                        results vary keeping ﬁxed   held test data probability test point xtisthen                                                        ﬁgures   plot results vary  given                                                       ing ﬁxed  plot absolute value log                                                       probability test data value relative gibbs sam     xt           xtηz ηz ztz   qz                             train train   pler gs  iterations burnin run                  dηz             zt                                       iterations inference error bars computed rela                                               tive values order subtract variance caused differ  expectation   trainqztrain computed using  techniques introduced section  experiments ent splits measure variance paired experiments  conducted using gaussian mixtures vague priors following dasgupta  gaussian mixture cseparated                                                                                                         parameters                                    each pair components mi − mj  ≥                                                                max  max        max    ﬁrst experiment generated synthetic data maxλi λj  whereλ denotes maximum eigen  mixture  gaussians  dimensions separation value covariance                                                    ijcai                                                    
