                   compiling bayesian networks local structure                                    mark chavira      adnan darwiche                                       science department                                   university california los angeles                                       los angeles ca                                       chaviradarwichecsuclaedu                        abstract                          immediately extracts ac cnf factor                                                        ization beneﬁt logical approach twofold      recent work compiling bayesian networks    allows encode local structure form deter      reduced problem factoring cnf en  minism context speciﬁc independence csi boutilier et      codings networks providing expressive al  example using approach prac      framework exploiting local structure net tical compile bayesian networks binary vari      works local structure large cpts ables excessive determinism induced relational mod      excessive determinism quality cnf en els having treewidths excess  compiling      codings local structure cap ac minutes evaluating seconds chavira et al      ture signiﬁcant effect ofﬂine  second advantage approach ability      compile time online inference time ex    accommodate different representations conditional prob      amine encoding bayesian networks   ability tables cpts decision trees rules noisy–or      paper report new ﬁndings allow need algorithmic change paper      signiﬁcantly scale compilation approach consider tabular representations      particular obtain order–of–magnitude improve   critical computational step approach      ments compile time compile networks      clearly factoringcompiling cnf      successfully ﬁrst time obtain orders– ing exhaustive reﬁned version dpll algorithm      of–magnitude improvements online inference davis et al  darwiche  key observation      networks local structure compared underlying paper efﬁciency factoring      baseline jointree inference does exploit step—both factoring time size factorization—can      local structure                                  signiﬁcantly improved through careful cnf encodings                                                        capture local structure possible passing                                                        additional information cnfs factoring al    introduction                                       gorithm especially true handling net  shown recently compiling bayesian networks cor works local structure large cpts excessive  responds factoring multi–linear functions mlfs dar determinism propose particular cnf en  wiche  particular each bayesian network coding appears quite effective networks  characterized mlf exponential size eval properties identify key semantic property  uation differentiation solves exact inference prob resulting cnfs exploit cnf factoring al  lem  mlf factored arith gorithm incorporating ﬁndings show dramatic  metic circuit ac size necessarily exponen improvements ofﬂine compile time online  tial allowing use acs compiled representation ference ofﬂine compilation phase order–of–  bayesian networks interestingly park darwiche magnitude improvement cases ability com   shown building jointree jensen et al  pile networks ﬁrst time online phase  shenoy shafer  bayesian network corre observe orders–of–magnitude improvements  sponds precise sense process factoring mlf known benchmarks pathﬁnder munin water  ac embedded jointree structure online inference baseline jointree algorithm    ﬁndings created new possibilities performing ex  act inference provided new computational frame  factoring multi–linear functions  work based factoring mlfs fact speciﬁc mlf factor investigation based three technical observations  ing method proposed darwiche  ex darwiche  bayesian network inter  ploit structure inherent network parameters according preted exponentially–sized mlf evaluation  approach encodes mlf using propositional differentiation solves exact inference problem  theory conjunctive normal form cnf factors cnf mlf factored ac size ex                  row         prc         way factor mlf ac encoding                               θ                                           cab          mlf cnf factoring cnf illustrate                               θ                                       cab          encoding scheme consider mlf figure                             θcab                                 θ             real–valued variables basic idea specify                                    cab          mlf using propositional theory exactly                            θ                                            cab                                                             θc       models each term  speciﬁcally propositional                                                     theory ∆    ∧  ⇒   ∧ ⇒   boolean                            θcab                                                                θcab        variables va vb vc vd exactly models encodes                              θcab        follows                           θc                                                            model  va    vb    vc    vd    encoded term                           θcab                                                               σ     true  false false false                           θcab                                                               σ     true  false false true  ad                                                             σ     true  true  false true  abd  figure  small bayesian network cpts   σ     true  true  true  true  abcd  showing local structure form determinism csi                                                        model σ encodes term σvj  true precisely                                                        term contains real–valued variable                                                         factoringcompiling cnf ∆f discussed dar                                                       wiche  immediately extract ac represen            ad      factor                       tation mlf time space proportional                                                       factored cnf darwiche  discuss process              abd  abcd                                later ﬁrst provide encoding step                                                       start baseline encoding darwiche                                                         refer prev                                                 cnf boolean variable vλ each indicator                                                        variable λ boolean variable vθ each parameter                                                        variable θ brevity abuse notation          figure  mlf factored ac         simply write λ θ instead vλ vθ cnf clauses                                                        fall three sets each network variable  ponential mlf factoring process reduced domain     xn  factoring cnf encoding mlf                                                               indicator clauses  λx ∨ λx ∨    ∨ λxn    mlf network contains types variables                      ¬λx  ∨ ¬λx    each value each network variable                           dicator variable λx each network parameter prxu example variable figure  generates  parameter variable θ  mlf contains term                           xu                          λ  ∨ λ   ∨ λ  ¬λ   ∨ ¬λ   ¬λ  ∨ ¬λ   ¬λ   ∨ ¬λ  each instantiation network variables term                product indicators parameters consistent clauses ensure exactly indicator variable  instantiation network figure  variables appears each term mlf remaining sets  values variable three values clauses correspond network parameters particular  mlf corresponding network follows                                                        each parameter θxnxxxn−     λ  λ  λ  θ  θ θ        λ  λ λ  θ  θ  θ           cab cab       ip clause  λ ∧ λ ∧    ∧ λ ⇒ θ                                                                            xn    xnxxxn−                                                           pi clauses  θxnxxxn− ⇒ λxi  each    λa λb λc θa θb θcab  λa λb λc θa θb θcab    compute probability evidence evaluate example parameter θcab figure  generates  mlf setting indicators contradict                                                           λa  ∧ λb ∧ λc ⇒  θc  indicators  example compute pra set                                                                                               θcab ⇒ λa  θcab ⇒ λb  θcab ⇒ λc  indicators λa λb  set indicators  eval  uate reduced mlf pra                       models cnf one–to–one correspondence                                                        terms mlf particular each model   θa θba θcab  θa θba θcab  θa θba θcab                                                        cnf correspond unique network variable instantia    obvious example mlf ex tion set true indicator parameter  ponential size mlf factored ac variables compatible instantiation  size exponential leading formulate ex  act inference problem problem factoring mlfs  acs ac dag internal nodes labeled mul  encoding techniques  tiplicationsadditions leaves labeled variables prev encoding discussed does encode information  constants figure                              parameter values local structure quite    representations adds variations stricted representations mlfs unfolded acs        table  — jointree ran memory        table  cnfs generated prev determinism encoded                   max   ac inference improvement           network     vars  parm vars clauses  literals       network   cluster    time     jt            pathﬁnder                   bm                                  water                          stud                                mildew                     mm                                munin                         mm                      —              munin                      bm                      —              diabetes                 stud                   —                                                            cnf factoringcompilation process  easy encode information determinism en works    coding consider figure  parameter θcab   provide section sketch cnf factoring pro  generates clauses  clauses en cess note section skipped    sure parameter θcab appears mlf term iff ﬁrst reading paper strictly needed    term contains indicators λa  λb λc  following sections  given parameter known  terms consider cnf ∆f  va ∧ vb ⇒  vd ∧  contain parameter vanish vc ⇒ vb previous section mlf   suppress generation boolean variable param  ad  abd  abcd encodes brieﬂy  eter replace clauses single clause scribe cnf factoring process allows produce  ¬λa ∨¬λb ∨¬λc  clause effect eliminating ac shown figure  output factor  cnf models correspond vanishing terms ing process shown left figure  logi    containing parameter θcab                   cal form known negation normal form nnf sat    armed determinism prev encoding produce isﬁes decomposability conjunctions share variables  impressive results applied networks bi determinism disjuncts logically incompatible  nary variables contain small cpts contain large smoothness disjuncts mention sets vari  numbers  parameters example chavira et al  ables factorization generated using exhaustive  reports networks properties generated version dpll procedure davis et al  par  lational models table  reviews results ticular algorithm pick variable cnf  clear table gets exponential improvements factor ∆x ∆¬x separately combine  standard jointree method does ad sults ∧ factor∆x ∨ ¬x ∧ factor∆¬x im  vantage network determinism similar results prove performance algorithm keeps cache stores  reported darwiche  respect bayesian cnfs factored factorizations  networks corresponding digital circuits           checks cache trying factor cnf Γ finally    bayesian networks local structure large cpts fore picking variable split Γ algorithm checks  excessive determinism encoding determinism cnf broken disconnected com  effective table  lists set benchmark net ponents say α α case algorithm factors  works having variables large cardinalities components separately combines results  having large cpts determin factorα ∧ factorα factoring algorithm use  ism necessarily excessive table  provides statistics darwiche  utilizes decomposition tree dtree  cnfs generated networks according manage decomposition process particular dtree  prev encoding encoding determinism dis cnf binary tree leaves correspond cnf  cussed cnfs quite large striking clauses each node dtree associated  property large percentage  set variables instantiation guaranteed decom  cases boolean variables represent parameters versus pose cnf independent components  representing indicators cnfs proved procedure generates nnfs decompos  challenging factor taking long run able deterministic smoothness established easily  ning memory key observations postprocessing step given nnf satisﬁes  allowed handle networks successfully required properties extract ac simply replac  leading signiﬁcant improvements ofﬂine compile ing conjunctions multiplications disjunctions ad  time online inference time explain each ditions negative literals constant  positive lit  providing overview cnf erals replaced real–valued variables encode  factoringcompilation algorithm darwiche   decoding process shown figure  darwiche                                                         details                                                          factoring algorithm logical version    technique “zero compression” employed ex recursive conditioning rc algorithm darwiche  ploit determinism jointrees requires inference  jointree ﬁrst prohibitive case        similar algorithms used recently solve probabilis                              table  networks experimented       network   max clust  vars  card  ave card  total parms max cpt parms ave cpt parms  det   dp       alarm                                                                       bm                                                                       diabetes                                                         hailﬁnder                                                              mildew                                                        mm                                                                        munin                                                               munin                                                               munin                                                               munin                                                               pathﬁnder                                                            pigs                                                                     students                                                                   tccf                                                                    water                                                                                                                                                                                                                                                                                                                                                       decode                            reduce                                                                                                   va  vb  vd ¬vd  vc  ¬vc  ¬vb                                                           figure  nnf left encoded ac middle simpliﬁcation ac right    principle use rc compile bayesian network duction cnf allows naturally accommodate  directly ac bypassing cnf encoding types cpt structures decision trees rules  approach use allows capitalize state need algorithmic change reduction  art logical reasoning handling determinism csi cnf factoring corresponding techniques lead quite  incur overhead factoring pro bit overhead cases justiﬁed  cess particular cnf factoring algorithm uses unit compiling network  resolution propagate logical constraints conﬂict directed ac application techniques lead smaller  backtracking recover efﬁciently conditioning acs compile time amortized online  variable settings lead contradictions addition queries illustrate beneﬁt concretely  clause learning means avoiding contradictions experimental results section  early future conditioning provides ﬂexi  ble framework exploiting csi through use tech  encoding parameter equality  csi  niques detect non–structural decompositions  subproblems independent condi cpt depicted figure   parameters   tioning speciﬁc variable values—such independence distinct equalities parame  detected based structural considerations net ters imply context–speciﬁc independence  work topology removing clauses example equality parameters rows  −   come subsumed conditioning disconnecting rows  −  imply independent given  subsets cnf speciﬁc variable values second  equality parameters rows   uses non–structural caching scheme allows  imply csi  prove equivalence subproblems speciﬁc variable purely encoding viewpoint clearly want  values avoiding multiple factorings exploit parameter equality reduce number  subproblem equivalences proven boolean variables generate table  shows ex  use structural considerations finally tent parameter equality help regard                                                        particular table reports dp percentage distinct  tic inference using sat bacchus et al       parameters non–extreme parameters percentage parameters remain each cpt  informed factoring algorithm  collapsed equal non–extreme parameters single pa cnf factoring algorithm employs key techniques  rameter dramatic example pathﬁnder half discussed earlier ﬁrst variable splitting  parameters extreme half thought doing case analysis second caching   distinct cpts addition gener avoid factoring cnf subset multiple  ating smaller cnfs encoding parameter equality allows times variables algorithm ends splitting  compiler run overhead generate smaller affect running time size factoriza  acs parameter equality provides opportunities tions generates complexity caching  factoring immediately translates gains online scheme proportional number variables appearing  ference                                              cached cnf subset state variables    key observation parameters used generate keys uniquely deﬁne cnfs fol  cpt appear mlf term lowing observations state interesting properties cnf  correspond incompatible network instantiations ob encodings passed factoring algorithm sig  servation suggests use boolean variable niﬁcantly improve splitting caching processes  represent multiple parameters assuming param clauses share parameter variable  eters equal values appear cpt share indicators network variable  idea work applied prev consider property presence indicator clauses allow  cpt figure  use variable θ cnf factoring algorithm restrict splitting indicator  represent parameters θcab θcab  variables sufﬁcient decompose prob  equal  following pi clauses lem independent components splittingcase  cnf θ ⇒ λb θ ⇒ λb  inconsistent analysis needed parameter variables second given  clauses generally pi clauses assert parameter structure indicator ip clauses state indicator  implies corresponding family instantiation variables sufﬁcient characterize state parameter  simply use boolean variable represent equal variables property allows involve indicator  parameters implying inconsistent family instan variables generating cnf keys during caching pro          tiations                                             cess optimizations exploited    solution adopt drop pi clauses encod simply identifying parameter variables factoring algo  ing note dropping pi clauses introduces additional rithm  intended models cnf allowing mlf terms technique used ex  contain multiple parameters cpt unin periments involves construction decomposition tree  tended modelsterms easily ﬁltered during dtree given bayesian network converting  decoding process given following             dtree cnf encoding dtree bayesian net  theorem  consider bayesian network variables work simply binary tree leaves correspond  let ∆ cnf encoding includes indicator ip network cpts darwiche dtree cnf  pi clause sets let Γ cnf encoding binary tree leaves correspond cnf clauses  cludes indicator ip clause sets ∆’s models each clause cnf encoding generated cpt  cardinality subset Γ’s models convert network dtree cnf dtree simply  σ model Γ ∆ σ’s cardinality  unfolding dtree node corresponding cpt sub  unintended models higher cardinality tree leaves correspond clauses generated  original models cardinality cpt main point technique efﬁciently  turns Γ nnf satisﬁes decomposability generate dtrees large cnf encodings gener  terminism smoothness linear time obtain ated bayesian networks small number cpts  nnf Γ models exactly minimum cardi happens network contains large cpts  nality models Γ satisﬁes required properties  optimizations  darwiche safely drop pi clauses  long minimize resulting nnf decode cnf encodings utilize additional enhancements  ac                                                   described deﬁne new type    including indicator ip clauses clause called eclause syntax  safely represent equal parameters cpt regular clause stronger semantics asserts exactly  single boolean variable cnf encoding literals true use eclauses representing  pathﬁnder network example drops number dicator clauses reducing size cnfs consid  boolean variables needed represent non–extreme param erably networks having multi–valued variables  eters      reduction similar outﬁt dpll procedure used factoring cnf  ductions obtained networks table  work directly eclauses having unfold  show later does technique improve regular clauses optimization example  compilation time lead signiﬁcantly smaller acs indicators parameters corresponding state                                                        root variable logically equivalent making possible    restricted case encoding parameter equality discussed delete parameter variables corresponding ip  darwiche                                   pi clauses establish equivalence
