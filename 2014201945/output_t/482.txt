       dynamically weighted hidden markov model spam deobfuscation               seunghak lee                      iryoung jeong                    seungjin choi        department chemistry           department       department science           postech korea                    science education                 postech korea          boypostechackr              korea university korea           seungjinpostechackr                                         crexcomedukoreaackr                        abstract                          effect limited approaches involve various                                                        search strategies viterbi decoding timeconsuming      spam deobfuscation processing detect obfus task hmms contain large vocabulary       cated words appeared spam emails convert words beam search algorithm jelinek  speeds      original words correct recog viterbi decoding eliminating improper state paths      nition lexicon tree hidden markov model lt     trellis threshold limitation      hmm recently shown useful spam      performance gain large number states involved      deobfuscation lthmm suffers      states number states      huge number states desirable taken account algorithm      practical applications paper present    spam deobfuscation important preprocessing task      complexityreduced hmm referred dy      contentbased spam ﬁlters use words contents      namically weighted hmm dwhmm         emails determine incoming email spam      states involving emission probability                                                        instance word ”viagra” indicates email      grouped superstates preserving state containing word likely spam spam      transition probabilities original hmm dw mers obfuscate words circumvent spam ﬁlters inserting      hmm   dramatically reduces number states                                                        deleting substituting characters words      state transition probabilities determined troducing incorrect segmentation example ”viagra”      decoding phase illustrate  written ”vigraa” spam emails examples      vert lthmm associated dwhmm                                                        obfuscated words real spam emails shown table       conﬁrm useful behavior dwhmm       important task successful contentbased spam ﬁl      task spam deobfuscation showing signiﬁ tering restore obfuscated words spam emails origi      cantly reduces number states maintain nal ones lee ng lee ng  proposed method      ing high accuracy                            spam deobfuscation based lexicon tree hmm lt                                                        hmm demonstrating promising results    introduction                                       lthmm suffers large number states   large vocabulary problems hidden markov  models    states desirable practical applications  hmms addressed various areas hand  writing recognition koerich suen                                                           table  examples obfuscated words spam emails  speech recognition jelinek  vocabulary size  increases computational complexity recognition                                                                tains forwa rdlook ing sta tements  decoding dramatically grows making recognition                                                                contains forwardlooking statements  impractical order solve large vocabulary problem  various methods developed especially speech     th’e lowest rates thkhe  handwriting recognition communities                      lowest rates    example approach reduce lexicon size     dsclamerbelow  using side information word length word    disclaimer  shape method reduces global lexicon  subset true word hypothesis dis paper present complexityreduced structure  carded alternative approach reduce search space hmm solution large vocabulary problem  large lexicon initial characters shared core idea group states involving emission  lexical tree leading redundant computations com probabilities number superstates pre  pared ﬂat lexicon words simply cor serving state transition probabilities original hmm  rected methods reduce computational complexity proposed complexityreduced hmm referred dy  lexical tree large number nodes namically weighted hmm dwhmm state transition                                                    ijcai                                                    probabilities dynamically determined using data struc         ysp yq  ture contains state transition probabilities                                                        dwhmm number states reduced   original hmm decoding phase illustrate                                                          construct dwhmm given lthmm reducing                                                          data structure Φ shown right  number states dramatically explain conditions                                                        figure  constructed order preserve state transi  equivalence dwhmm lthmm apply                                                        tion probabilities deﬁned original hmm each node  dwhmm    task spam deobfuscation emphasizing                                                        Φ labeled superstate belongs  reducedcomplexity performance                                                        state transition probabilities stored following origi                                                        nal hmm    dynamically weighted hidden markov     model                                                                           hidden markov model simple dynamic bayesian net                      work characterized initial state probabilities state                   transition probabilities emission probabilities notations                                                                                         sq  hmm follows                                                                                       individual hidden states hmm denoted                                                                                   qqqqk wherek number states                                                       hidden state vector time denoted qt ∈                          observation symbols belong  ﬁnite alphabet                                                                 hmm                  number distinct ob                                   qq      servation symbols observation data time                                                                                                           ∈ rm                                                                  qq     qq      noted                                                                                   qq                                                                                                                                                                             qq qq    state transition probability state state                                                                                                                      Πq                                     qjqi                                                                          deﬁned                                                                                                                                                  emission probability observation symbol yi                                                                                                                                        given state qj denoted yiqj                                                                                                                                   initial state probability state denoted                                 qq             Π                                                                                   deﬁnitions hmm characterized joint dis dwhmm                        Φ  tribution states qt  qqt  observed sym  bols yt  yyt  factorized form figure  transition diagrams state hmm asso                                                        ciated state dwhmm data structure areshown                              t                                                               Φ                         original hmm contains  different states  different     Π            t−       emission probabilities nodes emission                                                                                     probabilities colored grayscale dwhmm    ﬁrst illustrate dwhmm simple example contains  different superstates data structure Φ  figure  shows transition diagram state hmm constructed way transition probabilities  associated dwhmm  consists superstates preserved dwhmm  sands example original state hmm  shown figure  distinct emission trellis state dwhmm shown figure   probabilities                                  transition probabilities determined searching Φ using                        yq                                                      hypothesis st show relation dwhmm              yqp yqp  yq              hmm deﬁne superstate sequence dwhmm                                                        st  corresponding state sequence hmm qt              yqp yqp  yq                       yq                                                                   yqip ysi   ≤ ≤    states involving emission probability                                                        figure  hypothesis state hmm cor  grouped superstate denoted dwhmm                                                        responding  ssss state sequence  shown left figure                                                           qqqq given observation sequence  case construct dwhmm containing  superstates                                                         joint probabilities state  sands following satisﬁed                                                        sequence observation sequence follows                   ysp yq                                                                                             ysp yqp  yqp yq                                                          Πq                ys     yq     yq    yq                                      t−                                                                                                                            ijcai                                                                                                                                                    observation                                                                                   Πs                                                                                                              ss                                                                                                                                                superstates                                                                                                                                                                                        ss                                                                                           hypothesis  ss                        ss                                                 ss                                                                                                                                                                        Πs                                                                     ss                                                                                                                                                         Φ                                                                                                                                                                                                                                                                                                                                                                           figure  trellis state dwhmm converted state hmm transition probabilities determined searching  data structure Φ hypothesis st search process time instance represented line Φ                                                            yyt  hmms equals corresponding                                                                                                                                      superstate sequence                                                                 observation sequence yt converted dwhmms  yΠsp ys stst−p ytst                                                    follows                                             state sequence corresponding          qt  yt st  yt   emission probabilities involved joint probabilities state transition probability dwhmm deﬁned  equal follows                                     follows                     yqp ys                                                                                                                      st does match                   yq    ys                                                        stst−           paths Φ                   yqp ys                                      ωst                     yqp ys                    st state sequence decoded far st                                                             ω  dwhmm    searches Φ hypothesis st deter      t−     weight function  mining transition probabilities follows       returns transition probabilities Φ weight function                                                        ωst traces hypothesis stinΦ returns state                                                                                              ΠsΠq                        transition probability  t− stored node vis                                                        ited st example figure  ωs determines                  ssp qq                                                        state transition probability ss  line                  ssp qq                  Φ shows ωs traces hypothesis sandre                                                                                                    ssp qq                  turns transition probability    stored node                                                        value qq shown  equalities state hmm state dw figure  node contains state transition probabil  hmm joint probability follows       ities choose correct according node vis                                                              −                                         ited    noted dwhmm determines                                       transition probability searching data structure Φ    searching probability stst− assume hmms ﬁnd transition probability matrix  state sequence st unique Φ constraint dwhmms converted hmms following  strong state sequences characteristics dwhmms useful hmms  exactly emission probabilities each state large state transition structure com  possible model redundant paths mon emission probabilities number states  usual constraint kept hmms      lthmms convert hmm    associated     joint probability state sequence qt      dwhmm computational complexity signiﬁcantly  qqt  observation sequence yt    creases number states dramatically reduced                                                    ijcai                                                    second need maintain transition probability hmm  matrix weight function dynamically gives transition  probabilities decoding phase dwhmms  ﬂexible easy add delete change states  state transition structure data structure Φ                                                                                                 needs updated fourth speed accuracy                          ﬁgurable using beam search algorithm nbest search  jelinek  respectively securing desirable perfor                                                                            mance                                                                                  conversion algorithm  convert hmm  dwhmm make set      figure  representation selftransitions hmms Φ  superstates states hmm repre  sent unique emission probabilities consists  small number superstates original hmm’s   conditions equivalence  state transition structure large dwhmm conversion process dwhmm conserves transition  efﬁcient hmms example lthmm good   emission probabilities difference  candidate convert dwhmm hmm associated dwhmm use  states unique emission probabilities contains straightforward viterbi algorithm figure  illustrates trellis  large trie dictionary following explains algorithm                                                        dwhmm   state state path  converting hmm dwhmm                                                        sss propagate sss                                                        smaller probability sss path                                                        sss discarded purging step viterbi algo  algorithm conversion hmm dwhmm                rithm case hmm shown figure                                                          state state paths qqq qqq                                                        propagate time instant    make set superstates unique emission                                                        states      probabilities  sssk  hmm      step number states hmm reduced ensure results dwhmm hmm      shown figure                                 adapt nbest search dwhmms choose                                                        best path time instant trellis figure                                                         shows twobest search makes hypotheses    loops selftransitions hmm  state paths sss sss      add additional superstates example si kept propagate      loop additional sj state makes      possible distinguish selftransitions                                                                                       nonselftransitions                                                                                     construct dwhmm   associated hmm                                                                                         using superstates state transitions                                    superstates exists state transition                                                                                      hmm superstates      example figure  state dwhmm state          figure  trellis dwhmm      transition transition      state hmm                                                                                       make data structure Φ deﬁne weight function      ωst gives transition probability                           dwhmm    Φ contains transition structure                              hmm   stores transition probabilities each node                                making Φ selftransitions hmm changed                             shown figure  superstate loop      transitions additional superstate step                          transitions states original state      goes structure Φ state transition struc        figure  trellis hmm      ture hmm different selftransitions                                                          figure  illustrates case twobest search useful    deﬁne emission probabilities dwhmm’s super lthmm denote physical property states      states corresponding states nodes showing states emission                                                    ijcai                                                                                                 observation symbols model lee ng                                                        transition probabilities dwhmm determined                                                                                  decoding phase weight function equipped Φ                                               data structure lexicon tree containing transition                                                        probabilities lthmm null transitions allowed                                                                                  transition probabilities determined                                               weight function recovers deletion characters                                                        data                                                  set individual hidden superstates dwhmm                                                        converted lthmm follows                                                                                                figure  trellis twobest search                                                                                  initial state states ss  probability qn initial ﬁnal state lt match states states ss insert states  hmm respectively assuming exist hypothe ﬁnal state match state superstate representing  ses  qaba qacathelthmmallow    letters english alphabet insert state  propagate dwhmm state stems selftransitions lthmm  preserve use onebest search selftransitions lthmm reﬂect insertion characters  states labeled ”a” lthmm grouped super obfuscated words state named insert state  state hypothesis selected  ﬁnal state state represents end words  case dwhmm answer’s state sequence transition probability dwhmm follows  acaciaq                      aba                                       hypothesis                                  st does match             chosen  fail ﬁnd answer address stst−         apreﬁxinΦ  problem nbest search adapt twobest search             ωst                aba aca  hypotheses                 able propa  structure Φ using lexicon tree each node  gate preserving hypothesis answer Φ transition probability lthmm    hmm converted dwhmm exactly                                                                                       hypothesis starts  initial  sults adapt nbest search maximum state decoded dwhmm converted lthmm  number states hmms compose superstate initial state appear times  propagate time instant practi                                                      hypothesis input data sentence reduce  cal purposes does need large application computational cost searching Φ use sub  spam deobfuscation shows dwhmm works                                                               sequence search Φ possible reach    just                                   node Φ subsequence starts initial state                                                        time instant                                                          deobfuscate spam emails choosing best path                   baca                                 ing decoding algorithms given observation characters                                                        example given observation characters ”vi” best                                                      state sequence ssss chosen represents                   cacia                                ”via”                                                          deﬁne emission probabilities follows                                              qn                                                            st st match state                                                                                                                                  ρ   corresponding character            zebra                                                                                                                          ρ  yt similar character                                                                   ρ   figure  transition diagram lthmm using twobest                                                                 ⎧t insert state  search associated dwhmm able states        σ                                                                   ⎨⎪    corresponding character  labeled ”a” time instance                                     similar character                                                                                                                            ⎩⎪     letter english alphabet                                                                  σ     application                                                          ytst st ﬁnal state  lexicon tree hidden markov modellthmm spam                                                                        ψ  yt white space  deobfuscation proposed lee ng lee ng                                                               ψ  yt letter english alphabet          consists  states  observation sym  ψ   bols english alphabet space  standard noncontrol ascii characters transform lt consecutive character deletion considered  hmm dwhmm consists  superstates severe harm readability                                                    ijcai                                                    
