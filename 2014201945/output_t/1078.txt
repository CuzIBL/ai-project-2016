              grounding abstractions predictive state representations                 brian tanner    vadim bulitko     anna koop     cosmin paduraru                                     department computing science                                   edmonton alberta canada tg                              btanner bulitko anna cosmincsualbertaca                          abstract                          deﬁne compared construction tower                                                        babel mcdonald et al  likewise manually      paper proposes systematic approach rep notating modern games simulations prohibitively time      resenting abstract features terms lowlevel consuming errorprone      subjective state representations demonstrate    paper makes contributions aforemen      mapping agent’s predictive state tioned problems propose automated approach      representation abstract features derived learning mapping agent state representations      automatically highlevel training data sup  humandeﬁned abstractions using small set data labeled      plied designer empirical evaluation   human expert use “i know it” ap      demonstrates experienceoriented state rep proach deﬁning abstract features instead programmat      resentation built singlebit sensor rep ically deﬁning assigning values abstract features      resent useful abstract features “back human expert examines number examples labels      wall” “in corner” “in room” result appropriately machine learning classiﬁcation algo      agent gains virtual sensors used                                                                                   rithm quinlan   create classi      control policy                            ﬁer appropriately label novel future experiences                                                          approach useful important    introduction                                       agent’s state representation allows values abstract                                                        features generalize labeled examples  useful intelligent agents reason level unseen data argue agents using subjective grounded  abstract perceptions abstractions aggregate representations suited making generaliza  sensory situations single conﬁguration abstract tions subjective grounded approach represents agent’s  features allowing behavior expressed abstract terms state terms experience sensors effectors  generalize similar situations generalization al speciﬁcally use predictive representation state  low humans designers encode control policies closer agent’s state stored vector probabilities outcome  level human reasoning instance using abstractions sensations given various sequences action littman et al  agent’s designer deﬁne policy “avoid navigating  believe concise vague abstractions  through open areas” “don’t stop near doorway”   characterized patterns interaction abstractions    desire write control policies abstract terms learned terms predictive representation portable  thwarted policies implemented novel situations similar patterns interaction  set state variables sensor readings available small navigation domain demonstrate  agent simulation option directly augment agent using simple classiﬁcation algorithm learn  environment highlevel information each tree identify intuitive abstractions like backtowall corner  forest annotated possible cover soldier narrowcorridor room using subjective  agent paull darken  access environ objective state representations show  ment available programmer write code map subjective case learned classiﬁer allows agent iden  lowlevel state coordinates obstacle detectors tify abstractions novel environment ad  higherlevel abstract terms narrow corridor ditional training  unit sideways orkin     realism simulations used reallife training  background related work  education dini et al  increases approaches  expensive number abstract features typical situated agent framework agent decision  underlying software engineering needed maker interacts environment series time steps                                                        agent receives perceptions observations envi    work supported rlai nserc icore ronment each moment responds actions  alberta ingenuity                                affect environment paper model world                                                    ijcai                                                    partially observable markov decision process pomdp ple consider mdp navigation task state  assume each discrete time step set data represented using three discrete variables x θ ﬁrst  called state sufﬁcient make accurate proba variables x y represent location θ denotes ro  bilistic predictions future experience markov assump tation orientation coordinate abstraction  tion state directly observable agent φi identify northeastcorner deﬁned  observation received environment correspond states  units   corner environment  multiple different states                         case                                                                         standard pomdp model represents agent’s current                                                                          ∈    ∈     state probability distribution set unobservable φix θ                                                                           situations agent each unobserv  able situations called nominal state distributions generally refer outcomes abstractions ab  nominal states called belief states pomdps use stract features abstract features allow control algorithm  ditional probability rule nominal state transition model make useful generalizations behave similarly states  observation model update belief state each new different state variable combinations similar abstract  action observation transition observation mod features example agent know north  els usually determined human expert later eastcorneris good place recharge batteries  parameters optimized data    alternatively historybased methods model partially  representing abstractions  observable environments considering ﬁxed vari useful abstract features invented human ex  able length window recent interactions environ pert leveraging knowledge particular domain task  ment mccallum                                 matter agent’s representation abstract fea    predictive state representations psr type tures understood expert’s terms mechanism  representation model observable partially reliably converts agent’s state repre  observable environments littman et al  instead sentation abstract features usually exten  focusing previous interaction environment sive software engineering effort involving lengthy tuning  predictive model represents state set predictions trial error paull darken  games virtual  future interactions psr agent’s state repre reality trainers resulting abstraction referred  sented answers questions future experience simply “sensors” orkin  “situation awareness  world example element state representation components” kunde darken   “what probability receiving sequence agent’s state representation strong impact                 observations     sequence actions complexity robustness script converts           ” singh et al  proved linear predic agent’s state abstract features instance abstract fea  tive state representations represent environments tures backtowall narrowcorridor  represented ﬁnitestate pomdp ﬁnitelength difﬁcult concisely deﬁne function x θ  history method                                       features value  various disjoint locations    psr components structure parameters map making values difﬁcult know explicit  structure set events psr makes predictions reasoning walls obstacles contrary  called core tests each core test predicts prob predictive representation stores state predictions  ability observing particular sequence observations future perceptions succinctly capture abstrac  particular sequence actions chosen agent tions terms patterns interaction environment  parameters used update core test values each  new action observation algorithms proposed  learning abstractions                                             learning psr parameters singh et al  dis propose machine learning approach automatically  covering learning psr structure parameters ﬁnding mapping agent’s state representation                             mccracken bowling                           expert’s understanding abstract features expert                                                        look number situations appropriately label ab    abstractions                                       stract feature values each case set labeled                                                        examples training set example case  state representation stores each state conﬁguration mobile agent expert looks map particular envi  variables traditional mdp state represented ronment labels examples agent narrow  single discrete variable unique value each state corridor agent uses offtheshelf machine learn  state space pomdp state represented                                  ∈            ing algorithm decision tree learner learn set  vector continuousvalued variables       classiﬁer takes state variables inputs emits abstract  number underlying nominal states linear psr feature values outputs  state vector continuousvalued variables ∈    number core tests    paper abstraction manytoone operator φ  experimental results  maps conﬁgurations state variables sin demonstration chose simple model path  gle conﬁguration different set variables exam ﬁnding environment allows evaluate approach                                                    ijcai                                                                                            room                                          corridor                                               figure  map used train agent’s virtual sensors  recognize various abstract features                                                                 room  speciﬁcally agent actions single corridor  binary observation situated discrete grid environ  ment cells open blocked  agent occupies exactly cell possible orien  tations left right agent’s actions figure  map used testing agent’s virtual sensors  forward turn left turn right  backward  agent moves forward backward collides example consider predictive state representation  obstacle agent’s position remains unchanged                                                        core tests core test deﬁned seeing   time step agent’s sensor reports  agent faces                                                                                       executing action  value   blocked cell                           agent facing obstacle reach    chose make grid world deterministic actions                                                        step forward core test deﬁned seeing     succeed determinism greatly simpliﬁes perfor                                                        executing value   mance measures visualization experiments agent obstacles right left  weakening results                                side deterministic environment core test    use different maps experiments ﬁrst value   micro representation  map figure  total  reachable grid locations                                                        states     orientations each total  states                                                         tests compactly denoted  second environment map figure  total  rrr  reachable grid locations orientations each construct psr representation accurate  tal  states                                  pomdp model environment using adaptation  state representations                                 algorithm introduced littman et al creating lin  agent uses different state representations ear psrs pomdp models  psr construc  based objective coordinates x θ tion algorithm polynomial algorithm uses depthﬁrst  predictive representation discussed ob search ﬁnd set psr core tests values  jective x θ coordinate useful characteriz pomdp nominal states straightforward adapta  ing certain abstractions tied physical location tion littman et al’s algorithm uses breadthﬁrst  map certain areas map certain abstract fea depthﬁrst search yielding considerably shorter core tests  ture value “in room” classiﬁer learned abstract features     x θ        state correctly classify states chose abstract features experiments ranging  room training examples formally succinctly deﬁned backtowall  agent seen examples particular room classiﬁer vague room  means identify identical size  shape room seen previously               backtowall  feature agent    agent’s predictive representation vector test val hit wall backward action taken  ues each test value corresponds probability  test’s observations matching generated environ  corner feature grid location  ment conditioned test’s actions executed   corner blocked grid cells meet                                                    ijcai                                                      room  feature agent room        data used training      difﬁcult feature program manually                                      fact “room” vague humanlevel concept                  room      approach circumvent problem simply al  baseline  ±   ±   ±       lowing human designer label certain states room x θ  ±   ±   ±       formally deﬁning figures            tests  ±   ±   ±                                                                            backtowall    narrowcorridor   feature cell baseline  ±   ±   ±       wide corridors labeled human designer  x θ  ±   ±   ±       room  abstraction labeled entirely consis  tests  ±   ±   ±       tently environments      subjective decisions human designer  table  accuracy classiﬁer learned x θ repre                                                        sentation classiﬁer learned  core test psr    finally grid cells labeled “neither” room backtowall abstract features test      expert knew classiﬁed room training data sets disjoint      narrowcorridor abstract      feature label                                                        discussion    experiment   x θ vs psr map        expected x θ classiﬁer generally ac                                                        curate psr classiﬁer room feature surpris  experiment compare classiﬁcation accuracy ingly small amounts data psr classiﬁer actually  decision trees learned varying amounts training accurate indicates subjective state repre  data single map map using representa sentation able identify canonical examples  tions hypothesize training examples room feature little data  x θ representation generally perform better ab testing backtowall feature psr clas  stract features characterized spatial locality siﬁer substantially better x θ classiﬁer  room feature conversely expect predic backtowall characterized simple pat  tive representation perform abstract features tern interaction occurs various locations  characterized patterns interaction map orientations makes ideal candi  towall                                             date represented subjective representation                                                        stead coordinatebased decision tree  experimental method                                   learned psr classiﬁer  core tests notice                                                        ably lengthier  leaf nodes manually crafted clas  states map labeled positive negative                                                        siﬁer  leaf nodes believe  examples each abstract feature agent uses                                                        overﬁtting experiment run  similar quinlan  classiﬁcation algorithm                                                        towall  feature using fewer core tests  fewer  create separate decision tree each abstract feature                                                        node decision tree figure   representations using weka machine learning software  package witten frank  experiments  reported results psr created using subset                                                                               core tests generated pomdp psr conversion al                            gorithm subset ﬁrst tests algorithm              using set thousands core tests simply nec                                     essary various sample sizes                                                                                                                       examples randomly sampled map             wall  training set examples left used  test set classiﬁer learned training set                   applied test set classiﬁcation accuracy measured                                                                                                                                                                     wall  proportion positive examples negative examples               wall  quite biased results report accuracy  baseline classiﬁer simply predicts majority class  training data precision recall speciﬁcity statis figure  decision tree classiﬁer backtowall fea  tics measured reported exhibited ture learned using predictive state representation   similar trends accuracy procedure repeated  fewer core tests  times mean standard deviation accuracies  reported    experiment performed abstract fea  experiment  transfer using psr  tures present results represent end experiment investigate degradation classiﬁ  performance spectrum room backtowall   cation accuracy decision tree learned training data  shown table                                      map used predict abstract feature values                                                    ijcai                                                    map good performance map evidence classi results table  produced using classiﬁer  ﬁer learned subjective state representation suc learned different numbers core tests tests  cessful novel experiences share patterns interac ﬁrst breadthﬁrst search meaning  tion previous experiences note com quite short ask questions states im  pare psr classiﬁer’s ability transfer x θ classi mediate neighborhood abstract features  ﬁer experiment x θ decision tree towall narrowcorridor corner char  basis used different map x θ acterized short tests evidenced high accuracy  locations abstract features highly mapspeciﬁc  test psr  translation rotation invariant    perform set experiments using varying amounts  core tests features classiﬁer anticipate  abstractions backtowall corner  easily identiﬁed small number short tests features  vague larger area abstractions like room narrow  corridor  require longer tests hypothesis  holds accuracy room narrowcorridor ab  stractions worse classiﬁers built using fewer  core tests better core tests used  experimental setup  states map labeled positive  negative examples each abstract feature like previous  experiment agent uses algorithm induce  decision tree classiﬁers training set case  states map decision tree tested  examples map agent access  available training testing data single learning  trial used standard deviation values reported  table  present results using      core tests    results labeled baseline correspond predicting  value abstract feature occurred frequently  training data accuracy classiﬁer  information each training example  label                                                        figure  errors identifying value abstract feature             room    corridor    backwall    corner                                                        room grid locations marks indicate errors ranging   baseline                           small circles error single orientation large circles error    tests                          orientations    tests                          tests                                                                               rows table     tests pro    tests                                                                            vide empirical support conjecture larger area ab  table  accuracy psrbased decision trees training stractions need longer core tests classiﬁcation  map testing map various amounts tests accuracy room abstraction increases substantially                                                        core test values provided classiﬁcation algo                                                        rithm number leaf nodes decision tree grows  discussion                                             leaves  core tests   ﬁnally   transfer results shown table  show accuracy    core tests respectively  decision trees abstract features tested indicate sheer volume tests improv  map accuracies good close perfect ing quality classiﬁer tests used makes  exception room abstraction room par difference accuracy classiﬁer  ticularly hard vague small classiﬁcation accuracy lost  room  feature locally aliased places moved  core tests presumably low ra  map labeled room look similar areas tio features training examples allowed classiﬁer  map labeled room evident overﬁt training data  left middleright rooms figure  rooms figure  shows location misclassiﬁed room feature  sections look locally like double wide map decision tree induced  tests makes mis  area map figure  labeled takes cells appear locally similar opposite  room                                             labeling map decision tree misclassiﬁes certain                                                    ijcai                                                    
