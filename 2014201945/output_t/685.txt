                   local search balanced submodular clusterings                        narasimhan∗†                                   bilmes†                           live labs                            dept electrical engg                     microsoft corporation                      university washington                     redmond wa                                seattle wa                 mukundnmicrosoftcom                      bilmeseewashingtonedu                        abstract                          distances submodularity allows model decom                                                        posable criteria allows model complex crite      paper consider problem produc ria problem criteria      ing balanced clusterings respect submodu quite sensitive outliers algorithms      lar objective function submodular objective func optimize criteria produce imbalanced parti      tions occur frequently applications  tions parts clustering smaller      problem broadly applicable show wish impose balance constraints      results patkar narayanan  attempt tradeoff optimizing jk balance      applied cases submodular function  straints paper show results patkar      derived bipartite objectfeature graph narayanan  derived graph cuts broadly appli      case efﬁcient ﬂow    cable submodular function lead efﬁcient      based algorithm ﬁnding local improvements    implementations broad class functions based      show effectiveness approach ap bipartite adjacency apply clustering words      plying clustering words language  language models      models                                                           preliminaries prior work                                                                                    Γv  →     introduction                                       let   ground set function        deﬁnedon                                                        subsets said increasing Γa ≤ Γb  clustering objectsdata important problem ⊆ said submodular ΓaΓb ≥  machine learning applications Γa ∪ bΓa ∩ symmetric ΓaΓv  aand  guises unsupervised learning vector quantization di normalized Γφ normalized increasing sub                                                                                                      mensionality reduction image segmentation clus modular function Γ →  function Γc  →  tering problem formalized follows given ﬁnite deﬁned ΓcxΓxΓv x−Γv  symmetric  set criterion function jk deﬁned partitions submodular function function called connectivity  parts ﬁnd partition parts sssk function Γ normalized symmetric submodu  jk sssk maximized number                 ΓcxΓcv    xΓcx                                                          lar think  kclusters size nkdata set roughly  cost “separating”  Γc  exhaustive search efﬁcient solution itwas submodular polynomial time algorithms ﬁnding  shown broad class criteria submodular deﬁned nontrivial partition  minimizes Γcsuch  allows application recently discovered normalized symmetric submodular functions arise naturally  polynomial time algorithms submodular function mini applications example widely used graph  mization ﬁnd optimal clusters submodularity cut criterion  malization notion diminishing returns powerful set partitioned set vertices                                                                                                           way modeling quality clusterings rich graph ve edges weights  →  model important criteria including graph cuts mdl proportional degree similarity  single linkage traditionally clustering algorithms ends edge graph cut criterion seeks partition  relied computing distance function pairs vertices parts minimize sum  objects directly capable incorporating weights edges broken partition  complicated measures global quality clusterings ⊆ let  quality just decomposable function individual                                                          γx   set edges having endpoint    ∗     work author univer δx set edges having exactly endpoint  sity washington supported microsoft  search fellowship                                     example             reddark    †this work supported nsf grant iis shaded set figure left γx  intel corporation grant                                       set edges                                                    ijcai                                                                                                                                                                                                                                  f∈γx     shown normalized                                                        creasing submodular function positive weight func                                                                                                                            tion wf  → andΓcxΓxΓv       x− Γv                                                         measures weight common features ex                                                                                                                                                        ample shown figure right                                                      reddarkshaded set γxa eand                                                        δxb                                                                    refer bipartite adja                                                     cency cut criterion                                                                  Γ                                                        symmetric submodular use                                                        queyranne’s algorithm  ﬁnd optimal partition                                                                                                                     time ov   problems approach                                                                                                                                                algorithm scales   imprac                                                                   figure  left undirected graph cut criterion Γcx tical large second problem  sum weights edges  right criterion quite sensitive outliers tends  bipartite adjacency criterion Γcx number produce imbalanced partitions parts  elements features adjacent  substantially smaller example                                                        graph vertex weakly connected                                                        rest graph graph cut criterion produce  dashedred solidblack δx partitioning just vertex partition  set solidblack edges         applications quite desirable produce clusters  easy verify positive weights somewhat balanced inherent tension                                        assign edges we  →     function  tween desire balanced clusters desire mini                                                                                            Γ  Γxweγx          e∈γx normalized mize connectivity clusters                                                                                     Γ   increasing submodular function function like minimize connectivity  making sure                                                        clustering balanced similar criteria  Γcxwe   δx  weγxwe   γv x−wee     capture optimization goal    normalized symmetric submodular function                            Γ                                                                                  refer undirected graph cut criterion         ratiocut         ·     paper particularly interested slightly                        different function falls framework                          Γc                                                             normcut vv  left bipartite graph right                minwv  vwv  graph think objects set fea  tures objects posses example  vocabulary words features words criteria clearly closely related unfortunately  including possibly context words occur minimizing criterion npcomplete andsowe  examples include diseases symptoms species need settle solutions necessarily shown  subsequences nucleotides occur genome optimal normalized cut closely related  people preferences                     spectral clustering methods  spectral clustering    construct bipartite graph vfe edge used approximate normalized cut paper  object ∈ feature ∈ object present local search approach approximating normalized                                                     feature assign positive weights wv  → cut advantage local search techniques al                   wf  →    weight wf measures “im low utilize partial solutions preexisting clus  portance” feature weight wv used tering objects useful dynamic situations  determine balanced clusterings applica local search techniques produce sequence  tions natural way assigning weights solutions each better serve anytime  probability occurrence example algorithms timeconstrained situations  case ⊆  set                          run time available local search                                                        strategy employ allow make strong guar   γxf   ∈  ∩ nef   ∅                      antees ﬁnal solution produced local search   δxf   ∈  ∩ nef   ∅  ∩ nef   ∅ technique originally proposed patkar narayanan                                                         producing balanced partitions graph cut crite  ne· graph neighbor function words rion paper show results paper  bipartitions sets types  equally applicable submodular criterion  objects γx set features neighbors noted applicability general techniques  “type x” δx set features neigh submodular function does necessarily make practical  bors types object let Γxwf γx  contributions  show                                                        efﬁciently graph cut criterion reduction                                                    use notation function  → ﬂow problem problem show bipar                                    ﬁned edges function  →  modular exten tite adjacency criteria solved similar efﬁcient  sion deﬁned subsets                            fashion reducing different ﬂow problem                                                    ijcai                                                       local search principal partition           proposition  narayanan  proposition  let vv                                                                            ∪      ∩   φ  local search strategy generate sequence solutions bipartition                                                                φ   ⊂                    each solution obtained previous let   proper subset  satisfying  small perturbation case clustering partitioning                                                                             Γc − Γc   amounts starting bipartition  ∪       μg                                                                                     changing partition picking set moves                       set moves consider going bi                                                        ratiocut  ∪  ratiocut vv  partition vv bipartition uuwherethenew  partition obtained moving elements par                                                        proof assumption  tition example vv   ∪      ⊆                          amounts moving                                Γc − Γc   elements key local search         μg   max                                                                               φx⊆v          strategy good way generating                                          ⊆                                                              Γ  − Γ   pick       moving side                                 improve objective function section show                      wv  Γc submodular function principal par  tition submodular function deﬁned particular   used compute best local polynomial time  speciﬁc application discuss pa Γ  − Γ   Γ  − Γ                                                                       ≤            actually compute fast large data                 sets                                                                                bipartition  ∪ vandx ⊆ vlet                                                        Γcv  vwehave             ggain xΓc  − Γc                            ggain                                    Γc   Γc − Γc         averagegain                                                     ≤                          wv                                      wv   wv − wv                  μg  max   averagegain                          a−c                         φx⊆v                        observe ≤ b−d thenab − ad ≤ ab − bc                                                            figure left assign weight  edges ≥   vertices ≡  wv ≡  let                                                                      Γc   Γc   set bluelight nodes  set redshaded nodes                ≥                                                                                          wv   wv     ggain Γc  − Γc −  −                                                        dividing sides wv vweget  figure right bipartite graph                                                                                 Γ      ggain Γc  − Γc −                                                                                                 ratiocut vv  ggain measures change partition                   wv vwv  cost Γc ignoring balance constraints                   Γ                                                                             ≥                                            vv  really interested change normcut whichin                       wv  uwv  corporates balance constraint μg seen                                                                                        related rationormalized cut use solutions          equation   μg ﬁnd set moves local search algo                      Γ                                                                                        rithm section present results relate               wv  uwv ∪  changes       vv principal partition           normcut                                                                 ∪     submodular function Γc μg play                              central role principal partition submodular function            ratiocut  ∪  Γc consists solutions minx⊆v Γc − λ · wv  possible values λ ≥  shown    solutions possible value λ com similar strict result normalized cuts  puted polynomial time way entire  regularization path svm computed  corollary  assumptions previous  speciﬁcs computation procedure section  proposition  section present results relate                                                              normcut  ∪ ≤ normcut vv  lutions minx⊆v Γc − λ · wv solutions  μg max                                  φx⊆v averagegain                    proof wv wv equation     following proposition proven narayanan  follows Γc  Γc  consider cases   graph cut criterion generalizes immedi assume wv ≤ wv case  ately arbitrary increasing submodular function Γcin normcut deﬁnition equation   particular applicable problem interested  submodular function derived bipartite                Γc   Γc                                                               normcut vv          ≥  graph                                                                        wv   wv                                                     ijcai                                                                                                     proof suppose λ  μg φ   ⊆                                                         Γc   Γc                                                ≥                         v≤v  wv   wv                                                            Γc − Γc                                                                  λ  μg ≥            Γc                                                               wv                          Γc   Γc              wv                                   equality holding   follows            Γ                                    Γ   − Γ  ≤ λ ·                             ∪                                     ∪                                                                                          λ · wv − λ · wv                                                          wv positive                     Γc   normcut vv                                                    Γc − λwv ≤ Γc  − λ · wv                                                                         Γ    Γ                     ≥ max                         left hand side constant follows                           wv  wv ∪                                                          Γc − λwv ≤ min Γc  − λwv                     normcut  ∪                                 x⊆v    remaining case assume wv ≥ wv  using equation                        note equality holds   particular                                                          weget          Γc   Γc    Γc                                                          Γ  − λ ·   min Γ − λ ·          wv     wv    wv ∪                                                                                                                               x⊆v  follows                                                           Γc  − λ · wv                           Γ   Γ                                                                           normcut vvmax                                 taking         forward direction fol                           wv wv                                                           λ                                                      lows reverse direction suppose                            Γ    Γ                           ≥ max                                        wv  wv ∪         min Γc − λ · wv  Γc − λ · wv                                                           x⊆v                    normcut  ∪                                                        taking   xweget                                                           Γc   − λwv   ≥ Γc − λ · wv    previous results show ﬁnd non                                                         trivial solution maxφx⊆v averagegain  ﬁnd local improve normalized cut λ · wv − λ · wv  λ · wv   ratio cut ideally want show possible im                 ≥ Γ  − Γ     prove normalized cut ratio cut fact ﬁnd                               local improve current solution unfortu  wv  wehave  nately result  slightly weaker serves partial converse           Γc − Γc                                                             λ ≥  proposition  suppose φ   ⊂ satisﬁes α ·                wv   normcut vv ≥ normcut  ∪ α    wv       Γcvu   Γcv  ∪u thenw  ≤                                                         compute   solutions                                                        min      Γ − λ ·  proof appendix                                      x⊆v                ﬁnd lo                                                        cal let improve normalized cut    previous result shows existence set section show compute solutions  moved side let improve efﬁciently application  current value normalized cut existence  result need able compute set  computing principal partition  following theorem gives connection set  principal partition bipartite adjacency func proposition  tells partition vvthen  tion compute principal partition ﬁnd set φ   ⊆ satisfying μg  explicitly compute local improve Γcv−Γcvu                                                            wv     improve current partition  malized cut                                          moving partition propo  proposition  narayanan  proposition  λ    sition  tells ﬁnd subset ﬁnding λ  μg iff proper subset ⊂       min Γc − λ · wv  Γc − λ · wv   min Γc − λ · wv  Γc − λ · wv    x⊆v                                                   x⊆v                              Γc  − λ · wv                                Γc − λ · wv                                                      ijcai                                                                                                                                                                                                                                  ≈  polynomial time submodu grams words pr  pr   i−  lar function   section show n−                                                                prwiwi− · prwiwi−ni− prob                                                                                                    especially efﬁciently case reducing paramet lem number ngrams grows   ric ﬂow problem parametric ﬂow problems use                                                         set words vocabulary grows  results   solve ﬂow problem values exponentially obtain highconﬁdence  parameter time required solve single statistical estimates using naive methods alternatives  ﬂow problem ﬁxed parameter λ com      min     Γ − λ ·                       needed order learn reliable estimates  pute   x⊆v                 solving max ﬂow  ﬁnite size training corpora brown et al  suggested  problem network created follows add clustering words constructing predictive models                                                        based word classes cw class word             λ · wv          wf               approximate the probability word sequence                                                                    ≈    n−   cw  cw  ·                                                        k pr         pr    i−                      λ · wv          wf                                                                          prwicwi−cwi−n    case             λ ·                             number probabilities needing  estimated                                                                       n−                                                     grows       ·w     factored language                                                    models   generalize  use             λ · wv          wf               prwiwi−cwi−wi−ncwi−n  —    note                                                        conditioning wi− cwi− redundant             λ · wv          wf               backoffbased smoothing methods say                                                        instance wiwi− encountered training data             λ ·                                                              instance wicwi− encountered                                                                                                                                                             word     wi− wiw   figure  ﬂow network compute principal partition                cwcw        bipartite adjacency cut                        encountered           i−                                                         construct models datadependent way  source node connect nodes ∈ quality models depends crucially qual  edge capacity λ · wv add sink node  connect ity clustering section construct bipartite  nodes ∈  capacity wf shown adjacency graph use algorithm described  figure  remaining edges original graph generating clusters algorithm described  inﬁnite capacity maxﬂowmincut theorem ev paper generates partition clusters ap  ery ﬂow corresponds cut just examine cuts ply recursively form binary tree gener  network clear min cut ﬁnite ated clusters generate clusters stopping  ﬁnite cut edges number elements cluster goes prescribed  cut newly added edges ad value height tree exceeds prespeciﬁed  jacent  vertex ∈ limit bipartite graph use constructed follows  side cut neighbors copies words language model                                                                     ∈         ∈            cut value form wvv  xwf γx   connect node     node     word follows                                                                 λ · wv  − λ · wv xwf minimizing function word sentence ideally want words  equivalent minimizing wf γx − λ · wv set neighbors cluster  compute value λ using parametric ﬂow model described ignores number occurrences  algorithm shown distinct bigram pair easily account numbers  solutions corresponding  values λandfur replicating each word ∈ form fffkwhere  ther complexity ﬁnding solutions values awordv ∈ connected fffr bigram  λ complexity ﬁnding solution vf occurs times text simple modify  single value λ ﬂow computation networkﬂow algorithm solve networks type  network algorithm returns values λ correspond complexity original network goal  ing distinct solutions solutions partition words clusters words different   distinct solutions each clusters share neighbors possible words  examined ﬁnd results maximum cluster share neighbors possible ob  improvement current partition local serve criterion does require compute “dis  improves normalized cut value tances” words clustering method                                                                                complexity ﬂow computation ov  etheﬁnal proposed brown et al   advantage scheme  search through distinct solutions does add distance based approach naturally cap  complexity total time required computing tures transitive relationships                            local improvement ov                      test procedure generated clustering                                                         clusters wall street journal wsj data penn                                                        treebank  tagged  wsj collection word hu    word clustering language models                 man generated partofspeech pos tag information  statistical language models used applications extracted treebank sentence order ran  including speech recognition machine translation domized produce fold cross validation results using  based estimating probabilities  trainingtesting sizes compared sub                                                    ijcai                                                     
