                     planning risk knightian uncertainty           felipe trevizan                fabio´ cozman                leliane barros  instituto matem´atica estat´ıstica    escola polit´ecnica      instituto matem´atica estat´ıstica       universidade s˜ao paulo        universidade s˜ao paulo        universidade s˜ao paulo          rua mat˜ao           av prof mello moraes            rua mat˜ao           s˜ao paulo sp brazil            s˜ao paulo sp brazil           s˜ao paulo sp brazil          trevisanimeuspbr                fgcozmanuspbr                  lelianeimeuspbr                        abstract                          gebraic mdps amdps forgo generality                                                        want employ models solid behavioral justiﬁcation      noteworthy models planning ai prob exploit speciﬁc structure combined probabilistic      abilistic planning based mdps gener  nondeterministic planning general algorithms      alizations nondeterministic planning mainly amdpbased value iteration useful theoretically      based model checking paper    ﬁnd speciﬁc approach based realtime      show probabilistic nondeterministic plan dynamic programming leads encouraging results com      ning extremes rich continuum prob    putational complexity      lems deal simultaneously risk knigh                                                          necessarily brief review closest literature      tian uncertainty  obtain unifying model dicate central motivation work strive work      problems using imprecise mdps  derive   decision processes solid behavioral founda      simpliﬁed bellman’s principle optimality                                                        tion smoothly mix problems practical signif      model  show adapt analyze                                                        icance similar approach proposed eiter      stateofart algorithms lrtdp ldfs  lukasiewicz  using nonmonotonic logic causal se      unifying setup discuss examples                                                        mantics deﬁne setvalued transitions partial observable      connections various proposals planning                                                        mdps leaving algorithms future work offer      der general uncertainty                        model assumes observability obtain algo                                                        rithms complexity analysis model    introduction                                         remainder paper organized follows  planning problems classiﬁed based effects section  discuss mdpsts capture continuum  actions deterministic probabilistic nondeterministic planning problems “pure” probabilistic “pure” non  paper concerned action dynamics gen deterministic planning section  show mdpsts  eral forms uncertainty interested plan markov decision processes imprecise probabilities  ning risk knightian uncertaintyweshow mdpips model received attention operations  use concepts express probabilistic non research displays solid foundation com  deterministic planning combinations thereof markov ment various relationships mdpsts  decision processes setvalued transitions mdpsts models literature section  show mdpsts    similar generalizations markov decision processes lead important simpliﬁcations “minimax” bellman  mdps appeared research artiﬁcial intel style equation note simpliﬁcations men  ligence example givan et al  use intervals tioned proof buffet aberdeen   encode set exact mdps used conduct space bmdps obtain interesting insights concerning compu  state reduction mdps boundedparameter mdps tational complexity mdpsts related models section  bmdps form  superset subset mdp  investigates algorithms produce minimax policies  sts buffet aberdeen  use bmdps produce  mdpsts results yield easy variants value  robust policies probabilistic planning show policy iteration mdpsts interested  realtime dynamic programming rtdp used efﬁcient algorithms based rtdp section  derive  bmdps perspective different wish unify conditions true rtdp applied sec  various strands planning proven practical value tion  brings concluding remarks  using theory behavioral basis preferences  beliefs — follow similar path buf  background  fet aberdeen’s exploit rtdp models  recent work mentioned perny et  varieties planning  al’s  transitions satisfy alge start reviewing basic models planning problems  braic properties models strict subset al attempting unify possible suggested                                                    ijcai                                                    recent literature bonet geffner           compute optimal policies each mod                                                        els algorithms specialized  discrete ﬁnite state space                                                        bonet geffner  emphasize  nonempty set initial states ⊆s            previous unifying frameworks intend handle  goal given set sg ⊆s                       smooth “mixtures” planning problems fact                                                        goals paper provide framework  nonempty set actions ⊆arepresenting                                                      nondet mdps extreme points continuum     actions applicable each state                  planning problems  state transition function ⊆smapping state     action ∈as  nonempty sets states     a≥and                                     varieties uncertainty  positive cost cs taking ∈as   probability theory based decision theory berger  adapting mandm produce                 appropriate scheme realm planning                                                        decision maker contemplates set actions each    •      deterministic models det state transition yields different rewards different states                                  function deterministic    “classical” nature complete preferences actions imply pre                                                     planning following constraints added   cise probability value associated each state — situa              ∅        ∀s ∈sa∈as            ii   iii                   tion risk knight  luce raiffa anobvi    • nondeterministic models nondet ac   ous example sequential decision making “pure” risk      tions result successor state probabilistic planning preferences      preferences                           actions partially ordered incompleteness    • probabilistic models mdps actions   beliefs lack timeresources experts      probabilistic consequences function disagree possible guarantee precise      a≥ given model includes probabilities represent beliefs cases set proba                                                        bility measures adequate representation uncertainty      mdp probability distribution p· sand                                                        sets referred credal sets levi       mdp probability distribution ·s                                                                                          ∈sa∈as                              kadane et al  walley   terminology                                                        stable situation said contain knightian uncer    models expect solution tainty terms ambiguity simply uncertainty  policy evaluated longterm costs cost extreme case nondeterministic planningwhereno proba  lution evaluated ﬁnitehorizon max bilities speciﬁed                                             ∈  imum number actions executed limited   note actual decision making rarely restricted ei  alternative consider discounted inﬁnitehorizonin ther “pure” risk “pure” knightian uncertainty fact  number actions bounded cost realistic scenario mixes elements sur  actions discounted geometrically using discount factor    γ                                               prisingly combinations studied economics            difﬁcult ﬁnd appropriate psychology statistics philosophy note credal  each problem paper assume discounted                                                       sets raised steady interested connection arti  inﬁnitehorizon framework                            ﬁcial intelligence example theory probabilis    assumption observability discounted                                      inﬁnitehorizon cost valid solution stationary policy tic logic nilsson   dempstershafer theory shafer  function π mapping states ∈sinto actions  theories argumentation anrig et al   ∈as bellman’s principle optimality deﬁnes op generalizations bayesian networks cozman                    ∗  timal cost function smina∈as qv ∗ bellman fagiuoli zaffalon                                             usual prescription decision making risk           cs aγv  ss ∈ det     select action maximizes expected utility pres                                          cs aγ   max   nondet     ence knightian uncertainty matters com                      s∈f sa   qv                                      plex decision maker carries set probability           cs aγ      ss av s                                      mdps       measures consequently action associated                     s∈f sa                         interval expected costs walley  decision   principle characterizes ∗ called optimal value maker choose criteria minimax                                                                                                 function induces optimal policy each model ity maximality eadmissibility troffaes  inthispa   ∗                                                    follow minimax approach interested  π    argmina∈as qv ∗ deﬁnition                                                 actions minimize maximum possible expected cost       clariﬁes guarantees each model det leave criteria future work  guarantees given π∗ depend execution  nondet guarantees worstcase cost  mdps guarantees expected cost algorithms term “nondeterministic” somewhat unfortunate non                                                        determinism equated probabilism term plan    results presented applicable ﬁnitehorizon ning pure knightian uncertainty longer offer  easily adapted address partial observability better description                                                    ijcai                                                                drug                      drug                 heart transplant                                                                                           cost actions          cardiopathy                  cardiopathy               cardiopathy                                                                                    state  ht noop                                                                                    cardiopathy    −−−      severe           controlled                                                                         severe         controlled severe        controlled     cardiopathy       cardiopathy                                                  severe                                  cardiopathy     cardiopathy cardiopathy  cardiopathy cardiopathy    −−−                                                                                    unrecoverable                                                                           cardiopathy    −−−                                                                          controlled                                                  controlled                        controled    unrecorverable      controlled                                          cardiopathy cardiopathy −−− −−− −−−      cardiopathy       cardiopathy unrecorverable cardiopathy unrecorverable                                  cardiopathy               cardiopathy     sequels                    sequels               sequels                      controled                                                                                 cardiopathy −−− −−− −−−                                                                                  sequels                                                                            stroke                       stroke                                      stroke   −−− −−− −−−                     death                       death         stroke   death                                                                                    death    −−− −−− −−−     figure  mdpst representing example  dotted lines indicate each reachable sets cost taking actions  ht example  states “–” indicates action applicable action noop represents persistence  action absorbing states      markov decision processes setvalued          example   hospital offers three experimental treatments     transitions                                        cardiac patients drug ddrugd heart transplant                                                        ht state indicates patient cardiopathy effects  section develop promised synthesis proba procedures lead states severe cardiopathy  bilistic nondeterministic planning focus tran unrecoverable cardiopathy cardiopathy se                                          ⊆s  sition function instead taking    quels controlled cardiopathy stroke death                         ⊆  ∅         setvalued         thatis        little understanding drugs                        ∈as  maps each state action     set nonempty considerable data heart transplants consequently  subsets refer each set ∈ fs reachable “partial” nondeterminism knightian                                       set transition state given action asso certainty way actions operate figure   ciated probability ks note knight                                                       depicts transitions actions indicating mass  ian uncertainty concerning each successor state assignments costs heart transplant suppose  s ∈         refer resulting model markov deci transitions purely probabilistic  sion process setvalued transitions mdpststransi  tions probabilistically reachable sets prob  mdpsts mdpips bmdps  ability particular state resolved model  fact close connection probabilities section comment relationship  fs mass assignments associated mdpsts existing models literature markov  theory capacities inﬁnite order shafer toavoid decision processes imprecise probabilities mdpips  confusion ks ss refer white iii eldeib  satia lave jr   mass assignments denote mks boundedparameter markov decision processes bmdps                                                                           mdpst given mdp  givan et al                                                          mdpip markov decision process transitions  mdpst state transition function fs ⊆  ∅ mapping speciﬁed through sets probability measures          states actions ∈as reachable sets effects action modelled credal set                                                            state space mdpip given mm  mdpst mass assignments mks ∈as mdpand              ∈                                                 mdpip nonempty credal set ksa ∈sand                                                                ∈as    clearly varieties uncertainty mdpst           representing probability distributions                                                                ss                     probabilistic selection reachable set nondetermin      successor states   istic choice successor state reachable set paper assume decision maker seeks min  important feature mdpsts encompass imax policy selects policy minimizes  models discussed section                         maximum cost possible probability distributions                                                        adopts implicit assumption probabilities se    • det single successor state ∀s ∈ lected adversarial manner interpretations md      sa ∈asfs  ∀s ∈sa  ∈ask  ∈    pips possible troffaes  minimax inter      fs ak                                    pretation bellman principle optimality satia                                                        lave jr     • nondet single reachable set                                                                                          ∗                                          ∗        selection set left unspeciﬁed nondeter min max   cs aγ    ·s av                                                                a∈as ·sa∈ksa      ministic ∀s ∈sa  ∈asfs                                         s∈s      ∃s ∈sa∈ask   ∈ fs ak                                                                                                                          equation unique solution    • mdps selection ∈ fs probabilistic yields optimal stationary policy mdpip inves      resolves uncertainty ∀s ∈sa∈asfs  tigate relationship mdpsts mdpips      and∀s ∈sa∈ask    ∈ fs ak           following notation useful ∈ fs denote                                                    ijcai                                                                 mdpst                bmdp                                       mdpip                                                                                          det mdp                                                               bmdp              mdpst                                                                non−det                                                                                                                                                                                                figure  relationships models bmdps pre                                                                                                                                  cise rewards                                                                                                                            bmdp bmdp expressed                                                          −p                                                                                                                   −p          mdpst technical aside note                                                                                                    ﬁne choquet capacities inﬁnite order transitions                                                        bmdps deﬁne choquet capacities second order wal  figure  ﬁgure illustrates examples planning ley  clearly representational  der uncertainty modeled through mdpsts bmdps ex power  ample  heart example perny et al  ex results section captured figure   ample  simple example models sections present main results  express problem modelled        explore properties mdpsts make models                                                        amenable practical use                                                                                     k         set states k∈fsak       simpliﬁed bellman equation mdpsts  dk represents nondeterministic effects                                                      present substantial simpliﬁcation bellman  belong wenowhave                       principle mdpsts intuition following  proposition  mdpst   sssg fcpm     result equation  minima maxima  expressible mdpip   sssg afcp  taken respect combinations actions possible                                                        probability distributions possible “pull”  proof detailed trevizan et al                                                         maximum inside summation combinations  prove ∀s ∈sa∈as    mdpst                                                  need considered  mdpst imply ksa mdpip note mdpst  bounds s ∈sthe probability state s theorem  mdpst associated mdpip                                                         equivalent  applying action state follows                                                                                                 ∗                                       ∗                                                         min  cs aγ     mks amaxv        ≤ ≤      ks ≤                  a∈as                      s∈k                                                                      k∈fsa                          k∈fsa∧s∈k                                                                      ∗         ∗  use deﬁnition reachable sets let ∈ proof deﬁne vip vst shorthand val  fs aifs ∈ possible select s ues obtained through respectively   want  nondeterministic effect                        prove mdpst   sssg fcpm     mdpstandmdpst possible bound sum associated mdpip   sssg afcp                                                                 ∗       ∗  probabilities each state reachable set ∈ fs ∀s ∈s vip  vst proposition                                                                                                     ∗   associated set dk                 probability measure induced maxs∈k                                                       ∈ fs  valid choice according ksathere     ≤      ss ≤ ks ≤   ss ≤                     ∗         ∗                                             fore ∀s ∈svst ≥ vip show                                s∈k                               ∗        ∗     ∈dksa                                        ∀s ∈svst ≤ vip conclude proof                                                          sˆ ∈s denote fsˆs set reach  set inequalities   ∈sand ∈as                                      ∗                                                           able sets ∈ fs sˆ argmaxs∈k vst  possible credal set ksa mdpip                        ∗         ∗                                                        proof ∀s ∈svst  ≤  vip proceeds contra  deﬁnition  mdpip obtained through proposition  diction follows ∈sand ∈aslet  called associated mdpip                  ·s probability measure chosen operator                                                               ∗                ∗  v∗       noted section  bmdps related mdpsts max ip   suppose st  ip                                                                       ∈s                      ks   tuitively bmdps markov decision processes tran fore k∈fssa       sition probabilities rewards speciﬁed intervals gi ss aasp ·s probability measure                                                       ∈s                ks  ss   ∗    van et al   bmdps comparable md     st k∈fssa                ip    pips possible imprecision rewards ∗ snowletp·s probability measure deﬁned  consider bmdps realvalued rewards clearly ip                                                        pss ap ss ∀s ∈ss pss  bmdps form strict subset mdpips relation ss   ss  ss −      ship bmdps mdpsts complex                             note                                                                   ss ∗        ss ∗  figure presents mdpst bmdp  s∈s        ip      s∈s        ip   equivalent represent mdpip fig tradiction deﬁnition ·s rest  ure presents mdpst expressed proof shows ss satisﬁes proposition                                                     ijcai                                                      deﬁnition p·s awehavethattheleftside caseofanmdpmodelledasanmdpstie   ∀s ∈sa  ∈  right side  trivially satisﬁed respectively fs a≤sand ∀k ∈ fs  worst  ss ss treat case case complexity osa round using  sufﬁcient deﬁne  follows             bellman principle mdps papadimitriou                                         min    mks a−p ss apss a− mks                                                           algorithms mdpsts       k∈fssa                      k∈fssa                                                        proposition  algorithm ﬁnds optimal   using deﬁnition  hypothesis policy mdpips directly applied mdpsts   gives lower upper bound sum stances algorithms mdpip value iteration pol  ·s respectively ∈ fs dk ⊆ icy iteration satia lave jr  modiﬁed policy iter  s∈dk ∈dk noth ation white iii eldeib  algorithm ﬁnd  ing changes bounds remain valid optimal policies presented harmanec  case each bound satisfaction trivial better approach use theorem  proposi  upper bound ∈dk ii tion gives clear path adapt algorithms  lower bound ∈  nontrivial case realm mdps — algorithms lrtdp bonet  lower bound  ∈ ∈ kthis     geffner  ldfs bonet geffner  bound holds mss a ≤ ss hy algorithms deﬁned stochastic shortest path problems                     ss          ss  pothesis s∈k           s∈k              ssps bertsekas  ssps special case mdps                          δ   ≤               δ    ss   ≤    initial state set           ∈ks                                                                             goal states nonempty ﬁnd optimal policy    s∈ks ap ss aδ≥  using proposition       ·s                                         additional assumption required goal reachable                                               state nonzero probability reachability    remaining case prove equation  sumption mdpsts assumption generalized          ·s             ∈dk       ∈  true      happens                   requirement goal reachable state          upper bound  case valid nonzero probability probability measures  k ∈ fs k                                                        model following proposition gives sufﬁcient  s∈ deﬁnition reachable set pss ≤ necessary condition prove reachability assumption             ks   ks    k∈fssa               hypothesis mdpsts  s ∈   st ss                                                         proposition  ∈s exists ∈as  bound holds choosing validate      ∈      s ∈ ss                         ·s                                         thenit  bounds       respects proposition  sufﬁcient prove reachability assumption valid                                     ss s   we contradiction s∈s              using probability measure each ∈sand        ss s                   ·s    s∈s           hypothesis            ∈a                           ss ∗  argmaxp ·sa∈ksa s∈s            ∀s ∈sv∗    ≤ ∗                                 proof reachability assumption true speciﬁc se          st     ip   completes proof    quence probability measures   ppn    immediate consequence theorem  decrease exists policy π history sequence vis  worst case complexity order mdpips algorithms ited states executed actions induced π                                                               ∈ π sπ sn− sn ∈    used solving mdpsts consider ﬁrst iteration                          min                                    ∈s                                        i≤n   i−   i−  bellman principle optimality each round  imum ∀s ∈sps     πs       using equations  deﬁne upper bound fs si reached exists ac  ∈sand  ∈as   mdpst instance    tion ∈asi sisia                                        maxs∈s  maxa∈as fs ≤  inthemdpip      sequence probability measures model history                                            ∗                                              obtained through proposition  computation induced π contains reaches ∈ sg     sists solving linear program induced max operator                                                    example   consider planning problem example   linear program variables  cost actions figure  obtained  description proportional worst case complex                                                      following optimal policy mdpst  ity round oaspf forp ≥  ≥                  value related algorithm used solve                                                                               π∗   linear program instance using interior point al  ht   noop   noop  noop   noop  gorithm kojima et al  leads  karmarkar’s algorithm karmarkar  leads       worst case complexity round using conclusion  equation  osaf true prob paper examined approaches planning  ability measure maximizes right side equation dimensions determinism nondeterminism risk                                           represented choice maxs∈k  equation certainty like suggest markov decision   avoiding cost linear program special processes setvalued transitions represent remarkable                                                    ijcai                                                    
