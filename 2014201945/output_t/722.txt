                     visualsensor model mobile robot localisation                                          matthias fichtner axel grofimann                                            department science                                             technische universitat dresden                                                    dresden germany        introduction   recent advances robot hardware   great demand visionbased robot localisation techniques   desouza kak  present probabilistic sen•  sor model camerapose estimation hallways   known structured environments given geometrical map   environment want approximate mea•  sure probability given camera image   obtained certain place robots operating environ•    figure  processing steps visualsensor model   ment sensor model based feature matching tech•  niques simpler stateoftheart photogrammet     similarity measures correspondence image   ric approaches allows model used proba•    model features evaluated similarity measure gen•  bilistic robot localisation methods monte carlo lo•  eral measure account differences   calisation mcl dellaert et al  combined     orientation corresponding line segments im•  photogrammetric techniques feature projection    age model distance difference length   flexibility robustness mcl approach  following present simple efficient similarity   sufficiently fast allow sensor fusion using measures solely based distance line seg•  distance measurements sonars laser addition    ments hough space consider image fea•  visual input able improve localisation ac•  tures possible matches lie rectangular cell   curacy used sensor model mcl track   hough space centred model feature matches   position pioneer  robot navigating hallway possi• counted resulting sum normalised map•  bly approach used localisation cluttered ping expectation model features measure•  environments shapebased object detection            ment image features accounts fact measure     section briefly components  invariant respect objects modelled   visualsensor model conclude discussion     provided map unexpected changes operating en•  experimental results                                         vironment invariance number visible features                                                                 obtained normalisation specifically centred match    sensor model                                                count cmc measure scmc defined   visualsensor model describes probability obtaining   particular camera image given cameras pose ge•  ometrical map environment comparing   camera image expected view pixel level     predicate defines valid match using dis•  gained improved robustness using image features de•       tance parameters operator  counts num•  cided use line segments detected com•  ber matches generally speaking similarity measure   paratively reliably changing illumination conditions   computes proportion expected model hough points   world model use wireframe model operating            confirmed measured image   environment represented vrml individual process•     hough point falling tolerance note   ing steps depicted figure                            endpoint coordinates lengths considered     representation each straightline feature represented   second measure based comparison   single point hough space given              total length values groups lines grid                          endpoints neglected     length match glm split lines image grouped   representation truncated split lines similar coor• using uniform discretisation hough space   dinates                                                      method similar hough transform straight       poster papers                                                                                                                                                                                                     poster papers 
