                               portfolio approach algorithm select     kevin leytonbrown eugene nudelman galen andrew jim mcfadden yoav shoham                kevinlbeugnudgalandjmcfshohamcsstanfordedu stanford university stanford ca            introduction       algorithms better average       rarely best algorithm given problem instead       case different algorithms perform dif•      ferent problem instances surprisingly phenomenon       pronounced algorithms solving aaphard       problems runtimes algorithms       highly variable instance instance algorithms       exhibit high runtime variance faced problem       deciding algorithm use  rice dubbed       algorithm selection problem  nearly three          figure  algorithm portfolio runtimes       decades followed issue algorithm selection       failed receive widespread attention course       excellent work does exist far common       approach algorithm selection measure different       algorithms performance given problem distribution       use algorithm having lowest average run•      time winnertakeah approach driven recent ad•      vances algorithm design refinement resulted       neglect algorithms uncompetitive       average offer excellent performance particular prob•      figure  optimal figure  selected       lem instances consideration algorithm selection       literature dissatisfaction winnertakeall ap•  use domain knowledge select features problem in•      proach led ask following questions   stances indicative runtime       general techniques use perform perinstance       perdistribution algorithm selection second    generate set problem instances given dis•      rejected notion winnertakeall algorithm   tribution collect runtime data algorithm       evaluation ought novel algorithms evaluated      each instance       offer following answers                                   use regression learn realvalued function fea•                                                                      tures predicts runtime          algorithms high average running times com•           bined form algorithm portfolio low average    given existing technique predicting runtime            running time algorithms easy inputs suffi• propose building portfolios multiple algorithms fol•           ciently uncorrected                                   lows          new algorithm design focus problems          train model each algorithm described            current algorithm portfolio performs poorly    given instance         readers familiar boosting paradigm machine         compute feature values       learning  recognize boosting uses similar ideas    predict each algorithms running time       combining weak classifiers stronger ensemble                                                                        run algorithm predicted fastest       iterativcly training new classifiers data       ensemble performs poorly                                    wdp case study past work                                                                   case study based data collected previous        algorithm portfolios                                      work  work constructed models pre•      previous work  demonstrated statistical re• dicting running time cplex solver winner       gression used learn surprisingly accurate algorithm determination problem wdp npcomplete       specific models empirical hardness given distribu• combinatorial optimization problem formally equivalent       tions problem instances short method proposed weighted setpacking created models       work                                               wdp algorithms gl gonenlehmann  simple            branchandbound algorithm cplexs lp solver   heuristic cass  complex branchandbound   algorithm nonlp heuristic data set consists    instances fixed size  goods  non  dominated bids sampled uniformly cats  instance   generator methodology relies machine learning   split data training validation test sets re•  port portfolio runtimes test set   used train evaluate models runtime data collected    mhz pentium xeons running linux                              conclusions                                                                           learned runtime models used create algorithm    wdp case study portfolios                                                                           portfolios outperform constituent algorithms                                                                           models used induce harder benchmark distri•  new results fig  compares average                                                                           butions use development evaluation new al•  runtimes three algorithms portfolio note                                                                           gorithms case study combinatorial auctions demon•  cplex chosen winnertakeall algo•                                                                          strates portfolio composed cplex older  rithm selection optimal bar shows performance                                                                           generally slower—algorithms outperforms cplex   ideal portfolio algorithm selection performed per•                                                                          factor  version paper   fectly overhead portfolio bar shows time                                                                           methodology   taken compute features light portion time taken   run selected algorithm dark portion despite fact             • show reduce time spent computing features   cass gl slower cplex average                       substantially degrading portfolio performance   portfolio outperforms cplex factor                 • demonstrate ways using response variable transfor•  neglecting cost computing features port•                 mations focus portfolios metrics average   folios selections  longer run optimal                running time   selections figs   show frequency each   algorithm selected ideal portfolio portfo•            • explain induce distributions characteristics   lio illustrate quality algorithm selection               hardness realism   relative value three algorithms portfo•              • compare approach previous work executes   lio does make right choice mis•                   algorithms parallel  uses classification instead   takes occur algorithms similar running times                  regression  considers problem mdp    mistakes costly explains   portfolios choices running time close optimal            references   results show portfolio methodology work                                                                            fujishima leytonbrown shoham taming   small number algorithms                                                                                computational complexity combinatorial auctions optimal   algorithm superior average performance                         approximate approaches ijcai                                                                             gomes selman algorithm portfolios artificial intel•   focused algorithm design                                                   ligence                                                                              gonen lehmann linear programming helps solv•  decided select algorithms portfo•                 ing large multiunit combinatorial auctions technical report                                                                               tr leibniz center research science   lio perinstance basis necessary reexamine                                                                                april    way design evaluate algorithms purpose   designing new algorithms reduce time           horvitz ruan gomes kautz selman   solve problems designers aim produce new                 chickering bayesian approach tackling hard computa•                                                                               tional problems uai    algorithms complement existing portfolio given dis•  tribution reflecting problems encountered              lagoudakis littman algorithm selection using re•  practice instances greatest potential im•                  inforcement learning icml    provement hard portfolio common                leytonbrown nudelman shoham learning   version paper describes technique              empirical hardness optimization problems case com•  using rejection sampling automatically generate in•                 binatorial auctions cp    stances figures   show techniques               leytonbrown pearson shoham uni•  able automatically skew easiest cats instance                 versal test suite combinatorial auction algorithms acm   distributions harder regions fact                ec    distributions generated instances respectively            rice algorithm selection problem advances com    times harder previously                     puters    seen average runtime new distribu•                                                                           schapire strength weak learnability machine learn  tions greater observed maximum running time                    wg      original distribution       poster papers                                                                                                                          
