                      emergence norms through social learning                                       sandip sen    stephane´ airiau                                          university tulsa usa                                       sandip stephaneutulsaedu                          abstract                          social milieu play pivotal role kinds business                                                        political social personal choices interactions      behavioral norms key ingredients allow   selfenforcing “a norm exists given social setting      agent coordination societal laws suf extent individuals usually act certain way      ﬁciently constrain agent behaviors social punished seen acting way” ax      laws need enforced topdown manner    elrod       norms evolve bottomup manner typ     aspects norms conventions merited      ically selfenforcing effective norms indepth study evolution economics norms      signiﬁcantly enhance performance individ  social situations epstein  posch  young       ual agents agent societies lit  particularly interested following charac      tle work multiagent systems formation terization “ deﬁne convention equilibrium      social norms propose model supports    expects interactions      emergence social norms learning   equilibrium” young  observation particular      interaction experiences model individual signiﬁcance study norms context com      agents repeatedly interact agents putational agents computational agents coor      society instances given scenario each  dinate actions interactions formulated      interaction framed stage game agent   stage games simultaneous moves play      learns policy play game repeated  ers genesereth et al  stage games      interactions multiple agents term   multiple equilibria myerson  makes coordina      mode learning social learning distinct tion uncertain focal points schelling       agent learning repeated interactions used disambiguate choices available      player particularly inter situations norms thought focal points      ested situations multiple action combina evolved through learning young  emer      tions yield optimal payoff key  gence norms learning agent societies promises      search question ﬁnd entire population productive research area improve coordination      learns converge consistent norm addition functioning agent societies      studying emergence social norms                                                          researchers studied emergence norms      homogeneous learners social learning study      effects heterogeneous learners population agent populations typically assume access signiﬁcant                                                                                        size multiple social groups                global knowledge epstein  posch                                                         young   example models assume                                                        individual agents observe sizable fraction interac    introduction                                       tions agents environment                                                        results provide key insights emergence norms  norms conventions routinely guide choice behav                                                        societies assumption observability holds  iors human societies conformity norms reduces social                                                        unclear norms emerge interactions  frictions relieves cognitive load humans facilitates                                                        private observable agent involved  coordination “everyone conforms expects                                                        interaction  conform good reason conform  cause conforming each person’s best ev study important phenomenon emergence social  eryone plans conform” lewis  conventions norms private interactions use following interac  human societies range fashions tipping driving tion framework consider population agents  etiquette interaction protocols norms ingrained each interaction each agent paired agent      conventions substituted external correlating henceforth use term norm refer social norms  signals promote coordination                      conventions                                                    ijcai                                                    randomly selected population each agent depends joint action agents popula  learning concurrently repeated interactions ran tion tumer wolpert  goal learning  domly selected members population refer agent maximize objective function entire pop  kind learning social learning distinguish learning ulation world utility  iterated games opponent fudenberg social learning framework use study norm emer  levine  experiments involve symmetrical gence population somewhat different  games multiple purestrategy equilibria lines research considering potentially large  payoff previous work learning games opponent population learning agents each time step  ﬁxed work opponent different each itera each agent interacts single agent chosen random  tion addition opponent use learning population payoff received agent  algorithm unclear apriori social norm time step depends interaction case  emerge social learning framework experi agents learning play game twoagent case  mental results concomitant analysis throws light learner adapt respond opponent’s policy  dynamics emergence norm social learning framework opponent changes each inter  private interactions investigate number key action clear aprioriif learners converge  lated issues effect population size number choices useful policies situation  available multiple populations limited interpopulation  interactions heterogeneous population multiple learning  algorithms effect nonlearners shaping norm adoption  norms social dilemmas                          social learning framework      related work                                       speciﬁc social learning situation norm evolution                                                        consider learning “rules road” partic  need effective norms control agent behaviors ular consider problem side road  wellrecognized multiagent societies boella van der drive yields drivers arrive inter  torre  v´azquezsalceda et al  particular action time neighboring roads   norms key efﬁcient functioning electronic represent each interaction drivers nperson  stitutions garciacamino et al  work maction stage game stage games typically mul  multiagent systems norms centered tiple pure strategy equilibria each time period each agent  logic rulebased speciﬁcation enforcement norms paired randomly selected agent population  dignum et al  v´azquezsalceda et al  simi interact agent randomly assigned row  lar research work normative gametheoretic column player interaction assume stage  approach norm derivation enforcement assumes game payoff matrix know players agents  centralized authority knowledge level distinguish players population  goals boella lesmo  boella van der torre each agent develop single pair policies   norms established centralized dictat row player column player play  number reallife norms evolve bottomup manner player agent population learning al  “the gradual accretion precedent” young gorithm used agent ﬁxed intrinsic property  ﬁnd little work multiagent systems distributed agent  emergence social norms believe impor cars arrive intersection driver  tant niche research area effective techniques dis times car left right  tributed norm emergence based local interactions util experiences mapped different roles  ities bolster performance open multiagent systems agent assume social dilemma scenario cor  focus importance electronic agents solving responds agent playing row column player  social dilemma efﬁciently quickly adopting norm cen respectively consequently agent private bimatrix  tralized social laws norms sufﬁcient general matrix row player matrix  resolve agent conﬂicts ensure smooth coordination column player each agent learning algorithm play  gradual emergence norms individual learning row player column player learns independently  facilitate coordination situations make individuals play row column player agent does  societies efﬁcient                          know identity opponent opponent’s payoff    formulation norms evolve agents learn observe action taken opponent perfect  interactions agents society using multiagent incomplete information protocol interaction  reinforcement learning algorithms panait luke  presented algorithm   tuyls now´e  multiagent reinforcement  learning literature involve agents iteratively playing  stage game goal learn policies reach preferred modern reader “rules road”  equilibrium powers shoham  line ﬁxed authority historical records show “society  search considers large population agents learning play converges convention ﬁrst informal process ac  cooperative game reward each individual agent cretion later codiﬁed law” young                                                     ijcai                                                      ﬁxed number epoch                                                                       yl                             repeat                                                                                 remove randomly agents prow pcol                                                            yr                                  population ask each agent select action                                             send joint action row col policy   social dilemma game   coordination game          update       agents selected during epoch            algorithm  interaction protocol            table  stage games corresponding social interactions    use three different learning algorithms learning  norms qlearning watkins dayan  greedy player learns yield situations al  exploration wolfphc bowling veloso   “fair” situation possible framework  fictitious play fp qlearning widely used mul each agent independently learns play row  tiagent systems converges pure strategies wolf column player  phc win learn fast  policy hill climbing learn agent introduced agents know  mixed strategies wolf guaranteed converge identity opponents agent longer beneﬁt  nash equilibrium repeated game person  choosing “go” agents  actions game given opponent clear “yield” “go” agent agents  guaranteed converge social learning finally fp receive relatively poor utility playing each  basic learning approach widely studied game theory result learn “go” optimize perfor  literature fudenberg levine anfpplayeruses mance learn settle norm  historical frequency count opponent’s past actions follows hoped  tries maximizing expected payoff playing best happen social learning large population experi  sponse mixed strategy represented frequency mental results show uniform norm emerges  distribution                                         population three agents example pop                                                        ulation  agents using wolf ran   runs    results                                            observed population converged “yield                                                        left” norm  times “yield right” norm     example social dilemma                      times present averaged dynamics payoffs  typical example use norms convention frequency joint action during learning figure   resolve social dilemmas straightforward example dynamics ﬁrst agents avoid  drivers arrive intersection simultaneously collision prefer yield agent notice  neighboring streets each player incentive exploit situation choosing “go”  yielding myopic decisions lead unde yielding depending notices ﬁrst pop  sirable accidents drivers yielding cre ulation converges norm note  ates inefﬁciency ideally like norms like “yield plot figure  averaged runs explains  driver right” serves drivers long run yl yrg appear  time  dilemma resolved each member popu presence jointactions exploration  lation learns “yield” row column player “go” results conﬁrm private experience sufﬁcient  column row player player yields gets lesser pay emergence norm society learning agents  losing time compared player contrast prior work norm evolution  players know playing row col requires agents knowledge nonlocal interac  umn player row player sees car right tions agents strategies epstein   column player sees car left action choices posch  young   row player yield car right  ylandtheyaregog yield car left yl  inﬂuence population size number actions  column player model game using payoffs learning algorithm  presented table note social norm evolve time required emergence norm society  agents population learn follow interacting agents measured number interaction pe  ing policy pairs rowgcolyl yield car riods agents adopt norm depends  left  rowyrcolg yield car factors study inﬂuence size popula  right say norm emerged population tion learning algorithm used number actions  learners make corresponding choice infrequent available agents  random exploration                                     consider effect population size    ﬁrst note iterated play players larger population likelihood particular agents  population consisted agents policy teract decreases variety opponents  combinations emerge example addition diversity personal interaction history increases  possible norms case population size population takes time evolve  learners learn “go” row column player norm figure  present dynamics aver                                                    ijcai                                                                                                                                               dynamics payoff learners frequence joint action driving scenarios expanded actions agents                                                 receive payoff  choose action                                                                −                                                 payoff   actions differ figure  show                                                        dynamics probability agent choosing action                                                  each learning algorithm population  agents                                                  ran experiment ∈                                       gg         population  agents using wolf results pre                                           gyl                                    yrg         sented figure  number actions increase                                          yryl         proportion joint actions high payoff decreases                         frequence          average  payoffs                                    agents explore beginning expected utility                                                                                     larger game time norm emerges av                                                 erage payoff population approaching  takes longer          payoff row                               evolve norms larger action sets space joint            payoff col                                                   actions increases quadratically                                             iterations                iterations    figure  social dilemma game  agents using wolf       averaged  runs population converges   times yl  times yrg                                                                                         age agent reward social dilemma game population  agents using wolf different population sizes      agents takes longer entire population                                                                  verge particular norm wellknown tightknit  small societies groups clans develop eclectic norms     larger open societies                    policy learners                                                                      influence population size average  runs agents using wolf                                                                                                                                                                        number iterations                                                                figure  dynamics probability play action  each                                                        agent represented lines policy play row                                    agents          column player darker color represents probability                                      agents                                      agents          closer  agents converge probability close                                    agents          chooses action                                       agents                                      agents      average  payoff learner      agents                                   agents           finally consider effect learning algorithm                                      agents         used agents clear choice learn                                      agents                                                         number iterations                   dynamics payoff  wolf learners different size game                                                                  figure  dynamics average payoff learners                                                                 ing wolf different population sizes average   runs                                                                                                                           consider effect number actions avail                                                                  able each agent rest paper use                                                                     ordination game presented table stage game  average  payoffs  models situation agents need agree       equally desirable alternatives example                                                                                                                           twoaction case game represent situation                                                                                                 agents choose side road drive                       agents drive left right col                iterations  lision penalty societal norms  want evolve driving left driv figure  dynamics payoff learners using wolf  ing right stylized game representing non different game sizes average  runs                                                    ijcai                                                    ing algorithms use general wanted evaluate              effect fixed agents  representative learning algorithms study inﬂuence                                                                      converged   learning algorithms population  agents play    converged   ing twoaction game entire population uses  learning algorithm population qlearners    quickest evolve norm ≈  iterations followed    population wolf ≈  iterations population    agents using fp ≈   iterations payoff reached    convergence different different algorithms dif    ferent exploration schemes show results hybrid                                                               population using equal proportions three  algorithms time taken mixed groups evolve    norms time taken corresponding     homogeneous groups                                     percentage  time converged norm                                                                                                                                                                          number additional agents playing fixed strategy           dynamics average payoff population  agents                     using different learning algorithms figure  number times each norm emerges average                                                        runs small imbalance number agents using                                                        pure strategy inﬂuence entire population                                                                truth adage fashion                                                        trends decided handful trend setters paris                                                fp                                         ql               emergence norms isolated      average  payoffs                  wolf                                      fpql                  subpopulations                                 fpwolf             welldocumented societies isolated populations                                    qlwolf                                  qlwolffp            using contradictory norms driving “right”                                              “wrong” side road wanted replicate                           iterations                   phenomenon using social learning framework                                                        groups agents interact infrequently possible  figure  dynamics payoff learners using different different norm emerges each group particular  learning algorithms population  agents average interested studying degree isolation required di   runs                                            vergent norms emerge different groups experi                                                        ments consider groups equal size probability                                                        agents different groups interact    inﬂuence ﬁxed agents                            results set experiments presented fig  far observed norms equal payoffs ure  observe probability interaction  evolved roughly frequency multi  single norm pervades entire population  ple runs understandable payoff matrix roughly half runs agents learn drive left  table does support preference norm half learn drive right  extraneous effects bias soci interaction probabilities  runs  ety learners particular norm example divergent norms emerge groups corresponding  agents learning capabilities repeat pre white space shaded bars figure   determined action study inﬂuence agents playing interesting observation surprised rel  ﬁxed pure strategy emergence norm atively high interaction probabilities sustain  study use coordination game table divergent norms  sider population   learners nf agents play  ing ﬁxed strategy  driving left nf agents  playing strategy  driving right ran experiments  conclusions  add additional agents playing pure strategy  investigated bottomup process evolution  figure  presents percentage time norm   social norm depends exclusively individual experi  driving left   ences observations hearsay proposed  driving right emerges note equal cial learning framework requires each agent learn  number agents playing ﬁxed strategy  ﬁxed strategy  peated interaction anonymous members society  norms emerges equal frequency goal work evaluate social  interesting note  additional agents choos learning successfully evolve sustain useful social  ing drive right entire population  agents norm resolves conﬂicts facilitates coordination  converges driving right just tween population members experimental results conﬁrm                                                    ijcai                                                    
