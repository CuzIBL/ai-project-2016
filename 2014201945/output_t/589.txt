                    efﬁcient stochastic local search mpe solving                frank hutter                    holger hoos                    thomas stutzle¨        science dept            science dept            science dept       univ british columbia         univ british columbia      darmstadt univ technology         vancouver bc canada            vancouver bc canada               darmstadt germany            huttercsubcca                  hooscsubcca          stuetzleinformatiktudarmstadtde                        abstract                          approximate mpe algorithms reaching loopy belief                                                        propagation bp pearl  generalized bp yedidia      finding probable explanations mpes      et al  stochastic local search sls algorithms kask      graphical models bayesian belief net    dechter  park  specialized algorithms      works fundamental problem reasoning  graph cuts certain pairwise markov random      der uncertainty effort spent fields mrfs example occur vi      developing effective algorithms phard sion boykov et al       problem stochastic local search sls approaches   bb approaches recently shown state      mpe solving previously explored oftheart methods mpe solving claimed      competitive stateofthe mpe bb algorithms clearly outperform gls      art branch  bound methods work iden best performing sls algorithm known far terms      tify shortcomings earlier sls algorithms ability ﬁnd highquality solutions quickly marinescu et      mpe problem demonstrate     al  stark contrast results numerous      overcome leading sls algorithm sub combinatorial optimisation problems weighted      stantially improves stateoftheart solving maxsat sls algorithms clearly deﬁne stateof      hard networks variables large domain   theart hoos stutzle¨       sizes high degree importantly networks work analyse shortcomings previous      high induced width                          sls algorithms mpe demonstrate weak                                                        nesses overcome based careful consideration    introduction                                       important issues time complexity individ                                                        ual search steps search stagnation thorough parameter  pearl’s classic text pearl  graphical models tuning particular introduce improvements park’s  bayesian networks prime representation gls algorithm park  overcome inferior scal  uncertainty ai paper deals problem ing behaviour network domain size new al  ﬁnding probable explanation mpe ev gorithm gls clearly outperforms current stateoftheart  idence reasoning uncertainty speciﬁcally mpe algorithms various types networks especially  light uncertain knowledge represented proba hard networks high induced width establishes  bilistic graphical model problem cast ﬁnding stochastic local search highly attractive competitive  probable instantiation model’s variables approach mpe solving                                     given observed values subset ⊆               remainder paper structured follows    mpe problem graphical models applications ﬁrst introduce basic concepts notation section   different ﬁelds medical diagnosis jaakkola section  gls gls present  jordan  fault diagnosis rish et al  computational results illustrating improvement  vision tappen freeman  prediction side gls gls section  present empirical results  chains protein folding yanover weiss  establish gls new stateoftheart algorithm  just consequently algorithms sug ﬁnding mpes close conclusions brief  gested solve problem phard outlook future work section   hard problem instances solved efﬁciently  available algorithms mpe solving include exact meth  ods like variable elimination ve dechter  junc  preliminaries  tion tree jt cowell et al  conditioning tech discrete bayesian belief network bayes net  niques pearl  systematic search algorithms quadruple hv Φi ordered set ran                                                                      branch  bound bb guided minibuckets dom variables ordered set ﬁnite domains dvi  mb heuristic dechter rish  practice each vi ∈  directed acyclic graph dag  applications require efﬁcient online algorithms net Φ ordered set cpts φv  pav  speci  works high induced width research fying conditional probability distribution each ∈ vgiven parents pav  semantically bayes net spec algorithm  glsgls mpe                                                                    iﬁes joint probability distribution φ variables gls gls differ procedure used generate ini                      factored form φ     qv ∈v φv                   tial solution subsidiary local search procedure    given bayes net  hv Φi set evidence importantly evaluation function gvvi  vi dif  variables  probable explanation mpe   ferences explained text  problem ﬁnd instantiation  maximal prob utilities utilφ deﬁned text                                                                                       ability   qφ∈Φ φ    variable instantia input bayes net    Φi evidence   time  tions consistent evidence networks     bound smoothing factor ρ smoothing interval nρ  experimental analysis bayes nets algorithms output variable assignment  highest probability                                                                      φ    time  equally applicable graphical models mrfs     qφ∈Φ         general factor graphs                                initialize variable assignment penalties λφ local    cpts special case potentials functions optima counter lo  nonnegative entries assignment  ← generateinitialsolutionb  variables wellknown method solving mpe gen  foreach φ ∈ Φ instantiations vφ  vφ  eral networks variable elimination ve dechter  λφvφ  vφ ←    iteratively eliminates variables multiplying  lo ←   potentials deﬁned maximizing  alternate local search updates evaluation  product obtained variables elimi  function termination  nated best assignment recovered linear time  runtime   minibuckets ibound ib mbib dechter rish  ←  subsidiarylocalsearchb   approximates ve splitting each product smaller  local optimum update evaluation function  products ib variables mbws new variant  foreach φ ∈ Φ  mb instead limits number entries each prod  utilφ  maxφ∈Φ utilφ                                                  ib  uct constant domain size mbib mbwd         λφv  ← λφv     equivalent networks different domain sizes  mbw performed better experiments ve mb    regularly smooth penalties  mbw employ minweight heuristic                  lo ←  lo                                                             lo modulo nρ      sls mpe gls gls                             φ ∈ Φ instantiations vφ  vφ                                                                  λφvφ  vφ ← λφvφ  vφ ∗ ρ  probably prominent stochastic local search algo  rithm inference bayesian networks method called  stochastic simulation pearl  kask dechter   known gibbs sampling mpe  method simulated annealing shown dynamically updated search reaches local  clearly outperformed simple algorithm called greedy optimum   stochastic simulation gsts kask dechter  outline gls algorithm shown figure   probabilistically chooses greedy sam high level initialising search setting penal  pling steps                                          ties zero gls alternates search phases    mpe problem closely related weighted max simple iterative improvement search performed  sat park  maxcsp marinescu dechter spect evaluation function takes account   based close relationship park adapted current penalty values process reached lo  highperformance maxsat   algorithms dlm    cal optimum certain penalty values incremented  gls mills tsang  mpe problem park penalties solution components present   computational experiments identiﬁed gls selected incremented selection based  stateoftheart sls algorithm mpe solving showed contribution respective solution component  gls dlm clearly outperform gsts gls current penalty value details algorithm                                                                    performed better dlm instances park   additionally penalties regularly multi  shown marinescu et al  gls does reach plied factor ρ ≤  smoothing mechanism prevents  performance current bb algorithms                penalty values growing large performed    gls applied successfully combinato nρ local optima nρ parameter  rial problems including tsp voudouris tsang  park’s gls mpe solution components par  sat weighted maxsat  mills tsang  tial instantiations variables speciﬁcally each  classiﬁed dynamic local search algorithm hoos potential φ ∈ Φ instantiation vφ  vφ vari  stutzle¨  uses penalties associated solu ables solution component evaluation function  tion components guide search process penalties                                                           note number components present candidate    park motivated versions algorithms solution mpe instance constant vari  maxsat domain implementation works mpe directly able instantiation  consistent exactly partial  best knowledge suggested encoding im instantiation vφ  vφ each potential φ number  plemented aware implementation gls solution features present each instantiation total number  weighted maxsat realvalued weights            potentials Φ                                                                                                                                                                                  improving                                                                scores                  −                    −                                                                                                                                       −                    −                  log  probability assignment gls                                                gls                          −                                                                                                                                                                                                     speedup  previous best caching scheme                                cpu time sec                   instance size times average                speedup modiﬁed evaluation function speedup novel caching schemes  figure  effect modiﬁcation evaluation function gls compared gls instance munin given  best average worst solution quality computation time  runs gls gls gls plot ends   cpu seconds runs optimal solution quality speedup achieved new caching  schemes previously bestperforming caching scheme collection randomly generated realworld instances  instance size given number variables times average domain size                                           minimized deﬁned   pφ∈Φ λφ       tune” park  performance boosted  λφv   penalty associated solution compo orders magnitude simply changing park’s  nent vφ  vφ noted deviates fault smoothing value ρ   constant value ρ   standard form evaluation function general gls  example hailfinder network gls  algorithm captures contribution each solu ﬁnds optimal solution  times faster ρ    tion component optimisation objective pv    ρ   random instances ef    nonstandard evaluation function sole fect pronounced interesting note  teraction objective function penalties park’s gls small smoothing performed ρ    mpe utilities potentials φ current important smoothing ρ    assignment deﬁned utilφ  −φv  rare conclusive evidence search stagnation random   λφv    entry φvφ  vφ high   networks  probability assigned low utility associated penalty secondly subsidiary local search procedure gls             increased driving search uses computationally efﬁcient ﬁrstimprovement strategy  λφvφ  vφ                                                        partial variable instantiation vφ  vφ eventually gls employs powerful bestimprovement  possibly considerable delay         procedure conjunction newly developed powerful    initial persistent lack greediness ex strategies caching updating effects variable ﬂips  pected performance gls mpe boosted sig evaluation function previously used caching  niﬁcantly integrating objective function search schemes locally update partial evaluation function  heuristic achieved change gls’s evalua value involving variables markov blanket ﬂipped  tion function improved version gls variable developed substantial improvements ev  gls adds logarithmic objective function appro ery step maintain score ﬂipping each variable  priate penalties making new evaluation function values caching scheme scores                                              set variables lead improvement eval  maximized    Φ logφ    −w  ×λφ                         φ∈                                  uation function value ﬂipped value caching  weighting factor modiﬁcation                                                        scheme improving initial search phase  evaluation function major consequences search                                                        quantity low constant practice caching  behaviour especially boosts search early phases                                                        scheme enables evaluation neighbourhood  search figure illustrates realworld                                                        search position constant time figure demonstrates  network munin bayesian network repository                                                        large performance gains new caching schemes  gls ﬁnds optimalquality solutions  times faster                                                        previous stateoftheart caching scheme  average                                                          thirdly gls initializes search randomly    gls  differs gls number components                                                        shown strong initial solutions  parameter setting caching scheme                                                        ones obtained mb lead better overall solu  initialization modiﬁcations contribute signiﬁ                                                        tions kask dechter  consequently gls initial  cantly gls’s improved performance detailed analy                                                        izes search using mb variant mbw  section  sis individual importance hutter                                                                                         improves quality solutions consider   firstly thorough experimental analysis showed                                                        ably instances speeds search optimal  park states “gls parameters                                                        solutions orders magnitude                                                                                          order achieve meaningful guidance evaluation study version gls additional  function areas search space probability zero treat preprocessing stage based ve preprocessing ve  logφv  − φv    ﬁxed applied potential entries ob  weighting factor  make penalties comparably large tained parameter   results standard                                   stats gls     gls              bbmb               aomb                   distribution                                     opt default orig   static dynamic static dynamic                                                 random networks           baseline                                                                                                                                                                                                                                                grid networks              baseline                                                                                                                                                                                                                                                                 table  scaling performance random networks grid networks network size domain size number  parents  each problem distribution  networks gives average induced width opt number  networks quasioptimal solutions provably optimal better solution quasioptimal  each algorithm problem distribution list average time ﬁnd quasioptimal solution algorithm did  ﬁnd quasioptimal solution instances  cpu seconds average time solved instances  parentheses number unsolved instances followed average approximation quality instances    gls  algorithm  ∞ yields pure ve result   experiments random instances                                                    ing reduced network quickly solved gls  ﬁrst experiments each network executed  eliminated variables instantiated optimally each algorithm maximum  cpu seconds  linear time like regular ve                       best solution run algorithm                                                        quasioptimal second experiment ran    experimental results                               bb algorithms long time obtain provably opti  conducted number computational experiments mal solution qualities agree  compare performance scaling behaviour orig quasioptimal solutions fair comparison  inal gls algorithm gls current stateoftheart report times each algorithm requires ﬁnding quasi  mpe solving marinescu et al  bb static optimal solution experiment addition  mb heuristic sbbmb bb algorithm mb tree ally report time required proving optimality finally  elimination heuristic bbbt claimed state deﬁne approximation quality algorithm run  oftheart mpe solving marinescu dechter  ratio probability solution  introduced bb dynamic mb heuristic dbbmb quasioptimal probability  versions sbbmb dbbmb employ    ﬁrst experiment evaluates various algorithms  andor search tree called saomb scale important instance characteristics network  aomb                                                 size domain size variables network den    used radu marinescu’s implementations  sity controlled number parents each node  bbmb dbbmb saomb daomb     furthermore   created instances random network generator pro  used marinescu’s implementation gls instead vided radu marinescu described mari  original java implementation park park  nescu et al  topologically sampled variables  orders magnitude faster lat guarantee nonzero joint probability randomly picked   ter instances tried gls implementation evidence variables table  shows small easy net  written employed ﬁxed parameter setting works identiﬁed “baseline” table original gls                                                                                                   hρ nρi  gls overall best bb algorithms competitive gls   performing ﬁxed ibound ib ∈       each scaling  performance al  bb algorithm preprocessing stage gls im gorithms gls degrades rapidly marinescu et al  proves performance structured networks set  showed sbbmb scales better domain                                                        size original gls algorithm    experiments carried compute servers each ﬁrmed experiments table  results fig  equipped dual ghz intel xeon cpus kb cache ure show gls substantially outperforms sbbmb  gb ram  running linux version  build  imple larger relative variability runtime  mentation benchmark instances used available online creases sbbmb remains constant gls  httpwwwcsubccalabsbetaprojectsslsmpe                                                                               report results bbbt implementa gls does outperform algorithms  tion available correctly handle networks generated terms runtime ﬁnding quasioptimal solutions  rees httpwwwicsuciedu˜radumreeshtml terms solution quality given ﬁxed time                                                                                                                                                                                          −                                                               gls                                                                                                                                −                                                                                                                                                                                                                                         −                                                 gls −                                                                                                                 gls        cpu  time −                                             −                                                                   s−bbmb                                       d−bbmb                                                                                                        −                                              s−bbmb                                                              −                   gls                                                                                                                                                            gls      −                                                                         − − − − −          −   −                                                                                                                                    s−bbmb                        original gls                maximal induced width       cpu time ﬁnd optimal solution approximation quality gls scaling induced width                                         gls sbbmb  figure  cpu time required gls sbbmb solve random network instances optimality each point  result single run instance instances summarized table  cputime  algorithms indicated line comparison quality reached three algorithms gls gls  bbmb  cpu seconds instances gls best known solution quality approximation  quality  each point ﬁgure result single run instance gls sbbmb  lines show approximation quality gls scaling induced width random networks  variables  domain size  maximal node degree  each induced width based run each  instances plot  median runtime ﬁnding optimal solution errorbars based quantiles employ  means standard deviations bb algorithms did succeed ﬁnding optimal solution network  example networks induced width  gls took  seconds worst case sbbmb failed ﬁnd  optimal solution   networks  seconds    seen table   link network solved  visualized figure scaling random grid net bb algorithms gls gls ﬁnd optimal  works scatter plot compares original gls gls lution cpu second interestingly mb ﬁnds  sbbmb given maximum computation time tight upper bound solution quality  cpu millisec  possible gls ﬁnds quasioptimal onds feasible ibounds comes close  solutions approximation quality constantly tight lower bound consequently combination sls   sbbmb scales better origi mb ﬁnd optimal solution prove optimality  nal gls gls shows better scaling behaviour cpu second  average quality difference gls grows  gls sbbmb relative variability  conclusion future work  increases network size                                                        work identiﬁed various weaknesses gls    scaling results extended second ex                                                        previously bestperforming sls algorithm mpe prob  periment studied impact induced width                                                        lem introduced gls novel variant gls pays  networks performance gls vs gls                                                        attention important concerns algorithmic  bb algorithms used networks generated                                                        complexity search step thorough parameter tuning  bngenerator allows generate networks                                                        strong guidance evaluation function wide range  accurate upper bound induced width                                                        mpe instances gls widely outperforms gls  sults figure show induced width major                                                        bestperforming exact algorithms bb algo  effect algorithm performance gls gls                                                        rithms deﬁned stateoftheart mpe solving  scale better induced width bb algo                                                        importantly demonstrated performance gls  rithms omit saomb daomb worse                                                        scales better gls bb algorithms  dbbmb attribute bb algorithm’s mb                                                        network domain size network density  heuristic guidance impaired high induced widths                                                        induced width gls shows best performance    experiment studied realworld networks                                                        realworld instances  bayesian network repository gls                                                          contrast recent claims stochastic local search al  performs large networks low                                                        gorithms competitive mpe solving marinescu et  duced width easily solved ve show                                                        al  results establish sls stateoftheart ap  table  short preprocessing stage   signiﬁcantly                                                        proach mpe solving merits investigation  improves performance gls structured net                                                        particular anytime characteristics excellent scaling  works making faster bb algorithms op                                     timal ibound network particular note preprocessing   performed  additional runs                                                        hours instances diabetes munin         httpwwwpmrpoliuspbrltdsoftwarebngenerator runs solved diabetes network munin    httpwwwcshujiacillabscompbiorepository  network solved highlights importance pre    study gls eventually ﬁnds optimum processing structured networks
