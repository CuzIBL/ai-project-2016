                        learning    payoff   functions     inﬁnite   games                    yevgeniy  vorobeychik   michael  wellman    satinder  singh                                           university michigan                                      artiﬁcial intelligence laboratory                                               beal avenue                                      ann arbor  mi    usa                                 yvorobey  wellman  baveja    umichedu                                                                                     abstract                          identify game restrictive game                                                        limited data entailing generalization observed       consider class games realvalued    stances approximating payoff functions using supervised      strategies payoff information available learning regression methods allows deal contin      form data given sample strategy  uous agent strategy sets providing payoff arbitrary      proﬁles solving games respect strategy proﬁle doing adopt functional forms      derlying strategy space requires generalizing sistent prior knowledge game ad      data complete payofffunction representa mit biases forms facilitating subsequent game analysis      tion address payofffunction learning stan equilibrium calculation      dard regression problem provision captur paper present ﬁrst investigation approxi      ing known structure symmetry multiagent  mating payoff functions employing regression lowdegree      environment measure learning performance     polynomials explore example games      consider relative utility prescribed strate complete information realvalued actions      gies accuracy payoff functions standard ﬁrstprice sealed bid auction players      se demonstrate approach evalu    symmetric value distributions solution game      ate effectiveness examples twoplayer wellknown krishna  availability analytical      version ﬁrstprice sealedbid auction form proves useful benchmarking learning approach      known analytical form ﬁveplayer market  second example ﬁveplayer marketbased schedul      based scheduling game known solution   ing game reeves et al  time slots allocated                                                        simultaneous ascending auctions milgrom     introduction                                       game known solution previous work iden  gametheoretic analysis typically begins complete tiﬁed equilibria discretized subsets strategy space  scription strategic interactions game  sider prior question determining game actually  preliminaries  given database game experience direct  speciﬁcation possible target learning applied  notation  games shoham et al  agents avail generic normal form game formally expressed  able actions outcomes deterministic game ∆si  uis  refers set players                                                                       identiﬁed through systematic exploration instance  number players si set strategies                                                                ask agents play each strategy proﬁle en available player set ∆si simplex                                                                         ∈  tire joint strategy set record payoffs each mixed strategies si finally uis  sm                                                                                             ×· · ·×  →   joint action space small limited nondeterminism payoff function player players jointly  handled sampling coordinating exploration play      sm each sj sj com                                                                                          ∈  joint set does pose difﬁcult issues brafman tennenholtz mon assume von neumannmorgenstern utility allow  example address carefully case common ing agent i’s payoff particular mixed strategy pro  stochastic games brafman tennenholtz  ﬁle uiσ  sσs σmsmuis                                                                             ∈       · · ·  general problem maintaining equilib σj  sj   mixed strategy player assign                                                                →          rium learning algorithms brafman tennenholtz ing probability each pure strategy sj sj                                                  probabilities agent’s strategy set∈add     difﬁculties posed intractably large inﬁ σj ∆sj   nite strategy sets make problem tractable it∈will convenient refer strategy pure  reducing number proﬁles agents allowed mixed player separately remaining  play comes cost transforming game players accommodate use denote joint  different game entirely instead seek strategy players player i−  nash equilibrium                                 approximation quality directly terms distance  paper concerned oneshot normalform tween uˆ terms strategies dictated  games players make decisions simultaneously uˆ evaluated respect appeal  accrue payoffs game ends singleshot notion approximate nash equilibrium  nature preclude learning experience deﬁnition  strategy proﬁle σ  σ     σm constitutes  fact repeated episodes allowed long actions nash equilibrium game ∆s                                                                                                  affect future opportunities condition future strategies σi ∆si uiσi σ   uiσi σ  game payoff data obtained observations  ∈      ∈              −      ≥       −                                                           propose using  deﬁnition mea  agents playing game simulations hypo                                                        sure approximation error uˆ employ evaluat  thetical runs game cases learning                                                        ing learning methods known com  relevant despite fact game played                                                        pute  straightforward manner let denote i’s best                                                                                      i∗                                                        response correspondence deﬁned si∗σ      faced oneshot game agent ideally play                                 −           ∈                                                        arg maxs uisi σ  clarity exposition  best strategy given played agents         −                                                         si∗σ singlevalued let σˆ solution nash  conﬁguration agents play strategies best −                                                        equilibrium game ∆s   uˆ  σˆ   sponses constitutes nash equilibrium                                                                                      nash equilibrium true game ∆s                                                                                                    deﬁnition  strategy proﬁle      sm constitutes   maxi uisi∗σˆ σˆ uiσˆi σˆ                                                                 ∈         −    −  −        −  purestrategy nash equilibrium game si  uis  general unknown amenable                                                  si si uisi uisi   analysis developed method estimating              ∈     ∈          −   ≥       −  similar deﬁnition applies mixed strategies al data  lowed                                                  remainder report focus special case                                                        general problem action sets realvalued  deﬁnition  strategy proﬁle σ  σ     σm tervals si    restrict attention sym  stitutes mixedstrategy nash equilibrium game    metric games limit number variables  ∆si  uis  σi    ∆si   payofffunction hypotheses using form aggrega                              ∈         ∈                                     uiσi σ uiσi σ                             tion agents’ actions assumption symmetry        −   ≥        −    study devote particular attention games allows adopt convention remainder                                                        paper payoff usi agent playing si  exhibit symmetry respect payoffs                                 −  deﬁnition  game ∆si  uis  symmetric                                                      polynomial  regression    si  sj uisi  uj sj    ∀    ∈                            −            −      class models consider nthdegree separable  si  sj                       −    −                            polynomials  symmetric games relatively compact descriptions                                                                                                                                      usi φs  ansi    asi  present associated computational advantages given         −                                                                              · · ·                     symmetric game focus subclass symmet               bnφ     bφs    ric equilibria arguably natural kreps                −    · · ·     −                                                        φs represents aggregation strategies  avoid need coordinate roles fairly general   −  settings symmetric games possess symmetric equilibria played agents twoplayer games φ  nash                                          simply identity function refer polynomials                                                        form  separable lack terms combining si                                                        consider models terms example    payoff  function  approximation                    the− nonseparable quadratic    problem  deﬁnition                                                                                                                                  usi φs  asi  asi  bφ  given set data points each describing         −                       −                                                                                    bφs  csiφs   instance agents played strategy proﬁle realized                     −         −  value      vm deterministic games complete note   coincide case     information simply incomplete information  experiments described employ simpler  stochastic outcomes random variable speciﬁcally                                                        version nonseparable quadratic takes     independent draw distribution function advantage quadratic form ana  expected value                                  lytically solve nash equilibrium given general non    payoff function approximation task select func separable quadratic  necessary ﬁrstorder condition  tion uˆ candidate set minimizing measure                                                        interior solution si   cφs ia  deviation true payofuf function true                     −          −                                                        reduces si   aa separable case  function unknown course base selection          −                                                        nonseparable case additive aggregation φsums   evidence provided given data points                                                      −    goal approximating payoff functions typically restrictions inherent approach  predicting payoffs assessing strate course recognize tradeoffs complexity hy  gic behavior assessing results measure pothesis space generalization performance  ji sj  derive explicit ﬁrstorder condition  strategy aggregation       symmetric equilibrium si  aa          noted consider payoff functions                        −             −    purestrategy equilibrium necessarily exist dimensional strategy proﬁles form usi                                                                                                     −  separable polynomial model guaranteed ex fsi φs long φs invariant different                                                                −                −  ist nonseparable case learned quadratic permutations strategies payoff func  concave experiments follow learned tion symmetric actual payof−f functions  nonseparable quadratic does pure nash equilib example games known symmetric constrain  rium generate arbitrary symmetric pure proﬁle φs preserve symmetry underlying game                                                               −  approximate nash equilibrium                           experiments compared three variants φs                                                                                                       −    difﬁculty arises polynomial degree compact simple sum φsums sec                                                                                                   −  higher three nash equilibrium ond ordered pair φsum φss φsss                                                                                                     −  case select equilibrium arbitrarily          sj   variant φidentity  sim                                                          ji                               −       −                                                        ply  takes strategies direct unaggregated form    local regression                                 enforcep symmetry requirement case sort  addition polynomial models explored learning using strategies                                                                       −  local regression methods locally weighted average  locally weighted quadratic regression atkeson et al   firstprice sealedbid auction  unlike modelbased methods polynomial regression                                                        standard ﬁrstprice sealedbid fpsb auction game  local methods attempt infer model coefﬁcients                                                        krishna  agents private valuations good  data instead methods weigh training data points                                                        sale simultaneously choose bid price representing  distance query point estimate answer—in                                                        offer purchase good bidder naming high  case payoff strategy proﬁle point—using                                                        est price gets good pays offered price  function weighted data set used gaussian weight                                                     agents receive pay classic setup ﬁrst ana  function  e−  distance training lyzed vickrey  agents identical valuation dis  data point query point weight tributions uniform   distributions com  assigned training point                      mon knowledge unique bayesian nash equilibrium    case locally weighted average simply                                                                            game agent bid m− xi xi i’s valua  weighted average payoffs training data points tion good  payoff arbitrary strategy proﬁle locally weighted note strategies game generally games  quadratic regression hand ﬁts quadratic incomplete information bi      func  gression weighted data set each query point tions agent’s private information→we consider                                                        stricted case bid functions constrained form    support vector machine  regression               bixi  kixi ki     constraint transforms  category learning methods used support action space real∈ interval corresponding choice  vector machines svms details regarding learn parameter ki easily restricted strategy  ing method refer interested reader vapnik  space includes known equilibrium game                                                                    experiments used svm light package joachims si  ki  m− equilibrium   opensource implementation svm clas restricted game agents constrained strategies  siﬁcation regression algorithms                  given form                                                           focus special case   corre    finding mixed  strategy equilibria               sponding equilibrium    twoplayer  case polynomial regression able ﬁnd ei fpsb derive closedform description  ther analytic simple robust numeric methods com actual expected payoff function  puting pure nash equilibria local regression svm                                                                                         learning fortunate access                                                                                     −    −                                                                                        closedform description function learning                                                                                                  ≥  furthermore interested mixed strategy ap           −              proximate equilibria polynomial models solution            methods yield pure strategy equilibria                 availability known solutions example fa     particular learned model amenable cilitates analysis learning approach results  closedform solution approximate learned game summarized figure  each methods classes  ﬁnite strategy grid ﬁnd mixedstrategy equi functional forms measured average  varying train  librium resulting ﬁnite game using generalpurpose ing set sizes instance evaluate performance  ﬁnitegame solver employed replicator dynamics fu separable quadratic approximation training size  denberg levine  searches symmetric independently draw strategies     sn  uniformly  mixed equilibrium using iterative evolutionary algorithm   corresponding training set comprises   treat result ﬁxed number iterations points si sj usi sj         approximate nash equilibrium learned game     given  ﬁnd best separable∈  quadratic ﬁt uˆ tothese points ﬁnd nash equilibrium corresponding uˆ indicated inferior learning performance displayed  calculate  strategy proﬁle game  nash equilibrium respect actual payoff func results game provide optimistic view  tion repeat process  times averaging results regression expected perform compared  strategy draws obtain each value plotted figure  discretization game quite easy learning                                                        underlying payoff function captured lower                                                    degree model experimental setup eliminated                              sample best               issue noisy payoff observations employing ac                              separable quadratic                         non−separable quadratic   tual expected payoffs selected strategies                              rd degree poly                              th degree poly                                                       marketbased    scheduling  game      ε                                                        second game investigate presents signiﬁcantly                                                   difﬁcult learning challenge ﬁveplayer symmetric        average                                           game analytic characterization theoreti                                                    cally known solution game hinges incomplete infor                                                        mation training data available simulator                                                   samples underlying distribution                                                          game based marketbased scheduling scenario                                                       reeves et al  agents bid simultaneous auc                                                             number strategies training set  tions timeindexed resources necessary perform                                                        given jobs agents private information job  figure  epsilon versus number training strategy points lengths values completing jobs various dead  different functional forms                       lines note space strategies quite complex                                                        dependent multidimensional private information                                                        preferences price histories time slots                                                        fpsb example transform policy space                                           actual function      real interval constraining strategies parametrized                                   learned quadratic    form particular start simple myopic policy—                                                        straightforward bidding milgrom  modify                                                    scalar parameter called “sunk awareness” denoted                                                        controls agent’s tendency stick slots                                                                 currently winning details motivation                                                     sunk awareness inessential current study                                                        note   optimal setting involves        payoffss                                         tradeoffs generally∈ dependent agents’ behavior                                                      investigate learning game collected data                                                        strategy proﬁles discrete set values                                                                 accounting symmetry represents∈                                                         distinctstrategy proﬁles evaluation purposes                                                    treat sample averages each discrete proﬁle true                                                                                   expected payoffs grid                                                           previous empirical study game reeves  figure  learned actual payoff function et al  estimated payoff function dis  agent plays  learned function separable crete grid proﬁles assembled strategies  quadratic particular sample                 computing approximate nash                                                        equilibrium using replicator dynamics    seconddegree polynomial forms generated training set based data  tried quite game   quadratic strategies  samples proﬁle regressed  regression outperforms model labeled “sample best” quadratic forms calculated empirical  values  payoff function approximated discrete respect entire data set computing maxi  training set directly derived equilibrium model mum beneﬁt deviation data emp     simply nash equilibrium discrete strategies maxi maxsi si uisi sˆ uisˆ  si  training set ﬁrst success quadratic model strate∈gy set ∈player represented− − data set  surprising actual payoff function  game symmetric maximum players  piecewise differentiable point discontinu dropped agent strategy sets identical  ity figure  appears quite results presented table  nash  smooth approximated quadratic polynomial equilibria learned functions quite close pro  higherdegree polynomials apparently overﬁt data duced replicator dynamics  values quite bit                                                              −       separable quadratic  lower  grid point determined    post hoc running proﬁle simulations                                                                                 φsum                                                             agents playing  agent deviates                      φsumsum squares  strategies                                                                                       φidentity                                                                               sample best symmetric            method          equilibrium si                                      sample best           separable quadratic                     ε     nonseparable quadratic                          replicator dynamics                                                             average                                                                table  values  symmetric purestrategy equilib  ria games deﬁned different payoff function approxima  tion methods quadratic models trained proﬁles   conﬁned strategies                                                                                                                                                                                                      comprehensive trial collected  million ad     number strategies training set  ditional samples proﬁle ran learning algorithms   training sets each uniformly randomly selected  discrete grid         each training set included figure  effectiveness learning separable quadratic                                                      model different forms φs  proﬁles generated ﬁve                         −  agent strategies grid case pro                                                                −      non−separable quadratic  ﬁle does typically appear complete data   set developed method estimating  pure sym                      φsum                                                             metric approximate equilibria symmetric games based                      φsumsum squares  mixture neighbor strategies appear test set               φidentity  let designate pure symmetric equilibrium strategy                  sample best symmetric  approximated game sˆ ﬁrst determine closest                     sample best    neighbors sˆ symmetric strategy set represented ε  data let neighbors denoted   deﬁne mixed strategy α support                                                          average    probability playing computed based relative   distance sˆ neighbors α   sˆ    note symmetry allows compact−  representation−   −  payoff function agents choice   strategies deﬁne usi payoff  symmetric player playing strategy si                                      ∈                                                          agents play strategy  agents each independently                          −                                         number strategies training set  choose play probability α proba  bility exactly choose given                                                       figure  effectiveness learning nonseparable quadratic                                              model different forms φs          prα     −    α   α  − −                                         −                               −                            approximate  mixed strategy α     figure  regression separable                                                     quadratic produces considerably better approximate equi       −  max     prα usi αus  αus  librium size training set relatively small  si                   −          −   −   ∈                                                figure  shows nonseparable quadratic performs                                                      similarly results appear relatively insensitive    using method estimating  complete data gree aggregation applied representation  set compared results polynomial regression agents’ strategies  method simply selects training set pure polynomial regression methods employed yield                                         strategy proﬁle smallest value  refer purestrategy nash equilibria evaluated  method “sample best” differentiating methods generally produce mixedstrategy equilibria  case consider symmetric pure proﬁles la local regression learning methods svm gaussian  beled “sample best symmetric” pure proﬁles la                                                       radial basis kernel direct estimation using training  beled “sample best all”                           data discussed computed mixed strategy equi    interesting observe figures   libria applying replicator dynamics discrete approxima                                                                                         strict search best pure strategy proﬁle symmetric proﬁles tions learned payoff functions ensure  average better terms  restriction  imposed                                                 case direct estimation training data data
