                       representations action selection learning                         realtime observation task experts                                  mark wood joanna bryson                              artiﬁcial models natural intelligence amoni                                      department science                                           university bath uk                                   cspmawjjbcsbathacuk                        abstract                          apes understanding complexity characteristics                                                        task key understanding human intelligence      association perception action key harnessing approach ai      learning observation general program      level task imitation particular question  overview      structure information learn      ing tractable resourcebounded agents  coil adaption generic imitation learning roy’s      introducing combination symbolic represen   language learning cell cell      tation bayesian reasoning demonstrate    convincing examples date realtime interactive social      theoretical empirical improvements  learning enables robot learn names various toys      generalpurpose imitation originally based using sorts input infant cell      model infant social learning     coil detailed roy  wood bryson      show prior task knowledge selective    skeletal overview coil clarify      tention rigorously incorporated loss ma parts relevant extentions described later      trices automatic relevance determination      spectively                                                          rawsensordata      introduction                                                                  featureextraction                                              programlevel imitation byrne russon  orthe    achannels  acquisition behavioural structure observation                                                           pchannels  underresearched ﬁeld ai robot ai effort  rightly directed actionlevel imitation repro                  eventsegmentation  duction movements involving ﬁne degree motor  trol highly complex difﬁcult task needs aevents  solved robot able acquire structural data pevents  using ‘intelligent’ virtual environments                       cooccurencefiltering  implicitly deal lowlevel actions gain access  rich class higherlevel problems unreal tournament dig                                                          apevents  ital extremes  example environment  popular looking problem thu  rau et al  le hy et al  domain                 recurrencefiltering  choice underpins paper coil wood  bryson                                        mecandidates    paper demonstrate formal bayesian  framework incorporated complex modular learn                      mutualinformationfiltering  ing through widen potential applicability  theory signiﬁcantly improve learning performance meitems  practise add natural extensibility tried  tested bayesian methodology experiments en  able examine broader issue combinatorial figure  inputs outputs each stage coil  complexity social learning social learning important wood bryson   mechanism acquiring intelligent behaviour — arguably  accounts massive accumulation culture artifacts learning coil ﬁve constituent stages  seen humans compared nearest biological relatives processing figure  designed function embed                                                    ijcai                                                     dedinanimitator agent observing conspeciﬁc expert agent actions required imitation task lie discrete space  executing given task shared environment input ‘nearness’ hard deﬁne partic  ﬁrst stage consists incoming raw data im ularly useful concept example far jump  itator’s sensors during feature extraction data turn right use information  directed separate channels types way perceptual channels similarly unrelated  action channels receive data pertaining actions taken simply learning respond different shapes  expert perception channels receive data pertain interested different proprioceptive  physical position  ing identical perceptual state expert ing thoroughly categorised ‘visual’ stimuli  channels data segmented pevents identifying object vs agent comparisons  respectively psubevents accord point using thoroughly discrete representation  ing set preprogrammed triggers event seg actions perceptions coil  mentationthecooccurrence filter simply binds obvious solution appear reduce level  occurring pevents apevents shunts abstraction learning action selection oc  queue called stm short term memory curs example descending ﬁnergrained mus  new apevent arrives stm compared cle motor position spaces reclaim continuity  each turn recurrence filter problems ﬁrstly spaces  scans cooccurring psubevent pairs unusual discontinuities lead problems  binds motivationexpectation inverse kinematics ensnare traditional robotics sec  candidate stores mtm mid term memory   ondly complexity inherent remaining imitation  finally mutual information filter calculates mutual subsequent action selection process demands reduced  information score each candidate using space generic operators learn  complex algorithm described wood ing  different turnright commands each varying  bryson  details candidates scores degree turn arc simply learn initiate turn  exceed predetermined threshold saved ltm long right check stopping criteria note  term memory items                             solution robust uncertain motion sensing    items represent observed perception suming stopping homing criteria perceivable  action pairs note original agent range degrees during turn  model bryson wood  consequently  used create reactive imitative behaviour imita algorithms  tor’s sensors deﬁne perception space  through task surroundings change items performance coil affected certain char  used create maps regions space im acteristics inherited cell algorithms firstly  itator’s action repertoire practise imitator searches recurrence filter designed search events recurring  perception chunks stored ltm match short history observations appropri  current perceptual state matches highest pri ate aspects infant learning assume frequent rep  ority match selected ranked mutual information score etition wordobject pairs task learning gen  associated action chunk returned executed eral arbitrarily long gaps recurring                                                        ceptionaction pairs problem simply increasing                                                        size recurrence filter window arriv    shortcomings                              ing apevent compared present                                                        clearly results combinatorial problems size  coil previouslyreported success queue increases mutual information filter simi  performing imitation tasks discovered number lar scaling problem cubic complexity number  ﬂaws prevent scaling difﬁcult prob elements mtm general grow  lems                                                 bound exponential number monitored channels                                                        grows complexity task domain addi  representations                                       tionally probabilities used calculation mutual  coil’s primary weakness results trying represent information frequentist opposed bayesian approx  general action perception cell imations consequently sensitive noise caused  uses speech vision cell receives continuous mi small frequency counts rarely observed events roy  crophone data later converted discrete phonemes during tackles interpolating probabilities priors  event segmentation coil receives continuous action data choice prior mass parameter required tech  parsed discrete action segments crucial nique signiﬁcant effects resulting probabili  difference spaces discrete ob ties particularly events question infre  jects lie omit details roy’s metric roy quent case applications    intuitively phonemes shapes desire robust method  inﬁnite variation mapped continuous  space using histograms notion ‘nearness’ rel limited relatively actions initiated  atively welldeﬁned contrast limited set executable given time                                                    ijcai                                                     model                                                probabilities action class membership given                                                        ceptual state achievable using softmax activation  wish implement learning algorithm                                                        function network output units bridle   operate coil framework minimise po                                                        minimising crossentropy error function network  tential problems outlined speciﬁcally                                                        weights bishop   empirical testing  scalable  terms memory requirements learn chose include three hidden units network  ing complexity                                       results particularly sensitive  incremental  observations used knowl choice currently looking bayesian model  edge consolidated natural way                selection techniques selecting number hidden units  rigorous  having output interpretable justiﬁable section  given node structure network  through established mathematical argument            used fully connected simple feedforward                                                        structure shown figure   robust  prone failure processing unusual  forseen extreme events                                                                 outputscorrespondtoactionclassprobabilities    preferable algorithm sufﬁ                                                                              ciently generalpurpose applied similar learn  ing problems ﬁeld bayesian framework  good place begin allows each observed event  update prior belief efﬁcient welldeﬁned manner  bishop   algorithms  make use question  use order obtain desired posterior beliefs chose biases  multilayer perceptron mlp architecture given  certain set constraints provides bayesian posterior proba  bilities outputs speciﬁc conﬁguration  section                                           binaryinputsgroupedbyperceptionchannel      network architecture                             figure  diagram mlp architecture binary input  parts coil prone kinds problems vector concatenation ofc encoded symbols each  scribed recurrence mutual information ﬁl perception channel three hidden units soft  ters replace require new algo max activation outputs consequently correspond  rithm receive perceptionaction data cooccurrence posterior probabilities action class membership arrow  ﬁlter output behavioural map mlp terms map shows direction forward propagation biases shown ex  looks like classiﬁer network receives perceptual data plicitly clarity  assigns appropriate action class allow  mlp learn classiﬁcation translate ob network training scheme uses bayesian regularisa  served perceptionaction pairs appropriate set train tion separate hyperparameters each weight  ing examples each example consist set input groups ﬁrstlayer weights ﬁrstlayer biases secondlayer  variables set target variables case input weights secondlayer biases bishop    variables correspond observed perceptual state training backpropagation  cycles  expert target variables correspond scaled conjugate gradient search fewer convergence oc  observed action question encoding use curred followed reestimation hy  variable sets                              perparameters using evidence approximation technique     explained    assuming     mackay cycle reestimation retraining  perceptual categories item left     carried  times test data network  item  visible implicit relationship each sisted querying possible combinations perceptual  lie metric space state evaluate probable action assigned  represented ordinal variables use purely state classiﬁer finally posterior probabilities  categorical ofc encoding input bishop  marginalised according observed data mackay   suppose given perception channel possible step does affect prob  symbolic states symbol represented able action class signiﬁcant effects loss matrices  vector bits ith bit set   added section   perception channels concatenation empirical evidence showing increased learning perfor  vectors produces complete required binary input mance new algorithm section  vector length    nmiftherearek observable examine review theoretical  actions equivalent classiﬁcation problem criteria set beginning section ask  target classes create output node satisﬁed  each class stated desirable scalable  far learning complexity concerned net  outputs bayesian interpretation posterior work training time increases linearly number                                                    ijcai                                                     observed events compared combinatorics  task   original algorithms section  mlp ﬁrst task involved collecting health vials  function requires storage equal number net socalled ‘pickups’ available ut various locations  work weights opposed potentially boundless number game map data originally received  stored items                                  processed coil embedded aicontrolled  incremental  increase efﬁciency bot programmed observe environment  lief accumulation property bayesian framework humancontrolled bot carrying task used three  observation taken account consolidated different ‘tactics’ during demonstrations  prior knowledge                                      cw   tend turn clockwise vials visible  rigorous  fact interpret mlp outputs acw tend turn anticlockwise  posterior probabilities wellproven property type  network totally independent domain mix ﬁxed tendency  we’re working                                        trials each tactic carried total  tri  robust  parametric reestimation carried each als each lasting approximately  seconds during origi  network training cycle serves minimise problems nal experimental runs data arriving channels post  caused local minima relating say weight initialisation feature extraction saved prior processing                                                        allowed compare new learning algorithms                                                        data sets mlp replaces recurrence    experiments                                        mutual information ﬁltering stages coil ﬁrst                                                        three stages remaining unchanged performance  evaluate new model tested comparison fed data decision tree algo  data collected original coil experiments data rithm quinlan   gathered unreal tournament ut commercially performance metric derives representation  released multiplayer ‘first person shooter’ game digi behaviour mapping discrete regions perceptual  tal extremes  term suggests user space discrete actions deﬁned behaviour  agent’seye view game direct realtime control based demonstrations ‘ideal’ map percep  avatar’s actions ut supports remote control tion action task proportion learned  agents sending commands game server net haviour matches ideal allowed assign ‘per  work provides framework allowing external pro centage correct behaviour’ score each trial results  grams direct agent’s actions ut provides comparing three techniques shown figure  viable platform testing strong ai humans ai seen ﬁgure mlp grey bars generated  compete interact realtime spatially situated universally perfect behaviour task correcting er  main game server sends categories sensor data rors coil’s native algorithms black bars  client ﬁrst synchronous regular inter ingly white bars performs perfect clas  vals client informed agent’s status health siﬁcation  ammo current weapon second asynchronous  example wall bumped footstep heard  task   damage taken                                   second task required expert locate destroy en    data viewed highly dynamic emy bots environment contained equal  highdimensional mixture categorical continuous vari number friendly bots each trial lasted long took  ables akin sensory data acquired real world task completed typically  seconds  similarities include physics simulation collisions tactics cw acw mix used analogously task   gravity sound light transmission ai agents’ bots’ trials each total  algorithms  sensor data incomplete sense reduced training methods remained task  subset game variables observable bots previous results summarised figure  limited virtual sensors example imitator mlp lefthand grey bar each group provides small  know health state expert signifcant ttest  increase performance  affect expert’s choices environment contains coil black bars white bar  independent features each represented task performs better coil inspection  number ways problem assimilating data clear majority trials asso  haviour agent observation far simple ciations necessary form fully correct  ﬁrst three stages coil each serve reduce com haviour observed speciﬁcally mis  plexity problem section  arrives classiﬁcations turning enemy  inputs new algorithm tractable state absence associations imitator tended adopt    short ut agents deal realworld temporally dominant turning direction observed consequently err  bounded cognitive constraints combinatorial enemy left enemy right state  complexity learning makes ideal test subjects common mistake ﬁre enemy centred  research                                     sights network                                                    ijcai                                                                  task                          task                          ard    figure  comparative performance different learning algorithms variety tasks black bars correspond  original coil algorithms white bars correspond grey bars correspond new mlp classiﬁcations  second study righthand grey bar corresponds moderated loss matrix text details  study shows automatically determined relative importance perception channel input sets error bars show  standard error means    algorithms performance improved time sig penalty misclassiﬁcation informally  niﬁcantly ttest  introducing loss matrix expect equivalent giving imitator  represent prior task knowledge righthand grey bars each instruction “only shoot you’re sure” prior acting  group extentions talk results applying matrix task  network outputs  section                                         shown figure righthand grey bars each group                                                        improvement expected fewer cases ﬁring    bayesian extentions                              enemy position relatively  discussed section  probabilistic interpretation simple example application technique does  results possible network model highly desirable demonstrate ease prior knowledge  allows bayesian techniques applied mally incorporated model sys  network outputs discuss tech tematically altered test effect output behaviour  niques show preliminary results                                                        selective attention  loss matrices                                         likely given task small subset  general decision theoretic terms loss matrix describes available perceptual state required good  relative penalties associated misclassifying given formance far paper subset chosen  input bishop  case hand mlp model enable make selec  matrix having elements lkj representing loss resulting tion automatically sound bayesian framework  assigning action aj given perceptual state automatic relevance determination neal    fact ak assigned decisions achieved using different hyperprior instead grouping  minimising risk equivalently using following weights independent regularisa  discriminant classify given perceptual state  tion hyperparameters weights associated each input                                                        hyperparameter coefﬁcients vary     c               c                 ∀         proportion inverse posterior variance weight dis          kj             ki                      tribution input given input high coef                                                ﬁcient value weight distribution input low  akx obtained marginalised net variance input little bearing ultimate classi  work output probabilities demonstrate applied ﬁcation input low relevance using similar training  simple loss matrix networks generated during task  reestimation scheme described earlier hyperpa                                                      rameters used determine relative relevance                                                     different network inputs case correspond                 lkj                           different aspects environment method                                                     automatic attention selection broader set chan    action turn left   note loss matrix zeros main diagonal ones ev  turn right matrix speciﬁes ‘accidentally’ ﬁring erywhere describes discriminant equivalent simply choos  instead correctly turning incur ﬁve times greater ing class greatest posterior probability                                                    ijcai                                                     
