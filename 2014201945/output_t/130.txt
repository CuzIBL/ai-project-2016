   color learning mobile robot             autonomy changing                                              illumination                                      mohan sridharan      peter stone                                     university texas austin usa                              smohaneceutexasedu pstonecsutexasedu                          abstract                          colored objects environment manually                                                        given sequence actions execute learning cur      central goal robotics ai able riculum  separately shown robot      ploy agent act autonomously real world recognize illumination changes switch color maps      extended period time commonly   appropriate times given ﬁxed set pretrained color      asserted order agent maps  prior work limited controlled en      able learn deal unexpected environmental vironments solidcolored objects      conditions ability learn suf paper signiﬁcantly extends results enabling      ﬁcient true extended autonomy agent robot recognize illumination changed sufﬁ      able recognize abandon cur ciently require completely new color map      rent model favor learning new ing existing ones ii plan action se      learn current situation paper presents quence learning new color map online furthermore      fully implemented example autonomy   introduce hybrid colormap representation enables      context color map learning visionbased robot learn controlled environments including      mobile robot purpose image segmenta   textured surfaces algorithms run realtime      tion past research established ability robot physical robot enabling operate autonomously      learn color map single ﬁxed lighting uncontrolled environment changing illumination      dition manually given “curriculum” ac extended period time      tion sequence designed facilitate learning      paper introduces algorithms enable robot      devise curriculum ii recognize    problem speciﬁcation      lighting conditions changed sufﬁciently formulate problem solution      warrant learning new color map                 section  presents hybrid colormap representation used                                                        autonomous color learning section  describes ap    motivation                                         proach detecting signiﬁcant illumination changes  mobile robotic systems recently used ﬁelds  learn color model  diverse medicine rescue surveillance   key enabler applications development able recognize objects operate colorcoded  powerful sensors color cameras lasers world robot typically needs recognize discrete number  rich sensors come need extensive sensor colors ω ∈ −  complete mapping identiﬁes  calibration performed manually usually repeated color label each point color space  environmental conditions change signiﬁcantly  ∀p ∈   cpcqcr → ωω∈n−     focus visual sensor camera arguably  richest source sensory information important subtask ccc color channels rgb ycbcr  visual processing color segmentation mapping each im corresponding values ranging  −   age pixel color label signiﬁcant advances start modeling each color threedimensional  ﬁeld   algorithms com gaussian mutually independent color channels  putationally expensive implement mobile robot andor using empirical data statistical technique boot  involve time consuming offline preprocessing phase fur strapping  determined representation closely  thermore resulting segmentation typically quite sensi approximates reality gaussian model simpliﬁes calcula  tive illumination variations change illumination tions stores just mean variance statistics  require repetition entire training phase    each color reducing memory requirements    past research established robot efﬁciently train making learning process feasible execute mobile  color map based knowledge locations robots constrained resources                                                    ijcai                                                      aprioriprobability density functions color ω ∈   learn detecting illumination changes  −  given                                                      detect signiﬁcant changes illumination need                                         −         mechanism representing illumination conditions            ∼ √            · exp −      ci  μci  ccc ω                                        differentiating                                           σci                   π   σci                        hypothesized images lighting condi                                                     tions measurably similar distributions pixels          ∈                                     color space original image ycbcr format  ci cimin    cimax       represents value values ranging  each dimension reduce  pixel color channel ci μci σci represent storage retain useful information transformed  corresponding means standard deviations      image normalized rgb space    assuming equal priors ωn ∀ω ∈ −                                                                                                                                 each color’s posteriori probability given     rgb         rgb         rgb                        ∝                        ω ccc  ccc ω                three features                                                        sufﬁcient statistic pixel values represent partic  gaussian model color distributions described ular illumination condition set distributions  previous work  performs inside lab addi space quantized bins each dimension correspond  tion generalizes limited samples color ing images captured robot  distributions actually unimodal able handle minor need welldeﬁned measure capable detect  illumination changes settings outside lab ing correlation discrete distributions based  factors shadows illumination variations cause experimental validation use kldivergenceanentropy  color distributions multimodal robot unable based measure distributions  model colors properly using gaussians             space number bins each dimension    order extend previous work controlled                   n− n−                                                                                              bij  settings propose hybrid color representation uses  kla b−            aij · ln         gaussians color histograms histograms provide ex                           aij  cellent alternative colors multimodal distribu similar distributions smaller kl          tions   possible color values – each divergence kldivergence function  channel discretized bins store count pixels log observed color distributions reasonably  map bin histogram normalized robust large peaks observed color distributions  provide probability density function             affected images large amounts single                           histωbbb              color lack symmetry kldivergence eliminated            pcccω ≡                          using resistoraverage kldivergence rakld                            sumhistv alsω                  given set distributions corresponding different il                                                                                                      represent histogram bin indices cor lumination conditions previously shown   responding color channel values cand possible effectively classify distribution correspond  sumhistv alsω  sum values bins ing test image illumination classes ma  histogram color ωthea posteriori probabilities jor limitation know illumination  thengivenbyequation                                 ditions advance provide manually trained    unfortunately histograms generalize lim color maps each illumination make signif  ited training data especially samples observed icant extension need know different  training set minor illumination changes illumination conditions ahead time  source constraints prevent implementation operations illumination condition addition set                                                        distributions rgsampi calculate rakl dis  sophisticated smoothing histograms require                        storage wasteful colors modeled tances pair distributions dis  gaussians combine representations tribution distances di model gaussian  complement each colors gaus illumination changes signiﬁcantly average ra                                                        kl distance test distribution rgsampi  sian good ﬁt modeled using histogramsthe                             goodnessofﬁt decision online each color maps point outside range intra                                                        illumination distances di feature used measure    samples gaussian bad ﬁt                                                        detecting change illumination  modeled analytically using distributions mixture  gaussians weibull through methods expectation  maximization  methods involve param  algorithms learn  eter estimation schemes computationally expensive algorithms color learning adaptation illumina  perform mobile robots use hybrid repre tion change summarized algorithm  algorithm   sentation gaussians histograms works algorithm  enables robot decide learnthe  requires inexpensive computation addition robot au robot ﬁrst learns color map current illumination  tomatically generates curriculum action sequence based generating curriculum using world model described  object conﬁguration described section  algorithm  represents illumination condition                                                    ijcai                                                    algorithm  adapting illumination change – algorithm  autonomous color learning – learn  learn                                                require known initial pose colorcoded model  require each illumination ∈ −  color map   robot’s world  objects known positions     distribution rakld distances di               change trials    begin  current                          require color map list colors learned    generate curriculum learn colors  algorithm  require arrays colored regions rectangular shapes    generate rgsampcurrent space distribu  list each color consisting properties     tions distribution rakld distances dcurrent size shape regions color    save color map image statistics      require ability approximately navigate target pose    currentt ime − testt ime ≥ timeth             θ     rgtest  sample test distribution            maxcolors      − do                               timest   currt ime time —  maximum time                                                    davgtest     kldist  rgtestrgsamp       allowed learn each color     end                                            indo    davgtestcurrent lies threshold range  color  bestcolortolearn        dcurrent                                     targetpose  besttargetpose color       continue current color map                   motion  requiredmotion targetpose    davgtesti lies range dii    perform motion monitored using visual input       current                                           localization      use corresponding color map current           targetregionfound color     ∀i ∈ − davgtesti lies outside    collect samples   candidate region       range di                                         observed      relearn color map autonomously algorithm        possiblegaussianfitobserved      save distributions new illumination       learngaussparams colorsi       transition new color map subsequent op    learn mean variance samples         erations                                            gaussian good ﬁt samples       current                                   learnhistvals colorsi     end                                                  update color’s histogram using sam    testt ime  currentt ime                                  ples   end                                                 end                                                             updatecolormap                                                           valid color   collecting sample image distributions com    removefrommap  color   puting distribution rakl distances dcurrill                                                          end    periodically timeth   robot generates test dis   tribution rgtest computes average distance each set                                                         rotate target position  previously stored distributions rgsamp ifdavgtest  end  lies threshold range  corresponding                                                            currt ime  −  timest  ≥   timecolor   di robot transitions corresponding illumination                                                              rotationangle ≥ angth   condition lies outside threshold range     known distribution distances robot learns new color                                                             timest  currt ime  map collects image statistics used subse  end  quent comparisons changing threshold changes res  end  olution illumination changes detected  write color statistics color map  robot able handle minor illumination changes using  color map corresponding closest illumination condi  tion section  transition thresholds ensure  change illumination accepted iff occurs color facilitate color learning outside lab decides  frames smoothly transitions learned learn automatically determines learn  maps algorithm requires manual supervision   generates curriculum learning colors    brieﬂy planned color learning algo robot starting pose object conﬁguration  rithm algorithm  used lines   algorithm  robot starts known location color  previous algorithm  lines    − hadthe knowledge list colors learned list  robot prespeciﬁed motion sequence model object descriptions corresponding each color size shape  each color gaussian outside controlled lab location regions approach does require  setting color distributions multimodal human input applications particularly object  modeled effectively gaussians current algorithm locations change frequently illumination  signiﬁcantly extends previous approach ways efﬁcient handlabeling images generate  automatically chooses representations each curriculum robot decide order col                                                    ijcai                                                    ors learned best candidate object learning algorithm  possiblegaussianfit line  algorithm  –  particular color algorithm currently makes deci learn  sions greedily heuristically makes choices  determine maximumlikelihood estimate gaussian  step time actually planning subse parameters samples observed  quent steps aim large target object  draw samples gaussian – estimatednsize  moving little possible especially observed  colors known robot computes three weights each  dist  kldistobserved estimated  objectcolor combination                        mix observed estimated – data items                                                          numtrials     fd dc iw  fs sc iw  fu oc    sample items replacement data – set                                                           remaining items – set  functions dc sc oc represent  disti  kldistsetset  distance size object description each colorobject  end  combination function fd dc iassigns larger weights  goodnessofﬁt pvaluewheredist lies distri  smaller distances fs sc iassigns larger weights larger bution disti  candidate objects fu oc iassigns larger weights iff  object used learn color having wait  color learned object consists color color map andor action sequence each time envi  colors learned    ronment illumination changes just provide                                                        positions objects robot’s world plan    bestcolortolearn line  given                                                        curriculum learn colors autonomously adaptation    arg max     max    fd dc       c∈ i∈nc−                               illumination changes makes entire process autonomous                                                                                                       video robot learning colors seen online                      fs dc ifu oc                                                         wwwcsutexasedu∼austinvillapresearchauto vis  robot parses through different objects available  each color nc calculates weights color  experiments  chosen robot determines best target color ﬁrst provide brief overview robotic platform used  using minimum motion maximum size constraints followed experimental results    arg  max     fd dc       i∈n −                                                       experimental platform                       fs dc ifu oc    sony  ers aibo legged robot primary                                                        sensor cmos camera located tip nose  chosen color best candidate object limited ﬁeldofview horz vert im  maximum weight given heuristic functions ages captured ycbcr format hz resolution  robot chooses besttargetpose line  learn color  ×  pixels possess common defects noise  object moves lines  searches distortion robot  degreesoffreedom three  candidate image regions satisfying set constraints based each leg three head total ﬁve tail mouth  current robot location target object description ears noisy ir sensors wireless lan inter  suitable image region targetregionfound – line robot communication legged opposed wheeled lo   pixels region used samples observedto comotion results jerky camera motion processing  verify goodnessofﬁt gaussian line  test vision localization motion action selection performed  using bootstrapping  using kldivergence onboard using mhz processor  distance measure described algorithm           major application domain aibos    samples generate good gaussian ﬁt used robocup legged league  research initiative  determine mean variance color distribution teams robots play competitive game soccer  learngaussparams – line  used pop indoor ﬁeld ≈ × applications aibos mo  ulate histogram learnhistvals – line  learned bile robots cameras typically involve initial calibra  distributions used generate color map mapping tion phase color map produced handlabeling  pixel values color labels line  robot uses images period hour section   map segment subsequent images ﬁnd objects approach robot autonomously learning colors  objects help robot localize positions suitable learn ﬁve minutes adapting illumination changes  ing colors validate learned colors remove  spurious samples lines                          experimental results    account slippage motion model errors suit tested algorithm’s ability answer three main ques  able image region robot turns place tions learn  ability detect illumination  ﬁnd rotated place threshold changes learn  ability plan action se                    angle angth    andor spent thresh quence learn colors good learning   old time color timecolor ≈ sec segmentation localization accuracy comparison  transitions color list instead providing standard humansupervised scheme                                                    ijcai                                                    learn                                        location unable learn colors motion  tested ability accurately detect changes il planning works working making algo  lumination robot learned colors distributions rithm robust failure conditions localization  corresponding illumination condition moved accuracy learned map comparable  environment chasing ball changed handlabeled color map ≈ cm cm deg comparison  lighting controlling intensity speciﬁc lamps cm cm deg andθ  robot identiﬁed signiﬁcant illumination changes      good learning           change   changec     table  presents test accuracy learning different illuminations    change                  sults averaged  robot learn colors controlled lab condi                                                      tions indoor corridors outside lab    change                   trials                                   rows  columns    head ﬂuorescent lamps provided nonuniform illumination  table  illumination change detection representing lux colors ﬂoor wall  errors  trials       ground truth ob modeled gaussians ob  served values respectively false positives served robot automatically selected gaussian  false negatives errors highlights shadows histogram model each color successfully learned  removed accepting change illumination unless colors  observed consecutive frames                                                        table  shows     conﬁg     localization error    test ability transition known illumina localization accu  tions robot learned color maps statistics three                   dist cm   θ deg                                                        racies                ±      ±    ditions brightlux darklux interimlux                    lab                                                                          different illumina   indoor   ±   ±   intensity   illum  transition accuracy    tion conditions lab  overhead lamps             correct  errors     indoor    corridor table  localization accuracy compa  changed  bright                    based learned rable handlabeled map  three conditions                                 color maps robot walk  different points       ≈               dark                      sec ta   interim                    averaged results  trials differences  ble  shows results av                               statistically signiﬁcant corresponding seg  eraged ≈     table  illumination transition accu mentation accuracies   respectively  trials each racy errors ≈  trials calculated  images   false transitions shadows highlights quickly  obtained handlabeled color map differences  corrected subsequent tests tested conditions statistically signiﬁcant learned maps good  known ones robot ﬁnds closest illumi handlabeled maps object recognition highlevel  nation condition able work entire range task competence technique takes  minutes                                                        robot time instead hour human effort  learn                                         sample images different testing conditions video  previous work  ﬁxed object locations resulted sin robot localizing corridor seen online  gle curriculum learn colors test robot’s ability wwwcsutexasedu∼austinvillapresearchgen color  generate curricula different object robot starting po summarize algorithm enables robot plan  sitions invited group seven graduate students motion sequence learn colors autonomously given  experience working aibos suggest challenging object conﬁguration able detect adapt illumi  conﬁgurations difﬁcult deﬁne challenging situations nation changes manual training  ahead time examples came include hav  ing robot large distance initial stages  related work  color learning process target objects close                                                        color segmentation wellresearched ﬁeld vi  each making difﬁcult distinguish                                                        sion effective algorithms   attempts  success ratio corresponding localization accuracy                                                        learn colors make robust illumination changes  overtrialsareshownintable                                                        produced reasonable success   compu  trial success colors conﬁg success   tationally expensive perform mobile robots typi  learned successfully  worst                cally constrained resources  localization error differ best               aibos standard approaches creating map                                                                                                       ence robot’s esti avg      ±       pings ycbcr values color labels    mate actual target posi                       require handlabeling images ≈  hour  tions measured human table  planning accu attempts automatically learn  ing tape measure observe racy challenging conﬁgu color map mobile robots approach closed ﬁg  robot able rations             ures constructed corresponding known environmental  plan suitable motion sequence learn colors cases features color information regions used  fails main problem robot build color classiﬁers  algorithm time consum  long distances little color knowledge cou ing use ofﬂine processing requires hu  pled slippage puts places far away tar man supervision approach three layers color                                                    ijcai                                                    
