               clusterbased selection statistical answering strategies                                   lucian vlad lita     jaime carbonell                                        carnegie mellon university                                          llita jgccscmuedu                          abstract                          paper investigate beneﬁts prin                                                        cipled strategy selection method applied main      question answering qa highly complex task  components qa document retrieval answer ex      brings classiﬁcation clustering traction answer merging overall qa performance      trieval extraction question answering sys  present experiments show carefully select      tems include various statistical rulebased com ing  available answering strategies      ponents combine form multiple strategies signiﬁcant performance degradation observed      ﬁnding answers reallife scenarios integrate clusterbased conﬁdence scoring method      efﬁciency constraints make infeasible simul answer merging component observe signiﬁcant ques      taneously use available strategies qa sys tion answering performance improvements      tem address issue present approach                                                          experiments collinsthompson et al  using      carefully selecting answering strategies                                                        cmu javelin nyberg et al  waterloo’s multitext      likely beneﬁt individual questions sig                                                        clarke et al  question answering systems corrobo      niﬁcantly reducing performance evaluate                                                        rate expected correlation improved document      impact strategy selection question answer                                                        trieval performance qa accuracy systems results      ing performance important qa stages                                                        suggest retrieval methods adapted question answering      document retrieval answer extraction answer                                                        include question analysis performed better adhoc      merging present strategy selection experiments                                                        ir methods supporting previous ﬁndings monz       using statistical question answering      show signiﬁcant efﬁciency improvements       practical approaches developed deal      selecting  available answering strategies complexity question answering process                                                                                            obtained similar performance compared     smu  harabagiu et al  later lcc sys                                                                                    using strategies combined          tem  moldovan et al  incorporate feedback loops                                                        tween components question answering                                                        cmu  treats qa process planning problem    introduction related work                      formalizing notion feedback qa sys  past years increasing number question tems using statistical components chucarroll et al   answering systems started employing multistrategy nyberg et al  lita carbonell  introduced  approaches attempt complement multiple answering strategies used simultaneously  searching answers questions approaches results combined furthermore  include multiple question classiﬁcations retrieval swering complex questions harabagiu lacatusu   approaches multiple answer extractors different data argue multistrategy approach question processing  sources question answering performance presented extraction selection  context ofﬁcial evaluations systems strategy selection problem closely related active  processing batches questions time constraints learning explores tradeoff performance  reallife scenarios limited number cost active learning algorithms suggest data  strategies component combinations parameter set labeling minimizing expected error roy mccal  tings fully explored cases trade lum  problem strategy selection goal  performance problem complexity reduce qa complexity limiting number answering  directly response time require careful selection answering strategies increasing error qa process  strategies performance optimized according  alistic constraints                                     answering strategies    present answering strategy selection approach  directly addresses performancecomplexity tradeoff question answering systems implemented  apply statistical instancebased question answering pipeline different stages successively process data                                                    ijcai                                                    each stage qa pipeline vari account answer type disregarding question structure  ety methods employed each method typically domain knowledge  different parameters needs different resources approach similar using ontologies ques  produce answers different conﬁdences tion clustering lita carbonell  training  comparable methods refer complete questions clustered according different similarity crite  combination components each stage pipeline ria shared number ngrams contiguous sequences  answering strategy today’s qa systems words semantic similarity answer type com  answering strategy consists following components pared ﬁxed ontologies approach adaptive training    question analysis – produces expected answer type data language domain independent allows      extracts question keywords analyzes question lapping types clusters hierarchical rela      speech tagging parsing semantic analysis tionship figure  shows relationship ontol      additional processing used question analysis ogy clustering used question analysis stage     retrieval – speciﬁes query types query qa process clustering performed different gran      content yield high expected performance ularities each cluster corresponds ontology node      qa systems prespecify query type additional individual answering strategies built different clusters      content according question answer types iden different ontology nodes                                                                                      tiﬁed earlier strategy                      clustering approach allows each component    answer extraction – speciﬁes answers identi answering strategy learned training ques      ﬁed relevant documents answer extraction meth tions ii known correct answers strategies      ods range rule patternbased extractors hid learned individual clusters using corresponding ques      den markov models hmm maximum    entropy  tions training data retrieval component learns      support vector machinebased extractors          queries query types high performance run                                                        incluster training questions answer extraction com   stage          strategy sa     strategy sb           ponent trained correct answers incluster ques    answer type temporal        year                  tions finally answer merging component considers clus    queries     mozart die mozart die biography  ter statistics retrieval performance extraction performance                                  mozart died death     merges answer sets produced answering strategies    extraction  rulebased      hmm                     sufﬁcient data learning sufﬁcient num                                                        ber questions clusters training questions  table  answering strategies sa sb use different answer qa generates answering strategies  types different queries extraction methods     applied new questions qa performance                                                        increase additional answering strategies    applied new question answering strategy noise irrelevant clusters time takes  processes question text retrieves documents extracts actually run strategies goal allow exis  set possible answers case multiple strate tence multiple clusterbased strategies select set  gies simultaneously applied new question answer clusters associated strategies likely lead  merging component employed combine answers  high performance document retrieval high performance  conﬁdences ﬁnal answer set table  shows sim translates high recall relevant documents answer  plistic strategies question “when did mozart die” extraction high performance corresponds large number  realistic scenarios question analysis component produces correct answers extracted  information just expected answer type queries learned different strategies lead  queries generated according prespeciﬁed types relevant documents – queries “the ﬁrst aria  various processing performed answer extraction composed mozart”vs“aria mozart” lead overlap                                                        retrieved document sets strategy leads    clusterbased strategies                         retrieval document di subsequent strategies  ﬁrst stage answering strategies question beneﬁt retrieve di each strategy  swering systems employ question ontologies selection depends previously selected strategies  tologies combine expected answer types date location  question types birthdayx nicknamex construc  experiments  results  tion datex consider question “when did experiments chosen use statistical ques  mozart die” depending desired answer type gran tion answering reasons statistical qa  ularity question classiﬁed temporal question systems usually faster implement rulebased sys  temporalyear question speciﬁcally tempo tems require knowledge resources limited man  ralyeardeath year question each classiﬁcation lead ual input results easier replicate standard  entirely different answering strategy existing systems datasets paper implemented instance  consider answer types ranging simple answer type sets based question answering ibqa lita car  qa speciﬁc ontologies semantic networks  wordnet provide better coverage speciﬁcity details datadriven framework refer  ontologies restrictive lita carbonell  publication                                                    ijcai                                                    figure  classiﬁcation according question ontology versus classiﬁcation according set clusters training data  answering new question using multiple strategies learned training questions each cluster ontology node answer sets  produced individual clusterbased strategy merged single ranked answer set    bonell  question analysis component relies able extract multiple instances correct answer  clustering training questions different levels granular time assign higher conﬁdence scores com  ity classifying new questions clusters pared incorrect answers end evaluate  each cluster answering strategy learned equiva question answering performance using metrics  lent set retrieval extraction answer type models • mean reciprocal rank mrr computed inverse  remainder paper shall refer strategies rank ﬁrst correct answer returned sys  clusterbased single answering strategy learned tem higher ﬁrst correct answer  training questions individual cluster     ranked answer list higher mrr score    new questions presented qa • second metric tests existence cor  classiﬁed according training clusters cor rect answer ﬁve answers topandis  responding answering strategies activated each generat strict compared mrr  ing set answers strategyspeciﬁc answers • goal redundancy document retrieval  merged ﬁnal ranked answer list details learning evaluate number relevant documents obtained  implementation answer type retrieval extraction documents containing correct answer  models lita carbonell         answer extraction evaluate number correct    question datasets used experiments presented answers extracted  paper consist temporal questions previous trec  evaluations trec  voorhees   temporal                 questions      strategies  questions advantage having relatively high den           mrr      mrr     sity necessary training statistical qa components                  distributed cover simple questions extracted       “when did beethoven die” structurally  complex questions “what year did general mont table  statistical qa results temporal questions  gomery lead allies victory axis troops questions ii questions answer  north africa” each question collection set extracted show average score questions  corresponding answer keys form regular expressions average performance strategies question    questions processed speech tagger formance small number strategies need successful  brill  morphological analyzer minnen et al   sentence splitter synonyms hypernyms ex comparison purposes evaluated instance  tracted used enhance keywordbased queries doc based qa using mrr table  shows  ument retrieval queries generated each mrr scores question dataset used  swering strategy documents paper present qa performance  retrieved each query through google api questions dataset performance  wwwgooglecomapi documents containing reference questions proposed answer extracted intu  trec actual question problematic itively measure viewed precision  tent ﬁltered                                measure recall question level    desired qualities question answering systems trec evaluations voorhees   use show   correctness – correct answers higher rank performance averaging questions – each  incorrect answers  redundancy – correct answers question combine results strategies strat  occur documents speciﬁ egy cluster level compute performance averaging  cally retrieval component produce multiple rel strategies – each strategy compute perfor  evant documents answer extraction component mance questions applied note                                                    ijcai                                                    answering strategies successful lower mrr speciﬁc answering strategies measure retrieval conﬁ  average time questions beneﬁt multiple dence confaircj answering strategy derived  strategies average mrr higher cluster cj given new test question  formance experiments computed through  leaveoneout crossvalidation                                                                                                       confaircj qp  aircj  · cj · sj     experiments each iteration corresponds                                                         aircj probability retrieving rel  swering strategy selected newly selected answer            ing strategy includes speciﬁc query types known evant document using strategy aircj measured  perform training questions respective testing effectiveness heldout set questions  clusters addition clusterspeciﬁc svm extractor ﬁnds cluster cjq probability cluster containing  scores potential answers experiments questions similar given average similarity  computation greedyoptimal oracle cluster selection qj ∈ cj  normalized clusters sj  method tractable confused global minimal cardinality condition clusters  optimal classiﬁer ﬁnds absolute best strategy selec figure  shows effect using conﬁdencebased selec  tion sequence – tractable present performance tion order iteratively add appropriate answering strate                                                        gies beneﬁcial query content strategies    selection document retrieval                 employed create queries retrieve new documents  assume document relevant context ques time available answer extraction answer  tion answering contains correct answer correct merging iterative process offers good tradeoff  text difﬁcult automatically evaluate tween performance number strategies used  correctness context notion relevance good basis userdeﬁned utility functions exper                                                                                           relaxed document contains correct answer iments qa selects available                                                                                                       regardless context through clusterspeciﬁc data strategies retrieval performance approximately  trieval component qa learns ngrams fea maximum achievable using existing current strategies  tures improve retrieval added queries im  selection answer extraction  provement measured queries used  trieve documents questions cluster particular cluster svm answer extractor trained  learned features clusterbased answering documents obtained running retrieval compo  strategy applied new similar questions nent answering strategy using learned queries                                                        retrieve documents basic features include proximity                                                        features sentence statistics patterns ngrams para               strategy selection document retrieval                                                     phrases discriminate best sentences contain                                                        correct answers sentences classiﬁer                                                     value features given information gain                                                          answer extractor used experiments consists                                                     support vector machine svm classiﬁer joachims                                                         producing probabilities task decide                                                      sentences contain correct answer                                                        svm   trained features extracted onesentence                                                      passages containing keyword original                                                        question features consist distance keywords                                                                  potential answers keyword density passage simple          relevant docs retrieved                           confidence selection       statistics document sentence length query type                             random selection           lexical ngrams words length paraphrases                                                         clusterbased approach sufﬁcient                                            train answer extractor each answering strategy                      iterations strategies                                                        strategies trained different number questions                                                        cluster size sensitive notion cluster rele  figure  smart selection based strategy conﬁdence allows                                                        vance based different query types dif  qa employ  available strategies retrieve                                                        ferent relevant document distributions extractor   accessible relevant documents                                                        conﬁdence taken context history –    trying answer question “when did mozart rest answering strategy measure                                                        swer extraction conﬁdence confaaecj strategy  die” beneﬁcial create queries contain fea                                  tures “biography” “cemetery” “spent life” “sac derived cluster given new test question   riﬁced himself” qa systems retrieval com                                                                                 ponent contains rules building better queries speciﬁc confaaecj qp aae cj · confaircj  types questions – example time deathinthe                                                                                                                 clusterbased approach features learned aae cj probability extracting cor                                                                      similar questions training data added cluster rect answer using answering strategy aaecj  –                                                    ijcai                                                                                        strategy selection answer extraction wo merging                                                                                                                                                                                                                                                                                                                                                                                              mrr                                                                                                                                                                                                              greedy oracle                                                   confidence selection   fraction  extracted answers                         random selection                                                            cluster size selection                                                                                                                                                                   iterations strategies            iterations strategies             iterations strategies    figure  selection based conﬁdence yields best performance carefully selecting limited number strategies cluster queries  extractor answer question better redundancy better use additional answering strategies correct answers  required answer merging method used – answers preserve individual strategygenerated scores    speciﬁcally using clustertrained svm extractor answer extraction stage qa       aaecj  measured testing effectiveness  heldout set training questions cluster  selection answer merging                                                        stage qa pipeline answering strategies    figure  evaluate effectiveness selection                                                        activated produce strategyspeciﬁc answer set  method conﬁdence selection according mrr                                                        task answer merging component make use  fraction correct answers extracted total num                                                        dundancy rescore answers correct  ber correct answers extracted strate                                                        swers ranked higher incorrect answers answer  gies used random selection consists random                                                        ing merging method implemented consists weighted  sampling available strategies using ex                                                        sum individual answer conﬁdences answer  tract answers cluster size selection intuitive                                                        stances surface form answer conﬁdence  baseline gives priority speciﬁc focused strate                                                        confakq answer ak end question  gies correspond clusters higher similarity                                                        swering process aggregated clusters cj  test question cjq does perform                                                        given  cluster similarity necessary property  sufﬁcient selection process finally greedy oracle         optimizes each iteration strategy yields confakq akaaecj  · confaaecjq  additional correct answers cases conﬁdence se       ak cj  lection method performs virtually indistinguishable                                            oracle sequence                                      akaaecj  probability extracting cor                                                                                                 beneﬁt using selection method rect answer using answering strategy ae   quickly obtain larger number correct answers high terms mrr scores seen fig  swer redundancy required strategies ure  figure  weighted answer merging method                                                        gains approximately  mrr points andalso  used terms mrr scores              small number carefully selected strategies ef points   performance gap tradeoff  fective utilizing available answering strategies tween using conﬁdence selection scores using  important observation performance does strategies improved case answer extrac  degrade subsequent iterations increased number tion encouraging conﬁdence selection approach  strategies explained fact best closely follows greedy optimal selection  strategies provide highest conﬁdence values corre  sponding answer scores unsuccessful strategies  conclusions  future work  introduce additional noise experiments answer increasing number question answering systems  merging method used each instance answer lying multistrategy approaches order ﬁnd answers  treated separately original conﬁdence score given questions rely multiple question classiﬁcations  speciﬁc strategy approach does provide boost answer extractors multiple retrieval methods using  conﬁdence answer seen data sources different webbased services qa  provides measure relative answering performance presented batch processing ques  strategy noise informative performance tions time constraints reallife scenarios                                                    ijcai                                                    
