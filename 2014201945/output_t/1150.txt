                       stereotype    extraction      default   clustering                                   julien velcin jeangabriel   ganascia                                          lip universite´ paris vi                                           rue du capitaine scott                                            paris  france                          abstract                          ﬁrst artiﬁcial data sets secondly real data case                                                        generated newspaper articles      concept stereotype really      adapted wishing extract meaningful      scriptions data especially high  conceptual clustering sparse data      rate missing values paper proposes log  dealing missing values      ical framework called default clustering based paper proposes clustering method deals high      default reasoning local search techniques rates missing values contrary algorithms      ﬁrst experiment deals rediscovering ini modes categorical version kmeans em eas      tial descriptions artiﬁcial data sets second ily lead local optima chosen achieve clus      extracts stereotypes politicians real case tering using combinatorial optimization approach like      generated newspaper articles shown figueroa et al  sarkar leong  note      default clustering adapted context goal cluster examples mainly      three classical clusterers considered   cluster way simple easy                                                        understand problem stated ﬁnding read  introduction                                          able understandable consistent rich descriptions                                                        data  conceptual clustering michalski  fundamental  machine learning task applied various areas  overview default logic  image analysis analytical chemistry biology sociology during eighties attempts model  takes set object descriptions input creates ductive reasoning missing information exists lot  classiﬁcation scheme conceptual descriptions clus formalisms developed encompass inherent difﬁ  ters particular reason categories culties models especially nonmonotony close  compare different data sets predict new world assumption circumscription default logic  observations work focuses extraction goal deal missing values natural  conceptual descriptions especially speciﬁc context advantage work default logic formalism  missing data                                         troduced reiter  chosen    automatic inductive techniques deal missing correspond problem  information voluntary omissions human error bro logic default reasoning based notion  ken equipment newgard lewis  context default rule through possible infer new formu  sparse data huge missing values las hypotheses inconsistent current  concept stereotype appropriate usual context generally default rule fol  prototype data clusters goal lowing form     bnc called  extract stereotype sets represent data sets prerequisite bi justiﬁcations conclusion  possible analogy default logic reiter  default rule interpreted follows known  speciﬁc logic default deduction make use true consistent assume    bn                                                        clude instance let consider default rule  fault subsumption speciﬁc logic default induc related experiments section  tion build stereotypes    section  presents new approach conceptual clustering politicianx ∧ introducedabroadx  ¬diplomatx  missing information exists section  proposes gen                 traitorx  eral framework attributevalue formalism new rule translates usual way reasoning peo  tion default subsumption introduced seeing ple living france end th century states  concept stereotype makes possible clusters conclusion traitorx derived  stereotype set extraction algorithm based local search politician known introduced abroad  techniques presented section  concerns experiments prove diplomat  key idea use similar observations signiﬁes ∧ entails exact deﬁnition  descriptions infer new information instead default rules follows                                                                                                          underlying mechanism following deﬁnition  subsumes default noted ≤d                                                                                                  subsection explains transition default logic default iff ∃ dc dc ⊥ ≤ dc ≤ dc                                                                                  induction                                            ≤ stands subsumes classical sense dc                                                        minorant subsumption lattice    default clustering                                 illustrate deﬁnition descriptions  rosch saw categorization im based binary attributes compared respect  portant issues cognitive science rosch  default subsumption  troduced concept prototype ideal member  raitor  yes internationalist  yes  category categorization makes similar observa  raitor  yes connection jews  yes  tions ﬁt dissimilar observations sepa  atriot  yes  rated clustering induction process data mining ≤d ≤d ∃ dc ≤ dc  actually build categories speciﬁcally conceptual ≤ dc dc  raitor  yes internationalist   clustering machine learning task deﬁned michalski yes connection jews  yes  michalski  does require teacher uses considering patriot interna  evaluation function discover classes appropri tionalist viceversa ¬patriotyes ∧ internation  ate conceptual descriptions conceptual clustering prin alistyes implicit statement people  cipally studied probabilistic context instance living france end th century does  fisher’s cobweb algorithm fisher  rarely subsume default ¬d ≤d  ally sparse data sets instance experiments property  notion default subsumption gen                                                                                                        ph gennari exceed  missing values gennari eral classical subsumption subsumes                                                                                                                                                      ≤   subsumes default ≤d     seen default logic logic deduction converse true  pending background knowledge paper proposes  property  default subsumption relationship sym                                                                                        new technique called default clustering uses similar metrical ∀d ∀d ≤d ≤d  principle induction missing information exists note notion default subsumption appear  main assumption following observation strange people accustomed classical subsumption  grouped similar observations use cause symmetrical relationship consequence  observations complete unknown information original does deﬁne ordering relationship description  fact remains consistent current context space notation ≤d confusing respect  default logic needs implicit knowledge expressed default symmetry relative underlying idea  rules default clustering uses information available generality  data set section presents new framework  shows extract stereotype sets sparse data  concept stereotype  ﬁrst extends classical subsumption section  literature categorization rosch introduced  discusses stereotype choice section  ﬁnally cept prototype rosch   inspired fam  proposes local search strategy ﬁnd best solution ily resemblance notion wittgenstein wittgenstein   section                                          shawver  electronic version narboux                                                         analysis focused family resemblance    logical  framework                                 approach original idea concept                                                        prototype features common prefer refer  section presents logical framework default clus older concept stereotype introduced  tering attributevalue formalism adaptation publicist lippman lippman  stereotypes  ceptual graphs ganascia velcin  perceptive schemas structured association character  description space noted descriptor space istic features shared group person object  values attributes example set categories simplifying generalizing images  function δ maps each example ∈ description reality affect human behavior subjective  δe ∈                                             three main reasons make choice                                                          concept prototype misused    default subsumption                              data mining techniques reduced average ob  contrary default logic problem deduce servation examples artiﬁcial description built  induce knowledge data sets frequent shared features  information unknown forward far underlying idea family resemblance es  tion default subsumption equivalent sub pecially context sparse data correct  sumption default rule deduction saying speak combination features different ex  scription ∈ subsumes ∈ default means ample descriptions average mode selection  exists implicit description completed second argument notion stereotype  ∧ speciﬁc classical sense ﬁned imaginary picture distorts reality goalis precisely generate pictures caricat  stereotype extraction  ural observations finally speciﬁc descriptions paper default reasoning formalized using  better adapted fast classiﬁcation say dis tions default subsumption stereotype set  crimination prediction prototypes feature stereotype sets supposed given  closely linked lippman’s deﬁnition             section shows classiﬁcation organized    order avoid ambiguities restrict notion sets nonsupervised learning task summa  stereotype speciﬁc description ∈ associated rized follows given  say “covering” set descriptions ⊂    example set  following subsection does deal just stereo                                                           description space  types stereotype sets cover description set                                                           description function δ −→ associates  objective automatically construct stereo                                                        description δe ∈ each example belonging train  type sets studies focus ﬁxed                                                        ing set  stereotype usage rich  amossy herschberg pier                                                        function nonsupervised learning algorithm  rot  keeping mind space possible                                                        ganize initial set individuals structure  stereotype sets browsed order discover best                                                        instance hierarchy lattice pyramid present  set best covers examples respect                                                        case structure limited partitions training set  similarity measure just addressing                                                        corresponds searching stereotype sets dis  search consider relation relative                                                        cussed partitions generated    cover similarity measure used build categoriza                                                        stereotypes        sufﬁcient asso  tion stereotype sets                                             ∅                                                               ciate each si set ei examples belonging    stereotype sets relative cover               covered si relative examples cov                                                        ered stereotype cluster associ  given example characterized description                                  ∅                                                        ated s∅  δe ∈ consider following statement stereotype choose numerous possible partitions  ∈ cover subsumes default combinatorial problem nonsupervised algo  means context missing data each piece infor rithm requires function evaluating stereotype set rele  mation crucial single contradiction prevents vance categorical nature data pre  stereotype correct generalization vious deﬁnition relative cover appears natural make  contradiction example                                                        use similarity measure msim exactly  related stereotype stereotype used com introducing following evaluation function   plete example description                                                                                                                              deﬁnition        example  set       order perform clustering general similarity                                                        s∅    sn stereotype set cs function  measure msim deﬁned counts number associates each example relative cover closest  common descriptors belonging descriptions                                                        stereotype respect msim evaluation func  ignores unknown values takes account default tion deﬁned follows  subsumption relationship                                                          msim d×d     →                                                                    hes    msimδe cs         di dj  → msimdi dj   ∈ dd  di ∧ dj                                                                             e∈e                        di ≤d dj                    msimdi dj    ¬di ≤d dj     kmodes em algorithms straightforward    di ∧ dj minorant di dj sub each step leads convergence  sumption lattice                                     duce nonsupervised learning task optimization    let consider set  s∅    sn ⊂ problem approach offers interesting features  stereotypes s∅ absurdstereotype linked set e∅ avoiding local optima especially categorical sparse  categorization calculated using data providing “good” solutions best ones  affectation function called relative cover   better control search addition necessary    deﬁnition  relative cover example ∈ specify number expected stereotypes dis  respect set stereotypes  s∅    sn noted covered during search process  cse stereotype si             methods exploring search    • si ∈                                           space hillclimbing simulated annealing                                                        chosen metaheuristic called tabu search improves    • ms δe si                                                          local search algorithm remember local search    • ∀k ∈   msimδe si  msimδe sk process schematized follows  initial solution    means example ∈ associated sini given instance random  neighborhood  similar “coveringable” stereotype relative set calculated current solution si assistance  competitive stereotypes equal higher permitted movements movements low  score covering stereotype example inﬂuence enrich stereotype descriptor remove  associated absurdstereotype s∅ case com descriptor high inﬂuence add retract  pletion calculated                      stereotype current stereotype set   sc ← s∅  current solution                      new constraint called cognitive cohesion deﬁned    sb ← sc  best uptonow solution    ← ∅  list contains tabuattributes      veriﬁes cohesion cluster example set ej ⊂    ←  nstep                                                         relative corresponding stereotype sj ∈ cognitive       let sc s∅    sk        ← ∅  initialize neighborhood              cohesion veriﬁed given descriptors       ai ∈                              ∈  sj  possible ﬁnd series          ←                             examples makes possible pass correlation            ← ai  vij             does belong stereotype sc  example sets covering               ←    sm− sm ∪ sm    sk stereotype example left veriﬁes constraint               ← ∪                               right does            belongs stereotype sc                                ← sm                                                                                                          ∅ ←    sm−  sm    sk                        ←    sm− sm    sk                                   ∅ ← ∪                                                                                                                ← ai  vij                                                does belong stereotype sc             sn ←            ←    sm sn                   possible pass            ← ∪                                  allowed begin                                                        use  means       sn ← argmax s∈p                                                                  updated depending chosen attribute ai case able ﬁnd “correlation          permits pass sc sn           path” descriptor description       sc ← sn       sc  sb sb ← sc               examples explaining relationship descriptors    return sb                                           stereotype                                                           experiments          figure  default clustering algorithm    section presents experiments performed artiﬁcial data                                                        sets followed original comparison real  best movement relative evaluation function cho data case using three wellknown clusterers default clus  sen new current solution si computed  tering implemented java program called press  process iterated speciﬁc number times nstep programme reconstruction d’ensembles ster´ eotypes´  best uptonow discovered solution recorded structures´  experiments kmodes em cob  solution stereotype set sb best maximizes web performed using weka platform garner   comparison crossed sets    local search techniques trade  validation artiﬁcial data sets  exploitation choosing best movement experiments use artiﬁcial data sets validate ro  exploration choosing non optimal state reach bustness algorithm ﬁrst step  completely different areas tabu search extends basic trasted descriptions let note ns number  local search manipulating short longterm memories descriptions initial descriptions duplicated  used avoid loops intelligently explore nd times finally missing data artiﬁcially simulated  search space metaheuristic detailed glover removing percentage descriptors random  laguna  application clustering ns × nd artiﬁcial examples evaluation carried  alsultan  note shortterm memory testing different clusterers data comparing  used stage work                   discovered cluster representatives initial descrip                                                        tions verify recovered descriptors    default clustering algorithm                     proportion initial descriptors paper  fig  main frame default clustering algorithm presents results obtained ns   nd    based basic version tabu search tries  runs number examples  descriptions  maximize function ai denotes ith attribute built using langage  binary attributes tabu  example set sc sb stands respectively list length equal  nstep  note ﬁrst  current best solution nstep maximal group experiments placed missing completely  number iterations current neighborhood random mcar framework  tabulist contains tabuattributes attribute ai fig  shows ﬁrstly results press good  tabulist descriptor ai  vij  used robust learning process stereotypes discovered  calculate neighborhood current solution   correspond original descriptions     “noredundancy” constraint added order missing descriptors addition score remains good  obtain perfect separation stereotypes nearly   cobweb stable rel  context sparseness really important extract ative increase number missing values  contrasted descriptions used quickly classify sults em rapidly worse  obtained  examples does concept stereotype introduced ing kmodes worst number expected  lippman                                              classes speciﬁed                                                                               kmodes       em                                                                                                                                                                                                                                              ex contradiction                                                                         av contradiction                                                                                                                                                         redundancy                                                                               cog cohesion × ×    ×   ×   ×    ×                                                                        em          cobweb      press                                                                                                                                                                                                                                      ex cont                                                                                av cont                                                                                                                                                             red                                                                                    cog coh ×  ×   ×   ×    ×   ×                                                                     figure  comparative results le matin        figure  proportion recovered descriptors                                                        representative facet conceptual clustering                                                        important especially sparse data context    studying social misrepresentation                  secondly check cognitive cohesion constraint  second experiments deals real data ex  veriﬁed rate descriptor redundancy  tracted newspaper called “le matin” end considered notions linked concept  th century france purpose automatically dis stereotype sparse data context  cover stereotype sets events related political dis finally consider degree similarity  order ﬁrst days september  results examples covering representatives corre  press compared three clusterers kmodes sponds notion compactness clusters  em  cobweb pointed penalizing stereotypes descriptors  focuses cluster descriptions representa function really adapted account rep  tives avoid ambiguity clusters resentative relevance fact used version  selves                                               malized   dividing total number    articles linked chosen theme gathered descriptors  represented using language  attributes terms  language attributes associated values ex  results  tracted manually attributes binary  accept fig  gives results obtained articles published  values  ordinals number ex le matin experiments kmodes algorithm  tracted examples  rate missing data nearly carried       clusters     unusual                           sults presented comparison rows ta                                                        ble show number extracted representatives    evaluation default clustering                                                        scores concerning contradiction result redun  order evaluate press comparison dancy score cognitive cohesion  three classical clusterers kmodes em cobweb straint veriﬁed columns represent each type experi  nonprobabilistic description clusters built ment kmodes associated techniques   em  algorithms extracted using techniques  using cobweb ﬁnally algorithm press  frequent descriptors mode approach  let begin considering contradiction scores   forbidding contradictory features exam highlight principal result default clustering  ples representative  dividing descriptors ing press percentage examples having contradictory  tween different representatives   features representative equal   forbidding contradictory features remarks need contrast descriptions built using techniques    firstly cluster descriptions resulting kmodes clusterer used possess contradic  correspond technique  tried tory descriptor   examples belonging  three techniques exhaustively secondly representatives cluster furthermore  descriptors  sulting extraction techniques   entail examples contradiction covering  struction redundancy rate  comparison scription way considered negligible  according following three points              noise reason processes      ﬁrst approach considers contradictions avoided especially sparse data context building  example representative example contradiction representatives kmodes em cobweb cluster  percentage examples containing descriptor ing consider techniques    contradiction covering representative addition following experiments  consider contradictory examples average let study results concerning clustering qual  contradiction percentage descriptors contradiction ity quality expressed thanks compactness
