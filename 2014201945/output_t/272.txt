                  combining learning word sense disambiguation                                    intelligent user proﬁling∗                  giovanni semeraro marco degemmis pasquale lops pierpaolo basile                                         department informatics                                          university bari italy                             semeraro degemmis lops basileppdiunibait                        abstract                          search process traditional keywordbased approaches                                                        primarily driven stringmatching operation string      understanding user interests text documents  morphological variant proﬁle      provide support personalized information   document match occurs document      recommendation services typically services sidered relevant string matching suffers problems      automatically infer user proﬁle structured polysemy presence multiple meanings word      model user interests documents  synonymy multiple words having meaning      deemed relevant user tradi  result synonymy relevant information      tional keywordbased approaches unable cap missed proﬁle does contain exact keywords      ture semantics user interests work documents polysemy wrong documents      proposes integration linguistic knowledge deemed relevant problems alternative      process learning semantic user proﬁles methods learn accurate proﬁles capture concepts      capture concepts concerning user interests   expressing user interests relevant documents se      proposed strategy consists steps ﬁrst mantic proﬁles contain references concepts deﬁned      based word sense disambiguation tech lexicons ontologies paper describes approach      nique exploits lexical database wordnet user proﬁles obtained machine learning tech      select possible meanings senses niques integrated word sense disambiguation wsd      polysemous word correct second strategy based wordnet lexical database miller       step na¨ıve bayes approach learns semantic sense fellbaum  paper organized follows      based user proﬁles binary text classiﬁers user brief discussion main works related research      likes userdislikes disambiguated docu section  wsd strategy proposed represent docu      ments experiments conducted com    ments using wordnet described section  presents      pare performance obtained keywordbased    na¨ıve bayes text categorization method adopted build      proﬁles obtained sensebased proﬁles  wordnetbased user proﬁles method implemented      classiﬁcation accuracy effective contentbased proﬁling item recommender      ness ranking imposed different  itr experimental sessions carried order      kinds proﬁle documents recom     evaluate proposed approach movie recommending      mended considered main outcome     scenario main results presented section       classiﬁcation accuracy increased clusions future work discussed section       improvement ranking conclusion      integration linguistic knowledge   related work      learning process improves classiﬁcation      documents classiﬁcation score close research mainly inspired following works      likes  dislikes threshold items syskill  webert pazzani billsus  learns user pro      classiﬁcation highly uncertain           ﬁles bayesian classiﬁers able recommend web pages                                                        represents documents using keywords libra mooney                                                        roy  adopts bayesian classiﬁer produce    introduction                                       contentbased book recommendations exploiting product                                                        descriptions obtained web pages amazon  personalized systems adapt behavior individual users                                                        line digital store documents represented using key  learning preferences during interaction order                                                        words subdivided slots each corresponding  construct user proﬁle later exploited                                                        speciﬁc section document like syskill  webert    ∗this research partially funded european commis main limitation work keywords used  sion th framework programme ist integrated project represent documents conversely siteif magnini  vikef priority  semanticbased knowledge systems strapparava  exploits sensebased document repre                                                    ijcai                                                    sentation build user proﬁle semantic network second step described section  na¨ıve bayes  nodes represent senses words documents requested approach learns sensebased user proﬁles binary text clas  user semantic network built assigning each siﬁers userlikes userdislikes disambiguated doc  node score inversely proportional fre uments thorough experimental evaluation idea  quency corpus score higher context hybrid contentbased  collaborative rec  frequent senses prevents common mean ommender carried degemmis et al  ings prevailing user model   approach probability distribution senses  corpus documents rated user learned  jigsaw algorithm word sense  ontoseek guarino et al  designed   disambiguation  contentbased information retrieval online yellow pages textual documents directly interpreted learning  product catalogs explored role linguistic algorithms indexing procedure maps document  ontologies knowledgeretrieval systems approach di compact representation content ap  shown structured content representations coupled plied typical choice document indexing classi  linguistic ontologies increase recall pre cal bagofwords bow approach each document  cision contentbased retrieval systems taking ac represented feature vector counting number occur  count lessons learned aforementioned works itr rences different words features sebastiani  conceived text classiﬁer able  deal extend bow model model each document  sensebased document representation obtained exploit represented senses corresponding words  ing linguistic ontology  learn bayesian proﬁle content respective occurrences sensebased  documents subdivided slots strategy devise document representation exploited learning algo  order shift keywordbased document representa rithm build semantic user proﬁles “sense” used  tion sensebased integrate lexical knowledge synonym “meaning” implementation sense  indexing step training documents meth based document indexing solve problem  ods proposed accomplish task scott words occur document meanings  matwin  included wordnet information feature hidden context procedure needed  level expanding each word training set assigning senses words task known word sense  synonyms wordnet order avoid wsd process disambiguation consists determining senses  approach shown decrease effectiveness ob ambiguous word invoked particular use  tained classiﬁer word ambiguity problem word manning sch¨utze   suggests kind disambiguation goal wsd algorithm associate word wi oc  required bloedhorn hotho  experiment var curring document appropriate meaning sense  ious settings mapping words senses wsd exploiting context wi com  frequent sense provided wordnet wsd based monly deﬁned set words precede follow wi                                                  text positive results reuters  sense selected predeﬁned set possibilities                              ohsumed     faodoc  corpora pre usually known sense inventory proposed algorithm  vious approaches embedding wsd classiﬁcation sense inventory obtained wordnet version   taken account fact wordnet hierarchical wordnet designed establish connections  saurus distinctive feature work adoption types parts speech pos noun verb adjective  similarity measure takes account hierarchical adverb basic building block wordnet synset  structure wordnet                                 synonym  set represents speciﬁc meaning                                                        word speciﬁc meaning word type    using wordnet represent documents               pos called sense synsets equivalent senses  consider problem learning user proﬁles binary structures containing sets words synony  text categorization task each document classiﬁed mous meanings each synset gloss short textual  interesting respect user preferences set scription deﬁnes concept represented synset  categories  c−wherec positive class example words night nighttime dark constitute  userlikes c− negative userdislikes single synset following gloss “the time  ways content represented order sunset sunrise dark outside” synsets  used basis learning component connected through series relations antonymy oppo  exists variety machine learning methods sites hyponymyhypernymy isa meronymy partof  exploited inferring user proﬁles propose strategy jigsaw wsd algorithm based idea com  learn sensebased proﬁles consists steps bining three different strategies disambiguate nouns verbs  section describes ﬁrst wsd technique adjectives adverbs motivation approach  exploits word senses wordnet represent documents effectiveness wsd algorithms strongly                                                        inﬂuenced pos tag target word adaptation    httpaboutreuterscomresearchandstandardscorpus lesk dictionarybased wsd algorithm used    httpwwwltgedacukdispresources            disambiguate adjectives adverbs banerjee pedersen    httpwwwfaoorgfaobibindexhtml               adaptation resnik algorithm used                                                    ijcai                                                    disambiguate nouns resnik  algorithm synset corresponding sense verb look  developed disambiguating verbs exploits nouns lookappearseemis“give certain impression  context verb nouns glosses certain outward aspect” examples usage  phrases wordnet utilizes verb “she sleeping” “this appears  age verb algorithm disambiguates words difﬁcult problem” description synset  belong synset jigsaw takes “give certain impression certain outward  document   wh output pect sleeping appears dif  list wordnet synsets   sk ≤ ﬁcult problem” jigsawverbs includes  each element si obtained disambiguating tar context target verb wi nouns win  word wi based information obtained wordnet dow words surrounding wi each candidate synset  immediately surrounding words deﬁne sik wi algorithm computes nounsi  context target word window words set nouns description sik exam  left words right total ple nounslook impression aspect problem  surrounding words algorithm based three different each wj each synset sik following value  procedures nouns verbs adverbs adjectives called computed  jigsawnouns   jigsawverbs  jigsawothers respec                                                                                   sinsim         tively pos tag each word computed hmm maxjk   maxwl∈nounsik         wj  wl       based tagger acopost jigsaw  proceeds  iterations using disambiguation results previ words maxjk highest similarity value wj  ous iteration reduce complexity respect nouns related kth sense wi  jigsaw  performs jigsawnouns   procedure   finally score each sik computed                                                                                verbs disambiguated jigsawverbs exploiting                                                                                ∈c gposj · maxjk  words disambiguated jigsawnouns finally         ϕi krk  ·                         jigsawothers procedure executed details                           hgposh  each mentioned procedures follow                                                        rk ranking sik synsets wordnet           nouns  jigsaw                                                ranked according frequency usage gposj   algorithm assigns wi appropriate synset sih gaussian factor related position wj respect  sense inventory wi wi computes sim wi original text gives higher weight words near  ilarity each sik sense inventory target word synset assigned wi  text wi method differs original algorithm highest ϕ value  resnik  use similarity measure  adopted leacockchodorow measure whichis   jigsawothers  based length path concepts procedure based wsd algorithm proposed  hierarchy idea measure similar banerjee pedersen  idea compare  ity synsets inversely proportional glosses each candidate sense target word  distance wordnet isa hierarchy distance                                                        glosses words context let wi  computed counting number nodes shortest                                                        sense inventory target word wi each sik ∈  path joining  passing through spe                                                    wi jigsawothers  computes string targetglossik  ciﬁc subsumer similarity function sinsim                                                contains words gloss sik proce  −            number nodes    logn                                        dure computes string contextglossi contains  shortest path bandd maximum depth words glosses synsets corresponding each  taxonomy        wordnet  proce                                                   word context wi finally procedure computes  dure starts deﬁning context set words                                                    overlap contextglossi targetglossikand  having pos tag sentence                                                        assigns synset highest overlap score withis  wi algorithm identiﬁes sense inventory score computed counting words occur  sense inventory each word                                                 targetglossik contextglossi jigsaw algo  sense inventory context given rithm evaluated according parameters sen  union wj jigsawnouns measures similar seval initiative provides forum wsd sys  ity each candidate sense sik ∈ wi each sense    ∈                                                   tems assessed disambiguated datasets order  sh   sense assigned wi highest measure capability disambiguating complete text  similarity score                                     “all words task” english chosen jigsaw reaches  jigsawverbs                                           fourth position task achieving precision  describing jigsawverbs procedure descrip equal  result assures wsd algorithm  tion synset deﬁned string obtained conﬁgured high precision add  concatenating gloss sentences wordnet uses little noise training set space limitations  explain usage word example gloss details experiments reported      httpacopostsourceforgenet                       httpwwwsensevalorg                                                    ijcai                                                                  keywordbased synsetbased document          bowrepresented documents tokens tk bim words                   representation                                   induced categorization model relies word frequencies              wsd   procedure described previous section conversely training performed bosrepresented              adopted obtain synsetbased vector space representation documents tokens synsets induced model relies                                                                    synset frequencies calculate  esti              called bagofsynsets bos model synset                          vector instead word vector represents document mate cj tk cjsm training phase doc              key feature approach each document uments used train rated discrete scale              represented set slots each slot textual  max max maximum rating              ﬁeld corresponding speciﬁc feature document assigned document according idea proposed                                                                    mooney roy  each training document di la              attempt account document structure                                                                                                   beled scores “userlikes” score “user              according bos model text each slot repre                      sented counting separately occurrences synset dislikes” score w− obtained original rating                slots occurs formally assume          −                              collection documents let index                    w− −                                                                                            max   −               slot  nthenth document dn reduced               bags synsets each slot                  scores  exploited weighting occur                                                                    rences tokens documents estimate prob                                                      dn   tntntndnm  mm           abilities training set tr prior probabilities                                                                  classes computed according following equation              tnk kth synset slot sm document dn              dnm  total number synsets appearing mth slot                tr                                                 ∈                                                           document dnforalln tnk   vmwhichis                                 wj               vocabulary slot sm set different synsets                                                                                                  pˆcj                                       slot sm document dn ﬁnally represented                    tr               vector space synsetfrequency vectors           wittenbell smoothing  adopted  compute                                                          tkcjsm taking account documents                          fn   wnwnwndnm                                                                  structured slots token occurrences weighted              wnk weight synset tk slot sm doc using scores equation               ument dn computed different ways                                                                                  ⎧              simply number times synset tk appears slot smas                                                                                  ⎪     nptkcj sm                                                                                  ⎪     nt  ntkcjsm               used experiments complex tfidf score         ⎨   cj                 hypothesis proposed document representation pˆtkcjsm                                                                                  ⎪                     helps obtain proﬁles able recommend documents seman          ⎩⎪      cj                                                                                                 nt  −v              tically closer user interests difference respect       cj        cj              keywordbased proﬁles synset unique identiﬁers                                                       place words                                          ntkcjsm count weighted occurrences                                                                    token tk slot sm training data class cj              ana¨ıve bayes method user proﬁling               vcj total number unique tokens class cjand                                                                     total number unique tokens classes              item recommender itr uses na¨ıve bayes text catego ntkcjsm computed follows              rization algorithm build proﬁles binary classiﬁers user              likes vs userdislikes induced probabilistic model esti                   tr                                                                                                                 mates posteriori probability cj di document di      ntkcjsm      wjnkim                         belonging class cj follows                                                                                                                    nkim number occurrences token tk slot                                                 nditk                      cjdip cj    tkcj              sm document dithesumofallntkcjsm                                          w∈di                          nominator equation  denotes total weighted length                                                                                                        ˆ                nditk number times token tk occurs slot sm class cjinotherwordsp tk cjsm es              document di itr each document encoded vec timated ratio weighted occurrences tk              tor bos synsetbased representation vector slot sm class cj total weighted length slot              bow  keywordbased representation bos ﬁnal outcome learning process probabilistic              bow each slot equation   model used classify new document class c−                                                                    model user proﬁle includes tokens                                    s bim                     turn indicative user preferences                              cj                  nkim                    cjdi              tkcjsm         according value conditional probabilities                                                                                sss set slots bim bos  experimental evaluation              bow slot sm di nkim number oc goal experiments compare performance              currences token tk bim trained synsetbased user proﬁles keywordbased pro                                                                ijcai                                                                ﬁles experiments carried contentbased ex    precision   recall              ndpm  tension eachmovie dataset collection   tex id bow bos bow bos  bow   bos   bow   bos  tual descriptions movies rated   users point                                                                                    scale − content information each movie col                                                                          lected internet movie database using crawler               gathered titlethedirectorthegenre cat           egory movie keywordsthesummary cast                movies subdivided different genres action anima              tion classic art foreign comedy drama family horror               romance thriller each genre category set               users randomly selected users rated items              ≤ ≤  movie category genre ‘anima               tion’ number users rated movies   low number movies genre way each table  performance itr  different datasets  category dataset   triples user movie rat  ing obtained  ‘animation’ table  sum ing aposteriori probability class likesvalues  marizes data used experiments            range  agreement  disagreement adop                                                        tion classiﬁcation accuracy rank accuracy metrics     id     genre    number ratings  pos   neg        gives possibility evaluating sys          action                              tem able recommend relevant documents         animation                            documents ranked experiments movie      artforeign                                                                             scription di considered relevant user rating          classic                                                                             greater equal  itr considers description rele          comedy                                                   drama                               vant di   computed equation  ex          family                              ecuted run experiment each user dataset          horror                              each run consisted  selecting documents         romance                              corresponding ratings given user  splitting se         thriller                            lected data training set tr test set tsusing                                              tr learning corresponding user proﬁle  evaluating                                                        predictive accuracy induced proﬁle tsusing    table   ‘genre’ datasets obtained eachmovie aforementioned measures methodology adopted                                                        obtaining tr ts fold cross validation table     tokenization stopword elimination stemming shows results reported  genres itr  applied index documents according bow signiﬁcant improvement bos bow pre  model content slots title director cast cision  recall  noticed bos  tokenized elimination stopwords produced model outperforms bow model speciﬁcally datasets  unexpected results example slots containing ex   precision  recall   precision  clusively stopwords “it”or“et”  recall   precision  recall  does make sense apply stemming dataset  improvement observed probably  stopword elimination proper names documents  cause precision recall high  processed jigsaw algorithm indexed ac noticed ndpm values relevant  rele  cording bos model obtaining  feature reduction vant classiﬁcation accuracy increased improving  mainly fact synonym words repre ranking result explained example  sented synset keywordbased proﬁles table  each column reports ratings scores  ferred learning bowrepresented documents whilst items corresponding positions ranking  synsetbased proﬁles obtained bosrepresented                                                          let ru ranking imposed user set  documents itr conceived text classiﬁer ef                                                         items ra ranking computed aandrb rank  fectiveness evaluated wellknown classiﬁcation ac ing computed method ratings ranging                                                  curacy measures precision recall sebastiani   classiﬁcation scores ranging   item  used measure combination precision recall considered relevant rating symmetrically  adopted normalized distancebased performance mea ranking score ≥  method better classiﬁcation                        sure ndpm  yao  measure distance accuracy compared method recall precision  ranking imposed documents user ratings vs recall precision ndpm  ranking predicted itr ranks documents accord                                                        methods rankings ra rb    eachmovie  dataset longer available   similar difference ranked  load grouplens home  page  new  ver   ra whilst ranked rb general conclu  sion named movielens originally based dataset sion method bos model improved clas  httpwwwcsumneduresearchgrouplens             siﬁcation items score ratings close    imdb httpwwwimdbcom                          relevant  relevant threshold items classi                                                    ijcai                                                    
