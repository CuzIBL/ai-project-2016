    constructing diverse classifier ensembles using artificial training examples                                          prem melville raymond mooney                                            department sciences                                                     university texas                                                 university station                                                     austin tx                                     melvillecsutexasedu mooneycsutexasedu                             abstract                                 present new metalearner decorate diverse en•                                                                 semble creation oppositional relabeling artificial        ensemble methods like bagging boosting                                                                  training examples uses existing strong learner        combine decisions multiple hypotheses                                                                  provides high accuracy training data build        strongest existing machine learning                                                                  effective diverse committee fairly simple straightfor•       methods diversity members                                                                  ward manner accomplished adding different ran•       ensemble known important factor                                                                  domly constructed examples training set building        determining generalization error paper                                                                  new committee members artificially constructed ex•       presents new method generating ensembles                                                                  amples given category labels disagree cur•       directly constructs diverse hypotheses using                                                                  rent decision committee easily directly        additional artificiallyconstructed training exam•                                                                 increasing diversity new classifier trained        ples technique simple general meta                                                                 augmented data added committee        learner use strong learner base                                                                    boosting bagging provide diversity subsampling        classifier build diverse committees experimen•                                                                 reweighting existing training examples train•       tal results using decisiontree induction base                                                                  ing set small limits ensemble diversity        learner demonstrate approach consistently                                                                  methods obtain decorate ensures diversity        achieves higher predictive accuracy                                                                  arbitrarily large set additional artificial examples        base classifier bagging boosting                                                                  hypothesis result higher gen•       occasionally decrease accuracy obtains                                                                  eralization accuracy training set small pa•       higher accuracy boosting early learning                                                                  presents experimental results wide range uci data        curve training data limited                                                                  sets comparing boosting bagging decorate using                                                                  decisiontree induction java implementation    introduction                                                 quinlan  introduced witten frank                                                                   base learner crossvalidated learning curves support hy•  major advances inductive learning past                                                                  pothesis decorated trees generally result greater   decade development ensemble committee ap•                                                                 classification accuracy small training sets   proaches learn retain multiple hypotheses com•  bine decisions during classification dietterich    example boosting freund schapire  en•       ensembles diversity   semble method learns series weak classifiers each  ensemble combination output   focusing correcting errors previous     classifiers useful disagree inputs   currently best generic    krogh vedelsby  refer measure   inductive classification methods hastie et al         disagreement diversity ensemble      constructing diverse committee each hypothesis   methods proposed measure ensemble diver•  different possible decorrelated members   sity kuncheva whitaker  — usually dependent   ensemble maintaining consistency  measure accuracy regression mean   training data known theoretically important property squared error commonly used measure accuracy vari•  good committee krogh vedelsby        ance used measure diversity diver•  successful ensemble methods encourage diversity    sity ith classifier example defined   extent focused directly goal maximizing    dix      diversity existing methods focus achieving diversity  predictions iih classifier ensemble respec•  opitz shavlik  rosen  fairly complex      tively setting krogh et al  show gen•  general metalearners like bagging breiman       eralization error ensemble expressed    boosting applied base learner      mean error diversity   produce effective committee witten frank     ensemble respectively       learning                                                                                                                 classification problems  loss function nonzero probability occurrence constructing artificial   commonly used measure accuracy diversity       data points make simplifying assumption at•    ith classifier defined                          tributes independent possible accurately es•                                                                 timate joint probability distribution attributes                                                               time consuming require lot data                                                                    each iteration artificially generated examples la•  case simple linear relationship     beled based current ensemble given example   does hold strong    class membership probabilities predicted   reason believe increasing diversity decrease en• ensemble replacing zero probabilities small nonzero   semble error zenobi cunningham  underly•       value labels selected probability   ing principle approach build ensembles classi• selection inversely proportional current ensembles   fiers consistent training data maximize  predictions   diversity defined     decorate algorithm definition   decorate algorithm  ensemble generated   iteratively learning classifier each iteration adding   current ensemble initialize ensemble contain   classifier trained given training data classifiers   each successive iteration trained original training   data artificial data each iteration artifi•  cial training examples generated data distribu•  tion number examples generated spec•  ified fraction  training set size labels   artificially generated training examples chosen   differ maximally current ensembles predic•  tions construction artificial data explained   greater following section refer labeled   artificially generated training set diversity data   train new classifier union original training data   diversity data adding new classifier cur•  rent ensemble increases ensemble training error   reject classifier add current ensemble   process repeated reach desired committee   size exceed maximum number iterations     classify unlabeled example employ fol•    lowing method each base classifier ci ensemble   provides probabilities class membership     pciyx probability example belonging class   according classifier ci compute class   membership probabilities entire ensemble       probability belonging class   select probable class label      construction artificial data   generate artificial training data randomly picking data   points approximation trainingdata distribu•  tion numeric attribute compute mean stan•  dard deviation training set generate values   experimental evaluation   gaussian distribution defined nominal   attribute compute probability occurrence each     methodology   distinct value domain generate values based evaluate performance decorate ran experi•  distribution use laplace smoothing nominal at•     ments  representative data sets uci repository   tribute values represented training set blake merz  used similar studies webb                                                                                                                   learning quinlan  compared performance deco•           decorate outperforms bagging geometric mean    rate adaboost bagging using   ratio suggests cases bagging beats   base learner ensemble methods using weka       decorate improvement decorates im•   implementations methods witten frank     provement bagging rest cases   ensemble methods set ensemble size         decorate outperforms adaboost early learning   note case decorate specify max•      curve significant winsdrawloss record geomet•  imum ensemble size algorithm terminates number     ric mean ratio trend reversed given    iterations exceeds maximum limit desired    data note large amounts   ensemble size reached experiments set      training data decorates performance quite competitive   maximum number iterations decorate          adaboost  given  data decorate produces   ran experiments varying artificially generated   higher accuracies   data sets   data rsize results vary     observed previous studies webb    range   rsize values lower     bauer kohavi  adaboost usually sig•  adversely affect decorate insufficient ar•   nificantly reduces error base learner occasionally   tificial data rise high diversity results report increases large extent decorate does   rsize set  number artificially generated problem clear table    examples equal training set size                      data sets decorate achieves higher      performance each learning algorithm evaluated    accuracy bagging adaboost fewer training   using  complete fold crossvalidations each fold   examples figure  show learning curves clearly demon•  crossvalidation each data set randomly split  equal strate point domains little data avail•  size segments results averaged  trials each able acquiring labels expensive decorate ad•  trial segment set aside testing remaining vantage ensemble methods   data available training test performance vary•     performed additional experiments analyze role   ing amounts training data learning curves generated   diversity plays error reduction ran decorate   testing training increasing subsets                                                                   different settings rsize ranging     overall training data like summarize    varying diversity ensembles produced com•  results data sets different sizes select dif• pared diversity ensembles reduction gener•  ferent percentages total trainingset size points alization error diversity ensemble computed   learning curve                                         mean diversity ensemble members given eq       compare learning algorithms domains       compared ensemble diversity ensemble error re•  employ statistics used webb       duction difference average error   windrawloss record geometric mean error ratio   ensemble members error entire ensemble   windrawloss record presents three values number      cunningham carney  correla•  data sets algorithm obtained better equal     tion coefficient diversity ensemble error reduc•  worse performance algorithm respect classi•     tion   fairly strong further•  fication accuracy report statistically significant compared diversity base error reduction   windrawloss record win loss counted   difference error base classifier   difference values determined significant ensemble error base error reduction gives better in•   level paired ttest geometric mean error ratio  dication improvement performance ensemble   defined ea eb mean                     base classifier correlation diversity versus                                                                  base error reduction  note   errors algorithm domain ge•     correlation weak statistically   ometric mean error ratio implies algo• significant positive correlation results reinforce   rithm performs better vice versa compute     belief increasing ensemble diversity good approach   error ratios capture degree algorithms   reducing generalization error   outperform each win loss outcomes                                                                    determine performance decorate changes    results                                                    ensemble size ran experiments increasing sizes                                                                  compared results training  available data   results summarized tables  each cell     advantage decorate noticeable low   tables presents accuracy decorate versus al•    learning curve lack space include   gorithm difference statistically significant results  datasets present representative   larger shown bold varied training     datasets figure  performance datasets   set sizes  total available data   similar note general accuracy decorate   points lower learning curve      increases ensemble size datasets   expect difference algorithms      performance levels ensemble size     tables provide summary statistics discussed   each points learning curve                                                                     lthe pvalue probability getting correlation large      decorate significant wins losses bag•      observed value random chance true correlation   ging points learning curve table     zero       learning                                                                                                                                              figure  decorate compared adaboost bagging                                                                   related work                                                                attempts building ensembles                                                                focus issue diversity liu et al  rosen                                                                 simultaneously train neural networks ensemble                                                                using correlation penalty term error functions opitz                                                                shavlik  use genetic algorithm search                                                                good ensemble networks guide search use                                                                objective function incorporates accuracy                                                                diversity term zenobi et al  build ensembles based                                                                different feature subsets feature selection                                                                using hillclimbing strategy based classifier error                                                                diversity classifier rejected improvement                                                                metrics lead substantial deterioration                                                                substantial defined presct threshold                                                                   approaches ensembles built attempting                                                              simultaneously optimize accuracy diversity indi•                                                               vidual ensemble members decorate goal                                                                minimize ensemble error increasing diversity                                                                point does training accuracy ensemble                                                                                                                learning base classifier possibility  future work conclusion   previous methods furthermore previous stud•                                                                current approach encouraging diversity using   ies compared methods standard ensemble ap•                                                                artificial training examples domains   proaches boosting bagging fopitz shavlik                                                                  large unlabeled data available    compares bagging boosting                                                                 exploit unlabeled examples label diversity     compared boosting requires weak base          data allow decorate act form semi  learner does completely fit training data boosting supervised learning exploits labeled unlabeled   terminates constructs hypothesis zero training data nigam et al    error decorate requires strong learner ar•    current study used base learner how•  tificial diversity training data prevent adequately expect similarly good results base   fitting real data applying boosting strong base   learners decisiontree induction com•  learners appropriately weakened order   monly used base learner ensemble studies   benefit boosting decorate         work using neural networks naive bayes   preferable ensemble metalearner strong learners          bauer kohavi  opitz maclin  exper•    knowledge ensemble approach uti•   iments decorating learners area   lize artificial training data active learning method intro• future work   duced icohn et al  goal committee      manipulating artificial training examples decorate   select good new training examples improve able use strong base learner produce effective   accuracy using existing training data labels diverse ensemble experimental results demonstrate   artificial examples selected produce hypotheses approach particularly effective producing highly accurate   faithfully represent entire version space ensembles training data limited outperforming   produce diversity cohns approach labels artificial data ei bagging boosting low learning curve empir•  ther positive negative encourage respectively ical success decorate raises issue developing   learning general specific hypotheses         sound theoretical understanding effectiveness gen      learning                                                                                                              
