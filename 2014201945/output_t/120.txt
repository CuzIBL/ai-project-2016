allocation scheduling mpsocs decomposition nogood generation                       luca benini davide bertozzi alessio guerri michela milano                                        deis university bologna                                 vle risorgimento   bologna italy                            lbenini dbertozzi aguerri mmilanodeisuniboit        paper proposes decomposition approach allo based methodology target application running  cation scheduling multitask application multi hardware platform precharacterized ab  processor systemonchip mpsocs wolf  stracted task graph speciﬁcation computation  currently critical problems electronic storage communication requirements  sign automation verylarge scale integrated vlsi cir worst case execution time wcet speciﬁed each  cuits limits chip integration reaching task plays critical role application real time  billion elementary devices current advanced integrated constraints expressed terms minimum required  hardware platforms highend consumer application throughput met fact tasks scheduled each  multimediaenabled phones contain multiple processors processor based timewheel sum wcets  memories complex onchip interconnects tasks iteration time wheel exceed  hardware resources mpsocs need optimally time period rt minimum task scheduling period en  allocated scheduled tight throughput constraints suring throughput constraints met  executing target software workload video each processor minimum throughput appli  coder                                               cation single processor requirement         multi                                       problem facing scheduling problem  processor                                      alternative resources each task allocated  consists pre                                    processors node figure  each task needs  deﬁned number                                       memory areas executing allocated  distributed com                                      memory device internal task state program data  putation nodes                                    allocated local scratchpad memory  depicted figure                                    remote onchip memory communication queue    each node                                      memory area used tasks communicate  process                                    allocated local scratchpad tasks duration  ing core                                       pends memory slots allocated tasks need time  tightly coupled figure  single chip multiprocessor access bus use remote memory clearly tasks  local   memory   architecture                       scheduled time subject real time constraints  unfortunately                                    precedence constraints capacity constraints unary  scratchpad memory limited size data excess cumulative resources different perspec  stored externally remote onchip memory tive problem decomposes problems alloca  accessible bus bus stateoftheart mpsocs tion tasks processors memory slots required  shared communication resource serialization bus each task proper memory device scheduling problem  access requests processors bus masters carried static resource allocation  centralized arbitration mechanism             objective function overall problem mini    predictable performance needed applica mization communication cost function involves  tions important avoid high levels congestion variables ﬁrst problem particular com  bus makes completion time bus transactions munication cost each time communicating tasks allo  predictable low congestion cated different processors each time memory slot  regime performance stateoftheart shared busses scales allocated remote memory device communica  way advanced busses topol tion cost minimized feasible schedules  ogy communication protocol enhancements finally bus prefer having minimum makespan  modelling simpler working conditions ad allocation problem difﬁcult solve constraint  ditive models communication cost critical programming cp cp naive method solving op  determining overall performance mini timization problems each time solution addi  mized task allocation framework               tional constraint added stating each successive solutionshould better best far objec solve overall problem actually ﬁrst experi  tive function strongly linked decision variables cp ments showed cp ip able ﬁnd  effective hopeless use cp ﬁnd solution easiest instances  minutes  optimal solution case objective function related simpliﬁed models removing variables  single variable like makespan scheduling problems cp straints cp ﬁxed activities execution time  works quite objective function sum sidering execution time variability remote memory  cost variables cp able prune values deep accesses ip consider variables  search tree connection objective straints involving bus model bus resource  function problem decision variables weak suppose each activity access data  objective function relates pairs assignments situation necessary  worse case application generate large variety problems varying  objective function depends pairs assignments fact number tasks processors results presented  contribution objective function added mean set  problems each task processor  communication tasks allocated different processors number problems considered solution experi    contrary integer programming ip extremely ments performed ghz pentium   mb  good cope problems weak coping ram used ilog cplex  ilog solver   time scheduling problems require assign tasks modelling solving tools  time slots each slot represented integer                                  ﬁg  variable number variables increases enormously                                   ure                                                                                                                                cp instead effective cope time constraints                               compare                                                                                                                                                                                                               hybrid                                                                                                                                                           algorithms    ﬁrst problem solved ip effec                                                                                                                                                    ip                                                                                                                                                              search time    tively second cp technique choice                                                                                                                                                        cp                                                              question problems interact                                              prob    solve separately allocation problem ﬁrst                                    lems    called master problem scheduling problem called                                     different                                                              subproblem later master solved optimality                             number  solution passed subproblem solver solution       number tasks              tasks                                                                                                times    feasible overall problem solved optimality figure  comparison algorithms                                                                                                expressed  instead master solution completed search times different process number  subproblem solver nogood generated added                                    seconds  model master problem roughly stating solu yaxis logarithmic scale space reasons omit  tion passed recomputed search time ﬁgure varying number processors  feasible new optimal solution master similar behaviours ﬁgure   problem respecting set nogoods generated far cp ip deal simpler problem model  allocation problem solver ip solver nogood algorithms general comparable  form linear constraint                  hybrid number tasks grows ip cp    similar method known operations research ben performances worsen search times orders  ders decomposition benders  overall prob magnitude higher wrt hybrid furthermore considered  lem decomposed parts connected  ﬁgures instances algorithms able  variables related approaches hooker  ﬁnd optimal solution  minutes problems  grossmann jain                             tasks ip cp ﬁnd solution    show method extremely effective com  cases  pared approaches considering problem    methodology proposed paper applied references  video signal processing pipeline each task pro benders  benders partitioning procedures solv  cesses output data preceding task pipeline func ing mixedvariables programming problems numerische math  tional pipelining widely used domain multimedia ematik –   applications task parameters derived real grossmann jain  grossmann jain algo  video graphics pipeline processing pixels digital image rithms hybrid milpcp models class optimization prob  proposed allocation scheduling techniques lems informs journal computing –   easily extended applications using pipelining work                                                        hooker  hooker hybrid method planning  load allocation policy aim providing designers scheduling procs th intern conference principles  automated methodology come effective practice constraint programming  cp  pages –  solutions cut design time sched  toronto canada sept  springer  ule repetitions pipeline processes order                                                        wolf  wolf future multiprocessor systemson  achieve working rate conﬁguration                    chips procs st design automation conference    validate strength approach compare  dac  pages – san diego ca june  acm  results obtained using model hybrid follow  ing results obtained using cp ip model
