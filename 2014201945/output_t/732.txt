                                     deictic option schemas           balaraman ravindran                 andrew barto                    vimal mathew    dept science engineering dept science dept science engineering              iit madras india         university massachusetts amherst     iit madras india             ravicseiitmacin               bartocsumassedu                vmlcseiitmacin                          abstract                          problem present bayesian algorithm learning                                                        correct conﬁguration pointers validate approach      deictic representation  representational     simulated game domain inspired agre chapman      paradigm based selective attention point       ers allows agent learn reason       employ markov decision processes mdps      rich complex environments article  basic modeling paradigm present notation      present hierarchical reinforcement learning  regarding factored mdps section  brief summary      framework employs aspects deictic repre  relativized options section  introduce deictic option      sentation present bayesian algorithm   schemas section  present bayesian algo      learning correct representation given rithm choose right pointer conﬁguration apply      subproblem empirically validate      subtask section  relate approach existing      complex game environment                         family deictic algorithms section  section                                                         scribe related work conclude section     introduction                                       discussing future directions research  agre   introduced deictic representations  ai community way reasoning learning large  notation  complex domains representational paradigm based structured ﬁnite mdp described tuple  using small set pointers lets agent focus parts s Ψprwheres ﬁnite set states ﬁnite  state space relevant solving problem hand set actions Ψ ⊆ × set admissible stateaction    deictic pointers simple physical locators pairs Ψ×s →   transition probability function  encode complex semantics agre chapman  s probability transition state  employ pointers let agent precisely locate important state s action aandr Ψ→ ir expected  components method needs substan reward function rs expected reward  tial preprocessing domain knowledge solving performing action state state set given                                                                                  m  arcade game pengo agent pengi employs complex features variables ⊆ siwheresi set  pointers beeattackingme icecubenexttomeetc permissible values feature ∈  actions agent deﬁned respect form  ssm wheresi ∈ si  pointers example push icecubenexttome bee transition probability function usually described  attackingme general deictic representations used family twoslice temporal bayesian networks   rich environments incredible amounts tbns tbn each action tbn  useful systems physical limita layer directed acyclic graph nodes ssm                                                                     tions sensory capabilities form atten smheresi denotes random variable repre                                                                                           tional mechanism employed minut mahade senting feature present state si denotes random  van                                            variable representing feature resulting state    considerable employing deictic classes structured problems modeled tbn  representations reinforcement learning rl framework each arc restricted node ﬁrst  whitehead ballard  mccallum  finney et set node second statetransition probabilities  al  attractions synthesis obvious factored  lead trialanderror approach work large                                                                            m  environments article develop hierarchical deictic                                                                                             probsiparentssia  rl framework based relativized options ravindran                                                                             barto speciﬁcally extend earlier approach                                                                                                           factored mdps show certain aspects deixis parentssia denotes parents node si  modeled ﬁnding structured homomorphic reductions tbn corresponding action each                                                    ijcai                                                                    probsiparentssia given conditional probability option invoked particular instantiation                                 table cpt associated node si computing condi schema chosen binding appropriate resources  tional probabilities implicitly assumed nodes given set possible bindings ravindran barto            parentssia assigned values according     presented bayesian approach choosing right    option temporally extended action sutton et al binding apply given context based experience gath   mdp    s Ψp r deﬁned ered solving task assumed set bindings  tuple  iπβ initiation set i⊆s given family transformations applied Ψ  set states option invoked π op maintained heuristic weight vector wnh ψswhich  tion policy termination function β  →   gives measure likelihood transformation ∈hbeing  probability option terminating given state right transformation context represented ψs  option policy general mapping arbitrary weight vectors updated using  sequences stateaction pairs histories action proba                                                                                              pofsgsafs wn−h ψs  bilities restrict attention markov subgoal options wnh ψs                              policies functions current state                         option terminates reaching set predeﬁned                                                                                          where pos maxν pos andk      subgoal states states option policy                    deﬁned known domain option cases h∈h po gs wn− ψ    option policy deﬁned submdp known malizing factor projected transition probability  option mdp consisting states domain op lower bounded ν approach works ho  tion                                                 momorphic image exact article extend                                                        earlier work cases bindings speciﬁed                                                        deictic pointers    relativized options  relativized option combines mdp homomorphisms ravin  deictic option schemas  dran barto options framework com set candidate transformations speciﬁed  pactly represent family related options mdp ho set deictic pointers possible conﬁg                                            momorphism transformation mdp   urations agent learns place pointers speciﬁc             m                      m  duced model    solution yields solu conﬁgurations effect correct bindings schema         tion  notationally mdp homomorphism hisde  option schema set pointers                       Ψ    Ψ  ﬁned surjection  given tuple surjec deictic option schema formally deictic option schema  tions fgss ∈ s hs  fsgsawhere                                                     deﬁned follows   →  gs  → afs ∈ called  homomorphic image optimal policy deﬁnition  deictic option schema factored mdp  m lifted yields optimal policy     s Ψpr tuple dowhereo                                                                                                      relativized option policy achieving op β  relativized option                                                               ···      tion’s subgoal deﬁned image partial homo dd dk   set admissible conﬁgurations                                                        deictic pointers number deictic point  morphism deﬁned subset image                             ···m  called option mdp option invoked ers available di ⊆  collection  current state projected option mdp mo   possible subsets indices features pointer  soao Ψoporo policy action lifted project schema number features  original mdp based states option used  voked relativized option deﬁned follows                                                       set di indicates set objects pointer  deﬁnition   relativized option mdp           point environment example blocks world  s Ψpr tuple  h mo iβwherei⊆                            →                      domain set blocks example  initiation set β     termination section set possible adversaries  function  fgss ∈ s partial homomorphism                   Ψ                                 deictic option schema invoked decision mak  mdp pr   option mdp    ing proceeds alternating phases ﬁrst phase  r chosen based subtask                                                      agent picks suitable pointer conﬁguration using heuris  words option mdp partial homomor tic weight function similar given section   phic image mdp states actions tran                                                      second phase agent picks action based  sition dynamics  reward function chosen ceptual information obtained pointers using  based option’s subtask homomorphism condi function calling semantics similar followed  tions hold states domain option othe whitehead ballard   option policy π Ψo →   obtained solving mo                                                        each member  state transformation form  treating episodic task lifted π            ∈                                          Ψ               ρji whereji   di ρj  projec  suitably transformed policy fragments      tion subset features indexed jifh    relativized option viewed option schema  template option policy speciﬁed using frequently ψs simple function state space like  parameterized representation family subproblems projection features                                                    ijcai                                                    known priori pointer conﬁgurations chosen  appropriately learning absence prior knowl  edge bayesian algorithm developed ravindran  barto used determine correct bindings  schema possible pointer conﬁgurations  algorithm entirely suitable deictic option  schemas following reason    algorithm assumes candidate transformations  structured maintains monolithic weight vector  wn· · case deictic option schemas transfor  mations structured advantageous maintain                                            “factored” weight vector wn· ·wn· ·wn· · ···  ideally each component weight vector figure  game domain interacting adversaries  likelihood corresponding pointer right stochastic actions task collect black diamond  ﬁguration usually certain degree dependence adversaries three types—benign shaded retriever  pointers correct conﬁguration white delayers black text explanation  pointers depend conﬁguration pointers                                  three cases need considered assume                                                                                 pos maxν pos   ψs  pointers following dis function captures features states  cussion concepts generalize arbitrary number                                                        necessary distinguish particular subproblem  pointers                                                                             i    i    i                                                         consideration   hi∈h pof sgs af                                      ∈                         i                                        independent pointers di ρj satisﬁes wn−h  ψs normalizing factor pos                                                                                        homomorphism condition transition probabilities “projection” pos  computed follows let      right assignment pointer independent set features required com                                                                           pointers component putation wnh ψs determined                                                                                                           weight vector corresponding pointer updates scribed various cases pos                                                                                components depends features probsj parentssja      dexedbysomej   ∈ di                              j∈j      mutually dependent pointers each ∈ di                                                          experimental illustration game       ∈ dj ρj × ρj satisﬁes homomorphism condi      tions ρj ρj satisfy homomorphism environment                                          conditions ∈ di ∈ dj apply deictic option schema learning mod      treated separately composite projec iﬁed version game environment introduced ravin      tions given crossproducts considered dran barto layout game shown      component weight vector corre figure  environment usual stochastic gridworld      sponds crossproduct projection update dynamics just room world goal      component depend features indexed agent collect diamond room exit                            ∈ di ∈ dj                           agent collects diamond occupying square                                                       diamond boolean variable indicates posses    dependent pointer each ∈ di ∈ dj ρj ×                                                        sion diamond      ρj satisﬁes homomorphism conditions does ρj                                                           room  autonomous adversaries adver      ρj does satisfy homomorphism conditions                                                       saries three types—benign delayer retriever      value ∈ dj means pointer      independent pointer dependent agent happens occupy square delayer      separate component weight vector captured prevented moving random num      corresponds pointer update depends ber time steps determined geometric distribution                                                       parameter hold occupying square      features indexed ∈ di ∈ dj                                                        delayer pursues agent probability chase benign    weight vector chosen com robots execute random walks room act mobile  ponent each independent pointer each dependent obstacles retriever behaves like benign adversary till  pointer each set mutually dependent pointers agent picks diamond agent picks  let resulting number components modiﬁed diamond retriever’s behavior switches  version update rule ravindran barto layer main difference retriever occupies  used update each component weight independently square agent diamond returned  updates components              original position retriever reverts benign behavior                                                        retriever returns benign behavior agent                       ·      “captured” delayer adversaries leave        po  gs    wn− ψ  wn ψ                                           room agent “escape” room exit                                                     ing corridor agent aware types                                                    ijcai                                                    figure  option mdp corresponding subtask  objectandleaveroom domain figure   just delayer retriever image mdp                                                          figure  average number steps episode taken  individual adversaries                                                        agents solving task shown figure     option mdp figure  symmetrical room just  adversaries—a delayer retriever ﬁxed chase                                                                     hold parameters features describing state space                  transformation   option mdp consists coordinates relative  room agent adversaries boolean     variable indicating possession diamond room  world does match option mdp exactly ad          transformation    versary world chase hold parameters  adversaries                                                                                                       transformation  weights      deictic agent access  pointers delayer pointer     transformation    projects adversaries delayer im    age mdp retriever pointer projects ad                                                                     versaries retriever image mdp delayer                             pointer independent pointer retriever pointer                     steps  dependent delayer pointer sets ddelayer  dretriever given  pairs features describing figure  typical evolution subset weights  adversary coordinates                                monolithic agent task shown figure     addition pointers agent access  background information location  formalized self pointer dia single typical run figure  shows typically deic  mond note option mdp approxi tic agent identiﬁes delayer quite rapidly fact takes  mate homomorphic image homomorphism conditions average  update steps identify delayer  strictly met projections com  independent runs monolithic agent takes  puting weight updates inﬂuence features longer identify right transformation number   used construction image mdp ignored encoding seen figure  average  marginalizing                              takes  update steps figure  shows identi                                                        fying retriever harder deictic agent takes    experimental results                              update steps average  performance deictic agent compared rela result surprising correct position  tivized agent monolithic agent employs option retriever depends position delayer pointer  mdp chooses set  monolithic transforma delayer learned weights  tions formed cross product  conﬁgurations retriever receive inconsistent updates takes  deictic pointers agents employ hierarchical smdp weights track time  qlearning learning rates option main interested identifying delayer correctly  task set  agents trained initially deictic agent lower variability  option mdp acquire approximate initial option policy performance overall single run composite agent  achieves goal percentage trials takes  hours cpu time pentium iv  ghz  optimal agents use  greedy exploration results machine single run deictic agent takes  reported averaged  independent runs        hours monolithic agent considers possi    learning trials agents perform similarly figure  ble combinations pointer conﬁgurations simultaneously  monolithic agent marginally better initial perfor takes fewer update steps converge  mance understand look rates right weights deictic agent makes far fewer number  transformation weights converge figures    weight updates  vs  average                                                    ijcai                                                                                      robot                          phases perceptual phase agent looks                                                        environment ﬁnd consistent representation                                                     lying state consistent representation whitehead bal              robot                                    lard  state states map                                                     representation optimal actionvalue func                                                        tion overt phase agent picks action apply                      delayer  weights                               environment based current sensory input learning                                                        takes place phases lion algorithm whitehead              robot                                 ballard  example consistent representa                                                        tion algorithm qlearning used overt phase                                                       simple learning rule based step error information                                                                steps                       used train sensory phase step error                                                        update rule particular conﬁguration negative  figure  typical evolution subset delayer weights representation considered perceptually aliased  deictic agent task shown figure    ignored future simple rule limits applicability                                                        algorithm deterministic settings                                                          representation used homomorphic image                                    robot                          consistent representation mentioned ravindran             robot                                     barto restricting deﬁnition deictic op                                                                   tion schema employ partial homomorphic images option                                                        mdps guaranteed consistent representation al                robot                                                          ways employed absence knowledge option                                                        homomorphism ﬁnding right transformation employ                    retriever  weights                             constitutes search consistent representation                                                        employ bayesian learning phase lion                                                     algorithm form qlearning used overt phase                                                                          steps                          related work                                                        deixis originates greek word deiknynai  figure  typical evolution subset retriever means show point employed linguists  weights task shown figure                 denote pointing function certain words like                                                        meaning change depending                                                        text deixis introduced ai community agre  comment                                               mentioned earlier agre chapman  used deic  algorithm used updates weights tic representations design agent pengi plays  transformations each transition world arcade game pengo pengi designed play game  possible transformations assumed math view point human player used visu  ematical operations agent use different trans als screen input  formations project transition option whitehead ballard  ﬁrst use  mdp deictic pointers implemented physi ictic representations rl lion algo  cal sensors cases equivalent sensing ev rithm unfortunately method lion algorithm employs  ery adversary world making determine consistency works deterministic environ  sensing making gather data ments mccallum  takes direct approach  quired updates weights converge fairly overcoming perceptual aliasing employs deixis solve  rapidly compared convergence policy time car driving task models problem partially ob  agent spends “looking around” fraction servable mdp uses tree structure known utrees  total learning time                                  representing “states” identiﬁes necessary distinc                                                        tions resulting representation consistent    perceptual aliasing consistent                 approach divided explicit perceptual overt                                                        phases work using hierarchical     representations                                    rl deixis work aware minut  power deixis arises ability treat mahadevan  develop selective attention  ceptually distinct states fashion searches particular object room oper  chief difﬁculty employing deictic representations ates identifying salient object agent’s visual  phenomenon known perceptual aliasing whitehead ﬁeld shifting visual ﬁeld center focus  ballard  approach overcome perceptual alias object employ option identify salient  ing class methods known consistent representation object current visual ﬁeld state  methods methods split decision making “deictic” option effect depends                                                    ijcai                                                    
