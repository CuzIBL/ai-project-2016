          twostage method active learning statistical grammars                         markus becker                                 miles osborne                     school informatics                        school informatics                    university edinburgh                      university edinburgh                   mbeckeredacuk                           milesinfedacuk                          abstract                          depend probability unreliably es                                                        timated rarely observed event case      active learning reduces manually model indicate certainty particular analysis      notated sentences necessary training stateof conﬁdent general like      theart statistical parsers popular method place conﬁdence selection decisions based entropy      certainty sampling selects sentences probability distributions involving low frequency events      parser exhibits low certainty method sentences predicted parse selected      does quantify conﬁdence current sta basis infrequent events informative      tistical model particular entropy allow reliably select      conﬁdent selection decisions based  examples labelling need consider mech      low frequency events present novel     anisms      stage method ﬁrst targets sentences     propose novel twostage method ﬁrst selects      reliably selected using uncertainty sam unparsable sentences according bagged parser ap      pling applies standard uncertainty sam plies uncertainty sampling remaining sentences using      pling remaining sentences evaluation   fully trained parser evaluation shows method      shows method performs better pure  forms better single parser uncertainty sampling bet      uncertainty sampling better ensemble ter ensemble method bagged ensemble members      method based bagged ensemble members       explain results show empirically entropy                                                        fmeasure negatively correlated selection ac                                                        cording entropy tends acquire annotations sentences    introduction                                       low fmeasure current model oracle  stateoftheart parsers collins  charniak  based experiment demonstrates preferably selecting low  quire large amounts manually annotated training mate fmeasure sentences beneﬁcial explains  rial penn treebank marcus et al  certainty sampling successful general furthermore  achieve high performance levels creating la ﬁnd exactly sentences proposed meth  belled data sets costly timeconsuming active learning ods targets show correlation entropy  promises reduce cost requesting highly infor measure words entropy reliably identify  mative examples human annotation methods formative examples subset sen  proposed estimate example informativity degree tences average fmeasure particu  uncertainty single learner correct label larly useful ﬁndings help explain proposed  example lewis gale  disagreement method successful strategy  committee learners seung et al  paper  cerned reducing manual annotation effort necessary  active learning methods  train stateoftheart lexicalised parser collins  popular methods active learning estimate example infor    uncertaintybased sampling successfully applied mativity uncertainty single classiﬁer dis  problem problem hwa  sentences agreement ensemble classiﬁers  selected manual annotation entropy uncertaintybased sampling tree entropy chooses ex  probability distribution competing analyses high en amples high entropy probability distribution  tropy quantiﬁes degree uncertainty correct single parser hwa   analysis sentence                                                                  te            problem active learning methods uncer        fm τ  −  pm  ts log pm ts    tainty sampling method dealing               t∈τ  consequences low counts example parse tree τ set parse trees assigned sentence  probability likely reading peaked distribution stochastic parser parameter model spikeddistributions higher entropy indicate uncertainty  experimental setup  parse model correct analysis experiment employ stateoftheart lexicalised  useful know true parse tree                 parser collins  employ default settings    ensemblebased methods active learning select exam expending effort optimise parameters  ples ensemble classiﬁers shows high siderably smaller training sets involved active learning  gree disagreement kullbackleibler divergence common active learning research  mean quantiﬁes ensemble disagreement pereira et al  compare efﬁcacy different selection methods  mccallum nigam  average kullback forming simulation experiments label sentences sec  leibler divergence each distribution mean tions    penn wsj treebank marcus et al  distributions                                  ignoring sentences longer  words                                                          report average fold crossvalidation en                                                     sure statistical signiﬁcance results single fold            kl τ      dp                                            avg               randomly sample replacement initial labelled                         m∈m                            training set ﬁxed size –   sentences depend                                                        ing experiment – test set  sentences    denotes set ensemble models                                                  avg   remaining sentences constitute global pool unlabelled  mean distribution ensemble members                                                        sentences ca  sentences realistic experiment          tsk d·· kldivergence   avg                                              tag test set tnt partofspeech tagger  informationtheoretic measure difference                                                        parser brants  train tnt   distributions useful acquire manual annota                                                        sentences global resource fold crossvalidation  tion sentences high kldivergence mean                                                        parser  labelled precision  labelled  metric applied active learning context                                                        recall trained sentences applied test sets  text classiﬁcation mccallum nigam                                                          sentences                                                          randomly sample replacement subset    novel twostage selection method                  sentences global pool each iteration                                                        subset  sentences selected manual annotation  acquiring correct analysis sentence pre according current sample selection method  dicted analysis selected basis infrequent events notated sentences added training set  informative entropy allow consistent comparison methods evaluate test  reliably select examples labelling need set performance single parser trained entirety  consider mechanisms simple effective method labeled training data each step regardless selec  eliminate infrequent events parsing model tion method single ensemble method  simply bagging current training set retraining  parser set allows identify examples la length balanced sampling situations active  belling                                              learning parsing sentences question need variable    bagging general machine learning technique number labelling decisions confound sample  duces variance underlying training methods breiman selection metrics necessary normalise   aggregates estimates classiﬁers trained example tree entropy directly normalised sen  bootstrap replicates bags original training data cre tence length hwa  binary logarithm  ating bootstrap replicate entails sampling replacement number parser readings hwa   examples training set examples bootstrap use following method control sentence length  replicate perturb event counts sample selection given batch size randomly sam  gree inevitably eliminate low frequency ple sentences pool record number el  event types                                          selected examples sentence length lengths    proposed method operates stages ﬁrst        select sentences pool  select sentences unparsable according single length el examples highest score according  bagged version parser possibly parsable sample selection metric course union  current fully trained model remaining sentences sets examples randomly sampled  select highest entropy determined batch pool assume batch dis  fully trained model express formally follows tribution reﬂects pool distribution particular wrt                                                        distribution sentence lengths                        te                              use ﬂexible reimplementation parser dan           τ  maxf τm  failures          mm                                           bikel developed university pennsylvania bikel                                                         obtained httpwwwcisupennedu˜dbikel         te  fm tree entropy according fully trained model desirable methodological reasons automati                                          deﬁned  function failures  returns inﬁn cally tag global resource corpus split scheme  ity sentence parsable given bagged parser model does leave disjoint training material tagger                                    use gold standard tags pool sentences                                                                                                                                                                                                                                                                                                                                             fmeasure      performance                                                                                 coverage                                      entropyunparsed                              precision                                              unparsed                            fmeasure                                               random                                 recall                                               entropy                                                                                                                                                  number constituents                                number constituents    figure  random sampling learning curve maximal figure  comparison fmeasure learning curves number  training set sentences constituents num constituents given log scale  ber constituents given log scale                                                                method              cost  reduction                                                                random                    na    method effectively reproduces sentence length      entropyunparsed          proﬁle original corpus construction   unparsed                  guards selection sentence length biased sub   entropy                   sets furthermore equally applicable metrics  allows direct comparison metrics note table  annotation cost reach  fmeasure reduc  method applicable general sample selection tion random sampling  sequential data expect ﬁnd correlation  tween sample length score                                                        includingexcluding unparsed sentences experi                                                        ment compare methods include  relevant evaluation measures active learning parsing parsed sentences batch selected examples acquiring  typically evaluated terms achieving given fmeasure correct parse tree unparsable sentence increases  labelling expenditure cost acquir size model structure grammar presumably  ing manually annotated training material given terms helps increase coverage test set  number constituents fmeasure composite                                                          simple method unparsed preferably includes  term composed precision recall black et al                                                        parsed pool sentences batch number   fig  shows learning curve random sampling                                                        unparsed sentences fall short batch size randomly  experiment precision recall increase                                                        sample parsable sentences pool ﬁll batch  rate reason advantageous                                                        contrast entropy selects parsable sentences high  aggressively increase recall minimal impact pre                                                        entropy method entropyunparsed preferably selects  cision formulate stronger want increase precision                                                        unparsed pool sentences ﬁlls batch high entropy  way achieving pursue sentences                                                        examples view method composed  parsed                                                        binary parsability component gradual uncertainty com                                                        ponent baseline random parser trained ran    results                                            domly sampled training sets different sizes                                                          start initial training set  randomly sam  experiments section address following ques pled sentences containing  labeled constituents  tions generally useful select unparsable sentences continue  rounds  sentences sam  manual annotation gain using novel pled ca constituents subsequent experi  stage method stateoftheart uncertaintybased sam ments employ length balanced sampling cf sec   ple selection method given twostage method methods unparsed entropyunparsed perform  bagged component does compare state sistently better random fig  note  oftheart ensemblebased method employs bagged en formance nearly identical constituents  semble members                                       labelled method entropy performs consistently                                                                                                                                                                                              fmeasure                                         fmeasure                                                                                               twostage                                           twostage                        entropyunparsed                                    kldivunparsed                                 random                                              random                                                                                  number constituents                              number constituents    figure  new twostage method versus stateoftheart figure  new twostage method versus stateoftheart  uncertainty sampling                                 ensemblebased method         method            cov   prec   rec   fm                 method               cost  reduction       random                                  random                    na       entropyunparsed                        stage                        unparsed                                entropyunparsed                 entropy                                                                         table  annotation cost reach  fmeasure  table  parseval values different metrics  duction random sampling  constituents annotated                                                          twostage selection method novel method addresses  worse random                                    problems sentences reliably selected    methods unparsed  entropyunparsed reduce   popular active learning methods expect  labeled constituents necessary achieve  gain performance method stage preferably includes  measure  compared random en sentences unparsable according parser trained  tropy actually increases cost  tab    bagged version current training set    compare performance methods batch ﬁlled parsable sentences high en  annotation effort tab  shows precision recall tropy according second fully trained parser  fmeasure labelling constituents methods                                                          given composite methods preferably select  parsed entropyunparsed considerably higher cov                                                        parsed sentences perform nearly uniformly  erage random entropy lower coverage                                                        use considerably larger initial training set order  methods show comparable values precision differ                                                        able observe differences methods start  decidedly recall values methods                                                         sentences constituents continue   aggressively pursue unparsed sentences unparsed en                                                        rounds total  sentences sampled  tropyunparsed  points higher recall                                                        ca constituents  entropy accordingly higher fmeasures random  entropy                                            method stage performs consistently better    results conﬁrm importance including unparsed random entropyunparsed fig  reduces  sentences doing helps achieving better coverage labelled data necessary reach  fmeasure  higher recall value directly translates higher  compared random tab  central  measure accordingly following experiments sult paper reach level stage reduces  include unparsed sentences batch negative number constituents  constituents  sult purely entropybased method shows clearly stateoftheart method entropyunparsed reduction  naive application uncertainty sampling adverse  consistently higher precision  consequences extremely important consider recall entropyunparsed labelling  phenomena selection method targeting            stituents tab                                                                        sentences  fmeasure  pearson                                                                     parsable                 −                                                         unreliable                                                                           table  average fmeasure correlation coefﬁcients                                                        tween entropy fmeasure                                                                  periment test claim method oracle selects sentences                                                        preferred parse tree according current gram        fmeasure                                       mar low fmeasure determined goldstandard                                                      tree fig  shows method oracle performs consistently                                                        better best result new stage method                                                        suggests selection method successfully targets                                  oracle                difﬁcult sentences low fmeasure perform                             twostage                                 random                   experiment train parser randomly                                                        sampled training set  sentences apply test                                  set  sentences interested degree                    number constituents              correlation variables fmeasure preferred tree                                                        goldstandard tree tree entropy correlation  figure  comparison fmeasure learning curves number analysis  parsable sentences shows  constituents given log scale              variables negatively correlated cf tab  pear                                                        son’s coefﬁcient − given size considered       method            cov   prec   rec   fm          data set correlation highly signiﬁcant   selec       random                           tion according entropy tend pick low fmeasure       stage                        sentences given observation oracle experiment       entropyunparsed                 beneﬁcial target low fmeasure sentences                                                        ﬁnding explains entropy useful selection method  table  parseval values different metrics  apply bagged version parser  constituents annotated                     test set sentences unparsable elimi                                                        nate infrequent parse events focusing                                                         reliable sentences parsable fully trained  ensemble method   compare performance    model bagged model ﬁnd pearson  new method stateoftheart ensemble method efﬁcient entropy fmeasure close  tab   kldivergence mean ensemble words entropy fmeasure uncorrelated  bagged parsers cf subsec  method kldivunparsed entropy reliably select difﬁcult examples  preferably selects unparsed pool sentences ﬁlls batch class sentences average fmeasure  sentences having high mean kldivergence unreliable sentences  percent  sider sentence unparsed ensemble age points average indicating acquiring true  members fails deliver analysis previous ex parse trees particularly useful  periment start  sentences continue  note ﬁrst stage new method targets exactly  rounds set ensemble size              kind unreliable sentences experiments    fig  shows ensemble method kldivunparsed demonstrate new method successful  form better stage constituents af  ter point stage performs clearly better kl  divunparsed actually surprising result given  related work  methods perform similar jobs select unparsable preferably selecting high entropy examples shown  sentences according bagged parsers effective method parsing hwa  selecting  apply informationtheoretic measure entropy unparsed sentences previously suggested  kldivergence conjecture having ﬁltered high uncertainty thompson et al   difﬁcult examples ﬁrst stage second stage best knowledge effect  make use information fully trained quantiﬁed bagging ensemble members alterna  parser rate proposed method conceptually tively random perturbation event counts explored  simpler quicker compute ensemblebased context active learning argamonengelson  method                                               dagan  mccallum  nigam   particu                                                        lar argamonengelson dagan indicated    understanding new method                       methods target low frequency events bagging boost                                                        ing parser ensemble employed increase parser  acquiring annotation objectively difﬁcult sentences performance henderson brill  ap  improve parser employ oraclebased ex plication bagged parser ensemble active learning
