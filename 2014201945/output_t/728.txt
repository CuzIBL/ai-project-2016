                    learning understand web site update requests             william cohen                    einat minkov                    anthony tomasic          center automated        language technologies institute   institute software research         learning  discovery           carnegie mellon university        carnegie mellon university       carnegie mellon university            einatcscmuedu                tomasiccscmuedu          wcohencscmuedu                        abstract                           add following contact staff list                                                         arthur scott ascottardracom rm         natural language processing nlp     events page delete row december  assembly      requests information wellstudied    automotive engineers conference room      little prior work understand    people page tommy lee delete        ing requests update information pa    delete kevin smith’s phone number  thanx martha      propose intelligent     change mike roberts michael roberts      process natural language website update requests      semiautomatically particular figure  example update requests edited slightly space      analyze requests posted email update readability      factual content individual tuples database      backed website users’ messages processed      ing scheme decomposing requests se waiting period human webmaster incorporate      quence entity recognition text classiﬁcation corrections leading long processing times web site      tasks using corpus generated humansubject  date      experiments experimentally evaluate                                                          paper intelligent      formance robustness                                                        process website update requests semiautomatically      handling request types seen training                                                        natural language processing used analyze incoming      userspeciﬁc language styles seen training                                                        request based analysis constructs                                                        executable version proposed change repre    introduction                                       sented preﬁlled instance form examining  paper present natural language form end user efﬁciently determine anal  helps webmaster maintain web site organiza ysis step correctly accomplished necessary  tion speciﬁcally understanding ride results agent’s analysis changing values  certain naturallanguage requests change factual form prior experiments human subjects shown  tent website assume website based process effective means reducing human ef  database focus requests update speciﬁc facts fort initial analysis step imperfect   database                                       paper focuses naturallanguage processing    motivate note nlp requests typical informal text like email users’  deliver informationie questionanswering messages ungrammatical use capitalization patterns  studied little prior work nlp requests inconsistently use abbreviations include typos  update information nlp update requests illustrated figure  consequence standard shallow  attractive research problem user nlp tools partofspeech tagging nounphrase  easily detect imperfectlyprocessed utterance chunking preliminary steps text parsing    concrete example update requests consider quite unreliable suggest learning ap  requests website updates proach parse text framework  practically useful organizations maintain single premodeled domain knowledge decompose gen  large databasebacked web site includes information eral task sequence entity extraction classiﬁcation  contributed corrected individuals subtasks subtasks learned incom  individual users each contribute ing messages improving performance time  database changes year reluctant learn ﬁrst scheme decomposing request  terface database make occasional updates understanding sequence learning tasks  orginazations users submit update requests email corpus requests used performance  natural language human webmaster frequently evaluation each learning subtasksin experimental results present sider request  ﬁgure previous analysis tells  experimental results robustness – par delete attribute value tuple “per  ticular perform request types seen son” relation key value “tommy lee” does  training userspeciﬁc language usage seen specify value deleted complete  training finally evaluate endtoend system’s perfor analysis deletevalue requests necessary determine  mance determine fraction messages pro attribute needs deleted text clas  cessed completely errors conclude review siﬁcation task given database schema ﬁxed number  related work conclusions                  attributes need considered possible targets                                                          pedagogical reasons described steps    understanding update requests                      taken separately steps                                                        independent—ie information each step analysis    analysis procedure                               affect steps section  eval  figure  gives example web site update requests uate particular sequence outputs steps  addressed given analysis procedure general requests propagated inputs steps  factual update “the animated gif  logo doesn’t ﬂash properly view home  pc” simply ﬂagged forwarded real human  experimental corpus  webmaster                                                        order collect appropriate corpus series controlled    analysis procedure contains following steps                                                        humansubject experiments performed partic     request type classiﬁcation informal prelimi                                                        ipants given series tasks pictorial form asked  nary analysis real webmaster request logs suggested                                                        compose send appropriate email messages  factualupdate requests following forms add                                                        webmaster agent response user’s request  new tuple database delete existing tuple delete                                                        agent returned preview updated page pre  value existing tuple alter add replace value                                                        ﬁlled form contained structured representation  existing tuple step analysis deter                                                        user’s request user correct errors editing text  mining type request text classiﬁcation task                                                        various slots form choosing pulldown  each request mapped categories addtu                                                        menus  ple deletetuple deletevalue altervalue  categories mapped otherrequest    overall humangenerated corpus contains total    named entity recognition ner step  example requests involving approximately  sub  analysis identify entity names request figure  jects  different tasks  shows result correctly recognizing person names email note pictorial task descriptions pre  addresses phone numbers room numbers event titles sented multiple users sort duplication lead  sample requests subscript entity indicates undesirable behavior learning certain  type instance “person” “room number”   pictorial task demonstrating addition phone number    rolebased entity classiﬁcation distinguish person named greg johnson example represented  different roles entity update request multiple similar examples data  entity keyentity serves identify database learn correlation phrase “greg johnson”  tuple modiﬁed ﬁgure key entities task adding phone number address problem  marked superscript example entity manually replaced duplicate entity names alterna  “freddy smith” sentence “please delete freddy smith’s tive values corpus preserving surface features  phone number” entity newentity marked capitalization patterns misspellings  superscript value stored database requests corpus largely factual updates  entity oldentity superscript value cur cerning single tuple database focus  rently database user expects replaced tention requests relations underlying  newentity entities unrelated execution database schema corpus contain attributes  request considered noiseentities ﬁgure type “type” deﬁned output  superscript marking rolebased entity classiﬁcation entity recognizer instance personal details  entity classiﬁcation task entities produced include home phone number ofﬁce phone number  earlier ner step given additional classiﬁcation corpus duplications duplications    target relation classiﬁcation second column fig sort require additional entity classiﬁer  ure  shows relation associated each request mentioned text ungrammatical  ﬁxed database schema ﬁxed set possible noisy preprocessed text annotating ver  lations text classiﬁcation operation   sion brill’s partofspeech tagger brill  hand    target attribute classiﬁcation given entities roles coded nounphrase chunker tuned email  entities target relation request type seman ing different corpus learning rely mainly  tics tuplebased commands com alternative features exploit syntactic properties  pletely determined type request messages features prove informative  derspeciﬁed deletevalue request example noisy text corpus                                   request                          request    target    target                                                                       type     relation  attribute                                                                      add following contact staff list arthur scottperson                                                               addtuple   people      −              ascottardracomemail rm room   phone                                                              events page delete row december date assembly                                                                deletetuple events      −              automotive engineers conferenceeventtitle room aroom                                                         people page tommy leeperson delete                                                                    deletevalue people  phonenum              phone              delete freddy smith’sk ’s phone number  thanx                                    person                          deletevalue people  phonenum              marthaperson                                                               change mike robertsperson michael robertsperson altervalue people personname              people page                                               add greg johnsonperson’s phone number                                                                    altervalue  people  phonenum              phone                                         figure  analyzed update requests      learning                                                                     test set                                                                   type    corpus validation  each individual learning tasks rel    time               na  evant experimental results given component        date                                                                                  email                entity recognition                                                                             rules  named entity recognition ner identiﬁcation  substrings request correspond entity names       base  tuned    tuned features  wellstudied nontrivial naturallanguage processing type    cv      cv     cvusr    cvreq  task evaluated ner performance seven linguistic  time                         types time date email addresses phone numbers date                       room numbers personal names data includes                       mentions additional entity types job titles orga phone                 nization names sufﬁcient quantity learning room                       experimented approaches entity extraction person                    rulebased approach handcoded rules used                 learning  recognize entities learningbased extraction rule  language used based cascaded ﬁnite state machines table  entity recognition results measures  learning algorithm use vphmm method  discriminatively training hidden markov models using  votedperceptron algorithm collins            entity types applying vphmm algorithm ner    manually constructed rules best suited reduced problem sequentially classifying each token  entities email addresses temporal expres “inside” “outside” entity type extracted  sions types based limited vocabularies performance evaluated fmeasure entities  fairly regular patterns relatively easy counted correct start end boundaries  model manually email addresses extreme example correct partially correct entity boundaries given  simple regular expression matches email ad partial credit lefthand columns table titled  dresses                                              “cv” show fmeasure performance unseen examples    table shows results extraction using handcoded estimated using fold cross validation righthand  rules email temporal expressions evaluated columns discussed later  rules main corpus used generating performance shown sets features base  rules message “validation set” containing feature set corresponds words capitalization templates  messages collected second later series window including word classiﬁed  humansubject experiments unfortunately time expres three adjacent words each side second set features  sions present additional set shown labeled tuned features table comprised base  table entity performance  cases features plus additional entitytype speciﬁc features  evaluated    table show results learning set geometric mean recall precisionwhich constructed using rule language used “cv” column shown results task  build handcoded extractors example extracting lation determination relatively straightforward provided  dates added indicator word number sufﬁcient training data  range  personal names added indica  tor words certain dictionaries ﬁrst target       ferror             def  names                                                   relation   cv      cvusr    cvreq     error    overall level performance extraction – better people            entity type using tuned features – budget             encouraging especially considering irregularity events            text relatively small training data sponsors            available users tend use terminology  formats website resulting reduced variability table  target relation classiﬁcation results    rolebased entity classiﬁcation  entity span identiﬁed determine  request type classiﬁcation  functional role—ie acts keyentity newen cases type request determined  tity oldentity noiseentity outlined section  roles entities request instance addtu  approach problem classiﬁcation task ex ple request keyentities multiple newen  tracted entities transformed instances tities conversely deletetuple request keyentities  classiﬁed learner                               newentities altervalue request    features used learner follows keyentities newentities means request  closest preceding “action verb” action verb types determined algorithmically set en  dozen words generally used denote update tity roles request  “add” “delete” closest preceding preposition primary need requesttype classiﬁer distin  presence absence possessive marker guish deletevalue deletetuple requests  entity indication entity deter types requests syntactically quite similar  mined np                                             sider instance requests “delete extension dan    experimental results important classes smith” “delete entry dan smith” ﬁrst  shown table  column marked “cv” used deletevalue phone number second delete  svm learner linear kernel joachims  tuple request action verb “delete” included en  show results each class separately addition tities identical distinguish request  performance each category show error rate types necessary determine direct object verb  “default error” error obtained guessing “delete”—which difﬁcult shallow parsing inaccu  frequent class                              rate noisy corpus—or construct features                                                        correlated direct object verb   entity                ferror            default      used following features counts                                                        keyentities oldentities newentities request   role         cv     cvusr    cvreq     error   keyentity             action verbs appearing request nouns   newentity              appear np immediately following action verb   oldentity                 appear nps action verb passive form                                                        nouns previous step appear dictionary                                                         common attribute names “phone” “extension”       table  rolebased entity classiﬁcation results “room” “ofﬁce”                                                          results shown table  features     results role determination distinguish request types quite accurately  surprisingly good considering difﬁcult linguistic nature  role assignment task set features suggested request            ferror            def  small simple informative support type     cv     cvusr    cvreq    error  ing effective learning roles semiungrammatical deletetuple            texts                                                  deletevalue                target relation classiﬁcation                            table  request type classiﬁcation results  determine target relation used svm  learner input features classiﬁer “bagof  words” representation request entity types  target attribute classiﬁcation  included request example presence “phone classiﬁcation requests target attributes sim  number” entity request indicates “people” relation ilar request type classiﬁcation  database schema results shown table  termining delete request concerns attribute mustdetermine attribute request concerns given test fold tasks encountered  sumptions step need performed deletevalue training set results split given columns  requests specify oldentity value      titled “req”    fact learn vocabulary attributes names summarize results loss performance ner  simple bagofwords feature works quite task problems moderate larger seen splitting  shown results table  “cv” column users entityrole classiﬁcation drops slightly  vocabulary used corpus each attribute performance targetrelation classiﬁcation remains ex  fairly small phone usually described ”phone” cellent relations performance request  ”line” ”extension” users tend type classiﬁcation does drop noticibly drop al  use terminology website relevant certainly lack appropriate training data  vocabularies limited nature                   handful tasks updating “budget” relation                                                        relatively small number tasks requiring request   request                  ferror            def    type classiﬁcation similarly task classiﬁcation   type            cv     cvusr    cvreq     error   tribute practically infeasible attribute types   personal             settings small number attribute names   phone                     mentions corpus provided   room                    given sufﬁcient training data relevant relation   publication               attribute perform different requests   photo                      cv                                overall evaluation                     section complement componentlevel evalua                                                        tions evaluation entire endtoend process           table  attribute classiﬁcation results     executed tasks following order ner run                                                        each entity type roles extracted entities                                                        signed ﬁnally relation request types assigned note    robustness issues                                  noisy predicted entities entities extracted                                                        ner model used input entityrole classiﬁer  practically important question robust auto relation requesttype classiﬁers  mated webmaster changes distribution users used vphmms handcoded rules extraction  andor requests investigate questions use nonsequential multiclass voted perceptron freund  different sampling strategy performing crossvalidation schapire  classiﬁcation  instance determine robust queries user’s perspective interesting note  new users grouped examples generated percentage requests successfully processed  each subject single set performed cross message level different levels automation exper  validation constrained set split train iments  messages got relation  ing test words test fold quest type classiﬁed correctly cases user  example requests subjects contributed received correct form entries ﬁlled  training set split estimates performance incorrectly half cases  user  used large pool users cross received correct form entities cor  validation user results given results tables rectly extracted entity roles mislabeled  columns marked “usr”                               messages automatic processing encountered    corpus users usually personal stylistic errors  quirks—for instance user consistently dates note endtoend scenario errors entity  names particular format expect recognition phase propagated role classiﬁcation task  performance sort split worse perfor order message considered fully correct  mance default uniform splits seen assignments accurate each multiple  results ner task drops slightly entities included message correct   entity types slight drops performance cisions perfect performance request  seen three entityrole tasks notici overall ﬁnd results promising consider  ble drops seen seven attributeclassiﬁcation ing limited size corpus  tasks person photo overall performance  affected slightly setting            related work    similarly determine robust fu  ture requests quite different requests encoun lockerd et al  propose automated webmaster  tered during training grouped examples called “mr web” similar emailbased interface  request type including requests generated voted perceptron marginbased classiﬁer im  particular pictorial task performed cross plementation reasons convenient use exper  validation constrained set split train iments svm performance generally quite  ing test scenario example requests good
