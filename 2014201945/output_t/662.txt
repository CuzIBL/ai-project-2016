                utile distinctions relational reinforcement learning                                    william dabney amy mcgovern                                          university oklahoma                                        school science                                 amarackouedu amcgovernouedu                          abstract                          ignore irrelevant ones traditionally state representation                                                        designed user learned policy      introduce approach autonomously cre                                                          learning relational representation introduces key      ating state space abstractions online rein                                                        challenges ﬁrst exponential growth search space      forcement learning agent using relational repre                                                        second relational environments tend      sentation approach uses treebased function                                                        high degree autocorrelation shown cause      approximation derived mccallum’s                                                         selection bias makes distinctions appear useful      utree algorithm extended approach                                                        jensen neville  relational utree      use relational representation relational                                                        compensates size search space using stochas      observations represented attributed graphs                                                        tic sampling srinivasan  autocorrelation violates      mcgovern et al  address chal                                                        independent identically distributed assumption      lenges introduced relational representation                                                        statistical techniques compensate effects      using stochastic sampling manage search                                                        temporal autocorrelation temporally sampling      space srinivasan  temporal sampling                                                          separately address need adapt changes      manage autocorrelation jensen neville                                                         environment incorporating efﬁcient tree restructuring ut      relational utree incorporates iterative tree induc                                                        goff et al  allows relational utree create      tion utgoff et al  allow adapt                                                        compact trees representational power      changing environments empirically demon                                                        helps prevent overﬁtting stochastic environments      strate relational utree performs better      similar relational learning methods finney et al similar works   finney et al       driessens et al  blocks world  chapman kaelbling  tg algorithms      main demonstrate relational utree   driessens  driessens et al       learn play subtask game    major differences tg based      called tsumego ramon et al              algorithm relational utree primary difference                                                        relational utree dynamically restructure trees                                                        tg build new tree scratch allows    introduction                                       relational utree adapt changes environment  paper introduces method combines expressive correct early mistakes tree relational  power relational representation learning power utree uses graphs represent observations tg uses ﬁrst  reinforcement learning rl goal autonomously der logic predicates addition tg creates separate policy  learn relational state space approximation simultane tree called ptree relational utree derives policy  ously learning act optimally relational representation qvalue tree finney et al’s  approach  enables agent reason higher level allow based algorithm uses deictic representation  agent learn difﬁcult problems kaelbling et al relational utree makes use relational representation   rl ideal technique realworld control incorporates tree restructuring empirically compare  cause learn achieve goal told performance relational utree approaches  accomplish considerable recent inter blocks world environments  est combining techniques tadepalli et al  van  algorithm description  otterlo     primary contribution paper introduc relational utree algorithm follows utree algorithm  tion online rl method relational utree au closely use standard rl partially observable  tonomously construct treebased function approxi markov decision process pomdp notation each  mation using relational representation utree mccallum time step agent executes action ∈ receives   develops treebased state space allowing observation ot ∈ reward rt ∈ ℜ sutton  focus important aspects observations barto  kaebling et al                                                     ijcai                                                                                                     variable memories    mark         focus                                       list                    block exists                                  block                                        color  green                                       hasfocus  true                       left relationship              list blocks color  green                             mark                                                 yes                                                                           list blocks                                                          green block                         block                               figure  example variable memory creation instance                         color  red                    figure dropped tree                                                                          istence xh  ∈ tvh ∈ relationship existence    block  leftright block                             xooh  ∈ teo  o∀oo ∈ mvh ∈                                                                                      ∈     ∈         color  blue   color  green                   attribute value valuea  valuea                                                          mv ∪ meh ∈ history index                                                        memory parameter limiting number previ                                                                                                  block           block           block               ous observations considered set                                                        natural numbers        color  table   color  table   color  table                                                          variables pointers variable memories                                                        variable memories reference previous distinctions al  figure  example blocks world conﬁguration partially lowing simple distinctions used construct complex  observable blocksworld finney et al  observation queries each type distinction set variable mem  fully observable blocksworld driessens et al  obser ories created instance dropped node  vation                                                        distinction given ∈ vi  tvx object                                                                        ∈               ∈       observation takes form attributed graph  distinctions ei vi                                         relationship distinctions ∈ vi ∪ ei  avaluea ∈        set objects             environment represented vertices graph valuea attribute value distinctions  set relationships represented edges mcgov figure  shows example relational utree uses  ern et al  av ae set attributes variable memories observation shown figure  vertices edges respectively elements falls root node blocks added variable  discrete real valued attributes av ae contain memory second node selects blocks list  zero elements tv te required discrete “color  green” saves matches  valued types vertices edges example observations relational utree allows static objects referenced                                                        nonstatic attributes mayt accessed set  blocks world shown figure  attributes                                         ∈  relationships omitted readability graphical repre static objects deﬁned vi focal object  sentation used does place individual identiﬁers objects incorporated allow agent reason deictically                                                        let mvn set object variable memories  instead objects identiﬁed type attributes                      ∪    relationships objects property graphical rep node root node nr nr  set                                                        object variable memories created distinction given  resentations advantageous generalizing concepts                        relational utree description uses mccallum’s  node denoted  let np parent node                                                        set object variable memories node  notations refer set distinctions lead tree           ∪      node state represented leaf node transition deﬁned np np  similarly                                                        deﬁne mengivenmenr  instance tt  tt−at−ot rt  represents step  agent’s experience set instances contained leaf  relational utree algorithm  node denoted set instances contained  leaf node action sa time relational utree algorithm works follows                                             ordered set transition instances th   create tree distinctions initialize  leaf node speciﬁc transition instance belongs                    denoted tt                                      step experience environment choose                                                            action at− policy action ltt−    relational utile distinctions                        ε probability choosing random action record                                                                                             ∪     refer distinction utile   experience tt tt− at− ot rt   tt   distinction statistically separates set transition using standard decision tree methods drop tt  instances agent better able predict tree save tt leaf node ltt setting  ward  sets possible distinctions object ex  ∪tt  mark tree node ∈ stale                                                    ijcai                                                        stale node indicates distinction node     need changed during restructuring                            transposition     environments observations  au                                                                                                     tocorrelated example blocksworld environ     ment shown figure  objects relationships                                                                                            remain largely regardless action                                performed example temporal autocorrela     tion cause feature selection bias jensen                      neville  situations remove autocor     deletion       replacement     relation through temporal sampling steps                                                                                                                                               forgotten user deﬁned value                                                                                                                                                                                                     leaves tree representing states       leaf      form step value iteration using equations                         leaf leaf leaf leaf     equations estimated immediate reward esti        mated probability arriving state s executing     action state given equation   di figure  let current node cnnn                                                                                φ    φ    φ     rectly follow mccallum’s equations               denote children     perform tree                                                       transposition setting φ  φ  φ φ  φ                                                                                                       ←    γ                  φ    φ             φ    φ                            ∑pr                    set                                                                                            reclassify instances using subtree                                                                                                                                                    cncn set    φn  φ  use φ reclassify                    usmaxqsa                                ∪                             a∈a                         instances                                                               ∈ pφ user speciﬁed value                           ∑t ∈t sa ri                   rsa                            pruned tree used                               sa                                                                                                               paper φn replaced φ through series                                                           tree transpositions distinction trees depth greater                                                              ∀t ∈ sa st lt            distinctions ’pulledup’ time        prs sa                                                      sa                     beginning root distinction                                                           best distinction tree given node   update tree steps ﬁrst ensuring quality termined tree restructured following utgoff et al     current distinctions followed expanding tree  current distinction best                                                                      adding new distinctions leaves stale tree φn  φ  recursive depth     nodes updated follows                       ﬁrst traversal tree applied base     stochastically generate set distinction trees cases shown figure  reached point                                                                                Φ include existing distinction tree φn set Φ utile distinction φ  ”pulledup” recursively     Φ  Φ∪φn distinction tree forming tree transposition steps shown ﬁgure     distinctions set instances organized single ”pullup” performed     tree structure consider distinction trees depth base case tree addressed best distinc     constant consider larger depths tion tree φ target node     utile distinction trees each distinction tree tree restructuring operation completed     φ ∈ Φ deﬁnes set fringe leaf nodes            mark stale node changed through     each fringe leaf node ∈ set expected fu tree restructuring mark nodes subtree     ture discounted rewards makes distribution stale continue apply step  each stale child node     δs given equation  mccallum             process continues branches stale                                                           quality distinctions tree ensured             δ     γ       ∈                finally perform value iteration convergence                  rti  ti  ti               calculate kolmogorovsmirnov distance    steps expand tree leaves each leaf                                                           node tree determine best distinction tree     each pair distributions denoted ksδδ let pφ     set pvalues given equation     instances node using process outlined                                                           step  new distinction tree utile expand                   δ δ  ∀   ∈                tree adding subtree leaf dropping             pφ    ks   si     si               instances new distinction tree     choose best distinction tree Φ moves list leaves adds set leaves                                                               current distinction tree φn using equation          list continue expanding tree                                                           longer utile perform value iteration                           ∑                                   p∈pφ log                     vergence expansion                   φ  min                                              φ∈Φ    pφ                        repeat step  stopped                                                   ijcai                                                      stochastic sampling                              example observations domains shown fig  use stochastic sampling srinivasan  address ure   large space possible distinctions introduced rela blocksworld domain agent focus marker  tional representation srinivasan shows sample deictic marker agent perceives attribute  tests stochastically look small fraction formation focused object marked  total highly conﬁdent ﬁnding object marker observable adjacent  best possible number tests focus marker example marker                      ln−α  sampled given ≥  −   α probability focus block agent observe block object                      ln                             marker object relationship indicating block ob  ﬁnding test  × srinivasan                                                         ject marker object small difference  key equation sample size does depend                                                        finney’s domain arise translation deictic rep  number possible distinctions                                                        resentation truly relational goal pick    paper used   α                                                          green block requires ﬁrst removing blocks   conﬁdent ﬁnding distinction                                                         covering actions available agent identi  situation need sample  distinctions grad                                                        cal finney movefocusdirection focusoncolor  ually reducing search distinctions                                                        pickup putdown markertofocusmarker focus  ward exhaustive search values took                                                        tomarkermarker agent given reward   second expand leaf node containing  instances                                                        reaching goal penalty  invalid moves   reduce  takes minutes                                                        time step  expansion similarly   expansion  time leaf node  minutes demon second domain blocksworld fully observable  strates exhaustive search distinction space task stack green block red block  feasible compensate use stochastic sampling actions movexy unique blocks                                                        driessens agent received reward  reaching    tree restructuring                               goal minimal number steps   early stages learning agent seen performance relational utree tree  fraction environment create state repre restructuring domains shown figure  left pan  sentation suited true nature en els empirical performance εoptimal ε    vironment prevent tree overﬁtting allow domains results averages  runs  adapt changing environments relational utree im cause online performance large changes tree’s  plements online tree restructuring based iterative tree structure reﬂected temporary drops performance  induction algorithm utgoff et al  iterative tree happens frequently tree converges  duction ensures best split instances used difﬁcult blocksworld domain relational  each node tree beginning root working utree converges faster finney’s approach ac  way leaves                                    curate results  training instances finney’s    original iti algorithm kept track list statistics formance approximately  ﬁnal convergence  each possible test tree node relational  method converges  optimal  utree instance based redundant iti use εgreedy exploration methods does  looked list statistics node decide current ﬁrst  steps  best test node relational utree regenerates tests  node decides best directly keeping track comparatively actions blocksworld domain  possible tests practical solution situa higher level allows agent discover goal  tion large search space distinctions rela faster blocksworld performance driessens’  tional environments large search space known tg algorithm domain comparable tg does                                                                                                    ε  problem inductive logic programming dzeroski et al explore environment does use greedy   computationally expensive exploration method like allows algorithm  compute tests restructuring leads signiﬁcantly smaller converge average reward  converge                                                                                  trees reduces overall computation time         average reward trial                                                            figure  right panels compares tree sizes    experimental results                               tree restructuring domains                                                        mains performance comparable average tree size    blocks world results                             considerably smaller tree restructuring used  apply relational utree versions blocks agent able construct smaller tree capture  world domain ﬁrst blocksworld partially observ information remove irrelevant  able blocksworld task lowlevel actions blocks formation gained early learning use restructuring  finney et al  second blocksworldisa introduces increased variance temporary loss  fully observable domain highlevel relational actions performance directly following large tree restructuring  three blocks driessens et al  domains smaller trees result signiﬁcant improvement  tain moveable colored blocks unmovable table blocks running time                                                    ijcai                                                                                                                                                                                                                          caled                                                                                                                                        tree                                                                                                                                                                                                                                                                                                           es   trial                                                                               er                      restructuring                             lea                                                                                                                                                                              restructuring                                      ard                                                                                                                                                                  bw  restructuring                                                                          umber                                                                                       bw  restructuring     total                                                                              bw  restructuring                                                                                         bw  restructuring                                                                                                                                                                                                                                                                                                                                          number training instances         number training instances blocksworld  domain                                            figure  learning curves relational utree blocksworld blocksworld domains tree sizes  tree restructuring shown domains right    autocorrelation                                  effective sample size dramatically lower sam                                                        pling small amounts sampling dramatically increase  detect potential temporal autocorrelation used ran                                                        sample size tests actions temporal autocorre  domization sets observations perform                                                         lation direct correlation ac  randomizations data each time performing                                                        tion performed recent action  kolmogorovsmirnov test test statistics form distri                                                        autocorrelation causes feature selection bias jensen  bution analyzed ﬁnd effective sample                                                        neville  relational utree used sampling  size similar χ jensen neville                                                        autocorrelation   autocorrelation effective sample  size match actual sample size used tests  tsume results    kolmogorovsmirnov test compares distributions tsume domain subtask game  sizes total size data  stones placed different conﬁgu  mains constant proportion data split rations task identify best protecting  distribution change distinction player’s stones capturing opponent’s stones rela  experiment actual number instances var tional utree learns play best ﬁrst tsume  ied proportions speciﬁc distinction created game relational utree trained set  randomly                                 held constant use  max represent rela sampled problems gotools database wolf                            nn  tive sizes distributions substituting tested set  randomly sampled indepen  original equation ks given sachs  obtain dent problems database agent receives                                                        reward   correct answers depending     ×kα        ×         dα    ne     ×p−p effective sam quality penalized − incorrect                                                                                   −    ple size ne  kα dα critical values ks test tempts penalized   invalid moves                                                        placing stone stone trying                                                        board                 object block relationship action                    exists   holding exists             similar ramon et al’s  approach test rela                                                     tional utree’s approximation ranking moves using    sampling                                               values  runs relational utree averaged  ac                                                        curacy test set ramon et al’s                                                         approach obtained  accuracy test set  prob    drop th                                     lems generated gotools training  problems                                             encouraged results exploring                                                        main greater future work    drop th                                                discussion                                                        signiﬁcant performance difference finney  figure  effective sample size relative actual sample size large degree similarities algorithm  variable amounts sampling                    finney’s useful discuss relational utree                                                        able overcome problems previously    figure  shows results detection removal ported relying observation history disambiguate states  temporal autocorrelation blocks world domain using state values determine policy states  pie chart each group effective sample size disambiguated difﬁcult problem overcome  sampling lower pie charts removing through use tree restructuring agent contin  th th instance effective sample sizes ues learn carries older instances histories reﬂect  object existence relationship action test shown outdated policies agent’s performance increases                                                    ijcai                                                     
