       privacysensitive approach modeling multiperson conversations                         danny wyatt                              tanzeem choudhury                  dept science                           intel research                   university washington                    ne th st seattle wa                  dannycswashingtonedu                    tanzeemchoudhuryintelcom                            jeff bilmes                                 henry kautz                dept electrical engineering                dept science                   university washington                      university rochester                  bilmeseewashingtonedu                       kautzcsrochesteredu                        abstract                            limits analyses data                                                        does render data useless broad range infer      paper introduce new dynamic bayesian ences privacysensitive features      network separates speakers speak applications beneﬁt increased access      ing turns multiperson conversation pro spontaneous speech data needing know      tect speakers’ privacy using features content speech      intelligible speech recon     example research speech emotion uses      structed model present combines data      information pitch volume duration schuller      multiple audio streams segments streams et al  data used research      speech silence separates different  acted speech campbell  datasets gathered      speakers detects nearby individu constrained situations greasley et al  douglas      als wearing microphones speaking cowie et al  ang  acted speech known      pretrained speaker speciﬁc models used poorly reﬂect natural emotion batliner et al       easily applied new dif  constrained datasets recorded relatively unnatural set      ferent environments show promising results tings television shows interviews representative      different datasets vary background ordinary human communication demand      noise microphone placement quality natural data sets study speech emotion      versational dynamics                             douglascowie et al                                                          second example study social networks tra                                                        ditional social network analysis relied data gathered    introduction                                       through surveys vulnerable known bi  automatically modeling people’s spontaneous facetoface ases bernard et al  marsden  party ob  conversations problem increasing dif servers costly labor intensive does scale  ferent research areas little data available recent studies used automatically gathered data  captures truly spontaneous speech—speech recorded online interactions mccallum et al  kossinet  situ people lives portable devices capable watts  studies involving automat  recording grown storage capacity ically recorded facetoface conversations—despite fact  coming smaller cheaper powerful obstacles facetoface communication remains people’s dominant  gathering spontaneous speech remain mode interaction baym et al  study social net  obstacle prominent privacy            works sufﬁcient know spoke    collecting truly spontaneous speech requires recording said  people unconstrained unpredictable situations finally nonlinguistic aspects spoken communication  public private little control useful features medical meeting understand  recorded uninvolved parties recorded ing applications speaking rate indicator mental ac  consent—a scenario raw audio involved tivity hurlburt et al  behavioral symptom  unethical illegal recording spontaneous mania young et al  abnormal conversation dynam  data realworld situations require protecting pri ics symptoms asperger syndrome wing gould  vacy involved storing complete audio  autistic individuals speak highpitched  speciﬁcally data saved allow voice lack intonation tagerflusberg  meetings  linguistic content person’s speech reconstructed interruptions speaking time reveal information                                                    ijcai                                                                                                            voiced source  status dominance hawkins  gender speciﬁc                         vocal tract filter  differences interruptions consequences dif  ferences active topics research tannen   features require access linguistic content  applications beneﬁt increased access unvoiced source                                                                                                   speech  natural speech data                                                       gain      problem description  speciﬁc longterm goal model evolution spon figure  sourceﬁlter model speech production  taneous facetoface interactions groups individu  als extended periods time order protect model’s ability infer speaker turns seen nec  privacy research subjects nonsubjects essary lowlevel enabler higher level conversation  come contact ensure acous standing  tic information saved used reconstruct finally previously mentioned  intelligible speech stored features contain research recognizing emotions associated speech  information serve input models conversational douglascowie et al emotion  social dynamics time insufﬁcient recognition applications need know words  formation reconstruct said positively spoken shriberg  mentions importance  identify individuals wearing microphones modeling natural speaking behavior identiﬁes    work presented paper ﬁrst step fundamental challenge spoken language applications  goal present unsupervised approach separating  speakers turns multiperson conversation rely  speech features privacy  ing acoustic features compromise privacy  features employed useful modeling conversational begin giving simple description speech pro  dynamics—who speaking how—but sufﬁcient duction based sourceﬁlter model quatieri   speech recognition                               figure  speech sounds modeled    work novel ways key contribution independent components source sound generated  joint probabilistic model combines streams acoustic glottis ii ﬁlter vocal tract shapes  features set individuals wearing microphones infers spectrum source sound source ei  speech present separates different speak ther voiced fundamental frequency pitch  ers each detects individu voiced fundamental frequency prosodic information  als them—who equipped microphones— speech intonation stress duration described  speaking does require pretrained speaker speciﬁc fundamental frequency energy volume change  models scales number users during speech frequency response vocal tract—  used new speakers new environments model particularly resonant peaks formants—contains  extended dynamically varying number speak formation actual phonemes basis  ers new audio streams come new words reproduce speech intelligibly information                                                                                                  person enters exits group introduce novel fea three formants required donovan   pro  ture set useful segmenting speakers mod cessing audio removes information  eling conversation attributes used tran mants ensure intelligible speech synthe  scribe actual words spoken during conversation sized information remains privacy                                                        preserved    related work                                       detect speech speciﬁcally voiced speech                                                        model said extract features  work modeling spoken conversations contain information source prosody  domain meeting understanding nist  formants three features shown  dielmann renals  goals meeting useful robustly detecting voiced speech vary  understanding speaker diarization determining spoke ing noise conditions noninitial maximum autocor  reynolds torrescarrasquillo  relation peak ii total number autocorrelation peaks  work domain assumes access iii relative spectral entropy basu  computed  audio necessary remove information  ms chunks audio periodic components  used transcribe speech                voiced speech figure  autocorrelation    previous work linguistic conversa small number sharp peaks similarly relative spectral  tion analysis ochs et al  sacks  clearly entropy spectrum time local mean  work relies solely information words spectrum  ms window high voiced speech  spoken basic acoustics speech presence indoor outdoor noise wind  model presented paper complementary tra fan  ditional conversation analysis inasmuch detecting spoken regions needs ad  versations considered turn taking speakers ditional information separate different participants                                                    ijcai                                                                                                          complexity conditional probability table cpt              gt                     gt                                                        model capture dependencies                                                        tween speakers                                                                                                                                                 ut       state individuals wearing microphones mt                                                                                                                                                                                                   binary random variable indicates ith                                                                                                                                         individual wearing microphone speaking condi                                                                                                                                                            tional probability mt gt set semideterministic                                                                   ≈                ≈                                                    mt     gt                                                                                imposes constraint that—most time—people                                              talk simultaneously during conversation note                                                                                                                                         possible highly unlikely multiple mt                                                        variables true gt held single speaker        figure  dbn model multiperson conversation                                                        state unmiked ut                                                                                                                           similar mt  unmiked node ut binary ran  conversation features useful dom variable indicates wearing  purpose absolute energy ii entropy en microphone speaking multiple unmiked  ergy distribution different microphones described sons present modeled node ut condi  section                          tioned group node gt aggregate voicing node                                                             summarizing complete list acoustic features indicates microphone detected voiced  saved model noninitial maximum speech described condi                                                                                  autocorrelation peak ii total number autocorrelation tional probability utgtat deﬁned identically                                                                                   peaks iii relative spectral entropy iv energy mt gt ut gtat ≈                                                                                                                                                   voicing states vt aggregate voicing                                                                              multiperson conversation model                    voicing states vt binary variables indicate                                                        microphone recorded sound consistent  let assume individuals wearing microphones                                                                                            voiced human speech parents vt mt  given acoustic features microphones want        detect wearers speaking previous vt− each microphone pick speech                                                        wearer speakers nearby condi  microphones picking speech                                                                                                   tional probabilities vt nodes deﬁned vt   area wearing microphones dynamic bayesian network                          dbn dean kanazawa  ﬂexible way com mt ≈  vt mt    bine features uniﬁed model used infer words person speaking highly likely micro  speaking state factorization dbns makes phone record voiced speech speaking  relatively simple express complex dependencies uniform probability microphone record  different variables figure  depicts dbn voiced speech                                                                     model inferring spoken segments identify node aggregate voicing node deter                                                                                    ing speaker segments  example ministic logical vt nodes                                                             shaded nodes observed variables values helps distinguish individuals speaking  inputs hidden nodes vari silent regions  ables values inferred                            oi  eij       each time step dbn corresponds small chunk observations   frame audio data experiments used observed variables obtained acoustic features                                                        microphones included various points dbn  frames length  ms  ms overlap                                                                          children mt  ut vt   previous frame                                          different variables speciﬁed ot threedimensional variable includes three  dependencies                    features previously mentioned having useful                                                        tecting voiced speech noninitial maximum autocorrelation  group state gt                                        peak number autocorrelation peaks relative spectral                                                                                                                               entropy ot  ovt  modeled gaussian  group node determines holding ﬂoor                                                                                         covariance matrix otvt  parameters  taking turn speak discrete random variable                             cardinality  state speaker silent regions learned set labeled data vt given contain  state each people wearing microphones ing speakers present data eval  state speakers wearing microphones uated learning features manner  group state gt depends gt− conditional shown speakerindependent robust different  probability gtgt− encodes probability turn tran environmental conditions choudhury basu                                                             ij  sitions speakers time states equally et twodimensional variable containing log en  likely gn  group node allows  ergies microphones averaged  ms  constrain individual states described reduces window centered time conditional distribution                                                    ijcai                                                                                                                                                             entropy high likely                                                        wearing microphone speaking                                                                                                                                                 aggregate voicing node useful                                                                                                                                 ﬁne utgt  ≈     state                                                        node gt indicates unmiked person speaking                                                                                                                                             utgtat  ≈  gt   loosely                                                        means model infer unmiked speaker   log  energy                                           speaker   microphone picked voiced speech                                            speaker   speech assigned miked speakers                                                                                          −                                                          parameter learning inference          −                                                log energy                   learning entirely unsupervised manner using                                                        expectation maximization em unsupervised learning               figure  pairwise log energies         important application given privacy constraints                                                        associated recording spontaneous speech raw audio                                                        available labeling speakerspeciﬁc data                                                        model able ﬁt unlabeled data                                                       large number parameters em                                                        converge values result accurate infer                                                     ences prevent clamp param       log  entropy                                         eters predeﬁned pretrained values                                                       gaussians associated energybased observations         speaker unmiked speaker speaker speaker       ij                                                                                            −                                                et      ht    learned during em                              mentioned gaussians associated voicing ob                         time seconds                 servations pretrained speakerindependent way                                                        transition probabilities semideterministic condi   figure  log entropy energy distribution microphones tional probabilities ﬁxed predeﬁned values did ex                                                        periment leaving parameters free resulting      ij                                           inferences accurate  et mt  modeled covariance gaus                                                        free parameters learned em exact infer  sian pairwise energy feature associates voiced regions                                                        ence using junction tree algorithm during decod  speaker person speaks time en                                                        ing infer likely state sequence group node  ergy higher j’s vice versa                                                                                            speaker nodes mt ut voicing nodes vt  use  speak microphones high energy                                                        graphical models toolkit gmtk learning  speaks microphones low                                                        inference bilmes zweig   energy figure  illustrates example         ht  entropy logenergy distribution  microphones feature useful determining  experiments results  voiced regions come speaker wearing experimental evaluations performed datasets  microphone person wearing microphone speaks publicly available scripted meeting corpus  microphone signiﬁcantly louder others’ idiap mccowan et al  ii labeled dataset  entropy low person wearing mi natural interactions collected corpus  crophone speaks energy spread uniformly contains  person meetings each ﬁve  microphones entropy high figure  minutes long dataset audio recordings   illustrates example                       microphones—one  microphone array  lapel micro         ht computed follows microphones’ en phones speakers each recording followed script                                             eiτ  ergies normalized distribution peτ      certain meetingwide activities discussion argument                                                ej τ                                                      monologue told say experi                                                    hτ computed entropy peτ finally ht ments used data lapel microphones  average hτ  ms window centered time closely resembles data collection setup overall                      use log ht model gaussian dataset quite clean does background  random variable conditioned ut                    noise evaluated performance model  ran                 ht useful feature distinguishing domly selected meetings corpus  speech comes person wearing microphone dataset collected challenging  does help distinguish signiﬁcant background noise distant speech  unmiked person speaking speak  conversations collected  different locations  ing entropy high cases meeting room elevator hallway loud noisy                                 formation voicing states vt taken atrium speakers told  entropy distinguish situations voicing talk friends trouble ﬁlling                                                    ijcai                                                                                                                 mics   frame err der    prec  recall                                                                                                                                                                                                                                                                                                       table  results corpus meetings  participants                                                             speakers mics   frame err der    prec  recall                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             quiet environments  figure  people wearing portable recording equipment speakers mics frame err der prec recall         sensing unit right shoulders                                                                                                                   time spontaneous conversation recording                           used inexpensive condenser microphone                         multimodal sensing unit dimensions  mm  mm                              mm welbourne et al  sensing unit clipped                       strap small shoulder bag unit sits near     noisy environments  upper right shoulder microphone  ﬁxed location mouth pda           table  results data  bag records audio data figure  shows people wear  ing equipment unlike data lapel mi  crophones tethered recording each  person data carries equipment needed cases fewer microphones speakers averages  recording participants inde results permutations number microphones  pendently interact natural manner      number speakers    evaluate speaker segmentation performance  ﬁrst thing note der scores  learned unclamped parameters model unsu data comparable current speaker diarization results  pervised manner each meeting independently  currently best der achieved features  learning inferred likely state sequence                                                      preserve privacy meeting data nist   group state node gt speaker nodes mt ut fortunately dataset used evaluation generally    compute evaluation metrics compare available compare results directly  ferred value gt ground truth frame er best knowledge published di  ror rate fraction frames value gt arization result corpus ajmera et al   does match ground truth speaker consider technique better frame error rates  lower pre  frames ground truth speaker ii cision recall reported average   diarization error rate der standard metric used average —thus making incon                   nist  nist  measure performance speaker clusive comparison technique used features low  segmentation systems relaxed version frame er order cepstral coefﬁcients contain information  ror rate merges pauses shorter  long ig words spoken does protect privacy  nores  data change speaker relax  ations account perceptual difﬁculties labeling speech error rates signiﬁcantly better dataset  ﬁne time granularity iii precision fraction dataset collected dataset  total number inferred speaker frames correct substantially difﬁcult characteristics data  iv recall fraction truly spoken frames includes signiﬁcantly background noise  speaker inferred words accuracy basic versations ﬂuent fast paced  speechdetection                                    speaker overlap example data’s mean turn dura    results corpus table  results tion  median  dataset mean turn du  dataset tables datasets ration  median  clearly work remains  participants wear microphones test performance handling noisy environments conversations  model unmiked speakers selectively ignored faster variable pacing results  data participants’ microphones results shown quite promising                                                    ijcai                                                    
