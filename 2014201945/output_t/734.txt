                team programming golog partial observability            alessandro farinelli                alberto finzi  ∗              thomas lukasiewicz     †        dis universitadiroma            institut f¨ur informations       dis universitadiroma             “la sapienza”                   systeme tu wien                    “la sapienza”            rome italy                 vienna austria                rome italy                          abstract                          guestrin et al  allow compactly repre                                                        senting decisiontheoretic planning problems explic      paper present agent programming   itly referring atomic states state transitions ii exploit      language teamgolog novel approach     ing compact representations efﬁciently solving large      programming team cooperative agents scale problems iii nice properties modularity      partial observability agent associated parts speciﬁcation easily added removed      partial control program golog com modiﬁed elaboration tolerance solutions easily      pleted teamgolog interpreter opti   reused similar problems extra cost      mal way assuming decisiontheoretic seman     dtgolog designed singleagent      tics approach based key concepts framework model world essentially      synchronization state communication state sists single agent control dtgolog program      allow agents passively resp actively environment summarized “nature”      coordinate behavior keeping applications encounter multiple agents      lief states observations activities invisible cooperate each example robotic rescue      agents show usefulness ap mobile agents used emergency area acquire      proach rescue simulated domain              new detailed information locations injured                                                        people emergency area perform certain rescue    introduction                                       operations general acquiring information                                                        forming rescue operations involves different res  during recent years development controllers cue elements agents andor teams agents  autonomous agents increasingly important ai effectively handle rescue situation  way designing controllers programming cooperative work rescue elements solve  approach control program speciﬁed through lan rescue tasks involve certain level  guage based highlevel actions primitives way risk humans depending type rescue situation  planning approach goals reward functions mobile agents play major role rescue situations es  speciﬁed agent given planning ability achieve pecially teams cooperative heterogeneous mobile agents  goal maximize reward function integration crucial aspect realworld environments  approaches recently proposed through seminal typically partially observable noisy                                      language dtgolog boutilier et al   integrates inaccurate sensors relevant parts en                                                explicit agent programming golog reiter  vironment simply sensed example especially                                                  decisiontheoretic planning fully observable mdps robotic rescue domain described agent              erman   allows partially specifying control pro generally partial view environment  gram highlevel language optimally ﬁlling  missing details through decisiontheoretic planning practical importance controlling coop  seen decisiontheoretic extension golog erative agents partial observability generalization  choices left agent maximizing ex dtgolog recognized recent works  pected utility different perspective ferrein et al  finzi lukasiewicz   seen formalism gives advice decisiontheoretic drawback works  planner naturally constrains search space implicitly centralized assumption global world                                                        model resp assumption agent knows belief    dtgolog nice features closely  related ﬁrstorder extensions decisiontheoretic plan states observations actions agents                                                                                                   ning especially boutilier et al  yoon et al  ferrein et al  finzi lukasiewicz                                                         explicit communication agents    ∗alternate address dis universita di roma “la sapienza” possible desirable realistic applications    †alternate address institut f¨ur informationssysteme tu wien paper present agent programming language                                                    ijcai                                                    teamgolog novel generalization dtgolog •dssa  set successor state axioms reiter   controlling cooperative agents partial each ﬂuent x contains axiom x doa  observability does centralization ≡ Φf x swhereΦf x formula free  sumptions guided idea truly distributed variables x aands axioms specify truth  acting multiagent systems minimal interaction ﬂuent situation doa terms  tween agents main contributions follows current situation solution frame problem                                                        deterministic actions example  • introduce agent programming language team  golog  controlling cooperative middlesize ato doa ≡  movetoo ∨  agents partial observability deﬁne decisionthe ato ∧¬∃xy  movetoo xy  oretic semantics teamgolog inspired                                                        express object doa iff  centralized partially observable mdps decpomdps nair                                             et al  goldman zilberstein          moved  moved away                                                         •dap   set action precondition axioms each  • introduce concepts synchronization state                                                        action contains axiom possaxs ≡ Πx  communication state used coordinate agents                                                        characterizes preconditions example  taking inspiration artiﬁcial social systems shoham                                                                                    possmovet oo ys ≡¬∃o ato xys ex  tennenholtz  behavior each agent encoded                                                        press possible object iff  advance domain theory program depends                                                                 object  online trace synchronization communication states  • deﬁne interpreter teamgolog provide  golog agent programming language based  number theoretical results particular show situation calculus allows constructing complex ac  interpreter generates optimal policies      tions primitive actions deﬁned basic action                                                        ory  standard standard algollike  • ﬁrst prototype implementation team                                                        structs used particular action sequences  golog  interpreter provide experimental results                                                        ii tests φ iii nondeterministic action choices pp  rescue simulation domain evidence iv nondeterministic choices action argument πx px  usefulness approach realistic applications conditionals whileloops procedures    notice detailed proofs results extended  abstract provided version paper  team golog partial observability                                                        introduce agent programming language team    situation calculus golog                   golog generalization golog programming  situation calculus mccarthy hayes  reiter teams cooperative agent partial observability   ﬁrstorder language representing dynamic approach based key concepts synchro  mains main ingredients actions situationsandﬂu nization state communication state allow  entsanaction ﬁrstorder term form auwhere agents passively resp actively coordinate behavior  action u arguments example keeping belief states observations activities  movetor represent action moving agent invisible agents synchronization state  position yasituation ﬁrstorder term en fully observable agents outside  coding sequence actions constant symbol trol communication state multidimensional state  form doa swherea action situation containing dimension each agent fully  constant symbol initial situation represents observable agents agent change  sequence doa encodes sequence ob communication state necessary  tained executing sequence sforexam encodes explicit communication agents  ple domovetor  domovetor  stands synchronization state commu  executing movetor   executing movetor   nication state fully observable agents  saﬂuent   represents world agent property used condition coordinate behavior  change executing action predicate sym agents time each agent belief state  bol right argument situation example observations actions invisible agents  atr express agent position realize maximally distributed acting agents  situation situation calculus dynamic teamgolog program each agent encodes agent’s                                                                               domain encoded basic action theory Σ ds  havior conditioned  current situa  dssa duna dapwhere                               tion teamgolog programs bear close similarity                                                        social laws artiﬁcial social systems shoham tennen  • Σ set foundational axioms situations                                                        holtz  basic idea systems formu  •duna  set unique axioms actionssaying late mechanism called social law minimizes need  different action terms stand different actions centralized control online resolution conﬂicts    •ds  set ﬁrstorder formulas describing initial realworld situations encounter  state domain represented atr  form coordination trafﬁc law “right  express agent initially position   precedence left” regulates order cars                                                    ijcai                                                                                                                    pass street cross cases law sufﬁcient qi siairic siai  make cars pass street cross inter qnc                                                                   i    i     action car drivers exceptional cases                                                                                                            picisioic siai ·  each street car approaching                                                                         ∈c ∈s ∈si oi∈oi                                                                               n−      cross car technical defect additional       pc c−is · ssi                                                                                 communication car drivers necessary sim                                                                                   vi si min qi siai   ilarly soccer team ﬁx advance behavior              ai∈ai  team members certain game situations defense  attack minimizing explicit communication        figure  qandv functions  members during game observed                                                                                                    ≥  adversary examples synchronization domain theory dt st ot consists                                                                                 ∈  state encodes situation street cross resp game agents    each agent  basic action  situation communication state encodes explicit theory iastochastic theory st iandanoptimization  communication correct behavior car drivers resp ory ot deﬁned                                                                                                   soccer players encoded trafﬁc laws resp strategy ﬁnite nonempty set primitive actions parti                                                                                                ﬁxed team training units game tioned nonempty sets primitive actions                                                                   rest section ﬁrst deﬁne variant dec agents   respectively assume ﬁnite nonempty                                                                         pomdps underlies decisiontheoretic semantics set observations  partitioned nonempty sets                                                                                 teamgolog   programs deﬁne domain observations     agents      respectively                                                                                         ∈  ory syntax teamgolog programs                stochastic theory st agent set ax                                                        ioms deﬁne stochastic actions agent iwerepresent    weakly correlated decpomdps                     stochastic actions through ﬁnite set deterministic actions  consider following variant decpomdps ≥  usual finzi pirri  boutilier et al  agents essentially consist transition function stochastic action executed certain proba  tween global states global state consists bility “nature” executes exactly deterministic ac  communication state each agent synchroniza tions produces exactly possible observation  tion state pomdp each agent each global derlying decisiontheoretic semantics assume weakly  state agent send message oth correlated decpomdps section                                                                                                     ers changing communication state weakly cor lational ﬂuents associate situation acom                                                                              ∈                     related decpomdp  iscii∈i psii∈i  aii∈i  munication state agent  synchronization state                                                                                 oii∈i  pii∈i  rii∈i  consists set ≥  agents local state agent  respectively communi   nonempty ﬁnite set synchronization cation synchronization properties visible  states nonempty ﬁnite set communication states ci agents private hidden use pred                                                                      μ  agent ∈ transition function  × → icate stochastic     encode executing                                                                                       pdc  × associates global state stochastic action situation  “nature” chooses                                                                                                 sisting joint communication state ∈  ×i∈i ci deterministic action producing observation                                                                  μ                               synchronization state ∈ probability distribution probability  stochastic action situa                                                                       μ                 μ  × agent ∈ nonempty ﬁnite set tion thesetofall  stochastic   local states si nonempty ﬁnite set actions ai ii non probability function set deterministic com                                                                                   ﬁnite set observations oi iii transition function ponents observations  use                                                                                      μ  pi × × si × ai → pdci × si × oi associates tation prob   denote probability                                                                  μ             global state ∈ local state si ∈ siand stochastic  assume nature                                                                                                         action ai ∈ ai probability distribution ci × si × oi choices preconditions stochastic action  iv reward function ri × × si × ai → rwhich indirectly represented providing successor state ax                                                                                          associates global state ∈ × local state iom associated nature choice  stochastic ac                                                                                                   si ∈ si action ai ∈ ai reward ric siai agent tion executable situation observation                                                                                      qandvfunctions agent ∈ ﬁnitehorizon noted poss iffprob                                                                                             ∈  value iteration deﬁned fig  ≥  optimization theory ot agent speciﬁes reward                                                                                       pc ·c                   ·c          utility function agent  associates        conditioning   iand                                                     situation action reward agent ∈ denoted   denotes  optimal action agent   −i                                                 reward utility function maps reward  global state local state si                                                      success probability realvalued utility utilityv prwe  stepstogoisgivenbyargmina   ∈a siai notice                                                  assume utilityv   utilityv    van  standard deﬁnitions qandvfunctions                                                        example utilityv prv · pr utility function suit  adapted framework local global states                                                        ably mediates agent reward failure    domain theory                                    actions unsatisﬁed preconditions  teamgolog   programs interpreted relative domain example  rescue domain consider rescue domain  theory extends basic action theory stochastic autonomous mobile agents localize  actions reward functions utility functions formally victims environment report positions                                                    ijcai                                                    remote operator assume team three heteroge set pairs μ consisting ordinary situation  neous agents aanda endowed shape recognition real μ ∈   μ sum  ii situa  sh infrared sensors respectively vic tions associated joint communication  tim position communicated operator sensed state synchronization state informally  analyzed three sensing devices each agent represents local belief agent ∈ expressed proba  ai execute actions gotoipos  analyze ipos  bility distribution local states unique joint  typeiandreporttoop ipos  action theory communication synchronization states probability  scribedbytheﬂuentsat ipos analyzed ipos  typeis ﬂuent formula φs uniform belief state  reported ix accessible agent ai denoted φbisthesumofallμ φs true  successor state axiom ipos   μ ∈ particular possa bwherea action                                                        deﬁned sum μ possa true      ipos doa ≡  gotoipos  ∨ ipos ∧                                                      μ ∈ bandreward deﬁned similar way                       ¬∃pos  gotoipos                                                           given deterministic action belief state agent  precondition axiom action analyze given ∈ ithesuccessor belief state executing bde                          ≡                                                     possanalyze ipos typei  ipos asforthe    noted doa belief state  doa sμpossa  global state communication state deﬁned ﬂuent  μ ∈ possa furthermore given stochas                csidata  agent data shared info tic action observation belief state                                     csatvictim   means  detected agent ∈ ithesuccessor belief state executing                                                                                                           victim position   through sensor global observing denoted doaob belief state                                                                                               data repvictim   victim reported position obtained pairs don sμ· μ                                                                                novictim  position inspected vic μ ∈ possa sandμ  proba                                                    tim synchronization states start  reset   malizing probabilities sum   standing starting resp resetting rescue session probability making observation executing  st deﬁne stochastic versions actions                                  ∈                                                       stochastic action local belief state agent   gotos ipos  analyzes ipos typei each denoted proba oisdeﬁnedasthesumofallμ · μ  fail resulting action          μ ∈ μ  proba         probgotos ipos sgotoipos  obssucc         probgotos ipos snop obsfail        example  rescue domain cont’d suppose agent                                                        aware initial situation initial  ot provide high reward fully analyzed victim                                                        lief state  executing stochastic action  correctly reported operator low reward analy                                                        gotos   observing success obssucc  sis detected victim distancedependent cost                                                        lief state changes  dogoto   sociated action goto agents obstacle                                                                                                  probgotos pos sgotopos   each operating location penalize                                                        obssucc  andgotos pos  executable  agents analyzing victim time  precisely employ following reward                                                          syntax   reward sr def ∃p  analyzeip ∧    detvictimp ∧ ¬conﬂicts ia ∧ ∨      given actions speciﬁed domain theory dt iapro            ∧   ∨¬    ∧  −  ∨    conﬂicts             detvictim                    gram teamgolog   agent ∈ fol     reporttoop ip ∧ fullyanalyzedp ∧   ∨                 φ                                                                 lowing forms condition   programs     goto ∧∃p ip ∧  − distp                                                       aan actions agent  conﬂicts true agent communicates                                                           deterministic stochastic action adoa  analysis location global state detvic  timp true agent discovered vic  nondeterministic action choice choicei a···an  tim csiatvictimp ts tand optimal action aan                fullyanalyzed   means analysis   test action φtestφ current situation  performed csatvictimp sh ∧ csatvictimp  ifs ∧ csatvictimp notice action  action sequence pdop followed        cost depending distance start  gotoi                                                  nondeterministic choice programs   ing point destination greedy policy agent                                                             closest nonanalyzed victim ana  lyze given penalty conﬂicts agents  nondeterministic choice argument πx px  encouraged distribute analysis different victims px  taking account decisions agents   nondeterministic iteration pdop zero times      belief states                                       conditional φ  introduce belief states situations single  whileloop φ  agents deﬁne semantics actions terms transi  tions belief states belief state agent ∈  procedures including recursion                                                    ijcai                                                    example  rescue domain cont’d following code • stochastic ﬁrst program action  represents incomplete procedure explorei agent                                                                         ga p bhπv prdef                                                                                     proc explore                                         ∃     gaoq  bhaoq  πq  vq pr  ∧            πx                                                                                      gotos                                             π               π ∧                                                              oq                obs succ analyzes type                        ·     ∧              obssucc ∧ fullyanalyzedx                      q prob                                                                               ·                    reporttoop irepvictim                      pr     pr prob            explore                                                         ool possible observations sto             agent ﬁrst decide posi chastic action generated policy conditional plan                     tion reached agent analyzes current location deploy observation oq considered  ing sensing devices victim detected                                                        •                                      position victim communicated operator nondeterministic ﬁrst program action                                                                                                                                                  gchoice a···anp bhπv prdef                                                                ∃   ga  pbha  π  v   ∧     teamgolog      interpreter                                                 prq                                                                                         ∧  section ﬁrst specify decisiontheoretic seman      argmax q∈n utility prq                                                                   π  π ∧  ∧         tics teamgolog programs terms interpreter                   pr  pr  provide theoretical results interpreter                                                          theoretical results    formal speciﬁcation                              following result shows teamgolog interpreter  deﬁne formal semantics teamgolog pro generates optimal hstep policy π  gram agent ∈ relative domain theory dtwe expected utility agent ∈ given teamgolog  associate teamgolog program belief state program belief state horizon ≥   horizon ≥  optimal hstep policy π                                                        theorem  let teamgolog   program agent  expected utility agent ∈ intuitively hstep pol                                                        ∈ wrt domain theory dt iletb belief state  icy π obtained hhorizon replacing                                                        let ≥  horizon optimal hstep policy π  nondeterministic action choice optimal action                                                        expected utility agent ∈ given    formally given teamgolog program agent ∈                                                        dt  gp π  pr   utilityv pr  relative domain theory dt horizon ≥ andastart  belief state agent say π hstep pol result gives upper bound number  icy expected hstep utility agent iff leaves evaluation tree polynomial  dt  gp π  pr   utilityv prwhere horizon bounded constant maximum  macro gp π  pr  deﬁned induction maximum number actions nondeterministic  different constructs teamgolog deﬁnition action choices maximum number observations  constructs given follows complete deﬁ actions maximum number arguments nondetermin  nition given version paper   istic choices argument number pairs consist  • null program  nil zero horizon       ing synchronization state communication state                                                                             gp π v prdef π  stop ∧v pr     theorem  let teamgolog program agent                                                        ∈ wrt domain theory dt iletb belief state  intuitively ends null horizon end let ≥  horizon computing hstep policy π  • stochastic ﬁrst program action observation expected utility agent ∈                                                                 nh                                                       generates      leaves evaluation tree     gao  bhπvprdef possaob∧       π stop ∧v pr    ∨ possaob   ∧       ∃   gp  bh−π  v   ∧              rescue scenario                         prq          π  ao  oq πq ∧      consider rescue scenario fig  assume three                            l                aob    vq ·   aoboq  ∧    victims detected environment             reward            prob                 ·     ·    bo       completely analyzed position   presence          pr  poss       pr prob                                                         alice detected through sh sensor position  ∃f  obtained existentially quantifying   agent discovered bob through analyzed  free variables  ool different through sensor ﬁnally position   victim  pairs joint communication state synchronization carol detected assume infor  state compatible aoandprobaoboq mation available global state properties  probability arriving oq executing ao bin csatvictim  sh csatvictim  ifs                           formally suppose ao  whereao stochastic action csatvictim  sandcsatvictim   observation ao executable bthenp ifs hold communication state agents  policy π  stop expected reward local state assume belief states    success probability pr  optimal exe   andb                    cution ao   depends doaob   sandat                                                     ijcai                                                    
