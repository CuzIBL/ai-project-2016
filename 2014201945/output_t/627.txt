   probabilistic learning method xml annotation documents                       boris chidlovskii                           j´erˆome fuselier               xerox research centre europe         universit´edesavoielaboratoiresyscom                   chemin maupertuis                        domaine universitaire                     meylan france                    le bourgetdulac france                          abstract                          xml documents like conversion through set lo                                                        cal transformations  entail transformation      consider problem semantic annota       particular tasks semantic annotation dy      tion semistructured documents according    namically generated web pages news portals       target xml schema task annotate      extraction logical structure page images       document treelike manner      notation tree instance tree class    paper consider general case tree      ﬁned dtd wc xml schema descrip            notation semistructured documents make        tions probabilistic setting cope assumptions structure source tar      tree annotation problem generalized      documents possible similarity repre                                                        sent document content sequence observations      probabilistic contextfree parsing obser                       vation sequence each observation comes         xxn  each observation xi      probability distribution terminals    tent fragment case html documents      supplied probabilistic classiﬁer associated  fragment multiple leaves sur      content documents determine       rounded rich contextual information form      probable tree annotation maximiz     html tags attributes tree annotation se      ing joint probability selecting terminal quence given pair yd refer                                                        leaves internal nodes tree respectively      sequence observation sequence                                 probable parse selected terminal     sequence   yyn  seen side      sequence                                         labels observations side                                                        terminal sequence tree deﬁnes internal tree                                                        structure according target xml schema     introduction                                        supervised learning document annotation sys  future world wide web associated  tem  includes selecting tree annotation model  semantic web initiative tar  training model parameters training set  widespread document reuse repurposing ex given triples yd adopt probabilistic set  change achieved means making document markup   ting estimate probability anno  annotation machinereadable success  tation tree yd given observation sequence  semantic web initiative depends large extent address problem ﬁnding pair yd maximal  capacity renderingoriented markup likelihood  documents like pdf html   semanticoriented     develop modular architecture tree  document markup like xml rdf                    notation documents includes major compo    paper address problem semantic nents ﬁrst component probabilistic contextfree  notation html documents according target xml  grammar pcfg probabilistic extension  schema treelike annotation document requires corresponding deterministic xml schema deﬁni  annotation tree instance target tion pcfg rules obtained rewriting  schema described dtd wc xml schema     schema’s element declarations case dtd  schema language annotation trees naturally gen element type deﬁnitions case wc  eralize ﬂat annotations conventionally used informa xml schema rule probabilities chosen  tion extraction wrapper induction web sites  observing rule occurrences training set similar    migration documents renderingoriented  learning rule probabilities treebank corpora  formats like pdf html xml recently   nlp tasks pcfgs oﬀer eﬃcient insideoutside al  important issue various research commu  gorithm ﬁnding probable parse given  nities     majority approaches sequence terminals complexity algo  make certain assumptions source target  rithm ·n length sequence yand number nonterminals pcfg    forms set unranked labeled rooted trees    second component probabilistic classiﬁer constrained schema  predicting terminals observations xi  case html documents use maximum        tree annotation problem  entropy framework  proved eﬃciency annotating html documents accordingly  combining content layout structural features ex target xml schema main diﬃculty arises  tracted html documents making probabilistic  fact source documents essentially layout  predictions pyforxi                                oriented use tags attributes nec    terminal predictions supplied  essarily consistent elements target schema  tent classiﬁer tree annotation problem represents irregular use tags documents combined  generalized case probabilistic parsingwhereeach complex relationships elements target  position sequence deﬁned speciﬁc schema makes manual writing htmltoxml  terminal terminal probability py conse transformation rules diﬃcult cumbersome  quently consider sequential joint evaluations supervised learning content source docu  maximum likelihood tree annotation observa ments presented sequence observations   tion sequences joint case develop general xxn observation xi refers  ized version insideoutside algorithm deter tent fragment surrounded rich contextual informa  mines probable annotation tree yd according tion form html tags attributes tree  pcfg distributions py positions annotation model deﬁned mapping → yd  show complexity generalized maps observation sequence intoapairyd                                insideoutside algorithm ·nn·t ·n yyyn terminal sequence  length yandwheren  parse tree according target schema equiv  number nonterminals terminals pcfg    alent pcfg  s⇒y training set  training    show  proposed extension    model parameters given set triples yd  insideoutside algorithm imposes conditional inde  determine probable tree annotation yd  pendence requirement similar naive bayes  sequence maximize joint probability  sumption estimating terminal probabilities test pydxg given sequence pcfg gus  method collections report important ing bayes theorem independence  advantage joint evaluation sequential gwehave                                                                                       ·        xml annotation schema                                    pydxgpd   yg   py                                                               pyx probability terminal sequence                                                        observed sequence xandpdyg proba    xml annotations documents trees inner  bility parse according pcfg gthe  nodes determine tree structure leaf nodes probable tree annotation pair ydthat  tag attributes refer document content xml maximizes probability   annotations abstracted class unranked  labeled rooted trees deﬁned alphabet Σ tag         ydmax  argmax  pdyg · pyx     names  set trees Σ constrained                      yd  schema  deﬁned using dtd wc xml                                                          following build probabilistic model  schema schema languages                                                        tree annotation source documents consisting    dtds important wc xml schema        components probability estimates   descriptions modeled extended contextfree  ﬁrst component probabilistic extension                grammars    regular expressions alpha  target xml schema given terminal sequence  bet Σ constructed using basic opera                                                          ·                                ﬁnds probable parse pd yg sequences  tions concatenation disjunction andwithoccur  according pcfg  rule probabilities  rence operators ∗ kleene closure  aaand         · ∗                                            trained available training set second com  aa    extended context free grammar ecfg  ponent probabilistic content classiﬁer citestimates  deﬁned tuple tnsr                                                        conditional probabilities pyxi annotating ob  disjoint sets terminals nonterminals Σ                           ∈        ∪                                             servations xi terminals  finally given  Σt       initial nonterminal ﬁnite sequence observations develop methods  set production rules form → α ∈                                           ∪            ﬁnding tree annotation yd maximizes joint  α regular expression Σ  nthe      probability pydxgin  language lgdeﬁnedbyanecfgg        set ter  minal strings derivable starting symbol  formally lgw    ∈ Σ∗s  ⇒ wwhere⇒          probabilistic contextfree grammars  notes transitive closure derivability relation pcfgs probabilistic extensions cfgs each  represent parse tree sequential form rule → α associated real number  reﬂects derivational steps set parse trees halfopen interval   values obey therestriction given nonterminal ∈ rules tree annotation model processes sequences ob  values sum                servations   xxn inﬁnite set                                                       observations xi words language              ∀a ∈            pr             terminals  complex instances                      ra→αr∈r                         like html leaves groups leaves                                                          content fragments frequently targeted vari    pcfgs normal form called chomsky                                                        ous probabilistic classiﬁers produce probability es  malformcnfaccordingtowhichanyruleinr                                                                 timates labeling observation terminal  → bcor    ∈ bwherea   non                                                                                    pyxi ∈  pyxi thetreean  terminals terminal rewriting xml                              annotations requires binarization source ranked notation problem seen generalized  trees followed extension nonterminal version probabilistic contextfree parsingwherethe  set underlying set rules conse input sequence given probability distribution  quence rewriting nodes multiple children terminal set probable annotation  sequence binary nodes binarization rewrites tree requires maximizing joint probability   rule → bcdas rules    →  bp  →  cd       similar generalization probabilistic parsing takes  new nonterminal                        place speech recognition presence noisy    pcfg deﬁnes joint probability distribution channel speech streams parsing sequence  random  variables possible sequences words replaced parsing word lattice  terminals possible parses respectively compact representation set sequence hypothe  clearly independent complete parse ses given conditional probabilities obtained spe  speciﬁes exactly terminal sequences cial acoustic models acoustic observations   ﬁne function pyd given terminal sequence  ∈ parse ∈ product values   content classiﬁer  rewriting rules rydusedins⇒ywe     produce terminal estimates observations xi  consider case does actually corre adopt maximum entropy framework according  spond                                           best model estimating probability distribu                                                      tions data consistent certain                         pr  parse     pyd      r∈ryd                              constraints derived training set                                           makes fewest possible assumptions  distri                                                        bution fewest possible assumptions    values closed interval                                                          highest entropy closest uniform distri  cases parse yallpr values                                                        bution each constraint expresses characteristic  product lie half open interval                                                          training set present  product case                                                          learned distribution constraint based binary  case pyd                                       dy              feature constrains expected value feature    pcfg   training takes evidence corpus model equal expected value  terminal sequences corresponding parses training set  training set associates each rule ex important advantage maximum entropy models  pected probability using rule producing cor ﬂexibility allow extension rule  pus presence parses terminal sequences additional syntactic semantic prag  each rule probability set expected count matic features each feature binary depend  malized pcfg constraints  satisﬁed ∈ properties input sequence                          counta →  α                 case tree annotation include content          pa →  α                                  features express properties content fragments                               counta → β                        a→β∈r                           like fx y“ify title x’s length     generalized probabilistic parsing                characters  otherwise” structural                                                        layout features capture html context  pcfgs used probabilistic models natural lan observation like fx y“ author x’s  guages naturally reﬂect “deep structure” father spanotherwise”  language sentences linear sequences  constraints based selected features  words pcfg   language model ﬁnite set  fx maximum entropy method attempts max  words serve terminal set production rules imize conditional likelihood pyx repre  nonterminals express set grammatical sented exponential model  structions language basic algorithms pcfgs                                          ﬁnd likely parse given sequence                        choose rule probabilities maximize probability      pyx        exp     λα · fαx                                                                            zαx  sentence training set represent  eﬃcient ex                          α  tensions viterbi baumwelsh algorithms zαx normalizing factor ensure  hidden markov models                                 probabilities sum                                                          book → au section      book → au se                                                               →                           →                                                         se  section section    se  section se                                                           section → ti els       section → ti el           zαx      exp     λαfαx              els → el el            els → el els                           α                             au → author            ti → title                                                           el → para              el → footnote    iterative parameter estimation max  imum  entropy exponential models use     assume test content classiﬁer  quasi newton methods limited memory       pcfg   sequence ﬁve unlabeled observations  bfgs method observed eﬀective     xx let classiﬁer estimate prob  generalized iterative scaling gis im  ability terminals given following table  proved iterative scaling iis nlp tasks                                                                                           author                                                                                 title                        sequential tree annotation                              para                                                                                   footnote                   use pairs triples yd training  set train content classiﬁer pairs yd  according probability distribution  choose rule probabilities maximize likelihood probable terminal sequence ymax composed  instances training set predicts ter probable terminals xi                                                              ’title title para footnote title’  minal probabilities pyx observation                                  prob                                                                                           ·    max  insideoutside algorithm ﬁnd parse ability pymaxpymax  xΠi       pyi   xi                                                           ·    ·    ·   ·  highest probability given terminal sequence            ymax     analogy speech recognition exists  corresponding parse tree instead exist  naive sequential method combine compo    valid annotation trees xydandyd                                                        shown figure    figure terminal  nents computing tree annotation se              ‘author title para title para’  quence xfirstfromc’s estimates  pyx deter   sequence                                                                                          parse dbookau sesection ti el section ti  probable sequences ymaxj                                          second ﬁnd probable parses   el maximizes joint probability pydxg                                                        py  ·  ·  ·  ·   ymaxj dmaxj  argmax pdymaxjg ﬁ                                                      pdpbook  → au se  · pau →  author ×  nally choose pair ymaxjdmaxjthatmaximizes      pse  → section section · psection → ti el ×                      ×                                                                      product pymaxj pdmaxj                            pti →  title  · pel → para  ×    sequential method works noise level       psection → ti el  low speech recognition content classiﬁer  ·  ·  ·  ·  ·  ·   tree annotation accurate predicting                                 −                                                        jointly py×pd ≈ ·  similarly  terminals xi unfortunately gives poor results                                                        annotation tree figure py×pd  classiﬁer far  accuracy pre    ·          ≈     ·  −  dictions faces impossibility ﬁnding parse       probable sequences ymaxj                                                                book                  book                                                                    section                                                                                                 se  example    consider example target schema given                   els  following dtd                                                                            els             section section                                                                                     element     book     author section                 element     section  title para  footnote      au  ti  el   el   el      auti    el  ti  el                                           element     author   pcdata                      author title para footnote para author title para title para    element     title    pcdata                                                                                          element     para     pcdata                                       element     footnote pcdata                                                         figure  tree annotations example sequence    reduction  schema deﬁnition    chomsky normal form    introduce extra non  terminals pcfg     tnsr  terminal set author title para  footnote nonterminal set book author      probable annotation tree  se section ti els el sbookandr     includes   sequential method fails ﬁnd probable  production rules                              annotation tree try couple selection termi    assume trained content classiﬁer nal sequence ﬁnding probable parse  pcfg  obtained following prob yd maximizes probability prod  abilities production rules              uct pdyg· pyx  goal extend thebasic insideoutside algorithm terminal pcfgs    experimental results  redeﬁne inside probability probable  joint probability subsequence beginning tested method xml annotation  index ending index proba  collections collection  shakespearean                                                                                                      ble partial parse tree spanning subsequence yi plays available html xml format      rooted nonterminal                              scenes   leaves randomly selected                                                        evaluation dtd fragment scenes consists                                                     terminals  nonterminals binarization        βai jmaxayj  paij ⇒ yi  · pyi                                                       pcfg cnf contains  nonterminals  rules                                                          second collection called techdoc includes     inside probability calculated recursively tak                                     ing maximum possible ways nonter technical documents repair manuals tar  minal expanded parse                 documents ﬁnegrained semantic granularity                                                        deeper shakespeare collection                                                        longest document  leaves target schema                                              βai  maxi≤q≤j  pa →  bc · pb ⇒ yi  ×       given complex dtd   terminals                                                     nonterminals binarization increased number                     pc ⇒     · py                                                  nonterminals  collections content    proceed make  independence   observation refers pcdata leaf html  sumption pyx meaning ≤ ≤  evaluate annotation accuracy use met                              pyi xpyi · pyqx rics terminal error ratio ter similar  rewrite follows                          word error ratio used natural language tasks mea                                                        sures percentage correctly determined terminals                                                      test documents second metric nonterminal  βai jmaxi≤q≤j   pa →  bc · pb ⇒ yi  ×      error ratio ner percentage correctly                                                  annotated subtrees                    pc ⇒ yq · pyi · pyqx                                                          content classiﬁers test maximum en            maxi≤q≤j pa → bc  · βbi · βc                                                        tropy classiﬁer model extract     recursion terminated βs nwhichgives content features each observation number  probability likely tree annotation yd words fragment length pos tags textual                                                        separators second extract  layout struc                                              βs nmax ps⇒y      · py         tural features include surrounding tags associated                                                        attributes models use maximum  length sequences      entropy markov models memm extends    initialization step requires extra work hidden markov structure terminal conditional  select terminals candidates yk features  automaton structure used memm                                                        state terminal          βak kmaxy   pa →  yk · pykx                                                          tests crossvalidation folds used    shown redeﬁned inside function memm   ﬁrst tested col  verges local maximum yd space extra lections corresponding ter values  work during initialization step takes ·t ·n probable terminal sequences ymax serve reference  time brings total complexity extended methods coupling classiﬁers pcfg  io algorithm ·n  ·t ·n             coupling classiﬁer pcfg test    independence assumption established rep  sequential joint methods additionally  resents terminal conditional independence pyx cluded special case memmpcfg content  n    pyix matches naive bayes assumption classiﬁer memm  terminal condi  assumption frequent text processing sim tional independence respected  pliﬁes computation ignoring correlations results tests collected table   tween terminals require   joint method shows important advantage  ment content classiﬁer pcfgs   sequential method particular techdoc case  sumed capture short long distance  content classiﬁer achieves   lations terminals extended inside algo  accuracy joint method reduces errors ter  rithm  imposes terminal conditional inde minals  instead coupling memm     pendence building probabilistic model  pcfg reports decrease ter values  impacts feature selection maximum entropy important ner increase  model disallowing features include terminals  neighbor observations yi− yietcasinthemaxi  mum entropy extension hmm  crf models        httpmetalabuncedubosakxmlegshakszip                                                        available authors request
