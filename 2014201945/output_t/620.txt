                            optimized execution action chains                  using learned performance models abstract actions∗                                        freek stulp michael beetz                 intelligent autonomous systems group technische universitat¨    munchen¨                              boltzmannstrasse  munich germany                                     stulpbeetzintumde                        abstract                          fewer actions viewed abstract level actions                                                        applicable broader range situations mod      planbased autonomous robot controllers      els concise eases      generate chains abstract actions order   job programmers computational task      achieve complex dynamically changing pos   automatic planning systems abstract levels      sibly interacting goals execution   search space plans substantially smaller fewer      action chains results robot behavior interactions actions need considered      shows abrupt transitions subsequent ac     advantages abstraction come cost      tions causing suboptimal performance result planning considers actions black boxes      ing motion patterns characteristic robots performance independent prior subsequent      people imitating robotic behavior steps planning tailor actions      making abrupt movements actions          contexts execution yields suboptimal      paper propose novel computation      havior abrupt transitions actions resulting      model execution abstract action chains motion patterns characteristic robots people      computation model robot ﬁrst learns     trying imitate robotic behavior making abrupt      situationspeciﬁc performance models abstract  movements actions contrast impres      actions uses models automatically sive capabilities animals humans capability      specialize abstract actions execution perform chains actions optimal ways seamless      given action chain specialization results transitions subsequent actions      reﬁned chains optimized performance   let illustrate points using simple scenario au      side effect behavior optimization ap tonomous robot soccer depicted figure  start      pears produce action chains seamless tran ing situation shown left subﬁgure planner      sitions actions                          sues three step plan  ball  dribble ball                                                        shooting position  shoot robot naively executed                                                        ﬁrst action depicted center subﬁgure ar    introduction                                       rive ball goal unfortunate  recent years number autonomous robots including position start dribbling goal  witas  doherty et al  minerva thrun et al  problem abstract view planner  chip firby et al  shown impressive ball considered sufﬁcient dribbling ball  formance long term demonstrations robots dynamical state robot arriving ball considered  common generate maintain execute chains irrelevant dribbling action  discrete actions achieve goals use plans en    ables robots ﬂexibly interleave complex interact                              plan                                                            goal score      plan  ing tasks exploit opportunities optimize intended               − ball     − ballin order                                                                              − dribble ball   − dribble ball  course action                                                           − shoot          − shoot    allow planbased control plan generation mech  anisms equipped libraries actions causal mod  els actions models include speciﬁcations  action effects conditions actions  executable good reasons action models spec                       iﬁed abstractly disregard aspects situations  during execution abstractness figure  alternative execution plan  big advantages programmers need supply      ∗the work described paper partially funded like robot instead  deutsche forschungsgemeinschaft spp      ball order dribble goal therobot depicted figure perform ﬁrst strips operators sense temporally ex  action suboptimally order achieve better posi tended actions treated planner  tion executing second plan step behavior shown atomic actions  figure exhibits seamless transitions plan steps  higher performance achieving ultimate goal       state−space        state−space  time                                                        pre−cond  action    paper propose novel computational model                             post−cond  plan execution enables planner abstract  action models optimizes action chains execution  time basic idea approach learn perfor gotoposetop   precondition  mance models abstract actions offline observed ex executed state state space post  perience performance models rules predict condition xt ≈ xdyt ≈ yd φt ≈ φd action  situation parameterizationspeciﬁc performance gotoposeaction  abstract actions expected duration execu libraries contain set tops frequently  tion time determines set parameters used given domain domains small  set plan deﬁne possible ac number control routines sufﬁces execute tasks  tion executions determines each abstract action kept general abstract allowing ap  parameterization predicted performance plicable situations library contains tops  action chain optimal                          gotoposetop   dribbleballtop    technical contributions paper threefold chain given goal chain tops  propose novel computational model execu precondition ﬁrst satisﬁed current  tion time optimization action chains presented section  situation postcondition each step satisﬁes pre  second show situationspeciﬁc performance models condition subsequent postcondition  abstract actions learned automatically section  satisfy goal represents valid plan  mechanism subgoal postcondition achieve goal  reﬁnement action chain optimization apply im  plemented computational model chains navigation plans pre−cond          pre−cond                                                                        action  post−cond action  different objectives constraints different task current state                                                                                                        goal  contexts section  show typical action chains                                  post−cond  robot soccer computational model achieves substantial      state−space  statistically signiﬁcant performance improvements  action chains generated robot planners section   performance models actions map speciﬁc situation                                                        performance measure paper performance    overview                                    measure time alternatives chance success                                                        accuracy models used predict perfor  section introduces basic concepts mance outcome action applied speciﬁc situation  base computational model action chain optimization specifying current state satisfying preconditions  using concepts deﬁne computational task end state satisfying postconditions  sketch key ideas solution                                                          gotoposeactionperformancextytφtxdydφd →    conceptualization                                  computational task solution idea  conceptualization computational problem based online computational task optimize overall  notion actions performance models actions formance chain input consists chain  teleooperators teleooperator libraries chains teleo generated planner uses library  operators section introduce concepts resource output intermediate reﬁned subgoal    actions control programs produce streams optimizes chain inserted chain exe  trol signals based current estimated state cuting chain simply calling action  ﬂuencing state world actions used each ﬂow displayed figure   gotopose navigates robot cur optimize action chains pre postconditions  rent pose time xtytφt future destination pose tops chains analyzed determine  xdydφd setting translational rotational velocity variables subgoal freely tuned  robot                                         variables specify future states robot    gotoposeactionxtytφtxdydφd → vtravrot       constrained pre postconditions respec    teleooperators tops consist action tive optimization free variables  pre postconditions nilsson  postcondition formance models actions required offline  represents intended effect goal spec models learned experience each action  iﬁes region state space goal sat library used subgoal reﬁnement sys  isﬁed precondition region respect tempo tem during execution time available resource  rally extended action deﬁned set world states systems  continuous execution action eventually sat big advantages approach  isfy postcondition similar action schemata library generation chains planner     library                                      tial learning accurate performance models figure                               learn performance model shown exploiting transformational rotational                                                   variance reduces original sixdimensional feature space          action                                        threedimensional predictive power          prepost−conds           perfmodel   off−line                                                           −d xt  yt ϕt xd  yd ϕd −d dist angleatdest       generate chain                                                                       angletodest                              subgoal refinement                                                             chain                 relevant variables      state−space state−space state−space                                      ϕ      pre−cond pre−cond goal                                     ϕ                     actioni actioni                                                      post−cond post−cond  optimize relevant variables                             angleatdest                                                                                                                   on−line                                 refined optimal subgoal                                 angletodest       execute chain                                                                    dist                                                                                       figure  overview                                                                                       figure  transformation original state space  chain executor need modiﬁed way lowerdimensional feature space  accommodate action chain optimization                                                          currently perform transformation manually    learning performance models                        each action ongoing research investigating                                                        methods automate transformation explicitly rep  actual optimization chains discussed resenting reasoning physical meaning state  section  needs performance models each action variables research feature language generation methods  library each action robot learns function step approximate function trans  maps situations cost performing action formed data using model trees model trees  spective situation paper performance measure functions map continuous nominal features  time mechanisms applies cost functions tinuous value function learned examples  requiring change robot learn piecewise partitioning feature space linear function  formance function  experience  using transformed ﬁtted data each partition model trees gener  state space  partitioning state space  approxi alization decision trees nominal values  mating functions data each partitions leaf nodes replaced line segments use model trees  ﬁrst motivate explain  transformed sets rules  implemented                                          suited human inspection interpretation  com    let consider navigation action gotoposeaction parative research shows best belker   navigation action based computing bezier balac   tend use relevant variables  curve trying follow closely possible means start features  dribbleballaction    uses method restricts needed predict performance having model  deceleration rotational velocity loose ball tree function automatic feature selector tree  abstract away implementation methods actually learned dimensional feature space  consider actions black boxes performance xyφxgygφgdxdydistangle destangle dest  learn observed experience                    model tree algorithm automatically discovered    robot learns performance function experi distangle destangle dest necessary  ence executes action varying situations observes accurately predict performance  performance logs experience examples trained model tree gathered data yield  method based solely observations possi ing rules present example fig  ble acquire models actions internal workings ure  depict example situation dist  accessible robot executed each action  times angle dest ◦ respectively given  random initial destination poses robot recorded values plot performance function varying val  direct variables time took reach destina ues angle dest plots depicted fig  tion state hz gathering   examples ure  cartesian polar coordinate  format xtytφtxdydφdtime action examples linear plot clearly ﬁve different line seg  gathered using simulator uses learned dy ments means model tree partitioned  namics models pioneer platform proven feature space dist angle dest ﬁve areas  accurate port control routines simulator each linear model plots  real robot change using pioneer robots learned model tree rules applies situation  acquiring data approximately displayed arrow indicates linear model plots  hours operation time                                polar plot clearly shows dependency predicted    variables recorded necessarily corre execution time angle approach example sit  late performance design trans uation approaching goal  degrees fastest  formed feature space features poten predicted approaching goal      situation                                         robot subset state variables observable        dist                         angletodest                               perceptive estimated using state        angleatdest  −                      estimation module controller distinction                                                        direct derived observable state variables                                                       direct state variables navigation task depicted                                                                                               figure  direct state variables directly provided state                                                        estimation derived state variables computed                                                             combinations direct variables extra information                                                       tained derived variables chosen derived vari                                                        time                                          ables better correlated control task                                                                                                                                                                                                                                                                  ϕt         predicted  execution time                                                   ϕ                                                                                    −                                                    angleatdestangle goal degree degree                                                                                                                                             model tree rule                                                                               ϕg     dist    angletodest    angleatdest                                                                                      time  dist  angletodest  angleatdest −  xt        xg    figure  example situation graphs time prediction figure  direct state variables relevant navigation task  situation varying angle dest model  tree rule line segments                                                          state variables used specify goals internal                                                        controller variables bound conform plan                                                        ning terminology controller’s goal bound  degrees means robot navigate internal variables approximately coincide external  goal point taking longer evaluate ac observable variables robot’s goal arrive inter  curacy performance models randomly gen mediate position represented state variables  erate  new test situations gotoball routine                                                        xiyi setting velocities robot inﬂuence  mean absolute error rootmeansquare error current position  achieve ≈ ≈   predicted actual execution time                              dribbleball  routine values  determining search space  errors accurate  optimize action chains                               optimize performance variables actually inﬂu                                                        ence performance tuned implementation                                                        means variables used model    automatic subgoal reﬁnement                        tree partition state space nodes used  depicted figure  automatic subgoal reﬁnement linear functions leaves  takes performance models chain teleo learned model trees  actions  operators input returns reﬁned intermediate goal gotoposeaction dribbleballaction rel  state optimized respect performance evant variables dist angle dest angle dest  overall action chain need specify derived variables computed direct vari  variables task recognize ables xtytφtxiyiφi xiyiφixgygφg ﬁrst  variables inﬂuence performance ﬁxed second action respectively changing direct  variables form search space optimize variables change indirect variables computed  performance using learned action models          effect change performance                                                          change variables xtyt    state variables                                  φt simply change current state  dynamic model dean wellmann  world alter bound variables robot  world changes through interaction processes committed xiyixgygφg changing  controlling process case lowlevel control pro make plan invalid  grams implementing action chains generated plan leaves free variable φi angle  ner controlled process case behavior intermediate goal approached acknowledges intu  robot evolution dynamic represented ition figure  changing variable make  set state variables changing values plan invalid inﬂuence overall  controlling process steers controlled process sending formance plan left onedimensional  control signals control signals directly set search space optimize performance  state variables indirectly ones affected  state variables called controllable state variables  optimization  robot instance set translational rotational ve optimize action chain ﬁnd val  locity directly causing robot indirectly ues free variables overall performance  inﬂuencing future poses robot                 action chain highest overall performance isestimated summing performance models ac ﬁltering total higher equal lower  tions constitute action chain figure  ﬁrst  runs                polar plots represent performance individual improvement                actions different values free variable ﬁltering total higher equal lower  angle approach overall performance computed  runs                      adding depicted polar plot improvement                                                       gotopose       gotoposetime action  ss dribbleballtime action  dribbleballtotal time  table  results ﬁltering cases                                                                                performance loss predicted                                                                                                                                                                        trained decision tree predict nominal value tree                                                        yields simple rules predict performance dif                                      ference correctly  given cases rules declare                                                                               performance stay equal three points                                                        aligned decrease ﬁnal goal po  total              total                                                    sition area robot                                                   robot’s distance intermediate goal smaller                                                        essentially rule states robot using                                                                   gotoballaction                                                   bezierbased                 difﬁculty approaching                                                   ball awkward angles close cases                                                        small variations initial position lead large variations                                                        execution time learning accurate general model  figure  selecting optimal subgoal ﬁnding opti action fails resulting inaccuracy temporal pre  mum summation action models chain diction causes suboptimal optimization note                                                        shortcoming action chain optimization                                                        methods investigate creating specialized action    fastest time ﬁrst polar plot angle                                                        cases bezier based navigation unsuccessful  approach  degrees direction indicated                                                        solve problems  center plot total time  second action takes angle  values gathered  runs described  read directly polar plots value applied subgoal reﬁnement decision tree pre  optimum overall performance minimum dicted applying yield higher performance al  overall performance read increase overall performance dramatic  polar plot polar plots situation figure    number cases perfor  repeated time predicted performance each mance worsened applying subgoal reﬁnement  action                                               creased     apparently decision    expect higherdimensional search spaces ex tree correctly ﬁltered cases applying subgoal  haustive search infeasible optimiza ﬁnement decrease performance  tion techniques investigated           summarizing subgoal reﬁnement ﬁltering yields                                                         increase performance half time    results                                            times does cause small performance loss  determine inﬂuence subgoal reﬁnement  related work  performance action chain generated  situ  ations random robot ball ﬁnal goal positions similar work use model trees learn  robot executed each navigation task twice subgoal performance models optimize hierarchical transition net  reﬁnement results summarized work plans belker  work models used  table  overall increase performance select action chain reﬁne   runs  split cases existing action chain planner selected  subgoal reﬁnement yielded higher equal independently optimization process  lower performance comparison using reﬁnement reinforcement learning rl method seeks  shows performance improved  cases optimize performance speciﬁed reward function  cases causes  improvement  cases recent attempts combat curse dimensionality  improvement expected rl turned principled ways exploiting temporal  situations three positions opti abstraction hierarchical reinforcement  mally aligned straight line subgoal reﬁnement learning methods programmable hierarchical ab  effect                                  stract machines maxq options described    unfortunately applying method causes decrease overview paper barto mahadevan  ap  performance   runs analyze proaches use concept actions called ‘machines’ ‘sub  cases subgoal reﬁnement decreases performance labeled tasks’ ‘options’ respectively view beneﬁts  each runs higher equal lower methods acquire informative
