                        temporaldifference networks history                                     brian tanner richard sutton                                            university alberta                       reinforcement learning artiﬁcial intelligence laboratory                                   edmonton alberta canada tg                                      btannersuttoncsualbertaca                        abstract                          represent nthorder markov model partially observ                                                        able markov decision process pomdp singh et al       temporaldifference td networks formal   littman et al  showed size      ism expressing learning grounded world    psr scales existing approaches linear      knowledge predictive form sutton tan   psr model compact equivalent pomdp      ner  partially observ    nthorder markov model td networks generaliza      able markov decision processes efﬁciently  tion linear psrs inherit representational      learned td networks paper ex   power singh       tend td networks allowing networkupdate     td networks applied successfully simple en      process answer network depend recent  vironments fully partially observable td      history previous actions observations networks expressive power accurately model com      recent action observa  plex partiallyobservable environments show ex      tion show extension enables isting learning algorithm insufﬁcient learning      lution larger class problems  models      solved original td networks history   paper explore classes environment      based methods addition apply td net model previously learned improve td      works problem simple sig networks learn models environments      niﬁcantly larger previously consid   section  review td networks speciﬁcation      ered show historyextended td networks   sections   examine class problems      learn commonsense knowledge   unable learn existing speciﬁcation      egocentric gridworld domain single bit td networks augment speciﬁcation present new      perception                                       sults present results applying augmented td                                                        networks complex gridworld domain section                                                         finally conclude discuss direction future  temporaldifference td networks formalism ex research section   pressing learning grounded knowledge dynamical  systems sutton tanner  td networks represent  td networks history  state dynamical vector predictions following text speciﬁc instantiation  future action–observation sequences each prediction original td networks speciﬁcation instructive  estimate probability expected value understanding details work information  future event example prediction estimate general speciﬁcation td networks direct reader  probability seeing particular observation time original work sutton tanner   step predictions generated each time step thought problem addressed td networks general  “answers” set “questions” asked td net learning predict aspects interaction  work                                                 cision making agent environment dynamical sys    representations encode state dynamical sys tem each series discrete time steps  tem vector predictions known predictive repre agent takes action ∈ environment responds  sentations littman et al  jaeger  rosencrantz generating observation ot ∈ work  et al  predictive representations relatively consider td networks observations   new area research community answering  action observation events occur sequence  fundamental questions possibilities limita at− ot ot ot sequence called  tions far results encouraging singh et experience interested predicting just each  al shown particular representation known observation general actionconditional functions  linear predictive state representations linear psrs future experience  focus work current partially observable extraneous questions                                                                     environments—environments observation ot formally yt ∈         −  denotes predic  sufﬁcient statistic make optimal predictions future tion node time step column vector predic                                                                         n−  experience ot does uniquely identify state envi tions yt  yt      yt  updated according vector  ronment using td networks learn model valued prediction function modiﬁable parameter  environment accurate maintained  time                                                                    yt  σwtxt                     td network network nodes each representing prediction function corresponds answer net  single scalar prediction nodes interconnected                                                                    work xt ∈   feature vector wt ×  links representing target relationships predictions matrix weights σ sshaped logistic function  observations actions nodes links determine σs    feature vector function pre  set questions asked data predictions e−s                                                        ceding action observation node values  accordingly called question network                                                          previous work td networks binary compo    each node td network function approximator                                                                                     nent each unique combination current observation  outputs prediction using inputs current ob                                                        previous action  rest   servation previous action predictions                                                        previous node values  additionally  previous time step computation td network                         t−                                                                     bias term constant value  experiments  thought providing answers questions                                                        included real valued features complement pre  accordingly called answer network                                                        dictions time step  −  later    figure  shows typical question network question                             t−                                                       necessary learning algorithm each  node time ‘if action    ij                                                        component wt wt form  probability observation ot ’ sim               ilarly node asks ‘if action node   ∆wij  αzi − yiyi − yixjci      predict time  ’ desired relationship                                                                                                                         tween predictions question data α stepsize parameter zt target                                                                                       unroll interpredictive td relationship look ﬁned question network ct ∈   corresponds  extensive relationship data yields action condition yi met time  question ‘if actions prob  ability ot ’                           cycleworld counterexamples    fully observable markov environment natural  question network set questions experimentation td networks able  way interesting experimenter partially solve certain small testing problems  observable environments structure question net success learning does directly corre  work additional constraints answers suf lated complexity environment previous  ﬁcient statistic accurately represents state work td networks able learn accurate model  updated new data available ques partiallyobservable sevenstate deterministic random walk  tion discover question network expresses probabilities fully observable stochastic  minimal sufﬁcient statistic important tangental random walk sutton tanner  time  focus work question networks use discovered td networks unable learn accu  minimal network like figure  likely contains rate model certain small partiallyobservable deterministic                                                        environments careful analysis determined ques                                                        tion networks used sufﬁcient represent                                                        appropriate model issue lie td                          ot                                                  network speciﬁcation                                                          figure  presents simple example task question                                                                                  network solution representable learn                                                        able td networks history cycle world                                                                sists states shown left current state                                                        cycles clockwise through states                                                                     single observation bit  cycle                                                         times right question network                                                        asks observation bit three time                                                        steps future recall time yt calculated  figure  symmetric actionconditional question network function yt− at− ot wt assume yt−  network forms symmetric tree branching fac correct solution weights yt  tor example depth   labels correct each successive time step unfortunately yt−  left diagram clarity each correct solution exists  nodes label yi each conditioned illustrate look question network  action                                               remember speciﬁes target values answernetwork start training yt− likely incor       features initial final  rect actions environment current                         observation ot useful input feature xt       history        network correct necessary sequence        history        questions eventually answered starting anchored        history                                                                             history        knowledge ot note training  gins node valid target tar      history        prediction grounded observable          history                                                                             history        value ot training progresses agent interacts      history        environment answers learned anchored                                                                                                                                                                             grounded observations eventually environ                                                                                                ment reach point ot   yt                      information distinguishes case case                                                  ot   yt  lies correct answer yt−                                 unfortunately target yt− yt  case cyclic figure  input vector cycle world step history  dependency question network temporal  levels predictive nodes left deﬁni  ﬂow information eliminates possibility td net tion each feature ﬁrst feature bias term  work learning correct solution                      features correspond  distinct step histories                                                        ot−ot−ot possible world ﬁnal     considering problem apparent features predictions previous time step  necessary ﬁnd augmentation td network spec middle vector sample input vector state  iﬁcation eliminate cyclic information dependencies                                                    cycle world start learning point  dependency occurs target node relies predictions initial value  finally  making accurate predictions dependency elim rightmost vector input vector state  inated providing additional input features td net learning complete predictions accurate  work additional information acts anchor  td network predictions                                                           td networks history    incidentally good approximate solutions cycle world  learned td networks consisting single node cycle world problem simple  clearly way single predictive node solve lationship observations recent experience  problem perfectly achieve low error methods try directly learn relationships called  unusual way ot   network predicts approxi historybased methods consider historybased meth  mately  time step network multiply ods predict ot using different variable each  previous prediction predict approximately  unique klength window history klength window  step predict  ﬁnally  history deﬁned at−kot−kat−ot case  step ot  unfortunately solution window length  sufﬁcient uniquely identify  stable continued training leads oscillation each state able make accu  sort approximate solution strictly predicting  rate predictions incorporating short history feature  each step                                            vector xt td network allow td network                                                        learn correct solution problem figure  shows                                                        example hybrid input vector uses  time steps                                                        history  predictive nodes              cycle world question network                order test hypothesis incorporating history                                                        input vector xt td network allow                               ot                    solve greater class problem used cycle world like                                                        figure  states instead                                                    size chosen clearly illustrate effectiveness dif                                                        ferent conﬁgurations history predictive nodes                                                        problem tested three different methods  td networks                                                    previously speciﬁed history  simple history                                                        based approach  combination td networks                                                    tory each method used values                                                        step size parameter best used perfor                                                        mance measure method each method step  figure  counterexample tdnetwork learning size network trained million time  history left representation cycle world steps step prediction errors averaged ﬁ  environment states cycled through nal  steps produce overall performance measure  terministically right associated question net each method  work actions world               results shown figure  show simple                                                                               state                                                                                                                                                           state              state                                   history                                                                                              rms             error                                                                                                                                                                                                                           state                                                                                                    figure  indeﬁnitememory problem fourstate                                                         terministic ring world actions world                   length history                     previous advances clockwise rotation                                                         previous advances counterclockwise rotation prediction                                                         methods using ﬁnite length history lose localization af                                                         ter number transitions forth states   figure  performance state cycle world td net   works extend incorporate various lengths history   different lines correspond different depths question   network indicated numeric label           uniquely identify current state environment                                                         refer problems class indeﬁnitememory                                                         problems   historybased method performed                                                           simple example indeﬁnitememory problem   history solve problem exactly td networks                                                         ring world shown figure  states   history correspond data points history                                                         indistinguishable sequences actions   length performances better history                                                         environment subset states eventually ﬁll   length good td networks                                                         ﬁxedlength memory useless information contrast   tory interesting notice td network                                                         td network easily represent environment   able solve problem shorter window                                                         forget location environment   historybased method illustrates com   bined algorithm simply using history instead pre applied td networks various depths question   dictive representation leveraging history network lengths history state ring world prob   learn predictive representation interesting lem performance measure used   formance various combinations history predic previous experiments case averaged    tive nodes follow clear pattern example independent runs  million time steps results    predictive nodes appears   steps shown figure  history window increases   history better having  steps veriﬁed historyonly method closely approximates correct   minimum length history required solve state cycle solution improvement diminish   world exactly  predictive nodes step history tory window gets larger hampered fact   means low error seen  steps history case number unique histories grows exponentially   td network stumbling good approximate solution length window predictive approach   represent exact solution discussed problem solved correctly  level history   end section                                 predictive question network depth                                                            interesting provided time td network                                                         learn correct model environment history     indeﬁnitememory problems                          cycle world espe   previous section introduced history td net cially puzzling problems highly   work speciﬁcation order eliminate cyclic dependencies related cycle world seemingly complex   increase class problems solutions ring world fact actions inverses ring   learned td networks appeared tradeoff world eliminates information ﬂow dependencies ex   predictive levels question network lengths isted cycle world ring world agent   history example clear crementally learn environment   combined approach superior historyonly approach early training agent anchor ot     potentially large class problems cause observation uniquely identiﬁes state time   represented historyonly approach repre passes agent learn accurate step predictions   sented solved td networks environments anchored location learn step predictions   class ﬁnite length history involve leaving position returning immerms                history  error                     predictive level                    predictive levels                    figure  gridworld used ﬁnal experiment                                                        agent’s location represented triangle agent                               predictive levels       limited perceptual space observes  arrow                                                        pointing block  arrow pointing                                                                            levels history                     open space agent actions forward                                                        turn forward agent  space direction                                                        arrow points blocked turn                                                        rotate arrow clockwise  degrees  unique  figure  performance state ring world function environmental states world  length history depth question network  tory method suffers diminishing returns size  history window increases learning slows considerably types commonsense knowledge  number unique histories observed harder learn history facing wall  grows exponentially                                  turn  degrees observe wall walk                                                        forward commonsense predictions make                                                        know turning  degrees  diately process continue chaining effect clear walking forward  allowed agent make accurate predictions wall know rotate  degrees  positions network                             number times step process en                                                        tire process remains intact changes concept     gridworld experiments                             impossible learn ﬁxed length history sce                                                        nario exempliﬁes conceptual practical difference  previous work far paper td networks                                                        tween predictive representations historybased represen  applied abstract problems fewer                                                         tations facing wall turning  degrees going  states ﬁnal section paper present suggestive                                                        forward level historybased approach knows ‘i  results gridworld environment order mag                                                        state described wall turn clear turn clear forward  nitude complex previously considered                                                        clear’ predictive agent different representation  gridworld figure  shows environment chose                                                        like ‘i state wherep rclearturn turn   environment agent single perceptual input                                                         rwallturn turn forward   etc’  single bit indicating wall directly  agent limited action space ran td network depth  history length  attempt forward rotate  degrees  environment  million time steps  clockwise encourage reader consider analo opportunity learn causal structure  gous tasks suitable human consider sitting environment end time took control  table buttons light bulb told decisions explore particular places world shown  light bulb turn based buttons pressed figure  left ﬁgure shows state en  according unobservable process unobserv vironment various points time agent controlled  able process map figure  human learn state state right representation agents  problem                                         predictions each step shown predictions show    second interpretation problem agent learned great deal environment  familiar navigating room lights   agent corner  times feel touching wall knows wall left side wall  sorts commonsense knowledge notice just right ’a’ dark bar bar rep  apply type scenario simplest knowledge resents prediction turning right going forward twice  touching wall attempt walk forward turning right three times fact bar  touching wall know  dark indicates agent correctly knows  consecutive  degree turns ends observation nearest interior blocked cell ’a’  started types knowledge agent predicts wall ’a’ predicts gray  learned easily historybased approach      shows agent does completely understand
