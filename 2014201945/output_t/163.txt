       inferring longterm user properties based users’ location history                        yutaka matsuo      naoaki okazaki     kiyoshi izumi                 yoshiyuki nakamura      takuichi nishimura      koitiˆ hasida                     national institute advanced industrial science technology               ymatsuoaistgojp kiyoshi nmura takuniaistgojp hasidakaistgojp                                             hideyuki nakashima                                        future university hakodate                                          hnakashimafunacjp                      abstract                          laboratory imply working behavior laboratory                                                        members different types users guests      recent development location technologies en   campus tour laboratory implies sightseeing      ables obtain location history users behavior user modeling behavior detection      paper proposes new method infer users’ long mutually complementary precise user      term properties respective location histo model guess precisely user behavior      ries counting instances sensor detection vice versa automatically obtaining user model boot      user obtain sensoruser matrixaf strap activity recognition ubiquitous environment en      ter generating features matrix machine able contextaware information services      learning approach taken automatically classify                                                          user modeling ubiquitous computing      users different categories each user prop                                                        studies recent years heckmann pro      erty inspired information retrieval research                                                        poses concept ubiquitous user modeling heckmann      problem infer user properties reduced text                                                         proposes general user model context ontol      categorization problem compare weightings                                                        ogy gumo  user model context markup language      features propose sensor weight                                                        userml lay foundation interoperability using se      ing algorithms evaluated using experimen                                                        mantic web technology carmichael et al proposes user      tal location data ofﬁce environment                                                        modeling representation model people places things                                                        ubiquitous computing supports different spatial    introduction                                       temporal granularity camichael et al   contextaware computing gaining increasing paper describes algorithm infer user’s long  ai ubiquitous computing communities date nu term properties gender age profession interests  merous approaches taken recognize model location information automatically learns  user’s external context example one’s location physi patterns users’ locations user properties conse  cal environment social environment provide context quently infer properties automatically  dependent information “context” slippery produce user model new user coming environ  tion dourish  promising recognize ment show properties likely inferred  adapt aspects users activities general difﬁcult infer algorithm useful  terests current information needs jameson kruger various ubiquitous computing environments provide user   user models useful personalized informa modeling personalized information services  tion services ubiquitous computing                  address users’ longterm properties especially    recently location information widely avail usermodeling dimensions kobsa lists frequently  able commercial systems research systems services usermodeling utilize users’  vices wifi bluetooth lowcost radiofrequency tags longterm characteristics knowledge preference  associated rfid readers ultrasound devices pro abilities kobsa  jameson discusses different  vide locationbased information support various situations types information user ranging current  environments early famous project ac text information user’s longterm properties  tive badge want et al  work numer tribute simultaneously user adaptive mechanisms jame  ous studies users’ activity recognition locationaware son  ontology gumo longterm user model di  applications developed using location mensions categorized demographics age group  sensory information context ubiquitous mobile gender personality characteristics profession  systems wilson  hightower et al  ashbrook proﬁciency interests music sports  starner  liao et al  lester et al  basic domain independent  wilson philipose  studies user mod domain dependent  els implicitly assumed example algorithm simple applicable                                                    ijcai                                                                figure  idcobit sensors                                                                      figure  idcobit  types location data inspired research information  retrieval regard problem inferring users’ proper  ties text categorization problems support vector machine  svm applied problem various feature weight  ing methods compared paper study evaluated  empirical data obtained through oneweek experiments  research institute collected location data   users staffs guests idcobit consist  ing namecardtype infrared transmitters sensors  stalled environment recognize users’ location figure  sensor allocation map fourth ﬂoor    paper organized follows section intro  duces idcobit describes location data  experiments  proposed algorithm user modeling location informa  tion explained section  analyses results idcobit installed ofﬁce environment  section  propose measurements sensor research institute location data collected aist  importance section  related works discussion tokyo waterfront research center february    described section  finally conclude paper mon through february  fri  sensors                                                        stalled ﬁrst ﬂoor fourth ﬂoor ﬁrst ﬂoor                                                        entrances reception areas lobbies lounges    location information                               fourth ﬂoor main ofﬁce consisting research area  research location information obtained using administrative area sensor allocation map  cobit section brieﬂy overviews idcobit fourth ﬂoor shown partly fig    describes experiments collect location data square meters entire covered area ev                                                        ery working staff member ﬂoors delivered    idcobit                                         idcobit continued wear during period  compact batteryless information terminal cobit  delivered idcobits obtained location  compact information terminal operate bat formation  guests visited institute temporarily  teries utilizes energy information carrier during period  nishimura et al  idcobit terminal inte experiments analyzed location data  grating cobit infrared ir id tag liquid crys detection instances sensors  times   tal lc shutter figure depicts idcobit times staff  times guests number  useful namecard holder id detector idcobit constant each day average staff member detected  single detector type ir sensor shown fig  times guest detected  times  sending cycle tag  effective distance location information user properties staffs quanti  – detailed speciﬁcations available nakamura et tatively qualitatively better guests use  al                                            staff information paper    idcobit provides locationbased informa  obtaining users’ longterm properties manually  tion support environment exhibitions mu surveyed user attributes staff age work fre  seums academic conferences nishimura et al  quency room smoke user  users download information depending location properties used study shown table   orientation mainly voice information entire ar chose demographic properties age position  chitecture shown fig  idcobit domaindependent properties team work  multiple communication channels study use frequency userspeciﬁc properties cof  ir led idcobit ir sensors envi fee smoking  ronment speciﬁcally address obtaining locations users elaborate properties considering usefulness  disturbing usual daily behavior              domain versatility domains age                                                    ijcai                                                                   table  user properties   user property  range   age                                  position       sc∗ fulltime researcher                  parttime researcher                   technicalstaff temporarystaff   team           researchgroupa                      secretaries administrators   work          high middle low   frequency∗∗   coffee∗∗∗      high middle low   smoking        yes   room              commuting    stationa stationb  ∗ sc stands steering committee ∗∗ free time  work environment working time commuting fre  quency depend person ∗∗∗ drinks coffee   working room one’s desk  train stations lines  accessible institute                                                        figure  illustration sensor detection sensoruser  position  important properties especially japan matrix  japanese culture age position make large differences                                                        fee                                          communication using respect language behav property represented yes   ior inappropriate impolite ask user suming three users values yes noandyes  age position directly useful property following table training set  infer properties team workfrequency                        coffee  seen users’ interests research domain                         cause team organization ﬂexible institute                       ﬂect reseracher’s coffee smok                               ing useful guests recognize  guest likes coffee smoking suggest appropriate new user comes detection fre                                                        quencies observed prediction problem arises  restaurants cafes break time coffee  asked “do like coffee tea” “do smoke not”   property user    japan indicates usefulness properties         coffee  daily lives lastly room commuting navi                               gation knowing properties infer training set classiﬁcation learned using  room researcher does wear machinelearning techniques nearest neighbor  bit recognize heshe goes home                                                        method similar                                                        depends similarity measure method    inference user properties                       outputs   section propose algorithm infer user prop approach justiﬁed using following example let  erties based respective location histories ﬁrst consider situation sensor installed  reduce prediction problem user prop coffee server frequent detection means  erties text categorization problem feature user comes frequently coffee server  design machine learning explained             imply user likes coffee know advance                                                        sensors important classiﬁcation    reduction text categorization problem       coffee server ones vending  sensor detects user sensorid userid machine completely unexpected  obtained each time sensor detects user counting num case classiﬁcation learned through sensor detection data  ber detections build matrix represents performance evaluated kcross validation  times each sensor detects each user sensor leaveoneout method each training data  user matrix denoting number users num used repeatedly initial training data test data  berofsensorsasm sensoruser matrix n×m matrix obtained problem closely resembles text categoriza   denote wij element  number tion problem document represented word vec  detections user uj sensor si illustration sensor tor bag words each word document  detection sensoruser matrix shown fig  weighted word weighting structure linear    consider user properties example user ordering words document ignored term  property user drinks coffee cof document matrix documentbyword matrix manning                                                    ijcai                                                    sch¨utze  resembles sensoruser matrix  documents words each user table  classiﬁcation performance depending various  corresponds document each sensor corresponds feature weighting  word text categorization task categories annotated        fvalue recall  precision  each document considered user properties freq                     problem classiﬁcation learned used infer binary                 category based word vectors user tfidf                    modeling problem location information reduced  idf                       multilabel text categorization problem proper nfreq                 sumptions simpliﬁcations                            nbinary                       text categorization typically attained using clas nidf                 siﬁcation techniques employ support vector machine    ntfidf                     svm learner creates hyperplane separates             ×  data classes maximummargin vapnik   feature weighting methods   svms offer important advantages text compared section freq  categorization term selection unnecessary binaryidftfidfnfreqnbinarynidfandn  svms tend fairly robust overﬁtting addition tfidf normalized tfidf ntfidf known  theoretically motivated “default” choice parameter set perform text categorization different results  ting joachims  beneﬁts provided vealed usermodeling problem  usermodeling problem                                                           evaluation    feature design  context text categorization tfidf frequently used each user property shown table  categorization  feature weighting encodes intuition problem generated exactly svm fun  word occurs document rep damentally applicable twoclasses problem problem                                                        generated each value property example  resentative content ii documents age  word occurs discriminating studies property ﬁve values ﬁve classiﬁcation prob  rephrased follows sensor detects lems generated make positive negative classes  user representative user’s characteristics each value say   ii users sensor detects discriminat obtained classiﬁer clas  ing                                            sify people     tfidf weighting function tailored case deﬁned svm used learn categorization                                                        formance evaluated leaveoneout employ radius  tfidfsiujfreqsiuj×idfsi freqsiuj                                                        basis function rbf kernel performs pre  number detections users uj sensor sithe                                                        liminary experiments   idfsj deﬁned idfsi  lognufsi ufsi                                                          average performances categorization problems  number users sensor si detects corresponding  document frequency sensor detects users shown table  example use freq feature                                                        weighting recall  meaning detect  high ufsi value low idfsi value  extreme case sensor detecting users zero idf  persons property having certain value  value lognn                                  baseline investigate performance straightfor    aside tfidf weighting ways feature ward classiﬁer outputs positive fvalue   weighting possible compare typical weighting meth precision  method better  ods used compared information retrieval baseline feature weighting nfreq high  following list feature weighting methods est fvalue ntfidf second best normalization  use                                                  function effectively feature weighting                                                        alleviate difference detection frequency    • frequency number detections wij  freqsiuj                                                       users caused difference working time                        freqsiuj fthre          individual deviceusage characteristics depending fea    • binary wij                                                                         ture weighting performance varies  points      fthre threshold paper determine fthre  emphasizing importance feature weighting       through preliminary experiments                user modeling                                                         text categorization normalized tfidf works                   idfsi freqsiuj fthre    • idf wij                                         normalized frequency does compete joachims                                                                                 case ntfidf performs nfreq performs    • tfidf wij  tfidfsiuj                         best result completely identical    weights fall  interval text categorization literature reason considered  vectors equal length weight normal follows compared documents functional                                        normalized  ized by cosine normalization given wij            kernels linear polynomial kernels produce                 wij    iwij                                     similar results overall results worsen points                                                    ijcai                                                    words popular words information location data    suffers problem naive approach    using normalized frequency work                 generally recall  precision   better results particular  set user properties smoking room com          muting fvalues high     respectively  recall                                                              value  precision values agemost          team                   coffee  values     andhigh  value                points greater baseline                                                                                                 wtotalfreq                                                                                                   tfidfsum  fvalues   recall                                         totalfreq                                                                                                totaluser  precision                                                                                      ntfidfsum                                                                                                 ntotalfreq    summary user properties team                                           ntotaluser                                                                                                    random  room predicted effectively using solely loca                                                                                                         tion information degree age coffeeand                             number enabled sensors  smoking   predictable position work  frequency    difﬁcult predict                    figure  number enabled sensors versus fvalue    investigated feature weights learned models                                                          compare importance measures sensor  sensors unexpectedly important                                                        rived text categorization studies importance  coffee  property example ones                                                        sensor si deﬁned follows overall frequency  coffee server ﬁfth ninth importance                 n                                                        talfreq  wsi       freqsiuj ii total detected  sensors important                                                                        users totaluser wsiufsi  iii total tfidf sum  small table people gather break corridors             n  recognized important surprisingly sensor exactly tfidfsum wsi tfidfsiuj functions  coffee server slightly negatively weighted normalized taking summation user  sensor copy machine denoted ntotalfreqntotaluserntfidfsum  door detection little information prop addition use importance measure called  erty results show limitation presumption weighted frequency wtotalfreq following intu  user behaviors effectiveness approach     ition sensor detects users detected                                                        fewer sensors important iv weighted fre                                                                                                       ×    sensor weighting                                   quency wtotalfreq   wsi     freqsiuj  actual usecases possible prepare train logmsfuj sfuj represents number sen  ing data consisting users’ location histories user prop sors detect uj regarded tfidf measure  erties question arises way ﬁnd transposed sensoruser matrix summary  sensor useful future user modeling ad seven sensor importance measures  vance training data real world situation  comparison results  change sensor locations depending actual user  haviors useful know importance assume tentatively disable sensors enable  sensors future user modeling properly decreasing order sensor importance  choose sensors ﬁx locations section describes ap eventually sensors enabled results coin  proach measure usefulness sensors using loca cide case sensor weighting method  tion histories similar keyword extraction indexing superior performance improve faster  documents future retrieval                       sensor weighting poor performance grows faster                                                        random selection sensors does approach eval    importance sensors                            uate feature selection text categorization research  sensor does detect users useless joachims  mladenic et al   user modeling purposes deﬁnition figure  shows categorization performance  measure usefulness importance sensor sim changes number enabled sensors used  ply total number detections frequency detection freq feature frequency used user properties  alternatively sensors detect different users shown predictable shown section   important                                         ﬁgure undermost line random plotted se    importance sensor understood follows lecting sensors randomly shown baseline  usermodeling performance better best performance obtained wtotalfreq total  sets sensors set ”important” sensors freq methods totalusertfidfsumand  context information retrieval studies normalized series ntotalfreqntotaluserandn  examined ﬁnding good indexing terms document catego tfidfsum better random  rization better indexing terms improve categorization best  formance mladenic et al                        sensor weighting beneﬁcial situations                                                    ijcai                                                    
