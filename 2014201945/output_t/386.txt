               learning reportwriting behavior individuals               mohit kumar                      nikesh garera∗                alexander rudnicky       carnegie mellon university        johns hopkins university         carnegie mellon university            pittsburgh usa                   baltimore usa                    pittsburgh usa         mohitkumcscmuedu                ngareracsjhuedu                  aircscmuedu                          abstract                          maries argue enduser involvement                                                        likely generate quality products reﬂect      brieﬁng learns pre  functional needs user preferences worth      dict contents reports generated users effort current paper describes application      create periodic weekly reports approach context engineering project class      mal activity observes contentselection students expected produce weekly summaries      choices users make builds predictive   work course worked reporting      model example used generate quirement place minimally modiﬁed      initial draft report using feature inter process augmenting instrumenting webbased      face collects information po porting software use collect relevant data      tential userspeciﬁc features eval users apart normal activities      uated realistic conditions collecting data turbed data collected used perform offline learn      projectbased university course student ing experiments      group leaders tasked preparing weekly     each student produces logs team      reports beneﬁt instructors using leader additionally tasked reading logs se      material individual student reports         lecting log entries referred ‘items’ hereon suitable      paper addresses question data summary group activity learning based information      derived implicit supervision provided items selected team leader fur      endusers robust support    ther collect data identifying “features” deemed important      model parameter tuning form feature leader creating summary asking      discovery results indicate case sys team leader highlight key wordsphrases selected      tem performance improves based feedback    summary items phrases believe led se      user activity ﬁnd individual learned lect item thought having users      models features userspeciﬁc  directly select summary content units nenkova pas      completely idiosyncratic suggest sonneau  identify rougelike units ngrams word      approaches seek optimize models globally sequences lin  paper focus      say large corpus data fact extractive summarization believe approach      produce results acceptable individuals    extended prime information abstractive summariza                                                        tion longterm goals work                                                          plan paper follows relevant    introduction                                       ideas literature domain  paper personalized learningbased report generation tasks performed class  approach summarization minimizes need details data collected learning section  learningexpert time eliminates need expert outlines key details feature representation weighting rank  generated evaluation materials “gold standard” sum ing model selection describing basic learning  mary each user provides standard framework experiments results  work speciﬁc summarization believe different settings followed conclu  basic techniques extensible learning situ sions  ations share characteristic repeated execution  availability unambiguous user feedback           related work    course comes cost enduser time                                                        automatic text summarization explored  needed teach produce satisfactory sum                                                        halfcentury luhn  current work    ∗this work author student focuses generic newswire summaries duc    cmu                                                      radev mckeown  provide                                                    ijcai                                                    useful distinction brieﬁngs general  cept summaries focus generating multi  document newswire brieﬁngs mani et al  fo  cus generating brieﬁngs approach contrasts  different domain assume users  given outline brieﬁng try populate  outline does provide initial struc  ture generic template hand mani  et al  extend work multimedia inputs  current perspective believe fo  cus identifying important information allowing user  concentrate organization coherent presentation    personalized interactive learning systems  proposed summarization amini  describes  queryrelevant text summary based interactive  learning learning form query expansion sen  tence scoring classiﬁcation leuski et al  ex  plored interactive multidocument summarization  interaction user terms giving user  trol summary parameters support rapid browsing doc figure  demonstrationacquiring user based fea  ument set alternative forms organizing displaying tures phrase highlighting  summaries approach ‘content selection’ identify  key concepts unigrams bigrams trigrams based  likelihood ratio dunning  different statis writers experienced researchers asked  tical analysis zhang et al  generate weekly reports students taking course  proposed personalized summarization based requirement weekly report generation  user’s annotation presented good case course projectbased taught university engineer  usefulness user’s annotations getting personal ing school students divided groups work  ized summaries differs cur ing different projects required produce weekly  rent respects scenario single docu report activities submitted instructors  ment newswire summary different brieﬁng each group welldeﬁned roles including leader  purely statistical does include students class logged time spent different  concept humanintheloop improves performance activities related course each timelog entry included    elhadad et al  applied personalized summa following ﬁelds date category activity time spent  rization medical domain given patient proﬁle details activity category selected pre  set documents search query gen deﬁned set included coding group meeting research  erates personalized summary relevant patient previously set instructors  active learning community raghavan et al  example timelog entry is“visited voyager site  moving using user feedback identifying im spoke marine architects got feel possibili  portant features interesting domains ties scope project” data domain  summarization systems developed technical structured grammatical newswire documents  chat zhou hovy  newsgroup conversations new different chatlikeconversational corpora  man blitzer  email threads rambow et al  age words does contain spelling mistakes  spoken dialogues zechner    important characteristic data content    garera rudnicky  summarization timelogs changes time project progresses  recurring weekly reportwriting taking place wordbased features indicate importance  research project knowledgeengineered fea earlier weeks useful later weeks  tures lead best performance performance task team leader prepare weekly report  close based ngram features given beneﬁt instructor using timelog entries  desirable procedure leverages human knowl individual team members raw material students  edge identify highperformance features does using online create logs  quire participation experts process relatively straightforward augment application  approach problem                    allow creation leader summaries augmented ap                                                        plication provided interface allowed leader    target domain                                      easily prepare report instrumented collect                                                        data behavior instrumentation included mouse  identiﬁed domain similar reporting  structure studied garera rudnicky  italicized text shows reportwriter’s highlighting  differed signiﬁcant respects speciﬁcally report timelog                                                    ijcai                                                    keyboard level events report analysis meaningful train models nonobserved  data paper                            features                                                          resulting model used classify each candidate item    data collection process                          belonging summary item conﬁdence  following garera rudnicky  leader selected assigned classiﬁcation used rank order raw  items display items student reports items  items designated predicted  figure  shows interface used data collection summary week following sections explain  leader instructed through items select learning  subset inclusion report selection  highlighting “important” wordsphrases items  classiﬁer settings  scribed participant words phrases features  led select particular item report features used classiﬁer words unigrams  items highlighted text automatically candi                                                       stemmed stop words removed experimented  date brieﬁng items highlighted words phrases sub three different classes features nefalse  sequently designated custom user features unigrams neclass unigrams  abstracted named enti  used train model user’s selection behavior exami ties using neclass label person organization  nation data indicated users followed instruc ’white house’ treated unique token ‘lo  tions did example simply select entire items cation’ representing class neuniq raw unigrams   just ﬁrst word                                   each named entity substituted unique token ’white    data collected                                   house’ treated unique token ‘location’ used                                                        bbnidentiﬁnder bbntechnologies  extracting  able collect total complete  groupweeks named entities  data groupweek includes time logs written  members particular group associated extrac feature extraction  tive summaries class consisted stages design extract features different settings firstly  implementation lasting   weeks respectively use entire sentences extracting unigram features  groups roles reconstituted ﬁrst stage fraw secondly combine entire sentence features  meant ﬁrst stage new “authors” userspeciﬁc featuresfuser fuser ⊆ frawwhich  combine ﬁrst stage data second stage similar idea combining ‘context’ ‘anno  continuous sequence  groups ﬁrst tated keywords’ described zhang et al   stage average  students group  groups tails ﬁnal scores computed given  second stage average  students group  students dropped course ﬁrst weeks description  average  weekly summaries group stage  standard information retrieval ir metrics used score   weekly summaries group stage  evident features did ﬁx parameters schemes  averages groups submitted summary ev characteristics data did particularly recommend  ery week provide consistent data development testing particular setting tunable parameters schemes  analysis selected  groups possible values term weighing method  tf  later stage class produced reports consis term frequency tfidf saltonbuckleysb yates   tently described evaluation section corpus measuring idf word inverse doc                                                ument frequency obtained considering                                                        documents training set test set    learning                                    three different ways calculating idf normal                                                        ization scheme various scoring functions normal  modeled learning process described ization  garera rudnicky  models rebuilt feature scoring ﬁrst setting extracting unigram  weekly basis using training data available point features fraw straightforward using mentioned  previous weeks model used ir parameters tf tfidf sb combining scores  predict user’s selections current week example second setting ‘userspeciﬁc’ features  model built weeks   tested week  used following equation  model built weeks    tested week                                                                          α   ∗                                                                              fbase                vocabulary varied signiﬁcantly week  week trained models using words features idea capture user’s preference wrt particular  raw data target week classes nes user prefers select item                                                        son organization mentioned    interface enforces minimum  maximum  experimented using just userspeciﬁc features  number percentages total number items particu isolation useful combination  lar week item selections make sure summary reported features                                                    ijcai                                                                                group                    group                    group           week   tni   anw     nis   ans    tni   anw    nis   ans    tni   anw    nis   ans                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      table  table showing weekwise item details three selected groups tni  total number items week  anw  average number words item week nis  number items selected week ans  average number  words highlighted selected item week    α weight contribution userspeciﬁc fea  experiment results           tures fbase base score tf tfidf sb                α                                       selected experimentation three groups  empirically ﬁxed ‘’ current study        consistently generated complete weekly datasets     tested mentioned variations feature groups    complete weeks data detailed statis  scription feature extraction feature scoring using tics data shown table  groups  learning schemes naive bayes voted perceptron support different number weeks grouped observations  vector logistic regression event preliminary three phases combining results successive weeks  testing indicated support vector logistic regression create phase merging data three phases  suited problem hand consistent intuition task activity  eliminated consideration used weka initial starting period middle activities                       witten frank  package developing closing activity combined observations sliding                                                        window form three phases window size    evaluation                                       overlap different groups  base performance metric recall deﬁned terms group  items recommended compared items treated modeling technique free variable  ultimately selected user justify noting ran experiments possible combinations fea  recall directly linked expected time sav ture dimensions described previous section  ings eventual users prospective summarization overall best performing based jointly op  based ideas developed study ob timized metrics wmr slope selected ﬁnal  jective functions used selecting model model generate predictions  built basis recall                      ﬁnal model following parameters learning     weighted mean recall wmr scheme voted perceptron term weighing scheme salton  weeks weeks given linearly increasing weights buckley document frequency set training set normaliza  malized captures intuition performance tion scheme feature set gave best perfor  later weeks increasingly important mance neuniq  consecutively training data                       figure  shows key results experiments   slope phasewise performance curve slope abovementioned model performance averaged  ﬁrst calculate three phasewise recall performance values three groups  normal average recall values ﬁnd figure shows performance obtained  slope curve three points            generic ngram features comparable performance    note metrics used selection criterion incorporating userspeciﬁc features  results figure  stated terms original hoped userspeciﬁc features better generic  recall values averaged phase three ones it’s clear users select consistent personal features  users compare results random base figure shows userselected features  line random baseline calculated randomly selecting good selected based information gain arguably  items large number  runs “optimal” way select useful features table  shows  determining mean performance value              mean number active features each phase                                                        previously identiﬁed features occur test set    doing rougelike lin  evaluation interesting information  modeled problem creating draft summary terms  log items selected ﬁnal polished summary tionally used ‘ﬁrst’ sentence document    domain baseline methods tradi suitable characteristically different corpora                                                    ijcai                                                                                                                                                                                                                                                                                                                                                                                                                           recall      recall                          recall                                                                                                                                                                                               crossgroup                        usercombined                       igcombined                                                                                             igcombined                                                            usercombined                     raw ngrams                                                    usercombined                                                            raw ngrams                                                                                             raw ngrams                        baseline                            baseline                         baseline                                                                                                                                                                           phase                               phase                             phase    recall values final model recall comparison informa recall comparison individual    individual users comparing raw tion gain selected features user se user training crossgroup training    gram features usercombined fea lected features    tures    figure  figure showing various experiments ‘raw ngrams’ represents entire ngrams items ‘usercombined’  represents groupwise single user selected features combined raw ngram features ‘igcombined’ information  gain selected features combined raw ngrams ‘crossgroup’ training data pooled groups user’s  selections combined raw ngrams    gain ig selects features humans select phase  igselected suselected  overlap  broader number directly predict                                  item importance features future                            use curious little overlap                       ig selections human ones interpretation  humans selecting broader potentially robust table  table showing phasewise number features  set features supported observation information gain ig single user su se  igbased model fails select active feature  lected conditions column shows features  time human model fails  time common techniques  reason    figure shows happens pool userselected phase   cgselected  suselected overlap  features groups use train sin                               gle model testing performance group                               different crossgroup features                                                                                           form groupspeciﬁc features suggests  speciﬁc features matter reﬂect particular table  table showing phasewise number features  group’s activities leader’s emphases crossgroup pooled cg single user su  reports table  comparable table  training data conditions column shows features  indicates better overlap pooling data common techniques  troduces signiﬁcant error model  sults suggest important features taskspeciﬁc  userspeciﬁc interpretation consistent els sufﬁciently consistent predict increasing ac                                          results reported garera rudnicky         curacy summarization behavior users    table  shows frequent active features selected show naive endusers able consistently select fea  conditions single user selection information tures automatic process  gain crossgroup pooled data                 evidence feature sets selected humans                                                        turn robust long run automatic    conclusions                                        features predictive power spread larger num  show consistent summarization models built ber features useful result  relatively sparse usergenerated data mod opens possibility understanding eventually au                                                    ijcai                                                    
