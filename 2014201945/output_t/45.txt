        planning weaklycoupled partially observable stochastic games                                        anyuan guo        victor lesser                                    university massachusetts amherst                                      department science                                 governor’s drive amherst ma                                       anyuan lessercsumassedu                                                                     introduction                                         • si ∈ ∆si initial state distribution agent  partially observable stochastic games posgs provide • ai action set agent  × ×    ×  powerful framework modeling multiagent interactions denotes joint action set    elegant expressive framework shown          ai                                                          • bi  →    available action function maps  computationally intractable bernstein et al  joint state set available actions agent  exact dynamic programming algorithm posgs     ⊂ ∈   developed recently high computational demands                  demonstrated work extremely small • pi  si × ai × si →   transition function  problems approximate approaches devel agent joint transition function completely                                                                                    oped emerymontemerlo et al  nair et al  factored    sn     sn                                                                 qn         lack strong theoretical guarantees light  pisisi ai  oretical practical limitations need identify • ri  si × ai →  reward function agent  special classes posgs solved tractably    states rewards agents depend    dimension computational gain     local state action taken agent  leveraged exploiting independence present  problem dynamics paper examine class  model each agent complete view  posgs agents interact loosely restricting local state local policy each agent mapping  another’s available actions speciﬁcally hav local state available action set action  ing ﬁxed action sets each agent’s action set function set joint policy tuple local policies each  global state agents independent agent  separate transition reward func deﬁnition  local policy πi agent nagent  tions interact class problems arises fre posg statedependent action sets mapping  quently practice real world domains inhabited pairs local states local action sets hsi aisi  selfinterested agents act achieve individual actions current local action set ais   goals affect each way hs     si     sni  occasionally putting restrictions each                                                          example posg statedependent ac    bestknown solution concepts game theory                                                        tion sets autonomous rovers exploring unknown  computing nash equilibrium performing strategy elim                                                        terrain collecting rock samples river  ination work addresses solution concepts                                                        narrow bridge allows rover pass  show ﬁnding nash equilibrium each                                                        time simplify illustration assume rovers  agent achieves reward nphard contri                                                        states land bridge three actions each  bution work present exact algorithm                                                        bridge pick rock rovers receive  performing iterated elimination dominated strategies                                                        ward number rocks picked statedependent  able solve larger problems exact algorithms                                                        action set used constrain rover’s actions  general class exploiting problem structure                                                        allowed bridge time exam                                                        ple available actions rover  speciﬁed follows    posgs statedependent action sets             bhs  land  landi  bridge  section present formal deﬁnition pick rock bhs  land  bridgei   model   nagent posg  statedependent action pick rock analogously rover                               sets deﬁned hsi si  ai bi pi rii                                                    complexity      • si state space agent  × ×    × sn state decision problem denoted posgne      denotes joint state set                      follows given posg statedependent action sets                hsi si  ai bi pi rii does exist                      nash equilibrium agents expected utility       states  pruning    pruning                                                                                                                                                           theorem  posgne nphard problems involv                               ing  agents horizon                                             ×                                                                                  ×                                                                                            iterated action elimination algorithm                                  ×        present algorithm performs iterated elimination table  average size policy space  dominated strategies algorithm able work directly action elimination problems  constrained states  compact representation posg ﬁrst  verting double exponentially large normal form rep  resentation algorithm ﬁrst ﬁrst ﬁx action sets ﬁx available action sets each agent  each agent each state optimistic pessimistic states agents longer depend each way  action sets idea agent model decomposes set mdps each agent  predict exactly actions available each solve mdps using optimistic action sets  state ﬁnd actions available using pessimistic action sets solutions pro  best worst case scenario best case ac vide upper lower bound actual value  tions restricted state agents function each agent upper lower bounds  worst case actions restricted expected values each state derive bounds  fact unavailable                              expected action values each state dominated ac                                                        tions pruned iterate action elimination procedure                                                        actions pruned number   each agent                                                        actions each state ﬁnite procedure eventually      each state sk compute optimistic pes converge       simistic action sets  hs     sni                                                    theorem   iterated action elimination algorithm corre         sk                                         sponds iterated elimination weakly dominated                                                aoptsk    bis                  strategies                                                                                      experiments                    apessk    bis                                                      tested algorithm simpliﬁed agent autonomous                                                        rover exploration scenario size each agent’s local      compute value functions  mdps cor                                                        state space varies   introduced three       respond alternately ﬁxing available action sets                                                        constrained states each agent’s state space  trials                       opt     pes                               run each size state space number constraints                                                      table  shows detailed results problems three                                         max    rs     ss aus    strained states problems constrained              a∈a                    opt                                states ﬁnal policy space ranges                                                          respectively three cases iterated action elimi                                                      nation algorithm able reduce size policy space        ls   max     rs    ss als              a∈a                                   orders magnitude                  pes                 each action each state derive upper lower references       bounds action value value function bernstein et al  bernstein givan immer       bounds ls                               man zilberstein complexity decentralized                                                         control markov decision processes mathematics op             rs   ss aus                                                         erations research  november                                                                                       emerymontemerlo et al  emerymontemerlo                                              qls  rs    als          gordon schneider thrun approximate                                                        solutions partially observable stochastic games                                                          common payoffs proceedings joint      each state eliminate actions action ference autonomous agents multiagent systems       value dominated action qls ≥                                                                 qu                                                         nair et al  nair tambe yokoo pyna      repeat steps   actions   dath marsella taming decentralized pomdps       eliminated state                            efﬁcient policy computation multiagent set                                                           tings proceedings eighteenth international joint      table  iterated action elimination algorithm  conference artiﬁcial intelligence 
