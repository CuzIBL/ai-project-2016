         semisupervised learning multicomponent data classiﬁcation                              akinori fujino naonori ueda      kazumi saito                                 ntt communication science laboratories                                              ntt corporation                        hikaridai seikacho sorakugun kyoto japan                                  afujinouedasaitocslabkeclnttcojp                        abstract                          yx learn mapping multinomial logistic      paper presents method designing semi regression hastie et al  used purpose      supervised classiﬁer multicomponent data  shown discriminative classiﬁers      web pages consisting text link informa achieve better performance generative classiﬁers      tion proposed method based hybrid    provide better generalization performance      generative discriminative approaches trained labeled samples ng      advantage approaches hybrid ap jordan  hybrid classiﬁers pro      proach each component consider indi  posed advantage generative discriminative                                                        approaches raina et al  construct hybrid classi      vidual generative model trained labeled samples                                model introduced reduce effect ﬁers generative model px jth component      bias results labeled sam ﬁrst designed individually component models      ples construct hybrid classiﬁer com combined weight determined basis discrim      bining models based maximum en    inative approach shown experimentally      tropy principle experimental results using hybrid classiﬁer performed better pure generative      three test collections web pages techni discriminative classiﬁers raina et al       cal papers conﬁrmed hybrid approach    hand large number labeled samples      effective improving generalization required wish obtain better classiﬁers gen      formance multicomponent data classiﬁcation   eralization ability practice fairly ex                                                        pensive collect labeled samples class labels    introduction                                       manually assigned experienced analysts contrast  data samples web pages multimodal data usually unlabeled samples easily collected effec  contain main additional information example web tively utilizing unlabeled samples improve generaliza  pages consist main text additional components tion performance classiﬁers major research issue  hyperlinks anchor text main content ﬁeld machine learning semisupervised learning  plays important role designing classiﬁer additional algorithms use labeled unlabeled samples  content contain substantial information classiﬁcation training classiﬁers developed cf joachims   recently classiﬁers developed deal multi nigam et al  grandvalet bengio  fujino et  component data web pages chakrabarti et al  al bseeseeger  comprehensive survey  cohn hofmann  sun et al  lu getoor paper focus semisupervised learning   technical papers containing text citations cohn multicomponent data classiﬁcation sslmc based  hofmann  lu getoor andmusicdata  probabilistic approach present hybrid classiﬁer ssl  text titles brochu freitas           mc problems hybrid classiﬁer constructed ex    supervised learning cases existing probabilistic ap tending previous work semisupervised learning fu  proaches classiﬁer design arbitrary multicomponent jino et al deal multiple components  data generative discriminative hybrid formulation individual generative model each compo  generative classiﬁers learn joint probability model nent designed trained labeled samples  pxy feature vector class label compute labeled samples class boundary provided  yx using bayes rule prob trained generative models far  able class label deal multiple heterogeneous com appropriate trained generative models  ponents assumption class conditional inde high bias result labeled  pendence components class conditional probabil samples mitigate effect bias classiﬁcation  ity density pxjy jth component xj individually performance each component introduce bias cor  modeled brochu freitas  contrast discrim rection model discriminatively combining  inative classiﬁers directly model class posterior probability models based maximum entropy principle berger et                                                    ijcai                                                    al  obtain hybrid classiﬁer bias correc drawn marginal generative distribution pxΘ                                                         k  tion models trained using unlabeled samples pxkΘ model parameter set Θ computed  incorporate global data distribution classiﬁer design maximizing posterior pΘd map estimation ac    consider straightforward applications cording bayes rule pΘd ∝ pdΘpΘ  conventional generative discriminative semisupervised provide objective function model parameter estimation  learning algorithms nigam et al  grandvalet ben  gio  train abovementioned classiﬁers multi        n           j  component data using three test collections web                               xj   θj                                                               Θ      log yn  yn yn   pages technical papers show experimentally                    proposed method effective improving generaliza                                                                        m    k      j  tion performance multicomponent data classiﬁcation es                               xj   θj  pecially generative discriminative classiﬁers              log       provide similar performance                                                                                                                    logpΘ                              straightforward approaches                      pΘ prior Θ obtain Θ value     semisupervised learning                           maximizes Θ using expectationmaximization em                                                                                      multicomponent data classiﬁcation               algorithm dempster et al                                                            estimation Θ affected number unlabeled  multiclass classes singlelabeled classiﬁcation samples used labeled samples words  problems classes ∈kk                                                              model parameter Θ estimated unsuper  assigned feature vector classiﬁer each vised clustering training model using unlabeled  feature vector consists separate components       xj     xj                                    samples useful terms classiﬁcation accu           semisupervised learning settings racy mixture model assumptions true actual  classiﬁer trained labeled sample set dl                                             classiﬁcation tasks mitigate problem weighting pa    nyn unlabeled sample set du        rameter λ ∈   reduces contribution  usually greater require framework labeled samples parameter estimation introduced  allow incorporate unlabeled samples emλ nigam et al  value λ determined  class labels classiﬁers consider straight crossvalidation leaveoneout labeled samples  forward applications conventional semisupervised learn far possible correctly classiﬁed  ing algorithms nigam et al  grandvalet bengio   view incorporating labeled unlabeled  discriminative classiﬁers  samples generative discriminative hybrid classiﬁers discriminative classiﬁers directly model class posterior prob  proposed multicomponent data                    abilities yx classes design discrimina                                                                        generative classiﬁers                            tive model  separation components                                                                                                           generative classiﬁers model joint probability density multinomial logistic regression mlr hastie et al    pxy direct modeling hard arbi class posterior probabilities modeled  trary components consist completely different types                       expwk  ·                                                                 kx                         media deal multicomponent data genera                                                                                                         k expwk ·  tive approach assumption components                                                           wwkwk   set unknown  class conditional independence joint probability model           ·                                                                 xj  θj     model parameters   represents inner product  expressed kΘ                                                                  cf brochu freitas  θk jth com certain assumptions required incorpo                                                 ponent model parameter kth class Θθkjk rate unlabeled samples discriminative classiﬁers  set model parameters note class conditional px modeled classiﬁers minimum entropy                                                    regularizer mer introduced approach  probability model px θk selected according  features jth component class posteriors semisupervised learning discriminative classiﬁers grand  classes computed according bayes rule valet bengio  approach based empir                                                       ical knowledge classes separated                                                                 px θˆk          advantage unlabeled samples asymptotic           ˆ                     Θ                              formation content unlabeled samples decreases classes                                  xj  θˆ                      k    k       overlap conditional entropy used measure class                                                      overlap minimizing conditional entropy classiﬁer        ˆ    θˆ   Θ     jk parameter estimate set class trained separate unlabeled samples possible  label determined maximizes kx Θˆ  applying mer mlr estimate maximize    semisupervised learning generative classi following conditional loglikelihood regularizer  ﬁers unlabeled samples dealt missing class la      n  bel problem incorporated mixture joint prob  log ynxn                                            ∈  ability models nigam et al thatis du                                                                   ijcai                                                                                                                          objective function Θ estimation             λ        kxm logp kxm                                                                                                                       j   n                   k                                                                       xj    θj            θj                                                         fΘ            log yn yn   log             logpw                                                             λ weighting parameter pw  prior                                              gaussian prior chen rosenfeld      θj              θj  employed pw                                     prior                                                          labeled samples classiﬁer obtained    hybrid classiﬁers                                using trained component generative models pro  hybrid classiﬁers learn individual class conditional prob vides class boundary far appropriate                                                    trained component generative models  ability model px θ  jth component directly                                                      high bias obtain classiﬁer smaller bias  model class posterior probability using trained                                                        newly introduce class conditional generative model  component models raina et al  fujino et al                                                        component called bias correction model generative  each component model estimated basis                                                        bias correction models each component belong  generative approach classiﬁer constructed                                    ψj   basis discriminative approach hybrid classiﬁers model family set parameters Ψ jk  class posteriors provided                  bias correction models different Θ                                                        struct hybrid classiﬁer combining trained com              ry   kx Θˆ  Γ                       ponent generative models bias correction models                      j                              mitigate effect bias                    μk             γj                      px θˆk              k        j                         discriminative class posterior design                      μk       xj  θˆ γj                 k      k              deﬁne hybrid classiﬁer using class posterior                                                        probability distribution derived discriminative combi  Θˆ    θˆjkjk parameter estimate set                                                        nation component generative bias correction mod                              xj  θj   component generative models  jkandΓ       els combination provided based maximum en             γj μk  parameter set provides com tropy principle berger et al   bination weights components class biases super principle framework obtaining proba  vised learning cases Γ estimated maximize cross bility distribution prefers uniform models  validation conditional loglikelihood labeled samples satisfy given constraints let rkx target    incorporate unlabeled samples hybrid classiﬁers distribution wish specify using princi  consider simple approach train com ple constraint expectation loglikelihood  ponent generative models using emλ mentioned sec                                                              log px θˆ  respect target distribution rkx  tion  approach incorporate unlabeled sam                                                             equal expectation loglikelihood respect  ples component generative models discrimi                                                                                                                       −    −  natively combine models convenience empirical distribution p˜ δ nk                                                        ynn training samples  approach cascade hybrid ch                                                                                                                                                                                                  p˜xklogpx θˆk    proposed method                                                xk  mentioned introduction propose semi                                                                                                                       xj  θˆ  ∀  supervised hybrid classiﬁer multicomponent data         p˜ rk  logp         bias correction models introduced use unlabeled sam       xk                                                                       ples effectively convenience classiﬁer hy                                                               p˜x   δx − xnn empirical distribu  brid classiﬁer bias correction models hbcm classi                                     xj  ψj  ﬁer section present formulation tion  equation constraint log  bcm classiﬁer parameter estimation method    represented form eq                                                         strict rkx class probability seen                                                        labeled samples    component generative models bias                                          correction                                                    p˜xk     p˜xrkx ∀k        ﬁrst design individual class conditional probability                                                           model component generative model pxjk θ  jth                                                      by  maximizing  conditional entropy hr  component xj data samples belong kth class                                                        −   xk p˜xrkxlogrkx constraints            θj   Θ     jk denotes set model parameters obtain target distribution  components classes formulation com  ponent generative models trained using set la ry  kx Θˆ  Ψ Γ                                                                                 beled samples dl Θ computed using map estimation          μk           γj      γj                                                                    px θˆk px ψk  Θmaxˆ   Θlog pdlΘ  log pΘ assuming Θ                                                           k        j                                                                                               μ              γj        γj  dependent class probability  derive k  px  θˆk  px  ψk                                                     ijcai                                                                               Γγjγjj  μkk set lagrange    experiments  multipliers γj γj represent combination weights  test collections  generative bias correction models jth com  ponent μk bias parameter kth class empirical evaluations performed three test collec                                                                       cora                               distribution rkx Θˆ  Ψ Γ gives formulation tions webkb  andnewsgroups news  discriminative classiﬁer consists trained com datasets used benchmark tests                                                                                                        ponent generative models bias correction models classiﬁers text classiﬁcation tasks nigam et al      according principle solution Γ eq  webkb contains web pages universities dataset  Γ maximizes loglikelihood consists seven categories each page belongs                                                        following setup nigam et al     ˆ                        xn    ∈     rk   Θ Ψ Γ labeled samples    berger   used categories course faculty projectandstu  et al  nigam et al used                                                      dent categories contained  pages extracted  estimate Θ using labeled samples Γ components main text mt outlinks ol inlinks  Θ lead bias estimation Γ leaveone il anchortext each page mt  crossvalidation labeled samples used estimate                                                        text description tags links ol page                         ˆ −n  Γ raina et al letΘ  generative model pa consists web page urls linked page il  rameter set estimated using labeled samples page set web page urls linking page     nyn objective function Γ     anchor text set each page consists text            n                                          descriptions expressing link page                             −n   fΓΨ     log rynxn Θˆ   Ψ Γ  log pΓ  web pages collected il links                                                    dataset mt components removed stop  pΓ  prior Γ  used gaus     words vocabulary words included web page  sian prior chen rosenfeld  pΓ  ∝    removed urls included page ol                                         exp−μkρ   lj exp−γlj − σ  global il components   vocabulary                                                 −n   words mt dataset respectively ol  vergence guaranteed estimated ﬁxed ˆ                          Γ                    Θ        il contained   different urls respectively  ΨsincefΓΨ upper convex function Γ                                                          cora contains  summaries technical pa    training bias correction models                  pers each paper belongs  groups  formulation parameter set Ψ bias correction evaluation used  papers included  groups ar  models trained unlabeled samples reduce bias tiﬁcial intelligencemachine learning extracted three  results labeled samples according components main text mt authors au citations                                                        ci each paper mt consists text distri  rkx Θˆ  Ψ Γ shown eq  class label                                                      bution included papers au set authors  feature vector determined maximizes ci consists citations papers removed vocab  discriminative function                              ulary words authors cited papers each component                     j                                                    way webkb  vocabulary                μk      xj  θˆ γ xj  ψ   γ      gk Ψ                 words  authors  cited papers dataset                                                      news consists  different usenet discussion groups  values gkxΨ classes small each article belongs  groups test col  classiﬁcation result reliable gkxΨ lection used evaluate supervised hybrid classi  classes expect clas ﬁer multicomponent data raina et al  following  siﬁer provide large gkxΨdifference classes setup nigam et al  used ﬁve groups  unseen samples estimating Ψ maximizes sum comp  articles groups extracted  discriminative function unlabeled samples  components main title each article                  m     k                             text description following “subject”       fΨΓ       log   gkxmΨlogpΨ       main content each article title                                                removed stop words vocabulary words included                                                        article   vocabulary words  pΨ prior Ψ incorporate unlabeled                                                        components dataset respectively  samples hybrid classiﬁer directly maximizing        fΨ Γ way mixture model genera  experimental settings  tive approaches joint probability models regarded  discriminative functions                          used naive bayes nb model nigam et al     Γ known estimate Ψ provides lo generative model bias correction model each com  cal maximum fΨΓ initialized value Ψ ponent assuming different features works links cita  help em algorithm dempster et al  httpwwwcscmueduafscscmueduprojecttheo  Γ known value unknown parameter wwwdatawebkbdatagtargz  estimated using eq  Θ Ψ ﬁxed httpwwwcsumassedu˜mccallumdatacoraclassifytargz  estimate Ψ Γ iteratively alternatively httppeoplecsailmitedujrennienewsgroupsnews  Ψ Γ updated convergence criterion met targz                                                    ijcai                                                    tions authors included component independent mentally hbcm classiﬁer useful improving  xj provided featurefrequency vector jth generalization performance multicomponent data clas  component map estimation eqs    siﬁcation labeled unlabeled samples  used dirichlet priors priors nb model param speciﬁcally hbcm classiﬁer outperformed  eters                                                mlrmer classiﬁer labeled    experiments randomly selected labeled samples webkb result mlrmer tends  labeled test samples each dataset overﬁtted labeled samples contrast hbcm  different evaluation sets each dataset random se inherently characteristic generative models  lection  data samples each dataset used overﬁtting problem mitigated  test samples each experiment    labeled samples available overﬁtting  labeled samples used labeled samples training problem solved natural discrimi  classiﬁers webkb cora news respectively native classiﬁer better hbcm classiﬁer  average classiﬁcation accuracy evaluation classiﬁcation performance hbcm better  sets used evaluate methods                emλ labeled samples    compared hbcm    classiﬁer three semi webkb known discriminative approaches  supervised classiﬁers multicomponent data mentioned provide better classiﬁcation performance generative ap  section  nb based classiﬁer emλ nigam et proaches labeled samples ng jor  al  nlr classiﬁer mer mlrmer grand dan  experimental result indicates  valet bengio  ch classiﬁer exam intrinsic limitation preventing emλ achieving  ined three supervised classiﬁers nb mlr hybrid hy high level performance weighting parameter  classiﬁers nb mlr hy classiﬁers trained λ trained discriminatively  labeled samples                                     hbcm   provided better classiﬁcation performance    experiments emλ value weighting pa ch labeled samples webkb  rameter λ set manner mentioned section  hbcm ch classiﬁers constructed based  note experiments selected value hybrid generative discriminative approaches ch  teen candidate values        differs hbcm does contain bias        save computational time correction models experimental result indicates  carefully selected candidate values preliminary troducing bias correction models effective incorporat  experiments                                          ing unlabeled samples hybrid classiﬁer im    mlrmer value weighting parameter λ  proves generalization ability  eq  selected sixteen candidate values ×    −n         −n         −n       ×    ×   carefully conclusion  selected preliminary experiments fair compar proposed semisupervised classiﬁer design method  ison methods value λ determined multicomponent data based hybrid generative dis  ing training samples example using crossvalidation criminative approach called hybrid classiﬁer bias cor  labeled samples grandvalet bengio wede rection models hbcm classiﬁer main idea  termined value λ gave best classiﬁcation sign individual generative model each component  formance test samples examine potential ability introduce models reduce bias results  mlrmer computation cost tuning λ  labeled samples evaluation consid  high                                            ered straightforward applications conventional generative                                                        discriminative semisupervised learning algorithms    results discussion                           classiﬁers proposed multicomponent data conﬁrmed  table  shows average classiﬁcation accuracies experimentally hbcm effective improv  different evaluation sets webkb cora news ing generalization performance multicomponent data  different numbers labeled samples each number classiﬁcation straightforward approaches exper  parentheses table denotes standard deviation imental results using three test collections suggest  evaluation sets dl du represents number la bcm classiﬁer useful especially generative  beled unlabeled samples                            discriminative classiﬁers provide similar performance fu    reported raina et al  fujino et al ain ture work involve applying hbcm multimodal data  supervised cases hybrid classiﬁer useful achiev different generative models employed  ing better generalization performance multicomponent  data classiﬁcation experiments average classiﬁ references  cation accuracy hy similar better berger et al  berger della pietra  nb mlr                                             della pietra maximum entropy approach natural language    examined emλ mlrmer ch hbcm classi      processing computational linguistics –   ﬁers semisupervised cases hbcm classiﬁer brochu freitas  brochu freitas “name  performed semisupervised classiﬁers song” probabilistic approach querying music text  generative classiﬁer performed differently advances neural information processing systems  pages  discriminative classiﬁer webkb conﬁrmed experi – mit press cambridge ma                                                     ijcai                                                    
