         learning strategies opendomain natural language question                                           answering                                                eugene grois         david wilkins            department science beckman institute advanced science                                            technology                              university illinois urbanachampaign                                      egrois dcwuiucedu                                                                       recent systems specifically addressed                     abstract                      task story comprehension  deep read reading     present approach automatically learning comprehension hirschman et al  uses     strategies natural language question answering statistical bagofwords approach matching question     examples composed textual sources    lexically similar sentence story  quarc     questions answers  approach formulates riloff thelen  utilizes manually generated rules     qa problem order inference selects sentence deemed contain answer based     suitably expressive learned representation  combination syntactic similarity semantic     framework draws prior work learning action correspondence semantic categories nouns      problemsolving strategies relational brown university statistical language processing class     learning methods  design project systems charniak et al  combine use     implementing model framework manually generated rules statistical techniques     natural language question answering story bagofwords bagofverb matching deeper     comprehension  finally compare approach semantic analysis nouns  rule three systems     three prior systems present experimental effective identifying sentence containing     results demonstrating efficacy model  correct answer long answer explicit                                                   contained entirely sentence  difficult     introduction                                 deal semantic alternations                                                   moderate complexity  address situations   paper presents approach automatically learning                                                   answers split multiple sentences   strategies natural language question answering                                                   requiring complex inference   examples composed textual sources questions                                                     framework called qable questionanswering   answers  approach focused specific type                                                   behavior learner draws prior work learning action   textbased question answering known story                                                   problemsolving strategies tadepalli natarajan   comprehension  trecstyle qa systems designed                                                    khardon   represent textual sources sets   extract answer document contained fairly                                                   features sparse domain treat qa task   large general collection voorhees    tend                                                   behavior stochastic partially observable world  qa   follow generic architecture suggested                                                   strategies learned sequences transformation rules   hirschman gaizauskas  includes                                                   capable deriving certain types answers particular   components document preprocessing analysis                                                   textquestion combinations  transformation rules   candidate passage selection answer extraction response                                                   generated instantiating primitive domain operators   generation  story comprehension requires similar                                                   specific feature contexts  process reinforcement   approach involves answering questions single                                                   learning kaebling et al  used select   narrative document  important challenge textbased                                                   promote effective transformation rules  rely recent   question answering general posed syntactic                                                   work attributeefficient relational learning khardon et   semantic variability question answer forms                                                   al  cumby roth  evenzohar roth   makes difficult establish match question                                                    acquire natural representations underlying   answer candidate  problem particularly acute                                                   domain features  representations learned   case story comprehension rarity                                                   course interacting domain encode   information restatement single document                                                   features levels abstraction                                                   conducive successful behavior  selection effect                                                   apply                                                 reinforcement                                                   rule base                                                      return fail                                                                                                                                                                                     yes   lookup existing  valid rule                            processing                                     primitive                                           applicable rule   exists                              time                                         ops                                                    acting     yes           yes acting                                               inference                      search                                                                          instantiate                       yes   goal state                                    new rule                             reached                                   generalize                                                                          rule base                                                 start                             extract current                                                                  execute rule abstract                           state features                                                                     domain      learning                           compare goal                                                                               reasoning                                                                               framework          match candidate                            lexically pre                                    intermediate           sentence                                               modify raw text                           process raw text                                    processing         extract answer                                                          layer                                                                                    raw         lexicalized answer                                                     textual                                         raw text   question  answer         domain     figure   qable architecture question answering     achieved fusion abstraction space generalization provided set training instances each   sacerdoti  knoblock  reinforcement consisting textual narrative question   learning elements                              corresponding answer  during performance phase     rest paper organized follows  section  narrative question given   presents details qable framework  section  lexical level answer question generated   preliminary experimental results indicate applying series transformation rules text   promise approach  section  summarize narrative  transformation rules augment   draw conclusions                               original text additional sentences                                                   explicitly contains answer matches     qable – learning answer questions         form question                                                     abstract level essentially process     overview                                   searching path through problem space transforms                                                   world state described textual source   figure  shows diagram qable framework                                                    question world state containing appropriate   bottommost layer natural language textual domain                                                    answer  process efficient learning answer  represents raw textual sources questions answers                                                    generation strategies  strategies store procedural   intermediate layer consists processing modules                                                   knowledge regarding way answers derived   translate raw textual domain topmost                                                   text suggest appropriate transformation rules   layer abstract representation used reason learn                                                   each step answergeneration process  strategies     framework used learning answer                                                   procedural knowledge stored acquired   questions actual qa task  learning explaining deducing correct answers training phrase type    comments   examples  framework’s ability answer questions              “who” nominal “what”                                                    subj   tested respect kinds documents             questions   seen during training kinds questions practiced verb event “what” questions   answering interface world domain sensors              “who” nominal “what”                                                    dirobj   operators                                                       questions     sections discuss lexical pre                     “who” nominal “what”                                                    indirobj   processing representation features relations          questions                                                                         descriptive “what” questions   qable framework  section  look elabsubj   structure transformation rules             kind   instantiated  section  build elabverbtime    information details strategies elabverbplace    learned utilized generate answers  section  elabverbmanner    explain candidate answers matched question elabverbcause  “why” question                                                                          “why” “what for”   extracted                                   elabverbintention                                                                          question                                                                         smooth handling undefined     lexical preprocessing                      elabverbother                                                                         verb phrase types   levels syntactic semantic processing               descriptive “what” questions                                                    elabdirobj   required order generate structures facilitate higher       kind   order analysis  currently use montytagger             descriptive “what” questions                                                    elabindirobj   theshelf pos tagger based brill  pos                  kind   tagging  tier utilize named entity ne            wherewhenhow   tagger proper nouns semantic category classifier verbcompl questions concerning state   nouns noun phrases coreference resolver          status   limited pronominal anaphora  taxonomy table   phrase types used qable framework   semantic categories derived list unique   beginners wordnet nouns fellbaum     parallel stage identifies phrase types  table  raw textual input tags generated pre  gives list phrase types currently use processing modules   categories questions each phrase type answer  lexical sentence represented sequence words    near future plan utilize link parser boost 〈w w… wn〉 wordwi word binds particular   phrasetype tagging accuracy  questions word position sentence  kth sentence   classifier identifies semantic category passage given unique designation sk  simple   information requested question  currently functions capture syntax sentence  sentence   taxonomy identical semantic categories  main main verb controlling element   future expanded accommodate sentence recognized mainwm sk  parts speech   wider range queries  separate module reformulates recognized function pos poswi nn   questions statement form later matching poswi vbd  relative syntactic ordering words   answercontaining phrases                      captured function beforewi wj  applied                                                   recursively beforewi beforewj wk generate     representing questionanswering domain entire sentence starting arbitrary word usually   section explain features extracted sentence main  each word wi  sentence                                                   insentencewi si ⇒ mainwm sk ∧ beforewi wm ∨                                                   beforewm wi  consecutive sequence words    instantiate rule                               phrase entity simply entity  given designation ex     given                                         declared binding function entityex ne    • set primitive operators                   named entity entityex np syntactic group    • current state specification                  type noun phrase  each phrase entity identified    • goal specification                           head headwh ex say phrase head                                                   controls entity  phrase entity defined headwh                                                     ∧             ∧ … ∧    select primitive operator instantiate    ex  inphrasewi ex    inphrasewj ex     bind active state variables  goal spec existentially wish represent higherorder relations                                                   functional roles semantic categories  functional       quantified condition variables                                                     dependency pairs words encoded     execute action domain                                                   example subjwi wj auxwj wk  functional groups     update expected effect new rule according represented just like phrase entities  each assigned       change state variable values                                                   designation rx declared example funcrolerx subj                                                   defined terms head members    figure   procedure instantiating transformation individual words composite entities  semantic  categories similarly defined set words relevant attributes world state   represents    syntactic phrase entities – example semcatcx expected effect action   inductively acquired            ∧             ∧             ∧   person    headwh cx  poswh nnp  wordwh prior applications rule  example     “john”       semantically sentences treated events defined ∧    ∧          →                                                         verbs  multisentential passage represented                                                                        −     −     −         tying member sentences relations         add  word   word    verbs  declare relations – seq cause                                                     indicates phrase “w w”    seq relation sentences seqsi sj ⇒                                                    text operator expected attach end    priormainsi mainsj defined sequential   ordering time corresponding events  cause generating phrase “w w”   rule                                                    effective given state  match    relation causesi sj ⇒ cdepmainsi mainsj defined   second event causally dependent   system’s goal specification state                                                      instantiated rule assigned rank composed      primitive operators transformation rules                                                       •   priority rating    general starts procedural                                                       •   level experience rule    knowledge domain transformation rules  •    equipped  primitive operators confidence current parameter bindings    define basic actions domain  primitive operators component priority rating inductively    existentially quantified  activation condition acquired measure rule’s performance previous    existence condition – minimal binding instances  second component modulates priority    condition operator applicable given state  rating respects frequency use measure                                              primitive operator form → aˆ   component captures uncertainty inherent    existence condition aˆ  action implemented underlying features serving parameters rule     domain  example primitive operator       rank rule computed following function                                                          primitiveop      ∃ wx wy →  addwordafterwordwy wx                                                              rank  × ×  log     primitive operators delete words manipulate entire     phrases  figure  lists primitive operators  note each time new rule added rule base    primitive operators act directly syntax attempt combine similar existing rules    domain  particular manipulate words phrases  produce general rules having wider relevance    primitive operator bound state domain applicability                                                       given rule ∧  ∧  ∧ →  covering set    constitutes transformation rule  procedure         ca cb  gx    instantiating transformation rules using primitive operators                                                    example instances     rule    given figure   result procedure                                                                                                                             ∧  ∧   ∧   →   covering set examples     universally quantified rule having form ∧ →    cb cc                                                                                     ∧ →   represent action world add general rule cb  strategy     internal predicate  represents necessary condition                                                    new rule  consistent   addition   rule activation form conjunction                                                                       bind state literal cb  active                                                     hypothesis represented triggering condition            ∃ wx wy →  addwordafterwordwy wx likely overgeneralization target concept                                                     means rule  bind states erroneously           ∃ wx wy →  addwordbeforewordwy wx                                                                 rules bind state compete          ∃ wx →  deletewordwx                                                    state better rule           ∃   →  addwordafterphrasep                                                                                  preempted          ∃ wx py →  addwordbeforephrasepy wx                                                      generating answers          ∃ px wy →  addphraseafterwordwy px          ∃   →  addphrasebeforewordw   returning figure  note abstract level                                            process answer generation begins extraction            ∃    →           px py   addphraseafterphrasepy px features active current state  features represent            ∃ px py →  addphrasebeforephrasepy px lowlevel textual attributes relations                                                    described section                                                             immediately reading current state     figure   primitive operators used instantiate checks goal state   goal state state     transformation rules                          corresponding textual domain representation contains explicit answer right form match questions  qable’s preprocessing stage analyzes text respect   abstract representation say state various syntactic semantic types  addition   goal constraints satisfied             supporting abstract feature generation tags     current state goal state used analyze text lexical level  question   inference required  inference process terminates marked elabverb quantitydistance wrb   actual answer identified matching technique rb far verb vbz subj action dt nn   described section  extracted         drive verbcompl nnp place chicago      current state goal state reformulated statement form elabverb   processing time available qable passes state quantitydistance   verb vbz subj action dt   inference engine  module stores strategies nn drive verbcompl nnp place chicago    form decision lists rules  given state each goal sentence syntactic   strategy recommend rule execute  semantic analysis matches reformulated   each strategy rule decision list  question’s closely possible  example text   selects rule highest relative contain sentence “the drive chicago  hours”   rank recommends transformation rule corresponding analysis subj action dt nn   applied current state                drive verbcompl nnp place chicago verb     valid rule exists executed domain  vbz verbcompl quantitytime cd  nns hours    modifies concrete textual layer  point pre notice elements candidate answer   processing feature extraction stages invoked new match corresponding elements question   current state produced inference cycle begins exception semantic category elabverb   anew                                           phrase  likely answer seeking      valid rule recommend qable text contain second sentence “the drive chicago   passes current state search engine se  se  miles” analyses subj action dt nn   uses current state set primitive operators drive verbcompl nnp place chicago verb   instantiate new rule described section  rule vbz verbcompl quantitydistance cd  nns   executed domain iteration miles  case elements match   process begins                                 counterparts reformulated question  second     primitive operators remain applied sentence matched correct answer high   current state se instantiate new rule  confidence   point search goal state proceed   processing terminates qable returns failure   experimental evaluation     training phase se   instantiates new rule rule generalized   experimental setup   existing rule base  procedure attempts create evaluate approach opendomain natural language   general rules applied unseen example question answering remedia corpus    instances                                      collection  children’s stories provided remedia     inferencesearch process terminates  publications reading comprehension    successfully reinforcement learning algorithm comprehension each story tested answering   applied entire rule searchinference tree  specifically questions     rules solution path receive positive reward rules remedia corpus initially used evaluate   fired solution path receive negative deep read reading comprehension hirschman et   reinforcement                                  al  later systems including quarc                                                   riloff thelen  brown university     candidate answer matching extraction   statistical language processing class project charniak et   discussed previous section goal state al      generated abstract representation corresponds corpus includes answer keys  answer   textual domain representation contains explicit key contains annotations indicating story sentence   answer right form match questions  lexically closest answer published answer   candidate answer present original text key autsent  second answer key contains sentences   generated inferencesearch process  case human judged best answer each question   answercontaining sentence humsent  examination keys shows   actual answer extracted  accomplished reliable  trained tested using humsent   answer matching extraction procedure       answers  compare results humsent     step procedure reformulate results prior systems  remedia corpus   question statement form  results sentence approximately  questions lack answer    containing slot information queried  following prior work questions annotated   example “how far drive chicago” answers considered       “the drive chicago ”  recall 
