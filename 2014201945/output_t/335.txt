improving anytime pointbased value iteration using principled point selections                        michael james michael samples dmitri dolgov                                           ai robotics group                             technical research toyota technical center usa                    michaeljames michaelsamples dmitridolgovtematoyotacom                          abstract                          algorithms choose additional points signiﬁcantly im                                                        prove resulting approximation value function      planning partiallyobservable dynamical sys   improvement potentially beneﬁcial ways      tems pomdps psrs com          computation time reduced      putationally challenging task popular approx    fewer points computation performed      imation techniques proven successful    beneﬁt offset      pointbased planning methods including point additional time required select new points po      based value iteration pbvi works ap  tential beneﬁt reduced memory storage smaller sets      proximating solution ﬁnite set points points currently solution systems require      pointbased methods typically anytime   large numbers points storage beneﬁt      algorithms initial solution obtained important size problems increases      using small set points solution points required      incrementally improved including additional      points introduce family anytime pbvi al      gorithms use information present cur  background      rent solution identifying adding new points planning methods developed partially      potential best improve observable discretetime ﬁnitespace dynamical systems      lution motivate present different meth actions chosen set observations      ods choosing points evaluate perfor set rewards set exactly action      mance empirically demonstrating highquality observation reward timestep—planning al      solutions obtained signiﬁcantly fewer gorithms attempt ﬁnd policy maximizes long      points previous pbvi approaches             term discounted reward discount factor γ ∈                                                            pointbased planning methods suitable    introduction                                       classes models represent dynamical  pointbased planning algorithms pineau et al  spaan systems wellknown partially observable markov deci  vlassis  partiallyobservable dynamical sys sion processes pomdp newer predictive state rep                                                                                        tems popular relatively good resentation psr singh et al   sake famil  formance implemented anytime iarity use pomdps noted  algorithms suggested pineau et al methods presented planning methods   anytime pointbased planning algorithms dynamical systems just easily applied                                                                                  beneﬁt signiﬁcantly principled selection points psrs james et al  details  add    provide methods using information col  pomdps  lected during value iteration speciﬁcally characteristics pomdps models dynamical systems based  value function choose new additional points show lying latent variables called nominal states ∈satany  properties value function allow computation time step agent nominal state taking  upper bound potential improvement gain resulting action ∈athe agent receives reward rs  addition single point argue addition function state action transitions new state  points maximal gain produces good approximations s according stochastic transition model prss  value function argument empirically ver receives observation ∈oaccording stochastic ob  iﬁed deﬁne optimization problem ﬁnds servation model pros compactness deﬁne                                                                                   point maximal gain given region   vector ra rasrs    new approaches empirically compared tradi  tional anytime pointbased planning results show notation ve vector refers value entry                                                    ijcai                                                                                                                                                                                                                      agent does directly observe nominal state ga  ra  γ argmaxgaoi gao pbvi  maintain sort memory fully charac backup applied each point  follows  terize current state pomdps typically                                                        function   onesteppbvibackup             using belief state probability distribution nomi                             sold    nal states belief state summarizes entire history  snew  ∅  computing probability each nominal state                                                        each   ∈  compute   α   backupb  bs computation new belief state ba reached af              ∪  ter taking action getting observation belief state set snew  snew α  given following update                     return                                                                      new                                                     pros prs abs          bo                                        perseus each iteration current set α vectors                       proa                     transformed new set α vectors randomly choos  equation used agent interacts dynami ing points current set applying backup  cal maintain agent’s current belief state operator process                                                        function   onestepperseusbackup                pointbased value iteration algorithms                                                   sold                                                                      ∅  pointbased planning algorithms pbvi perseus  snew            lists  partially observable dynamical systems perform planning nonimproved  points  constructing approximation value function  sample uniformly  random      updating value function point valuefunction compute α  backupb  approximation nearby points improved ba                                                                α  ≥ vnb add    α  snew  sic idea calculate value function gradient                                                                                add                         small number points value function   α  argmaxα   ∈sold α     snew  points “carried along” pointbased ap                                                          compute     ∈  vnb − vnb  proach uses fraction computational resources  construct approximate value function compared  return  snew   exact methods                                              step     main sets vectors used set points                                                          given basic nonanytime algorithms  ∈  each belief state vector set                                                      pbvi perseus  represents approximate value function vn step  value function piecewise linear convex function function basic  lief states deﬁned upper surface vectors α ∈ sn  value belief state                            pickinitialpoints                                                                  minimalalpha                                                       vnbmaxb    α                           α∈sn                           sn    onestepbackupp     sn    bellman equation used deﬁne update  increment goto    value function                                                     pickinitialpoints typically uses random walk                                       vnbmax    ra  γ   pro bvnba            distancebased metrics choose initial set points                                                               function minimalalpha returns α vector en                                                                               −    maxbt       γ   proa bmaxbot αi           tries equal minr∈r γ algorithm stop                                                                  α ∈sn                  condition value function number                                                                            iterations algorithm easily expanded                 maxb      ra                                      time algorithm modifying pickinitialpoints start         a                                          small set initial points including step iteratively                                                        γ    max     pros   prs absαis                                                       expands set current points  typically having cur             α ∈sn                                                   rent set points result better approximation                                                                                value function require computation    maxb      ra  γ    max gao                      gi                            update anytime versions algorithms                        ao                                                        function   anytime                                                                pickinitialpoints                gaos    pro aprs aα                      s                                       minimalalpha                                                             ifreadytoaddpoints           ∪  α ∈ sn vectors deﬁned  lead computational savings computation α vectors bestpointstoaddfindcandidatepoints  vnb uses socalled backup operator         sn    onestepbackupp     sn                                                 backupb  argmax ga                increment    goto                                                          gaa∈a                                                    ijcai                                                       three new functions introduced anytime points lead points effect  algorithm readytoaddpoints determines discounted improving parts value function  algorithm adds new points ﬁndcandidatepoints gain deﬁned  ﬁrst step determining points add best                                                                                                                                    −  pointstoadd takes set candidate points gbbmaxrb aγ       pro av ba                                                                      determines set points add section  present                       variations functions including main contribu     bt α −  tions methods determining best points add based  examination value function                 α    backup note measure includes                                                        immediate expected reward quantity    incremental pbvi perseus                       previously included computation α vector                                                        measure make use cached ga vectors equation   section present methods ﬁnding best points inexpensive computational standpoint  add given set candidate points cases following section different measure gain  best points subset candidates stronger theoretical justiﬁcation comes  cases new points outside set original candidates expensive higher computational cost  identiﬁed best cases make use  scalar measure called gain point way  gain based valuefunction bounds  evaluate useful point show second measure gain introduce uses fol  current approximate value function used compute lowing insight ﬁrst illustrate  useful measures gain used informed nominal states extend intuition threestate sys  methods point selection                           tem general calculation num    point belief space gain gb estimates ber states value function piecewise linear convex  value function improve problem function consisting nominal states upper sur  construct measure gain identiﬁes points face set lines deﬁned α vectors figure  improve approximation value func running example vectors deﬁne lines corre  tion complex problem primarily changing spond points interior regions correspond  value function point affect value ing lines maximal points intuitively  points seen examining backup value function relevant points  operator equation  changes propagate relevant increasing distance point  arbitrary number time steps changes points assume value given α vector correct  propagate points exactly identifying corresponding point consider inclusion new  points best gain computationally expen α vector new point point figure value  sive measures gain used        function point correct new α vector    present different measures gain based change value greater current value  examining backup operator written gb holds new α vector point  derived ﬁnding upper bound gain upperbounded line value  point use linear programming com value gain difference  pute gain written glp                          upper bound current value    given deﬁnitions gain present differ case three nominal states analogous pla  ent methods identifying points add simplest nar solution upper bound simple compute  method detailed section  takes candidate points figure visualize problem consider  ders according gains selects mobile plane pushed upward point  sophisticated method leverages informa constrained existing  tion present computing glp identify points points deﬁne valuefunction surface  higher gain candidate points returns dif figure example depicted figure  ferent points original candidates plane come rest points deﬁned loca  selection methods implemented section  fol tions belief space values  lowing detailed discussion sections   value plane gives tightest upper bound  measures gain                                     value add new α vector                                                        gain computed manner    gain based onestep backup                    state case ﬁnding abovedescribed plane  gain gb measures difference current straightforward difﬁcult higher  value point value according α vector com dimensional spaces difﬁculty higher dimen  puted onestep backup equation  mea sional spaces — contrast state case  sure does strong theoretical support intuitively minimal upper bound deﬁned points imme  onestep difference point large diately left right new point — selecting  improve approximations nearby points signiﬁ points deﬁne minimal upperbounding surface  cantly improvements positive effects nontrivial task problem formulated                                                    ijcai                                                        value    glp               xb                      ps                                                                                     figure  value function dynamical nominal states note ps− ps axis ps   unnecessary value function deﬁned α vectors corresponding points gain glp point   difference upper bound deﬁned line v avb current value bc value function   three nominal states value function deﬁned α vectors corresponding points   gain glp point difference tightest upper bound deﬁned plane v avbvc   current value tightest upperbound plane produced ﬁrst lp findgainandregionforpoint x   best point produced second lp findbestpointforregion bounding region     linear program lp lp table  variables augmented lp scalar   refer findgainandregionforpointb         weights wwm deﬁne points ∪u form     given candidate belief point current scalar value bounding region Γb   current points bb  current scalar values vv                                                       finding best point bounding region   points value vectors ααn minimiza   tion lp ﬁnds tightest upper bound vub wivi given gains glp candidate points possible   used compute gain glp  choose points add based criteria draw   vub − words minimization lp works add multiple points   ﬁnding set points set points non bounding region Γ waste resources ap   zero weights wi expressed convex proximating value function multiple points just   linear combination points ii value func work   tion deﬁned plane rests valuefunction points point region highest   points minimal surface set gain address issues introduce lp called   points nonzero weights bounding region findbestpointforregionΓ table  takes bounding   Γbbiwi     point property region ﬁnds point interior region maximal   point interior bounding regions glp  note region contain unit basis points al   play important role section      lowing new point exterior current set points                                                           lp takes input bounding region Γb     subtle issue regarding lp     points potential interior set bbl  scalar values vvl points value   current points α vectors deﬁned fact early vectors ααn optimization variables scalar   process points useful weights wwl vector bnew  point   points outside convex hull current points scalar value vnew value bnew   problematic want consider points process ﬁnding best points add lp   correspond relatively poorly approximated areas unique regions running ﬁrst lp findgainan   value function interior subset dregionforpoint candidate points   current points     resolve issue introduce set unit basis  using gains pbvi perseus   points points components equal  deﬁne incremental algorithms pbvii   remaining entry equal  standard orthonormal basis perseusi using gains gb glp  linear   belief space augment set current belief programs referencing anytime algorithm   points lp include unit basis points bbm  explored various possibilities readytoaddpoints   ∪ values vj points  computed bestpointstoaddc ﬁndcandidatepoints   vj  backup bj ∀bj ∈   points variations exist paper presents   updated onestepbackup points  promising                                                     ijcai                                                      table  linear programs used compute gain region Γb point given value function ii ﬁnd  best point given region Γ given value function     findgainandregionforpointb                       findbestpointforregionΓ                                                                                   minimize         wivi                              maximize           wivi − vnew                                                                                 given     bvbbmvvmααn            given     bblvvlααn     variables     wwm                             variables    wwlvnewbnew                                          ≥    constraints        wibi     wivi            constraints   bnew     wibi  wi ≥  ∀i ∈                                                                                                            ≥   ∀  ∈                       wi    wi                               wi    vnew ≥ αjbnew  ∀j ∈                                                                          computationally cheap possibilities readytoadd three types ﬁrst type performance vs number  points add points ﬁxed number iterations points measure effectiveness point selection  ii update process approximately converged second type performance vs number iterations  maximal onestep difference value points type performance vs cpu time measure  threshold maxb∈p vnb − vnb ≤  use principled point selection affects overall  explored methods ﬁndcandidatepoints formance type shows impact additional  ﬁrst list points onestep successors time incurred pointselection process graphs                        ∈     points  set ba  second method show performance xaxis resource  random walk use distance threshold choose points iterations time used achieve performance  points just pickinitialpoints               yaxis comparing algorithms respect    gains discussed previous section given resource better algorithm lower  used bestpointstoaddc gain gb orders candi  examination ﬁrsttype graphs shows lp  date points chosen gain glp  based perseusi did good job identifying best points  candidate points deﬁne set unique bounding regions add resulting policies produced better performance  Γbb ∈ each region lp findbestpointfor fewer points methods                                       region returns best candidate point  candidate three problems onestep backup perseus                            points ordered glp  chosen did signiﬁcantly better baseline choosing  compare methods baseline anytime algorithm points metric goal ﬁnding useful points  used standard random walk method choosing ﬁrst achieved promisingly largest problem  points exceeded distance threshold          hallway algorithms used signiﬁcantly fewer points                                                        achieve good performance graphs show    experiments                                        choosing good points does translate                                                        faster algorithm problem network versions  evaluate principled point selection algorithms perseusi faster baseline  ducted testing set standard pomdp domains three problems performance closely competitive  problems smalltomid sized fourth hallway slightly worse overhead incurred identifying  larger domain deﬁnitions obtained cassan good points result optimal fact  dra  tested three algorithms baseline anytime signiﬁcant speedups problem combined  perseus using distancebased metric ii onestep backup point selection results leads draw conclusion  perseusi using gb iii lpbased perseusi using glp method promising needs investigation  lps ﬁnding best points           development    three algorithms used convergence condition   −  readytoaddpoints algorithms net  work shuttle added  points time references  hallway added  points time choos                                                        cassandra  cassandra tony’s  pomdp  page  ing points using lps did add  fewer httpwwwcsbrowneduresearchai pomdpindexhtml   unique regions onestep backup perseus  used successor metric ﬁndcandidatepoints izadi et al  masoumeh izadi ajit rajwade doina  easily integrated little overhead lp precup using core beliefs pointbased value iteration th  based perseusi used random walk distance met international joint conference artiﬁcial intelligence   ric introduced overhead case results james et al  michael james satinder singh  averaged  runs performance metric michael littman planning predictive state representa  average discounted reward given initial belief state tions  international conference machine learn  results presented graphs figure  ing applications                                                     ijcai                                                     
