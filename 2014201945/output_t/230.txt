                      locating complex named entities web text                            doug downey matthew broadhead oren etzioni                                               turing center                             department science engineering                                         university washington                                                box                                           seattle wa  usa                               ddowneyhasturetzionicswashingtonedu                        abstract                          word capitalized “united kingdom”                                                        far difﬁcult consider phrases      named entity recognition ner task      locating classifying names text previous companies intel microsoft      work ner limited small number pre    ii companies procter gamble      deﬁned entity classes people locations ﬁrst phrase names entities “intel” “mi      organizations ner web far  crosoft” second names single entity “procter      challenging problem complex names    gamble” distinction readily appar      ﬁlm book titles difﬁcult pick ent text similar situations occur ﬁlm titles      precisely text web contains  “dumb dumber” book titles “gone wind”      wide variety entity classes known “war ” challenging prob      advance handtagging examples each   lem precisely determine boundaries entity      entity class impractical                      names text refer problem entity      paper investigates novel approach   limitation problem entity delimitation does deter      ﬁrst step web ner locating complex named      entity’s class subproblem solution      entities web text key observation necessary sufﬁcient successful ner      named entities viewed species multi fundamental challenge standard supervised      word units detected accumulat   ner techniques set entity classes known      ing ngram statistics web corpus     advance web applications including information      show statistical method’s score  extraction etzioni et al  question answering banko      higher supervised techniques includ  search pasca  impractical      ing conditional random fields crfs     hand tag elements each entity class train supervised      ditional markov models cmms applied        techniques instead forced create training cor      complex names method outperforms     pus entities type labeled “entity” non      cmms crfs  entity classes ab       entities labeled solution problematic      sent training data finally method  cause ner techniques rely orthographic contextual      outperforms semisupervised crf          features vary widely entity classes refer                                                        problem unseen classes problem                                                          paper introduces lex method addresses    introduction                                       delimitation unseen classes problems utiliz  named entity recognition ner task identifying ing ngram statistics computed massive web corpus  classifying names text previous work ner lex does address entity classiﬁcation problem lex  carried small number predeﬁned classes based observation complex names tend  entities—for example named entity task deﬁnition multiword units mwus sequences words  message understanding conference identiﬁed three meaning determined examining constituent  classes person organization location     gr   parts da silva et al  mwus identiﬁed  ishman sundheim  web contains high accuracy using lexical statistics frequency words  variety named entities fall outside categories phrases corpus da silva lopes   cluding products books ﬁlms diseases programming uncapitalized words entities tend come  languages nationalities events  small set terms “of” “and” sufﬁcient simply    ner requires ﬁrst locating entity names text ignore terms appear distinct entities  named entities easy detect english each “microsoft intel”                                                    ijcai                                                      lex  requires single threshold easily esti formally lexical method denoted lexisde  mated using small number handtagged examples drawn ﬁned thresholds τ δ function fsss  entity classes lex does require mapping three strings numerical value function  tagged corpus contains relevant lexical items hand fsss measures degree concatenated  ful times order compute accurate lexical statistics string sss occurs “more chance” – col  lex wellsuited web entity classes location identiﬁers exist mwu literature  known advance entity names complex measures experiment threshold  massive untagged corpus readily available         τ value fsss exceed order string    lex semisupervised learning method addition sss considered single lastly capitalized  conditional random fields crfs lafferty et al  word’s appearances come beginning sentence  conditional markov models cmms mccallum et al δ time assume heuristi   compare crfs augmented untagged cally set value δ  set τ using training data  data using cotraining selftraining ﬁnd lex described section   outperforms semisupervised methods  given sentence function fsss thresh                                                    olds τ δlex proceeds follows    contributions follows                      initialize sequence names nnnm      introduce insight statistical techniques equal maximal contiguous substrings      ﬁnding mwus employed detect entity names     consist entirely capitalized words elements      class classes unknown advance ordered left right ﬁrst     demonstrate experimentally lex surpris    word appears capitalized corpus      ingly simple technique based insight sub beginning sentence δ time omit      stantially outperforms standard supervised semi        supervised approaches complex names rarely   consecutive pairs evalu      sidered ner titles ﬁlms books  ated                                                                                                              show preliminary results demonstrating lex     choose unevaluated pair names nini                                                                 minimum      leveraged improve web applications reducing                        error rate web information extraction niwini τ wi uncapital       case                                        ized phrase separating ni ni wi                                                                 three words length     based analysis limitations lex pro                                                                 • replace ni ni single      pose enhanced algorithm lex attaches                                                                   niwini      common preﬁxes sufﬁxes names uses addi      tional lexical statistics detect spurious collocations  measures collocation      lex offers additional  performance improve      ment lex                                    function fsss intended measure                                                        string sss occurring text single    section  describes lex section  presents experi                                                        stead distinct names separated string  mental results comparing lex previous supervised                                                        functions consider based standard  semisupervised methods section  presents analysis                                                        collocation measures pointwise mutual information pmi  lex’s limitations experimental evaluation                                                        symmetric conditional probability scp da silva  lex section  considers related work paper                                                        lopes  deﬁne collocation function cka  cludes discussion future work                                                        strings                                                                                   pabk     lex  method locating names                                 cka                                                                                                        papb  lexical statisticsbased approach use locating                                                                    names based key intuition names type probability string occurring  multiword unit mwu broadly algorithm assumes corpus  contiguous capitalized words gives scp                                                                                            mixed case phrase beginning ending capital purposes equivalent pmi pmi scp  ized words single mwu—that deﬁned arguments variety techniques  appears corpus sufﬁciently frequently employed extend binary collocation measures  chance capitalized words start sentences nary case example averaging binary  considered names appear capitalized sufﬁciently partitions da silva lopes  computing  beginning sentence              measure split highest probability schone                                                        jurafsky  generalize measures fol    techniques achieve close  accuracy lowing simplistic fashion  simple names                                                               “capitalized” words beginning capital precisely pmia blogca mwu iden  letter text including punctuation digits “un tiﬁcation consider ordering collocation measure  capitalized”                                         monotonic log function ignored                                                    ijcai                                                                               pabck                                               recall  precision                gka                                                 papbpc                      lexpmi                                                                                   lexscp                     pmi function three variables  scp function three variables              table  performance lex using collocation measures                                                        pmi scp scp outperforms pmi     experimental results  section describes experiments web text left right boundaries precision deﬁned fraction  compare lex’s performance supervised semi putative entities suggested algorithm  supervised learning methods experiments web cor bona ﬁde entities test set contains proper  pus tricky scale diversity entity subset entities contained test text pur  classes encountered begin carefully describing pose computing precision ignore entities identiﬁed  experimental methodology used address difﬁculties algorithm overlap element                                                        test set    experimental methodology  classes named entities difﬁcult delimit pre  pmi versus scp  cisely example nested entities like phrase “director ﬁrst experiment investigates candidate col  microsoft” considered single entity job ti location functions pmi scp effective use  tle entities job title company lex method experiments follow  make evaluation objective possible performed threshold τ set value maximizes performance  experiments entities classes bound training set using simple linear search  aries names relatively unambiguous actor  book performance each metric difﬁcult cases shown  company film                                   table  scp metric outperforms pmi consider    lex method requires massive corpus order ac able margin performance difference merely  curately compute ngram statistics make experi sequence method acquiring thresholds perfor  ments tractable approximated corpus  mance discrepancy essentially unchanged each threshold  sentences automatically selected likely contain named chosen maximize performance test set  entities classes                focusing difﬁcult cases scp metric    formed training set containing total  sen outperforms pmi nondifﬁcult cases   tences evenly distributed classes vs   training sets manually tagged entities result large performance difference lexpmi  ing total  tagged examples formed test set lexscp extreme version similar results exhib  handtagging sample  entities each class ited measures mwu identiﬁcation schone  cause lexical approach requires estimates probabili jurafsky  case pmi performs poorly  ties different phrases ignored entities appeared task wellknown property returning dispropor  fewer ﬁve times corpus ensure tionately low values frequent items manning  reasonable restriction queried google schutze¨  pmi fails correctly join   original test entities appeared  distinct frequent names test set fact names  web pages requirement entities appear pmi fails join  appear corpus  ﬁve times corpus minor restriction given mas  times – versus  scp  sive size web corpus lexical statistics method like remainder experiments lexical method em  lex likely effective entities      ploys scp function referred simply lex    separated test set “easy” “difﬁ  cult” cases precisely easy cases cor  comparison ner approaches  rectly identiﬁed baseline method simply ﬁnds maxi experimented following ner methods  mal substrings contiguous capitalized words difﬁcult • svmcmm – supervised conditional markov model  cases simple baseline fails ﬁ trained probabilistic support vector machine  nal test set contained  difﬁcult cases  easy cases • crf – supervised conditional random field ap  suggesting difﬁcult entity names quite common  proach  web                                                 • caps  – baseline method locates maximal    test phase ran each methods sen tiguous substrings capitalized words  tences test set recall deﬁned fraction test • man – unsupervised recognizer based  set entities algorithm correctly identiﬁes manuallyspeciﬁed rules method taken                                                              location subcomponent knowitall web     downloaded sentences web matching patterns like formation extraction etzioni et al   “actors as” “and ﬁlms”    constructed training sets tagging entities conditional random fields crf lafferty et al  target classes actor book company film –  conditional markov models cmm mccallum  approach decreased performance supervised approaches et al  state art supervised approaches                                                    ijcai                                                                              recall  precision                                   recall  precision       svmcmm                                    svmcmm                              crf                                       crf                                 man                                       man                                 lex                                  lex                        table  performance difﬁcult cases lex’s score table  performance unseen entity classes difﬁcult   higher nearest competitor svmcmm       cases lex outperforms nearest competitor svmcmm                                                                                    recall  precision                                   recall  precision       svmcmm                                    svmcmm                              crf                                       crf                                 man                                       man                                 lex                                       lex                                 caps                                  caps                         table  performance easy cases methods perform table  performance unseen entity classes easy  comparably near perfect performance caps base cases caps outperforms methods small margin  line caps outperforms lex man              performing  better nearest competitor man    text delimitation tasks crf cmm implementations learned value τ factor  direction resulted  taken minorthird text classiﬁcation package lex outperforming svmcmm  dif  cohen  obtained settings each algorithm ﬁcult cases altering value δ    crossvalidation training set chose train resulted lex outperforming svmcmm   cmm   using support vector machine svmcmm  difﬁcult cases  maximum entropy approach mccallum et  al  svmcmm substantially outperformed  unseen entity classes  maximumentropy classiﬁer crossvalidation su argued introduction web applications  pervised classiﬁers create feature vectors each word target entity classes known advance poses  features include lowercase version word ortho particular problems standard ner approaches rely  graphic pattern word “xx” “bill” “” textual cues vary widely entity classes  “” analogous features tokens small experiment simulate performance each  window word size selected cross valida entity delimitation methods unseen entity classes specif  tion                                                ically evaluating performance entity class    deﬁnition caps baseline performs perfectly remove training set sentences containing enti  easy entity names does correctly delimit difﬁcult ties class results experiments difﬁcult  entity names caps equivalent step  lex algo cases shown table  lex outperforms ap  rithm section  lex includes caps initial proaches performance  higher  step handle easy names algorithms differ best competing method svmcmm precision  easy names lexical statistics computed step  recall differences lex svmcmm difﬁcult  lex indicate easy names delimited caps ought cases each statistically signiﬁcant fisher  concatenated consider example phrase “as exact test previous experiment methods  intel microsoft have” caps delimit form relatively easy cases table   phrase’s names correctly lex potentially  limit incorrectly example outputting phrase  semisupervised comparison  “intel microsoft” single practice sit lex outperforms supervised ner methods leveraging  uation occurs infrequently table              lexical statistics computed large untagged corpus    performance different methods difﬁcult cases augmenting tagged examples untagged data known  shown table  overall lex’s score  semisupervised learning increasingly popular approach   higher nearest competitor svmcmm text processing tasks untagged data plenti   precision differences lex svm ful section compare lex previous semi  cmm signiﬁcant recall differences supervised algorithms  signiﬁcant fisher exact test course create semisupervised baseline task aug  performance easy cases important shown mented supervised classiﬁers previous experi  table  methods perform comparably easy cases ments employ untagged data recent work  scores  higher range          semisupervised text segmentation ando zhang     performance lex fairly robust parameter experimented semisupervised approaches  changes sensitivity analysis revealed altering training selftraining                                                    ijcai                                                      ﬁrst semisupervised algorithms named en  selftagged  tity classiﬁcation collins singer  based  sentences        recall   precision  semisupervised cotraining blum mitchell                              training relies partition feature set produce                     dependent “views” each example classiﬁed                          assumed each individual view sufﬁcient build rela  tively effective classiﬁer cotraining separate classiﬁers table  performance semisupervised crf difﬁcult  trained each view each classiﬁer applied cases additional training sentences generated  untagged examples examples classiﬁca semisupervised algorithm “selftagged sentences”  tions certain added new training examples signiﬁcantly improve performance original  sen  iteratively bootstrapping information distinct views tences training set  cotraining algorithms able create new training exam  ples untagged data                                      cotraining approach developed collins singer    does actually perform entity delimitation instead  assumes entity delimitation problem solved ad   dresses task classifying given set entities cat   egories attempts utilize similar cotraining al                                                              gorithm entity delimitation task algo                                 lex  rithm’s partitioning feature set ill suited precision   task approach collins singer  employed                                    svmcmm  views classify named entities context surround                               crf  ing named entity orthographic features en                                 man  tity context surrounding known entity   good indicator entity’s class experiments   context effective determining                    recall  known entity’s boundaries cotraining classiﬁer trained  training set using “context” view achieved figure  information extraction performance  performance  difﬁcult cases  easy cases film class difﬁcult cases lex’s precision   versus   classiﬁer trained features higher closest competitor svmcmm  violates central assumption cotraining each  view independently capable producing relatively ef traction evaluation corpus using each  fective classiﬁer                                    methods delimit entities ranked extracted entities    cotraining unsuited task exper order decreasing frequency obtain precisionrecall  imented “singleview” cotraining known self curves each class figure  shows precisionrecall  training approach involved training supervised classi curves  frequent extractions difﬁcult cases  ﬁer training set iteratively applying clas film class graph shows lex enables sig  siﬁer untagged data adding training set niﬁcantly higher precision methods  sentences classiﬁer conﬁdent    methods perform comparably easy extractions    experimental results shown table  additional experiments necessary assess information  crf classiﬁer returned reliable probability esti extraction performance classes  mates sentences classiﬁer tested semi  supervised conﬁguration experiments    error analysis enhancements  algorithm executed total  selftraining  erations shown table bootstrapped training lex simple algorithm ways  examples make positive insigniﬁcant impacts simplistic assumptions structure names hinder  formance baseline supervised classiﬁer lex’s performance section three lex’s primary  formance   higher best semi error types introduce lex enhanced algorithm  supervised crf table                       addresses lex’s limitations lex follows lex                                                        algorithm given section  modiﬁcations each    information extraction performance               lex’s error types detailed  important application web named entity delimitation  unsupervised information extraction systems numbers punctuation boundaries  etzioni et al  systems use generic patterns lex’s assumption names begin end capitalized  “ﬁlms as” extract entities require words violated names begin end num  method identify boundaries entities extract bers punctuation—for example ﬁlm “ mile” com  given particular set patterns accurate pany including trailing punctuation “dell inc”  limitation result better extraction accuracy limitation lex accounted  false nega  experiment tested patternbased information ex tives difﬁcult cases experiments section                                                     ijcai                                                    
