   dynamic weighting searchbased map algorithm bayesian networks              xiaoxun sun                   marek druzdzel                   changhe yuan     science department        decision systems laboratory    department science    university southern california  school information sciences           engineering        los angeles ca            intelligent systems program      mississippi state university         xiaoxunsuscedu                 university pittsburgh        mississippi state ms                                             pittsburgh pa         cyuancsemsstateedu                                         mareksispittedu                      abstract                          map                                                        map problem deﬁned follows let set      paper propose dynamic weight                                                        map variables conﬁguration      ing dwa search algorithm solving map                                                        interested set evidence variables      problems bayesian networks exploiting                                                        states observed remainder vari      asymmetries distribution map variables                                                        ables denoted variables states      algorithm able greatly reduce search                                                        know care given assignment variables      space offer excellent performance terms                                                        map problem ﬁnding assignment vari      accuracy efﬁciency                                                        ables maximizes probability                                                         mpe problem special case map                                                           introduction                                                                                                                                   map   max     pms             maximum  posteriori assignment map prob                     lem ﬁnding probable instantiation set                       variables given partial evidence remaining variables general bayesian networks use conditional  bayesian network specialization map probability table cpt φ potential variable  received attention probable explanation parent nodes notation φe stands potential  mpe problem mpe problem ﬁnding  whichwehaveﬁxedthevalueofe   ∈ probability  probable assignment set variables given evidence     Φ                                                        map   cpts turns out real number  remaining variables map turns                                                                      map   max          φe             difﬁcult problem compared mpe computing prob                      ability evidence particularly decision problem                       φ∈Φ  mpe npcomplete corresponding map prob    equation  summation commutes summation           pp  lem np   complete park  map useful maximization commutes maximization sum  mpe providing explanations instance diag mation does commute maximization vice versa  nosis generally interested conﬁguration obligatory summation max  fault variables given observations imization order called elimination orderthe  variables observed outside size largest clique minus  jointree constructed  scope                            based elimination order called induced width    paper introduce dynamic weighting induced width best elimination order called  dwa search algorithm solving map generally treewidth map problems set  efﬁcient existing algorithms algorithm ex nonempty order constrained  plores asymmetries possible assignments constrained elimination order known  joint probability distribution map variables typi strained treewidth generally constrained treewidth  cally small fraction assignments expected larger treewidth leading problem  cover large portion total probability space limit feasibility complex models speciﬁcally  remaining assignments having practically negligible prob map problems variable elimination polytrees subject  ability druzdzel  dwa uses dynamic constrained treewidth requires exponential time  weighting based greedy guess park darwiche  mpe problems computed linear time park  yuan et al  heuristic function darwiche   theoretically admissible admissible heuristic efﬁcient approximate searchbased algorithm based  fer upper bound map heuristic signiﬁcantly local search proposed park darwiche  reduces size search tree rarely pruning away capable solving map efﬁciently exact method based  optimal solutions                                branchandbound depthﬁrst search proposed park                                                    ijcai                                                    darwiche  performs quite search layer leaf nodes search tree order guaran  space large approximate algorithm pro tee optimality solution hn admissible  posed recently yuan et al  reheated case means upperbound  nealing map algorithm somewhat slower simple net value assignment currently instantiated  works capable handling difﬁcult cases exact map variables elements  methods tackle                                                          heuristic function dynamic weighting    solving map using dynamic weighting             search known completeness optimality  propose section algorithm solving map each search step expand node frontier                                                                                 ing dynamic weighting search incorporates largest value   dynamic weighting pohl  heuristic function rel deﬁnition  heuristic function said  evance reasoning druzdzel suermondt  dy formed admissible closer  namic ordering search tree                    optimal cost map problem probability                                                        optimal assignment popt    search                                                                                    ∗  map solved search probability tree theorem  informed domi                                                              ∗                     composed variables map set nodes nates nilsson pearl   search tree represent partial assignments map power heuristic function measured  variables root node represents assignment pruning induced hn depends ac  map variables instantiated certain order curacy estimate hn estimates completion cost  avariablex set map variables instantiated precisely hnpopt expand nodes  ith place using jth state denoted mij  optimal path hand heuristic  leaves search tree correspond map variable used map problem amounts hn  instantiated vector instantiated states uniformcost search ensues far efﬁcient  each map variable called assignment scenario critical ﬁnd admissble tight hn    compute probability assignments search accurate efﬁcient solutions  ing probability tree using chain rule each inner  node newly instantiated node added evi greedy guess  dence set evidence set extended mij ∪ each variable map set conditionally indepen  probability map problem consists dent rest map variables called exhaustive  map variables presented follows          independence map problem amounts simple                                                        computation based greedy chain rule instantiate      ep    mni   mjmkmn−te       map variable current search layer state                   pmk  mjep mj         largest probability repeat each remain                                                        ing map variables probability map  suppose xth layer search tree  preparing instantiating xth map variables          function rewritten follows                                                                                       max mij mi−k mme                                                                                                                                                                                                                     requirement exhaustive independence strict            pm              ni       n−t         xz  xy           map problems calculated using      ·         pm             xy       x−q               function simulation results show prac                                                      tice requirement violated product                                                        extremely close map probability yuan et al     general idea dynamic weighting search suggests potentially used heuristic  during search each inner node probabil function map  ity tree compute exact value item curve greedy guess estimate figure  shows  function estimate heuristic value increase number map variables ratio  item map variables instanti greedy guess accurate estimate  ated given initial evidence set map variables optimal probability diverges ideal ratio  instantiated new evidence order ﬁt monotonically  typical format cost function search  logarithm equation change dynamic weighting  monotonicity fngnhnwheregn    greedy guess tight lower bound optimal  hn obtained logarithmic transformation probability map possible compensate error  items respectively gn gives exact cost greedy guess optimal probability  start node node nth layer search tree achieve adding weight greedy guess  hn estimated cost best search path nth product equal larger optimal probability                                                    ijcai                                                    each inner node search tree following set α safe parameter supposed larger  assumption                                            experiments set α                                                         accidentally smaller leading weighted           ∃∀pgreedyguess ∗    ≥ popt∧                  α                                                                                heuristic inadmissible suppose candi       ∀            ∗     ≥    ⇒  ≤            pgreedyguess          popt                date assignments probability     minimum weight guarantee spectively optimal assignment  heuristic function admissible figure  shows algorithm fails ﬁnd step  just  constant neglecting changes estimate search lead suboptimal solution skip  accuracy increase map variables estimate logarithm function sake clarity  function optimal probability represented cost function product transformed instead  curve constant weighting heuristic obviously problem sum  idea informed search pro     ·  ·  gresses fewer map variables estimate                                                        error introduced inadmissible fthe    dynamic weighting pohl  efﬁcient tool im                                                        algorithm ﬁnd instead  proving efﬁciency search applied properly  heuristic function admissible remaining          ⇒  · ·  tight optimal probability map shallow layers step search  section  search tree map variables deeper  suppose ideal heuristic function  layers greedy estimate likely di                                                                         leads  · hthenwehave  verge optimal probability propose following  dynamic weighting heuristic function xth layer · ·    ·                                                                             ⇒           ⇒          search tree map variables                            ·    ·                                 −    hxgreedyguess   ·   α          α ≥      clear ratio probability                                                      suboptimal assignment optimal larger  keeping weight constant ratio inadmissible heuristic function  search dynamically change make heavy ideal algorithm ﬁnd suboptimal solution  search goes deeper step search large asymmetries probabilities   −  weight zero greedy guess ampliﬁed multiplicative combination  map variable exact cost func druzdzel  expect cases  tion fn equal probability assignment fig ratios far   ure  shows empirical comparison greedy guess heuristic function break rule admis  stant dynamic weighting heuristics accurate esti sibility greedy guess divergent  mates probability dynamic weighting ideal estimate algorithm diverge  heuristic informed constant weighting   optimal probability simulation results conﬁrm                                                        robustness algorithm ﬁnding optimal solutions                                                                 improvements algorithm                                                                techniques improve efﬁciency                                                     basic algorithm                                                       relevance reasoning                                                     main problem faced approach complexity                                                       probabilistic inference critical factor exact infer                                                        ence schemes bayesian networks topology                  quality hx hxoptimal  hx  quality  underlying graph speciﬁcally connectivity rel                                                     evance reasoning druzdzel suermondt  tech                                                        nique based dseparation simple compu                                                tational efﬁcient techniques pruning irrelevant parts                      number map variables       bayesian network yield subnetworks smaller                                                        densely connected original network  figure   constant weighting heuristic dynamic   map focus set variables evidence set  weighting heuristic based greedy guess            parts model probabilistically independent                                                        nodes given observed evidence com                                                        putationally irrelevant reasoning map problem    searching inadmissible heuristics           dynamic ordering  minimum weight  guarantee heuristic search tree constructed dynamically  function admissible unknown map prob freedom order variables way improve  lem solved vary different cases normally efﬁciency dwa search expanding nodes                                                    ijcai                                                    largest asymmetries marginal probability distribu second group algorithms generated results  tions lead early cutoff promising branches time limit psys exact algorithm table   search tree use entropy marginal probability reports number map problems solved  distributions measure asymmetry              optimally plocannealedmap dwa                                                        dwa optimal solutions ploc missed    experimental results                               case andes annealedmap missed  test dwa compared performance map prob hailﬁnder cases andes  lems real bayesian networks current state            ploc   amap     dwa  art map algorithms ploc psys algo          alarm                        rithms park darwiche   samiam         cpcs                      annealedmap    yuan et al  smile imple        cpcs                      mented dwa performed tests  ghz       hailﬁnder                    pentium windows xp gb ram used           pathﬁnder                    default parameters settings three algorithms andes                     during comparison unless stated             winpts                       experimental design                                      munin                                                                                      hrl                         bayesian networks used experiments     hrl                         cluded alarm beinlich et al barleykristensen                                            rasmussen   cpcs cpcs pradhan et  table  number cases solved optimally                                        al   hailﬁnder abramson et al   munin dia  random cases ﬁrst second groups net                                                  betes andreassen et al   andes conati et al   works  pathﬁnder winpts heckerman et al someof  constructed diagnosis tested al annealedmap ploc failedtoﬁndall  gorithms large proprietary diagnostic networks optimal solutions andes studied performance  built hrl laboratories hrl hrl statis algorithms function number map variables  tics networks summarized table  divide randomly generated  cases each number map  networks three groups  small middlesized variables   large tractable  hard networks                                                                 map     psys    ploc   amap           group   network    nodes  arcs                                                                   alarm                                                                                cpcs                                                                             cpcs                                       timeout                               hailﬁnder                                       timeout                                pathﬁnder                                     timeout                                 andes                                        timeout                                winpts                                       timeout                                munin                             hrl                      table  number cases existing algo                    hrl                      rithms smaller probabilities search network                   barley                          andes                   diabetes                                                                   search time psys increased quickly   table  statistics bayesian networks use number map variables failed generate                                                        result number map variables reached     each network randomly generated  cases dwa largest probabilities compared  each case randomly chose  map variables three algorithms dwa increase  root nodes fewer  root number map variables ploc  nodes chose number evidence nodes nealedmap turned accurate dwa  leaf nodes set evidence sampled prior andes number map variables  probability distribution bayesian network topolog   cases ploc  cases  ical order cast states sample evidence annealedmap smaller probabilities  nodes following previous tests map algorithms set dwa notice table  ploc spent time  search time limit   seconds  minutes dwa using default settings andes                                                        increased search steps ploc spent    results second group           time dwa order make fair com  ﬁrst experiment ran plocpsysan    parison practice search time continu  nealedmap dwa networks ﬁrst ous number search steps just chose parameters                                                    ijcai                                                    ploc spent slightly time dwa p∗ stand probability map solutions  table  shows comparison results plocannealedmap dwa respectively  increasing search steps ploc dwa maintains  better accuracy                                                     p∗plp∗pl     p∗pap∗pa                                                              barley                               map    plocdwa     plocdwa                    diabetes                                                                                                           table  number cases solved differently                                                    plocannealedmap dwa                                                                                         barley accuracy three algorithms quite                                                    similar diabetes dwa accurate                                                    solutions largest probabilities  cases                                                    ploc failedtoﬁndandannealedmap failed                                                        ﬁndofthem  table  number cases ploc    largersmaller probabilities dwa network andes              psys    ploc   amap       spending slightly time dwa               barley    timeout                                                                       diabetes  timeout                addition precision results com  pared efﬁciency algorithms table  reports table  average running time seconds psysp  average running time algorithms ﬁrst locannealedmap dwa groups  second groups networks ﬁrst group                                                          dwa turned slower ploc                  psys   ploc    amap              nealedmap barley efﬁcient diabetes      alarm                         table       cpcs                     cpcs                         results incremental map test      hailﬁnder                     experiment focused robustness al      pathﬁnder                     gorithms number map variables experiment      andes                         set number evidence variables  gen      winpts                      erated map problems increasing number map      munin                         nodes ran algorithms cases chose      hrl                          munin network hardest network      hrl                          group    sufﬁciently large sets root                                                        leaf nodes running time each cases  table  average running time seconds psysp shown figure  typically psys ploc need  locannealedmap dwa algorithms ﬁrst       running time face complex problems  second group networks                         nealedmap dwa robust comparison    nealedmap ploc   psys algorithms showed similar  efﬁciency cpcs andes networks  dwa generated solutions shortest time av        psys                                                                      ploc  erage smaller variance search time indicates       annealingmap                                                                      dwa  dwa stable different networks    second group consists large bayesian net  works psysannealedmap dwa efﬁ  cient dwa search spent shortest time average      ploc slower hrl network       running  time    results group  group consisted complex bayesian networks  barley diabetes nodes                                                                     number map variables evidences   different states psys algorithm did pro  duce results time limit available mea                                                        figure  plot running time psysploc  sure accuracy relative algorithms                                                        annealedmap dwa algorithms increasing  assignment higher probability table  lists                                                        number map nodes munin network  number cases solved differently  plocannealedmap dwa algorithms     pl pa                                                    ijcai                                                    
