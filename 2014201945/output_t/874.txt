          roccer algorithm rule learning based roc analysis                         ronaldo prati                              peter flach        institute mathematics science       department science                    university sao˜ paulo                      university bristol                    sao˜ carlos sp brazil                    bristol united kingdom                   pratiicmcuspbr                      peterflachbristolacuk                        abstract                            decision tree induction necessarily builds complete                                                        disjoint models complex domains high      introduce rule selection algorithm called    dimensional feature spaces models quite com      roccer operates selecting classiﬁca    plex cases individual rule learning algorithms      tion rules larger set rules – instance preferable capable inducing overlapping      apriori – using roc analysis experi    simpler rule sets van den eijkel       mental comparison rule induction algorithms  problems setcovering rule learning rules      shows roccer tends produce considerably   isolation used context      smaller rule sets compatible area  inside classiﬁer issue pose prob      roc curve auc values individual rules      lems rule learning algorithm learning      compose rule set higher support perspective fewer fewer examples available cov      stronger association indexes                 ering progresses stages induction lead                                                        fragmented training sets rules insufﬁcient statis                                                        tical support domingos  furthermore each new rule    introduction                                       constructed complete ignorance examples  classiﬁcation rule learning deﬁned process covered previously induced rules bad rule  given set training examples ﬁnding set rules introduced rule set chance ﬁnding  used classiﬁcation prediction classiﬁca better rule examples backtracking  tion rule learning algorithms belong families work present new rule learning algorithm  separateandconquer divideandconquer algo named roccer aimed overcome problems  rithms families share number characteristics main idea algorithm construct convex hull  notably assumption example space contains roc space evaluate roccer broad set bench  large continuous regions constant class membership mark domains uci repository blake merz  major differences outlined                  compare rule induction methods    separateandconquer family classiﬁcation rule paper organized follows section  discuss  learning algorithms furnkranz¨  search procedure background related work section  presents pro  generally iterative greedy setcovering algorithm posed algorithm section  contains experimental  each iteration ﬁnds best rule according search cri evaluation section  make concluding remarks  terion removes covered examples process  repeated remaining examples examples  related work  covered stopping criterion met approaches proposed literature  der build classiﬁer rules each iteration overcome fragmentation problem liu et al   gathered form ordered rule list decision list couple rule generation covering step ba  unordered rule set case classiﬁcation sic idea use association rule algorithm gather  given ﬁrst rule list ﬁres rules predict class attribute pass mini  case predictions rules ﬁre combined predict mum quality criterion rule set ap  class                                              proach overcome problems separate    approach contrasts divideandconquer fam andconquer approach performance reported  ily learning algorithms quinlan  global outperform standard rule learning algorithms  classiﬁer built following topdown strategy consec mains main drawback related number gen  utive reﬁnements partial theory result gener erated rules considerably outnumber exam  ally expressed decision tree completely divides ples implying difﬁculties knowledge discov  instance space nonoverlapping axisparallel hyper ery point view understandability usability  rectangles                                           generated model decrease risk overﬁtting increase idea extended apri class values allowing deal multiclass problems  oric apriorisd algorithms javanoski lavracˇ  perform selection step based roc curve  kavsekˇ et al  adding additional ﬁltering step basic idea insert rule rule list  remove redundant rules aprioric insertion leads point outside current roc convex hull  tends build large rule sets apriorisd devel current roc convex hull upper convex hull  oped mainly subgroup discovery                   rules rule list rule    different approach use weighted covering discarded better understanding algorithm  independently proposed cohen singer works ﬁrst using example   weiss indurkhya  instead com  rules selected separately each class kept  pletely removing examples covered best rule ordered rule list let’s label class selecting  each iteration weights decreased each itera rules positive label negative represents conjunc  tion covering algorithm concentrates highlyweighted tion examples classes initialize  infrequently covered examples lavracˇ et al  rule list default rule rdefault pre  discuss use weighted covering subgroup dis dicts positive current roc convex hull formed  covery context alternative methods remove redundant  points   means “ignore  rules based pruning furnkranz¨ widmer  fault rule classify negative use default  cohen                                          rule classify positive” use fprri tprri    authors propose use conﬁdence thresholds refer rule ri’s true false positive rates tpri  classiﬁcation gamberger lavracˇ  include fpri refer point roc curve representing  rules high conﬁdence rule set classiﬁer corresponding rule list’s true false positive rates sup  refuses classify new instance rules cover pose inserting new rule actual  ferri et al  extends idea retraining new vex hull formed line segment  −   classiﬁer unclassiﬁed examples                inserted point formed rule’s                                                        fprrtprr convex hull let’s say    roccer      rule selection algorithm          serted current convex hull updated                                                        tains points fprtpr fpr  fprr  approach relies using roc analysis selecting rules tpr  tprr process depicted figure   instead using classical covering algorithm roughly  speaking roc graph plot fraction positive  examples misclassiﬁed — false positive rate fpr —  axis fraction positive examples correctly classi  ﬁed — true positive rate tpr — axis possible  plot roc graph single rule classiﬁer formed  rule set partial classiﬁer formed  subset rule set instance    thresholdbased classiﬁer obtain pairs  points fpritpri varying threshold trace  line connecting points obtain curve roc figure  leads point outside current convex hull  space represents behaviour classiﬁer main diagonal inserted rule list  possible choices respective threshold rule learning  context furnkranz¨ flach  show rule learning suppose trying insert second rule  using set covering approach seen tracing curve said standard setcovering approach  roc space assume rule list learning new rule does account rules  represented point  roc space adding new learnt approach try overcome issue  rule rule list implies shift point fpr jtpr using roc graph analyze interactions rules  fpr tpr tpr fpr partial rule list comparing rule trying insert  terpreted decision list containing rules learnt slopes each line segments current convex hull  including curve traced plotting partial roc graph example slope point  rule lists fpr jtpr varying  total number formed origin fprrtprr line  rules ﬁnal rule list order learnt origin point fprtpr say “improves  ﬁnal default rule predicts positive class relation to” insert rule list similar  added end connecting point fprntprn point learned setcovering ap                                                  proach comparing rules    approach based observation fact rule list algorithm provides kind backtracking  points represent optimum thresholds lie insertion course produce changes points  upper convex hull roc curve provost fawcett roc curve ﬁrst nontrivial point roc curve   rules come external larger set rules changes fprrtprr  implementation use apriori association rule learning lap second point fprr  fprrtprr  tprr  algorithm ﬁxing head rules each possible overlap discount examples covered rules calculate sec does necessarily lead convex curve insertion  ond point                                            new rule rule list introduce concavities    inserted ﬁrst iteration proceed fore point insertion concavities occur  comparing remaining line segments roc insertion inserted rule covers examples originally cov  vex hull compare line segment ered subsequent rules decreases latter’s preci  update r’s fpr tpr removing examples covered sion case remove rules concavity  examples evaluate true r’s antecedent occurs alternatively concavity occurs  fact “interpreting” ¬r ∧ updated sertion point rules share region misclas  position line rdefault sify examples case unreasonable use  inserted rule list process depicted partial rule list including ﬁrst rule excluding  figure  rules remain dis second corresponding roc point  carded pseudocode algorithm shown algo convex hull construct disjunction  rithm                                               rules treat single rule                                                          implementation rules presented roccer ini                                                        tially ordered using euclidean distance point                                                         roc space possibility remove                                                        selected rule implicit backtracking order                                                        pendence selecting rules lower decision list                                                        inducing rules experiments orderings                                                        interesting issue work                                                          concludes description training phase                                                        classiﬁcation use rocbased method bayes’                                                        orem states odds classiﬁer correctly classiﬁes   does improve does com instance posterior odds given likelihood ratio   convex hull compared pared rdefault    times odds instance predicted class                                                  prior odds roc space likelihood ratio                                                        terpreted tprfpr recall selected rules separately        figure  finding right point insert each class roc convex hull each                                                        class classify new instance consider each class                                                        separately each class determine ﬁrst rule                                                        ﬁres respective roc convex hull rule asso   algorithm  roccer algorithm                                                        ciated tprfpr roc curve yields likelihood    data rsin large rule set given class    ratio posterior odds converted prob    result rsout  smaller rule list containing ability ranking select class maximum           selected rules                               posterior odds classiﬁcation    rsout  rdefault    foreach rule ∈ rsin                                 experimental evaluation       trytoinsertrulerule    endfch    return rsout                                          order empirically evaluate proposed approach                                                        performed experimental evaluation using  data sets    procedure trytoinsertrulerule                     uci blake merz  used data sets      ruletocompare  ﬁrst rule rsout               missing values apriori association rule algorithm      repeat                                                        use generate rules subsequent selection roc         rule’s fprtpr outside convex hull                                                        cer can’t handle table  summarizes data sets em            insert rule rs ruletocompare                                                    ployed study shows each data set number                                                                attributes attrs number examples examples              shift new origin                  remove examples rule percentage examples majority class majclass –            covered ruletocompare                   roccer handle classes order            actualize rule’s fprtpr                 calculate auc values restricted experiments                                                        class problems data sets having classes            ruletocompare  rule rsout         endif                                          chose class fewer examples positive class                                                        collapsed remaining classes negative      ruletocompare                                default                       roccer’s results compared obtained      rule inserted                      following rule learning systems         discard rule      endif                                             cn  algorithm classical implementation                                                            separateandconquer rule learning family ﬁrst                                                            version clark niblett  cn induces deci    overlapping coverage rules process   sion list using entropy search heuristic later       data set    attrs  examples  majclass      shown table  perform twotailed dunett mul         breast                              tiple comparison control procedure using roccer          bupa                                control results roccer cells having         ecoli                               auc values statistically better roccer represented          flag                               dark gray light gray used represent cells statis         german                             tically worse roccer  conﬁdence level          glass                                table  shows relatively statistically signiﬁcant differ        haberman                              ences comparing roccer achieved  wins          heart                               loss score compare roccer       ionosphere                            ripper slipper results  wins       krvskp                            losses comparison roccer prun        lettera                          ing cn cn ordered yield  losses wins      newthyroid                            believe losses high degree class        nursery                            skew datasets skewed         pima                                study order allow apriori ﬁnd rules classes       satimage                            domains support parameter used apriori        vehicle                             low cases small number                                                        rules generated minority class large number       table  uci data sets used experiments  rules generated majority class improvements                                                        roccer cope situations                                                        instance interesting introduce different min      modiﬁed incorporate induction unordered imum support each class taking account      rule sets laplace error correction evaluation func rule learning algorithms score  wins  losses      tion clark boswell                    losses concentrated skewed domains  ripper cohen  proposed ripper incremental comparing generated rules roccer produced       reduced error pruning irep furnkranz¨ widmer wins losses compute auc value selecting       context features errorbased prun number roccerrandom rules rules      ing mdlbased heuristic determining higher individual auc values lack space results      rules learned                     shown paper cases  slipper algorithm improvement ripper signiﬁcantly worst better roccer indi      uses weighted setcovering approach cohen cates roccer’s selection procedure responsible      singer                                 gain performance presented rules                                                          good results versions cn rel                      quinlan  ’s standard empiri atively poor auc ﬁgures ripper slipper worth      cal comparison symbolic learning algorithms noticing explained absence pruning      member divideandconquer family uses infor mechanisms reported literature      mation gain quality measure build decision tree nonpruned trees better probability prediction      postpruning step based error reduction produce higher auc values provost domingos       consider each branch decision tree rule expected similar phenomenon  ripper slipper used option generate rules occur algorithms separateandconquer family  classes cn used versions ripper slipper – conceptually – similar  dered cnor unordered cn evaluated  cn incorporate respectively rule pruning weighted  pruned nonpruned cnp trees induced coverage  parameters set default values table  presents average size number rules  order calculate auc values estimated probabilities rule sets each algorithm size  means clas  each rule using laplace correction unordered ver siﬁer formed default rule picture  sion cn probabilities estimated using ﬁred rules clear apart exceptions roccer pro  auc values estimated using trapezoidal rule duces smaller rule sets pruning cn  used borgelt kruse ’s implementation apriori ordered unordered slipper hand  generate large rule sets used roccer parame ripper produced signiﬁcantly smaller rule sets   ters set  conﬁdence  percentage  domains  draws  win  minority class support roccer probabilities investigation involving data sets al  estimated posterior odds described section  gorithms produced smaller rule sets roccer breast  compare bagging rules generated heart ionosphere krvskp produce  apriori    ran experiments using fold stratiﬁed cross  multiple comparison used adjust observed signiﬁcance  validation experiment paired inducers level fact multiple comparisons use  given training test ﬁles averaged auc ttest each comparison  type error  values respective standard deviations brackets type error rate entire group higher        roccer              cnp       cn         cnor       ripper      slipper                                                                                                                                                                                                                                                                             avg                                                          table  auc values estimated fold crossvalidation  uci data sets described table  obtained  roccer pruning cn unordered cn ordered learning decision lists ripper slipper bagging  rules apriori numbers brackets indicate standard deviations dark gray indicates signiﬁcant wins  roccer light gray indicates signiﬁcant losses roccer    sights improvements approach              plexity number rules used    conclude tables   roccer combines average number iterations Ωmn  sense best worlds achieves auc values number rules selected algorithm  comparable unpruned decision trees lack space report runtime statistics  cn large number rules induced data sets datasets runtime ranges  systems finally table  presents statistics individual seconds  minutes fold pentium  ghz ma  rules comprise rule sets demonstrates chine mb ram datasets number  advantage roccer approach support ranges  rules used input  domains kr   measure relative coverage each vskp satimage number rules generated apriori  rule weighted relative accuracy wracc ranges  high  runtime cases   assesses signiﬁcance rule terms dif average nearly  hours fold  ference observed expected numbers true  positives odds ratio ranges  ∞ mea  conclusion  sure strength association clearly seen                                                        presented roccer rule selection algorithm based  rules selected roccer considerably higher values  measures means rules mean roc analysis roccer operates selecting rules  ingful isolation reference rules larger set rules maintaining roc convex hull                                                        roc space featuers roccer’s approach include implicit  rule set roccer successfully overcomes  main drawbacks setcovering approach          backtracking discovery pairs related rules exper                                                        imental results demonstrate auc values compatible                                                        best probability predictors unpruned deci             support     wracc        odds ratio     sion trees achieved considerably smaller rule sets   roccer                                                                 rules compose rule sets induced roccer                 cnp            higher values support weighted relative accuracy   cn              odds ratio meaningful individual rules   cnor              ripper           acknowledgments   slipper                         work partially supported brazilian research                                                        concil capes process bex car                                                        ried ﬁrst author visiting university  table  support weighted relative accuracy odds ratio                                                        bristol  averaged learned rules      ﬁnal word said regarding computational com references  plexity roccer course computationally expen blake merz  blake merz  sive algorithms worst case com uci repository machine  learning databases
