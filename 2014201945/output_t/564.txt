 integrated multilevel learning approach multiagent coalition formation                                                 leenkiat soh xin li                                   department science engineering                                              university nebraskalincoln                                     ferguson hall lincoln ne  usa                                                 lksoh xinlicseunledu                               abstract                               sen dutta  coalition formation                                                                  cooperative agents shchory et al  little work      paper integrated multilevel learn•   coalition formation self     ing approach multiagent coalition formation         interested cooperative agents furthermore      realtime environment domain agents negotiate      attempts study coalition formation      form teams solve joint problems agent       agents dynamic realtime uncertain noisy envi•     initiates coalition shoulders responsibility over• ronment typical realworld environment      seeing managing formation process coali•         suboptimal coalition needs formed real•     tion formation process consists stages during       time manner      initialization stage initiating agent identifies                                                                    propose integrated multilevel learning approach      candidates coalition known neighbors                                                                  multiagent coalition formation approach agents      help initiating agent negotiates                                                                  assumed cautiously cooperative—they willing      candidates during finalization stage determine                                                                  help think benefit it—and honest      neighbors willing help domain                                                                  noisy uncertain dynamic realtime      dynamic noisy timeconstrained coalitions                                                                  nature domain agent correct      optimal approach employs learning                                                                  perceptions assumptions achieve coalition      mechanisms levels improve quality                                                                  initiating agent negotiate agents      coalition formation process tactical level                                                                  through concurrent multiple  negotiations initiat•     use reinforcement learning identify viable candidates                                                                  ing agent identifies agents willing help      based potential utility coalition                                                                  formation process successful initiating agent suc•     casebased learning refine negotiation strategies                                                                  cessfully persuades agents join coalition      strategic level use distributed cooperative case                                                                   note paper focus improving quality     based learning improve general negotiation strate•                                                                 coalition formation process quality     gies implemented three learning                                                                  coalition formed executed     components conducted experiments multisensor     target tracking cpu reallocation applications            note approach example good                                                                  soon design paradigm domain    introduction                                                 agent incomplete information environment                                                                  task execution time constrained communica•  multiagent coalition formation important distributed    tion agents reliable optimal coalition   applications ranging electronic business mobile    formed deep learning impractical sub  ubiquitous computing adaptation changing re•          optimal fast coalition formation process warranted   sources environments crucial increases ability   agents execute tasks maximize payoffs          coalition formation   coalitions dynamically disband                                                                  problem domain agent solve task   longer needed effective automation                                                                  execution resource allocation problem   coalition formation save considerable labor                                                                  benefits collaborating agents initi•  time effective finding beneficial                                                                  ates coalition formation process form coalition   coalitions human complex settings jennings                                                                   solve problem jointly figure  depicts coalition     considerable research conducted                                                                  formation modules make stages initializa•  coalition formation selfinterested agents                                                                  tion finalization feasibility study ranking   tohme sandholm  sandholm et al                                                                   candidates initialization stage nego      multiagent systems                                                                                                      tiations management finalization stage    dynamic persuasion threshold responding agent    twostage model soh tsatsoulis  allows agent    agree request responding agent    form initial coalition hastily quickly react  ability counteroffer time constraints poor evi•   event rationalize arrive working final coalition dence based work soh tsatsoulis    time progresses result previously described       domain nature                                                 acknowledgment negotiations com•                                                                 pleted coalition formed agent confirms                                                                  success coalition agents agreed                                                                  help agent failed form coalition informs                                                                  agents agreed help release                                                                  agreements                                                                    section discuss learning mecha•                                                                 nisms critical coalition formation approach                                                                     learning                                                                  learning approach incorporates reinforcement learning                                                                  casebased learning levels tactical level                                                                  use reinforcement learning identify viable candidates                                                                  based potential utility coalition case       figure  overview coalition formation process  based learning refine specific negotiation strategies                                                                  strategic level use distributed cooperative casebased    briefly each module design           learning improve general negotiation capabilities    dynamic profiling agent dynamically profiles   each neighbor vector agent negotiation    reinforcement learning   relationship profiles each negotiation       reinforcement learning evident coalition initializa•  task case casebase negotiation strategy  tion finalization stages during initialization initiat•  description negotiation outcome                           ing agent measures potential utility candidate based    feasibility study module analyzes problem        weighted sum  past cooperation relationship   computes agent resources     initiator candidates helpfulness friend•  yes list agents liness agents helpfulness importance   agent thinks help                                       candidate  current cooperation relationship    ranking candidates module scores ranks        initialing agent agents   each candidate proportionately assigns requested      negotiating problems  ability   demand each candidate based potential utility sec• help current problem initiating agent   tion                                                      likely approach agents helpful    management module initiates negotiations        reinforcing cooperation relationship   topranked candidates module manages multi•        ple concurrent  negotiations each negotiation       during finalization initiating agent appeals   task finds negotiation strategy through cbr       candidate helpful initiating agent   spawns thread execute negotiation task     past candidate easily persuaded realizes   module oversees various negotiation threads        particular agent helpful past   modifies tasks realtime example module       reinforcing cooperation relationship   terminate remaining negotiations finds    details refer soh tsatsoulis    longer form viable coalition module   reduce requests demands secured         casebased learning   agreements successful negotiations         use cbr retrieve adapt negotiation strategies   effect management simulates  tomany negotiation    negotiations during coalition finalization    cbr given problem description task          equip cbr module individual coopera•  cbr module retrieves best case casebase      tive learning capabilities figure  individual learning   adapts solution best case current problem  refers learning based agents perceptions   based work soh tsatsoulis        actions direct communication agents                                                                  cooperative learning refers learning agents ex•   negotiation negotiation protocol argumenta•                                                                 perience through interaction agents   tive initiating agent provides evidence request                                                                  agent identifies problematic case casebase ap•  persuade responding agent responding agent         proaches agents obtain possibly better case   evaluates evidence pieces higher                                                                                                    multiagent systems                                                                case deemed problematic cooperative learning                                                                  triggered case replaced table                                                                   shows heuristics use tandem chrono•                                                                 logical casebase negotiation completes                                                                  new case adds casebases diversity agent                                                                  learns casebases size reached preset limit                                                                  agent considers replacing existing                                                                  cases new case individual casebased                                                                  learning use heuristics           figure  relationship case learning cbr                negotiation tasks agent     research distributed cooperative   cbr prasad plaza  proposed treating corporate   memories distributed case libraries resource discovery   achieved through  negotiated retrieval dealt   retrieving assembling case pieces different re•         table  usage history agent profiles each ease   sources corporate memory form good overall case    federated peer learning dealt distributed   collective cbr plaza et ai  martin et ah     extended model using notion competent   agents martin plaza  employed auction  based mechanism focused agentmediated systems   best case selected bid cases     methodology employs cautious utilitybased adap•  tive mechanism combine learning approaches   interaction protocol soliciting exchanging informa•  tion idea chronological casebase empha•  sizes individual learning triggers cooperative learn•  ing necessary cooperative learning differs   collective cbr does merge case pieces   considers entire cases addition re•  search focus define mechanism combines   individual cooperative learning                             table  heuristics support chronological casebase     note communication coordination overhead   cooperative learning high cooperative         cooperative learning   learning costeffective timely   agent learns experience view       figure  depicts cooperative learning design   world solution problem applicable     adhere cautious approach cooperative learning   agent facing problem injection    agent evaluates case determine   foreign knowledge risky add       problematic designate case problematic use   processing cost improving solution quality   heuristics frequently used case problem•                                                                 atic low success rate tsutu high incur•  agent marsella et al                                                                   rence rate tinctu profiling module keeps track    chronological casebase case utility                  utility cases   utilized notion chronological casebase         agent requests help selected agent   each case stamped timeofbirth       thinks good particular problem want ap•  created timeofmembership joined       proach neighbors initiated successful negotiations   casebase initial cases given time      current agent hope agent   ofbirth timeofmembership addition profile       able learn neighbors able suc•  each cases usage history table  agent evaluates        cessful determined based profile each   utility case based usage history case  neighbor agent maintains exchange protocol   low utility replaced forgotten   carried case request case response modules       multiagent systems                                                                                                      foreign case similar problematic case ing cbrrl  casebased reasoning norl     agent adapts foreign case adopting     reinforcement learning nocbr  learning    cascbase time usage history parameters   nocbrrl figure  shows result terms    new case reset                                       success rates negotiations coalition formations     problematic case fixed times    removed heuristics                                                                      figure  success rates negotiations coalition formations                                                                                  different learning mechanisms              figure  cooperative learning design                                                                    agent design casebased reasoninglearning                                                                  reinforcement learning outperformed     experiments results                                     negotiation success rate coalition formation success    implemented multiagent syrtem multiple         rate means learning agents able ne•   agents perform multisensor target tracking adap•    gotiate effectively efficiently    tive cpu reallocation noisy environment simulated    led coalitions formed learning    javabased program called radsim each agent           negotiation success rates remained    capabilities located unique position   coalition formation rate tended deterio•   each agent controls sensor activate sensor   rate indicates learning meth•   searchanddetect environment agent detects    ods agents able negotiate effectively    moving target tries implement tracking coalition  efficiently resulting processing time    cooperating neighbors   initiating agent postprocess agreement    cpu shortage arise activity consume         learning agents fared noticeably poorly    cpu resource agent detects cpu shortage    needs form cpu coalition address crisis           resource allocation coherence      multiagent implemented         conducted experiments cpu reallocation test   current design each agent   jv threads core        coherence refer cpu allocation   thread responsible making decisions managing        sustenance resource order agent obtain   tasks communication thread used interact     cpu needs incur cpu usage negotiating   message passing sensor execution thread      resource varying initial cpu   actuates physical sensor calibration searchanddetect   allocation each agent created mildlyconstrained   target each agent negotiation threads   overlyconstrained unevenlyconstrained scenarios   conduct multiple concurrent negotiations                  tables   compared agents behavior terms      used simulations experiments con•        successes negotiations coalition formations par•  ducted experiments simulation called radsim         ticular coalition success rate number success•  communication noisy unreliable      fully formed coalitions number coalitions initi•  targets appear environment designed        ated coalition successfully formed   implemented cpu shortage simulation module        cpu obtained satisfies agents need observed   each task designated cpu usage plus         following   random factor agent detects cpu shortage        experiments reduction cpu shortage   tasks currently performs slow cpu        each agent obvious gradually   shortage goes unresolved result failed negotia•   cpu resource reallocated evenly   tions negotiations timeconstrained             agents possibility cpu shortage decreases                                                                  each agents shortage decreases shows    impacts learning                                        coherent cooperative behavior agents   conducted experiments versions learn•  ing  casebased reasoning reinforcement learn•                                                                                                   multiagent systems  experiments period time each   agents cpu allocation converged average level    each agent fluctuated level    observed coalition formation   successful   roughly number resourceful resource                table  experiment sets example esi agent   starved agents experiment  type                   cases casebase   required number negotiations coalitions   converge                                                                                table  utility each outcome case                                                                     average utility case base average product                                                                 each cases tu value utility value outcome                                                                 diversity measure casebase computed av•      table  comparison negotiations experiments                                                                 erage difference each pair cases casebase                                                                 three slopes sizeslope diffslope utilslope com•                                                                puted growth rate learning point                                                                 learning point size diversity utility respec•                                                                tively table  shows example results initiat•                                                                ing casebases            table  comparison coalitions experiments      individual  cooperative casebased learning   investigation individual cooperative case  based learning conducted sets experiments   comprehensive experiment cea comprehensive   experiment ceb carried cea study   effects individual learning subsequent cooperative   learning roles cooperative learning agents   different initial knowledge performed ceb investi•  gate effects environment agents learning      comprehensive experiment cea   conducted sets experiments cea shown        table  utility difference gains subexperiments   table  goal experiment sets investi•      expl exp second stage initiating casebases   gate learning differed given different casebase sizes                                                                 looking results observed following   learning differed given different types initial                                                                  cooperative learning results utility diver•  casebases cases collected different agents                                                                 sity learning occurrence individual learning   earlier run cases note   following experiments set limit     small casebase learns effectively terms   casebase size  case replacement started    utility diversity faster learning   place used main parameters evaluate case      problemdriven large casebase learns similar man•  bases utility diversity rank outcome   ner average casebase greater   each case following utility values table             preset limit triggers case replacement       multiagent systems                                                                                                    
