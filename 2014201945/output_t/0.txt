                   planning gene regulatory network intervention                                        daniel bryce  seungchan kim                             department science engineering                               arizona state university brickyard suite                                   south avenue tempe az                                        danbryce dolchanasuedu                        abstract                          thousands genes living tissue terms mrna                                                        centrations products gene transcription used code      modeling dynamics cellular processes proteins correlations observed gene activity lev      cently important research area   els help regulatory inﬂuences predictor functions      disciplines important reasons    characterize regulatory inﬂuences provide dynamic      model cellular process enable high                                                        model highly active      throughput insilico experiments attempt  inactive grn state models activity levels genes      predict intervene process ex    predictor functions possible states      periments help accelerate design thera side interventions using rna interference suppress      pies through cheap replication alteration gene’s activity level alter predictor functions control      techniques exist reasoning cel dynamics grn providing natural planning problem      lular processes advantage ﬂexible plan each action models possible intervention      scalable algorithms popularized ai research nonintervention change state grn      domain scalability crucial feasi      ble application apply ai planning based search  number grn features affect choice      techniques demonstrate advantage   ai planning model intervention plans need fo      existing enumerative methods                     cus horizons long ensure grn naturally                                                        transition nominal states biological knowledge com                                                        putational simulation grns kim et al  tell    introduction                                       cellular processes left transition through  cell maintains functions various interconnections stable attractor states states represent common cellu  regulatory controls genes proteins lar phenomena cell cycle division  critical understanding living cell unravel states consistent disease metastasis  cellular components genes proteins interact cancer abnormal states planning interventions pro  each mathematical modeling computational simu vides method push evolution cell nomi  lation cellular systems especially gene regulatory systems nal attractor states second cell inherently hidden  crux computational systems biology biomed state observations prohibitively costly  ical science general model constructed limited accessability datta et al  planning  used predict behavior cellular partial observability important biologists analyz  usual conditions identify disease develop ing cellular processes expected understand  andor intervene development prohibit cells obtain complete state information cellular processes  reaching undesirable states models aid biol commonly viewed stochastic rao et al  genes  ogists quickly ruling conﬁrming simple hypotheses typically regulated different ways meaning grns  expensive timeconsuming wet lab experiments allow probabilistic selection predictor func    paper address problem planning tion each gene state transitions stochastic  tervene cellular processes focusing gene regulatory provide partial observations relevant  networks grns grn describes cellular process limited planning horizon formulate model grn  set genes regulatory inﬂuences each intervention decision theoretic planning ﬁnite horizon  grns focus solely genes omitting proteins partially observable markov decision process pomdp  molecules model high level behavior work ﬁrst address problem plan  genes versus low level behavior smaller sys ning interventions grns ﬁrst apply ai  tem practical grn models typically learned planning techniques existing research datta et al   microarray data kim et al  situated enumerates possible plans uses dynamic pro  right level granularity automated parametriza gramming algorithm ﬁnd optimal ﬁnite horizon plan  tion microarray experiments measure activity level planner based ao algorithm nilsson                                                      ijcai                                                    uses upper bounds plan quality reward prun horizon   horizon    horizon     horizon   ing evaluate planner formulations ran                                                           initial belief                                                                                                  dom grn different reward functions beneﬁt    pruning evaluate wnta grn weeraratna              intervention intervention intervention                                                           observe  observe  observe  et al whichdatta et al  use intervention                                                                 planning wnta gene plays signiﬁcant role          intervention intervention intervention                                                                     observe  development melanoma known induce            observe  observe                                                                                               metastasis melanoma highly active wnta                      problems studied datta et al  planner performs  signiﬁcantly better enumeration algorithm datta  et al  study formalizes interesting planning        figure  example plan  domain ﬁnite horizon pomdp shows gains  applying relatively standard ai techniques             quality plan expected reward possi    start describing simple example planning ble plan branches ﬁrst branch taken  probability  terventions grn brieﬂy deﬁne components reward  intervene sec  ﬁnite horizon pomdp grn intervention prob ond branch taken  probability reward   lem deﬁnitions map intervention prob total expected reward   lem pomdp solution pomdp condi  tional plan deﬁne semantics provide  solution algorithms – ao enumeration datta et al  decision theoretic planning   compare algorithms grns ei section describes basics ﬁnite horizon pomdp  ther randomly generated learned actual microarray model formally deﬁnes intervention planning details  experiments end related work conclusion formulation intervention planning pomdp  discussion future work                                                        pomdp model    unlike work pomdps ﬁnd                                                        policy belief space ﬁnd policy conditional    intervention planning example                      plan rooted initial situation ﬁnite horizon pomdp  clarify intervention planning consider small gene problem deﬁned tuple s Ωohbi   network each gene active gorinactive set states set actions  × a∪  ¬                                           predictor functions fg fg ⊥ × ∪⊥→  transition function  × ∪  scribe grn dynamics intervention suppress ⊥ × ∪⊥→r                                                                        transition reward function Ω  described predictor function fg  using predictor set observations  ×a×Ω →   observation  functions deﬁne following actions    function planning horizon bi  →     action    intervention     intervention        initial belief state overload symbol ⊥ denote   reward                                            terminal action state signifying end plan                   →¬    ¬  →          →¬   ¬   →   effects   fg   fg                   ¬  →¬      →       →¬   predictors fg  fg              intervention planning problem given deﬁnition   observation  ¬g           ¬g               pomdp model following show interven  intervening suppress incurs reward  rewrit tion planning problem maps pomdp intervention                                                       problem deﬁned tuple g                ing predictor function fg fg  assume                      domfxwy      observe goal intervention set genes dom set activity levels  problem associates reward  activating gene genes set predictor functions set inter  actions deterministic sake example ventions initial situation goal description  simplicity stochastic actions allowing set observations horizon genes  probabilistic choice predictor function each gene activity levels states pomdp pre    assume start initial belief state each dictor functions interventions actions interven  grn state equally likely depicted figure  ﬁg tions goal description deﬁne reward function  ure shows horizon three plan achieve goal activat initial situation observations horizon map directly  ing ﬁrst action plan intervene pomdp counterparts  let genes affect each observe inter states each gene ∈ghas activity level  vening leads belief state  ¬     ¬                                        main dom  values illustrate boolean  using observation  ¬  holds plan                                                    domains g¬g active inactive state  g→dom  branches belief states consistent appropriate ob gene network maps each gene value ∈ domthe  servation know value  occur                                                      entire set grn states deﬁnes pomdp states  plan branches ﬁrst branch apply  intervention action suppress following step predictor functions interventions given state  intervene having inactive activate gene network predictor functions states reach  leading state satisfying goal second branch able step interventions rewrite predictor functions  apply non intervention action indeﬁnitely speciﬁc genes ensure gene network transitions  goal satisﬁed remain satisﬁed        speciﬁc states each possible action pomdp                                                     ijcai                                                    described set predictor functions non interven algorithms ﬁnd plans ﬁrst algorithm ao nils  tion simply uses action interven son  second datta based competing  tion action ∈ replaces predictor functions approach datta et al  grn literature  new set fx each intervention ∈ set predictors                                                      conditional plans solution problem   fg fg    allowing deﬁne                                                                                  ditional plan horizon described partial func                ∪       ∈      ∈                fx     fg fg   fg             tion  →  ∪⊥over belief state space graph    each predictor function fg deﬁned mapping fg  ve subset vertices ∈ belief          domg   → dom  activity levels genes g ⊆g states mapped “best” action denoted pba                                                                    ∈                       activity level gene interventions described each edge directed ba mapped                                                                ∈                        ∈  work contain single predictor function fg  ∅ action observation Ω denoted                                                                                         meaning irrespective state activity level set eb baa oif ba eb baa othen                                                          deterministically                                      ba action execute executing receiving    each gene predicted predictor observation discussion assume  functions each state transition selects probabilis horizon feature state ensure graph  tically assign weight wfg each assume acyclic belief states horizon equal  predictor functions given learn single available action ⊥ signify end plan  microarray experiments empirical analysis evalu leading terminal ⊥                                                                                             ate grns predictor functions weights ba exists edge eb baa  generated randomly real microarray experiments successor belief state bo deﬁned                                                                              a    each action af deﬁned set predictor functions                                                                                                  bas      bst   similarly fx describes transitionp function probability              s∈s                                                                                                                 ∈f ss fg                                                                           bas αbas  os ao    af sprs              wf                                   ∈g      fg ∈f                                                       α normalization constant s ∈                                                            observations each step intervention bas observation consistent  non intervention observe state gene net lief state ba belief state added graph  work set o⊆gdeﬁnes genes observable      expected reward qa plan starts action  genetic markers physiology set observa belief state sum current future rewards                                                                        tions Ωoo  ∈ dom     deﬁned joint activity                                                                                                  qa        bst rs   levels genes  work assume observa           s∈s s∈s                                                                                        tions perfect each action meaning            bas os ao ba  state observation agree activity level        o∈Ω  each gene probability observation expected reward belief state vb  os zero os obser                         ≤          ≤                   maxa∈a  qa terminal vertices assigned expected  vations noisy  os  general goal reward  rewards  goal function describing desirable                                                                                          q⊥b     bsrs ⊥ ⊥  states assume goal maps states real values                  s∈s   domg →  reward function terminal actions                                       ⊥  ⊥  goal states deﬁned goal rs  ao algorithm solve ﬁnite horizon pomdp prob  assume reward associated actions    ao                                                       lem     search nilsson  space belief  intervention actions rs af s−  non       ao                                                     states   algorithm listed figure  takes plan  intervention rs af                   ning problem input iteratively constructs belief  initial situation initial situation distribution space graph rooted bi  algorithm involves three  grn states  domg →   mapping erated steps expand current plan expandplan  pomdp initial situation straightforward bi sw routine line  collect ancestors z’ new vertices                                                        line  compute current best partial plan line     formulation distinct initial belief state algorithm ends expands new vertices  explore traditional pomdp value policy itera following brieﬂy subroutines used ao  tion techniques computing ﬁnite horizon policy expandplan routine recursively walks current  use knowledge initial belief state guide ex plan ﬁnd unexpanded vertices lines  ﬁnding  pansion conditional plan searching forward vertex expand generates successors vertex  initial belief state possible focus plan construction lines  generating successors involves assigning ⊥  reachable belief states                              action vertex max horizon line                                                         structing vertices reached action observation  search                                               combinations lines  notice each vertex  section describes approach solving ﬁnite hori value initialized upper bound  zon pomdp start deﬁning semantics condi                                                          rmax  maxrs sh     maxrs  ⊥ ⊥  tional plans search space follow search    ss∈sa∈a                                                     ijcai                                                     aop                                                addancestorsz     expandedbifalse                                  z’                                                                                             repeat                                              ∃b st eb bp  ∈ bp  ∈            expandplan                                                                                    bi                                 z’  z’ ∪b       z’  addancestorsz                              end       updatez’                                        return z’                                                              updatez   expandplan               bhzn                                                                                                                                           expandedb                                   remove ∈ zst¬∃b ∈ zwhereeb  ∈                   ∈       eb bpb                                backupb               expandplan            z’             bpb hzn                  end         zz∪   z’                                     backupb       end                                           ∈ ∪⊥do                                                      compute qa       expandedbtrue               ∪                                         end                                                  vb   max   qa       hzn                                            a∈a∪⊥         ∪eb ⊥⊥  ⊥                        pb  argmax qa                                                            a∈a∪⊥        ∈ ∈ Ω                   ∪                                                      ao              ba                                              figure    subroutines                   ∪                           eb baa                               expandedbafalse                          dattap            vbormax                                                         expandplandb            end                                                                                                                     updatev      end    end                                            expandplandbhzn    return                                            hzn                                                               ∪eb ⊥⊥  ⊥             figure  ao search algorithm                                                                           ∈ ∈ Ω                                                                        ∪                                                                    ba  expected reward upper bound plays role prun         ∪                                                                               eb baa  ing vertices consideration search                 expandpland                                                                                ba hzn    expanding current plan expandplan returns     end  set expanded vertices order update      end  figure  ﬁnd best plan given new vertices  addancestors   adds z’ ancestor vertex ver     figure  datta enumeration algorithm  tex resulting set vertices consists ver                                            update  tex value best action change                           datta  update routine iteratively removes vertices entire graph   descendent calls backup vertices  remain backup routine computes value  vertex sets best action reason update chooses enumeration algorithm order compare planner  vertices descendent ensure each vertex work datta et al  provide description  value updated updated values children algorithm datta figure  unlike    ao  avoid computing entire belief space iterative ao datta consists steps expand  graph leading signiﬁcant savings problems large expandpland update each vertex ∈  horizons initializing vertices upper bound updatetheexpandpland   routine recursively expands  value possible ignore vertices consis reaching terminal vertex horizon line   tently lowest upper bound example backupifthere generating recursing each child vertex lines   exists action qvalue greater al  following expandpland update computes best  ternative actions best action set action each vertex   alternatives alternative actions unlike ao datta unable prune vertices ex  considered best expandsolution ex pansion making insensitive reward function  pand explore empirical evaluation result algorithms identical time  reward function signiﬁcant effect number space required different implemented  vertex expansions worst case possible expand algorithms planner demonstrate effec                                                     ijcai                                                                                                                     ao                   expansions                   expansions                       expansions      ao                                                                 datta                            datta                                                                  max                       max                                                                                    datta                            max                                                                                                                                                                                                                                                                                                                                                                                                  belief states           belief states                                          belief states                                                                                                                                                                                                                                                                                                                         horizon                           horizon                          horizon     figure  number expanded vertices random grn left wnta intervention center pirin intervention right                                                                     ao                              ao                   total time                    total time                      total time                                                                 datta                            datta                                                                                                                                            datta                                                                                                                                                        times       times                                        times                                                                                                                                                                                                                                                                                                                                                                                            horizon                      horizon                          horizon        figure  total planning times random grn left wnta intervention center pirin intervention right    tiveness grn intervention planning problems negative reward illustrates ability ao  implemented straightforward version datta et prune search space comparison enumeration  al  algorithm does make use efﬁ wnta grn reproduce intervention problems  ciency improvements planner using adds studied datta et al  ﬁrst directly intervenes  bryant  compact action belief state represen suppress wnta happens goal ob  tation duplicate belief state detection  serves pirin gene second attempts indirectly                                                        control wnta pirin predictor gene wnta    empirical evaluation                               intervention wnta problems use reward  test feasibility using planner solve grn inter function assigning interventions negative reward  vention problems experiment random grn goal activating wnta negative reward three  wnta grn    weeraratna et al  datta et al  use negative reward goal maintain consistency                                                                            following table summarizes features grns datta et al  model plans avoid activating                                                        wnta equivalent pursuing suppression                    dom              random                                wnta networks use initial belief state each gene            wnta                                 set activity level probability proportional  networks use seven genes each activity lev observed frequency data  els predictor functions gene each genes planner implemented ran ghz  predictors predictor functions selected ran linux machine gb ram each experiment  domly random grn learned microarray data given minute time limit plan  measurements mrna concentrations cell indi ner binary gene regulatory network encodings  cate gene activity levels wnta grn order did space visit  learn predictor functions use coefﬁcient determina httpverdeeasasuedugrn  tion cod statistic measure strength correlation random grn leftmost plot figure  depicts  tween predictor target genes normalized dis number expanded vertices including terminal actions  cretized data kim et al  use predic ao datta maximum possible max results  tor functions highest cod each gene setting ao indexed number indicating reward  weight equal cod                              sociated goal datta insensitive reward    grns study intervention problems max represents number vertices expanded search  random grn vary goal assign differ tree versus graph similar original implementation  ent rewards terminal states assigning interventions datta et al  implemented datta                                                     ijcai                                                    
