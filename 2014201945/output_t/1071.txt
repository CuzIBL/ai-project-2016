  morphological annotation large spontaneous speech corpus japanese                                   kiyotaka uchimoto     hitoshi isahara                     national institute information communications technology                       hikaridai seikacho sorakugun kyoto  japan                                       uchimotoisaharanictgojp                          abstract                          words each long word consists short                                                        words approximately oneeighth words      propose efﬁcient framework human       manually detected morphological information      aided morphological annotation large sponta partofspeech pos categories conjugation types      neous speech corpus corpus spon   assigned human annotators tagged mor      taneous japanese framework    pheme oneeighth csj tagged      word units deﬁnitions given cor annotators checked human annotators dis      pus words dictionary cussed disagreements resolved accura      training corpus morphologically analyze cies manual tagging short long words      given corpus high accuracy low labor oneeighth csj approximately       costs detecting words dictionary accuracies evaluated random sampling      putting reduce la took years tag oneeighth csj accurately      bor costs expanding training corpora based  tagging remainder morphological information      active learning                                  years remaining seven                                                        eighths csj tagged semiautomatically    introduction                                       paper methods detecting types  “spontaneous speech corpus processing technol word segments corresponding morphological informa  ogy” project sponsored construction large sponta tion accurately tag large spon  neous japanese speech corpus corpus spontaneous taneous speech corpus propose efﬁcient framework  japanese csj maekawa et al  csj collec humanaided morphological annotation large sponta  tion monologues dialogues majority mono neous speech corpus  logues academic presentations simulated public collectively short long words morphemeswe  speeches simulated public speeches short speeches use term morphological analysis process seg  presented speciﬁcally corpus paid nonprofessional menting given sentence row morphemes  speakers csj includes transcriptions speeches signing each morpheme morphological attributes  audio recordings goals pos category  project detect types word segments cor  responding morphological information transcriptions  framework morphological annotation  types word segments deﬁned mem  bers national institute japanese language series processes morphological analysis  called short words long wordsthetermshort word ap maintenance corpus morphological annotationour  proximates item ordinary japanese dictionary framework morphological annotation illustrated fig  long word represents various compounds length ure  purpose framework given annotated  morphological information each different corpus large raw corpus improve quality  short word included long word shorter annotated morphological information corpora  japanese phrasal unit bunsetsu example short low labor costs framework corpusbased morpho  long words “keitaisokaiseki ni tsuite ohanasi itashimasu” logical analyzer used deﬁnition set  like talk morphological analysis repre ofspeech categories word units changed  sented shown table  table each line indicates middle constructing corpus morphological  short word short words long words analyzer robust changes  shown                                                  framework morphological annotation consists    approximately  million short words detected three parts maintenance annotated corpus analysis  csj makes largest spontaneous speech cor large raw corpus enhancement linguistic resources  pus world hand fewer long described following sections                                                    ijcai                                                                                   table  example morphological analysis results                         short word                    label                   long word  ot   dicform lemma   pt   pos conjtype conjform     ot    dicform lemma  pos conjtype conjform  keitai keitai keitai form keˆtai noun               ba  keitaiso keitaiso keitaisokaiseki noun        element sufﬁx                       kaiseki kaiseki morphological  kaiseki kaiseki kaiseki analysis kaiseki noun       ia              analysis  ni   ni    ni        ni   ppp              case marker  nitsuite nitsuite nitsuite ppp         case marker  tsui tsuku tsuku relate tsui verb kagyo adf euphonic change                          compound  te   te    te        te   ppp              conjunctive                                         word  oo                 opreﬁx                             ohanashi ohanashi ohanashiitasu verb sagyo adf  hanashi hanasu hanasu talk hanashi verb sagyo adf  ia  itashi itasu talk  itashi itasu itasu   itashi verb sagyo adf           ia  masu masu  masu      masu aux       ending form       ba  masu  masu  masu     aux       ending form  ot orthographic transcription dicform dictionary form written kanji hiragana characters lemma lemma written  kanji hiragana characters pos partofspeech pt phonetic transcription written katakana characters conjtype  conjugation type conjform conjugation form ppp postpositional particle aux auxiliary verb adf adverbial form                                                          corpus method initially applied csj                                                        morphological information replaced method man                                                        ually examined                                                            analysis large raw corpus                                                             enhancement linguistic resources                                                        enhancement dictionary                                                        given raw corpus including unknown words                                                        dictionary training corpus detection er                                                        rors tend occur unknown words words left                                                        right unknown words cases single                                                        unknown word series unknown words                                                        unknown word consist known words unknown                                                        characters case accuracy morphological infor                                                        mation assigned raw corpus increased detecting      figure  framework morphological annotation  putting unknown words dictionary man                                                        ually examining words probability estimated low                                                        uchimoto et al     maintenance annotated corpus                 cost manual examination high word seg                                                        ments pos categories deﬁnitions  general annotated corpus training corpus cause csj types word deﬁnition cost  errors corpusbased analyzer easily overﬁts double type word segment consists  errors analysis accuracy decreases compounds types words manual examination  fore errors detected corrected avoid shortest word segments improves morphological  overﬁtting simplest way detect correct analysis accuracy types words use method  errors training corpus examine difference based chunking model uchimoto et al   original annotated corpus corpus auto methods morphological analy  matically annotated corpusbased analyzer trained sis csj number unknown words  using original annotated corpus previous studies reduced expanding conjugational words dictionary  boosting method anomaly detection method based conjugation chart developed members  applied detect errors corpus abney et al  national institute japanese language  eskin  method detecting correcting er  rors corpus proposed murata et al inthe active sampling  method detecting correcting errors difference general corpusbased morphological analysis  tween annotated labels original corpus quires large training corpus accuracy does  automatically annotated corpus ﬁrst detected each improve proportion simple increase train  difference probabilities labels original cor ing corpus model morphological analy  pus automatically annotated corpus calculated sis usually considers relationship adjacent words  model trained using original annotated corpus simply supplemented data rarely includes relation  labels original corpus probabilities lower ships initial training corpus  automatically annotated corpus replaced fore expanding training corpus data se  corresponding labels automatically annotated lected include sequences words possible                                                    ijcai                                                    difﬁcult morphological analysis model ana uchimoto et al  method uses model es  lyze expansion big improve timates likely string morpheme proba  ment achieved small supplement pos bility potential overcome unknown  sible argamonengelson et al reported data word problem used method morpho  usefully added training data selected extract logically analyze csj  ing sentences analysis results obtained using ran paper assume types word segments  domly selected models include great consistency short long words deﬁned long word  argamonengelson dagan howevertheyas    sists short words csj  sumed word boundaries given data                                                        method based morpheme model  unknown words method simply applied  japanese sentences word boundaries inconsistent given tokenized test corpus set strings  blank spaces used words japanese problem japanese morphological analysis reduced  sentences research assumed word boundaries assigning tags each string sen  given data unknown words tence string tagged   indicate  section describes active sampling method using single morpheme string morpheme grammatical  statistical model expanding training corpus    attribute assigned tag  assigned                                                        number grammatical attributes assigned morphemes    active sampling conducted follows three                                           assumptions assumptions set sentences problem assigning attribute                                                       string given sentence  minimize   extracted words extracted sen  tences probabilities threshold exam deﬁne morpheme model estimates likeli                                                       hood given string morpheme grammat  ined product probabilities estimated         ≤   ≤     morpheme model words set sentences ical attribute  implemented model                                                                                          three assumptions follows                 modeling framework  jaynes                                                          berger et al  model represented eq     similar errors tend appear speech                                                                                                                 exp                     speciﬁc words sequences words                         ij λij gij                                                               pλab                                       appear certain speech data                     zλb      compiled varied speeches possible                      ⎛              ⎞                                                                                        avoid examining erroneous words                 exp ⎝             ⎠      words each speech examined         zλ                   λij gij        maximum number examined words chosen                           ij      n×x        number words speech  called “future” categories clas    sentence errors product siﬁcation tagsfromton      probabilities estimated words low    called “history” contextual conditioning infor      preferred sentences low probabili mation enables make decision space      ties                                             futures zλb is normalizing constant determined                                                        requirement pλabfor bthecom    word probability certain threshold                considered correct                        putation pλ model dependent set                                                        “features” binary functions history      words whose probabilities thresh future instance features      old ignored  mentioned calcu                                                                                       ifhasb fja      ai      lated threshold set high reduce                                               chance errors ignored prelimi gij  fj “pos−major  verb         nary experiments threshold set                   accuracy obtained using threshold                                                         “hasb fj” binary function returns       higher                                                        tory feature fj features used experiments    models algorithms morphological          described section                                                           given sentence probabilities tags        analysis                                         estimated each length string sentence using  important problems morphological analy morpheme model possible divisions mor  sis posed unknown words words phemes sentence optimal using  dictionary training corpus statisti viterbi algorithm branch bound method each di  cal approaches applied problem vision represented particular division morphemes  ﬁnd unknown words corpora dic grammatical attributes sentence optimal di  tionary mori nagao  vision deﬁned division maximizes product  estimate model identify unknown words correctly probabilities estimated each morpheme division  kashioka et al  nagata  uchimoto et csj transcriptions consist basic forms pro  al used approaches proposed morphological nunciations pronunciation transcribed separately  analysis method based maximum entropy model basic form written kanji hiragana characters                                                    ijcai                                                    speech sounds faithfully transcribed katakana char set labels obtained ﬁnding division maximizes  acters pronunciation represented basic forms product probabilities estimated each label  kanji hiragana characters text targeted signed each short word model represented eq  morphological analysis transcription csj  equation labels  possible divisions morphemes sentence ob optimal set labels using viterbi algorithm  tained matched pronunciation each branch bound method hand svm  line representing bunsetsu using dynamic programming binary classiﬁer expanded multiclass  method morphemes phonetic transcription classiﬁer using multiclass methods pairwise  didates match aligned pronunciation elim method oneversusrest method optimal label  inated searching optimal division mor termined using svm model deterministically assigned  phemes                                               each short word features used experiments                                                        described section   method based chunking model  transformation rules                                    transformation rules automatically acquired                                                        training corpus extracting long words  long word segments pos information detected                                                        stituents short words labeled “b”  using method described detecting short word                                                        “i” rule constructed using extracted long word  segments pos information using morpheme                                                        adjacent short words left right exam  model                                                        ple rule shown figure  acquired exam    given types word segments longer                                                        ple shown table  rule indicates labels  consists compounds shorter problem detect                                                        “b” “i” “i” assigned “ni” postpositional parti  ing long word segments pos information                                                        cle “tsui” verb “te” postpositional particle respec  reduced problem assigning labels ex                                                        tively combination “nitsuite” transformed long  plained each short word model                                                        word having morphological information postpositional  estimates likelihood labels chunking model                                                        particle case marker compound word differ  implemented model support vector ma                                                        ent rules antecedent rule  chine svm based modeling frameworks labels                                                        highest frequency chosen rules applied  follows                                                        long word segment rules generalized following  ba beginning long word pos information steps      long word agrees short word                                                           delete posterior context  ia middle end long word pos informa      tion long word agrees short word  delete anterior posterior contexts  beginning long word pos information  delete anterior posterior contexts lexical      long word does agree short information orthographic transcriptions dictio      word                                                 nary forms lemmas phonetic transcriptions  middle end long word pos informa rules applied long word segment step      tion long word does agree short pos category leftmost constituent long word      word                                             assigned long word  label assigned leftmost constituent long word dictionary form lemma long word usually  “ba” “b” labels assigned constituents generated concatenating short words  long words “ia” “i” short word “ba” spoonerism example case long word “ipponbari”  “ia” assigned pos information cor consisting three short words “ichi” “hon” “hari”  responding long word pos information represents information phonetic transcriptions short words  set pos category conjugation type conjugation form used generate dictionary form lemma  detailed information pos shown table  long word concatenating short words  example table labels “label” column  assigned short words labels correctly  detected pos information long words ob  experiments discussion  tained short words “ba” “ia” assigned  experimental conditions  example pos information detected  long words “nitsuite” hand experiments used  short words   long word segment information assigned “nitsuite” long words training  short words   assigned labels constituents correct long words testing words extracted  cause additional pos information compound word oneeighth csj manually tagged  different pos information constituents training corpus consisted  speeches test  “ni” “tsui” “te” case pos information corpus consisted  speeches  obtained using transformation rules mentioned later experiments used basic forms pronunci    given sentence labeled beginningend ations transcriptions input morphological analy  endbeginning using mebased model optimal sis                                                    ijcai                                                               anterior context        transformation       posterior context    transformation    ot       kaiseki        ni         tsui           te                         nitsuite    dicform  kaiseki        ni         tsuku          te                         nitsuite    lemma    kaiseki        ni         tsuku          te                         nitsuite    pos      noun           ppp        verb           ppp        preﬁx         ⇒   ppp    conjtype                           kagyo    conjform                           adf                      case marker euphonic change conjunctive                case marker compound word    label    ia             bi                        ib                                       antecedent                                  consequent                                       figure  example transformation rule      sentences corpus boundaries experiments svmbased models used ana  selected places csj au lyze long words better results obtained using  tomatically detected pauses  ms longer des svmbased models mebased models prelim  ignated sentence boundaries addition inary experiments svmbased chunker yamchakudo  used utterance boundaries sentence boundaries matsumoto  used assign chunking  automatically detected places short pauses labels  tween   ms follow typical sentenceending selected following parameters yamcha based  forms predicates verbs adjectives copulas preliminary experiments    csj bunsetsu boundaries boundaries • degree polynomial kernel rd  japanese phrasal units manually detected fillers •  disﬂuencies marked labels analysis direction right left  experiments eliminated ﬁllers disﬂuencies • dynamic features preceding chunk labels  did use positional information features • multiclass method oneversusrest  used features bunsetsu boundaries labels  assigned particular morphemes used following information features target  personal names foreign words input words  sentences training testing character strings • morphological information orthographic transcription  ﬁllers disﬂuencies boundary information dictionary form lemma phonetic transcription pos  various labels attached candidate mor  category conjugation type conjugation form  phemes crossed bunsetsu boundaries ignored  detailed pos information  cause morphemes cross output se • boundary information bunsetsu various labels  quence morphemes grammatical attributes shown “ﬁller”  table  candidate morphemes pos informa                                                          •  tion corresponded correct morphemes used information target word  positive examples used negative ex closest words left right  amples used pos categories csj grammati target word  cal attributes obtained  major pos categories short morphological information approximately   long words eq   tags long words generated applying transformation rules    short words    features used morpheme  results discussion  models experiments each feature consists type results morphological analysis obtained  value corresponds function gij ing morpheme models shown table  table  eq  feature functions used combinations oov indicates outofvocabulary rates cal  features futures appeared three times culated proportion word morphological infor  training corpus features used experiments mation pairs dictionary pairs  basically uchimoto et al useduchi test corpus morphological information included  moto et al  main differences follows orthographic transcriptions dictionary forms lemmas pos                                                        categories conjugation types conjugation forms  strings following right twocharacter detailed pos information recall percentage mor      strings directly right target word phemes test corpus segmentation      character types combinations morphological information identiﬁed correctly preci      dictionary information target word used sion percentage morphemes identiﬁed sys      features                                         tem identiﬁed correctly fmeasure deﬁned  finegrained categories conjugation types forms harmonic mean recall precision      conjugation types forms divided ﬁne  table  line shows results obtained      grained categories according context      output short word analysis used input                                                    ijcai                                                    
