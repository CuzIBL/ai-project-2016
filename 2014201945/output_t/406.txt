                   factored search models sequences trees                                  dan klein                                  christopher manning                    department science                     department science                           stanford university                                 stanford university                        stanford ca                             stanford ca                           kleincsstanfordedu                             manningcsstanfordedu                              abstract                              sum scores arcs path lower                                                                  scores better particular assumption paper         investigate calculation bounds          arc scoring function special factored form         sequence tree models explicit          specifically exists set projections tt  ik         intersection set simpler models        nodes arcs graphs         bounded intersection provide            arc jc score given         natural viewpoint unifies various instances         factored models trees sequences         previously known novel includ•        ing multiple sequence alignment weighted finite        scoring function factors way         state transducer composition lexicalized sta•       immediate recipe factored  bound denote         tistical parsing specific case parsing      specifically bound shortest path         product syntactic pcfg semantic lexi•        node goal sum shortest paths inside         cal dependency components considered         each projection formally agn length         show factorization gives mod•     shortest path graph         ular lexicalized parser simpler com•       parably accurate nonfactored models         allows efficient exact inference large treebank         grammars                                                follows immediately optimality projected                                                                  paths structure scoring function pro•                                                                 jections need mutually compatible     introduction                                                bound tight broadly speaking greater de•                                                                 gree each projection prefers similar paths better    primary challenge using search heuris•                                                                 bound efficient search    tic functions simultaneously admissible close ac•   tual completion costs efficient calculate pa•   family tree sequence models       projection models sequences    path costs defined bounded com•   intuition consider applications sequence mod•   bination simpler component models each scores    els extending complex case tree models    projection structure models    exploit decoupled behavior each projection    example multiple sequence alignment    sharp heuristics combined space focus       situation fits framework perfectly align•   models trees sequences nlp applications     ment multiple genome sequences bioinformatics    approach applied generally   multiple sequence alignments msas standardly    case biological sequence models con• evaluated sumofpairs scoring durbin et al  msa    crete cases consider involve search spaces generalization longestcommonsubsequence prob•   equivalent dynamic programming lattices   lem given sequences like figure la    somewhat peripheral basic ideas       asked produce pointwise alignments alignments                                                                  sequences consist vertical timeslices     projection models graphs                                specify each sequence successive element                                                                  sequence gap  gaps re•   core idea factored search apply graph    moved rows contain original sequences score    search assume  large graph    timeslice sum scores each pairs    single source node single goal node      wish use search efficiently best path   talk minimum sums semirings work   concreteness assume score path specifically maximum products                                                                                                                   search figure  example multiple sequence alignment   original sequences multiple alignment timeslice dis•  tinguished sumofpairs scoring function timeslice                                                                 figure  effectiveness factored bound multiple   slice each pair symbols assigned    alignment sequence sets numbers data set names   experimental goodness value                                 number sequences aligned note log scale                                                                 example glob search trillion times     wellknown dynamic program calculating opti•                                                                efficient exhaustive search   mal multiple alignments involves lattice position nodes                  specify index each sequence     shows factored bounds highly effective   durbin et ai  each node visited each         potential worry search cost com•  successors each position in•                                                                puting heuristics substantial case   cremented relaxed best score through   pairwise alignments calculated efficiently   combined score timeslice change experiments presearch phase took   represents nodes form lattice size          total time   maximum length sequences be•  comes extremely inefficient grows                        example finite state transducers     specific following idea used ikeda    briefly potential application factored   lmai  tht earliest reference  search sequence models intersection weighted     worked recently yoshizumi et al  in•   finitestate transducers wfsts wfsts probabilistic   ter alia received attention mappings sequences alphabet sequences   deserves bioinformatics literature present example transducer map input    good example cast    written text output texts pronunciation   framework  gives good starting intuition  phoneme sequence intersections wfsts ap•  novel cases score arc timeslice plied various tasks speech nlp mohri    sum pairwise goodness scores define set texttospeech famously nlp lit•  projections each pair indices  erature modeling morphophonology kaplan kay    node project indices                   albro  cases each transducer constrains   easy optimal path projection just small portion overall output sequence case find•  optimal way alignment portions sequences    ing likely intersected output set wfsts   right indices respec•     input sequence involves following   tively bound total completion cost      each create projection output   away alignment onward sum pair        space mts output space note   wise completion costs way alignments inside each                                                                      identity projection   projection     figure  shows experimental speedups given         method compared exhaustive search took   protein sequence groups mcclure et ai             each set aligned large subset each group     transduction intersection fits cleanly fac•  possible using uniformcost search gb mem•       tored framework primary utility transducers lies   ory left runs show cost nodes visited   composition intersection mohri    aligning subsets uniformcost search   case transducers chained output   search right runs added sequence     serving input case   subsets solved multiple alignment using   worth switching talk summed distances talk   search savings substantial usually pro•   multiplied probabilities say transducers   viding orders magnitude uniformcost search  gives distribution sequences se•  orders magnitude exhaustive dynamic      quences gives   programming approach verifies previous findings                                                                     wfsts equivalent hmms emission weights                                                                 assigned transitions states epsilon      note dp run  fit memory    easy calculate size lattice transitions   subtleties running uniformcost search score simplicity assume history relevant transducer   timeslice negative add worst possible negative score encoded state space       search                                                                                                                                                                             symbol region input spans goal                                                                  node parse root symbol entire in•                                                                 ilyperpaths embody trees score path                                                                  combination scores arcs tree fine                                                                  point standard path source goal                                                                  through node  breaks smaller paths                                                                  tree case inside path                                                                  outside path shown right figure  general                                                                  completion structures represent paths goal                                                                  marked figure specified node   figure  representations parse tree path goal original source   edge hypergraph                                                 modification recipe factored                                                                  bound   wish answer questions composed be•  havior example want output   maximizes according model com•                                                                 present concrete projection model scoring lex  mon viterbi approximation settle                                                                  icalized trees construct parser using associated   pair  maximizes problem                                                                  factored bound   fit neatly factored framework usually false                                                                    generative models parsing natural language typically   conditional independence                                                                  model kinds structures shown figure    true  fact wfst intersection how•                                                                 wordfree syntactic configurations like embodied   close does trivially hold                                                                   phrase structure trees figure good capturing                     given define model                                                                  broad linear syntax language charniak  word                              proper probabilistic                                                                  toword affinities like embodied lexical dependency   model  assign probability trans•                                                                 trees figure shown important resolv•  duction  intersection does upperbound                                                                  ing difficult ambiguities hindle rooth    actual composed model projections pro•                                                                 kinds information relevant parsing trend   vide factored bound nonfactored model prac•                                                                 model lexicalized phrase structure trees like fig•  tical utility bound depending tightly                                                                  ure   typically bounds                                                                     current framework natural think lexi•                                                                 calizcd tree pair   phrase structure tree    projection models trees                                  dependency tree view generative mod•                                                                 els lexicalized trees sort standard lexicalized   search case trees standard directed                                                                  pcfg parsing collins  charniak  re•  graphs certain kind directed hypergraph                                                                  garded assigning mass pt pairs stan•  arcs multiple sources single tar•                                                                 dard approach builds joint model pt   multiple subtrees needed form                                                                  given word sequence searches maxi•  larger tree  figure  shows fragment hypergraph                                                                 mum posterior parse   small parse tree note lines going ar•  rowhead represent single hyperarc dont   definitions hypergraph search gallo et al    details basic idea traverse constant operationally searches instead   arc source nodes visited parse maximizer pt   case example build sentence node      naive way dynamic program   build noun phrase node adjacent verb phrase    called tabular parser chart parser works   node nodes graph arc identified grammar      follows core declarative object edge                                                                                 encapsulates parses span        directed bhypergraphs model explored labeled grammar symbol headed   andor trees ai                                            word edges correspond nodes                                                                                                                   search             extract pcfg projection set pcfg parser               use pcfg parser projection scores each edge               extract dependency projection set dependency parser               use dependency parser projection scores each edge               combine pcfg dependency projections model               form factored estimate                use combined parser hs estimate                figure  toplevel algorithm left illustration paths decompose parsing hypergraph right       parsing hypergraph edges  length increases estimates effective   combined contiguous right                 objectheavy java implementation com•  starts left ends grammar per•                bined parser total parse time dominated initial     mits combination example rewrite              arraybased pcfg phase figure                                edges combine   form combination scored               specific projection models parsing   joint model word symbol configuration                                                                           test factored parser built component mod•                      weighted combinations arcs                                                                           els intended show modularity ap•  hypergraph                                                                           proach merely sketch individual models      natural projection lexicalized tree com•        details klein manning     ponents knowledge projec•                 built successively accurate pcfgs simplest   tion exploited previously case              pcfgbasic used raw treebank grammar nontermi•  score combination                                nals rewrites taken directly training trees char                                                                          niak  model nodes rewrite atomically      kind projected model offers primary benefits            topdown manner ways observed training   building component models                 data improved models pt tree nodes labels   simpler projections designed engineered              annotated various contextual markers pcfgpa each   tested modularly easily underscore point              node marked parents label ljohnson    built three pcfg models pt lexical dependency              known annotation improves accu•  models pt section  discuss accuracy              racy pcfg parsing weakening pcfg independence   models combination                            assumptions example np figure actu•     second heuristic loose degree            ally labeled nps counts frag•  models prefer different structures         mented head word head tag able directly   combined search needs figure optimally               use mle parameters smoothing best   reconcile differences explore entire space            pcfg model pcfgling involved selective parent split•  legal structures figure  shows work                ting order rule markovization similar collins    uniformcost case versus case clearly               charniak  linguisticallyderived feature splits   uniformcost version parser dramatically ef•  ficient sentence length  extracts edges                note uniformcost parser does work exploit   length  heuristics effective         shared structure dynamic program edge                                                                           counts appear grow polynomially parser does   edges extracted length  av•                                                                          little work minimal structuresharing edge counts   erage number  fraction edges                                                                           appear grow exponentially sentence lengths   suppressed better  ok improves sentence          just like nondynamicprogramming parsers                                                                           longer sentences efficient estimate polynomial behav•                                                                          ior reappear       models including mention distance wc                                                                              thcre ways speeding lexicalized parsing with•  ignore                                                                                                                                 sacrificing search optimally eisner satta eisner satta       probabilistic model formulation mass deficient as•                                                                          propose clever modification separates pro•  signing mass pairs incompatible   generate terminal string embody compat•       cess steps introducing intermediate object   ible bracketings total mass assigned valid struc•    formulation impractical exhaustive parsing   tures imagine fixing renor     broadcoverage lexicalized treebank grammars essential   malizing particular situation fits productofexperts reason nonterminal set just large wc did imple•  framework hinton  semantic expert syn•         ment version parser using formulation be•  tactic expert agree single structure     cause effectiveness estimate marginally   presently interested finding mostlikely parses      faster figure shows combined search time small   global renormalization constants need calculated case      say smoothing improve perfor•  question mass deficiency impacts parameter estimation      mance underscore factored model encounters   inference focus                                 sparsity problems joint model       search                                                                                                                                                                                               parsing performance                                                                 section various projection models                                                                 test empirical performance ways mea•                                                                sure accuracy parses produced                                                                 phrase structure pcfg phrase structure pro•                                                                jection combination parsers compared                                                                 treebank parses parsing measures standardly used                                                                 task labeled precision recall report                                                                 fi harmonic mean quantities second                                                                 dependency combination parsers score                                                                 dependency structures dependency structure viewed                                                                 set headdependent pairs extra depen•                                                                dency root root special symbol                                                                 head sentence dependency model gen                                                                crates partofspeech tags ignored de•                                                                pendency accuracy punctuation scored de•                                                                pendency structures nonpunctuation terminals con•                                                                tain dependencies —  plus root dependency                                                                 report accuracy identical precision      models pd lexical dependency models       recall stressed correct dependency   deal partofspeech tagged words pairs structures generally correct generated    head constituent generated succes•         pcfg structures linguistically motivated automatic    sive right dependents stop token gen•             heuristic rules   erated successive left dependents generated                                                                    figure  shows relevant scores various pcfg   example figure  wc choose fellvbd                                                                 dependency parsers valence model increases   head sentence generate inin                                                                 dependency models accuracy      right generates septemberun right                                                                 each successive enhancement improves fj pcfg   generates sides return iiin gener•                                                                models    combination   ate right dependency models re•                                                                parsers performance given figure  each individ•  quired smoothing wordword dependency data                                                                 ual model improved combination improved   sparse basic model dbpbasic generate de•                                                                 pair basic models    pendent conditioned head direction requiring                                                                 pair models dependency accuracy goes    model estimated using                                                                   note pair ba•   backoff model interpolated sparse bilexical counts sic models combined dependency accuracy higher   denser specific counts given ignoring    enhanced dependency model three   head word generating dependent tag    combined better best pcfg model   generating dependent word given dependent   pair figure illustrates relative combina•  tag interpolation parameters estimated heldout  tion parser pcfg component showing unsur•   data resulting model capture classical bilexi• prising trend addition dependency model helps    cal selection affinity payrolls fell    monolexical preferences tendency                                                                   tree viewed set constituents ct constituents   modify nouns enhanced dependency model dep       correct proposed tree start end    val condition direction distance label considered identical measure lexical   valence note intentionally similar heads nodes irrelevant actual measures used detailed   generative model collins  broad structure magerman  involve minor normalizations like re•  substantially complex                                   moval punctuation comparison                                                                                                                  search 
